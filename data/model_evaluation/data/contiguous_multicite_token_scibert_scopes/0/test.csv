token_context,word_context,seg_context,sent_cotext,label
"['the authors  #TAUTHOR_TAG, an']","['the authors  #TAUTHOR_TAG, an']","['the authors  #TAUTHOR_TAG, an approach demonstrated']","['', 'some studies sampled tweets using small, ad hoc sets of keywords created by the authors  #TAUTHOR_TAG, an approach demonstrated to produce poor results  #AUTHOR_TAG.', '']",5
['transformer  #TAUTHOR_TAG 7 ]'],['transformer  #TAUTHOR_TAG 7 ]. in'],['transformer  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],1
['transformer  #TAUTHOR_TAG 7 ]'],['transformer  #TAUTHOR_TAG 7 ]. in'],['transformer  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],5
['transformer  #TAUTHOR_TAG 7 ]'],['transformer  #TAUTHOR_TAG 7 ]. in'],['transformer  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],5
['2 multi - head attention  #TAUTHOR_TAG'],['2. 2 multi - head attention  #TAUTHOR_TAG'],"['block - term tensor decomposition [ 9 ].', 'then, we describe in section 2. 2 multi - head attention  #TAUTHOR_TAG']","['- linear attention is carried out in this paper.', 'the analysis of multi - linear attention relies on these concepts and results from the field of tensor decomositon and multi - head attention.', 'we cover below in section 2. 1 basic background on block - term tensor decomposition [ 9 ].', 'then, we describe in section 2. 2 multi - head attention  #TAUTHOR_TAG']",5
['the transformer model  #TAUTHOR_TAG on'],['the transformer model  #TAUTHOR_TAG on'],"['2,..., y m ) representing the same phrase in a different language.', 'in this task, we have trained the transformer model  #TAUTHOR_TAG on']","['goal is to map an input sequence s = ( x 1, x 2,..., x n ) representing a phrase in one language, to an output sequence y = ( y 1, y 2,..., y m ) representing the same phrase in a different language.', 'in this task, we have trained the transformer model  #TAUTHOR_TAG on wmt 2016 english - german dataset [ 30 ].', 'sentences were tokenized using the sentencepiece 3.', 'for our experiments, we have replaced each of the attention layers with multi - linear attention.', 'for evaluation we used beam search with a beam size of 5 and length penalty α = 0. 6.', 'in this section, we only compared the results with transformer  #TAUTHOR_TAG.', 'our results are summarized in table 3.', '* indicates that the result is our own implementation.', 'in table 3, we select two baseline models.', 'the base - line [ 30 ] is first model in wmt 2016 english - german dataset.', 'for the other baseline, we use the basic transformer architecture  #TAUTHOR_TAG.', 'the bleu score is 34. 5 for the basic architecture.', 'we carry out two tensorized transformer structures, namely core - 1 and core - 2 respectively.', 'when tensorized transformer core - 1 and core - 2 are used, the bleu scores are 34. 10 and 34. 91, which achieves better performance over transformer.', 'as for the reported model parameter size, our model uses less parameters']",5
['the transformer model  #TAUTHOR_TAG on'],['the transformer model  #TAUTHOR_TAG on'],"['2,..., y m ) representing the same phrase in a different language.', 'in this task, we have trained the transformer model  #TAUTHOR_TAG on']","['goal is to map an input sequence s = ( x 1, x 2,..., x n ) representing a phrase in one language, to an output sequence y = ( y 1, y 2,..., y m ) representing the same phrase in a different language.', 'in this task, we have trained the transformer model  #TAUTHOR_TAG on wmt 2016 english - german dataset [ 30 ].', 'sentences were tokenized using the sentencepiece 3.', 'for our experiments, we have replaced each of the attention layers with multi - linear attention.', 'for evaluation we used beam search with a beam size of 5 and length penalty α = 0. 6.', 'in this section, we only compared the results with transformer  #TAUTHOR_TAG.', 'our results are summarized in table 3.', '* indicates that the result is our own implementation.', 'in table 3, we select two baseline models.', 'the base - line [ 30 ] is first model in wmt 2016 english - german dataset.', 'for the other baseline, we use the basic transformer architecture  #TAUTHOR_TAG.', 'the bleu score is 34. 5 for the basic architecture.', 'we carry out two tensorized transformer structures, namely core - 1 and core - 2 respectively.', 'when tensorized transformer core - 1 and core - 2 are used, the bleu scores are 34. 10 and 34. 91, which achieves better performance over transformer.', 'as for the reported model parameter size, our model uses less parameters']",5
['the transformer model  #TAUTHOR_TAG on'],['the transformer model  #TAUTHOR_TAG on'],"['2,..., y m ) representing the same phrase in a different language.', 'in this task, we have trained the transformer model  #TAUTHOR_TAG on']","['goal is to map an input sequence s = ( x 1, x 2,..., x n ) representing a phrase in one language, to an output sequence y = ( y 1, y 2,..., y m ) representing the same phrase in a different language.', 'in this task, we have trained the transformer model  #TAUTHOR_TAG on wmt 2016 english - german dataset [ 30 ].', 'sentences were tokenized using the sentencepiece 3.', 'for our experiments, we have replaced each of the attention layers with multi - linear attention.', 'for evaluation we used beam search with a beam size of 5 and length penalty α = 0. 6.', 'in this section, we only compared the results with transformer  #TAUTHOR_TAG.', 'our results are summarized in table 3.', '* indicates that the result is our own implementation.', 'in table 3, we select two baseline models.', 'the base - line [ 30 ] is first model in wmt 2016 english - german dataset.', 'for the other baseline, we use the basic transformer architecture  #TAUTHOR_TAG.', 'the bleu score is 34. 5 for the basic architecture.', 'we carry out two tensorized transformer structures, namely core - 1 and core - 2 respectively.', 'when tensorized transformer core - 1 and core - 2 are used, the bleu scores are 34. 10 and 34. 91, which achieves better performance over transformer.', 'as for the reported model parameter size, our model uses less parameters']",5
"['of transformer.', 'previous work  #TAUTHOR_TAG gets the multi - head attention by multiple groups of linear mappings']","['of transformer.', 'previous work  #TAUTHOR_TAG gets the multi - head attention by multiple groups of linear mappings.', 'we use three linear ma for matrices q, k and']","['our focus is on the compression of the multi - head mechanism in the multi - head attention of transformer.', 'previous work  #TAUTHOR_TAG gets the multi - head attention by multiple groups of linear mappings.', 'we use three linear ma for matrices q, k and']","['our focus is on the compression of the multi - head mechanism in the multi - head attention of transformer.', 'previous work  #TAUTHOR_TAG gets the multi - head attention by multiple groups of linear mappings.', 'we use three linear ma for matrices q, k and v, respectively.', 'for the output of three mappings, we choose to share them which are considered as three factor matrices in reconstructing the multi - linear attention.', 'this process is shown in figure 2 ( left ).', 'h is the number of heads in  #TAUTHOR_TAG, and d is the dimension of factor matrices.', 'the compression ratios can be computed by ( 3 × h × d ) / ( 3 × d + h ).', 'in practice, h is normally set to 8, d is set to 512.', '']",3
"['of transformer.', 'previous work  #TAUTHOR_TAG gets the multi - head attention by multiple groups of linear mappings']","['of transformer.', 'previous work  #TAUTHOR_TAG gets the multi - head attention by multiple groups of linear mappings.', 'we use three linear ma for matrices q, k and']","['our focus is on the compression of the multi - head mechanism in the multi - head attention of transformer.', 'previous work  #TAUTHOR_TAG gets the multi - head attention by multiple groups of linear mappings.', 'we use three linear ma for matrices q, k and']","['our focus is on the compression of the multi - head mechanism in the multi - head attention of transformer.', 'previous work  #TAUTHOR_TAG gets the multi - head attention by multiple groups of linear mappings.', 'we use three linear ma for matrices q, k and v, respectively.', 'for the output of three mappings, we choose to share them which are considered as three factor matrices in reconstructing the multi - linear attention.', 'this process is shown in figure 2 ( left ).', 'h is the number of heads in  #TAUTHOR_TAG, and d is the dimension of factor matrices.', 'the compression ratios can be computed by ( 3 × h × d ) / ( 3 × d + h ).', 'in practice, h is normally set to 8, d is set to 512.', '']",4
['to domainspecific corpora. the dpmm used in  #TAUTHOR_TAG'],['##able to domainspecific corpora. the dpmm used in  #TAUTHOR_TAG for clustering'],"['is easily adaptable to domainspecific corpora. the dpmm used in  #TAUTHOR_TAG for clustering verb senses.', 'm is the number of verb senses, and n is the sum total of slot counts for', 'that verb sense']","['', 'that verb, creating regularities in language to which speakers are extremely sensitive. it follows that', 'grouping verbs by allowable syntactic realizations leads from syntax to meaningful semantic groupings. this seed grew into verbnet, a process which involved', 'dozens of linguists and a decade of work, making careful decisions about the allowable syntactic', 'frames for various verb senses, informed by text examples. verbnet is useful for semantic role labeling and related tasks  #AUTHOR_TAG merlo and van der  #AUTHOR_TAG, but its widespread use is limited by coverage. not', 'all verbs have a verbnet class, and some polysemous verbs have important senses unaccounted for. in addition, verbnet is', 'not easily adaptable to domainspecific corpora, so these omissions may be more prominent outside of the general - purpose', 'corpora and linguistic intuition used in its construction. its great strength is also its downfall : adding new verbs, new senses, and new classes requires trained linguists - at least, to preserve', ""the integrity of the resource. according to levin's hypothesis, knowing the set of allowable syntactic patterns for a verb sense is sufficient to make meaningful semantic classifications. large - scale"", 'corpora provide an extremely comprehensive picture of the possible syntactic realizations for any particular verb. with enough data in the training set, even infrequent', 'verbs have sufficient data to support learning.  #AUTHOR_TAG showed that, using a dirichlet process mixture model (', 'dpmm ), a verbnet - like clustering of verb senses can be built from counts', 'of syntactic features. we develop a model to extend verbnet, using a large corpus with machine - annotated dependencies. we build on prior work by adding partial supervision from', 'verbnet, treating verbnet classes as additional latent variables. the resulting clusters are more similar to', 'the evaluation set, and each cluster in the dpmm predicts its verbnet class distribution naturally. because the technique', 'is data - driven, it is easily adaptable to domainspecific corpora. the dpmm used in  #TAUTHOR_TAG for clustering verb senses.', 'm is the number of verb senses, and n is the sum total of slot counts for', 'that verb sense']",5
"['dpmm used in  #TAUTHOR_TAG is shown in figure 1.', 'the clusters are drawn from a dirichlet process with hyperparameter α and base distribution g. the dirichlet process prior creates a clustering effect described by the chinese restaurant process.', 'each cluster is chosen proportional']","['dpmm used in  #TAUTHOR_TAG is shown in figure 1.', 'the clusters are drawn from a dirichlet process with hyperparameter α and base distribution g. the dirichlet process prior creates a clustering effect described by the chinese restaurant process.', 'each cluster is chosen proportionally']","['dpmm used in  #TAUTHOR_TAG is shown in figure 1.', 'the clusters are drawn from a dirichlet process with hyperparameter α and base distribution g. the dirichlet process prior creates a clustering effect described by the chinese restaurant process.', 'each cluster is chosen proportionally']","['dpmm used in  #TAUTHOR_TAG is shown in figure 1.', 'the clusters are drawn from a dirichlet process with hyperparameter α and base distribution g. the dirichlet process prior creates a clustering effect described by the chinese restaurant process.', 'each cluster is chosen proportionally to the number of elements it already contains, i. e.', 'where c k ( * ) is the count of clustered items already in cluster k. each cluster k has an associated multinomial distribution over vocabulary items ( e. g. slot : token pairs ), φ k, which is drawn from g, a dirichlet distribution of the same size as the vocabulary, parameterized by a constant β.', ""because the dirichlet is the multinomial's conjugate prior, we can actually integrate out φ k analytically, given counts of vocabulary items drawn from φ k."", 'for a particular vocabulary item w, we compute', 'where c k ( w ) is the number of times w has been drawn from', ', and | v | is the size of the vocabulary.', ""when assigning a verb instance to a sense, a single instance may have multiple syntactic arguments w. using bayes's law, we update each assignment iteratively using gibbs sampling, using equations ( 1 ) and ( 2 ), according to"", 'β < 1 encourages the clusters to have a sparse representation in the vocabulary space.', 'α = 1 is a typical choice, and encourages a small number of clusters to be used']",5
"['level categories, simplifying the selection process for y. in  #TAUTHOR_TAG, slot features were most effective features at producing a']","['and with marginalized y.', 'when incorporating supervision, we flatten verbnet, using only the top - level categories, simplifying the selection process for y. in  #TAUTHOR_TAG, slot features were most effective features at producing a verbnet - like structure ; we follow suit']","['.', 'when incorporating supervision, we flatten verbnet, using only the top - level categories, simplifying the selection process for y. in  #TAUTHOR_TAG, slot features were most effective features at producing a verbnet - like structure ; we follow suit']","['incorporating supervision, the more direct method of downstream sampling of the verbnet class may be preferred to using a prior.', 'however, the verb senses are generated through a dpmm, and we do not have a gold - label assignment of verbnet classes to each sense.', 'instead, we estimate, for each verb in verbnet, a distribution θ describing the likelihood a verb will participate in a particular class, using counts from semlink.', 'when sampling a cluster for a verb sense with a verb in verbnet, we sample y from a product of experts.', 'we cannot incorporate θ as a prior when sampling y, because we have multiple verbs, with distinct distributions θ v 1, θ v 2,....', 'because the product - of - experts is a discrete probability distribution, it is easy to marginalize out this variable when sampling k, using', 'either way, once a cluster is selected, we should update the ρ and θ.', 'so, once a cluster is selected, we still sample a discrete y. we compare performance for sampling k with assigned y and with marginalized y.', 'when incorporating supervision, we flatten verbnet, using only the top - level categories, simplifying the selection process for y. in  #TAUTHOR_TAG, slot features were most effective features at producing a verbnet - like structure ; we follow suit']",5
"['dataset and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous']","['dataset and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous']","['and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous verb classes of  #AUTHOR_TAG, a subset of frequent polysemous verbs.', 'this']","['evaluation, we compare using the same dataset and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous verb classes of  #AUTHOR_TAG, a subset of frequent polysemous verbs.', 'this makes the test set a sort of miniverbnet, suitable for evaluation.', 'they also define a normalized modified purity and normalized inverse purity for evaluation, explained below.', ""the standard purity of a hard clustering averages, for each cluster's majority gold standard class, the percentage of clustered items of that class."", 'because the clustering is polysemous, a typical automatically - induced cluster k will contain only some senses of the verbs.', ""we take this partial membership into account when deciding the cluster's majority class."", 'we define c iv ∈ [ 0, 1 ] as the proportion of instances of verb v grouped into cluster k i.', 'we also treat induced clusters containing only one verb sense as errors, rather than treating them as clusters of perfect purity.', 'therefore, the normalized modified purity ( nmpu ), with respect to the gold standard clusters g, is,', 'where', 'this nmpu is analagous to clustering precision : it measures, on average, how well the clustering avoids matching items that should not be clustered.', 'we also define a recall analogue, the normalized inverse purity ( nipu ), as,', '']",5
"['dataset and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous']","['dataset and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous']","['and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous verb classes of  #AUTHOR_TAG, a subset of frequent polysemous verbs.', 'this']","['evaluation, we compare using the same dataset and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous verb classes of  #AUTHOR_TAG, a subset of frequent polysemous verbs.', 'this makes the test set a sort of miniverbnet, suitable for evaluation.', 'they also define a normalized modified purity and normalized inverse purity for evaluation, explained below.', ""the standard purity of a hard clustering averages, for each cluster's majority gold standard class, the percentage of clustered items of that class."", 'because the clustering is polysemous, a typical automatically - induced cluster k will contain only some senses of the verbs.', ""we take this partial membership into account when deciding the cluster's majority class."", 'we define c iv ∈ [ 0, 1 ] as the proportion of instances of verb v grouped into cluster k i.', 'we also treat induced clusters containing only one verb sense as errors, rather than treating them as clusters of perfect purity.', 'therefore, the normalized modified purity ( nmpu ), with respect to the gold standard clusters g, is,', 'where', 'this nmpu is analagous to clustering precision : it measures, on average, how well the clustering avoids matching items that should not be clustered.', 'we also define a recall analogue, the normalized inverse purity ( nipu ), as,', '']",5
"['dataset and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous']","['dataset and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous']","['and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous verb classes of  #AUTHOR_TAG, a subset of frequent polysemous verbs.', 'this']","['evaluation, we compare using the same dataset and metrics as  #TAUTHOR_TAG.', 'there, the authors use the polysemous verb classes of  #AUTHOR_TAG, a subset of frequent polysemous verbs.', 'this makes the test set a sort of miniverbnet, suitable for evaluation.', 'they also define a normalized modified purity and normalized inverse purity for evaluation, explained below.', ""the standard purity of a hard clustering averages, for each cluster's majority gold standard class, the percentage of clustered items of that class."", 'because the clustering is polysemous, a typical automatically - induced cluster k will contain only some senses of the verbs.', ""we take this partial membership into account when deciding the cluster's majority class."", 'we define c iv ∈ [ 0, 1 ] as the proportion of instances of verb v grouped into cluster k i.', 'we also treat induced clusters containing only one verb sense as errors, rather than treating them as clusters of perfect purity.', 'therefore, the normalized modified purity ( nmpu ), with respect to the gold standard clusters g, is,', 'where', 'this nmpu is analagous to clustering precision : it measures, on average, how well the clustering avoids matching items that should not be clustered.', 'we also define a recall analogue, the normalized inverse purity ( nipu ), as,', '']",5
"['and  #TAUTHOR_TAG showed distinct ways of applying the hierarchical dirichlet process  #AUTHOR_TAG to uncover the latent clusters from cluster examples.', 'the latter used significantly larger corpora, and explicitly separated verb sense induction from']","['and  #TAUTHOR_TAG showed distinct ways of applying the hierarchical dirichlet process  #AUTHOR_TAG to uncover the latent clusters from cluster examples.', 'the latter used significantly larger corpora, and explicitly separated verb sense induction from']","['and  #TAUTHOR_TAG showed distinct ways of applying the hierarchical dirichlet process  #AUTHOR_TAG to uncover the latent clusters from cluster examples.', 'the latter used significantly larger corpora, and explicitly separated verb sense induction from the syntactic / semantic clustering, which allowed more fine - grained control of each step.', ""in  #TAUTHOR_TAG, two identical dpmm's were used""]","['and  #TAUTHOR_TAG showed distinct ways of applying the hierarchical dirichlet process  #AUTHOR_TAG to uncover the latent clusters from cluster examples.', 'the latter used significantly larger corpora, and explicitly separated verb sense induction from the syntactic / semantic clustering, which allowed more fine - grained control of each step.', ""in  #TAUTHOR_TAG, two identical dpmm's were used."", 'the first clustered verb instances into senses, and one such model was trained for each verb.', 'these verb - sense clusters are available publicly, and are used unmodified in this paper.', 'the second dpmm clusters verb senses into verbnet - like clusters of verbs.', 'the result is a resource that, like verbnet, inherently captures the inherent polysemy of verbs.', 'we focus our improvements on this second step, and try to derive verb clusters that more closely align to verbnet']",0
"['and  #TAUTHOR_TAG showed distinct ways of applying the hierarchical dirichlet process  #AUTHOR_TAG to uncover the latent clusters from cluster examples.', 'the latter used significantly larger corpora, and explicitly separated verb sense induction from']","['and  #TAUTHOR_TAG showed distinct ways of applying the hierarchical dirichlet process  #AUTHOR_TAG to uncover the latent clusters from cluster examples.', 'the latter used significantly larger corpora, and explicitly separated verb sense induction from']","['and  #TAUTHOR_TAG showed distinct ways of applying the hierarchical dirichlet process  #AUTHOR_TAG to uncover the latent clusters from cluster examples.', 'the latter used significantly larger corpora, and explicitly separated verb sense induction from the syntactic / semantic clustering, which allowed more fine - grained control of each step.', ""in  #TAUTHOR_TAG, two identical dpmm's were used""]","['and  #TAUTHOR_TAG showed distinct ways of applying the hierarchical dirichlet process  #AUTHOR_TAG to uncover the latent clusters from cluster examples.', 'the latter used significantly larger corpora, and explicitly separated verb sense induction from the syntactic / semantic clustering, which allowed more fine - grained control of each step.', ""in  #TAUTHOR_TAG, two identical dpmm's were used."", 'the first clustered verb instances into senses, and one such model was trained for each verb.', 'these verb - sense clusters are available publicly, and are used unmodified in this paper.', 'the second dpmm clusters verb senses into verbnet - like clusters of verbs.', 'the result is a resource that, like verbnet, inherently captures the inherent polysemy of verbs.', 'we focus our improvements on this second step, and try to derive verb clusters that more closely align to verbnet']",0
"['be optimized for the distinct tasks.', 'according to  #TAUTHOR_TAG, the best features']","['be optimized for the distinct tasks.', 'according to  #TAUTHOR_TAG, the best features']","['senses, the features can be optimized for the distinct tasks.', 'according to  #TAUTHOR_TAG, the best features']","['separating the verb sense induction and the clustering of verb senses, the features can be optimized for the distinct tasks.', 'according to  #TAUTHOR_TAG, the best features for inducing verb classes are joint slot : token pairs.', 'for the verb clustering task, slot features which ignore the lexical items were the most effective.', ""this aligns with levin's hypothesis of diathesis alternations - the syntactic contexts are sufficient for the clustering."", 'in this paper, we re - create the second stage clustering with the same features, but add supervision.', 'supervised topic modeling ( mimno and mc  #AUTHOR_TAG builds on the bayesian framework by adding, for each item, a prediction about a variable of interest, which is observed at least some of the time.', 'this encourages the topics to be useful at predicting a supervised signal, as well as coherent as topics.', ""we do not have explicit knowledge of verbnet class for any of the first - level dpmm's verb senses, so our supervision is informed only at the level of the verb""]",0
"['##r process may bring finer control over the number of clusters.', 'we have expanded the work in  #TAUTHOR_TAG by explicitly modeling a verbnet class']","['dirichlet process for a pitman - yor process may bring finer control over the number of clusters.', 'we have expanded the work in  #TAUTHOR_TAG by explicitly modeling a verbnet class']","['supervision tends to encourage a smaller number of clusters, so the precision - like metric, nmpu, is lower, but the recall - like metric, nipu, is much higher.', 'marginalizing out the variable y when sampling k does not make an appreciable difference to the f1 score.', 'swapping out the dirichlet process for a pitman - yor process may bring finer control over the number of clusters.', 'we have expanded the work in  #TAUTHOR_TAG by explicitly modeling a verbnet class']","['supervision tends to encourage a smaller number of clusters, so the precision - like metric, nmpu, is lower, but the recall - like metric, nipu, is much higher.', 'marginalizing out the variable y when sampling k does not make an appreciable difference to the f1 score.', 'swapping out the dirichlet process for a pitman - yor process may bring finer control over the number of clusters.', 'we have expanded the work in  #TAUTHOR_TAG by explicitly modeling a verbnet class for each verb sense, drawn from a product of experts based on the cluster and verb.', 'this allowed us to leverage data from semlink with verbnet annotation, to produce a higher - quality clustering.', 'it also allows us to describe each cluster in terms of alignment to verbnet classes.', ""both of these improvements bring us closer to extending verbnet's usefulness, using only automated dependency parses of corpora."", 'we may speculate, and should test, whether the improved verb clusters will prove useful in end - to - end semantic tasks']",6
['( 3 ) we release the first broad - coverage dataset for evaluation of lexical dialectology models ; ( 4 ) we incorporate our text - based model into a network - based model  #TAUTHOR_TAG and improve the performance utilising both network and text ; and ('],['to the specific location discretisation method ; ( 3 ) we release the first broad - coverage dataset for evaluation of lexical dialectology models ; ( 4 ) we incorporate our text - based model into a network - based model  #TAUTHOR_TAG and improve the performance utilising both network and text ; and ( 5 )'],['to the specific location discretisation method ; ( 3 ) we release the first broad - coverage dataset for evaluation of lexical dialectology models ; ( 4 ) we incorporate our text - based model into a network - based model  #TAUTHOR_TAG and improve the performance utilising both network and text ; and ('],"['', 'explicit user geolocation metadata ( e. g. gps tags, wifi footprint, ip address ) is not usually available to third - party consumers, giving rise to the need for geolocation based on profile data, text content, friendship graphs  #AUTHOR_TAG or some combination of these  #AUTHOR_TAG b, a ).', 'the strong geographical bias, most obviously at the language level ( e. g. finland vs. japan ), and more subtly at the dialect level ( e. g. in english used in north - west england vs. north - east usa vs. texas, usa ), clearly reflected in language use in social media services such as twitter, has been used extensively either for geolocation of users  #AUTHOR_TAG or dialectology  #AUTHOR_TAG.', 'in these methods, a user is often represented by the concatenation of their tweets, and the geolocation model is trained on a very small percentage of explicitly geotagged tweets, noting the potential biases implicit in geotagged tweets  #AUTHOR_TAG.', 'lexical dialectology is ( in part ) the converse of user geolocation  #AUTHOR_TAG : given text associated with a variety of regions, the task is to identify terms that are distinctive of particular regions.', 'the complexity of the task is two - fold : ( 1 ) localised named entities ( e. g. sporting team names ) are not of interest ; and ( 2 ) without semantic knowledge it is difficult to detect terms that are in general use but have a special meaning in a region.', 'in this paper we propose a text - based geolocation method based on neural networks.', ""our contributions are as follows : ( 1 ) we achieve state - of - the - art results on benchmark twitter geolocation datasets ; ( 2 ) we show that the model is less sensitive to the specific location discretisation method ; ( 3 ) we release the first broad - coverage dataset for evaluation of lexical dialectology models ; ( 4 ) we incorporate our text - based model into a network - based model  #TAUTHOR_TAG and improve the performance utilising both network and text ; and ( 5 ) we use the model's embeddings for extraction of local terms and show that it outperforms two baselines""]",0
"['discretised regions  #TAUTHOR_TAG as labels, and use label propagation over']","['discretised regions  #TAUTHOR_TAG as labels, and use label propagation over']","['discretised regions  #TAUTHOR_TAG as labels, and use label propagation over the interaction graph (']","['work on twitter user geolocation falls into two categories : text - based and network - based methods.', 'text - based methods make use of the geographical biases of language use, and networkbased methods rely on the geospatial homophily of user - user interactions.', 'in both cases, the assumption is that users who live in the same geographic area share similar features ( linguistic or interactional ).', 'three main text - based approaches are : ( 1 ) the use of gazetteers  #AUTHOR_TAG ; ( 2 ) unsupervised text clustering based on topic models or similar  #AUTHOR_TAG ; and ( 3 ) supervised classification  #AUTHOR_TAG, which unlike gazetteers can be applied to informal text and compared to topic models, scales better.', 'the classification models often rely on less than 1 % of geotagged tweets for supervision and discretise real - valued coordinates into equalsized grids  #AUTHOR_TAG, administrative regions  #AUTHOR_TAG or flat  #AUTHOR_TAG or hierarchical k - d tree clusters  #AUTHOR_TAG.', 'network - based methods also use either real - valued coordinates  #AUTHOR_TAG or discretised regions  #TAUTHOR_TAG as labels, and use label propagation over the interaction graph ( e. g. @ - mentions ).', 'more recent methods have focused on representation learning by using sparse coding  #AUTHOR_TAG or neural networks  #AUTHOR_TAG, utilising both text and network information  #TAUTHOR_TAG.', 'dialect is a variety of language shared by a group of speakers  #AUTHOR_TAG.', 'our focus here is on geographical dialects which are spoken ( and written in social media ) by people from particular areas.', 'the traditional approach to dialectology is to find the geographical distribution of known lexical alternatives ( e. g. you, yall and yinz :  #AUTHOR_TAG goncalves and sanchez, 2014 ;  #AUTHOR_TAG ), the shortcoming of which is that the alternative lexical variables must be known beforehand.', 'there have also been attempts to automatically identify such words from geotagged documents  #AUTHOR_TAG.', 'the main idea is to find lexical variables that are disproportionately distributed in different locations either via model - based or statistical methods  #AUTHOR_TAG.', 'there is a research gap in evaluating the geolocation models in terms of their usability in retrieving dialect terms given a geographic region.', 'we use a text - based neural approach trained on geotagged twitter messages that : ( a ) given a geographical region, identifies the associated lexical terms ; and ( b ) given a text, predicts its location']",0
"['discretised regions  #TAUTHOR_TAG as labels, and use label propagation over']","['discretised regions  #TAUTHOR_TAG as labels, and use label propagation over']","['discretised regions  #TAUTHOR_TAG as labels, and use label propagation over the interaction graph (']","['work on twitter user geolocation falls into two categories : text - based and network - based methods.', 'text - based methods make use of the geographical biases of language use, and networkbased methods rely on the geospatial homophily of user - user interactions.', 'in both cases, the assumption is that users who live in the same geographic area share similar features ( linguistic or interactional ).', 'three main text - based approaches are : ( 1 ) the use of gazetteers  #AUTHOR_TAG ; ( 2 ) unsupervised text clustering based on topic models or similar  #AUTHOR_TAG ; and ( 3 ) supervised classification  #AUTHOR_TAG, which unlike gazetteers can be applied to informal text and compared to topic models, scales better.', 'the classification models often rely on less than 1 % of geotagged tweets for supervision and discretise real - valued coordinates into equalsized grids  #AUTHOR_TAG, administrative regions  #AUTHOR_TAG or flat  #AUTHOR_TAG or hierarchical k - d tree clusters  #AUTHOR_TAG.', 'network - based methods also use either real - valued coordinates  #AUTHOR_TAG or discretised regions  #TAUTHOR_TAG as labels, and use label propagation over the interaction graph ( e. g. @ - mentions ).', 'more recent methods have focused on representation learning by using sparse coding  #AUTHOR_TAG or neural networks  #AUTHOR_TAG, utilising both text and network information  #TAUTHOR_TAG.', 'dialect is a variety of language shared by a group of speakers  #AUTHOR_TAG.', 'our focus here is on geographical dialects which are spoken ( and written in social media ) by people from particular areas.', 'the traditional approach to dialectology is to find the geographical distribution of known lexical alternatives ( e. g. you, yall and yinz :  #AUTHOR_TAG goncalves and sanchez, 2014 ;  #AUTHOR_TAG ), the shortcoming of which is that the alternative lexical variables must be known beforehand.', 'there have also been attempts to automatically identify such words from geotagged documents  #AUTHOR_TAG.', 'the main idea is to find lexical variables that are disproportionately distributed in different locations either via model - based or statistical methods  #AUTHOR_TAG.', 'there is a research gap in evaluating the geolocation models in terms of their usability in retrieving dialect terms given a geographic region.', 'we use a text - based neural approach trained on geotagged twitter messages that : ( a ) given a geographical region, identifies the associated lexical terms ; and ( b ) given a text, predicts its location']",0
"['based model based on the method of  #TAUTHOR_TAG, and improved upon their work.', 'we analysed the']","['tree by a reasonable margin.', 'we also incorporated the mlp predictions into a network - based model based on the method of  #TAUTHOR_TAG, and improved upon their work.', 'we analysed the']","['d tree by a reasonable margin.', 'we also incorporated the mlp predictions into a network - based model based on the method of  #TAUTHOR_TAG, and improved upon their work.', 'we analysed the']","['', 'comparing the two discretisation strategies, k - means outperforms k - d tree by a reasonable margin.', 'we also incorporated the mlp predictions into a network - based model based on the method of  #TAUTHOR_TAG, and improved upon their work.', 'we analysed the table 2 : nearest neighbours of place names.', '']",0
['( 3 ) we release the first broad - coverage dataset for evaluation of lexical dialectology models ; ( 4 ) we incorporate our text - based model into a network - based model  #TAUTHOR_TAG and improve the performance utilising both network and text ; and ('],['to the specific location discretisation method ; ( 3 ) we release the first broad - coverage dataset for evaluation of lexical dialectology models ; ( 4 ) we incorporate our text - based model into a network - based model  #TAUTHOR_TAG and improve the performance utilising both network and text ; and ( 5 )'],['to the specific location discretisation method ; ( 3 ) we release the first broad - coverage dataset for evaluation of lexical dialectology models ; ( 4 ) we incorporate our text - based model into a network - based model  #TAUTHOR_TAG and improve the performance utilising both network and text ; and ('],"['', 'explicit user geolocation metadata ( e. g. gps tags, wifi footprint, ip address ) is not usually available to third - party consumers, giving rise to the need for geolocation based on profile data, text content, friendship graphs  #AUTHOR_TAG or some combination of these  #AUTHOR_TAG b, a ).', 'the strong geographical bias, most obviously at the language level ( e. g. finland vs. japan ), and more subtly at the dialect level ( e. g. in english used in north - west england vs. north - east usa vs. texas, usa ), clearly reflected in language use in social media services such as twitter, has been used extensively either for geolocation of users  #AUTHOR_TAG or dialectology  #AUTHOR_TAG.', 'in these methods, a user is often represented by the concatenation of their tweets, and the geolocation model is trained on a very small percentage of explicitly geotagged tweets, noting the potential biases implicit in geotagged tweets  #AUTHOR_TAG.', 'lexical dialectology is ( in part ) the converse of user geolocation  #AUTHOR_TAG : given text associated with a variety of regions, the task is to identify terms that are distinctive of particular regions.', 'the complexity of the task is two - fold : ( 1 ) localised named entities ( e. g. sporting team names ) are not of interest ; and ( 2 ) without semantic knowledge it is difficult to detect terms that are in general use but have a special meaning in a region.', 'in this paper we propose a text - based geolocation method based on neural networks.', ""our contributions are as follows : ( 1 ) we achieve state - of - the - art results on benchmark twitter geolocation datasets ; ( 2 ) we show that the model is less sensitive to the specific location discretisation method ; ( 3 ) we release the first broad - coverage dataset for evaluation of lexical dialectology models ; ( 4 ) we incorporate our text - based model into a network - based model  #TAUTHOR_TAG and improve the performance utilising both network and text ; and ( 5 ) we use the model's embeddings for extraction of local terms and show that it outperforms two baselines""]",6
"['', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for']","['for acc @ 161.', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for']","['', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for']","['', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for twitter - world were over a superset of the dataset ; the results reported here are based on the actual dataset.', 'while the focus of this paper is text - based user geolocation, state - of - the - art results for the three datasets have been achieved with hybrid text + network - based models, where the predictions of the text - based model are fed into a mention network as "" dongle "" nodes to each user node, providing a personalised geolocation prior for each user  #TAUTHOR_TAG.', 'note that it would, of course, be possible to combine text and network information in a joint deep learning model  #AUTHOR_TAG, which we leave to future work ( noting that scalability will potentially be a major issue for the larger datasets ).', ""to test the applicability of the model's embeddings in dialectology, we created dareds."", 'the output of the hidden layer of the model is used as embeddings for both location names and dialect terms.', 'given a dialect region name, we retrieve its nearest neighbours in the embedding space, and compare them to dialect terms associated with that location.', 'we also compare the quality of']",6
"['based model based on the method of  #TAUTHOR_TAG, and improved upon their work.', 'we analysed the']","['tree by a reasonable margin.', 'we also incorporated the mlp predictions into a network - based model based on the method of  #TAUTHOR_TAG, and improved upon their work.', 'we analysed the']","['d tree by a reasonable margin.', 'we also incorporated the mlp predictions into a network - based model based on the method of  #TAUTHOR_TAG, and improved upon their work.', 'we analysed the']","['', 'comparing the two discretisation strategies, k - means outperforms k - d tree by a reasonable margin.', 'we also incorporated the mlp predictions into a network - based model based on the method of  #TAUTHOR_TAG, and improved upon their work.', 'we analysed the table 2 : nearest neighbours of place names.', '']",6
"['', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for']","['for acc @ 161.', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for']","['', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for']","['', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for twitter - world were over a superset of the dataset ; the results reported here are based on the actual dataset.', 'while the focus of this paper is text - based user geolocation, state - of - the - art results for the three datasets have been achieved with hybrid text + network - based models, where the predictions of the text - based model are fed into a mention network as "" dongle "" nodes to each user node, providing a personalised geolocation prior for each user  #TAUTHOR_TAG.', 'note that it would, of course, be possible to combine text and network information in a joint deep learning model  #AUTHOR_TAG, which we leave to future work ( noting that scalability will potentially be a major issue for the larger datasets ).', ""to test the applicability of the model's embeddings in dialectology, we created dareds."", 'the output of the hidden layer of the model is used as embeddings for both location names and dialect terms.', 'given a dialect region name, we retrieve its nearest neighbours in the embedding space, and compare them to dialect terms associated with that location.', 'we also compare the quality of']",4
"['', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for']","['for acc @ 161.', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for']","['', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for']","['', '4 the results reported in  #AUTHOR_TAG b ;  #TAUTHOR_TAG for twitter - world were over a superset of the dataset ; the results reported here are based on the actual dataset.', 'while the focus of this paper is text - based user geolocation, state - of - the - art results for the three datasets have been achieved with hybrid text + network - based models, where the predictions of the text - based model are fed into a mention network as "" dongle "" nodes to each user node, providing a personalised geolocation prior for each user  #TAUTHOR_TAG.', 'note that it would, of course, be possible to combine text and network information in a joint deep learning model  #AUTHOR_TAG, which we leave to future work ( noting that scalability will potentially be a major issue for the larger datasets ).', ""to test the applicability of the model's embeddings in dialectology, we created dareds."", 'the output of the hidden layer of the model is used as embeddings for both location names and dialect terms.', 'given a dialect region name, we retrieve its nearest neighbours in the embedding space, and compare them to dialect terms associated with that location.', 'we also compare the quality of']",4
"['9 ], [  #TAUTHOR_TAG ] and [ 20 ]. in sum,', 'the network']","['9 ], [  #TAUTHOR_TAG ] and [ 20 ]. in sum,', 'the network']","['. alternative forms to create the network could also be useful to grasp semantical features hidden in the topological space. in ( ii ), i suggest, for example, the', 'introduction of a hybrid classifier that could consider both linguistic ( deeper linguistic processing [ 18 ] ) and topological attributes at the same time in a hybrid way. examples of combinations of distinct strategies are described in [ 9 ], [  #TAUTHOR_TAG ] and [ 20 ]. in sum,', 'the network framework has proven applicable to']","['', '11 ] ). however, when deep analyzes are performed, network - based strategies usually do not perform better than other techniques making extensive use of semantic resources and tools. in order to improve the performance of network', '- based applications, i suggest a twofold research line : ( i ) the introduction of measurements consistent with the nature', 'of the problem ; and ( ii ) the combination of topological strategies with other traditional natural language processing methods. more specifically, in ( i ), i propose 1', 'e - mail : diego. raphael @ gmail. com, diego', '@ icmc. usp. br december 4, 2014 the conception of measurements', 'that are able to capture semantic aspects, since the topological measurements of co - occurrence', 'networks capture mostly syntactic factors [ 8 ]. although such networks have proved useful in some semantical - dependent tasks ( see e. g. a', 'topological approach to word sense disambiguation in [ 17 ] ), i believe that the creation of novel semantic - based', 'measurements would improve the state of the art. alternative forms to create the network could also be useful to grasp semantical features hidden in the topological space. in ( ii ), i suggest, for example, the', 'introduction of a hybrid classifier that could consider both linguistic ( deeper linguistic processing [ 18 ] ) and topological attributes at the same time in a hybrid way. examples of combinations of distinct strategies are described in [ 9 ], [  #TAUTHOR_TAG ] and [ 20 ]. in sum,', 'the network framework has proven applicable to understand the properties of the language and its applications, especially those related to the textual classification in', 'several levels. despite the limitations imposed by the restrict understanding of the mechanisms behind the classification, it is worth noting that the such representation remains entirely generic, being therefore useful to', '']",0
"['9 ], [  #TAUTHOR_TAG ] and [ 20 ].', 'in sum, the network framework has proven applicable to']","['same time in a hybrid way.', 'examples of combinations of distinct strategies are described in [ 9 ], [  #TAUTHOR_TAG ] and [ 20 ].', 'in sum, the network framework has proven applicable to']","['9 ], [  #TAUTHOR_TAG ] and [ 20 ].', 'in sum, the network framework has proven applicable to']","['conception of measurements that are able to capture semantic aspects, since the topological measurements of co - occurrence networks capture mostly syntactic factors [ 8 ].', 'although such networks have proved useful in some semantical - dependent tasks ( see e. g. a topological approach to word sense disambiguation in [ 17 ] ), i believe that the creation of novel semantic - based measurements would improve the state of the art.', 'alternative forms to create the network could also be useful to grasp semantical features hidden in the topological space.', 'in ( ii ), i suggest, for example, the introduction of a hybrid classifier that could consider both linguistic ( deeper linguistic processing [ 18 ] ) and topological attributes at the same time in a hybrid way.', 'examples of combinations of distinct strategies are described in [ 9 ], [  #TAUTHOR_TAG ] and [ 20 ].', 'in sum, the network framework has proven applicable to understand the properties of the language and its applications, especially those related to the textual classification in several levels.', 'despite the limitations imposed by the restrict understanding of the mechanisms behind the classification, it is worth noting that the such representation remains entirely generic, being therefore useful to many tasks as well as for analyzing the evolution of languages, cultures and emotional trends.', 'for this reason, i believe that the use of complex networks in both practical and theoretical investigations shall yield novels insights into the mechanisms behind the language']",0
"['', ' #TAUTHOR_TAG,']","['src, the transformer architecture', ' #TAUTHOR_TAG, which is built solely upon attention mechanisms  #AUTHOR_TAG, makes it possible to model dependencies without regard to their distance in']","['##e performance. to provide the awareness of errors in mt originating from src, the transformer architecture', ' #TAUTHOR_TAG,']","['##e performance. to provide the awareness of errors in mt originating from src, the transformer architecture', ' #TAUTHOR_TAG, which is built solely upon attention mechanisms  #AUTHOR_TAG, makes it possible to model dependencies without regard to their distance in the input or output sequences and also captures global dependencies between input and', 'output ( for our case src, mt, and pe ). the transformer architecture replaces recurrence and convolutions by using positional encodings on both the input', 'and output sequences. the encoder and decoder both use multi - head ( facilitating parallel computations ) self - attention to compute representations of their corresponding inputs, and also compute multi - head vanilla - attentions between encoder and decoder representations. our ape system extends this transformer -', 'based nmt architecture  #TAUTHOR_TAG by using two encoders, a joint encoder, and a single decoder. our model concatenates', 'two separate selfattention - based encoders ( enc src and enc mt ) and passes this sequence through another self - attended joint encoder ( enc src, mt ) to ensure capturing dependencies between src and mt. finally, this joint encoder is fed to the decoder which follows a similar architecture as described in  #TAUTHOR_TAG.', '']",0
"['', ' #TAUTHOR_TAG,']","['src, the transformer architecture', ' #TAUTHOR_TAG, which is built solely upon attention mechanisms  #AUTHOR_TAG, makes it possible to model dependencies without regard to their distance in']","['##e performance. to provide the awareness of errors in mt originating from src, the transformer architecture', ' #TAUTHOR_TAG,']","['##e performance. to provide the awareness of errors in mt originating from src, the transformer architecture', ' #TAUTHOR_TAG, which is built solely upon attention mechanisms  #AUTHOR_TAG, makes it possible to model dependencies without regard to their distance in the input or output sequences and also captures global dependencies between input and', 'output ( for our case src, mt, and pe ). the transformer architecture replaces recurrence and convolutions by using positional encodings on both the input', 'and output sequences. the encoder and decoder both use multi - head ( facilitating parallel computations ) self - attention to compute representations of their corresponding inputs, and also compute multi - head vanilla - attentions between encoder and decoder representations. our ape system extends this transformer -', 'based nmt architecture  #TAUTHOR_TAG by using two encoders, a joint encoder, and a single decoder. our model concatenates', 'two separate selfattention - based encoders ( enc src and enc mt ) and passes this sequence through another self - attended joint encoder ( enc src, mt ) to ensure capturing dependencies between src and mt. finally, this joint encoder is fed to the decoder which follows a similar architecture as described in  #TAUTHOR_TAG.', '']",4
"[""original transformer's encoder  #TAUTHOR_TAG,""]","[""original transformer's encoder  #TAUTHOR_TAG,""]","[""to the original transformer's encoder  #TAUTHOR_TAG, we use a joint encoder with an equivalent architecture,""]","['our multi - source model ( ms ), we propose a novel joint transformer model ( cf. figure 1 ), which combines the encodings of src and mt and attends over a combination of both sequences while generating the post - edited sentence.', ""apart from enc src and enc mt, each of which is equivalent to the original transformer's encoder  #TAUTHOR_TAG, we use a joint encoder with an equivalent architecture, to maintain the homogeneity of the transformer model."", 'for this, we extend  #TAUTHOR_TAG by introducing an additional identical encoding block by which both the enc src and the enc mt encoders communicate with the decoder.', 'our multi - source neural ape computes intermediate states enc src and enc mt for the two encoders, enc src, mt for their combination, and dec pe for the decoder in sequence - to - sequence modeling.', 'one self - attended encoder for src maps s = ( s 1, s 2,..., s k ) into a sequence of continuous representations, enc src = ( e 1, e 2,..., e k ), and a second encoder for mt, m = ( m 1, m 2,..., m l ), returns another sequence of continuous representations, enc mt = ( e ′ 1, e ′ 2,..., e ′ l ).', '']",4
"[""original transformer's encoder  #TAUTHOR_TAG,""]","[""original transformer's encoder  #TAUTHOR_TAG,""]","[""to the original transformer's encoder  #TAUTHOR_TAG, we use a joint encoder with an equivalent architecture,""]","['our multi - source model ( ms ), we propose a novel joint transformer model ( cf. figure 1 ), which combines the encodings of src and mt and attends over a combination of both sequences while generating the post - edited sentence.', ""apart from enc src and enc mt, each of which is equivalent to the original transformer's encoder  #TAUTHOR_TAG, we use a joint encoder with an equivalent architecture, to maintain the homogeneity of the transformer model."", 'for this, we extend  #TAUTHOR_TAG by introducing an additional identical encoding block by which both the enc src and the enc mt encoders communicate with the decoder.', 'our multi - source neural ape computes intermediate states enc src and enc mt for the two encoders, enc src, mt for their combination, and dec pe for the decoder in sequence - to - sequence modeling.', 'one self - attended encoder for src maps s = ( s 1, s 2,..., s k ) into a sequence of continuous representations, enc src = ( e 1, e 2,..., e k ), and a second encoder for mt, m = ( m 1, m 2,..., m l ), returns another sequence of continuous representations, enc mt = ( e ′ 1, e ′ 2,..., e ′ l ).', '']",4
"[""base'hyper - parameter configuration in  #TAUTHOR_TAG""]","[""' base'hyper - parameter configuration in  #TAUTHOR_TAG""]","[""the'big'or the'base'hyper - parameter configuration in  #TAUTHOR_TAG""]","['this paper, we investigated a novel transformerbased multi - source ape approach that jointly attends over a combination of src and mt to capture dependencies between the two.', 'this architecture yields statistically significant improvements over single - source transformer - based models.', 'an ensemble of both variants increases the performance further.', 'for the pbsmt task, the baseline mt system was outperformed by 3. 2 bleu points, while the nmt baseline remains 0. 51 bleu points better than our ape approach on the 2018 test set.', 'in the future, we will investigate if the performance of each system can be improved by using a different hyper - parameter setup.', ""unfortunately, we could not test either the'big'or the'base'hyper - parameter configuration in  #TAUTHOR_TAG due to unavailable computing resources at the time of submission."", 'as additional future work, we would like to explore whether using re - ranking and ensembling of different neural apes helps to improve the performance further.', 'moreover, we will incorporate word - level quality estimation features of mt into the encoding layer.', 'lastly, we will evaluate if our model indeed is able to better handle word order errors and to capture longrange dependencies, as we expect.', 'furthermore, we will analyze if adapting the learning rate to the size of the datasets used during training increases the performance compared to the currently used fixed learning rate initialization of 0. 001']",4
"['', ' #TAUTHOR_TAG,']","['src, the transformer architecture', ' #TAUTHOR_TAG, which is built solely upon attention mechanisms  #AUTHOR_TAG, makes it possible to model dependencies without regard to their distance in']","['##e performance. to provide the awareness of errors in mt originating from src, the transformer architecture', ' #TAUTHOR_TAG,']","['##e performance. to provide the awareness of errors in mt originating from src, the transformer architecture', ' #TAUTHOR_TAG, which is built solely upon attention mechanisms  #AUTHOR_TAG, makes it possible to model dependencies without regard to their distance in the input or output sequences and also captures global dependencies between input and', 'output ( for our case src, mt, and pe ). the transformer architecture replaces recurrence and convolutions by using positional encodings on both the input', 'and output sequences. the encoder and decoder both use multi - head ( facilitating parallel computations ) self - attention to compute representations of their corresponding inputs, and also compute multi - head vanilla - attentions between encoder and decoder representations. our ape system extends this transformer -', 'based nmt architecture  #TAUTHOR_TAG by using two encoders, a joint encoder, and a single decoder. our model concatenates', 'two separate selfattention - based encoders ( enc src and enc mt ) and passes this sequence through another self - attended joint encoder ( enc src, mt ) to ensure capturing dependencies between src and mt. finally, this joint encoder is fed to the decoder which follows a similar architecture as described in  #TAUTHOR_TAG.', '']",6
['transformer architecture  #TAUTHOR_TAG'],"['pe )', 'our single - source model ( ss ) is based on an encoder - decoder - based transformer architecture  #TAUTHOR_TAG']","['mt → pe )', 'our single - source model ( ss ) is based on an encoder - decoder - based transformer architecture  #TAUTHOR_TAG.', 'transformer models can replace sequence - aligned recurrence entirely']","['mt → pe )', 'our single - source model ( ss ) is based on an encoder - decoder - based transformer architecture  #TAUTHOR_TAG.', 'transformer models can replace sequence - aligned recurrence entirely and follow three types of multi - head attention : encoder - decoder attention ( also known as vanilla figure 1 : multi - source transformer - based ape attention ), encoder self - attention, and masked decoder self - attention.', 'since for multi - head attention each head uses different linear transformations, it can learn these separate relationships in parallel, thereby improving learning time']",6
"[""original transformer's encoder  #TAUTHOR_TAG,""]","[""original transformer's encoder  #TAUTHOR_TAG,""]","[""to the original transformer's encoder  #TAUTHOR_TAG, we use a joint encoder with an equivalent architecture,""]","['our multi - source model ( ms ), we propose a novel joint transformer model ( cf. figure 1 ), which combines the encodings of src and mt and attends over a combination of both sequences while generating the post - edited sentence.', ""apart from enc src and enc mt, each of which is equivalent to the original transformer's encoder  #TAUTHOR_TAG, we use a joint encoder with an equivalent architecture, to maintain the homogeneity of the transformer model."", 'for this, we extend  #TAUTHOR_TAG by introducing an additional identical encoding block by which both the enc src and the enc mt encoders communicate with the decoder.', 'our multi - source neural ape computes intermediate states enc src and enc mt for the two encoders, enc src, mt for their combination, and dec pe for the decoder in sequence - to - sequence modeling.', 'one self - attended encoder for src maps s = ( s 1, s 2,..., s k ) into a sequence of continuous representations, enc src = ( e 1, e 2,..., e k ), and a second encoder for mt, m = ( m 1, m 2,..., m l ), returns another sequence of continuous representations, enc mt = ( e ′ 1, e ′ 2,..., e ′ l ).', '']",6
"[""original transformer's encoder  #TAUTHOR_TAG,""]","[""original transformer's encoder  #TAUTHOR_TAG,""]","[""to the original transformer's encoder  #TAUTHOR_TAG, we use a joint encoder with an equivalent architecture,""]","['our multi - source model ( ms ), we propose a novel joint transformer model ( cf. figure 1 ), which combines the encodings of src and mt and attends over a combination of both sequences while generating the post - edited sentence.', ""apart from enc src and enc mt, each of which is equivalent to the original transformer's encoder  #TAUTHOR_TAG, we use a joint encoder with an equivalent architecture, to maintain the homogeneity of the transformer model."", 'for this, we extend  #TAUTHOR_TAG by introducing an additional identical encoding block by which both the enc src and the enc mt encoders communicate with the decoder.', 'our multi - source neural ape computes intermediate states enc src and enc mt for the two encoders, enc src, mt for their combination, and dec pe for the decoder in sequence - to - sequence modeling.', 'one self - attended encoder for src maps s = ( s 1, s 2,..., s k ) into a sequence of continuous representations, enc src = ( e 1, e 2,..., e k ), and a second encoder for mt, m = ( m 1, m 2,..., m l ), returns another sequence of continuous representations, enc mt = ( e ′ 1, e ′ 2,..., e ′ l ).', '']",6
"['', ' #TAUTHOR_TAG,']","['src, the transformer architecture', ' #TAUTHOR_TAG, which is built solely upon attention mechanisms  #AUTHOR_TAG, makes it possible to model dependencies without regard to their distance in']","['##e performance. to provide the awareness of errors in mt originating from src, the transformer architecture', ' #TAUTHOR_TAG,']","['##e performance. to provide the awareness of errors in mt originating from src, the transformer architecture', ' #TAUTHOR_TAG, which is built solely upon attention mechanisms  #AUTHOR_TAG, makes it possible to model dependencies without regard to their distance in the input or output sequences and also captures global dependencies between input and', 'output ( for our case src, mt, and pe ). the transformer architecture replaces recurrence and convolutions by using positional encodings on both the input', 'and output sequences. the encoder and decoder both use multi - head ( facilitating parallel computations ) self - attention to compute representations of their corresponding inputs, and also compute multi - head vanilla - attentions between encoder and decoder representations. our ape system extends this transformer -', 'based nmt architecture  #TAUTHOR_TAG by using two encoders, a joint encoder, and a single decoder. our model concatenates', 'two separate selfattention - based encoders ( enc src and enc mt ) and passes this sequence through another self - attended joint encoder ( enc src, mt ) to ensure capturing dependencies between src and mt. finally, this joint encoder is fed to the decoder which follows a similar architecture as described in  #TAUTHOR_TAG.', '']",3
"['.', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", '']","['layer.', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", '']","['', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", '']","['', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", 'for the scaled dotproduct attention, the input consists of queries and keys of dimension d k, and values of dimension d v.', 'as multi - head attention parameters, we employ h = 8 for parallel attention layers, or heads.', 'for each of these we use a dimensional -', 'for optimization, we use the adam optimizer  #AUTHOR_TAG with β 1 = 0. 9, β 2 = 0. 98 and [UNK] = 10 −9.', 'the learning rate is varied throughout the training process, first increasing linearly for the first training steps warmup steps = 4000 and then adjusted as described in  #TAUTHOR_TAG.', 'at training time, the batch size is set to 32 samples, with a maximum sentence length of 80 subwords, and a vocabulary of the 50k most frequent subwords.', 'after each epoch, the training data is shuffled.', 'for encoding the word order, our model uses learned positional embeddings  #AUTHOR_TAG, since  #TAUTHOR_TAG reported nearly identical results to sinusoidal encodings.', 'after finishing training, we save the 5 best checkpoints saved at each epoch.', 'finally, we use a single model obtained by averaging the last 5 checkpoints.', 'during decoding, we perform greedy - search - based decoding.', 'we follow a similar hyper - parameter setup for mt → pe.', 'the total number of parameters for our { src, mt } → pe and mt → pe model is 46 × 10 6 and 28 × 10 6, respectively']",3
"['.', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", '']","['layer.', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", '']","['', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", '']","['', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", 'for the scaled dotproduct attention, the input consists of queries and keys of dimension d k, and values of dimension d v.', 'as multi - head attention parameters, we employ h = 8 for parallel attention layers, or heads.', 'for each of these we use a dimensional -', 'for optimization, we use the adam optimizer  #AUTHOR_TAG with β 1 = 0. 9, β 2 = 0. 98 and [UNK] = 10 −9.', 'the learning rate is varied throughout the training process, first increasing linearly for the first training steps warmup steps = 4000 and then adjusted as described in  #TAUTHOR_TAG.', 'at training time, the batch size is set to 32 samples, with a maximum sentence length of 80 subwords, and a vocabulary of the 50k most frequent subwords.', 'after each epoch, the training data is shuffled.', 'for encoding the word order, our model uses learned positional embeddings  #AUTHOR_TAG, since  #TAUTHOR_TAG reported nearly identical results to sinusoidal encodings.', 'after finishing training, we save the 5 best checkpoints saved at each epoch.', 'finally, we use a single model obtained by averaging the last 5 checkpoints.', 'during decoding, we perform greedy - search - based decoding.', 'we follow a similar hyper - parameter setup for mt → pe.', 'the total number of parameters for our { src, mt } → pe and mt → pe model is 46 × 10 6 and 28 × 10 6, respectively']",3
"['.', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", '']","['layer.', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", '']","['', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", '']","['', ""this is a similar setting to  #TAUTHOR_TAG's c − model 1."", 'for the scaled dotproduct attention, the input consists of queries and keys of dimension d k, and values of dimension d v.', 'as multi - head attention parameters, we employ h = 8 for parallel attention layers, or heads.', 'for each of these we use a dimensional -', 'for optimization, we use the adam optimizer  #AUTHOR_TAG with β 1 = 0. 9, β 2 = 0. 98 and [UNK] = 10 −9.', 'the learning rate is varied throughout the training process, first increasing linearly for the first training steps warmup steps = 4000 and then adjusted as described in  #TAUTHOR_TAG.', 'at training time, the batch size is set to 32 samples, with a maximum sentence length of 80 subwords, and a vocabulary of the 50k most frequent subwords.', 'after each epoch, the training data is shuffled.', 'for encoding the word order, our model uses learned positional embeddings  #AUTHOR_TAG, since  #TAUTHOR_TAG reported nearly identical results to sinusoidal encodings.', 'after finishing training, we save the 5 best checkpoints saved at each epoch.', 'finally, we use a single model obtained by averaging the last 5 checkpoints.', 'during decoding, we perform greedy - search - based decoding.', 'we follow a similar hyper - parameter setup for mt → pe.', 'the total number of parameters for our { src, mt } → pe and mt → pe model is 46 × 10 6 and 28 × 10 6, respectively']",3
"['', ' #TAUTHOR_TAG,']","['src, the transformer architecture', ' #TAUTHOR_TAG, which is built solely upon attention mechanisms  #AUTHOR_TAG, makes it possible to model dependencies without regard to their distance in']","['##e performance. to provide the awareness of errors in mt originating from src, the transformer architecture', ' #TAUTHOR_TAG,']","['##e performance. to provide the awareness of errors in mt originating from src, the transformer architecture', ' #TAUTHOR_TAG, which is built solely upon attention mechanisms  #AUTHOR_TAG, makes it possible to model dependencies without regard to their distance in the input or output sequences and also captures global dependencies between input and', 'output ( for our case src, mt, and pe ). the transformer architecture replaces recurrence and convolutions by using positional encodings on both the input', 'and output sequences. the encoder and decoder both use multi - head ( facilitating parallel computations ) self - attention to compute representations of their corresponding inputs, and also compute multi - head vanilla - attentions between encoder and decoder representations. our ape system extends this transformer -', 'based nmt architecture  #TAUTHOR_TAG by using two encoders, a joint encoder, and a single decoder. our model concatenates', 'two separate selfattention - based encoders ( enc src and enc mt ) and passes this sequence through another self - attended joint encoder ( enc src, mt ) to ensure capturing dependencies between src and mt. finally, this joint encoder is fed to the decoder which follows a similar architecture as described in  #TAUTHOR_TAG.', '']",5
['system  #TAUTHOR_TAG'],"['described approach, we demonstrate a word - error - rate ( wer ) reduction of 65 % over a do - nothing input baseline, and we improve over a state - of - the - art system  #TAUTHOR_TAG']","['over a do - nothing input baseline, and we improve over a state - of - the - art system  #TAUTHOR_TAG']","['##lling error correction is a longstanding natural language processing ( nlp ) problem, and it has recently become especially relevant because of the many potential applications to the large amount of informal and unedited text generated online, including web forums, tweets, blogs, and email.', 'misspellings in such text can lead to increased sparsity and errors, posing a challenge for many nlp applications such as text summarization, sentiment analysis and machine translation.', 'in this work, we present gsec, a generalized character - level spelling error correction model, which uses supervised learning to map input characters into output characters in context.', 'the approach has the following characteristics :', 'character - level corrections are learned at the character - level 1 using a supervised sequence labeling approach.', 'generalized the input space consists of all characters, and a single classifier is used to learn common error patterns over all the training data, without guidance of specific rules.', 'context - sensitive the model looks beyond the context of the current word, when making a decision at the character - level.', 'discriminative the model provides the freedom of adding a number of different features, which may or may not be language - specific.', 'language - independent in this work, we integrate only language - independent features, and therefore do not consider morphological or linguistic features.', 'however, we apply the model to correct errors in egyptian arabic dialect text, following a conventional orthography standard, coda  #AUTHOR_TAG.', 'using the described approach, we demonstrate a word - error - rate ( wer ) reduction of 65 % over a do - nothing input baseline, and we improve over a state - of - the - art system  #TAUTHOR_TAG which relies heavily on language - specific and manually - selected constraints.', 'we present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors']",0
['of  #TAUTHOR_TAG is the'],['of  #TAUTHOR_TAG is the'],"['considered in this paper  #AUTHOR_TAG.', 'the work of  #TAUTHOR_TAG is the']","['', 'discriminative models have been proposed at the word - level for error correction and for error detection  #AUTHOR_TAG.', 'in addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper  #AUTHOR_TAG.', 'the work of  #TAUTHOR_TAG is the most relevant to the present study : it presents a character - edit classification model ( cec ) using the same dataset we use in this paper.', '2  #TAUTHOR_TAG analyzed the data to identify the seven most common types of errors.', 'they developed seven classifiers and applied them to the data in succession.', 'this makes the approach tailored to the specific data set in use and limited to a specific set of errors.', 'in this work, a single model is considered for all types of errors.', 'the model considers every character in the input text for a possible spelling error, as opposed to looking only at certain input characters and contexts in which they appear.', 'moreover, in contrast to  #TAUTHOR_TAG, it looks beyond the boundary of the current word.', '3 the gsec']",0
['end 2  #TAUTHOR_TAG'],['end 2  #TAUTHOR_TAG'],['the end 2  #TAUTHOR_TAG'],"['', '• insert ( c ) : a character c is inserted bef ore e i.', 'to address errors occurring at the end 2  #TAUTHOR_TAG also considered a slower, more expensive, and more language - specific method using a morphological tagger that outperformed the cec model ; however, we do not compare to it in this paper.', 'we use a multi - class svm classifier to predict the action labels for each input character e i ∈ e.', '']",0
"['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding']","['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding']","['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding']","['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding and following two characters, and the first two and last two characters in the word.', 'these are the same features used by cec, except that cec does not include characters beyond the word boundary, while we consider space characters as well as characters from the previous and next words']",0
"['by  #TAUTHOR_TAG.', '']","['by  #TAUTHOR_TAG.', '']","[""##eery '."", 'the same speech effect handling was applied by  #TAUTHOR_TAG.', '']","['the training data was extracted to generate the form described in section 3. 1, using the sclite tool  #AUTHOR_TAG to align the input and reference sentences.', 'a speech effect handling step was applied as a preprocessing step to all models.', ""this step removes redundant repetitions of characters in sequence, e. g., ktyyyyyr'veeeeery '."", 'the same speech effect handling was applied by  #TAUTHOR_TAG.', 'for classification, we used the svm implementation in yamcha  #AUTHOR_TAG, and trained with different variations of the features described above.', 'default parameters were selected for training ( c = 1, quadratic kernel, and context window of + / - 2 ).', 'in all results listed below, the baseline corresponds to the do - nothing baseline of the input text.', 'metrics three evaluation metrics are used.', 'the word - error - rate wer metric is computed by summing the total number of word - level substitution errors, insertion errors, and deletion errors in the output, and dividing by the number of words in the reference.', 'the correct - rate corr metric is computed by dividing the number of correct output words by the total number of words in the reference.', 'these two metrics are produced by sclite  #AUTHOR_TAG, using automatic alignment.', 'finally, the accuracy acc metric, used by  #TAUTHOR_TAG, is a simple string matching metric which enforces a word alignment that pairs words in the reference to those of the output.', 'it is calculated by dividing the number of correct output words by the number of words in the input.', 'this metric assumes no split errors in the data ( a word incorrectly split into two words ), which is the case in the data we are working with']",0
"['4.', 'the results of the  #TAUTHOR_TAG cec system are also presented for the purpose of comparison.', 'we can see that using a single classifier,']","['4.', 'the results of the  #TAUTHOR_TAG cec system are also presented for the purpose of comparison.', 'we can see that using a single classifier,']","['( gsec ) on the dev data is presented in the first half of table 4.', 'the results of the  #TAUTHOR_TAG cec system are also presented for the purpose of comparison.', 'we can see that using a single classifier, the generalized model is able to']","['performance of the generalized spelling correction model ( gsec ) on the dev data is presented in the first half of table 4.', 'the results of the  #TAUTHOR_TAG cec system are also presented for the purpose of comparison.', 'we can see that using a single classifier, the generalized model is able to outperform cec, which relies on a cascade of classifiers ( p = 0. 03 for the basic model and p < 0. 0001 for the best model, gsec + 4grams ).', '']",0
['system  #TAUTHOR_TAG'],"['described approach, we demonstrate a word - error - rate ( wer ) reduction of 65 % over a do - nothing input baseline, and we improve over a state - of - the - art system  #TAUTHOR_TAG']","['over a do - nothing input baseline, and we improve over a state - of - the - art system  #TAUTHOR_TAG']","['##lling error correction is a longstanding natural language processing ( nlp ) problem, and it has recently become especially relevant because of the many potential applications to the large amount of informal and unedited text generated online, including web forums, tweets, blogs, and email.', 'misspellings in such text can lead to increased sparsity and errors, posing a challenge for many nlp applications such as text summarization, sentiment analysis and machine translation.', 'in this work, we present gsec, a generalized character - level spelling error correction model, which uses supervised learning to map input characters into output characters in context.', 'the approach has the following characteristics :', 'character - level corrections are learned at the character - level 1 using a supervised sequence labeling approach.', 'generalized the input space consists of all characters, and a single classifier is used to learn common error patterns over all the training data, without guidance of specific rules.', 'context - sensitive the model looks beyond the context of the current word, when making a decision at the character - level.', 'discriminative the model provides the freedom of adding a number of different features, which may or may not be language - specific.', 'language - independent in this work, we integrate only language - independent features, and therefore do not consider morphological or linguistic features.', 'however, we apply the model to correct errors in egyptian arabic dialect text, following a conventional orthography standard, coda  #AUTHOR_TAG.', 'using the described approach, we demonstrate a word - error - rate ( wer ) reduction of 65 % over a do - nothing input baseline, and we improve over a state - of - the - art system  #TAUTHOR_TAG which relies heavily on language - specific and manually - selected constraints.', 'we present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors']",1
"['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding']","['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding']","['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding']","['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding and following two characters, and the first two and last two characters in the word.', 'these are the same features used by cec, except that cec does not include characters beyond the word boundary, while we consider space characters as well as characters from the previous and next words']",1
['of  #TAUTHOR_TAG is the'],['of  #TAUTHOR_TAG is the'],"['considered in this paper  #AUTHOR_TAG.', 'the work of  #TAUTHOR_TAG is the']","['', 'discriminative models have been proposed at the word - level for error correction and for error detection  #AUTHOR_TAG.', 'in addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper  #AUTHOR_TAG.', 'the work of  #TAUTHOR_TAG is the most relevant to the present study : it presents a character - edit classification model ( cec ) using the same dataset we use in this paper.', '2  #TAUTHOR_TAG analyzed the data to identify the seven most common types of errors.', 'they developed seven classifiers and applied them to the data in succession.', 'this makes the approach tailored to the specific data set in use and limited to a specific set of errors.', 'in this work, a single model is considered for all types of errors.', 'the model considers every character in the input text for a possible spelling error, as opposed to looking only at certain input characters and contexts in which they appear.', 'moreover, in contrast to  #TAUTHOR_TAG, it looks beyond the boundary of the current word.', '3 the gsec']",3
['of  #TAUTHOR_TAG is the'],['of  #TAUTHOR_TAG is the'],"['considered in this paper  #AUTHOR_TAG.', 'the work of  #TAUTHOR_TAG is the']","['', 'discriminative models have been proposed at the word - level for error correction and for error detection  #AUTHOR_TAG.', 'in addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper  #AUTHOR_TAG.', 'the work of  #TAUTHOR_TAG is the most relevant to the present study : it presents a character - edit classification model ( cec ) using the same dataset we use in this paper.', '2  #TAUTHOR_TAG analyzed the data to identify the seven most common types of errors.', 'they developed seven classifiers and applied them to the data in succession.', 'this makes the approach tailored to the specific data set in use and limited to a specific set of errors.', 'in this work, a single model is considered for all types of errors.', 'the model considers every character in the input text for a possible spelling error, as opposed to looking only at certain input characters and contexts in which they appear.', 'moreover, in contrast to  #TAUTHOR_TAG, it looks beyond the boundary of the current word.', '3 the gsec']",3
['of  #TAUTHOR_TAG is the'],['of  #TAUTHOR_TAG is the'],"['considered in this paper  #AUTHOR_TAG.', 'the work of  #TAUTHOR_TAG is the']","['', 'discriminative models have been proposed at the word - level for error correction and for error detection  #AUTHOR_TAG.', 'in addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper  #AUTHOR_TAG.', 'the work of  #TAUTHOR_TAG is the most relevant to the present study : it presents a character - edit classification model ( cec ) using the same dataset we use in this paper.', '2  #TAUTHOR_TAG analyzed the data to identify the seven most common types of errors.', 'they developed seven classifiers and applied them to the data in succession.', 'this makes the approach tailored to the specific data set in use and limited to a specific set of errors.', 'in this work, a single model is considered for all types of errors.', 'the model considers every character in the input text for a possible spelling error, as opposed to looking only at certain input characters and contexts in which they appear.', 'moreover, in contrast to  #TAUTHOR_TAG, it looks beyond the boundary of the current word.', '3 the gsec']",5
"['deletion actions.', 'labels modeled by  #TAUTHOR_TAG']","['deletion actions.', 'labels modeled by  #TAUTHOR_TAG']","['is a single label that comprises all deletion actions.', 'labels modeled by  #TAUTHOR_TAG are marked with e, and ep for cases modeled partially,']","['apply our model to correcting egyptian arabic dialect text.', 'since there is no standard dialect orthography adopted by native speakers of arabic dialects, it is common to encounter multiple table 3 : character - level distribution of correction labels.', 'we model all types of transformations except complex actions, and rare insert labels with counts below a tuned threshold.', 'the delete label is a single label that comprises all deletion actions.', 'labels modeled by  #TAUTHOR_TAG are marked with e, and ep for cases modeled partially, for example, the insert { a } would only be applied at certain positions such as the end of the word.', 'spellings of the same word.', 'the coda orthography was proposed by  #AUTHOR_TAG in an attempt to standardize dialectal writing, and we use it as a reference of correct text for spelling correction following the previous work by  #TAUTHOR_TAG.', 'we use the same corpus ( labeled "" arz "" ) and experimental setup splits used by them.', 'the arz corpus was developed by the linguistic data consortium  #AUTHOR_TAG a - e ).', 'see table 2 for corpus statistics.', 'table 3 presents the distribution of correction action labels that correspond to spelling errors in the training data together with examples of these errors.', '3 we group the actions into : substitute, insert, delete, and complex, and also list common transformations within each group.', 'we further distinguish between the phenomena modeled by our system and by  #TAUTHOR_TAG.', 'at least 10 % of all generated action labels are not handled by  #TAUTHOR_TAG']",5
"['deletion actions.', 'labels modeled by  #TAUTHOR_TAG']","['deletion actions.', 'labels modeled by  #TAUTHOR_TAG']","['is a single label that comprises all deletion actions.', 'labels modeled by  #TAUTHOR_TAG are marked with e, and ep for cases modeled partially,']","['apply our model to correcting egyptian arabic dialect text.', 'since there is no standard dialect orthography adopted by native speakers of arabic dialects, it is common to encounter multiple table 3 : character - level distribution of correction labels.', 'we model all types of transformations except complex actions, and rare insert labels with counts below a tuned threshold.', 'the delete label is a single label that comprises all deletion actions.', 'labels modeled by  #TAUTHOR_TAG are marked with e, and ep for cases modeled partially, for example, the insert { a } would only be applied at certain positions such as the end of the word.', 'spellings of the same word.', 'the coda orthography was proposed by  #AUTHOR_TAG in an attempt to standardize dialectal writing, and we use it as a reference of correct text for spelling correction following the previous work by  #TAUTHOR_TAG.', 'we use the same corpus ( labeled "" arz "" ) and experimental setup splits used by them.', 'the arz corpus was developed by the linguistic data consortium  #AUTHOR_TAG a - e ).', 'see table 2 for corpus statistics.', 'table 3 presents the distribution of correction action labels that correspond to spelling errors in the training data together with examples of these errors.', '3 we group the actions into : substitute, insert, delete, and complex, and also list common transformations within each group.', 'we further distinguish between the phenomena modeled by our system and by  #TAUTHOR_TAG.', 'at least 10 % of all generated action labels are not handled by  #TAUTHOR_TAG']",5
"['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding']","['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding']","['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding']","['input character is represented by a feature vector.', 'we include a set of basic features inspired by  #TAUTHOR_TAG in their cec system and additional features for further improvement.', 'basic features we use a set of nine basic features : the given character, the preceding and following two characters, and the first two and last two characters in the word.', 'these are the same features used by cec, except that cec does not include characters beyond the word boundary, while we consider space characters as well as characters from the previous and next words']",5
"['by  #TAUTHOR_TAG.', '']","['by  #TAUTHOR_TAG.', '']","[""##eery '."", 'the same speech effect handling was applied by  #TAUTHOR_TAG.', '']","['the training data was extracted to generate the form described in section 3. 1, using the sclite tool  #AUTHOR_TAG to align the input and reference sentences.', 'a speech effect handling step was applied as a preprocessing step to all models.', ""this step removes redundant repetitions of characters in sequence, e. g., ktyyyyyr'veeeeery '."", 'the same speech effect handling was applied by  #TAUTHOR_TAG.', 'for classification, we used the svm implementation in yamcha  #AUTHOR_TAG, and trained with different variations of the features described above.', 'default parameters were selected for training ( c = 1, quadratic kernel, and context window of + / - 2 ).', 'in all results listed below, the baseline corresponds to the do - nothing baseline of the input text.', 'metrics three evaluation metrics are used.', 'the word - error - rate wer metric is computed by summing the total number of word - level substitution errors, insertion errors, and deletion errors in the output, and dividing by the number of words in the reference.', 'the correct - rate corr metric is computed by dividing the number of correct output words by the total number of words in the reference.', 'these two metrics are produced by sclite  #AUTHOR_TAG, using automatic alignment.', 'finally, the accuracy acc metric, used by  #TAUTHOR_TAG, is a simple string matching metric which enforces a word alignment that pairs words in the reference to those of the output.', 'it is calculated by dividing the number of correct output words by the number of words in the input.', 'this metric assumes no split errors in the data ( a word incorrectly split into two words ), which is the case in the data we are working with']",5
"['4.', 'the results of the  #TAUTHOR_TAG cec system are also presented for the purpose of comparison.', 'we can see that using a single classifier,']","['4.', 'the results of the  #TAUTHOR_TAG cec system are also presented for the purpose of comparison.', 'we can see that using a single classifier,']","['( gsec ) on the dev data is presented in the first half of table 4.', 'the results of the  #TAUTHOR_TAG cec system are also presented for the purpose of comparison.', 'we can see that using a single classifier, the generalized model is able to']","['performance of the generalized spelling correction model ( gsec ) on the dev data is presented in the first half of table 4.', 'the results of the  #TAUTHOR_TAG cec system are also presented for the purpose of comparison.', 'we can see that using a single classifier, the generalized model is able to outperform cec, which relies on a cascade of classifiers ( p = 0. 03 for the basic model and p < 0. 0001 for the best model, gsec + 4grams ).', '']",7
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG, the']","[' #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],7
[' #TAUTHOR_TAG was'],[' #TAUTHOR_TAG was'],"[' #TAUTHOR_TAG was the previous state of the art in comment moderation, in the sense that it had the best reported results on the wikipedia datasets ( section 2. 2 ), which were in turn the largest previous publicly available dataset of moderated user comments.', '8 detox represents each comment as a bag of word n - grams ( n ≤ 2, each comment']","[' #TAUTHOR_TAG was the previous state of the art in comment moderation, in the sense that it had the best reported results on the wikipedia datasets ( section 2. 2 ), which were in turn the largest previous publicly available dataset of moderated user comments.', '8 detox represents each comment as a bag of word n - grams ( n ≤ 2, each comment becomes a bag containing its 1 - grams and 2 - grams ) or a bag of character n - grams ( n ≤ 5, each comment becomes a bag containing character 1 - grams,..., 5 - grams ).', 'detox can rely on a logistic regression ( lr ) or mlp classifier, and it can use binary or probabilistic gold labels ( section 2. 2 ) during training.', 'we used the detox implementation provided by wulczyn et al. and the same grid search ( and code ) to tune the hyper - parameters of detox that select word or character n - grams, classifier ( lr or mlp ), and gold labels ( binary or probabilistic ).', 'for gazzetta, only binary gold labels were possible, since g - train - l and g - train - s have a single gold label per comment.', 'unlike wulczyn et al., we tuned the hyper - parameters by evaluating ( computing auc and spearman, section 4 ) on a random 2 % of held - out comments of w - att - train or g - train - s, instead of the development subsets, to be able to obtain more realistic results from the development sets while developing the methods.', ""for both wikipedia and gazzetta, the tuning selected character n - grams, as in the work of wulczyn et al. also, for both wikipedia and gazzetta, it preferred lr to mlp, whereas wulczyn et al. reported slightly higher performance 8 two of the co - authors of  #TAUTHOR_TAG are with jigsaw, who recently announced perspective, a system to detect'toxic'comments."", 'perspective is not the same as detox ( personal communication ), but we were unable to obtain scientific articles describing it.', 'an api for perspective is available at https : / / www. perspectiveapi.', 'com /, but we did not have access to the api at the time the experiments of this paper were carried out.', 'for the mlp on w - att - dev.', '9 the tuning also selected probabilistic labels for wikipedia, as in the work of wulczyn et al']",7
"['the annot', '##ator ensemble experiment of  #TAUTHOR_TAG on 8']","['the annot', '##ator ensemble experiment of  #TAUTHOR_TAG on 8']","['. we also repeated the annot', '##ator ensemble experiment of  #TAUTHOR_TAG on 8k randomly chosen comments of w']","['', 'the system is uncertain ( gray zone ) cannot be avoided and there are inevitably more misclass', '##ifications ; the use of f 2 during threshold tuning places more emphasis on avoiding wrongly accepted comments, leading to high p accept ( 0. 82 ), at the expense of wrong', '##ly rejected comments, i. e., sacrificing p reject ( 0. 59 ). on the re - moderated g - test - s - r ( similar diagrams, not shown ), p accept, p reject', 'become 0. 96, 0. 88 for coverage 50 %, and 0. 92, 0. 48 for coverage 100 %. we also repeated the annot', '##ator ensemble experiment of  #TAUTHOR_TAG on 8k randomly chosen comments of w - att - test ( 4k comments from random users, 4k comments from banned users ). 19 the decisions of 10 randomly chosen annotators ( possibly different per comment ) were used to construct the gold label of each comment. the gold labels were', 'then compared to the decisions of the systems and the decisions of an ensemble of k other annotators, k ranging from 1 to 10. table 3 shows the mean auc and spearman scores, averaged over 25 runs of the experiment, along with', 'standard errrors ( in brackets ). we conclude that rnn and a - rnn are as good as an ensemble of 7 human annotators ;', 'cnn is as good as 4 annotators ; detox is as good as 4 in auc and 3 annotators in spearman correlation, which is consistent with the', 'results of  #TAUTHOR_TAG']",7
"['the discriminator [ 13, 16 ] for backpropagation. we follow a similar training procedure for', 'gumbelgan. outputs are generated through sampling over a multinomial distribution for all methods', ', instead of argmax on the log - likelihood probabilities, as sampling has shown to produce better output quality  #TAUTHOR_TAG. please refer to supplementary section']","['the discriminator [ 13, 16 ] for backpropagation. we follow a similar training procedure for', 'gumbelgan. outputs are generated through sampling over a multinomial distribution for all methods', ', instead of argmax on the log - likelihood probabilities, as sampling has shown to produce better output quality  #TAUTHOR_TAG. please refer to supplementary section table 3 for training parameters of each dataset and table 2 for', 'hyperparameters of']","['the discriminator [ 13, 16 ] for backpropagation. we follow a similar training procedure for', 'gumbelgan. outputs are generated through sampling over a multinomial distribution for all methods', ', instead of argmax on the log - likelihood probabilities, as sampling has shown to produce better output quality  #TAUTHOR_TAG. please refer to supplementary section table 3 for training parameters of']","['model non - differentiable hence, we update parameters for the generator model with policy gradients', 'as described in yu [ 16 ]. we utilize awd - lstm [ 21 ] and transformerxl [ 22 ] based language models. for model hyperparameters please to refer to supplementary section table 2.', 'we use adam optimizer [ 23 ] with β1 = 0. 7 and β2 = 0. 8 similar to [ 20 ] and use a batch size', 'of 50. other practices for lm training were the same as [ 22 ] and [ 21 ] for transformer - xl and awd - lstm', 'respectively. we refer to our proposed gan as creative - gan and compare it to a baseline ( a language model equivalent to our pre - trained', 'generator ) and a gumbelgan model [ 15 ] across all proposed datasets. we use three creative', 'english datasets with distinct linguistic characteristics : ( 1 ) a corpus of 740 classical and contemporary english poems, ( 2 ) a corpus of 14950 metaphor sentences retrieved from a metaphor database website 1 and ( 3 ) a', 'corpus of 1500 song lyrics ranging across genres. the mix of linguistic styles within this corpus offers the potential for', 'interesting variation during the generation phase. we use the same pre - processing as in earlier work [ 20, 24 ]. we reserve 10 % of our data for test set and another 10 % for our validation set. we first', ""pre - train our generator on the gutenberg dataset [ 25 ] for 20 epochs and then fine - tune [ 20 ] them to our target datasets with a language modeling objective. the discriminator's encoder is initialized to"", 'the same weights as our fine - tuned language model. once we have our fine - tuned encoders for each target dataset, we train in an', 'adversarial manner. the discriminator objective here is to score the quality of the creative text. the discriminator is trained for 3 iterations for every iteration of the generator, a practice seen in previous', 'work [ 26 ]. creative - gan relies on using the reward from the discriminator [ 13, 16 ] for backpropagation. we follow a similar training procedure for', 'gumbelgan. outputs are generated through sampling over a multinomial distribution for all methods', ', instead of argmax on the log - likelihood probabilities, as sampling has shown to produce better output quality  #TAUTHOR_TAG. please refer to supplementary section table 3 for training parameters of each dataset and table 2 for', 'hyperparameters of each encoder. we pick these values after experimentation', 'with our validation set. training and output generation code can be found online 2']",1
"['the discriminator [ 13, 16 ] for backpropagation. we follow a similar training procedure for', 'gumbelgan. outputs are generated through sampling over a multinomial distribution for all methods', ', instead of argmax on the log - likelihood probabilities, as sampling has shown to produce better output quality  #TAUTHOR_TAG. please refer to supplementary section']","['the discriminator [ 13, 16 ] for backpropagation. we follow a similar training procedure for', 'gumbelgan. outputs are generated through sampling over a multinomial distribution for all methods', ', instead of argmax on the log - likelihood probabilities, as sampling has shown to produce better output quality  #TAUTHOR_TAG. please refer to supplementary section table 3 for training parameters of each dataset and table 2 for', 'hyperparameters of']","['the discriminator [ 13, 16 ] for backpropagation. we follow a similar training procedure for', 'gumbelgan. outputs are generated through sampling over a multinomial distribution for all methods', ', instead of argmax on the log - likelihood probabilities, as sampling has shown to produce better output quality  #TAUTHOR_TAG. please refer to supplementary section table 3 for training parameters of']","['model non - differentiable hence, we update parameters for the generator model with policy gradients', 'as described in yu [ 16 ]. we utilize awd - lstm [ 21 ] and transformerxl [ 22 ] based language models. for model hyperparameters please to refer to supplementary section table 2.', 'we use adam optimizer [ 23 ] with β1 = 0. 7 and β2 = 0. 8 similar to [ 20 ] and use a batch size', 'of 50. other practices for lm training were the same as [ 22 ] and [ 21 ] for transformer - xl and awd - lstm', 'respectively. we refer to our proposed gan as creative - gan and compare it to a baseline ( a language model equivalent to our pre - trained', 'generator ) and a gumbelgan model [ 15 ] across all proposed datasets. we use three creative', 'english datasets with distinct linguistic characteristics : ( 1 ) a corpus of 740 classical and contemporary english poems, ( 2 ) a corpus of 14950 metaphor sentences retrieved from a metaphor database website 1 and ( 3 ) a', 'corpus of 1500 song lyrics ranging across genres. the mix of linguistic styles within this corpus offers the potential for', 'interesting variation during the generation phase. we use the same pre - processing as in earlier work [ 20, 24 ]. we reserve 10 % of our data for test set and another 10 % for our validation set. we first', ""pre - train our generator on the gutenberg dataset [ 25 ] for 20 epochs and then fine - tune [ 20 ] them to our target datasets with a language modeling objective. the discriminator's encoder is initialized to"", 'the same weights as our fine - tuned language model. once we have our fine - tuned encoders for each target dataset, we train in an', 'adversarial manner. the discriminator objective here is to score the quality of the creative text. the discriminator is trained for 3 iterations for every iteration of the generator, a practice seen in previous', 'work [ 26 ]. creative - gan relies on using the reward from the discriminator [ 13, 16 ] for backpropagation. we follow a similar training procedure for', 'gumbelgan. outputs are generated through sampling over a multinomial distribution for all methods', ', instead of argmax on the log - likelihood probabilities, as sampling has shown to produce better output quality  #TAUTHOR_TAG. please refer to supplementary section table 3 for training parameters of each dataset and table 2 for', 'hyperparameters of each encoder. we pick these values after experimentation', 'with our validation set. training and output generation code can be found online 2']",1
['##ing model or suggest extensions or alternative solutions  #TAUTHOR_TAG'],['original centering model or suggest extensions or alternative solutions  #TAUTHOR_TAG'],"['or suggest extensions or alternative solutions  #TAUTHOR_TAG.', 'it must be acknowledged here that the production schedule of this volume may have been a factor in not including some of this recent work, and also that space limits']",[' #TAUTHOR_TAG'],0
"[' #TAUTHOR_TAG.', 'that research used treetransformations to create various grammars with different contextual annotations on the non - terminals.', 'these grammars were']","[' #TAUTHOR_TAG.', 'that research used treetransformations to create various grammars with different contextual annotations on the non - terminals.', 'these grammars were']","[' #TAUTHOR_TAG.', 'that research used treetransformations to create various grammars with different contextual annotations on the non - terminals.', 'these grammars were then']","['this work we learn clusters of contextual annotations for non - terminals in the penn treebank.', 'perhaps the best way to think about this problem is to contrast our work with that of  #TAUTHOR_TAG.', 'that research used treetransformations to create various grammars with different contextual annotations on the non - terminals.', 'these grammars were then used in conjunction with a cky parser.', 'the authors explored the space of different annotation combinations by hand.', 'here we try to automate the process - to learn the "" right "" combination automatically.', 'our results are not quite as good as those carefully created by hand, but they are close ( 84. 8 vs 85. 7 )']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG. in retrosp'],"['', 'the highest scoring nonterminals that are part of these joint events in the treebank, and use the resulting pcfg. coming to this problem from the standpoint of tree transformation, we naturally view our work', 'as a descendent of  #AUTHOR_TAG and  #TAUTHOR_TAG. in retrospect, however, there', 'are perhaps even greater similarities to that of  #AUTHOR_TAG. consider the approach of  #AUTHOR_TAG. they posit a series of latent annotations for each nonterminal, and learn a grammar using an em algorithm similar to the inside - outside algorithm. their approach, however, requires the number of annotations to be specified ahead of time, and assigns the same number of annotations to each', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG. in retrosp'],"['', 'the highest scoring nonterminals that are part of these joint events in the treebank, and use the resulting pcfg. coming to this problem from the standpoint of tree transformation, we naturally view our work', 'as a descendent of  #AUTHOR_TAG and  #TAUTHOR_TAG. in retrospect, however, there', 'are perhaps even greater similarities to that of  #AUTHOR_TAG. consider the approach of  #AUTHOR_TAG. they posit a series of latent annotations for each nonterminal, and learn a grammar using an em algorithm similar to the inside - outside algorithm. their approach, however, requires the number of annotations to be specified ahead of time, and assigns the same number of annotations to each', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG. in retrosp'],"['', 'the highest scoring nonterminals that are part of these joint events in the treebank, and use the resulting pcfg. coming to this problem from the standpoint of tree transformation, we naturally view our work', 'as a descendent of  #AUTHOR_TAG and  #TAUTHOR_TAG. in retrospect, however, there', 'are perhaps even greater similarities to that of  #AUTHOR_TAG. consider the approach of  #AUTHOR_TAG. they posit a series of latent annotations for each nonterminal, and learn a grammar using an em algorithm similar to the inside - outside algorithm. their approach, however, requires the number of annotations to be specified ahead of time, and assigns the same number of annotations to each', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG. in retrosp'],"['', 'the highest scoring nonterminals that are part of these joint events in the treebank, and use the resulting pcfg. coming to this problem from the standpoint of tree transformation, we naturally view our work', 'as a descendent of  #AUTHOR_TAG and  #TAUTHOR_TAG. in retrospect, however, there', 'are perhaps even greater similarities to that of  #AUTHOR_TAG. consider the approach of  #AUTHOR_TAG. they posit a series of latent annotations for each nonterminal, and learn a grammar using an em algorithm similar to the inside - outside algorithm. their approach, however, requires the number of annotations to be specified ahead of time, and assigns the same number of annotations to each', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG. in retrosp'],"['', 'the highest scoring nonterminals that are part of these joint events in the treebank, and use the resulting pcfg. coming to this problem from the standpoint of tree transformation, we naturally view our work', 'as a descendent of  #AUTHOR_TAG and  #TAUTHOR_TAG. in retrospect, however, there', 'are perhaps even greater similarities to that of  #AUTHOR_TAG. consider the approach of  #AUTHOR_TAG. they posit a series of latent annotations for each nonterminal, and learn a grammar using an em algorithm similar to the inside - outside algorithm. their approach, however, requires the number of annotations to be specified ahead of time, and assigns the same number of annotations to each', '']",0
"['', 'however,  #TAUTHOR_TAG find that this']","['as base.', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this']","['', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this']","['', 'extending on the notion of a base np, introduced by  #AUTHOR_TAG, we mark any nonterminal that dominates only preterminals as base.', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this hurts performance relative to just marking the nps, and so our base feature does not insert.', ""we have two features describing a node's position in the expansion of its parent."", '']",0
"['', 'however,  #TAUTHOR_TAG find that this']","['as base.', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this']","['', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this']","['', 'extending on the notion of a base np, introduced by  #AUTHOR_TAG, we mark any nonterminal that dominates only preterminals as base.', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this hurts performance relative to just marking the nps, and so our base feature does not insert.', ""we have two features describing a node's position in the expansion of its parent."", '']",0
['this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized'],['this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized'],"['most two labels.', 'we perform this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized intermediate rules in']","['our experiments make use of a cky  #AUTHOR_TAG parser 1 we must modify the treebank derived rules so that each expands to at most two labels.', 'we perform this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized intermediate rules in the same way, but we mostly use our clustering scheme to reduce sparsity.', 'we do so by aligning the labels contained in the intermediate nodes in the order in which they would be added when increasing the markovization hori - 1 the implementation we use was created by mark johnson and used for the research in  #AUTHOR_TAG.', 'it is available at his homepage.', 'zon from zero to three.', ""we also always keep the heir label as a feature, following  #TAUTHOR_TAG ( d, f, e, d, − ), where the first item is the heir of the parent's head."", '']",0
"['of  #TAUTHOR_TAG,']","['of  #TAUTHOR_TAG,']","['on the standard testsection of the penn wsj - treebank ( section 23 ).', 'while this is not as accurate as the hand - tailored grammar of  #TAUTHOR_TAG, it is close,']","['have presented a scheme for automatically discovering phrasal categories for parsing with a standard cky parser.', 'the parser achieves 84. 8 % precision - recall f - measure on the standard testsection of the penn wsj - treebank ( section 23 ).', 'while this is not as accurate as the hand - tailored grammar of  #TAUTHOR_TAG, it is close, and we believe there is room for improvement.', 'for starters, the particular clustering scheme is only one of many.', 'our algorithm splits clusters along particular features ( e. g., parent, headpart - of - speech, etc. ).', 'one alternative would be to cluster simultaneously on all the features.', 'it is not obvious which scheme should be better, and they could be quite different.', 'decisions like this abound, and are worth exploring.', 'more radically, it is also possible to grow many decision trees, and thus many alternative grammars.', 'we have been impressed by the success of random - forest methods in language modeling  #AUTHOR_TAG.', 'in these methods many trees ( the forest ) are grown, each trying to predict the next word.', 'the multiple trees together are much more powerful than any one individually.', 'the same might be true for grammars']",0
"[' #TAUTHOR_TAG.', 'that research used treetransformations to create various grammars with different contextual annotations on the non - terminals.', 'these grammars were']","[' #TAUTHOR_TAG.', 'that research used treetransformations to create various grammars with different contextual annotations on the non - terminals.', 'these grammars were']","[' #TAUTHOR_TAG.', 'that research used treetransformations to create various grammars with different contextual annotations on the non - terminals.', 'these grammars were then']","['this work we learn clusters of contextual annotations for non - terminals in the penn treebank.', 'perhaps the best way to think about this problem is to contrast our work with that of  #TAUTHOR_TAG.', 'that research used treetransformations to create various grammars with different contextual annotations on the non - terminals.', 'these grammars were then used in conjunction with a cky parser.', 'the authors explored the space of different annotation combinations by hand.', 'here we try to automate the process - to learn the "" right "" combination automatically.', 'our results are not quite as good as those carefully created by hand, but they are close ( 84. 8 vs 85. 7 )']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG. in retrosp'],"['', 'the highest scoring nonterminals that are part of these joint events in the treebank, and use the resulting pcfg. coming to this problem from the standpoint of tree transformation, we naturally view our work', 'as a descendent of  #AUTHOR_TAG and  #TAUTHOR_TAG. in retrospect, however, there', 'are perhaps even greater similarities to that of  #AUTHOR_TAG. consider the approach of  #AUTHOR_TAG. they posit a series of latent annotations for each nonterminal, and learn a grammar using an em algorithm similar to the inside - outside algorithm. their approach, however, requires the number of annotations to be specified ahead of time, and assigns the same number of annotations to each', '']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG. in retrosp'],"['', 'the highest scoring nonterminals that are part of these joint events in the treebank, and use the resulting pcfg. coming to this problem from the standpoint of tree transformation, we naturally view our work', 'as a descendent of  #AUTHOR_TAG and  #TAUTHOR_TAG. in retrospect, however, there', 'are perhaps even greater similarities to that of  #AUTHOR_TAG. consider the approach of  #AUTHOR_TAG. they posit a series of latent annotations for each nonterminal, and learn a grammar using an em algorithm similar to the inside - outside algorithm. their approach, however, requires the number of annotations to be specified ahead of time, and assigns the same number of annotations to each', '']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG. in retrosp'],"['', 'the highest scoring nonterminals that are part of these joint events in the treebank, and use the resulting pcfg. coming to this problem from the standpoint of tree transformation, we naturally view our work', 'as a descendent of  #AUTHOR_TAG and  #TAUTHOR_TAG. in retrospect, however, there', 'are perhaps even greater similarities to that of  #AUTHOR_TAG. consider the approach of  #AUTHOR_TAG. they posit a series of latent annotations for each nonterminal, and learn a grammar using an em algorithm similar to the inside - outside algorithm. their approach, however, requires the number of annotations to be specified ahead of time, and assigns the same number of annotations to each', '']",1
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG. in retrosp'],"['', 'the highest scoring nonterminals that are part of these joint events in the treebank, and use the resulting pcfg. coming to this problem from the standpoint of tree transformation, we naturally view our work', 'as a descendent of  #AUTHOR_TAG and  #TAUTHOR_TAG. in retrospect, however, there', 'are perhaps even greater similarities to that of  #AUTHOR_TAG. consider the approach of  #AUTHOR_TAG. they posit a series of latent annotations for each nonterminal, and learn a grammar using an em algorithm similar to the inside - outside algorithm. their approach, however, requires the number of annotations to be specified ahead of time, and assigns the same number of annotations to each', '']",1
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG. in retrosp'],"['', 'the highest scoring nonterminals that are part of these joint events in the treebank, and use the resulting pcfg. coming to this problem from the standpoint of tree transformation, we naturally view our work', 'as a descendent of  #AUTHOR_TAG and  #TAUTHOR_TAG. in retrospect, however, there', 'are perhaps even greater similarities to that of  #AUTHOR_TAG. consider the approach of  #AUTHOR_TAG. they posit a series of latent annotations for each nonterminal, and learn a grammar using an em algorithm similar to the inside - outside algorithm. their approach, however, requires the number of annotations to be specified ahead of time, and assigns the same number of annotations to each', '']",3
"['', 'however,  #TAUTHOR_TAG find that this']","['as base.', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this']","['', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this']","['', 'extending on the notion of a base np, introduced by  #AUTHOR_TAG, we mark any nonterminal that dominates only preterminals as base.', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this hurts performance relative to just marking the nps, and so our base feature does not insert.', ""we have two features describing a node's position in the expansion of its parent."", '']",3
['this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized'],['this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized'],"['most two labels.', 'we perform this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized intermediate rules in']","['our experiments make use of a cky  #AUTHOR_TAG parser 1 we must modify the treebank derived rules so that each expands to at most two labels.', 'we perform this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized intermediate rules in the same way, but we mostly use our clustering scheme to reduce sparsity.', 'we do so by aligning the labels contained in the intermediate nodes in the order in which they would be added when increasing the markovization hori - 1 the implementation we use was created by mark johnson and used for the research in  #AUTHOR_TAG.', 'it is available at his homepage.', 'zon from zero to three.', ""we also always keep the heir label as a feature, following  #TAUTHOR_TAG ( d, f, e, d, − ), where the first item is the heir of the parent's head."", '']",3
"['and that of  #TAUTHOR_TAG, we follow their lead in smoothing no production probabilities save those going from preterm']","['and that of  #TAUTHOR_TAG, we follow their lead in smoothing no production probabilities save those going from preterminal to nonterminal.', 'our smoothing mechanism runs roughly along the lines of theirs.', '']","['and that of  #TAUTHOR_TAG, we follow their lead in smoothing no production probabilities save those going from preterm']","['order to ease comparison between our work and that of  #TAUTHOR_TAG, we follow their lead in smoothing no production probabilities save those going from preterminal to nonterminal.', 'our smoothing mechanism runs roughly along the lines of theirs.', 'table 2 : parsing results for grammars generated using clusterer with different random seeds.', 'all numbers here are on the development test set ( section 22 ).', 'preterminal rules are smoothed as follows.', 'we consider several classes of unknown words, based on capitalization, the presence of digits or hyphens, and the suffix.', 'we estimate the probability of a tag t given a word ( or unknown class )', ', where p ( t | unk ) = c ( t, unk ) / c ( unk ) is the probability of the tag given any unknown word class.', 'in order to estimate counts of unknown classes, we let the clusterer see every tree twice : once unmodified, and once with the unknown class replacing each word seen less than five times.', 'the production probability p ( w | t ) is then p ( t | w ) p ( w ) / p ( t ) where p ( w ) and p ( t ) are the respective empirical distributions.', 'the clusterer does not use smoothed probabilities in allocating annotated preterminals to clusters, but simply the maximum likelihood estimates as it does elsewhere.', 'smoothing is only used in the parser']",3
"['- hand side.', 'as in  #AUTHOR_TAG and  #TAUTHOR_TAG, we annotate the penn treebank nonterminals with various context information.', 'suppose [UNK] is a']","[""rule's left - hand side."", 'as in  #AUTHOR_TAG and  #TAUTHOR_TAG, we annotate the penn treebank nonterminals with various context information.', 'suppose [UNK] is a']","[""conditioned on each rule's left - hand side."", 'as in  #AUTHOR_TAG and  #TAUTHOR_TAG, we annotate the penn treebank nonterminals with various context information.', 'suppose [UNK] is']","[""v is a set of terminal symbols ; m = { [UNK] i } is a set of nonterminal symbols ; [UNK] 0 is a start or root symbol ; r is a set of productions of the form [UNK] i → ρ, where ρ is a sequence of terminals and nonterminals ; and q is a family of probability distributions over rules conditioned on each rule's left - hand side."", 'as in  #AUTHOR_TAG and  #TAUTHOR_TAG, we annotate the penn treebank nonterminals with various context information.', 'suppose [UNK] is a treebank non - terminal.', 'let λ = [UNK] [ α ] denote the non - terminal category annotated with a vector of context features α.', 'a pcfg is derived from the trees in the usual manner, with production rules taken directly from the annotated trees, and the probability of an annotated rule q ( λ → ρ ) = c ( λ→ρ ) c ( λ ) where c ( λ → ρ ) and c ( λ ) are the number of observations of the production and its left hand side, respectively.', 'we refer to the grammar resulting from extracting annotated productions directly out of the treebank as the base grammar.', 'our goal is to partition the set of annotated nonterminals into clusters φ = { φ i }.', 'each possible clustering corresponds to a pcfg, with the set of non - terminals corresponding to the set of clusters.', 'the probability of a production under this pcfg is', 'where φs ∈ φ are clusters of annotated nonterminals and where :', 'we refer to the pcfg of some clustering as the clustered grammar']",5
"['', 'however,  #TAUTHOR_TAG find that this']","['as base.', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this']","['', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this']","['', 'extending on the notion of a base np, introduced by  #AUTHOR_TAG, we mark any nonterminal that dominates only preterminals as base.', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this hurts performance relative to just marking the nps, and so our base feature does not insert.', ""we have two features describing a node's position in the expansion of its parent."", '']",5
['this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized'],['this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized'],"['most two labels.', 'we perform this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized intermediate rules in']","['our experiments make use of a cky  #AUTHOR_TAG parser 1 we must modify the treebank derived rules so that each expands to at most two labels.', 'we perform this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized intermediate rules in the same way, but we mostly use our clustering scheme to reduce sparsity.', 'we do so by aligning the labels contained in the intermediate nodes in the order in which they would be added when increasing the markovization hori - 1 the implementation we use was created by mark johnson and used for the research in  #AUTHOR_TAG.', 'it is available at his homepage.', 'zon from zero to three.', ""we also always keep the heir label as a feature, following  #TAUTHOR_TAG ( d, f, e, d, − ), where the first item is the heir of the parent's head."", '']",5
"['', 'however,  #TAUTHOR_TAG find that this']","['as base.', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this']","['', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this']","['', 'extending on the notion of a base np, introduced by  #AUTHOR_TAG, we mark any nonterminal that dominates only preterminals as base.', 'collins inserts a unary np over any base nps without np parents.', 'however,  #TAUTHOR_TAG find that this hurts performance relative to just marking the nps, and so our base feature does not insert.', ""we have two features describing a node's position in the expansion of its parent."", '']",6
['this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized'],['this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized'],"['most two labels.', 'we perform this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized intermediate rules in']","['our experiments make use of a cky  #AUTHOR_TAG parser 1 we must modify the treebank derived rules so that each expands to at most two labels.', 'we perform this in a manner similar to  #TAUTHOR_TAG and  #AUTHOR_TAG our mechanism lays out the unmarkovized intermediate rules in the same way, but we mostly use our clustering scheme to reduce sparsity.', 'we do so by aligning the labels contained in the intermediate nodes in the order in which they would be added when increasing the markovization hori - 1 the implementation we use was created by mark johnson and used for the research in  #AUTHOR_TAG.', 'it is available at his homepage.', 'zon from zero to three.', ""we also always keep the heir label as a feature, following  #TAUTHOR_TAG ( d, f, e, d, − ), where the first item is the heir of the parent's head."", '']",6
"['as those of  #TAUTHOR_TAG or  #AUTHOR_TAG.', 'it is']","['as those of  #TAUTHOR_TAG or  #AUTHOR_TAG.', 'it is']","['as those of  #TAUTHOR_TAG or  #AUTHOR_TAG.', 'it is']","['results are shown in table 1.', 'the first three columns show the labeled precision, recall and fmeasure, respectively.', 'the remaining two show the number of crossing brackets per sentence, and the percentage of sentences with no crossing brackets.', 'unfortunately, our model does not perform quite as well as those of  #TAUTHOR_TAG or  #AUTHOR_TAG.', ""it is worth noting that matsuzaki's grammar uses a different parse evaluation scheme than klein & manning or we do."", 'we select the parse with the highest probability according to the annotated grammar.', 'matsuzaki, on the other hand, argues that the proper thing to do is to find the most likely unannotated parse.', 'the probability of this parse is the sum over the probabilities of all annotated parses that reduce to that unannotated parse.', 'since calculating the parse that maximizes this quantity is np hard, they try several approximations.', 'one is what klein & manning and we do.', 'however, they have a better performing approximation which is used in their reported score.', 'they do not report their score on section 23 using the most - probable - annotatedparse method.', 'they do however compare the performance of different methods using development data, and find that their better approximation gives an absolute improvement in f - measure in the. 5 - 1 percent range.', 'hence it is probable that even with their better method our grammar would not outperform theirs.', 'table 2 shows the results on the development test set ( section 22 ) for four different initial random seeds.', 'recall that when splitting a cluster, the initial partition of the base grammar nonterminals is made randomly.', 'the model from the second run was used for parsing the final test set ( section 23 ) in table 1.', 'one interesting thing our method allows is for us to examine which features turn out to be useful in which contexts.', 'we noted for each trereebank nonterminal, and for each feature, how many times that nonterminal was split on that feature, for the grammar selected in the model selection stage.', 'we ran the clustering with these four different random seeds.', 'we find that in particular, the clusterer only found the head feature to be useful in very specific circumstances.', 'it was used quite a bit to split preterminals ; but for phrasals it was only used to split adjp, adv p, n p, p p, v p, qp, and sbar.', 'the part of speech of the head was only used to split n p and v p.', 'furthermore, the grandparent tag appears to be of importance primarily for v']",7
"[', in studies performed on the text genres web debate forums  #AUTHOR_TAG, news paper text  #AUTHOR_TAG and tweets  #TAUTHOR_TAG.', 'stance detection is generally considered more difficult than']","['stance detection studies.', 'for instance, in studies performed on the text genres web debate forums  #AUTHOR_TAG, news paper text  #AUTHOR_TAG and tweets  #TAUTHOR_TAG.', 'stance detection is generally considered more difficult than']","[', in studies performed on the text genres web debate forums  #AUTHOR_TAG, news paper text  #AUTHOR_TAG and tweets  #TAUTHOR_TAG.', 'stance detection is generally considered more difficult than sentiment analysis and thereby a task']","['definition of stance is used in several stance detection studies.', 'for instance, in studies performed on the text genres web debate forums  #AUTHOR_TAG, news paper text  #AUTHOR_TAG and tweets  #TAUTHOR_TAG.', 'stance detection is generally considered more difficult than sentiment analysis and thereby a task for which currently available methods achieve lower results.', 'this was, for instance, shown by a recent shared task on three - category stance classification of tweets, where an f - score of 0. 59 was achieved by a classifier that outperformed submissions from 19 shared task teams  #TAUTHOR_TAG.', 'for the task of stance classification of posts of two - sided discussion threads, an f - score of 0. 70 is the best result we have been able to find in previous research  #AUTHOR_TAG', 'previous studies on attitudes towards vaccination do not make use of the term stance, but discuss negative / positive sentiment towards vaccination.', 'there are a number of such sentiment detection studies conducted on tweets, while studies on online forums, to the best of our knowledge, are limited to the task of topic modelling  #AUTHOR_TAG.', 'most vaccination sentiment studies have been conducted on tweets that contain keywords related to hpv ( human papillomavirus ) vaccination.', 'in one of these, 1, 470 hpv - related tweets were manually categorised according to sentiment towards the hpv vaccine ( positive, negative, neutral, or no mention ).', '']",0
"[', in studies performed on the text genres web debate forums  #AUTHOR_TAG, news paper text  #AUTHOR_TAG and tweets  #TAUTHOR_TAG.', 'stance detection is generally considered more difficult than']","['stance detection studies.', 'for instance, in studies performed on the text genres web debate forums  #AUTHOR_TAG, news paper text  #AUTHOR_TAG and tweets  #TAUTHOR_TAG.', 'stance detection is generally considered more difficult than']","[', in studies performed on the text genres web debate forums  #AUTHOR_TAG, news paper text  #AUTHOR_TAG and tweets  #TAUTHOR_TAG.', 'stance detection is generally considered more difficult than sentiment analysis and thereby a task']","['definition of stance is used in several stance detection studies.', 'for instance, in studies performed on the text genres web debate forums  #AUTHOR_TAG, news paper text  #AUTHOR_TAG and tweets  #TAUTHOR_TAG.', 'stance detection is generally considered more difficult than sentiment analysis and thereby a task for which currently available methods achieve lower results.', 'this was, for instance, shown by a recent shared task on three - category stance classification of tweets, where an f - score of 0. 59 was achieved by a classifier that outperformed submissions from 19 shared task teams  #TAUTHOR_TAG.', 'for the task of stance classification of posts of two - sided discussion threads, an f - score of 0. 70 is the best result we have been able to find in previous research  #AUTHOR_TAG', 'previous studies on attitudes towards vaccination do not make use of the term stance, but discuss negative / positive sentiment towards vaccination.', 'there are a number of such sentiment detection studies conducted on tweets, while studies on online forums, to the best of our knowledge, are limited to the task of topic modelling  #AUTHOR_TAG.', 'most vaccination sentiment studies have been conducted on tweets that contain keywords related to hpv ( human papillomavirus ) vaccination.', 'in one of these, 1, 470 hpv - related tweets were manually categorised according to sentiment towards the hpv vaccine ( positive, negative, neutral, or no mention ).', '']",0
['tweet in the study by  #TAUTHOR_TAG were employed through a crowdsour'],['tweet in the study by  #TAUTHOR_TAG were employed through a crowdsour'],['tweet in the study by  #TAUTHOR_TAG were employed through a crowdsour'],"['', ""portals, where meta - data on the debaters'stance is provided. our decision, to classify debate posts as against vaccination when they opposed an official vaccination policy, was based on that debaters often"", 'implicitly argue against such a policy. in addition, a system for surveilling increases in vaccine hesitancy is likely to take an official policy as its point of', 'departure. the eight annotators that classified each tweet in the study by  #TAUTHOR_TAG were employed through a crowdsourcing platform, which was made possible by that the', 'stance targets were chosen with the criterion that they should be commonly known in the united states. for annotating stance on vaccination, however, annotators with some amount of prior', 'knowledge of vaccine debate topics and vaccine controversies might be preferred. crowdsourcing might therefore not be a', 'viable option for this annotation task. 40 randomly selected posts', 'that did not fulfil the criterion of containing any of the selected vaccine - related filter terms, and which therefore had been excluded from the', 'study, were also annotated. although this set is too small to make any definite conclusions, the relatively large proportion of posts in the set that expressed a stance against or for vaccination ( 25 % ) indicates that the filtering criterion used was too crude and led to the', 'exclusion of relevant posts. future studies should therefore either apply a better filtering criterion, or include all discussion thread posts in an annotation and machine learning study']",0
"['authors of the paper.', 'following the principle of the guidelines by  #TAUTHOR_TAG,']","['authors of the paper.', 'following the principle of the guidelines by  #TAUTHOR_TAG,']","['of the authors of the paper.', 'following the principle of the guidelines by  #TAUTHOR_TAG,']","['1, 190 posts to include in the experiment were presented for manual classification in a random order, without revealing who the debater was or which thread the post belonged to.', 'the annotation was performed by one of the authors of the paper.', 'following the principle of the guidelines by  #TAUTHOR_TAG, we classified the posts as taking a stance against or for vaccination, or to be undecided.', '']",3
"['of  #TAUTHOR_TAG, as well as of many of the previously']","['of  #TAUTHOR_TAG, as well as of many of the previously']","['standard text classification approach, in the form of a linear support vector machine model, was applied to the task of automatically classifying the debate posts.', 'this follows the approach of  #TAUTHOR_TAG, as well as of many of the previously']","['standard text classification approach, in the form of a linear support vector machine model, was applied to the task of automatically classifying the debate posts.', 'this follows the approach of  #TAUTHOR_TAG, as well as of many of the previously performed vaccine sentiment studies.', 'the model was trained on all tokens in the training data, as well as on 2 -, 3 - and 4 - grams that occurred at least twice in the data.', 'the standard nltk stop word list for english was used for removing non - content words when constructing one set of n - grams.', 'an additional set of n - grams was generated with a reduced version of this stop word list, which mainly consisted of articles, forms of copula, and forms of "" it "", "" have "" and "" do "".', 'the reason for using a reduced list was that negations, pronouns etc.', 'that were included in the standard nltk stop word list can be important cues for classifying argumentative text.', 'two types of classifiers were trained : one to perform the task of classifying posts into all three categories annotated, and the other one to perform the task of distinguishing posts annotated as against vaccination from those annotated as for vaccination.', ""the classifiers were implemented using scikit - learn's linearsvc class with the default settings."", 'for training / evaluation, we applied crossvalidation on the 1, 190 annotated posts.', 'due to the relatively small data size, we used 30 folds, instead of the more standard approach of 10 folds']",3
"['of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which']","['of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which']","['from the previously mentioned shared task of stance detection of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which']","['choice of machine learning model was primarily based on that a linear support vector machine was successful on data from the previously mentioned shared task of stance detection of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which might intuitively be better adapted to the task, i. e., an lstm classifier  #AUTHOR_TAG.', 'support vector machines have also been used in many of the previous vaccine sentiment studies.', 'in addition, a linear support vector machine classifier is also a standard method that is often used for different types of text classification tasks  #AUTHOR_TAG pp.', '335 - 337 ).', '']",3
"['of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which']","['of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which']","['from the previously mentioned shared task of stance detection of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which']","['choice of machine learning model was primarily based on that a linear support vector machine was successful on data from the previously mentioned shared task of stance detection of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which might intuitively be better adapted to the task, i. e., an lstm classifier  #AUTHOR_TAG.', 'support vector machines have also been used in many of the previous vaccine sentiment studies.', 'in addition, a linear support vector machine classifier is also a standard method that is often used for different types of text classification tasks  #AUTHOR_TAG pp.', '335 - 337 ).', '']",3
"['authors of the paper.', 'following the principle of the guidelines by  #TAUTHOR_TAG,']","['authors of the paper.', 'following the principle of the guidelines by  #TAUTHOR_TAG,']","['of the authors of the paper.', 'following the principle of the guidelines by  #TAUTHOR_TAG,']","['1, 190 posts to include in the experiment were presented for manual classification in a random order, without revealing who the debater was or which thread the post belonged to.', 'the annotation was performed by one of the authors of the paper.', 'following the principle of the guidelines by  #TAUTHOR_TAG, we classified the posts as taking a stance against or for vaccination, or to be undecided.', '']",5
"['of  #TAUTHOR_TAG, as well as of many of the previously']","['of  #TAUTHOR_TAG, as well as of many of the previously']","['standard text classification approach, in the form of a linear support vector machine model, was applied to the task of automatically classifying the debate posts.', 'this follows the approach of  #TAUTHOR_TAG, as well as of many of the previously']","['standard text classification approach, in the form of a linear support vector machine model, was applied to the task of automatically classifying the debate posts.', 'this follows the approach of  #TAUTHOR_TAG, as well as of many of the previously performed vaccine sentiment studies.', 'the model was trained on all tokens in the training data, as well as on 2 -, 3 - and 4 - grams that occurred at least twice in the data.', 'the standard nltk stop word list for english was used for removing non - content words when constructing one set of n - grams.', 'an additional set of n - grams was generated with a reduced version of this stop word list, which mainly consisted of articles, forms of copula, and forms of "" it "", "" have "" and "" do "".', 'the reason for using a reduced list was that negations, pronouns etc.', 'that were included in the standard nltk stop word list can be important cues for classifying argumentative text.', 'two types of classifiers were trained : one to perform the task of classifying posts into all three categories annotated, and the other one to perform the task of distinguishing posts annotated as against vaccination from those annotated as for vaccination.', ""the classifiers were implemented using scikit - learn's linearsvc class with the default settings."", 'for training / evaluation, we applied crossvalidation on the 1, 190 annotated posts.', 'due to the relatively small data size, we used 30 folds, instead of the more standard approach of 10 folds']",5
"['of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which']","['of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which']","['from the previously mentioned shared task of stance detection of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which']","['choice of machine learning model was primarily based on that a linear support vector machine was successful on data from the previously mentioned shared task of stance detection of tweets  #TAUTHOR_TAG.', 'this model outperformed submissions from teams that used methods which might intuitively be better adapted to the task, i. e., an lstm classifier  #AUTHOR_TAG.', 'support vector machines have also been used in many of the previous vaccine sentiment studies.', 'in addition, a linear support vector machine classifier is also a standard method that is often used for different types of text classification tasks  #AUTHOR_TAG pp.', '335 - 337 ).', '']",5
"['presented in  #TAUTHOR_TAG.', 'we explore']","['presented in  #TAUTHOR_TAG.', 'we explore']","['- structurebased approach presented in  #TAUTHOR_TAG.', 'we explore the following improvements on the original metric : 1 )']","[""describe dcu's lfg dependencybased metric submitted to the shared evaluation task of wmt - metricsmatr 2010."", 'the metric is built on the lfg f - structurebased approach presented in  #TAUTHOR_TAG.', 'we explore the following improvements on the original metric : 1 ) we replace the in - house lfg parser with an open source dependency parser that directly parses strings into lfg dependencies ; 2 ) we add a stemming module and unigram paraphrases to strengthen the aligner ; 3 ) we introduce a chunk penalty following the practice of meteor to reward continuous matches ; and 4 ) we introduce and tune parameters to maximize the correlation with human judgement.', ""experiments show that these enhancements improve the dependency - based metric's correlation with human judgement""]",6
"['##s,  #TAUTHOR_TAG']","[""n - best parses,  #TAUTHOR_TAG's method considerably""]","['n - best parses,  #TAUTHOR_TAG']","['', ""with the addition of partial matching and n - best parses,  #TAUTHOR_TAG's method considerably outperforms  #AUTHOR_TAG w. r. t."", 'correlation with human judgement.', 'the edpm metric  #AUTHOR_TAG improves this line of research by using arc labels derived from a probabilistic context - free grammar ( pcfg ) parse to replace the lfg labels, showing that a pcfg parser is sufficient for preprocessing, compared to a dependency parser in  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'edpm also incorporates more information sources : e. g. the parser confidence, the porter stemmer, wordnet synonyms and paraphrases.', 'besides the metrics that rely solely on the dependency structures, information from the dependency parser is a component of some other metrics that use more diverse resources, such as the textual entailment - based metric of  #AUTHOR_TAG.', 'in this paper we extend the work of  #TAUTHOR_TAG in a different manner : we use an adapted version of the malt parser  #AUTHOR_TAG to produce 1 - best lfg dependencies and allow triple matches where the dependency labels are different.', 'we incorporate stemming, synonym and paraphrase information as in  #AUTHOR_TAG, and at the same time introduce a chunk penalty in']",6
"[' #TAUTHOR_TAG, lexical variations at']","[' #TAUTHOR_TAG, lexical variations at']","[' #TAUTHOR_TAG, lexical variations at the word - level are captured by wordnet.', 'we use']","[' #TAUTHOR_TAG, lexical variations at the word - level are captured by wordnet.', 'we use a porter stemmer and a unigram paraphrase database to allow more lexical variations.', 'with these two resources combined, there are four stages of word level matching in our system : exact match, stem match, wordnet match and unigram paraphrase match.', ""the stemming module uses porter's stemmer implementation 3 and the wordnet module uses the jaws wordnet interface."", '4 our metric only considers unigram paraphrases, which are extracted from the paraphrase database in terp 5 using the script in the me - teor 6 metric.', 'the metric described in  #TAUTHOR_TAG does not explicitly consider word order and fluency.', 'meteor, on the other hand, utilizes this information through a chunk penalty.', ""we introduce a chunk penalty to our dependency - based metric following meteor's string - based approach."", '']",6
"['##ased metric described in  #TAUTHOR_TAG, we use a publicly available parser instead of an in - house parser to']","[""this paper we describe dcu's dependencybased mt evaluation metric submitted to wmtmetricsmatr 2010."", 'building upon the lfgbased metric described in  #TAUTHOR_TAG, we use a publicly available parser instead of an in - house parser to']","['##ased metric described in  #TAUTHOR_TAG, we use a publicly available parser instead of an in - house parser to']","[""this paper we describe dcu's dependencybased mt evaluation metric submitted to wmtmetricsmatr 2010."", 'building upon the lfgbased metric described in  #TAUTHOR_TAG, we use a publicly available parser instead of an in - house parser to produce dependency labels, so that the metric can run on a third party machine.', 'we improve the metric by allowing more lexical variations and weighting dependency triple matches depending on their importance according to correlation with human judgement.', 'for future work, we hope to apply this method to languages other than english, and perform more refinement on dependency type labels and linguistic resources']",6
"['##s,  #TAUTHOR_TAG']","[""n - best parses,  #TAUTHOR_TAG's method considerably""]","['n - best parses,  #TAUTHOR_TAG']","['', ""with the addition of partial matching and n - best parses,  #TAUTHOR_TAG's method considerably outperforms  #AUTHOR_TAG w. r. t."", 'correlation with human judgement.', 'the edpm metric  #AUTHOR_TAG improves this line of research by using arc labels derived from a probabilistic context - free grammar ( pcfg ) parse to replace the lfg labels, showing that a pcfg parser is sufficient for preprocessing, compared to a dependency parser in  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'edpm also incorporates more information sources : e. g. the parser confidence, the porter stemmer, wordnet synonyms and paraphrases.', 'besides the metrics that rely solely on the dependency structures, information from the dependency parser is a component of some other metrics that use more diverse resources, such as the textual entailment - based metric of  #AUTHOR_TAG.', 'in this paper we extend the work of  #TAUTHOR_TAG in a different manner : we use an adapted version of the malt parser  #AUTHOR_TAG to produce 1 - best lfg dependencies and allow triple matches where the dependency labels are different.', 'we incorporate stemming, synonym and paraphrase information as in  #AUTHOR_TAG, and at the same time introduce a chunk penalty in']",0
"['##s,  #TAUTHOR_TAG']","[""n - best parses,  #TAUTHOR_TAG's method considerably""]","['n - best parses,  #TAUTHOR_TAG']","['', ""with the addition of partial matching and n - best parses,  #TAUTHOR_TAG's method considerably outperforms  #AUTHOR_TAG w. r. t."", 'correlation with human judgement.', 'the edpm metric  #AUTHOR_TAG improves this line of research by using arc labels derived from a probabilistic context - free grammar ( pcfg ) parse to replace the lfg labels, showing that a pcfg parser is sufficient for preprocessing, compared to a dependency parser in  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'edpm also incorporates more information sources : e. g. the parser confidence, the porter stemmer, wordnet synonyms and paraphrases.', 'besides the metrics that rely solely on the dependency structures, information from the dependency parser is a component of some other metrics that use more diverse resources, such as the textual entailment - based metric of  #AUTHOR_TAG.', 'in this paper we extend the work of  #TAUTHOR_TAG in a different manner : we use an adapted version of the malt parser  #AUTHOR_TAG to produce 1 - best lfg dependencies and allow triple matches where the dependency labels are different.', 'we incorporate stemming, synonym and paraphrase information as in  #AUTHOR_TAG, and at the same time introduce a chunk penalty in']",0
['basic method of  #TAUTHOR_TAG can be'],['basic method of  #TAUTHOR_TAG can be'],"['basic method of  #TAUTHOR_TAG can be illustrated by the example in table 1.', 'the metric in  #TAUTHOR_TAG performs triple matching over the hyp - and ref - triples and calculates the metric score using']","['basic method of  #TAUTHOR_TAG can be illustrated by the example in table 1.', 'the metric in  #TAUTHOR_TAG performs triple matching over the hyp - and ref - triples and calculates the metric score using the f - score of matching precision and recall.', 'let m be the number of matches, h be the number of triples in the hypothesis and e be the number of triples in the reference.', '']",0
['basic method of  #TAUTHOR_TAG can be'],['basic method of  #TAUTHOR_TAG can be'],"['basic method of  #TAUTHOR_TAG can be illustrated by the example in table 1.', 'the metric in  #TAUTHOR_TAG performs triple matching over the hyp - and ref - triples and calculates the metric score using']","['basic method of  #TAUTHOR_TAG can be illustrated by the example in table 1.', 'the metric in  #TAUTHOR_TAG performs triple matching over the hyp - and ref - triples and calculates the metric score using the f - score of matching precision and recall.', 'let m be the number of matches, h be the number of triples in the hypothesis and e be the number of triples in the reference.', '']",0
['metric described in  #TAUTHOR_TAG uses the'],['metric described in  #TAUTHOR_TAG uses the dcu lfg parser  #AUTHOR_TAG to produce lfg'],['metric described in  #TAUTHOR_TAG uses the dcu lfg parser  #AUTHOR_TAG to produce lf'],"['metric described in  #TAUTHOR_TAG uses the dcu lfg parser  #AUTHOR_TAG to produce lfg dependency triples.', 'the parser uses a penn treebank - trained parser to produce c - structures ( constituency trees ) and an lfg fstructure annotation algorithm on the c - structure to obtain f - structures.', 'in  #TAUTHOR_TAG, triple matching on f - structures produced by this paradigm correlates well with human judgement, but this paradigm is not adequate for the wmtmetricsmatr evaluation in two respects : 1 ) the inhouse lfg annotation algorithm is not publicly available and 2 ) the speed of this paradigm is not satisfactory.', 'we instead use the malt parser 1  #AUTHOR_TAG with a parsing model trained on lfg dependencies to produce the f - structure triples.', 'our collaborators 2 first apply the lfg annotation algorithm to the penn treebank training data to obtain f - structures, and then the f - structures are converted into dependency trees in conll format to train the parsing model.', 'we use the liblinear  #AUTHOR_TAG classification module to for fast parsing speed']",0
['metric described in  #TAUTHOR_TAG uses the'],['metric described in  #TAUTHOR_TAG uses the dcu lfg parser  #AUTHOR_TAG to produce lfg'],['metric described in  #TAUTHOR_TAG uses the dcu lfg parser  #AUTHOR_TAG to produce lf'],"['metric described in  #TAUTHOR_TAG uses the dcu lfg parser  #AUTHOR_TAG to produce lfg dependency triples.', 'the parser uses a penn treebank - trained parser to produce c - structures ( constituency trees ) and an lfg fstructure annotation algorithm on the c - structure to obtain f - structures.', 'in  #TAUTHOR_TAG, triple matching on f - structures produced by this paradigm correlates well with human judgement, but this paradigm is not adequate for the wmtmetricsmatr evaluation in two respects : 1 ) the inhouse lfg annotation algorithm is not publicly available and 2 ) the speed of this paradigm is not satisfactory.', 'we instead use the malt parser 1  #AUTHOR_TAG with a parsing model trained on lfg dependencies to produce the f - structure triples.', 'our collaborators 2 first apply the lfg annotation algorithm to the penn treebank training data to obtain f - structures, and then the f - structures are converted into dependency trees in conll format to train the parsing model.', 'we use the liblinear  #AUTHOR_TAG classification module to for fast parsing speed']",0
"[' #TAUTHOR_TAG, lexical variations at']","[' #TAUTHOR_TAG, lexical variations at']","[' #TAUTHOR_TAG, lexical variations at the word - level are captured by wordnet.', 'we use']","[' #TAUTHOR_TAG, lexical variations at the word - level are captured by wordnet.', 'we use a porter stemmer and a unigram paraphrase database to allow more lexical variations.', 'with these two resources combined, there are four stages of word level matching in our system : exact match, stem match, wordnet match and unigram paraphrase match.', ""the stemming module uses porter's stemmer implementation 3 and the wordnet module uses the jaws wordnet interface."", '4 our metric only considers unigram paraphrases, which are extracted from the paraphrase database in terp 5 using the script in the me - teor 6 metric.', 'the metric described in  #TAUTHOR_TAG does not explicitly consider word order and fluency.', 'meteor, on the other hand, utilizes this information through a chunk penalty.', ""we introduce a chunk penalty to our dependency - based metric following meteor's string - based approach."", '']",0
"[' #TAUTHOR_TAG, lexical variations at']","[' #TAUTHOR_TAG, lexical variations at']","[' #TAUTHOR_TAG, lexical variations at the word - level are captured by wordnet.', 'we use']","[' #TAUTHOR_TAG, lexical variations at the word - level are captured by wordnet.', 'we use a porter stemmer and a unigram paraphrase database to allow more lexical variations.', 'with these two resources combined, there are four stages of word level matching in our system : exact match, stem match, wordnet match and unigram paraphrase match.', ""the stemming module uses porter's stemmer implementation 3 and the wordnet module uses the jaws wordnet interface."", '4 our metric only considers unigram paraphrases, which are extracted from the paraphrase database in terp 5 using the script in the me - teor 6 metric.', 'the metric described in  #TAUTHOR_TAG does not explicitly consider word order and fluency.', 'meteor, on the other hand, utilizes this information through a chunk penalty.', ""we introduce a chunk penalty to our dependency - based metric following meteor's string - based approach."", '']",0
['the metric presented in  #TAUTHOR_TAG'],['the metric presented in  #TAUTHOR_TAG'],"['this section, we briefly review the metric presented in  #TAUTHOR_TAG']","['this section, we briefly review the metric presented in  #TAUTHOR_TAG']",5
['basic method of  #TAUTHOR_TAG can be'],['basic method of  #TAUTHOR_TAG can be'],"['basic method of  #TAUTHOR_TAG can be illustrated by the example in table 1.', 'the metric in  #TAUTHOR_TAG performs triple matching over the hyp - and ref - triples and calculates the metric score using']","['basic method of  #TAUTHOR_TAG can be illustrated by the example in table 1.', 'the metric in  #TAUTHOR_TAG performs triple matching over the hyp - and ref - triples and calculates the metric score using the f - score of matching precision and recall.', 'let m be the number of matches, h be the number of triples in the hypothesis and e be the number of triples in the reference.', '']",5
"['our enhancements.', 'the first two settings compare the effect of allowing / not allowing soft matches, but only uses wordnet as in  #TAUTHOR_TAG.', '']","['our enhancements.', 'the first two settings compare the effect of allowing / not allowing soft matches, but only uses wordnet as in  #TAUTHOR_TAG.', '']","['our enhancements.', 'the first two settings compare the effect of allowing / not allowing soft matches, but only uses wordnet as in  #TAUTHOR_TAG.', 'the third setting']","['experiment with four settings of the metric : hard, soft, softall and weighted in order to validate our enhancements.', 'the first two settings compare the effect of allowing / not allowing soft matches, but only uses wordnet as in  #TAUTHOR_TAG.', 'the third setting applies our additional linguistic features and the final setting tunes parameter weights for higher correlation with human judgement.', ""we report pearson's r, spearman's ρ and kendall's τ on segment and system levels on the nist metricsmatr 2010 development set using snover's scoring tool."", '7 table 2 shows that allowing soft triple matches and using more linguistic features all lead to higher correlation with human judgement.', 'though the parameters might somehow overfit on the data set even if we apply cross validation, this certainly confirms the necessity of weighing dependency matches according to their types.', 'table 3, the trend is very similar to that of the segment level.', 'the improvements we introduce all lead to improvements in correlation with human judgement']",5
['metric described in  #TAUTHOR_TAG uses the'],['metric described in  #TAUTHOR_TAG uses the dcu lfg parser  #AUTHOR_TAG to produce lfg'],['metric described in  #TAUTHOR_TAG uses the dcu lfg parser  #AUTHOR_TAG to produce lf'],"['metric described in  #TAUTHOR_TAG uses the dcu lfg parser  #AUTHOR_TAG to produce lfg dependency triples.', 'the parser uses a penn treebank - trained parser to produce c - structures ( constituency trees ) and an lfg fstructure annotation algorithm on the c - structure to obtain f - structures.', 'in  #TAUTHOR_TAG, triple matching on f - structures produced by this paradigm correlates well with human judgement, but this paradigm is not adequate for the wmtmetricsmatr evaluation in two respects : 1 ) the inhouse lfg annotation algorithm is not publicly available and 2 ) the speed of this paradigm is not satisfactory.', 'we instead use the malt parser 1  #AUTHOR_TAG with a parsing model trained on lfg dependencies to produce the f - structure triples.', 'our collaborators 2 first apply the lfg annotation algorithm to the penn treebank training data to obtain f - structures, and then the f - structures are converted into dependency trees in conll format to train the parsing model.', 'we use the liblinear  #AUTHOR_TAG classification module to for fast parsing speed']",4
"['the 50 - best parses in  #TAUTHOR_TAG, the 1 - best parse limits the number of triple matches that can be found.', 'to compensate for this, we allow triple']","['the 50 - best parses in  #TAUTHOR_TAG, the 1 - best parse limits the number of triple matches that can be found.', 'to compensate for this, we allow triple']","['the 50 - best parses in  #TAUTHOR_TAG, the 1 - best parse limits the number of triple matches that can be found.', 'to compensate for this, we allow triple matches']","['our parser produces only the 1 - best outputs.', 'compared to the 50 - best parses in  #TAUTHOR_TAG, the 1 - best parse limits the number of triple matches that can be found.', 'to compensate for this, we allow triple matches that have the same head and modifier to constitute a match, even if their dependency labels are different.', 'therefore for triples dep1 ( head1, mod1 ) and dep2 ( head2, mod2 ), we allow three types of match : a complete match if the two triples are identical, a partial match if dep1 = dep2 and head1 = head2, and a soft match if head1 = head2 and mod1 = mod2']",4
"[' #TAUTHOR_TAG, lexical variations at']","[' #TAUTHOR_TAG, lexical variations at']","[' #TAUTHOR_TAG, lexical variations at the word - level are captured by wordnet.', 'we use']","[' #TAUTHOR_TAG, lexical variations at the word - level are captured by wordnet.', 'we use a porter stemmer and a unigram paraphrase database to allow more lexical variations.', 'with these two resources combined, there are four stages of word level matching in our system : exact match, stem match, wordnet match and unigram paraphrase match.', ""the stemming module uses porter's stemmer implementation 3 and the wordnet module uses the jaws wordnet interface."", '4 our metric only considers unigram paraphrases, which are extracted from the paraphrase database in terp 5 using the script in the me - teor 6 metric.', 'the metric described in  #TAUTHOR_TAG does not explicitly consider word order and fluency.', 'meteor, on the other hand, utilizes this information through a chunk penalty.', ""we introduce a chunk penalty to our dependency - based metric following meteor's string - based approach."", '']",4
"['##ased metric described in  #TAUTHOR_TAG, we use a publicly available parser instead of an in - house parser to']","[""this paper we describe dcu's dependencybased mt evaluation metric submitted to wmtmetricsmatr 2010."", 'building upon the lfgbased metric described in  #TAUTHOR_TAG, we use a publicly available parser instead of an in - house parser to']","['##ased metric described in  #TAUTHOR_TAG, we use a publicly available parser instead of an in - house parser to']","[""this paper we describe dcu's dependencybased mt evaluation metric submitted to wmtmetricsmatr 2010."", 'building upon the lfgbased metric described in  #TAUTHOR_TAG, we use a publicly available parser instead of an in - house parser to produce dependency labels, so that the metric can run on a third party machine.', 'we improve the metric by allowing more lexical variations and weighting dependency triple matches depending on their importance according to correlation with human judgement.', 'for future work, we hope to apply this method to languages other than english, and perform more refinement on dependency type labels and linguistic resources']",4
"['to time  #TAUTHOR_TAG, the']","['to time  #TAUTHOR_TAG, the']","['to time  #TAUTHOR_TAG, the shift in descriptor use may also', ""stem from non - temporal factors as well, such as an author '""]","['while this shift appears to be due to time  #TAUTHOR_TAG, the shift in descriptor use may also', ""stem from non - temporal factors as well, such as an author's expectations of their audience ( audience design ) and additional information such as links to external news articles, included in the same sentence with the location ( a micro - level aspect of"", ""the discussion ). jointly modeling such macro - level factors, like post volume, and micro - level factors, from authors and information expectations, and their influence on a writer's use of descriptor context can"", 'help reveal a more comprehensive picture of the dynamics in collective attention. concretely, this work examines the public discussion of five recent devast', '##ating natural disasters on facebook and twitter. we investigate how people refer to locations of hurricanes with or without descriptor phrases in their discussion and how such descriptor context use changes in response to factors related to', 'audience, writer attributes', '']",1
"['to increased attention  #TAUTHOR_TAG.', 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing']","['to increased attention  #TAUTHOR_TAG.', 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing']","['to increased attention  #TAUTHOR_TAG.', 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing']","['work is also subject to several limitations.', 'first, the analysis of what factors influence the use of descriptive context are mainly correlational without casual validations.', 'our formulation of descriptor phrases is not exhaustive and may have missed other syntactic constructions that indicate that an entity is considered new information ( i. e. false negatives ).', 'a speaker may use a preceding descriptor phrase, instead of a subordinate descriptor phrase, to indicate that the entity is not shared knowledge ( e. g. "" a city called san juan "" ).', 'in addition, we focused on only a set of specific crisis events due to their representative usages of location mentions and large volume of online discussions.', 'future work can build upon our work and generalize it to other different types of crisis events.', ""in addition, we are unable to rule out the possibility that another event attracted attention to the locations under discussion before the crises began ( e. g. a political news story relevant to the event's region ) lastly, the study focuses exclusively on location names because of their geographic relevance to events, but other types of named entities ( people, organizations ) are also likely to undergo changes in descriptor use in response to increased attention  #TAUTHOR_TAG."", 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing how people discuss breaking news events.', 'by examining five recent hurricane events, our research demonstrated how referring expressions are shaped by author and audience expectations of collective attention over time and across communities']",1
"['to time  #TAUTHOR_TAG, the']","['to time  #TAUTHOR_TAG, the']","['to time  #TAUTHOR_TAG, the shift in descriptor use may also', ""stem from non - temporal factors as well, such as an author '""]","['while this shift appears to be due to time  #TAUTHOR_TAG, the shift in descriptor use may also', ""stem from non - temporal factors as well, such as an author's expectations of their audience ( audience design ) and additional information such as links to external news articles, included in the same sentence with the location ( a micro - level aspect of"", ""the discussion ). jointly modeling such macro - level factors, like post volume, and micro - level factors, from authors and information expectations, and their influence on a writer's use of descriptor context can"", 'help reveal a more comprehensive picture of the dynamics in collective attention. concretely, this work examines the public discussion of five recent devast', '##ating natural disasters on facebook and twitter. we investigate how people refer to locations of hurricanes with or without descriptor phrases in their discussion and how such descriptor context use changes in response to factors related to', 'audience, writer attributes', '']",0
"['to time  #TAUTHOR_TAG, the']","['to time  #TAUTHOR_TAG, the']","['to time  #TAUTHOR_TAG, the shift in descriptor use may also', ""stem from non - temporal factors as well, such as an author '""]","['while this shift appears to be due to time  #TAUTHOR_TAG, the shift in descriptor use may also', ""stem from non - temporal factors as well, such as an author's expectations of their audience ( audience design ) and additional information such as links to external news articles, included in the same sentence with the location ( a micro - level aspect of"", ""the discussion ). jointly modeling such macro - level factors, like post volume, and micro - level factors, from authors and information expectations, and their influence on a writer's use of descriptor context can"", 'help reveal a more comprehensive picture of the dynamics in collective attention. concretely, this work examines the public discussion of five recent devast', '##ating natural disasters on facebook and twitter. we investigate how people refer to locations of hurricanes with or without descriptor phrases in their discussion and how such descriptor context use changes in response to factors related to', 'audience, writer attributes', '']",0
"['to time  #TAUTHOR_TAG, the']","['to time  #TAUTHOR_TAG, the']","['to time  #TAUTHOR_TAG, the shift in descriptor use may also', ""stem from non - temporal factors as well, such as an author '""]","['while this shift appears to be due to time  #TAUTHOR_TAG, the shift in descriptor use may also', ""stem from non - temporal factors as well, such as an author's expectations of their audience ( audience design ) and additional information such as links to external news articles, included in the same sentence with the location ( a micro - level aspect of"", ""the discussion ). jointly modeling such macro - level factors, like post volume, and micro - level factors, from authors and information expectations, and their influence on a writer's use of descriptor context can"", 'help reveal a more comprehensive picture of the dynamics in collective attention. concretely, this work examines the public discussion of five recent devast', '##ating natural disasters on facebook and twitter. we investigate how people refer to locations of hurricanes with or without descriptor phrases in their discussion and how such descriptor context use changes in response to factors related to', 'audience, writer attributes', '']",0
"['to time  #TAUTHOR_TAG, the']","['to time  #TAUTHOR_TAG, the']","['to time  #TAUTHOR_TAG, the shift in descriptor use may also', ""stem from non - temporal factors as well, such as an author '""]","['while this shift appears to be due to time  #TAUTHOR_TAG, the shift in descriptor use may also', ""stem from non - temporal factors as well, such as an author's expectations of their audience ( audience design ) and additional information such as links to external news articles, included in the same sentence with the location ( a micro - level aspect of"", ""the discussion ). jointly modeling such macro - level factors, like post volume, and micro - level factors, from authors and information expectations, and their influence on a writer's use of descriptor context can"", 'help reveal a more comprehensive picture of the dynamics in collective attention. concretely, this work examines the public discussion of five recent devast', '##ating natural disasters on facebook and twitter. we investigate how people refer to locations of hurricanes with or without descriptor phrases in their discussion and how such descriptor context use changes in response to factors related to', 'audience, writer attributes', '']",0
"['natural disasters  #TAUTHOR_TAG, and political controversy ( gar']","['natural disasters  #TAUTHOR_TAG, and political controversy ( garimella et al. 2017 ).', 'with the wealth']","['natural disasters  #TAUTHOR_TAG, and political controversy ( gar']","['term collective attention refers to the attention that a public group of people pays to a particular event or topic ( sasahara et al. 2013 ), often as a result of a shared interest among the people.', 'collective attention is an important component in the spread of information ( wu and huberman 2007 ), and it can shift either vary rapidly or gradually in response to particular events such as sports games ( lehmann et al. 2012 ), natural disasters  #TAUTHOR_TAG, and political controversy ( garimella et al. 2017 ).', 'with the wealth of digital data available to researchers today, studies have often quantified collective attention using the volume of posting and sharing activity in social media sites such as reddit and twitter ( leavitt and clark 2014 ; mitra, wright, and gilbert 2016 ).', 'while these kinds of activity metrics provide an aggregate summary of attention dynamics, they largely obscure the nuanced content of collective attention such as how people refer to such particular events via language and how such referring language evolves over time.', '']",0
"['natural disasters  #TAUTHOR_TAG, and political controversy ( gar']","['natural disasters  #TAUTHOR_TAG, and political controversy ( garimella et al. 2017 ).', 'with the wealth']","['natural disasters  #TAUTHOR_TAG, and political controversy ( gar']","['term collective attention refers to the attention that a public group of people pays to a particular event or topic ( sasahara et al. 2013 ), often as a result of a shared interest among the people.', 'collective attention is an important component in the spread of information ( wu and huberman 2007 ), and it can shift either vary rapidly or gradually in response to particular events such as sports games ( lehmann et al. 2012 ), natural disasters  #TAUTHOR_TAG, and political controversy ( garimella et al. 2017 ).', 'with the wealth of digital data available to researchers today, studies have often quantified collective attention using the volume of posting and sharing activity in social media sites such as reddit and twitter ( leavitt and clark 2014 ; mitra, wright, and gilbert 2016 ).', 'while these kinds of activity metrics provide an aggregate summary of attention dynamics, they largely obscure the nuanced content of collective attention such as how people refer to such particular events via language and how such referring language evolves over time.', '']",0
"['online participation and large uncertainty among event observers towards the situation during the crisis events  #TAUTHOR_TAG.', 'we chose to study the collective attention changes in public discourse']","['online participation and large uncertainty among event observers towards the situation during the crisis events  #TAUTHOR_TAG.', 'we chose to study the collective attention changes in public discourse']","['online participation and large uncertainty among event observers towards the situation during the crisis events  #TAUTHOR_TAG.', 'we chose to study the collective attention changes in public discourse']","['events such as hurricanes present a useful case study for the development of collective attention, due to the large volume of online participation and large uncertainty among event observers towards the situation during the crisis events  #TAUTHOR_TAG.', ""we chose to study the collective attention changes in public discourse related to hurricanes, due to hurricanes'lasting economic impact, their broad coverage in the news, and their relevance to specific geographic regions."", 'we collected social media data related to five recent devastating hurricanes, and we describe the data collection ( § 3. 1 ), location detection ( § 3. 2 ), and descriptor detection ( § 3. 3 ) for the following datasets :', '1. twitter data : 2 million public tweets related to 5 major hurricanes, collected in 2017 and 2018.', '2. facebook data : around 30, 000 posts from 60 public groups related to disaster relief in hurricane maria, collected in 2017']",0
"['is expected to become shared', 'knowledge  #TAUTHOR_TAG.  #AUTHOR_TAG,']","['is expected to become shared', 'knowledge  #TAUTHOR_TAG.  #AUTHOR_TAG,']","['at which an entity is expected to become shared', 'knowledge  #TAUTHOR_TAG.  #AUTHOR_TAG, we defined the time of']",[' #TAUTHOR_TAG'],0
"['to increased attention  #TAUTHOR_TAG.', 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing']","['to increased attention  #TAUTHOR_TAG.', 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing']","['to increased attention  #TAUTHOR_TAG.', 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing']","['work is also subject to several limitations.', 'first, the analysis of what factors influence the use of descriptive context are mainly correlational without casual validations.', 'our formulation of descriptor phrases is not exhaustive and may have missed other syntactic constructions that indicate that an entity is considered new information ( i. e. false negatives ).', 'a speaker may use a preceding descriptor phrase, instead of a subordinate descriptor phrase, to indicate that the entity is not shared knowledge ( e. g. "" a city called san juan "" ).', 'in addition, we focused on only a set of specific crisis events due to their representative usages of location mentions and large volume of online discussions.', 'future work can build upon our work and generalize it to other different types of crisis events.', ""in addition, we are unable to rule out the possibility that another event attracted attention to the locations under discussion before the crises began ( e. g. a political news story relevant to the event's region ) lastly, the study focuses exclusively on location names because of their geographic relevance to events, but other types of named entities ( people, organizations ) are also likely to undergo changes in descriptor use in response to increased attention  #TAUTHOR_TAG."", 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing how people discuss breaking news events.', 'by examining five recent hurricane events, our research demonstrated how referring expressions are shaped by author and audience expectations of collective attention over time and across communities']",0
"['acyclic graph connecting words and phrases.', 'following  #TAUTHOR_TAG,']","['acyclic graph connecting words and phrases.', 'following  #TAUTHOR_TAG,']","['be shared knowledge.', 'to extract sentence structure from text, we used dependency parsing, which decomposes a sentence into a directed acyclic graph connecting words and phrases.', 'following  #TAUTHOR_TAG, we used a small set of dependencies']",[' #TAUTHOR_TAG'],5
"['is expected to become shared', 'knowledge  #TAUTHOR_TAG.  #AUTHOR_TAG,']","['is expected to become shared', 'knowledge  #TAUTHOR_TAG.  #AUTHOR_TAG,']","['at which an entity is expected to become shared', 'knowledge  #TAUTHOR_TAG.  #AUTHOR_TAG, we defined the time of']",[' #TAUTHOR_TAG'],5
"['is expected to become shared', 'knowledge  #TAUTHOR_TAG.  #AUTHOR_TAG,']","['is expected to become shared', 'knowledge  #TAUTHOR_TAG.  #AUTHOR_TAG,']","['at which an entity is expected to become shared', 'knowledge  #TAUTHOR_TAG.  #AUTHOR_TAG, we defined the time of']",[' #TAUTHOR_TAG'],3
"['to increased attention  #TAUTHOR_TAG.', 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing']","['to increased attention  #TAUTHOR_TAG.', 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing']","['to increased attention  #TAUTHOR_TAG.', 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing']","['work is also subject to several limitations.', 'first, the analysis of what factors influence the use of descriptive context are mainly correlational without casual validations.', 'our formulation of descriptor phrases is not exhaustive and may have missed other syntactic constructions that indicate that an entity is considered new information ( i. e. false negatives ).', 'a speaker may use a preceding descriptor phrase, instead of a subordinate descriptor phrase, to indicate that the entity is not shared knowledge ( e. g. "" a city called san juan "" ).', 'in addition, we focused on only a set of specific crisis events due to their representative usages of location mentions and large volume of online discussions.', 'future work can build upon our work and generalize it to other different types of crisis events.', ""in addition, we are unable to rule out the possibility that another event attracted attention to the locations under discussion before the crises began ( e. g. a political news story relevant to the event's region ) lastly, the study focuses exclusively on location names because of their geographic relevance to events, but other types of named entities ( people, organizations ) are also likely to undergo changes in descriptor use in response to increased attention  #TAUTHOR_TAG."", 'to conclude, this study adds a new content - based perspective to the measurement of collective attention, by analyzing how people discuss breaking news events.', 'by examining five recent hurricane events, our research demonstrated how referring expressions are shaped by author and audience expectations of collective attention over time and across communities']",2
"[') task  #TAUTHOR_TAG.', 'however, current']","['task  #TAUTHOR_TAG.', 'however, current']","[') task  #TAUTHOR_TAG.', 'however,']",[' #TAUTHOR_TAG'],0
"['##tz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most']","['fritz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most']","['##tz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most']","['number of datasets on visual question answering have been introduced in recent years ( malinowski and fritz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most attention and helped popularize the task.', 'however, these datasets mostly consist of a small set of answers covering most of the questions, and most of the answers being single word.', 'our fsvqa dataset, derived from  #TAUTHOR_TAG, minimizes such limitation by converting the answers to full - sentences, thus widely expanding the set of answers.', '( fukui et al. 2016 ) proposed multimodal compact bilinear pooling ( mcb ) to combine multimodal features of visual and text representations.', '']",0
"['##tz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most']","['fritz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most']","['##tz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most']","['number of datasets on visual question answering have been introduced in recent years ( malinowski and fritz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most attention and helped popularize the task.', 'however, these datasets mostly consist of a small set of answers covering most of the questions, and most of the answers being single word.', 'our fsvqa dataset, derived from  #TAUTHOR_TAG, minimizes such limitation by converting the answers to full - sentences, thus widely expanding the set of answers.', '( fukui et al. 2016 ) proposed multimodal compact bilinear pooling ( mcb ) to combine multimodal features of visual and text representations.', '']",1
"['##tz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most']","['fritz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most']","['##tz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most']","['number of datasets on visual question answering have been introduced in recent years ( malinowski and fritz 2014 ; ren, kiros, and zemel 2015 ), among which  #TAUTHOR_TAG in particular has gained the most attention and helped popularize the task.', 'however, these datasets mostly consist of a small set of answers covering most of the questions, and most of the answers being single word.', 'our fsvqa dataset, derived from  #TAUTHOR_TAG, minimizes such limitation by converting the answers to full - sentences, thus widely expanding the set of answers.', '( fukui et al. 2016 ) proposed multimodal compact bilinear pooling ( mcb ) to combine multimodal features of visual and text representations.', '']",6
[' #TAUTHOR_TAG to'],[' #TAUTHOR_TAG to full - sentence answers'],"['full - sentence annotations from crowd - sourcing tools can be highly costly.', 'we circumvent this financial cost by converting the answers in the original vqa dataset  #TAUTHOR_TAG to']","['full - sentence annotations from crowd - sourcing tools can be highly costly.', 'we circumvent this financial cost by converting the answers in the original vqa dataset  #TAUTHOR_TAG to full - sentence answers by applying a number of linguistic rules using natural language processing techniques.', 'furthermore, we also provide an augmented version of dataset by converting the human - written captions provided in the ms coco ( lin et al. 2014 ).', 'we generated questions with a set of rules, for which the caption itself becomes the answer.', 'both versions of fsvqa dataset along with the features used in our experiment, as will be described in the experiment section, are publicly available for download.', 'note that, for both versions, only train and validation splits are provided, since test splits are not publicly available.', 'also, we only provide open - ended version, and do not provide multiple choice version']",6
"['', 'following  #TAUTHOR_TAG, we examined the effect of conversely, we also examined an']","['', 'following  #TAUTHOR_TAG, we examined the effect of conversely, we also examined an']","['', 'following  #TAUTHOR_TAG, we examined the effect of conversely, we also examined an approach where only image features are concerned']","['', 'following  #TAUTHOR_TAG, we examined the effect of conversely, we also examined an approach where only image features are concerned.', 'this requires a slightly different training procedure, as it does not involve a series of onehot vector inputs.', 'we followed the conventional approach used in image captioning task ( vinyals et al. 2015 ), where the image features are fixed, and a stack of lstm units learns to generate the ground truth captions.', 'each lstm unit generates one word at a time, which in turn enters the next lstm unit.', 'the only difference in our case is that the ground truth captions are replaced by full - sentence answers']",5
['is consistent with the results reported in  #TAUTHOR_TAG'],['is consistent with the results reported in  #TAUTHOR_TAG'],"['the problem to a semantic q & a task, which can be handled one at a time.', 'this tendency is consistent with the results reported in  #TAUTHOR_TAG.', 'it must nevertheless be reminded that the best performances in both  #TAUTHOR_TAG and our experiment were achieved with the presence of both visual and textual clues']","['', 'as expected, answers generated from using both question and image features turn out to be most reliable.', 'answers from question features alone result in answers that match the questions but are frequently out of visual context given by the image.', 'likewise, answers generated from image features alone fit the images but are frequently out of textual context given by the question.', 'it is notable that using image features alone performs very poorly, whereas using question features alone results in performances comparable to using both features.', 'one plausible explanation is that, since using image features alone always generates the same answer for the same image regardless of the question, it can only get 1 out of k questions correctly at best, where k is the number of questions per image.', 'on the contrary, using question features alone essentially reduces the problem to a semantic q & a task, which can be handled one at a time.', 'this tendency is consistent with the results reported in  #TAUTHOR_TAG.', 'it must nevertheless be reminded that the best performances in both  #TAUTHOR_TAG and our experiment were achieved with the presence of both visual and textual clues']",3
['is consistent with the results reported in  #TAUTHOR_TAG'],['is consistent with the results reported in  #TAUTHOR_TAG'],"['the problem to a semantic q & a task, which can be handled one at a time.', 'this tendency is consistent with the results reported in  #TAUTHOR_TAG.', 'it must nevertheless be reminded that the best performances in both  #TAUTHOR_TAG and our experiment were achieved with the presence of both visual and textual clues']","['', 'as expected, answers generated from using both question and image features turn out to be most reliable.', 'answers from question features alone result in answers that match the questions but are frequently out of visual context given by the image.', 'likewise, answers generated from image features alone fit the images but are frequently out of textual context given by the question.', 'it is notable that using image features alone performs very poorly, whereas using question features alone results in performances comparable to using both features.', 'one plausible explanation is that, since using image features alone always generates the same answer for the same image regardless of the question, it can only get 1 out of k questions correctly at best, where k is the number of questions per image.', 'on the contrary, using question features alone essentially reduces the problem to a semantic q & a task, which can be handled one at a time.', 'this tendency is consistent with the results reported in  #TAUTHOR_TAG.', 'it must nevertheless be reminded that the best performances in both  #TAUTHOR_TAG and our experiment were achieved with the presence of both visual and textual clues']",3
"['of  #TAUTHOR_TAG, and presented by  #AUTHOR_TAG.', 'next, we introduce our multi - task learning approach of sharing the parameters between abstractive summar']","['of  #TAUTHOR_TAG, and presented by  #AUTHOR_TAG.', 'next, we introduce our multi - task learning approach of sharing the parameters between abstractive summarization and']","['##decoder model of  #TAUTHOR_TAG, and presented by  #AUTHOR_TAG.', 'next, we introduce our multi - task learning approach of sharing the parameters between abstractive summarization and']","[', we discuss our baseline model which is similar to the machine translation encoder - alignerdecoder model of  #TAUTHOR_TAG, and presented by  #AUTHOR_TAG.', 'next, we introduce our multi - task learning approach of sharing the parameters between abstractive summarization and entailment generation models']",3
"['model with bilinear attention, similar to  #TAUTHOR_TAG and following the details in  #AUTHOR_TAG']","['model with bilinear attention, similar to  #TAUTHOR_TAG and following the details in  #AUTHOR_TAG']","['with bilinear attention, similar to  #TAUTHOR_TAG and following the details in  #AUTHOR_TAG.', 'here, we encode']","['baseline model is a strong, multi - layered encoder - attention - decoder model with bilinear attention, similar to  #TAUTHOR_TAG and following the details in  #AUTHOR_TAG.', '']",3
['. 06  #AUTHOR_TAG our  #TAUTHOR_TAG baseline model'],[' #AUTHOR_TAG 28. 97 8. 26 24. 06  #AUTHOR_TAG our  #TAUTHOR_TAG baseline model'],[' #AUTHOR_TAG 28. 97 8. 26 24. 06  #AUTHOR_TAG our  #TAUTHOR_TAG baseline model achieves competitive performance with'],"[', we directly use the gigaword - trained model to test on the duc - 2004 dataset ( see tuning discussion in sec. 4. 1 ).', 'in table 2, we again see that et al. ( 2015 ) 28. 18 8. 49 23. 81  #AUTHOR_TAG 28. 97 8. 26 24. 06  #AUTHOR_TAG our  #TAUTHOR_TAG baseline model achieves competitive performance with previous work, esp.', 'on rouge - 2 and rouge - l. next, we show promising multi - task improvements over this baseline of around 0. 4 % across all metrics, despite being a test - only setting and also with the mismatch between the summarization and entailment domains.', 'figure 3 shows some additional interesting output examples of our multi - task model and how it generates summaries that are better at being logically entailed by the input document, whereas the baseline model contains some crucial contradictory or unrelated information']",3
"['model with bilinear attention, similar to  #TAUTHOR_TAG and following the details in  #AUTHOR_TAG']","['model with bilinear attention, similar to  #TAUTHOR_TAG and following the details in  #AUTHOR_TAG']","['with bilinear attention, similar to  #TAUTHOR_TAG and following the details in  #AUTHOR_TAG.', 'here, we encode']","['baseline model is a strong, multi - layered encoder - attention - decoder model with bilinear attention, similar to  #TAUTHOR_TAG and following the details in  #AUTHOR_TAG.', '']",5
"['attention - decoder model based on  #TAUTHOR_TAG and presented by  #AUTHOR_TAG.', 'as shown in']","['strong encoder - attention - decoder model based on  #TAUTHOR_TAG and presented by  #AUTHOR_TAG.', 'as shown in']","['our baseline is a strong encoder - attention - decoder model based on  #TAUTHOR_TAG and presented by  #AUTHOR_TAG.', 'as shown in']","['results and previous work our baseline is a strong encoder - attention - decoder model based on  #TAUTHOR_TAG and presented by  #AUTHOR_TAG.', 'as shown in table 1, it is reasonably close to some of the state - of - theart ( comparable ) results in previous work, though making this baseline further strong ( e. g., based on pointer - copy mechanism ) is our next step']",5
"['tasks across domains  #TAUTHOR_TAG.', 'in this work, we show improvements on the']","['tasks across domains  #TAUTHOR_TAG.', 'in this work, we show improvements on the']","['- task learning helps in sharing knowledge between related tasks across domains  #TAUTHOR_TAG.', 'in this work, we show improvements on the task']","['- task learning helps in sharing knowledge between related tasks across domains  #TAUTHOR_TAG.', '']",0
"['tasks across domains  #TAUTHOR_TAG.', 'in this work, we show improvements on the']","['tasks across domains  #TAUTHOR_TAG.', 'in this work, we show improvements on the']","['- task learning helps in sharing knowledge between related tasks across domains  #TAUTHOR_TAG.', 'in this work, we show improvements on the task']","['- task learning helps in sharing knowledge between related tasks across domains  #TAUTHOR_TAG.', '']",4
"['representations.', ' #TAUTHOR_TAG propose to transfer style']","['representations.', ' #TAUTHOR_TAG propose to transfer style']","['augment the encoded representations.', ' #TAUTHOR_TAG propose to transfer style']","['the following two comments about a movie : ( 1 ) i entered the theater in the bloom of youth and emerged with a family of field mice living in my long, white mustache ; 1 and ( 2 ) the movie was very long.', 'although the meaning of the two sentences is similar, their styles are very different.', ""style transfer is the task of transferring the attributes of a sentence ( e. g.,'sarcastic'and'not - sarcastic') without changing its content."", 'it is important for dialog systems such as personalized agents, customer service agents and smart home assistants to generate responses that are fluent and fit the social setting.', 'advances in text generation has motivated recent work on style transfer with non - parallel corpora  #AUTHOR_TAG.', ' #AUTHOR_TAG propose a novel method which leverages the refined alignment of latent representations to perform style transfer.', 'the paper introduces cross - aligned autoencoder with discriminators.', ' #AUTHOR_TAG 1 from https : / / www. thestranger. com / movies / 1210980 / sex - and - the - city - 2 learn a disentangled latent representation and use a code to generate a sentence.', ' #AUTHOR_TAG explore two models for style transfer which use multiple decoders or style embeddings to augment the encoded representations.', ' #TAUTHOR_TAG propose to transfer style through backtranslation.', 'the latter method is simpler to train and it attains the state - of - the - art performance in style transfer accuracy, confirming the efficacy of back - translation in grounding meaning.', 'the goal of the current study is to investigate alternative back - translation setups that attain a better balance between meaning preservation and style transfer.', 'we introduce two approaches which extend the back - translation models proposed by  #TAUTHOR_TAG exploring back - translation setups that preserve the content of the sentence better.', 'the first approach explores multilingual pivoting, hypothesizing that transfer through several languages will help ground meaning better than transfer through one language.', ""we follow johnson et al.'s ( 2017 ) setup."", 'the second approach is an investigation to include a term in the loss function which corresponds to preserving semantic content of the sentence : we add a feedback loss to the generative models.', 'we evaluate our models along three dimensions : style transfer accuracy, fluency and preservation of meaning.', 'we compare the results with the cross - aligned auto - encoder  #AUTHOR_TAG and the back - translation model with one pivot language  #TAUTHOR_TAG.', 'we find that both extensions improve the accuracy of style transfer without reduction in preservation of meaning']",0
[' #TAUTHOR_TAG focuses on creating'],[' #TAUTHOR_TAG focuses on creating'],"['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving']","['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving meaning in the generated sentences is still an unsolved question.', 'in this work, we try to tackle this question by extending their model in two directions :', '( 1 ) to improve the latent representation such that it grounds the meaning better and ( 2 ) providing the generative models with a feedback which represents how good the generator performs in preserving the meaning.', 'both the extensions are marked in figure 1.', 'notation.', 'given a dataset x in which each instance is labeled with a style s 1 or s 2, the goal of style transfer is to generate sentences of the target style without changing the meaning of the original sentence.', 'let the set of sentences in x which belong to s 1 be x 1 = { x', '1 } and the sentences which belong to s 2 be x 2 = { x', 'we denote the sentences of x 1 transferred to style s 2 asx 12 = { x ( 1 ) 12,..., x ( n ) 12 } and the sentences of x 2 transferred to style s 1 by', 'style transfer through back - translation.', ' #TAUTHOR_TAG introduces the technique of back - translation to perform style transfer.', '']",0
[' #TAUTHOR_TAG focuses on creating'],[' #TAUTHOR_TAG focuses on creating'],"['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving']","['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving meaning in the generated sentences is still an unsolved question.', 'in this work, we try to tackle this question by extending their model in two directions :', '( 1 ) to improve the latent representation such that it grounds the meaning better and ( 2 ) providing the generative models with a feedback which represents how good the generator performs in preserving the meaning.', 'both the extensions are marked in figure 1.', 'notation.', 'given a dataset x in which each instance is labeled with a style s 1 or s 2, the goal of style transfer is to generate sentences of the target style without changing the meaning of the original sentence.', 'let the set of sentences in x which belong to s 1 be x 1 = { x', '1 } and the sentences which belong to s 2 be x 2 = { x', 'we denote the sentences of x 1 transferred to style s 2 asx 12 = { x ( 1 ) 12,..., x ( n ) 12 } and the sentences of x 2 transferred to style s 1 by', 'style transfer through back - translation.', ' #TAUTHOR_TAG introduces the technique of back - translation to perform style transfer.', '']",0
[' #TAUTHOR_TAG focuses on creating'],[' #TAUTHOR_TAG focuses on creating'],"['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving']","['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving meaning in the generated sentences is still an unsolved question.', 'in this work, we try to tackle this question by extending their model in two directions :', '( 1 ) to improve the latent representation such that it grounds the meaning better and ( 2 ) providing the generative models with a feedback which represents how good the generator performs in preserving the meaning.', 'both the extensions are marked in figure 1.', 'notation.', 'given a dataset x in which each instance is labeled with a style s 1 or s 2, the goal of style transfer is to generate sentences of the target style without changing the meaning of the original sentence.', 'let the set of sentences in x which belong to s 1 be x 1 = { x', '1 } and the sentences which belong to s 2 be x 2 = { x', 'we denote the sentences of x 1 transferred to style s 2 asx 12 = { x ( 1 ) 12,..., x ( n ) 12 } and the sentences of x 2 transferred to style s 1 by', 'style transfer through back - translation.', ' #TAUTHOR_TAG introduces the technique of back - translation to perform style transfer.', '']",0
[' #TAUTHOR_TAG focuses on creating'],[' #TAUTHOR_TAG focuses on creating'],"['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving']","['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving meaning in the generated sentences is still an unsolved question.', 'in this work, we try to tackle this question by extending their model in two directions :', '( 1 ) to improve the latent representation such that it grounds the meaning better and ( 2 ) providing the generative models with a feedback which represents how good the generator performs in preserving the meaning.', 'both the extensions are marked in figure 1.', 'notation.', 'given a dataset x in which each instance is labeled with a style s 1 or s 2, the goal of style transfer is to generate sentences of the target style without changing the meaning of the original sentence.', 'let the set of sentences in x which belong to s 1 be x 1 = { x', '1 } and the sentences which belong to s 2 be x 2 = { x', 'we denote the sentences of x 1 transferred to style s 2 asx 12 = { x ( 1 ) 12,..., x ( n ) 12 } and the sentences of x 2 transferred to style s 1 by', 'style transfer through back - translation.', ' #TAUTHOR_TAG introduces the technique of back - translation to perform style transfer.', '']",0
"['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82 % for the gender - annotated corpus, 92 % accuracy for the political slant dataset and 93. 23 % accuracy for the sentiment dataset.', 'we use these classifiers to test the generated sentences for the desired style.', 'perplexity.', 'to measure the fluency of the generative models automatically, we use perplexity measure.', 'we create separate language models for each of the three tasks using only the training data.', 'we use only ngrams up to an order of 3 to create the language model 2.', 'meaning preservation.', 'we follow the procedure described in  #AUTHOR_TAG to perform a / b testing.', 'we reuse the instructions provided by  #TAUTHOR_TAG, we perform our evaluation on amazon mechanical turk.', 'we annotate 200 samples per task and ask 3 unique workers to annotate each sample.', 'we take the majority vote as the final label.', 'the results in  #TAUTHOR_TAG model.', 'as reported by  #TAUTHOR_TAG model performs better in preservation of meaning for the tasks of gender and political slant transfer.', 'we present the results for the comparison between  #TAUTHOR_TAG and mbst models ; and the mbst and the mbst + f models.', 'fluency.', 'we asked human annotators on mechanical turk to measure the fluency of the generated sentences on a scale of 1 to 4. 1 is unreadable and 4 is perfectly readable.', 'we annotate 120 samples for each model and each sample is annotated by three unique workers.', 'the 120 samples of each model has an equal distribution of samples from the three tasks']",0
"['representations.', ' #TAUTHOR_TAG propose to transfer style']","['representations.', ' #TAUTHOR_TAG propose to transfer style']","['augment the encoded representations.', ' #TAUTHOR_TAG propose to transfer style']","['the following two comments about a movie : ( 1 ) i entered the theater in the bloom of youth and emerged with a family of field mice living in my long, white mustache ; 1 and ( 2 ) the movie was very long.', 'although the meaning of the two sentences is similar, their styles are very different.', ""style transfer is the task of transferring the attributes of a sentence ( e. g.,'sarcastic'and'not - sarcastic') without changing its content."", 'it is important for dialog systems such as personalized agents, customer service agents and smart home assistants to generate responses that are fluent and fit the social setting.', 'advances in text generation has motivated recent work on style transfer with non - parallel corpora  #AUTHOR_TAG.', ' #AUTHOR_TAG propose a novel method which leverages the refined alignment of latent representations to perform style transfer.', 'the paper introduces cross - aligned autoencoder with discriminators.', ' #AUTHOR_TAG 1 from https : / / www. thestranger. com / movies / 1210980 / sex - and - the - city - 2 learn a disentangled latent representation and use a code to generate a sentence.', ' #AUTHOR_TAG explore two models for style transfer which use multiple decoders or style embeddings to augment the encoded representations.', ' #TAUTHOR_TAG propose to transfer style through backtranslation.', 'the latter method is simpler to train and it attains the state - of - the - art performance in style transfer accuracy, confirming the efficacy of back - translation in grounding meaning.', 'the goal of the current study is to investigate alternative back - translation setups that attain a better balance between meaning preservation and style transfer.', 'we introduce two approaches which extend the back - translation models proposed by  #TAUTHOR_TAG exploring back - translation setups that preserve the content of the sentence better.', 'the first approach explores multilingual pivoting, hypothesizing that transfer through several languages will help ground meaning better than transfer through one language.', ""we follow johnson et al.'s ( 2017 ) setup."", 'the second approach is an investigation to include a term in the loss function which corresponds to preserving semantic content of the sentence : we add a feedback loss to the generative models.', 'we evaluate our models along three dimensions : style transfer accuracy, fluency and preservation of meaning.', 'we compare the results with the cross - aligned auto - encoder  #AUTHOR_TAG and the back - translation model with one pivot language  #TAUTHOR_TAG.', 'we find that both extensions improve the accuracy of style transfer without reduction in preservation of meaning']",6
"['representations.', ' #TAUTHOR_TAG propose to transfer style']","['representations.', ' #TAUTHOR_TAG propose to transfer style']","['augment the encoded representations.', ' #TAUTHOR_TAG propose to transfer style']","['the following two comments about a movie : ( 1 ) i entered the theater in the bloom of youth and emerged with a family of field mice living in my long, white mustache ; 1 and ( 2 ) the movie was very long.', 'although the meaning of the two sentences is similar, their styles are very different.', ""style transfer is the task of transferring the attributes of a sentence ( e. g.,'sarcastic'and'not - sarcastic') without changing its content."", 'it is important for dialog systems such as personalized agents, customer service agents and smart home assistants to generate responses that are fluent and fit the social setting.', 'advances in text generation has motivated recent work on style transfer with non - parallel corpora  #AUTHOR_TAG.', ' #AUTHOR_TAG propose a novel method which leverages the refined alignment of latent representations to perform style transfer.', 'the paper introduces cross - aligned autoencoder with discriminators.', ' #AUTHOR_TAG 1 from https : / / www. thestranger. com / movies / 1210980 / sex - and - the - city - 2 learn a disentangled latent representation and use a code to generate a sentence.', ' #AUTHOR_TAG explore two models for style transfer which use multiple decoders or style embeddings to augment the encoded representations.', ' #TAUTHOR_TAG propose to transfer style through backtranslation.', 'the latter method is simpler to train and it attains the state - of - the - art performance in style transfer accuracy, confirming the efficacy of back - translation in grounding meaning.', 'the goal of the current study is to investigate alternative back - translation setups that attain a better balance between meaning preservation and style transfer.', 'we introduce two approaches which extend the back - translation models proposed by  #TAUTHOR_TAG exploring back - translation setups that preserve the content of the sentence better.', 'the first approach explores multilingual pivoting, hypothesizing that transfer through several languages will help ground meaning better than transfer through one language.', ""we follow johnson et al.'s ( 2017 ) setup."", 'the second approach is an investigation to include a term in the loss function which corresponds to preserving semantic content of the sentence : we add a feedback loss to the generative models.', 'we evaluate our models along three dimensions : style transfer accuracy, fluency and preservation of meaning.', 'we compare the results with the cross - aligned auto - encoder  #AUTHOR_TAG and the back - translation model with one pivot language  #TAUTHOR_TAG.', 'we find that both extensions improve the accuracy of style transfer without reduction in preservation of meaning']",7
['- translation model using only one pivot language and with no feedback loss  #TAUTHOR_TAG model )'],"['the gender and political slant tasks.', 'we also compare our results with the back - translation model using only one pivot language and with no feedback loss  #TAUTHOR_TAG model )']","['the gender and political slant tasks.', 'we also compare our results with the back - translation model using only one pivot language and with no feedback loss  #TAUTHOR_TAG model )']","['baseline model is a cross - aligned autoencoder ( cae ) from  #AUTHOR_TAG.', 'we use the off - the - shelf trained model for sentiment modification task and we separately train this model for the gender and political slant tasks.', 'we also compare our results with the back - translation model using only one pivot language and with no feedback loss  #TAUTHOR_TAG model )']",7
"['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82 % for the gender - annotated corpus, 92 % accuracy for the political slant dataset and 93. 23 % accuracy for the sentiment dataset.', 'we use these classifiers to test the generated sentences for the desired style.', 'perplexity.', 'to measure the fluency of the generative models automatically, we use perplexity measure.', 'we create separate language models for each of the three tasks using only the training data.', 'we use only ngrams up to an order of 3 to create the language model 2.', 'meaning preservation.', 'we follow the procedure described in  #AUTHOR_TAG to perform a / b testing.', 'we reuse the instructions provided by  #TAUTHOR_TAG, we perform our evaluation on amazon mechanical turk.', 'we annotate 200 samples per task and ask 3 unique workers to annotate each sample.', 'we take the majority vote as the final label.', 'the results in  #TAUTHOR_TAG model.', 'as reported by  #TAUTHOR_TAG model performs better in preservation of meaning for the tasks of gender and political slant transfer.', 'we present the results for the comparison between  #TAUTHOR_TAG and mbst models ; and the mbst and the mbst + f models.', 'fluency.', 'we asked human annotators on mechanical turk to measure the fluency of the generated sentences on a scale of 1 to 4. 1 is unreadable and 4 is perfectly readable.', 'we annotate 120 samples for each model and each sample is annotated by three unique workers.', 'the 120 samples of each model has an equal distribution of samples from the three tasks']",7
"['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82 % for the gender - annotated corpus, 92 % accuracy for the political slant dataset and 93. 23 % accuracy for the sentiment dataset.', 'we use these classifiers to test the generated sentences for the desired style.', 'perplexity.', 'to measure the fluency of the generative models automatically, we use perplexity measure.', 'we create separate language models for each of the three tasks using only the training data.', 'we use only ngrams up to an order of 3 to create the language model 2.', 'meaning preservation.', 'we follow the procedure described in  #AUTHOR_TAG to perform a / b testing.', 'we reuse the instructions provided by  #TAUTHOR_TAG, we perform our evaluation on amazon mechanical turk.', 'we annotate 200 samples per task and ask 3 unique workers to annotate each sample.', 'we take the majority vote as the final label.', 'the results in  #TAUTHOR_TAG model.', 'as reported by  #TAUTHOR_TAG model performs better in preservation of meaning for the tasks of gender and political slant transfer.', 'we present the results for the comparison between  #TAUTHOR_TAG and mbst models ; and the mbst and the mbst + f models.', 'fluency.', 'we asked human annotators on mechanical turk to measure the fluency of the generated sentences on a scale of 1 to 4. 1 is unreadable and 4 is perfectly readable.', 'we annotate 120 samples for each model and each sample is annotated by three unique workers.', 'the 120 samples of each model has an equal distribution of samples from the three tasks']",7
[' #TAUTHOR_TAG focuses on creating'],[' #TAUTHOR_TAG focuses on creating'],"['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving']","['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving meaning in the generated sentences is still an unsolved question.', 'in this work, we try to tackle this question by extending their model in two directions :', '( 1 ) to improve the latent representation such that it grounds the meaning better and ( 2 ) providing the generative models with a feedback which represents how good the generator performs in preserving the meaning.', 'both the extensions are marked in figure 1.', 'notation.', 'given a dataset x in which each instance is labeled with a style s 1 or s 2, the goal of style transfer is to generate sentences of the target style without changing the meaning of the original sentence.', 'let the set of sentences in x which belong to s 1 be x 1 = { x', '1 } and the sentences which belong to s 2 be x 2 = { x', 'we denote the sentences of x 1 transferred to style s 2 asx 12 = { x ( 1 ) 12,..., x ( n ) 12 } and the sentences of x 2 transferred to style s 1 by', 'style transfer through back - translation.', ' #TAUTHOR_TAG introduces the technique of back - translation to perform style transfer.', '']",1
[' #TAUTHOR_TAG focuses on creating'],[' #TAUTHOR_TAG focuses on creating'],"['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving']","['the previous work  #TAUTHOR_TAG focuses on creating a representation by translating to a pivot language, preserving meaning in the generated sentences is still an unsolved question.', 'in this work, we try to tackle this question by extending their model in two directions :', '( 1 ) to improve the latent representation such that it grounds the meaning better and ( 2 ) providing the generative models with a feedback which represents how good the generator performs in preserving the meaning.', 'both the extensions are marked in figure 1.', 'notation.', 'given a dataset x in which each instance is labeled with a style s 1 or s 2, the goal of style transfer is to generate sentences of the target style without changing the meaning of the original sentence.', 'let the set of sentences in x which belong to s 1 be x 1 = { x', '1 } and the sentences which belong to s 2 be x 2 = { x', 'we denote the sentences of x 1 transferred to style s 2 asx 12 = { x ( 1 ) 12,..., x ( n ) 12 } and the sentences of x 2 transferred to style s 1 by', 'style transfer through back - translation.', ' #TAUTHOR_TAG introduces the technique of back - translation to perform style transfer.', '']",5
"['use three tasks described in  #TAUTHOR_TAG to evaluate our models.', 'the three tasks correspond to : ( 1 ) gender transfer : we transfer the style of writing reviews of yelp from male and female authors  #AUTHOR_TAG.', '']","['use three tasks described in  #TAUTHOR_TAG to evaluate our models.', 'the three tasks correspond to : ( 1 ) gender transfer : we transfer the style of writing reviews of yelp from male and female authors  #AUTHOR_TAG.', '']","['use three tasks described in  #TAUTHOR_TAG to evaluate our models.', 'the three tasks correspond to : ( 1 ) gender transfer : we transfer the style of writing reviews of yelp from male and female authors  #AUTHOR_TAG.', '']","['use three tasks described in  #TAUTHOR_TAG to evaluate our models.', 'the three tasks correspond to : ( 1 ) gender transfer : we transfer the style of writing reviews of yelp from male and female authors  #AUTHOR_TAG.', '( 2 ) political slant transfer : we transfer the style of addressing comments to the two political parties namely democratic and republican  #AUTHOR_TAG and ( 3 ) sentiment modification : here we focus on only two sentiments - positive and negative.', 'the goal is to modify the sentiment of the sentence while preserving the content']",5
"['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82 % for the gender - annotated corpus, 92 % accuracy for the political slant dataset and 93. 23 % accuracy for the sentiment dataset.', 'we use these classifiers to test the generated sentences for the desired style.', 'perplexity.', 'to measure the fluency of the generative models automatically, we use perplexity measure.', 'we create separate language models for each of the three tasks using only the training data.', 'we use only ngrams up to an order of 3 to create the language model 2.', 'meaning preservation.', 'we follow the procedure described in  #AUTHOR_TAG to perform a / b testing.', 'we reuse the instructions provided by  #TAUTHOR_TAG, we perform our evaluation on amazon mechanical turk.', 'we annotate 200 samples per task and ask 3 unique workers to annotate each sample.', 'we take the majority vote as the final label.', 'the results in  #TAUTHOR_TAG model.', 'as reported by  #TAUTHOR_TAG model performs better in preservation of meaning for the tasks of gender and political slant transfer.', 'we present the results for the comparison between  #TAUTHOR_TAG and mbst models ; and the mbst and the mbst + f models.', 'fluency.', 'we asked human annotators on mechanical turk to measure the fluency of the generated sentences on a scale of 1 to 4. 1 is unreadable and 4 is perfectly readable.', 'we annotate 120 samples for each model and each sample is annotated by three unique workers.', 'the 120 samples of each model has an equal distribution of samples from the three tasks']",5
"['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82 % for the gender - annotated corpus, 92 % accuracy for the political slant dataset and 93. 23 % accuracy for the sentiment dataset.', 'we use these classifiers to test the generated sentences for the desired style.', 'perplexity.', 'to measure the fluency of the generative models automatically, we use perplexity measure.', 'we create separate language models for each of the three tasks using only the training data.', 'we use only ngrams up to an order of 3 to create the language model 2.', 'meaning preservation.', 'we follow the procedure described in  #AUTHOR_TAG to perform a / b testing.', 'we reuse the instructions provided by  #TAUTHOR_TAG, we perform our evaluation on amazon mechanical turk.', 'we annotate 200 samples per task and ask 3 unique workers to annotate each sample.', 'we take the majority vote as the final label.', 'the results in  #TAUTHOR_TAG model.', 'as reported by  #TAUTHOR_TAG model performs better in preservation of meaning for the tasks of gender and political slant transfer.', 'we present the results for the comparison between  #TAUTHOR_TAG and mbst models ; and the mbst and the mbst + f models.', 'fluency.', 'we asked human annotators on mechanical turk to measure the fluency of the generated sentences on a scale of 1 to 4. 1 is unreadable and 4 is perfectly readable.', 'we annotate 120 samples for each model and each sample is annotated by three unique workers.', 'the 120 samples of each model has an equal distribution of samples from the three tasks']",5
"['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82']","['transfer accuracy.', 'we measure the accuracy of style transfer as described in  #AUTHOR_TAG.', 'we have reproduced the classifiers described in  #TAUTHOR_TAG.', 'the classifier has an accuracy of 82 % for the gender - annotated corpus, 92 % accuracy for the political slant dataset and 93. 23 % accuracy for the sentiment dataset.', 'we use these classifiers to test the generated sentences for the desired style.', 'perplexity.', 'to measure the fluency of the generative models automatically, we use perplexity measure.', 'we create separate language models for each of the three tasks using only the training data.', 'we use only ngrams up to an order of 3 to create the language model 2.', 'meaning preservation.', 'we follow the procedure described in  #AUTHOR_TAG to perform a / b testing.', 'we reuse the instructions provided by  #TAUTHOR_TAG, we perform our evaluation on amazon mechanical turk.', 'we annotate 200 samples per task and ask 3 unique workers to annotate each sample.', 'we take the majority vote as the final label.', 'the results in  #TAUTHOR_TAG model.', 'as reported by  #TAUTHOR_TAG model performs better in preservation of meaning for the tasks of gender and political slant transfer.', 'we present the results for the comparison between  #TAUTHOR_TAG and mbst models ; and the mbst and the mbst + f models.', 'fluency.', 'we asked human annotators on mechanical turk to measure the fluency of the generated sentences on a scale of 1 to 4. 1 is unreadable and 4 is perfectly readable.', 'we annotate 120 samples for each model and each sample is annotated by three unique workers.', 'the 120 samples of each model has an equal distribution of samples from the three tasks']",4
['. 79 for  #TAUTHOR_TAG'],"['- political slant.', 'the over - all averaged scores for the two models mbst and mbst + f is the same 3. 08, whereas it is much lower 2. 79 for  #TAUTHOR_TAG']",['. 79 for  #TAUTHOR_TAG'],"['', 'table 2 shows the perplexity of the generative models for each of the three tasks.', 'we observe that both mbst and mbst + f models are better than the nmt and cae models but there is no significant difference between the two models.', 'table 3 shows the results for human evaluation of the models mbst and mbst + f for preservation of meaning.', 'perhaps confusingly, these results show no clear preference between the models.', 'this is a positive result as it means that these extensions do not degrade the meaning, in spite of them improving the style transfer accuracy.', 'although we observe that mbst may be slightly preferred over mbst + f. table 3 : human preference for meaning preservation % the four models for the three tasks.', 'we averaged the scores over the 120 samples and 3 annotators per sample.', 'mbst + f performs better than the other models in 2 out of 3 tasks and mbst performs the best in one task - political slant.', 'the over - all averaged scores for the two models mbst and mbst + f is the same 3. 08, whereas it is much lower 2. 79 for  #TAUTHOR_TAG and 2. 57 for cae.', 'table 4 : fluency in generated sentences']",4
['as sequence prediction  #TAUTHOR_TAG'],"[""as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer's attentions follow""]","['as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer']","['', 'previous decoded tokens. 3 ) decoder - encoder attention considers both encoded and decoded sequences, generating a sequence with the', ""same length as the decoded sequence. it should be noted that some applications has only the decoder self - attention such as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer's attentions follow the same general mechanism. at the high level, the attention can be seen as a weighted combination of"", 'the input sequence, where the weights are determined by the similarities between elements of the input sequence. we note that this operation is orderagnostic to the permutation in the input se - quence ( order is encoded with', ""extra positional embedding  #TAUTHOR_TAG. the above observation inspires us to connect transformer's attention to kernel learning  #AUTHOR_TAG : they both concurrently"", 'and order - agnostically process all inputs by calculating the similarity between the inputs. therefore, in', ""the paper, we present a new formulation for transformer's attention via the lens"", 'of kernel. to be more precise, the new formulation can be interpreted as a kernel smoother  #AUTHOR_TAG over the inputs in a sequence, where the kernel measures how similar two different', 'inputs are. the main advantage of connecting attention to kernel is that it opens up a new family of attention mechanisms that can relate to the well -', 'established literature in kernel learning  #AUTHOR_TAG. as a result, we develop a new variant of attention which simply considers a product of symmetric kernels when modeling non - positional and positional embedding. furthermore,', ""our proposed formulation highlights naturally the main components of transformer's attention, enabling a better understanding of this mechanism :"", 'recent variants of transformers  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ) can be expressed through these individual components. among all the components, we argue that the most important one is the construction of', ""the kernel function. we empirically study multiple kernel forms and the ways to integrate positional embedding in neural machine translation ( nmt ) using iwslt'14 germanenglish"", '( de - en ) dataset  #AUTHOR_TAG and sequence prediction ( sp ) using wikitext - 103 dataset  #AUTHOR_TAG']",0
['as sequence prediction  #TAUTHOR_TAG'],"[""as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer's attentions follow""]","['as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer']","['', 'previous decoded tokens. 3 ) decoder - encoder attention considers both encoded and decoded sequences, generating a sequence with the', ""same length as the decoded sequence. it should be noted that some applications has only the decoder self - attention such as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer's attentions follow the same general mechanism. at the high level, the attention can be seen as a weighted combination of"", 'the input sequence, where the weights are determined by the similarities between elements of the input sequence. we note that this operation is orderagnostic to the permutation in the input se - quence ( order is encoded with', ""extra positional embedding  #TAUTHOR_TAG. the above observation inspires us to connect transformer's attention to kernel learning  #AUTHOR_TAG : they both concurrently"", 'and order - agnostically process all inputs by calculating the similarity between the inputs. therefore, in', ""the paper, we present a new formulation for transformer's attention via the lens"", 'of kernel. to be more precise, the new formulation can be interpreted as a kernel smoother  #AUTHOR_TAG over the inputs in a sequence, where the kernel measures how similar two different', 'inputs are. the main advantage of connecting attention to kernel is that it opens up a new family of attention mechanisms that can relate to the well -', 'established literature in kernel learning  #AUTHOR_TAG. as a result, we develop a new variant of attention which simply considers a product of symmetric kernels when modeling non - positional and positional embedding. furthermore,', ""our proposed formulation highlights naturally the main components of transformer's attention, enabling a better understanding of this mechanism :"", 'recent variants of transformers  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ) can be expressed through these individual components. among all the components, we argue that the most important one is the construction of', ""the kernel function. we empirically study multiple kernel forms and the ways to integrate positional embedding in neural machine translation ( nmt ) using iwslt'14 germanenglish"", '( de - en ) dataset  #AUTHOR_TAG and sequence prediction ( sp ) using wikitext - 103 dataset  #AUTHOR_TAG']",0
['as sequence prediction  #TAUTHOR_TAG'],"[""as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer's attentions follow""]","['as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer']","['', 'previous decoded tokens. 3 ) decoder - encoder attention considers both encoded and decoded sequences, generating a sequence with the', ""same length as the decoded sequence. it should be noted that some applications has only the decoder self - attention such as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer's attentions follow the same general mechanism. at the high level, the attention can be seen as a weighted combination of"", 'the input sequence, where the weights are determined by the similarities between elements of the input sequence. we note that this operation is orderagnostic to the permutation in the input se - quence ( order is encoded with', ""extra positional embedding  #TAUTHOR_TAG. the above observation inspires us to connect transformer's attention to kernel learning  #AUTHOR_TAG : they both concurrently"", 'and order - agnostically process all inputs by calculating the similarity between the inputs. therefore, in', ""the paper, we present a new formulation for transformer's attention via the lens"", 'of kernel. to be more precise, the new formulation can be interpreted as a kernel smoother  #AUTHOR_TAG over the inputs in a sequence, where the kernel measures how similar two different', 'inputs are. the main advantage of connecting attention to kernel is that it opens up a new family of attention mechanisms that can relate to the well -', 'established literature in kernel learning  #AUTHOR_TAG. as a result, we develop a new variant of attention which simply considers a product of symmetric kernels when modeling non - positional and positional embedding. furthermore,', ""our proposed formulation highlights naturally the main components of transformer's attention, enabling a better understanding of this mechanism :"", 'recent variants of transformers  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ) can be expressed through these individual components. among all the components, we argue that the most important one is the construction of', ""the kernel function. we empirically study multiple kernel forms and the ways to integrate positional embedding in neural machine translation ( nmt ) using iwslt'14 germanenglish"", '( de - en ) dataset  #AUTHOR_TAG and sequence prediction ( sp ) using wikitext - 103 dataset  #AUTHOR_TAG']",0
['during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint'],['during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint'],[' #AUTHOR_TAG b ) ). t i can be a mixture of sine and cosine functions  #AUTHOR_TAG or parameters that can be learned during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint'],"['crucial for sequence modeling  #AUTHOR_TAG. as a result, transformer  #AUTHOR_TAG introduced positional embedding to indicate the positional relation for the inputs. formally, a sequence x = [ x 1, x 2, [UNK], x t ] defines each element as', 'x i = ( f i, t i ) with f i ∈ f being the nontemporal feature at', 'time i and t i ∈ t as an temporal feature ( or we called it positional embedding ). note that f i can be', 'the word representation ( in neural machine translation  #AUTHOR_TAG ), a pixel in a frame ( in', 'video activity recognition  #AUTHOR_TAG ), or a music unit ( in music generation  #AUTHOR_TAG b ) ). t i can be a mixture of sine and cosine functions  #AUTHOR_TAG or parameters that can be learned during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint space x [UNK] = ( f × t ). the resulting', 'permutationinvariant set is : followed the definition by  #AUTHOR_TAG, we use queries ( q ) / keys ( k ) / values ( v ) to represent the inputs for the attention. to be more precise, x { q', '']",0
"['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on']","['embedding k ( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on f ( the non - positional feature space ) and then discuss how different variants integrate the positional embedding ( with the positional feature space t ) into the kernel.', 'kernel construction on f. all the work considered the scaled asymmetric exponential kernel with the mapping w q and w k  #AUTHOR_TAG for non - positional features f q and f k :', 'note that the usage of asymmetric kernel is also commonly used in various machine learning tasks  #AUTHOR_TAG, where they observed the kernel form can be flexible and even non - valid ( i. e., a kernel that is not symmetric and positive semi - definite ).', 'in section 3, we show that symmetric design of the kernel has similar performance for various sequence learning tasks, and we also examine different kernel choices ( i. e., linear, polynomial, and rbf kernel ).', 'kernel construction on x = ( f × t ).', 'the designs for integrating the positional embedding t q and t k are listed in the following.', '( i ) absolute positional embedding  #TAUTHOR_TAG : for the original transformer  #AUTHOR_TAG, each t i is represented by a vector with each dimension being sine or cosine functions.', 'for learned positional embedding  #TAUTHOR_TAG, each t i is a learned parameter and is fixed for the same position for different sequences.', 'these works defines the feature space as the direct sum of its temporal and non - temporal space : x = f ⊕ t.', 'via the lens of kernel, the kernel similarity is defined as', '( ii ) relative positional embedding in transformer - xl  #TAUTHOR_TAG : t represents the indicator of the position in the sequence, and the kernel is chosen to be asymmetric of mixing sine and cosine functions :', 'with k fq t q, t k being an asymmetric kernel with coefficients inferred by f q : log k fq t q, t k = ∑ ( iii ) relative positional embedding of  #AUTHOR_TAG and music transformer  #AUTHOR_TAG b ) : t ⋅ represents the indicator of the position in the sequence, and the kernel is modified to be indexed by a look - up table :', 'where l tq−t k, fq = exp ( f q w q a tq−t k ) with a ⋅ being a learnable matrix having matrix width to be the length of the sequence.', 'we refer readers to  #AUTHOR_TAG for more details.', ' #AUTHOR_TAG showed that the way to integrate positional embedding is better through eq. ( 5 ) than through eq.']",0
"['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on']","['embedding k ( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on f ( the non - positional feature space ) and then discuss how different variants integrate the positional embedding ( with the positional feature space t ) into the kernel.', 'kernel construction on f. all the work considered the scaled asymmetric exponential kernel with the mapping w q and w k  #AUTHOR_TAG for non - positional features f q and f k :', 'note that the usage of asymmetric kernel is also commonly used in various machine learning tasks  #AUTHOR_TAG, where they observed the kernel form can be flexible and even non - valid ( i. e., a kernel that is not symmetric and positive semi - definite ).', 'in section 3, we show that symmetric design of the kernel has similar performance for various sequence learning tasks, and we also examine different kernel choices ( i. e., linear, polynomial, and rbf kernel ).', 'kernel construction on x = ( f × t ).', 'the designs for integrating the positional embedding t q and t k are listed in the following.', '( i ) absolute positional embedding  #TAUTHOR_TAG : for the original transformer  #AUTHOR_TAG, each t i is represented by a vector with each dimension being sine or cosine functions.', 'for learned positional embedding  #TAUTHOR_TAG, each t i is a learned parameter and is fixed for the same position for different sequences.', 'these works defines the feature space as the direct sum of its temporal and non - temporal space : x = f ⊕ t.', 'via the lens of kernel, the kernel similarity is defined as', '( ii ) relative positional embedding in transformer - xl  #TAUTHOR_TAG : t represents the indicator of the position in the sequence, and the kernel is chosen to be asymmetric of mixing sine and cosine functions :', 'with k fq t q, t k being an asymmetric kernel with coefficients inferred by f q : log k fq t q, t k = ∑ ( iii ) relative positional embedding of  #AUTHOR_TAG and music transformer  #AUTHOR_TAG b ) : t ⋅ represents the indicator of the position in the sequence, and the kernel is modified to be indexed by a look - up table :', 'where l tq−t k, fq = exp ( f q w q a tq−t k ) with a ⋅ being a learnable matrix having matrix width to be the length of the sequence.', 'we refer readers to  #AUTHOR_TAG for more details.', ' #AUTHOR_TAG showed that the way to integrate positional embedding is better through eq. ( 5 ) than through eq.']",0
"['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on']","['embedding k ( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on f ( the non - positional feature space ) and then discuss how different variants integrate the positional embedding ( with the positional feature space t ) into the kernel.', 'kernel construction on f. all the work considered the scaled asymmetric exponential kernel with the mapping w q and w k  #AUTHOR_TAG for non - positional features f q and f k :', 'note that the usage of asymmetric kernel is also commonly used in various machine learning tasks  #AUTHOR_TAG, where they observed the kernel form can be flexible and even non - valid ( i. e., a kernel that is not symmetric and positive semi - definite ).', 'in section 3, we show that symmetric design of the kernel has similar performance for various sequence learning tasks, and we also examine different kernel choices ( i. e., linear, polynomial, and rbf kernel ).', 'kernel construction on x = ( f × t ).', 'the designs for integrating the positional embedding t q and t k are listed in the following.', '( i ) absolute positional embedding  #TAUTHOR_TAG : for the original transformer  #AUTHOR_TAG, each t i is represented by a vector with each dimension being sine or cosine functions.', 'for learned positional embedding  #TAUTHOR_TAG, each t i is a learned parameter and is fixed for the same position for different sequences.', 'these works defines the feature space as the direct sum of its temporal and non - temporal space : x = f ⊕ t.', 'via the lens of kernel, the kernel similarity is defined as', '( ii ) relative positional embedding in transformer - xl  #TAUTHOR_TAG : t represents the indicator of the position in the sequence, and the kernel is chosen to be asymmetric of mixing sine and cosine functions :', 'with k fq t q, t k being an asymmetric kernel with coefficients inferred by f q : log k fq t q, t k = ∑ ( iii ) relative positional embedding of  #AUTHOR_TAG and music transformer  #AUTHOR_TAG b ) : t ⋅ represents the indicator of the position in the sequence, and the kernel is modified to be indexed by a look - up table :', 'where l tq−t k, fq = exp ( f q w q a tq−t k ) with a ⋅ being a learnable matrix having matrix width to be the length of the sequence.', 'we refer readers to  #AUTHOR_TAG for more details.', ' #AUTHOR_TAG showed that the way to integrate positional embedding is better through eq. ( 5 ) than through eq.']",0
['xl  #TAUTHOR_TAG :'],['xl  #TAUTHOR_TAG :'],['- xl  #TAUTHOR_TAG :'],"['( x q, s x k ) = s x k contains the keys being all the tokens in the encoded sequence. note that encoder self - attention considers x q = x k', 'with x q being the encoded sequence. ( ii ) encoder - decoder attention in original transformer  #AUTHOR_TAG : for each query x q in decoded sequence, m ( x q, s x k ) = s x k contains the keys being all the tokens in the encoded sequence. note that encode - decoder attention considers x q', '= x k with x q being the decoded sequence and x k being the encoded sequence. ( iii', ') decoder self - attention in original transformer  #AUTHOR_TAG : for each query x q in the decoded sequence, m ( x q, s x k ) returns a subset of s x k ( m ( x q, s x k )', '⊂ s x k ). note that decoder self - attention considers x q = x k with x q being the decoded sequence. since', 'the decoded sequence is the output for previous timestep, the query at position i can only observe the keys being the tokens that are decoded with position < i. for convenience, let us define s 1 as the set returned by original transformer  #AUTHOR_TAG from m ( x q,', 's x k ), which we will use it later. ( iv ) decoder self - attention in', 'transformer - xl  #TAUTHOR_TAG : for each query x q in the decoded sequence, m ( x q, s x k ) returns a set containing s 1 and additional memories ( m ( x q, s x k ) = s 1 + s mem, m ( x q, s x k ) [UNK] s 1 ). s mem refers', 'to additional memories. ( v ) decoder self - attention in sparse transformer  #AUTHOR_TAG : for each query x q in the decoded sentence, m ( x q, s x k ) returns a subset of s 1 ( m ( x q, s x k ) ⊂ s 1 ). to compare the differences for various designs, we see the computation time is inversely proportional', 'to the number of elements in m', '( x q, s x k ). for performance - wise comparisons, transformer - xl  #TAUTHOR_TAG showed that, the additional memories in m ( x q, s x k ) are able to capture longer - term dependency than the original transformer  #AUTHOR_TAG and hence results in', 'better performance. sparse transformer  #AUTHOR_TAG showed that although having much fewer elements in m ( x q, s x k ), if the elements are carefully chosen, the', 'attention can still reach the same performance as transformer - xl  #TAUTHOR_TAG']",0
"['sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nm']","['', 'we conduct experiments on neural machine translation ( nmt ) and sequence prediction ( sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nmt has three different types of attentions ( e. g., encoder']","['sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nm']","['', 'is positional embedding required in value function?', 'we conduct experiments on neural machine translation ( nmt ) and sequence prediction ( sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nmt has three different types of attentions ( e. g., encoder selfattention, decoder - encoder attention, decoder selfattention ) and sp has only one type of attention ( e. g., decoder self - attention ).', ""for the choice of datasets, we pick iwslt'14 german - english ( de - en ) dataset  #AUTHOR_TAG for nmt and wikitext - 103 dataset  #AUTHOR_TAG for sp as suggested by edunov et al.  #AUTHOR_TAG and  #TAUTHOR_TAG."", 'for fairness of comparisons, we train five random initializations and report test accuracy with the highest validation score.', 'we fix the position - wise operations in transformer 3 and only change the attention mechanism.', 'similar to prior work  #TAUTHOR_TAG, we report bleu score for nmt and perplexity for sp']",0
"[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder']","[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder self - attention, the operation is not order - agnostic.', 'for clarification,']","['is an order - agnostic ( or, permutation equivariant ) operation  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder']","['need of the positional embedding ( pe ) in the attention mechanism is based on the argument that the attention mechanism is an order - agnostic ( or, permutation equivariant ) operation  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder self - attention, the operation is not order - agnostic.', 'for clarification, we are not attacking the claim made by the prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG, but we aim at providing a new look at the order - invariance problem when considering the attention mechanism with masks ( masks refer to the set filtering function in our kernel formulation ).', 'in other words, previous work did not consider the mask between queries and keys when discussing the order - invariance problem ( perez et al., 2019 ).', 'to put it formally, we first present the definition by for a permutation equivariance function :', 'definition 2.', 'denote π as the set of all permutations over [ n ] = { 1, [UNK], n }. a function f unc [UNK] x n → y n is permutation equivariant iff for any permutation π ∈ π, f unc ( πx ) = πf unc ( x ). showed that the standard attention ( encoder self - attention  #TAUTHOR_TAG is permutation equivariant.', 'here, we present the non - permutation - equivariant problem on the decoder self - attention :  #TAUTHOR_TAG is not permutation equivariant.', 'to proceed the proof, we need the following definition and propositions']",0
['as sequence prediction  #TAUTHOR_TAG'],"[""as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer's attentions follow""]","['as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer']","['', 'previous decoded tokens. 3 ) decoder - encoder attention considers both encoded and decoded sequences, generating a sequence with the', ""same length as the decoded sequence. it should be noted that some applications has only the decoder self - attention such as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer's attentions follow the same general mechanism. at the high level, the attention can be seen as a weighted combination of"", 'the input sequence, where the weights are determined by the similarities between elements of the input sequence. we note that this operation is orderagnostic to the permutation in the input se - quence ( order is encoded with', ""extra positional embedding  #TAUTHOR_TAG. the above observation inspires us to connect transformer's attention to kernel learning  #AUTHOR_TAG : they both concurrently"", 'and order - agnostically process all inputs by calculating the similarity between the inputs. therefore, in', ""the paper, we present a new formulation for transformer's attention via the lens"", 'of kernel. to be more precise, the new formulation can be interpreted as a kernel smoother  #AUTHOR_TAG over the inputs in a sequence, where the kernel measures how similar two different', 'inputs are. the main advantage of connecting attention to kernel is that it opens up a new family of attention mechanisms that can relate to the well -', 'established literature in kernel learning  #AUTHOR_TAG. as a result, we develop a new variant of attention which simply considers a product of symmetric kernels when modeling non - positional and positional embedding. furthermore,', ""our proposed formulation highlights naturally the main components of transformer's attention, enabling a better understanding of this mechanism :"", 'recent variants of transformers  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ) can be expressed through these individual components. among all the components, we argue that the most important one is the construction of', ""the kernel function. we empirically study multiple kernel forms and the ways to integrate positional embedding in neural machine translation ( nmt ) using iwslt'14 germanenglish"", '( de - en ) dataset  #AUTHOR_TAG and sequence prediction ( sp ) using wikitext - 103 dataset  #AUTHOR_TAG']",1
['as sequence prediction  #TAUTHOR_TAG'],"[""as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer's attentions follow""]","['as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer']","['', 'previous decoded tokens. 3 ) decoder - encoder attention considers both encoded and decoded sequences, generating a sequence with the', ""same length as the decoded sequence. it should be noted that some applications has only the decoder self - attention such as sequence prediction  #TAUTHOR_TAG. in all cases, the transformer's attentions follow the same general mechanism. at the high level, the attention can be seen as a weighted combination of"", 'the input sequence, where the weights are determined by the similarities between elements of the input sequence. we note that this operation is orderagnostic to the permutation in the input se - quence ( order is encoded with', ""extra positional embedding  #TAUTHOR_TAG. the above observation inspires us to connect transformer's attention to kernel learning  #AUTHOR_TAG : they both concurrently"", 'and order - agnostically process all inputs by calculating the similarity between the inputs. therefore, in', ""the paper, we present a new formulation for transformer's attention via the lens"", 'of kernel. to be more precise, the new formulation can be interpreted as a kernel smoother  #AUTHOR_TAG over the inputs in a sequence, where the kernel measures how similar two different', 'inputs are. the main advantage of connecting attention to kernel is that it opens up a new family of attention mechanisms that can relate to the well -', 'established literature in kernel learning  #AUTHOR_TAG. as a result, we develop a new variant of attention which simply considers a product of symmetric kernels when modeling non - positional and positional embedding. furthermore,', ""our proposed formulation highlights naturally the main components of transformer's attention, enabling a better understanding of this mechanism :"", 'recent variants of transformers  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ) can be expressed through these individual components. among all the components, we argue that the most important one is the construction of', ""the kernel function. we empirically study multiple kernel forms and the ways to integrate positional embedding in neural machine translation ( nmt ) using iwslt'14 germanenglish"", '( de - en ) dataset  #AUTHOR_TAG and sequence prediction ( sp ) using wikitext - 103 dataset  #AUTHOR_TAG']",5
"['previous attention variants  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'last, we present a new form of attention,']","['categorize previous attention variants  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'last, we present a new form of attention,']","['previous attention variants  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'last, we present a new form of attention,']","['section aims at providing an understanding of attention in transformer via the lens of kernel.', 'the inspiration for connecting the kernel  #AUTHOR_TAG and attention instantiates from the observation : both operations concurrently processes all inputs and calculate the similarity between the inputs.', 'we first introduce the background ( i. e., the original formulation ) of attention and then provide a new reformulation within the class of kernel smoothers  #AUTHOR_TAG.', 'next, we show that this new formulation allows us to explore new family of attention while at the same time offering a framework to categorize previous attention variants  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'last, we present a new form of attention, which requires fewer parameters and empirically reaches competitive performance as the state - of - the - art models.', 'for notation, we use lowercase representing a vector ( e. g., x ), bold lowercase representing a matrix ( e. g., x ), calligraphy letter denoting a space ( e. g., x ), and s denoting a set.', 'to relate the notations in sequence to sequence learning  #AUTHOR_TAG, x represents a specific element of a sequence, x = [ x 1, x 2, [UNK], x t ] denotes a sequence of features, s x = { x exp, x 2, [UNK], x t } represents the set with its elements being the features in sequence x, and we refer the space of set s x as s']",5
['during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint'],['during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint'],[' #AUTHOR_TAG b ) ). t i can be a mixture of sine and cosine functions  #AUTHOR_TAG or parameters that can be learned during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint'],"['crucial for sequence modeling  #AUTHOR_TAG. as a result, transformer  #AUTHOR_TAG introduced positional embedding to indicate the positional relation for the inputs. formally, a sequence x = [ x 1, x 2, [UNK], x t ] defines each element as', 'x i = ( f i, t i ) with f i ∈ f being the nontemporal feature at', 'time i and t i ∈ t as an temporal feature ( or we called it positional embedding ). note that f i can be', 'the word representation ( in neural machine translation  #AUTHOR_TAG ), a pixel in a frame ( in', 'video activity recognition  #AUTHOR_TAG ), or a music unit ( in music generation  #AUTHOR_TAG b ) ). t i can be a mixture of sine and cosine functions  #AUTHOR_TAG or parameters that can be learned during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint space x [UNK] = ( f × t ). the resulting', 'permutationinvariant set is : followed the definition by  #AUTHOR_TAG, we use queries ( q ) / keys ( k ) / values ( v ) to represent the inputs for the attention. to be more precise, x { q', '']",5
['during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint'],['during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint'],[' #AUTHOR_TAG b ) ). t i can be a mixture of sine and cosine functions  #AUTHOR_TAG or parameters that can be learned during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint'],"['crucial for sequence modeling  #AUTHOR_TAG. as a result, transformer  #AUTHOR_TAG introduced positional embedding to indicate the positional relation for the inputs. formally, a sequence x = [ x 1, x 2, [UNK], x t ] defines each element as', 'x i = ( f i, t i ) with f i ∈ f being the nontemporal feature at', 'time i and t i ∈ t as an temporal feature ( or we called it positional embedding ). note that f i can be', 'the word representation ( in neural machine translation  #AUTHOR_TAG ), a pixel in a frame ( in', 'video activity recognition  #AUTHOR_TAG ), or a music unit ( in music generation  #AUTHOR_TAG b ) ). t i can be a mixture of sine and cosine functions  #AUTHOR_TAG or parameters that can be learned during back - propagation  #TAUTHOR_TAG. the feature vector are defined over a joint space x [UNK] = ( f × t ). the resulting', 'permutationinvariant set is : followed the definition by  #AUTHOR_TAG, we use queries ( q ) / keys ( k ) / values ( v ) to represent the inputs for the attention. to be more precise, x { q', '']",5
"['different variants of attention in prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'in the following, we study these components by dissecting']","['at the same time it is able to categorize different variants of attention in prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'in the following, we study these components by dissecting eq. ( 2 ) into : 1 ) kernel feature']","['different variants of attention in prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'in the following, we study these components by dissecting eq. ( 2 ) into : 1 ) kernel feature space x']","['', 'is a probability function depends on k and n when k ( ⋅, ⋅ ) is always positive.', 'in the prior work  #AUTHOR_TAG', 'note that the kernel form k ( x q, x k ) in the original transformer  #AUTHOR_TAG is a asymmetric exponential kernel with additional mapping w q and w k  #AUTHOR_TAG 2.', 'the new formulation defines a larger space for composing attention by manipulating its individual components, and at the same time it is able to categorize different variants of attention in prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'in the following, we study these components by dissecting eq. ( 2 ) into : 1 ) kernel feature space x, 2 ) kernel construction k ( ⋅, ⋅ ), 3 ) value function v ( ⋅ ), and 4 ) set filtering function m ( ⋅, ⋅ ).', '2. 2. 1 kernel feature space x in eq. ( 2 ), to construct a kernel on x, the first thing is to identify the kernel feature space x.', 'in addition to modeling sequences like word sentences  #AUTHOR_TAG or music signals  #AUTHOR_TAG b ), the transformer can also be applied to images  #AUTHOR_TAG, sets, and multimodal sequences  #AUTHOR_TAG a ).', 'due to distinct data types, these applications admit various kernel feature space :  #TAUTHOR_TAG :', 'with f being non - positional feature space and t being the positional embedding space of the position in']",5
"['different variants of attention in prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'in the following, we study these components by dissecting']","['at the same time it is able to categorize different variants of attention in prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'in the following, we study these components by dissecting eq. ( 2 ) into : 1 ) kernel feature']","['different variants of attention in prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'in the following, we study these components by dissecting eq. ( 2 ) into : 1 ) kernel feature space x']","['', 'is a probability function depends on k and n when k ( ⋅, ⋅ ) is always positive.', 'in the prior work  #AUTHOR_TAG', 'note that the kernel form k ( x q, x k ) in the original transformer  #AUTHOR_TAG is a asymmetric exponential kernel with additional mapping w q and w k  #AUTHOR_TAG 2.', 'the new formulation defines a larger space for composing attention by manipulating its individual components, and at the same time it is able to categorize different variants of attention in prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ).', 'in the following, we study these components by dissecting eq. ( 2 ) into : 1 ) kernel feature space x, 2 ) kernel construction k ( ⋅, ⋅ ), 3 ) value function v ( ⋅ ), and 4 ) set filtering function m ( ⋅, ⋅ ).', '2. 2. 1 kernel feature space x in eq. ( 2 ), to construct a kernel on x, the first thing is to identify the kernel feature space x.', 'in addition to modeling sequences like word sentences  #AUTHOR_TAG or music signals  #AUTHOR_TAG b ), the transformer can also be applied to images  #AUTHOR_TAG, sets, and multimodal sequences  #AUTHOR_TAG a ).', 'due to distinct data types, these applications admit various kernel feature space :  #TAUTHOR_TAG :', 'with f being non - positional feature space and t being the positional embedding space of the position in']",5
"['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on']","['embedding k ( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on f ( the non - positional feature space ) and then discuss how different variants integrate the positional embedding ( with the positional feature space t ) into the kernel.', 'kernel construction on f. all the work considered the scaled asymmetric exponential kernel with the mapping w q and w k  #AUTHOR_TAG for non - positional features f q and f k :', 'note that the usage of asymmetric kernel is also commonly used in various machine learning tasks  #AUTHOR_TAG, where they observed the kernel form can be flexible and even non - valid ( i. e., a kernel that is not symmetric and positive semi - definite ).', 'in section 3, we show that symmetric design of the kernel has similar performance for various sequence learning tasks, and we also examine different kernel choices ( i. e., linear, polynomial, and rbf kernel ).', 'kernel construction on x = ( f × t ).', 'the designs for integrating the positional embedding t q and t k are listed in the following.', '( i ) absolute positional embedding  #TAUTHOR_TAG : for the original transformer  #AUTHOR_TAG, each t i is represented by a vector with each dimension being sine or cosine functions.', 'for learned positional embedding  #TAUTHOR_TAG, each t i is a learned parameter and is fixed for the same position for different sequences.', 'these works defines the feature space as the direct sum of its temporal and non - temporal space : x = f ⊕ t.', 'via the lens of kernel, the kernel similarity is defined as', '( ii ) relative positional embedding in transformer - xl  #TAUTHOR_TAG : t represents the indicator of the position in the sequence, and the kernel is chosen to be asymmetric of mixing sine and cosine functions :', 'with k fq t q, t k being an asymmetric kernel with coefficients inferred by f q : log k fq t q, t k = ∑ ( iii ) relative positional embedding of  #AUTHOR_TAG and music transformer  #AUTHOR_TAG b ) : t ⋅ represents the indicator of the position in the sequence, and the kernel is modified to be indexed by a look - up table :', 'where l tq−t k, fq = exp ( f q w q a tq−t k ) with a ⋅ being a learnable matrix having matrix width to be the length of the sequence.', 'we refer readers to  #AUTHOR_TAG for more details.', ' #AUTHOR_TAG showed that the way to integrate positional embedding is better through eq. ( 5 ) than through eq.']",5
"['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on']","['embedding k ( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on f ( the non - positional feature space ) and then discuss how different variants integrate the positional embedding ( with the positional feature space t ) into the kernel.', 'kernel construction on f. all the work considered the scaled asymmetric exponential kernel with the mapping w q and w k  #AUTHOR_TAG for non - positional features f q and f k :', 'note that the usage of asymmetric kernel is also commonly used in various machine learning tasks  #AUTHOR_TAG, where they observed the kernel form can be flexible and even non - valid ( i. e., a kernel that is not symmetric and positive semi - definite ).', 'in section 3, we show that symmetric design of the kernel has similar performance for various sequence learning tasks, and we also examine different kernel choices ( i. e., linear, polynomial, and rbf kernel ).', 'kernel construction on x = ( f × t ).', 'the designs for integrating the positional embedding t q and t k are listed in the following.', '( i ) absolute positional embedding  #TAUTHOR_TAG : for the original transformer  #AUTHOR_TAG, each t i is represented by a vector with each dimension being sine or cosine functions.', 'for learned positional embedding  #TAUTHOR_TAG, each t i is a learned parameter and is fixed for the same position for different sequences.', 'these works defines the feature space as the direct sum of its temporal and non - temporal space : x = f ⊕ t.', 'via the lens of kernel, the kernel similarity is defined as', '( ii ) relative positional embedding in transformer - xl  #TAUTHOR_TAG : t represents the indicator of the position in the sequence, and the kernel is chosen to be asymmetric of mixing sine and cosine functions :', 'with k fq t q, t k being an asymmetric kernel with coefficients inferred by f q : log k fq t q, t k = ∑ ( iii ) relative positional embedding of  #AUTHOR_TAG and music transformer  #AUTHOR_TAG b ) : t ⋅ represents the indicator of the position in the sequence, and the kernel is modified to be indexed by a look - up table :', 'where l tq−t k, fq = exp ( f q w q a tq−t k ) with a ⋅ being a learnable matrix having matrix width to be the length of the sequence.', 'we refer readers to  #AUTHOR_TAG for more details.', ' #AUTHOR_TAG showed that the way to integrate positional embedding is better through eq. ( 5 ) than through eq.']",5
"['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on']","['embedding k ( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on f ( the non - positional feature space ) and then discuss how different variants integrate the positional embedding ( with the positional feature space t ) into the kernel.', 'kernel construction on f. all the work considered the scaled asymmetric exponential kernel with the mapping w q and w k  #AUTHOR_TAG for non - positional features f q and f k :', 'note that the usage of asymmetric kernel is also commonly used in various machine learning tasks  #AUTHOR_TAG, where they observed the kernel form can be flexible and even non - valid ( i. e., a kernel that is not symmetric and positive semi - definite ).', 'in section 3, we show that symmetric design of the kernel has similar performance for various sequence learning tasks, and we also examine different kernel choices ( i. e., linear, polynomial, and rbf kernel ).', 'kernel construction on x = ( f × t ).', 'the designs for integrating the positional embedding t q and t k are listed in the following.', '( i ) absolute positional embedding  #TAUTHOR_TAG : for the original transformer  #AUTHOR_TAG, each t i is represented by a vector with each dimension being sine or cosine functions.', 'for learned positional embedding  #TAUTHOR_TAG, each t i is a learned parameter and is fixed for the same position for different sequences.', 'these works defines the feature space as the direct sum of its temporal and non - temporal space : x = f ⊕ t.', 'via the lens of kernel, the kernel similarity is defined as', '( ii ) relative positional embedding in transformer - xl  #TAUTHOR_TAG : t represents the indicator of the position in the sequence, and the kernel is chosen to be asymmetric of mixing sine and cosine functions :', 'with k fq t q, t k being an asymmetric kernel with coefficients inferred by f q : log k fq t q, t k = ∑ ( iii ) relative positional embedding of  #AUTHOR_TAG and music transformer  #AUTHOR_TAG b ) : t ⋅ represents the indicator of the position in the sequence, and the kernel is modified to be indexed by a look - up table :', 'where l tq−t k, fq = exp ( f q w q a tq−t k ) with a ⋅ being a learnable matrix having matrix width to be the length of the sequence.', 'we refer readers to  #AUTHOR_TAG for more details.', ' #AUTHOR_TAG showed that the way to integrate positional embedding is better through eq. ( 5 ) than through eq.']",5
"['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature']","['( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on']","['embedding k ( ⋅, ⋅ ) the kernel construction on x = ( f × t ) has distinct design in variants of transformers  #TAUTHOR_TAG b ;  #AUTHOR_TAG.', 'since now the kernel feature space considers a joint space, we will first discuss the kernel construction on f ( the non - positional feature space ) and then discuss how different variants integrate the positional embedding ( with the positional feature space t ) into the kernel.', 'kernel construction on f. all the work considered the scaled asymmetric exponential kernel with the mapping w q and w k  #AUTHOR_TAG for non - positional features f q and f k :', 'note that the usage of asymmetric kernel is also commonly used in various machine learning tasks  #AUTHOR_TAG, where they observed the kernel form can be flexible and even non - valid ( i. e., a kernel that is not symmetric and positive semi - definite ).', 'in section 3, we show that symmetric design of the kernel has similar performance for various sequence learning tasks, and we also examine different kernel choices ( i. e., linear, polynomial, and rbf kernel ).', 'kernel construction on x = ( f × t ).', 'the designs for integrating the positional embedding t q and t k are listed in the following.', '( i ) absolute positional embedding  #TAUTHOR_TAG : for the original transformer  #AUTHOR_TAG, each t i is represented by a vector with each dimension being sine or cosine functions.', 'for learned positional embedding  #TAUTHOR_TAG, each t i is a learned parameter and is fixed for the same position for different sequences.', 'these works defines the feature space as the direct sum of its temporal and non - temporal space : x = f ⊕ t.', 'via the lens of kernel, the kernel similarity is defined as', '( ii ) relative positional embedding in transformer - xl  #TAUTHOR_TAG : t represents the indicator of the position in the sequence, and the kernel is chosen to be asymmetric of mixing sine and cosine functions :', 'with k fq t q, t k being an asymmetric kernel with coefficients inferred by f q : log k fq t q, t k = ∑ ( iii ) relative positional embedding of  #AUTHOR_TAG and music transformer  #AUTHOR_TAG b ) : t ⋅ represents the indicator of the position in the sequence, and the kernel is modified to be indexed by a look - up table :', 'where l tq−t k, fq = exp ( f q w q a tq−t k ) with a ⋅ being a learnable matrix having matrix width to be the length of the sequence.', 'we refer readers to  #AUTHOR_TAG for more details.', ' #AUTHOR_TAG showed that the way to integrate positional embedding is better through eq. ( 5 ) than through eq.']",5
"[':', '( ii ) transformer - xl  #TAUTHOR_TAG, music']","[':', '( ii ) transformer - xl  #TAUTHOR_TAG, music']","[':', '( ii ) transformer - xl  #TAUTHOR_TAG, music transformer  #AUTHOR_TAG b ), self - attention with relative positional embedding  #AUTHOR_TAG :', 'compared']","['current transformers consider two different value function construction :  #AUTHOR_TAG and sparse transformer  #AUTHOR_TAG :', '( ii ) transformer - xl  #TAUTHOR_TAG, music transformer  #AUTHOR_TAG b ), self - attention with relative positional embedding  #AUTHOR_TAG :', 'compared eq. ( 7 ) to eq. ( 8 ), eq. ( 7 ) takes the positional embedding into account for constructing the value function.', 'in section 3, we empirically observe that constructing value function with eq. ( 8 ) constantly outperforms the construction with eq. ( 7 ), which suggests that we do not need positional embedding for value function']",5
['xl  #TAUTHOR_TAG :'],['xl  #TAUTHOR_TAG :'],['- xl  #TAUTHOR_TAG :'],"['( x q, s x k ) = s x k contains the keys being all the tokens in the encoded sequence. note that encoder self - attention considers x q = x k', 'with x q being the encoded sequence. ( ii ) encoder - decoder attention in original transformer  #AUTHOR_TAG : for each query x q in decoded sequence, m ( x q, s x k ) = s x k contains the keys being all the tokens in the encoded sequence. note that encode - decoder attention considers x q', '= x k with x q being the decoded sequence and x k being the encoded sequence. ( iii', ') decoder self - attention in original transformer  #AUTHOR_TAG : for each query x q in the decoded sequence, m ( x q, s x k ) returns a subset of s x k ( m ( x q, s x k )', '⊂ s x k ). note that decoder self - attention considers x q = x k with x q being the decoded sequence. since', 'the decoded sequence is the output for previous timestep, the query at position i can only observe the keys being the tokens that are decoded with position < i. for convenience, let us define s 1 as the set returned by original transformer  #AUTHOR_TAG from m ( x q,', 's x k ), which we will use it later. ( iv ) decoder self - attention in', 'transformer - xl  #TAUTHOR_TAG : for each query x q in the decoded sequence, m ( x q, s x k ) returns a set containing s 1 and additional memories ( m ( x q, s x k ) = s 1 + s mem, m ( x q, s x k ) [UNK] s 1 ). s mem refers', 'to additional memories. ( v ) decoder self - attention in sparse transformer  #AUTHOR_TAG : for each query x q in the decoded sentence, m ( x q, s x k ) returns a subset of s 1 ( m ( x q, s x k ) ⊂ s 1 ). to compare the differences for various designs, we see the computation time is inversely proportional', 'to the number of elements in m', '( x q, s x k ). for performance - wise comparisons, transformer - xl  #TAUTHOR_TAG showed that, the additional memories in m ( x q, s x k ) are able to capture longer - term dependency than the original transformer  #AUTHOR_TAG and hence results in', 'better performance. sparse transformer  #AUTHOR_TAG showed that although having much fewer elements in m ( x q, s x k ), if the elements are carefully chosen, the', 'attention can still reach the same performance as transformer - xl  #TAUTHOR_TAG']",5
['xl  #TAUTHOR_TAG :'],['xl  #TAUTHOR_TAG :'],['- xl  #TAUTHOR_TAG :'],"['( x q, s x k ) = s x k contains the keys being all the tokens in the encoded sequence. note that encoder self - attention considers x q = x k', 'with x q being the encoded sequence. ( ii ) encoder - decoder attention in original transformer  #AUTHOR_TAG : for each query x q in decoded sequence, m ( x q, s x k ) = s x k contains the keys being all the tokens in the encoded sequence. note that encode - decoder attention considers x q', '= x k with x q being the decoded sequence and x k being the encoded sequence. ( iii', ') decoder self - attention in original transformer  #AUTHOR_TAG : for each query x q in the decoded sequence, m ( x q, s x k ) returns a subset of s x k ( m ( x q, s x k )', '⊂ s x k ). note that decoder self - attention considers x q = x k with x q being the decoded sequence. since', 'the decoded sequence is the output for previous timestep, the query at position i can only observe the keys being the tokens that are decoded with position < i. for convenience, let us define s 1 as the set returned by original transformer  #AUTHOR_TAG from m ( x q,', 's x k ), which we will use it later. ( iv ) decoder self - attention in', 'transformer - xl  #TAUTHOR_TAG : for each query x q in the decoded sequence, m ( x q, s x k ) returns a set containing s 1 and additional memories ( m ( x q, s x k ) = s 1 + s mem, m ( x q, s x k ) [UNK] s 1 ). s mem refers', 'to additional memories. ( v ) decoder self - attention in sparse transformer  #AUTHOR_TAG : for each query x q in the decoded sentence, m ( x q, s x k ) returns a subset of s 1 ( m ( x q, s x k ) ⊂ s 1 ). to compare the differences for various designs, we see the computation time is inversely proportional', 'to the number of elements in m', '( x q, s x k ). for performance - wise comparisons, transformer - xl  #TAUTHOR_TAG showed that, the additional memories in m ( x q, s x k ) are able to capture longer - term dependency than the original transformer  #AUTHOR_TAG and hence results in', 'better performance. sparse transformer  #AUTHOR_TAG showed that although having much fewer elements in m ( x q, s x k ), if the elements are carefully chosen, the', 'attention can still reach the same performance as transformer - xl  #TAUTHOR_TAG']",5
['xl  #TAUTHOR_TAG :'],['xl  #TAUTHOR_TAG :'],['- xl  #TAUTHOR_TAG :'],"['( x q, s x k ) = s x k contains the keys being all the tokens in the encoded sequence. note that encoder self - attention considers x q = x k', 'with x q being the encoded sequence. ( ii ) encoder - decoder attention in original transformer  #AUTHOR_TAG : for each query x q in decoded sequence, m ( x q, s x k ) = s x k contains the keys being all the tokens in the encoded sequence. note that encode - decoder attention considers x q', '= x k with x q being the decoded sequence and x k being the encoded sequence. ( iii', ') decoder self - attention in original transformer  #AUTHOR_TAG : for each query x q in the decoded sequence, m ( x q, s x k ) returns a subset of s x k ( m ( x q, s x k )', '⊂ s x k ). note that decoder self - attention considers x q = x k with x q being the decoded sequence. since', 'the decoded sequence is the output for previous timestep, the query at position i can only observe the keys being the tokens that are decoded with position < i. for convenience, let us define s 1 as the set returned by original transformer  #AUTHOR_TAG from m ( x q,', 's x k ), which we will use it later. ( iv ) decoder self - attention in', 'transformer - xl  #TAUTHOR_TAG : for each query x q in the decoded sequence, m ( x q, s x k ) returns a set containing s 1 and additional memories ( m ( x q, s x k ) = s 1 + s mem, m ( x q, s x k ) [UNK] s 1 ). s mem refers', 'to additional memories. ( v ) decoder self - attention in sparse transformer  #AUTHOR_TAG : for each query x q in the decoded sentence, m ( x q, s x k ) returns a subset of s 1 ( m ( x q, s x k ) ⊂ s 1 ). to compare the differences for various designs, we see the computation time is inversely proportional', 'to the number of elements in m', '( x q, s x k ). for performance - wise comparisons, transformer - xl  #TAUTHOR_TAG showed that, the additional memories in m ( x q, s x k ) are able to capture longer - term dependency than the original transformer  #AUTHOR_TAG and hence results in', 'better performance. sparse transformer  #AUTHOR_TAG showed that although having much fewer elements in m ( x q, s x k ), if the elements are carefully chosen, the', 'attention can still reach the same performance as transformer - xl  #TAUTHOR_TAG']",5
"['designs ( eq. ( 5 ) by  #TAUTHOR_TAG.', 'we fix the size of the weight matrices']","['current state - of - the - art designs ( eq. ( 5 ) by  #TAUTHOR_TAG.', 'we fix the size of the weight matrices']","['cosine functions as in the prior work  #AUTHOR_TAG.', 'in our experiment, we find it reaching competitive performance as comparing to the current state - of - the - art designs ( eq. ( 5 ) by  #TAUTHOR_TAG.', 'we fix the size of the weight matrices w ⋅ in']","['far, we see how eq. ( 2 ) connects to the variants of transformers.', 'by changing the kernel construction in section 2. 2. 2, we can define a larger space for composing attention.', 'in this paper, we present a new form of attention with a kernel that is 1 ) valid ( i. e., a kernel that is symmetric and positive semi - definite ) and 2 ) delicate in the sense of constructing a kernel on a joint space ( i. e., x = ( f × t ) ) :', 'where w f and w t are weight matrices.', 'the new form considers product of kernels with the first kernel measuring similarity between non - temporal features and the second kernel measuring similarity between temporal features.', 'both kernels are symmetric exponential kernel.', 'note that t i here is chosen as the mixture of sine and cosine functions as in the prior work  #AUTHOR_TAG.', 'in our experiment, we find it reaching competitive performance as comparing to the current state - of - the - art designs ( eq. ( 5 ) by  #TAUTHOR_TAG.', 'we fix the size of the weight matrices w ⋅ in eq. ( 9 ) and eq. ( 5 ) which means we save 33 % of the parameters in attention from eq. ( 9']",5
"['sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nm']","['', 'we conduct experiments on neural machine translation ( nmt ) and sequence prediction ( sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nmt has three different types of attentions ( e. g., encoder']","['sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nm']","['', 'is positional embedding required in value function?', 'we conduct experiments on neural machine translation ( nmt ) and sequence prediction ( sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nmt has three different types of attentions ( e. g., encoder selfattention, decoder - encoder attention, decoder selfattention ) and sp has only one type of attention ( e. g., decoder self - attention ).', ""for the choice of datasets, we pick iwslt'14 german - english ( de - en ) dataset  #AUTHOR_TAG for nmt and wikitext - 103 dataset  #AUTHOR_TAG for sp as suggested by edunov et al.  #AUTHOR_TAG and  #TAUTHOR_TAG."", 'for fairness of comparisons, we train five random initializations and report test accuracy with the highest validation score.', 'we fix the position - wise operations in transformer 3 and only change the attention mechanism.', 'similar to prior work  #TAUTHOR_TAG, we report bleu score for nmt and perplexity for sp']",5
"['sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nm']","['', 'we conduct experiments on neural machine translation ( nmt ) and sequence prediction ( sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nmt has three different types of attentions ( e. g., encoder']","['sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nm']","['', 'is positional embedding required in value function?', 'we conduct experiments on neural machine translation ( nmt ) and sequence prediction ( sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nmt has three different types of attentions ( e. g., encoder selfattention, decoder - encoder attention, decoder selfattention ) and sp has only one type of attention ( e. g., decoder self - attention ).', ""for the choice of datasets, we pick iwslt'14 german - english ( de - en ) dataset  #AUTHOR_TAG for nmt and wikitext - 103 dataset  #AUTHOR_TAG for sp as suggested by edunov et al.  #AUTHOR_TAG and  #TAUTHOR_TAG."", 'for fairness of comparisons, we train five random initializations and report test accuracy with the highest validation score.', 'we fix the position - wise operations in transformer 3 and only change the attention mechanism.', 'similar to prior work  #TAUTHOR_TAG, we report bleu score for nmt and perplexity for sp']",5
['configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG'],['configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG'],"['↓ means the lower the better.', 'table 2 : kernel types.', 'other than manipulating the kernel choice of the non - positional features, we fix the configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG']","['', 'we present the results in table 1.', 'first, we see that by having pe as a look - up  #AUTHOR_TAG and sp stands for sequence prediction on wikitext - 103 dataset  #AUTHOR_TAG.', '↑ means the upper the better and ↓ means the lower the better.', 'table 2 : kernel types.', 'other than manipulating the kernel choice of the non - positional features, we fix the configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG for sp.', '34. 14 24. 13 24. 21 table, it outperforms the case with having pe as direct - sum in feature space, especially for sp task.', 'note that the look - up table is indexed by the relative position ( i. e., t q − t k ) instead of absolute position.', 'second, we see that pe in the product kernel proposed by  #TAUTHOR_TAG may not constantly outperform the other integration types ( it has lower bleu score for nmt ).', 'our proposed product kernel reaches the best result in nmt and is competitive to the best result in sp']",5
['configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG'],['configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG'],"['↓ means the lower the better.', 'table 2 : kernel types.', 'other than manipulating the kernel choice of the non - positional features, we fix the configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG']","['', 'we present the results in table 1.', 'first, we see that by having pe as a look - up  #AUTHOR_TAG and sp stands for sequence prediction on wikitext - 103 dataset  #AUTHOR_TAG.', '↑ means the upper the better and ↓ means the lower the better.', 'table 2 : kernel types.', 'other than manipulating the kernel choice of the non - positional features, we fix the configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG for sp.', '34. 14 24. 13 24. 21 table, it outperforms the case with having pe as direct - sum in feature space, especially for sp task.', 'note that the look - up table is indexed by the relative position ( i. e., t q − t k ) instead of absolute position.', 'second, we see that pe in the product kernel proposed by  #TAUTHOR_TAG may not constantly outperform the other integration types ( it has lower bleu score for nmt ).', 'our proposed product kernel reaches the best result in nmt and is competitive to the best result in sp']",5
['.  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG'],['al.  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG'],['.  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG'],"['find the best kernel form in the attention mechanism, in addition to the exponential kernel ( see eq. ( 3 ) ), we compare different kernel forms ( i. e., linear, polynomial, and rbf kernel ) for the non - positional features.', 'we also provide the results for changing asymmetric to the symmetric kernel, when forcing w q = w k, so that the resulting kernel is a valid kernel  #AUTHOR_TAG.', 'the numbers are shown in table 2.', 'note that, for fairness, other than manipulating the kernel choice of the non - positional features, we fix the configuration by vaswani et al.  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG for sp.', 'we first observe that the linear kernel does not converge for both nmt and sp.', 'we argue the reason is that the linear kernel may have negative value and thus it violates the assumption in kernel smoother that the kernel score must be positive  #AUTHOR_TAG.', '']",5
"[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder']","[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder self - attention, the operation is not order - agnostic.', 'for clarification,']","['is an order - agnostic ( or, permutation equivariant ) operation  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder']","['need of the positional embedding ( pe ) in the attention mechanism is based on the argument that the attention mechanism is an order - agnostic ( or, permutation equivariant ) operation  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder self - attention, the operation is not order - agnostic.', 'for clarification, we are not attacking the claim made by the prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG, but we aim at providing a new look at the order - invariance problem when considering the attention mechanism with masks ( masks refer to the set filtering function in our kernel formulation ).', 'in other words, previous work did not consider the mask between queries and keys when discussing the order - invariance problem ( perez et al., 2019 ).', 'to put it formally, we first present the definition by for a permutation equivariance function :', 'definition 2.', 'denote π as the set of all permutations over [ n ] = { 1, [UNK], n }. a function f unc [UNK] x n → y n is permutation equivariant iff for any permutation π ∈ π, f unc ( πx ) = πf unc ( x ). showed that the standard attention ( encoder self - attention  #TAUTHOR_TAG is permutation equivariant.', 'here, we present the non - permutation - equivariant problem on the decoder self - attention :  #TAUTHOR_TAG is not permutation equivariant.', 'to proceed the proof, we need the following definition and propositions']",5
"[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder']","[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder self - attention, the operation is not order - agnostic.', 'for clarification,']","['is an order - agnostic ( or, permutation equivariant ) operation  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder']","['need of the positional embedding ( pe ) in the attention mechanism is based on the argument that the attention mechanism is an order - agnostic ( or, permutation equivariant ) operation  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder self - attention, the operation is not order - agnostic.', 'for clarification, we are not attacking the claim made by the prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG, but we aim at providing a new look at the order - invariance problem when considering the attention mechanism with masks ( masks refer to the set filtering function in our kernel formulation ).', 'in other words, previous work did not consider the mask between queries and keys when discussing the order - invariance problem ( perez et al., 2019 ).', 'to put it formally, we first present the definition by for a permutation equivariance function :', 'definition 2.', 'denote π as the set of all permutations over [ n ] = { 1, [UNK], n }. a function f unc [UNK] x n → y n is permutation equivariant iff for any permutation π ∈ π, f unc ( πx ) = πf unc ( x ). showed that the standard attention ( encoder self - attention  #TAUTHOR_TAG is permutation equivariant.', 'here, we present the non - permutation - equivariant problem on the decoder self - attention :  #TAUTHOR_TAG is not permutation equivariant.', 'to proceed the proof, we need the following definition and propositions']",5
"[':', '( ii ) transformer - xl  #TAUTHOR_TAG, music']","[':', '( ii ) transformer - xl  #TAUTHOR_TAG, music']","[':', '( ii ) transformer - xl  #TAUTHOR_TAG, music transformer  #AUTHOR_TAG b ), self - attention with relative positional embedding  #AUTHOR_TAG :', 'compared']","['current transformers consider two different value function construction :  #AUTHOR_TAG and sparse transformer  #AUTHOR_TAG :', '( ii ) transformer - xl  #TAUTHOR_TAG, music transformer  #AUTHOR_TAG b ), self - attention with relative positional embedding  #AUTHOR_TAG :', 'compared eq. ( 7 ) to eq. ( 8 ), eq. ( 7 ) takes the positional embedding into account for constructing the value function.', 'in section 3, we empirically observe that constructing value function with eq. ( 8 ) constantly outperforms the construction with eq. ( 7 ), which suggests that we do not need positional embedding for value function']",7
"['designs ( eq. ( 5 ) by  #TAUTHOR_TAG.', 'we fix the size of the weight matrices']","['current state - of - the - art designs ( eq. ( 5 ) by  #TAUTHOR_TAG.', 'we fix the size of the weight matrices']","['cosine functions as in the prior work  #AUTHOR_TAG.', 'in our experiment, we find it reaching competitive performance as comparing to the current state - of - the - art designs ( eq. ( 5 ) by  #TAUTHOR_TAG.', 'we fix the size of the weight matrices w ⋅ in']","['far, we see how eq. ( 2 ) connects to the variants of transformers.', 'by changing the kernel construction in section 2. 2. 2, we can define a larger space for composing attention.', 'in this paper, we present a new form of attention with a kernel that is 1 ) valid ( i. e., a kernel that is symmetric and positive semi - definite ) and 2 ) delicate in the sense of constructing a kernel on a joint space ( i. e., x = ( f × t ) ) :', 'where w f and w t are weight matrices.', 'the new form considers product of kernels with the first kernel measuring similarity between non - temporal features and the second kernel measuring similarity between temporal features.', 'both kernels are symmetric exponential kernel.', 'note that t i here is chosen as the mixture of sine and cosine functions as in the prior work  #AUTHOR_TAG.', 'in our experiment, we find it reaching competitive performance as comparing to the current state - of - the - art designs ( eq. ( 5 ) by  #TAUTHOR_TAG.', 'we fix the size of the weight matrices w ⋅ in eq. ( 9 ) and eq. ( 5 ) which means we save 33 % of the parameters in attention from eq. ( 9']",3
"['sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nm']","['', 'we conduct experiments on neural machine translation ( nmt ) and sequence prediction ( sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nmt has three different types of attentions ( e. g., encoder']","['sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nm']","['', 'is positional embedding required in value function?', 'we conduct experiments on neural machine translation ( nmt ) and sequence prediction ( sp ) tasks since these two tasks are commonly chosen for studying transformers  #TAUTHOR_TAG.', 'note that nmt has three different types of attentions ( e. g., encoder selfattention, decoder - encoder attention, decoder selfattention ) and sp has only one type of attention ( e. g., decoder self - attention ).', ""for the choice of datasets, we pick iwslt'14 german - english ( de - en ) dataset  #AUTHOR_TAG for nmt and wikitext - 103 dataset  #AUTHOR_TAG for sp as suggested by edunov et al.  #AUTHOR_TAG and  #TAUTHOR_TAG."", 'for fairness of comparisons, we train five random initializations and report test accuracy with the highest validation score.', 'we fix the position - wise operations in transformer 3 and only change the attention mechanism.', 'similar to prior work  #TAUTHOR_TAG, we report bleu score for nmt and perplexity for sp']",3
['configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG'],['configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG'],"['↓ means the lower the better.', 'table 2 : kernel types.', 'other than manipulating the kernel choice of the non - positional features, we fix the configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG']","['', 'we present the results in table 1.', 'first, we see that by having pe as a look - up  #AUTHOR_TAG and sp stands for sequence prediction on wikitext - 103 dataset  #AUTHOR_TAG.', '↑ means the upper the better and ↓ means the lower the better.', 'table 2 : kernel types.', 'other than manipulating the kernel choice of the non - positional features, we fix the configuration by  #AUTHOR_TAG for nmt and the configuration by  #TAUTHOR_TAG for sp.', '34. 14 24. 13 24. 21 table, it outperforms the case with having pe as direct - sum in feature space, especially for sp task.', 'note that the look - up table is indexed by the relative position ( i. e., t q − t k ) instead of absolute position.', 'second, we see that pe in the product kernel proposed by  #TAUTHOR_TAG may not constantly outperform the other integration types ( it has lower bleu score for nmt ).', 'our proposed product kernel reaches the best result in nmt and is competitive to the best result in sp']",4
"[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder']","[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder self - attention, the operation is not order - agnostic.', 'for clarification,']","['is an order - agnostic ( or, permutation equivariant ) operation  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder']","['need of the positional embedding ( pe ) in the attention mechanism is based on the argument that the attention mechanism is an order - agnostic ( or, permutation equivariant ) operation  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder self - attention, the operation is not order - agnostic.', 'for clarification, we are not attacking the claim made by the prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG, but we aim at providing a new look at the order - invariance problem when considering the attention mechanism with masks ( masks refer to the set filtering function in our kernel formulation ).', 'in other words, previous work did not consider the mask between queries and keys when discussing the order - invariance problem ( perez et al., 2019 ).', 'to put it formally, we first present the definition by for a permutation equivariance function :', 'definition 2.', 'denote π as the set of all permutations over [ n ] = { 1, [UNK], n }. a function f unc [UNK] x n → y n is permutation equivariant iff for any permutation π ∈ π, f unc ( πx ) = πf unc ( x ). showed that the standard attention ( encoder self - attention  #TAUTHOR_TAG is permutation equivariant.', 'here, we present the non - permutation - equivariant problem on the decoder self - attention :  #TAUTHOR_TAG is not permutation equivariant.', 'to proceed the proof, we need the following definition and propositions']",4
"[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder']","[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder self - attention, the operation is not order - agnostic.', 'for clarification,']","['is an order - agnostic ( or, permutation equivariant ) operation  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder']","['need of the positional embedding ( pe ) in the attention mechanism is based on the argument that the attention mechanism is an order - agnostic ( or, permutation equivariant ) operation  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'however, we show that, for decoder self - attention, the operation is not order - agnostic.', 'for clarification, we are not attacking the claim made by the prior work  #AUTHOR_TAG b ;  #TAUTHOR_TAG, but we aim at providing a new look at the order - invariance problem when considering the attention mechanism with masks ( masks refer to the set filtering function in our kernel formulation ).', 'in other words, previous work did not consider the mask between queries and keys when discussing the order - invariance problem ( perez et al., 2019 ).', 'to put it formally, we first present the definition by for a permutation equivariance function :', 'definition 2.', 'denote π as the set of all permutations over [ n ] = { 1, [UNK], n }. a function f unc [UNK] x n → y n is permutation equivariant iff for any permutation π ∈ π, f unc ( πx ) = πf unc ( x ). showed that the standard attention ( encoder self - attention  #TAUTHOR_TAG is permutation equivariant.', 'here, we present the non - permutation - equivariant problem on the decoder self - attention :  #TAUTHOR_TAG is not permutation equivariant.', 'to proceed the proof, we need the following definition and propositions']",4
"[' #TAUTHOR_TAG,']","['flickr8k  #AUTHOR_TAG, flickr30k  #TAUTHOR_TAG,']","[' #AUTHOR_TAG, flickr30k  #TAUTHOR_TAG,']","['description is one of the core challenges at the intersection of natural language processing ( nlp ) and computer vision ( cv )  #AUTHOR_TAG.', 'this task has only received attention in a monolingual english setting, helped by the availability of english datasets, e. g. flickr8k  #AUTHOR_TAG, flickr30k  #TAUTHOR_TAG, and ms coco  #AUTHOR_TAG.', 'however, the possible applications of image description are useful for all languages, such as searching for images using natural language, or providing alternative - description text for visually impaired web users.', 'we introduce a large - scale dataset of images paired with sentences in english and german as an initial step towards studying the value and the characteristics of multilingual - multimodal data.', 'multi30k is an extension of the flickr30k dataset  #TAUTHOR_TAG with 31, 014 german translations of english descriptions and 155, 070 independently collected german descriptions.', 'the translations were collected from professionally contracted translators, whereas the descriptions were collected from untrained crowdworkers.', 'the key difference between these corpora is the relationship between the sentences in different languages.', 'in the translated corpus, we know there is a strong correspondence between the sentences in both languages.', 'in the descriptions corpus, we only know that the sentences, regardless of the language, are supposed to describe the same image.', 'a dataset of images paired with sentences in multiple languages broadens the scope of multimodal nlp research.', 'image description with multilingual data can also be seen as machine translation in a multimodal context.', 'this opens up new avenues for researchers in machine translation  #AUTHOR_TAG inter - alia ) to work with multilingual multimodal data.', 'image - sentence ranking using monolingual multimodal datasets  #AUTHOR_TAG inter - alia ) is also a natural task for multilingual modelling.', 'the only existing datasets of images paired with multilingual sentences were created by professionally translating english into the target language : iapr - tc12 with 20, 000 english - german described images  #AUTHOR_TAG, and the pascal sentences dataset of 1, 000 japanese - english described images  #AUTHOR_TAG.', 'multi30k dataset is larger than both of these and contains both independent and translated sentences.', 'we hope this dataset will be of broad interest across nlp and cv research and anticipate that these communities will put the data to use in a broader range of tasks than we can foresee.', 'the independent sentences are all accurate descriptions of the image but do not contain the same details in both languages, such as shirt colour or the scaffolding.', 'in the second translation pair ( bottom left ) the translator has translated "" glide "" as "" schweben']",0
"['online photo - sharing websites  #TAUTHOR_TAG.', '']","['online photo - sharing websites  #TAUTHOR_TAG.', '']","['online photo - sharing websites  #TAUTHOR_TAG.', 'each image is paired with five english descriptions, which were collected from amazon mechanical turk 1.', 'the dataset contains 145,']","['flickr30k dataset contains 31, 014 images sourced from online photo - sharing websites  #TAUTHOR_TAG.', 'each image is paired with five english descriptions, which were collected from amazon mechanical turk 1.', 'the dataset contains 145, 000 training, 5, 070 development, and 5, 000 test descriptions.', 'the multi30k dataset extends the flickr30k dataset with translated and independent german sentences']",0
"[' #TAUTHOR_TAG,']","['flickr8k  #AUTHOR_TAG, flickr30k  #TAUTHOR_TAG,']","[' #AUTHOR_TAG, flickr30k  #TAUTHOR_TAG,']","['description is one of the core challenges at the intersection of natural language processing ( nlp ) and computer vision ( cv )  #AUTHOR_TAG.', 'this task has only received attention in a monolingual english setting, helped by the availability of english datasets, e. g. flickr8k  #AUTHOR_TAG, flickr30k  #TAUTHOR_TAG, and ms coco  #AUTHOR_TAG.', 'however, the possible applications of image description are useful for all languages, such as searching for images using natural language, or providing alternative - description text for visually impaired web users.', 'we introduce a large - scale dataset of images paired with sentences in english and german as an initial step towards studying the value and the characteristics of multilingual - multimodal data.', 'multi30k is an extension of the flickr30k dataset  #TAUTHOR_TAG with 31, 014 german translations of english descriptions and 155, 070 independently collected german descriptions.', 'the translations were collected from professionally contracted translators, whereas the descriptions were collected from untrained crowdworkers.', 'the key difference between these corpora is the relationship between the sentences in different languages.', 'in the translated corpus, we know there is a strong correspondence between the sentences in both languages.', 'in the descriptions corpus, we only know that the sentences, regardless of the language, are supposed to describe the same image.', 'a dataset of images paired with sentences in multiple languages broadens the scope of multimodal nlp research.', 'image description with multilingual data can also be seen as machine translation in a multimodal context.', 'this opens up new avenues for researchers in machine translation  #AUTHOR_TAG inter - alia ) to work with multilingual multimodal data.', 'image - sentence ranking using monolingual multimodal datasets  #AUTHOR_TAG inter - alia ) is also a natural task for multilingual modelling.', 'the only existing datasets of images paired with multilingual sentences were created by professionally translating english into the target language : iapr - tc12 with 20, 000 english - german described images  #AUTHOR_TAG, and the pascal sentences dataset of 1, 000 japanese - english described images  #AUTHOR_TAG.', 'multi30k dataset is larger than both of these and contains both independent and translated sentences.', 'we hope this dataset will be of broad interest across nlp and cv research and anticipate that these communities will put the data to use in a broader range of tasks than we can foresee.', 'the independent sentences are all accurate descriptions of the image but do not contain the same details in both languages, such as shirt colour or the scaffolding.', 'in the second translation pair ( bottom left ) the translator has translated "" glide "" as "" schweben']",6
"['online photo - sharing websites  #TAUTHOR_TAG.', '']","['online photo - sharing websites  #TAUTHOR_TAG.', '']","['online photo - sharing websites  #TAUTHOR_TAG.', 'each image is paired with five english descriptions, which were collected from amazon mechanical turk 1.', 'the dataset contains 145,']","['flickr30k dataset contains 31, 014 images sourced from online photo - sharing websites  #TAUTHOR_TAG.', 'each image is paired with five english descriptions, which were collected from amazon mechanical turk 1.', 'the dataset contains 145, 000 training, 5, 070 development, and 5, 000 test descriptions.', 'the multi30k dataset extends the flickr30k dataset with translated and independent german sentences']",6
"['dataset by translating the instructions used by  #TAUTHOR_TAG into german.', 'the translations were collected without showing the images to the translators']","['original flickr30k dataset by translating the instructions used by  #TAUTHOR_TAG into german.', 'the translations were collected without showing the images to the translators']","['.', 'these differences are deliberate and part of the larger scope of studying multilingual multimodal data in different contexts.', 'the descriptions were collected as similarly as possible to the original flickr30k dataset by translating the instructions used by  #TAUTHOR_TAG into german.', 'the translations were collected without showing the images to the translators']","['introduced multi30k : a large - scale multilingual multimodal dataset for interdisciplinary machine learning research.', 'our dataset is an extension of the popular flickr30k dataset with descriptions and professional translations in german.', 'the descriptions were collected from a crowdsourcing platform, while the translations were collected from professionally contracted translators.', 'these differences are deliberate and part of the larger scope of studying multilingual multimodal data in different contexts.', 'the descriptions were collected as similarly as possible to the original flickr30k dataset by translating the instructions used by  #TAUTHOR_TAG into german.', 'the translations were collected without showing the images to the translators to keep it as close to a standard translation task as possible.', 'there are substantial differences between the translated and the description datasets.', 'the translations contain approximately the same number of tokens and have sentences of approximately the same length in both languages.', 'these properties make them suited to machine translations models.', 'the description datasets are very different in terms of average sentence lengths and the number of word types per language.', 'this is likely to cause different engineering and scientific challenges because the descriptions are independently collected corpora instead of a sentence - level aligned corpus.', 'in the future, we want to study multilingual multimodality over a wider range of languages, for example beyond indo - european families.', 'we call on the community to engage with us on creating massively multilingual multimodal datasets']",5
"['representation of visual input.', 'in this paper, we consider the referential games of  #TAUTHOR_TAG, and investigate the representations']","['representation of visual input.', 'in this paper, we consider the referential games of  #TAUTHOR_TAG, and investigate the representations']","['representation of visual input.', 'in this paper, we consider the referential games of  #TAUTHOR_TAG, and investigate the representations the agents develop']","['is growing interest in the language developed by agents interacting in emergentcommunication settings.', ""earlier studies have focused on the agents'symbol usage, rather than on their representation of visual input."", 'in this paper, we consider the referential games of  #TAUTHOR_TAG, and investigate the representations the agents develop during their evolving interaction.', 'we find that the agents establish successful communication by inducing visual representations that almost perfectly align with each other, but, surprisingly, do not capture the conceptual properties of the objects depicted in the input images.', 'we conclude that, if we are interested in developing language - like communication systems, we must pay more attention to the visual semantics agents associate to the symbols they use']",1
"[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['has recently been a revival of interests in language emergence simulations involving agents interacting in visually - grounded games.', 'unlike earlier work ( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication will lead agents to associate visually - grounded conceptual representations to discrete symbols, developing naturallanguage - like word meanings.', ""however, while most studies present some analysis of the agents'symbol usage, they pay little or no attention to the representation of the visual input that the agents develop as part of their evolving interaction."", 'we study here agent representations following the model and setup of  #TAUTHOR_TAG.', 'this is an ideal starting point, since it involves an extremely simple signaling game  #AUTHOR_TAG, that is however played with naturalistic images, thus allowing us to focus on the question of how the agents represent these images, and whether such representations meet our expectations for natural word meanings.', 'in their first game,  #TAUTHOR_TAG\'s sender and receiver are exposed to the same pair of images, one of them being randomly marked as the "" target "".', 'the sender always sees the target in the left position, and it must pick one discrete symbol from a fixed vocabulary to send to the receiver.', 'the receiver sees the images in random order, together with the sent symbol, and it tries to guess which image is the target.', 'in case of success, both players get a payoff of 1.', 'since an analysis of vocabulary usage brings inconclusive evidence that the agents are using the symbols to represent natural concepts ( such as beaver or bayonet ),  #TAUTHOR_TAG next modify the game, by presenting to the sender and the receiver different images for each of the two concepts ( e. g., the sender must now signal that the target is a beaver, while seeing a different beaver from the one shown to the receiver ).', 'this setup should encourage conceptlevel thinking, since the two agents should not be able to communicate about low - level perceptual characteristics of images they do not share.', ' #TAUTHOR_TAG present preliminary evidence suggesting that, indeed, agents are now developing conceptual symbol meanings.', ""we replicate  #TAUTHOR_TAG's games, and we find that, in both, the agents develop successfully aligned representations that, however, are not capturing conceptual properties at all."", 'in what is perhaps our most striking result, agents trained in either version of the game succeed at communicating about pseudoimages generated from random noise ( fig. 2 ).', 'we']",1
"[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['has recently been a revival of interests in language emergence simulations involving agents interacting in visually - grounded games.', 'unlike earlier work ( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication will lead agents to associate visually - grounded conceptual representations to discrete symbols, developing naturallanguage - like word meanings.', ""however, while most studies present some analysis of the agents'symbol usage, they pay little or no attention to the representation of the visual input that the agents develop as part of their evolving interaction."", 'we study here agent representations following the model and setup of  #TAUTHOR_TAG.', 'this is an ideal starting point, since it involves an extremely simple signaling game  #AUTHOR_TAG, that is however played with naturalistic images, thus allowing us to focus on the question of how the agents represent these images, and whether such representations meet our expectations for natural word meanings.', 'in their first game,  #TAUTHOR_TAG\'s sender and receiver are exposed to the same pair of images, one of them being randomly marked as the "" target "".', 'the sender always sees the target in the left position, and it must pick one discrete symbol from a fixed vocabulary to send to the receiver.', 'the receiver sees the images in random order, together with the sent symbol, and it tries to guess which image is the target.', 'in case of success, both players get a payoff of 1.', 'since an analysis of vocabulary usage brings inconclusive evidence that the agents are using the symbols to represent natural concepts ( such as beaver or bayonet ),  #TAUTHOR_TAG next modify the game, by presenting to the sender and the receiver different images for each of the two concepts ( e. g., the sender must now signal that the target is a beaver, while seeing a different beaver from the one shown to the receiver ).', 'this setup should encourage conceptlevel thinking, since the two agents should not be able to communicate about low - level perceptual characteristics of images they do not share.', ' #TAUTHOR_TAG present preliminary evidence suggesting that, indeed, agents are now developing conceptual symbol meanings.', ""we replicate  #TAUTHOR_TAG's games, and we find that, in both, the agents develop successfully aligned representations that, however, are not capturing conceptual properties at all."", 'in what is perhaps our most striking result, agents trained in either version of the game succeed at communicating about pseudoimages generated from random noise ( fig. 2 ).', 'we']",1
"[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['has recently been a revival of interests in language emergence simulations involving agents interacting in visually - grounded games.', 'unlike earlier work ( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication will lead agents to associate visually - grounded conceptual representations to discrete symbols, developing naturallanguage - like word meanings.', ""however, while most studies present some analysis of the agents'symbol usage, they pay little or no attention to the representation of the visual input that the agents develop as part of their evolving interaction."", 'we study here agent representations following the model and setup of  #TAUTHOR_TAG.', 'this is an ideal starting point, since it involves an extremely simple signaling game  #AUTHOR_TAG, that is however played with naturalistic images, thus allowing us to focus on the question of how the agents represent these images, and whether such representations meet our expectations for natural word meanings.', 'in their first game,  #TAUTHOR_TAG\'s sender and receiver are exposed to the same pair of images, one of them being randomly marked as the "" target "".', 'the sender always sees the target in the left position, and it must pick one discrete symbol from a fixed vocabulary to send to the receiver.', 'the receiver sees the images in random order, together with the sent symbol, and it tries to guess which image is the target.', 'in case of success, both players get a payoff of 1.', 'since an analysis of vocabulary usage brings inconclusive evidence that the agents are using the symbols to represent natural concepts ( such as beaver or bayonet ),  #TAUTHOR_TAG next modify the game, by presenting to the sender and the receiver different images for each of the two concepts ( e. g., the sender must now signal that the target is a beaver, while seeing a different beaver from the one shown to the receiver ).', 'this setup should encourage conceptlevel thinking, since the two agents should not be able to communicate about low - level perceptual characteristics of images they do not share.', ' #TAUTHOR_TAG present preliminary evidence suggesting that, indeed, agents are now developing conceptual symbol meanings.', ""we replicate  #TAUTHOR_TAG's games, and we find that, in both, the agents develop successfully aligned representations that, however, are not capturing conceptual properties at all."", 'in what is perhaps our most striking result, agents trained in either version of the game succeed at communicating about pseudoimages generated from random noise ( fig. 2 ).', 'we']",1
"[').', 'however, the important contribution of  #TAUTHOR_TAG is to play a signaling game with real - life images instead of artificial symbols.', 'this']","['references therein ).', 'however, the important contribution of  #TAUTHOR_TAG is to play a signaling game with real - life images instead of artificial symbols.', 'this']","[').', 'however, the important contribution of  #TAUTHOR_TAG is to play a signaling game with real - life images instead of artificial symbols.', 'this']","['literature in game theory already showed that convergence towards successful communication is ensured under specific conditions ( see  #AUTHOR_TAG and references therein ).', 'however, the important contribution of  #TAUTHOR_TAG is to play a signaling game with real - life images instead of artificial symbols.', '']",1
"[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['has recently been a revival of interests in language emergence simulations involving agents interacting in visually - grounded games.', 'unlike earlier work ( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication will lead agents to associate visually - grounded conceptual representations to discrete symbols, developing naturallanguage - like word meanings.', ""however, while most studies present some analysis of the agents'symbol usage, they pay little or no attention to the representation of the visual input that the agents develop as part of their evolving interaction."", 'we study here agent representations following the model and setup of  #TAUTHOR_TAG.', 'this is an ideal starting point, since it involves an extremely simple signaling game  #AUTHOR_TAG, that is however played with naturalistic images, thus allowing us to focus on the question of how the agents represent these images, and whether such representations meet our expectations for natural word meanings.', 'in their first game,  #TAUTHOR_TAG\'s sender and receiver are exposed to the same pair of images, one of them being randomly marked as the "" target "".', 'the sender always sees the target in the left position, and it must pick one discrete symbol from a fixed vocabulary to send to the receiver.', 'the receiver sees the images in random order, together with the sent symbol, and it tries to guess which image is the target.', 'in case of success, both players get a payoff of 1.', 'since an analysis of vocabulary usage brings inconclusive evidence that the agents are using the symbols to represent natural concepts ( such as beaver or bayonet ),  #TAUTHOR_TAG next modify the game, by presenting to the sender and the receiver different images for each of the two concepts ( e. g., the sender must now signal that the target is a beaver, while seeing a different beaver from the one shown to the receiver ).', 'this setup should encourage conceptlevel thinking, since the two agents should not be able to communicate about low - level perceptual characteristics of images they do not share.', ' #TAUTHOR_TAG present preliminary evidence suggesting that, indeed, agents are now developing conceptual symbol meanings.', ""we replicate  #TAUTHOR_TAG's games, and we find that, in both, the agents develop successfully aligned representations that, however, are not capturing conceptual properties at all."", 'in what is perhaps our most striking result, agents trained in either version of the game succeed at communicating about pseudoimages generated from random noise ( fig. 2 ).', 'we']",0
"[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['has recently been a revival of interests in language emergence simulations involving agents interacting in visually - grounded games.', 'unlike earlier work ( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication will lead agents to associate visually - grounded conceptual representations to discrete symbols, developing naturallanguage - like word meanings.', ""however, while most studies present some analysis of the agents'symbol usage, they pay little or no attention to the representation of the visual input that the agents develop as part of their evolving interaction."", 'we study here agent representations following the model and setup of  #TAUTHOR_TAG.', 'this is an ideal starting point, since it involves an extremely simple signaling game  #AUTHOR_TAG, that is however played with naturalistic images, thus allowing us to focus on the question of how the agents represent these images, and whether such representations meet our expectations for natural word meanings.', 'in their first game,  #TAUTHOR_TAG\'s sender and receiver are exposed to the same pair of images, one of them being randomly marked as the "" target "".', 'the sender always sees the target in the left position, and it must pick one discrete symbol from a fixed vocabulary to send to the receiver.', 'the receiver sees the images in random order, together with the sent symbol, and it tries to guess which image is the target.', 'in case of success, both players get a payoff of 1.', 'since an analysis of vocabulary usage brings inconclusive evidence that the agents are using the symbols to represent natural concepts ( such as beaver or bayonet ),  #TAUTHOR_TAG next modify the game, by presenting to the sender and the receiver different images for each of the two concepts ( e. g., the sender must now signal that the target is a beaver, while seeing a different beaver from the one shown to the receiver ).', 'this setup should encourage conceptlevel thinking, since the two agents should not be able to communicate about low - level perceptual characteristics of images they do not share.', ' #TAUTHOR_TAG present preliminary evidence suggesting that, indeed, agents are now developing conceptual symbol meanings.', ""we replicate  #TAUTHOR_TAG's games, and we find that, in both, the agents develop successfully aligned representations that, however, are not capturing conceptual properties at all."", 'in what is perhaps our most striking result, agents trained in either version of the game succeed at communicating about pseudoimages generated from random noise ( fig. 2 ).', 'we']",0
"[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['has recently been a revival of interests in language emergence simulations involving agents interacting in visually - grounded games.', 'unlike earlier work ( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication will lead agents to associate visually - grounded conceptual representations to discrete symbols, developing naturallanguage - like word meanings.', ""however, while most studies present some analysis of the agents'symbol usage, they pay little or no attention to the representation of the visual input that the agents develop as part of their evolving interaction."", 'we study here agent representations following the model and setup of  #TAUTHOR_TAG.', 'this is an ideal starting point, since it involves an extremely simple signaling game  #AUTHOR_TAG, that is however played with naturalistic images, thus allowing us to focus on the question of how the agents represent these images, and whether such representations meet our expectations for natural word meanings.', 'in their first game,  #TAUTHOR_TAG\'s sender and receiver are exposed to the same pair of images, one of them being randomly marked as the "" target "".', 'the sender always sees the target in the left position, and it must pick one discrete symbol from a fixed vocabulary to send to the receiver.', 'the receiver sees the images in random order, together with the sent symbol, and it tries to guess which image is the target.', 'in case of success, both players get a payoff of 1.', 'since an analysis of vocabulary usage brings inconclusive evidence that the agents are using the symbols to represent natural concepts ( such as beaver or bayonet ),  #TAUTHOR_TAG next modify the game, by presenting to the sender and the receiver different images for each of the two concepts ( e. g., the sender must now signal that the target is a beaver, while seeing a different beaver from the one shown to the receiver ).', 'this setup should encourage conceptlevel thinking, since the two agents should not be able to communicate about low - level perceptual characteristics of images they do not share.', ' #TAUTHOR_TAG present preliminary evidence suggesting that, indeed, agents are now developing conceptual symbol meanings.', ""we replicate  #TAUTHOR_TAG's games, and we find that, in both, the agents develop successfully aligned representations that, however, are not capturing conceptual properties at all."", 'in what is perhaps our most striking result, agents trained in either version of the game succeed at communicating about pseudoimages generated from random noise ( fig. 2 ).', 'we']",0
"[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['has recently been a revival of interests in language emergence simulations involving agents interacting in visually - grounded games.', 'unlike earlier work ( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication will lead agents to associate visually - grounded conceptual representations to discrete symbols, developing naturallanguage - like word meanings.', ""however, while most studies present some analysis of the agents'symbol usage, they pay little or no attention to the representation of the visual input that the agents develop as part of their evolving interaction."", 'we study here agent representations following the model and setup of  #TAUTHOR_TAG.', 'this is an ideal starting point, since it involves an extremely simple signaling game  #AUTHOR_TAG, that is however played with naturalistic images, thus allowing us to focus on the question of how the agents represent these images, and whether such representations meet our expectations for natural word meanings.', 'in their first game,  #TAUTHOR_TAG\'s sender and receiver are exposed to the same pair of images, one of them being randomly marked as the "" target "".', 'the sender always sees the target in the left position, and it must pick one discrete symbol from a fixed vocabulary to send to the receiver.', 'the receiver sees the images in random order, together with the sent symbol, and it tries to guess which image is the target.', 'in case of success, both players get a payoff of 1.', 'since an analysis of vocabulary usage brings inconclusive evidence that the agents are using the symbols to represent natural concepts ( such as beaver or bayonet ),  #TAUTHOR_TAG next modify the game, by presenting to the sender and the receiver different images for each of the two concepts ( e. g., the sender must now signal that the target is a beaver, while seeing a different beaver from the one shown to the receiver ).', 'this setup should encourage conceptlevel thinking, since the two agents should not be able to communicate about low - level perceptual characteristics of images they do not share.', ' #TAUTHOR_TAG present preliminary evidence suggesting that, indeed, agents are now developing conceptual symbol meanings.', ""we replicate  #TAUTHOR_TAG's games, and we find that, in both, the agents develop successfully aligned representations that, however, are not capturing conceptual properties at all."", 'in what is perhaps our most striking result, agents trained in either version of the game succeed at communicating about pseudoimages generated from random noise ( fig. 2 ).', 'we']",0
"[""- implement  #TAUTHOR_TAG's sender and""]","[""we re - implement  #TAUTHOR_TAG's sender and""]","[""- implement  #TAUTHOR_TAG's sender and receiver architectures ( using their better -""]","['we re - implement  #TAUTHOR_TAG\'s sender and receiver architectures ( using their better - behaved "" informed "" sender ).', 'both agents are feed - forward networks.', 'the sender takes image representations as input, it projects them into its own representational space, compares them, and finally outputs a probability distribution over vocabulary symbols, from which a single discrete symbol is then sampled.', 'we report here results obtained with an output vocabulary of 100 symbols, but the same patterns were observed using a range of sizes from 2 to 1, 000.', 'the receiver takes as input the target and distractor input image representations in random order, as well as the symbol produced by the sender ( as a vocabulary - sized one - hot vector ).', 'it embeds the images and the symbol into its own representational space, where it performs a symbol - to - image comparison, producing a probability distribution over the two images, one of which is selected by sampling from this distribution.', 'if the receiver selected the target image, a reward of 1 is assigned to both agents.', 'the whole architecture is jointly trained by letting the agents play, and updating their parameters with reinforce  #AUTHOR_TAG.', 'see  #TAUTHOR_TAG for details.', 'data following  #TAUTHOR_TAG used, we randomly sample 100 images from imagenet  #AUTHOR_TAG.', '']",0
"[""- implement  #TAUTHOR_TAG's sender and""]","[""we re - implement  #TAUTHOR_TAG's sender and""]","[""- implement  #TAUTHOR_TAG's sender and receiver architectures ( using their better -""]","['we re - implement  #TAUTHOR_TAG\'s sender and receiver architectures ( using their better - behaved "" informed "" sender ).', 'both agents are feed - forward networks.', 'the sender takes image representations as input, it projects them into its own representational space, compares them, and finally outputs a probability distribution over vocabulary symbols, from which a single discrete symbol is then sampled.', 'we report here results obtained with an output vocabulary of 100 symbols, but the same patterns were observed using a range of sizes from 2 to 1, 000.', 'the receiver takes as input the target and distractor input image representations in random order, as well as the symbol produced by the sender ( as a vocabulary - sized one - hot vector ).', 'it embeds the images and the symbol into its own representational space, where it performs a symbol - to - image comparison, producing a probability distribution over the two images, one of which is selected by sampling from this distribution.', 'if the receiver selected the target image, a reward of 1 is assigned to both agents.', 'the whole architecture is jointly trained by letting the agents play, and updating their parameters with reinforce  #AUTHOR_TAG.', 'see  #TAUTHOR_TAG for details.', 'data following  #TAUTHOR_TAG used, we randomly sample 100 images from imagenet  #AUTHOR_TAG.', '']",0
,,,,0
"[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","[', by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication']","['has recently been a revival of interests in language emergence simulations involving agents interacting in visually - grounded games.', 'unlike earlier work ( e. g.,  #AUTHOR_TAG, many recent simulations consider realistic visual input, for example, by playing referential games with real - life pictures ( e. g.,  #TAUTHOR_TAG.', 'this setup allows us to address the exciting issue of whether the needs of goal - directed communication will lead agents to associate visually - grounded conceptual representations to discrete symbols, developing naturallanguage - like word meanings.', ""however, while most studies present some analysis of the agents'symbol usage, they pay little or no attention to the representation of the visual input that the agents develop as part of their evolving interaction."", 'we study here agent representations following the model and setup of  #TAUTHOR_TAG.', 'this is an ideal starting point, since it involves an extremely simple signaling game  #AUTHOR_TAG, that is however played with naturalistic images, thus allowing us to focus on the question of how the agents represent these images, and whether such representations meet our expectations for natural word meanings.', 'in their first game,  #TAUTHOR_TAG\'s sender and receiver are exposed to the same pair of images, one of them being randomly marked as the "" target "".', 'the sender always sees the target in the left position, and it must pick one discrete symbol from a fixed vocabulary to send to the receiver.', 'the receiver sees the images in random order, together with the sent symbol, and it tries to guess which image is the target.', 'in case of success, both players get a payoff of 1.', 'since an analysis of vocabulary usage brings inconclusive evidence that the agents are using the symbols to represent natural concepts ( such as beaver or bayonet ),  #TAUTHOR_TAG next modify the game, by presenting to the sender and the receiver different images for each of the two concepts ( e. g., the sender must now signal that the target is a beaver, while seeing a different beaver from the one shown to the receiver ).', 'this setup should encourage conceptlevel thinking, since the two agents should not be able to communicate about low - level perceptual characteristics of images they do not share.', ' #TAUTHOR_TAG present preliminary evidence suggesting that, indeed, agents are now developing conceptual symbol meanings.', ""we replicate  #TAUTHOR_TAG's games, and we find that, in both, the agents develop successfully aligned representations that, however, are not capturing conceptual properties at all."", 'in what is perhaps our most striking result, agents trained in either version of the game succeed at communicating about pseudoimages generated from random noise ( fig. 2 ).', 'we']",5
"[""- implement  #TAUTHOR_TAG's sender and""]","[""we re - implement  #TAUTHOR_TAG's sender and""]","[""- implement  #TAUTHOR_TAG's sender and receiver architectures ( using their better -""]","['we re - implement  #TAUTHOR_TAG\'s sender and receiver architectures ( using their better - behaved "" informed "" sender ).', 'both agents are feed - forward networks.', 'the sender takes image representations as input, it projects them into its own representational space, compares them, and finally outputs a probability distribution over vocabulary symbols, from which a single discrete symbol is then sampled.', 'we report here results obtained with an output vocabulary of 100 symbols, but the same patterns were observed using a range of sizes from 2 to 1, 000.', 'the receiver takes as input the target and distractor input image representations in random order, as well as the symbol produced by the sender ( as a vocabulary - sized one - hot vector ).', 'it embeds the images and the symbol into its own representational space, where it performs a symbol - to - image comparison, producing a probability distribution over the two images, one of which is selected by sampling from this distribution.', 'if the receiver selected the target image, a reward of 1 is assigned to both agents.', 'the whole architecture is jointly trained by letting the agents play, and updating their parameters with reinforce  #AUTHOR_TAG.', 'see  #TAUTHOR_TAG for details.', 'data following  #TAUTHOR_TAG used, we randomly sample 100 images from imagenet  #AUTHOR_TAG.', '']",5
"[""- implement  #TAUTHOR_TAG's sender and""]","[""we re - implement  #TAUTHOR_TAG's sender and""]","[""- implement  #TAUTHOR_TAG's sender and receiver architectures ( using their better -""]","['we re - implement  #TAUTHOR_TAG\'s sender and receiver architectures ( using their better - behaved "" informed "" sender ).', 'both agents are feed - forward networks.', 'the sender takes image representations as input, it projects them into its own representational space, compares them, and finally outputs a probability distribution over vocabulary symbols, from which a single discrete symbol is then sampled.', 'we report here results obtained with an output vocabulary of 100 symbols, but the same patterns were observed using a range of sizes from 2 to 1, 000.', 'the receiver takes as input the target and distractor input image representations in random order, as well as the symbol produced by the sender ( as a vocabulary - sized one - hot vector ).', 'it embeds the images and the symbol into its own representational space, where it performs a symbol - to - image comparison, producing a probability distribution over the two images, one of which is selected by sampling from this distribution.', 'if the receiver selected the target image, a reward of 1 is assigned to both agents.', 'the whole architecture is jointly trained by letting the agents play, and updating their parameters with reinforce  #AUTHOR_TAG.', 'see  #TAUTHOR_TAG for details.', 'data following  #TAUTHOR_TAG used, we randomly sample 100 images from imagenet  #AUTHOR_TAG.', '']",5
"[""- implement  #TAUTHOR_TAG's sender and""]","[""we re - implement  #TAUTHOR_TAG's sender and""]","[""- implement  #TAUTHOR_TAG's sender and receiver architectures ( using their better -""]","['we re - implement  #TAUTHOR_TAG\'s sender and receiver architectures ( using their better - behaved "" informed "" sender ).', 'both agents are feed - forward networks.', 'the sender takes image representations as input, it projects them into its own representational space, compares them, and finally outputs a probability distribution over vocabulary symbols, from which a single discrete symbol is then sampled.', 'we report here results obtained with an output vocabulary of 100 symbols, but the same patterns were observed using a range of sizes from 2 to 1, 000.', 'the receiver takes as input the target and distractor input image representations in random order, as well as the symbol produced by the sender ( as a vocabulary - sized one - hot vector ).', 'it embeds the images and the symbol into its own representational space, where it performs a symbol - to - image comparison, producing a probability distribution over the two images, one of which is selected by sampling from this distribution.', 'if the receiver selected the target image, a reward of 1 is assigned to both agents.', 'the whole architecture is jointly trained by letting the agents play, and updating their parameters with reinforce  #AUTHOR_TAG.', 'see  #TAUTHOR_TAG for details.', 'data following  #TAUTHOR_TAG used, we randomly sample 100 images from imagenet  #AUTHOR_TAG.', '']",5
"[""- implement  #TAUTHOR_TAG's sender and""]","[""we re - implement  #TAUTHOR_TAG's sender and""]","[""- implement  #TAUTHOR_TAG's sender and receiver architectures ( using their better -""]","['we re - implement  #TAUTHOR_TAG\'s sender and receiver architectures ( using their better - behaved "" informed "" sender ).', 'both agents are feed - forward networks.', 'the sender takes image representations as input, it projects them into its own representational space, compares them, and finally outputs a probability distribution over vocabulary symbols, from which a single discrete symbol is then sampled.', 'we report here results obtained with an output vocabulary of 100 symbols, but the same patterns were observed using a range of sizes from 2 to 1, 000.', 'the receiver takes as input the target and distractor input image representations in random order, as well as the symbol produced by the sender ( as a vocabulary - sized one - hot vector ).', 'it embeds the images and the symbol into its own representational space, where it performs a symbol - to - image comparison, producing a probability distribution over the two images, one of which is selected by sampling from this distribution.', 'if the receiver selected the target image, a reward of 1 is assigned to both agents.', 'the whole architecture is jointly trained by letting the agents play, and updating their parameters with reinforce  #AUTHOR_TAG.', 'see  #TAUTHOR_TAG for details.', 'data following  #TAUTHOR_TAG used, we randomly sample 100 images from imagenet  #AUTHOR_TAG.', '']",5
"[""- implement  #TAUTHOR_TAG's sender and""]","[""we re - implement  #TAUTHOR_TAG's sender and""]","[""- implement  #TAUTHOR_TAG's sender and receiver architectures ( using their better -""]","['we re - implement  #TAUTHOR_TAG\'s sender and receiver architectures ( using their better - behaved "" informed "" sender ).', 'both agents are feed - forward networks.', 'the sender takes image representations as input, it projects them into its own representational space, compares them, and finally outputs a probability distribution over vocabulary symbols, from which a single discrete symbol is then sampled.', 'we report here results obtained with an output vocabulary of 100 symbols, but the same patterns were observed using a range of sizes from 2 to 1, 000.', 'the receiver takes as input the target and distractor input image representations in random order, as well as the symbol produced by the sender ( as a vocabulary - sized one - hot vector ).', 'it embeds the images and the symbol into its own representational space, where it performs a symbol - to - image comparison, producing a probability distribution over the two images, one of which is selected by sampling from this distribution.', 'if the receiver selected the target image, a reward of 1 is assigned to both agents.', 'the whole architecture is jointly trained by letting the agents play, and updating their parameters with reinforce  #AUTHOR_TAG.', 'see  #TAUTHOR_TAG for details.', 'data following  #TAUTHOR_TAG used, we randomly sample 100 images from imagenet  #AUTHOR_TAG.', '']",3
"[""- implement  #TAUTHOR_TAG's sender and""]","[""we re - implement  #TAUTHOR_TAG's sender and""]","[""- implement  #TAUTHOR_TAG's sender and receiver architectures ( using their better -""]","['we re - implement  #TAUTHOR_TAG\'s sender and receiver architectures ( using their better - behaved "" informed "" sender ).', 'both agents are feed - forward networks.', 'the sender takes image representations as input, it projects them into its own representational space, compares them, and finally outputs a probability distribution over vocabulary symbols, from which a single discrete symbol is then sampled.', 'we report here results obtained with an output vocabulary of 100 symbols, but the same patterns were observed using a range of sizes from 2 to 1, 000.', 'the receiver takes as input the target and distractor input image representations in random order, as well as the symbol produced by the sender ( as a vocabulary - sized one - hot vector ).', 'it embeds the images and the symbol into its own representational space, where it performs a symbol - to - image comparison, producing a probability distribution over the two images, one of which is selected by sampling from this distribution.', 'if the receiver selected the target image, a reward of 1 is assigned to both agents.', 'the whole architecture is jointly trained by letting the agents play, and updating their parameters with reinforce  #AUTHOR_TAG.', 'see  #TAUTHOR_TAG for details.', 'data following  #TAUTHOR_TAG used, we randomly sample 100 images from imagenet  #AUTHOR_TAG.', '']",3
"[""- implement  #TAUTHOR_TAG's sender and""]","[""we re - implement  #TAUTHOR_TAG's sender and""]","[""- implement  #TAUTHOR_TAG's sender and receiver architectures ( using their better -""]","['we re - implement  #TAUTHOR_TAG\'s sender and receiver architectures ( using their better - behaved "" informed "" sender ).', 'both agents are feed - forward networks.', 'the sender takes image representations as input, it projects them into its own representational space, compares them, and finally outputs a probability distribution over vocabulary symbols, from which a single discrete symbol is then sampled.', 'we report here results obtained with an output vocabulary of 100 symbols, but the same patterns were observed using a range of sizes from 2 to 1, 000.', 'the receiver takes as input the target and distractor input image representations in random order, as well as the symbol produced by the sender ( as a vocabulary - sized one - hot vector ).', 'it embeds the images and the symbol into its own representational space, where it performs a symbol - to - image comparison, producing a probability distribution over the two images, one of which is selected by sampling from this distribution.', 'if the receiver selected the target image, a reward of 1 is assigned to both agents.', 'the whole architecture is jointly trained by letting the agents play, and updating their parameters with reinforce  #AUTHOR_TAG.', 'see  #TAUTHOR_TAG for details.', 'data following  #TAUTHOR_TAG used, we randomly sample 100 images from imagenet  #AUTHOR_TAG.', '']",3
,,,,3
,,,,0
,,,,0
"['of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were']","['of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were']","['of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were found and grouped into 16 groups.', 'the imbalance of the relations is a natural characteristic in discourse and, to avoid overfitting of a learning model on the lessfrequent relations, no balancing was']","['- dt ( rst discourse treebank )  #AUTHOR_TAG is the most widely used corpus annotated with rst in english.', 'table 1 compares it with available portuguese corpora labeled according to rst ( these corpora will be referred to as rst - dt - pt hereafter ).', 'the corpora cstnews  #AUTHOR_TAG, summ - it  #AUTHOR_TAG and two - thirds of rhetalho ( pardo and seno, ( 45 ) and many more words ( 55, 536 ) than rst - dt - pt.', 'this work focuses on the identification of rhetorical relations at the sentence level, and as is common since the work of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were found and grouped into 16 groups.', 'the imbalance of the relations is a natural characteristic in discourse and, to avoid overfitting of a learning model on the lessfrequent relations, no balancing was made.', 'the relation summary, for example, occurs only 2 times, and elaboration occurs 1491 times, making very difficult the identification of the summary relation']",0
[' #TAUTHOR_TAG and for portuguese the parser most similar to'],['information is crucial in spade  #TAUTHOR_TAG and for portuguese the parser most similar to'],['information is crucial in spade  #TAUTHOR_TAG and for portuguese the parser most similar to'],"['information is crucial in spade  #TAUTHOR_TAG and for portuguese the parser most similar to that used by soricut and marcu is the lx - parser ( stanford parser trained to portuguese  #AUTHOR_TAG ).', 'after the parsing of the text by the syntactic parser, the same lexicalization procedure  #AUTHOR_TAG was applied and adapted according to the tagset used by lx - parser.', 'in this adaptation, only pairs of adjacent segments at sentence - level were considered, and nuclearity was not considered, in order to avoid sparseness in the data.', 'training the adapted model ( here called spade - pt ) using the rst - dt - pt achieved f - measure of 0. 30.', 'the precision was 0. 69, but the recall was only 0. 19.', 'the same features used by hilda  #AUTHOR_TAG were extracted from the pairs of adjacent segments at sentence - level and many machine learning algorithms were tested, besides the svm, which was used in the original work.', 'the algorithm which obtained the best f - measure was j48, an implementation of decision trees  #AUTHOR_TAG.', 'the rst - dt - pt corpora was used and the adaptation ( here called of hilda - pt ) achieved an f - measure of 0. 548, which is much better than that of spade - pt.', 'a possible explanation is that the feature set in spade is composed only of syntactic tags and words.', 'the resulting probabilistic model is sparse and many equal instances may indicate different relations ( classes ).', 'however hilda adds more features over which the classifier can work better, even when some values are absent.', 'given the results of the adapted models, hilda - pt was chosen to be incorporated into the ssnel, explicated below']",0
"[' #TAUTHOR_TAG or  #AUTHOR_TAG', ',']","[' #TAUTHOR_TAG or  #AUTHOR_TAG', ',']","[' #TAUTHOR_TAG or  #AUTHOR_TAG', ',']","['', '##nel for english was realized in order to see the results that could be obtained when large annotated corpora are', 'available. in the ssnel for english, only decision - tree classifiers were used', 'to classify new instances. for portuguese, a symbolic model ( lexical patterns ) was also used together with the classifiers. the improved results presented in table 2 and 3 are very different due to differing evaluation strategies.', 'using separated test data, we tried to avoid possible overfitting on training data, but the size', 'of test data may not lead to a fair evaluation  #TAUTHOR_TAG or  #AUTHOR_TAG', ', since hilda - pt used different corpora ( rst -', 'dt - pt instead of rst - dt ), and some reported results are for the complete dp. however, our results show the potential of the ssnel workflow when not enough labeled data is', 'available for supervised learning, since the same', 'approach for relation identification of  #AUTHOR_TAG was used in hilda - pt and 0. 531 was initially obtained. these results constitute the state of art for rhetorical relation identification for portuguese and it is believed that with more time ( iterations in ssnel ),', 'the results may increase']",0
,,,,1
"[' #TAUTHOR_TAG and  #AUTHOR_TAG.', 'this choice for sslnel was']","[' #TAUTHOR_TAG and  #AUTHOR_TAG.', 'this choice for sslnel was']","[' #TAUTHOR_TAG and  #AUTHOR_TAG.', 'this choice for sslnel was made considering the large and free availability of news texts on the web']","['the above cited approaches to dp use annotated data to extract discursive knowledge and are limited to the availability of this resource, which is expensive to obtain.', 'specially, it is important to note that, to obtain good performance in the task more data is necessary.', 'semi - supervised learning ( ssl ) is employed in scenarios in which there is some labeled data and large availability of unlabeled data, and manual annotation is an expensive task  #AUTHOR_TAG.', 'related to the use of ssl in dp,  #AUTHOR_TAG used naive bayes to train binary classifiers to distinguish between some types of relations, as elaboration vs. cause - explanationevidence.', 'for example, for this binary classifier, applying ssl, the accuracy increased from approximately 0. 6 to 0. 95 after the use of millions of new instances.', ' #AUTHOR_TAG used ssl to develop a probabilistic model mapping the occurrence of discourse markers and verbs to rhetorical relations.', ' #AUTHOR_TAG conducted work in the same direction.', ' #AUTHOR_TAG performed similar work to marcu and echihabi, with similar results for a different set of relations and a more sophisticated classifier.', 'building on this, there is an interesting idea, known as never - ending learning ( nel ) by  #AUTHOR_TAG, in which they apply ssl with infinite unlabeled data.', 'the needed data is widely and freely available on the web.', 'their architecture runs 24 hours per day, forever, obtaining new information and performing a learning task.', 'with the aim of surpassing the limitation of labeled rst in portuguese to develop a good dp, we employ ssnel in the task by adapting the work of  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'this choice for sslnel was made considering the large and free availability of news texts on the web']",5
"['of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were']","['of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were']","['of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were found and grouped into 16 groups.', 'the imbalance of the relations is a natural characteristic in discourse and, to avoid overfitting of a learning model on the lessfrequent relations, no balancing was']","['- dt ( rst discourse treebank )  #AUTHOR_TAG is the most widely used corpus annotated with rst in english.', 'table 1 compares it with available portuguese corpora labeled according to rst ( these corpora will be referred to as rst - dt - pt hereafter ).', 'the corpora cstnews  #AUTHOR_TAG, summ - it  #AUTHOR_TAG and two - thirds of rhetalho ( pardo and seno, ( 45 ) and many more words ( 55, 536 ) than rst - dt - pt.', 'this work focuses on the identification of rhetorical relations at the sentence level, and as is common since the work of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were found and grouped into 16 groups.', 'the imbalance of the relations is a natural characteristic in discourse and, to avoid overfitting of a learning model on the lessfrequent relations, no balancing was made.', 'the relation summary, for example, occurs only 2 times, and elaboration occurs 1491 times, making very difficult the identification of the summary relation']",5
[' #TAUTHOR_TAG and for portuguese the parser most similar to'],['information is crucial in spade  #TAUTHOR_TAG and for portuguese the parser most similar to'],['information is crucial in spade  #TAUTHOR_TAG and for portuguese the parser most similar to'],"['information is crucial in spade  #TAUTHOR_TAG and for portuguese the parser most similar to that used by soricut and marcu is the lx - parser ( stanford parser trained to portuguese  #AUTHOR_TAG ).', 'after the parsing of the text by the syntactic parser, the same lexicalization procedure  #AUTHOR_TAG was applied and adapted according to the tagset used by lx - parser.', 'in this adaptation, only pairs of adjacent segments at sentence - level were considered, and nuclearity was not considered, in order to avoid sparseness in the data.', 'training the adapted model ( here called spade - pt ) using the rst - dt - pt achieved f - measure of 0. 30.', 'the precision was 0. 69, but the recall was only 0. 19.', 'the same features used by hilda  #AUTHOR_TAG were extracted from the pairs of adjacent segments at sentence - level and many machine learning algorithms were tested, besides the svm, which was used in the original work.', 'the algorithm which obtained the best f - measure was j48, an implementation of decision trees  #AUTHOR_TAG.', 'the rst - dt - pt corpora was used and the adaptation ( here called of hilda - pt ) achieved an f - measure of 0. 548, which is much better than that of spade - pt.', 'a possible explanation is that the feature set in spade is composed only of syntactic tags and words.', 'the resulting probabilistic model is sparse and many equal instances may indicate different relations ( classes ).', 'however hilda adds more features over which the classifier can work better, even when some values are absent.', 'given the results of the adapted models, hilda - pt was chosen to be incorporated into the ssnel, explicated below']",5
"['of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were']","['of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were']","['of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were found and grouped into 16 groups.', 'the imbalance of the relations is a natural characteristic in discourse and, to avoid overfitting of a learning model on the lessfrequent relations, no balancing was']","['- dt ( rst discourse treebank )  #AUTHOR_TAG is the most widely used corpus annotated with rst in english.', 'table 1 compares it with available portuguese corpora labeled according to rst ( these corpora will be referred to as rst - dt - pt hereafter ).', 'the corpora cstnews  #AUTHOR_TAG, summ - it  #AUTHOR_TAG and two - thirds of rhetalho ( pardo and seno, ( 45 ) and many more words ( 55, 536 ) than rst - dt - pt.', 'this work focuses on the identification of rhetorical relations at the sentence level, and as is common since the work of  #TAUTHOR_TAG, fine - grained relations were grouped : 29 sentence - level rhetorical relations were found and grouped into 16 groups.', 'the imbalance of the relations is a natural characteristic in discourse and, to avoid overfitting of a learning model on the lessfrequent relations, no balancing was made.', 'the relation summary, for example, occurs only 2 times, and elaboration occurs 1491 times, making very difficult the identification of the summary relation']",3
[';  #TAUTHOR_TAG'],['2008 ;  #TAUTHOR_TAG'],"[', 2008 ;  #TAUTHOR_TAG.', 'in']","['##ability assessment refers to the task of ( automatically ) linking a text to the appropriate target audience based on its complexity.', 'a diverse spectrum of potential application domains has been identified for this task in the literature, ranging from the design and evaluation of education materials, to information retrieval, and text simplification.', 'given the increasing need for learning material adapted to different audiences and the barrier - free access to information required for political and social participation, automatic readability assessment is of immediate social relevance.', 'accordingly, it has attracted considerable research interest over the last decades, particularly for the assessment of english  #AUTHOR_TAG.', 'for german readability assessment, however, little progress has been made in recent years, despite a series of promising results published around the turn of the decade ( vor der bruck et al., 2008 ;  #TAUTHOR_TAG.', 'in particular, german readability research has suffered from the lack of a shared reference corpus and sufficiently comparable corpora for cross - corpus testing of readability models : while for english research, the common core corpus consisting of examples from the english language arts standards of the common core state standards, and the weeklyreader corpus of online news articles have been widely used in studies on english readability and text simplification  #AUTHOR_TAG, there are no comparable resources for german.', 'this is particularly problematic, as over - fitting is a potential issue for classification algorithms, especially given the limited size of the typical data sets.', ""to address these issues, we first present two new data sets for german readability assessment in section 3 : a set of german news broadcast subtitles based on the primary german tv news outlet tagesschau and the children's counterpart logo!, and a geo / geolino corpus crawled from the educational geo magazine's web site, a source first identified by  #TAUTHOR_TAG, but double in size."", '1 the longstanding success of these outlets with their target audiences provides some external validity to the nature of the implicit linguistic adaptation of the language used.', 'as showed for german secondary school textbooks, this is not necessarily the case across all linguistic dimensions and adjustments may even be limited to only the surface level of text, sentence, and word length.', 'we conducted a series of analyses on these two data sets to accomplish the following objectives :', '1. investigate how instances of german educational news language differ in terms of language complexity across adult and child target audiences.', '2. build a binary readability model for german educational language targeting adults and children that shows high, robust classification performance across corpora.', 'for the purposes of our studies, we operationalize child']",0
"[';  #TAUTHOR_TAG, but also russian', ' #AUTHOR_TAG or french ( francois and  #AUTHOR_TAG.']","[';  #TAUTHOR_TAG, but also russian', ' #AUTHOR_TAG or french ( francois and  #AUTHOR_TAG.']","[';  #TAUTHOR_TAG, but also russian', ' #AUTHOR_TAG or french ( francois and  #AUTHOR_TAG.']","['than pos features,  #AUTHOR_TAG conduct an elaborate cross - corpus study on the use of word frequency features for readability assessment. they show, that the typical aggregation of word frequencies across documents are less informative than richer representations including frequency standard deviations.', 'in contrast to english, research on readability assessment for other languages, such as german, is more limited. there was a series of articles on this issue from the late 2000s to the early 2010s that demonstrated', 'the benefits of broad linguistic modeling, in particular the use of morphological complexity measures for languages with rich morphological systems like german ( vor der bruck et al., 2008 ;  #TAUTHOR_TAG, but also russian', ' #AUTHOR_TAG or french ( francois and  #AUTHOR_TAG. the readability checker delite of vor der bruck et al. ( 2008 ) is one of the first more sophisticated approaches', 'that went beyond using simple readability formulas for german. the tool employs morphological, lexical, syntactical, semantic, and discourse measures, which they trained on municipal administration texts', 'rated for their readability by humans in an online readability study involving 500 texts and 300 participant, resulting in overall 3', ', 000 ratings. however, due to the specific nature of the data, the robustness of', 'the approach across genres is unclear. municipal administration language is so particular that results are unlikely to generalize to educational or literary materials, which are more attractive in first and', 'second language acquisition contexts. later work by  #TAUTHOR_TAG also combines traditional readability formula measures, such as text or word length', ', with more sophisticated lexical, syntactic, and language model, and morphological features to assess german readability, but', ""they employ an overall broader and more diverse feature set than delite. they investigate readability of educational magazines on the geo / geolino data set, which they compiled from online articles freely available at the geo magazine's web page. their work illustrates the relevance of rich linguistic modeling for readability assessment and in particular the value of morphological"", 'complexity features for german. the latest large scale research endeavor for the assessment of german text readability has focused more on identifying linguistic differences between texts targeting different audiences than on building', 'readability models : in the reading demands project, complexity differences in german secondary school book texts across grade levels and school types were investigated. and analyze to which extent publishers successfully adapt their reading material to their target audiences. they find a lack of consistent adaptation', 'for passive constructions, concessive and adversative connectives, and relative clauses, and only some limited adaptation', 'in terms of lexical variation, noun complexity, and dependency length measures']",0
"[';  #TAUTHOR_TAG, but also russian', ' #AUTHOR_TAG or french ( francois and  #AUTHOR_TAG.']","[';  #TAUTHOR_TAG, but also russian', ' #AUTHOR_TAG or french ( francois and  #AUTHOR_TAG.']","[';  #TAUTHOR_TAG, but also russian', ' #AUTHOR_TAG or french ( francois and  #AUTHOR_TAG.']","['than pos features,  #AUTHOR_TAG conduct an elaborate cross - corpus study on the use of word frequency features for readability assessment. they show, that the typical aggregation of word frequencies across documents are less informative than richer representations including frequency standard deviations.', 'in contrast to english, research on readability assessment for other languages, such as german, is more limited. there was a series of articles on this issue from the late 2000s to the early 2010s that demonstrated', 'the benefits of broad linguistic modeling, in particular the use of morphological complexity measures for languages with rich morphological systems like german ( vor der bruck et al., 2008 ;  #TAUTHOR_TAG, but also russian', ' #AUTHOR_TAG or french ( francois and  #AUTHOR_TAG. the readability checker delite of vor der bruck et al. ( 2008 ) is one of the first more sophisticated approaches', 'that went beyond using simple readability formulas for german. the tool employs morphological, lexical, syntactical, semantic, and discourse measures, which they trained on municipal administration texts', 'rated for their readability by humans in an online readability study involving 500 texts and 300 participant, resulting in overall 3', ', 000 ratings. however, due to the specific nature of the data, the robustness of', 'the approach across genres is unclear. municipal administration language is so particular that results are unlikely to generalize to educational or literary materials, which are more attractive in first and', 'second language acquisition contexts. later work by  #TAUTHOR_TAG also combines traditional readability formula measures, such as text or word length', ', with more sophisticated lexical, syntactic, and language model, and morphological features to assess german readability, but', ""they employ an overall broader and more diverse feature set than delite. they investigate readability of educational magazines on the geo / geolino data set, which they compiled from online articles freely available at the geo magazine's web page. their work illustrates the relevance of rich linguistic modeling for readability assessment and in particular the value of morphological"", 'complexity features for german. the latest large scale research endeavor for the assessment of german text readability has focused more on identifying linguistic differences between texts targeting different audiences than on building', 'readability models : in the reading demands project, complexity differences in german secondary school book texts across grade levels and school types were investigated. and analyze to which extent publishers successfully adapt their reading material to their target audiences. they find a lack of consistent adaptation', 'for passive constructions, concessive and adversative connectives, and relative clauses, and only some limited adaptation', 'in terms of lexical variation, noun complexity, and dependency length measures']",0
"['of topics ranging from culture and history to technology and nature.', ' #TAUTHOR_TAG first compiled']","['of topics ranging from culture and history to technology and nature.', ' #TAUTHOR_TAG first compiled']","['cover a variety of topics ranging from culture and history to technology and nature.', ' #TAUTHOR_TAG first compiled']","['', '3 they are comparable to the national geographic magazine and cover a variety of topics ranging from culture and history to technology and nature.', ' #TAUTHOR_TAG first compiled and analyzed a data set from this web resource.', 'we followed their lead and crawled 8, 263 articles from the geo / geolino online archive, almost doubling the size of the original corpus.', 'we removed all material flagged as non - article contents by geo as well as all articles that contained less than 15 words.', 'we further cleaned our data from crawling artifacts and performed near - duplicate detection with the simhash algorithm.', 'we then grouped all texts into topic categories based on the subdomains they were published under, following the web page topic structure.', '4 table 1 shows the composition of the corpus in terms of the topic groups.', 'since the number of documents in the different topic groups differ between geo and the smaller geolino set, we created a more balanced subset ( geo / geolino s ).', 'for this, we included only topic categories existing in both geo and geolino, included all geolino texts in those categories and sampled from the geo texts in those categories until we reached the same overall size of 2480 texts each.', 'table 1 : distribution of topics in the full and sampled geo / geolino data set']",0
[';  #TAUTHOR_TAG'],['2008 ;  #TAUTHOR_TAG'],"[', 2008 ;  #TAUTHOR_TAG.', 'in']","['##ability assessment refers to the task of ( automatically ) linking a text to the appropriate target audience based on its complexity.', 'a diverse spectrum of potential application domains has been identified for this task in the literature, ranging from the design and evaluation of education materials, to information retrieval, and text simplification.', 'given the increasing need for learning material adapted to different audiences and the barrier - free access to information required for political and social participation, automatic readability assessment is of immediate social relevance.', 'accordingly, it has attracted considerable research interest over the last decades, particularly for the assessment of english  #AUTHOR_TAG.', 'for german readability assessment, however, little progress has been made in recent years, despite a series of promising results published around the turn of the decade ( vor der bruck et al., 2008 ;  #TAUTHOR_TAG.', 'in particular, german readability research has suffered from the lack of a shared reference corpus and sufficiently comparable corpora for cross - corpus testing of readability models : while for english research, the common core corpus consisting of examples from the english language arts standards of the common core state standards, and the weeklyreader corpus of online news articles have been widely used in studies on english readability and text simplification  #AUTHOR_TAG, there are no comparable resources for german.', 'this is particularly problematic, as over - fitting is a potential issue for classification algorithms, especially given the limited size of the typical data sets.', ""to address these issues, we first present two new data sets for german readability assessment in section 3 : a set of german news broadcast subtitles based on the primary german tv news outlet tagesschau and the children's counterpart logo!, and a geo / geolino corpus crawled from the educational geo magazine's web site, a source first identified by  #TAUTHOR_TAG, but double in size."", '1 the longstanding success of these outlets with their target audiences provides some external validity to the nature of the implicit linguistic adaptation of the language used.', 'as showed for german secondary school textbooks, this is not necessarily the case across all linguistic dimensions and adjustments may even be limited to only the surface level of text, sentence, and word length.', 'we conducted a series of analyses on these two data sets to accomplish the following objectives :', '1. investigate how instances of german educational news language differ in terms of language complexity across adult and child target audiences.', '2. build a binary readability model for german educational language targeting adults and children that shows high, robust classification performance across corpora.', 'for the purposes of our studies, we operationalize child']",6
['in  #TAUTHOR_TAG in'],['in  #TAUTHOR_TAG in'],['in  #TAUTHOR_TAG in'],[' #TAUTHOR_TAG'],6
"['of topics ranging from culture and history to technology and nature.', ' #TAUTHOR_TAG first compiled']","['of topics ranging from culture and history to technology and nature.', ' #TAUTHOR_TAG first compiled']","['cover a variety of topics ranging from culture and history to technology and nature.', ' #TAUTHOR_TAG first compiled']","['', '3 they are comparable to the national geographic magazine and cover a variety of topics ranging from culture and history to technology and nature.', ' #TAUTHOR_TAG first compiled and analyzed a data set from this web resource.', 'we followed their lead and crawled 8, 263 articles from the geo / geolino online archive, almost doubling the size of the original corpus.', 'we removed all material flagged as non - article contents by geo as well as all articles that contained less than 15 words.', 'we further cleaned our data from crawling artifacts and performed near - duplicate detection with the simhash algorithm.', 'we then grouped all texts into topic categories based on the subdomains they were published under, following the web page topic structure.', '4 table 1 shows the composition of the corpus in terms of the topic groups.', 'since the number of documents in the different topic groups differ between geo and the smaller geolino set, we created a more balanced subset ( geo / geolino s ).', 'for this, we included only topic categories existing in both geo and geolino, included all geolino texts in those categories and sampled from the geo texts in those categories until we reached the same overall size of 2480 texts each.', 'table 1 : distribution of topics in the full and sampled geo / geolino data set']",5
['observed by  #TAUTHOR_TAG on'],['observed by  #TAUTHOR_TAG on'],"['observed by  #TAUTHOR_TAG on the original geo / geolino data.', '11 as table 7a shows, erroneous classifications are roughly balanced']","['', 'on geo / geolino s, the performance is comparable to the performance observed by  #TAUTHOR_TAG on the original geo / geolino data.', '11 as table 7a shows, erroneous classifications are roughly balanced across both classes, showing that the model does not prefer one class over the other.', 'when training a model using only the 20 most informative measures identified in study 1, we reach an accuracy of 85. 1 %, i. e., the additional measures only account only for 3. 3 %.', '12 when testing the models on the tagesschau / logo corpus, accuracy increases to 98. 8 % for both models.', 'the confusion matrix for the model using 400 measures in table 7b table 7 : confusion matrices for testing models with 400 features trained on geo / geolino s']",3
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",0
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",0
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",0
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",0
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",0
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",0
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",0
"['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', 'in english,']","['has evolved continually over the centuries, in the branching off from antecedent languages in indo - european prehistory [ 34, 39 ], in the rates of regularisation of verbs [ 34 ] and in the waxing and waning in the popularity of individual words [ 3, 13, 37 ].', 'at a much finer scale of time and population, languages change through modifications and errors in the learning process [ 14, 27 ].', ""this continual change and diversity contrasts with the simplicity and consistency of zipf's law, by which the frequency a word, f, is inversely proportional to its rank k, as f ∼ k −γ and heaps law, by which vocabulary size scales sub - linearly with total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG."", 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', ""in english, the zipf's law in the n - gram data [ 41 ] exhibits two regimes : one among words with frequencies above about 0. 01 % ( zipf's exponent γ ≈ 1 ) and another ( γ ≈ 1. 4 ) among words with frequency below 0. 0001 %  #TAUTHOR_TAG."", ""the latter zipf's law exponent γ of 1. 4 is equivalent to a probability distribution function ( pdf ) exponent, α, of about 1. 7 ( α = 1 + 1 / γ )."", ""in addition to the well - known zipf's law, word frequency data have at least two other statistical properties."", 'one, known as heaps law, refers to the way that vocabulary size scales sub - linearly with corpus size ( raw word count ).', 'the n - gram data show heaps law in that, if n t is corpus size and v t is vocabulary size at time t, then v t ≈ n β t, with β ≈ 0. 5, for all english words in the corpus  #TAUTHOR_TAG.', 'if the n - gram corpus is truncated by a minimum word count, then as that minimum is raised the heaps scaling exponent increases from β < 0. 5, approaching β < 1  #TAUTHOR_TAG.', '']",0
"['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', 'in english,']","['has evolved continually over the centuries, in the branching off from antecedent languages in indo - european prehistory [ 34, 39 ], in the rates of regularisation of verbs [ 34 ] and in the waxing and waning in the popularity of individual words [ 3, 13, 37 ].', 'at a much finer scale of time and population, languages change through modifications and errors in the learning process [ 14, 27 ].', ""this continual change and diversity contrasts with the simplicity and consistency of zipf's law, by which the frequency a word, f, is inversely proportional to its rank k, as f ∼ k −γ and heaps law, by which vocabulary size scales sub - linearly with total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG."", 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', ""in english, the zipf's law in the n - gram data [ 41 ] exhibits two regimes : one among words with frequencies above about 0. 01 % ( zipf's exponent γ ≈ 1 ) and another ( γ ≈ 1. 4 ) among words with frequency below 0. 0001 %  #TAUTHOR_TAG."", ""the latter zipf's law exponent γ of 1. 4 is equivalent to a probability distribution function ( pdf ) exponent, α, of about 1. 7 ( α = 1 + 1 / γ )."", ""in addition to the well - known zipf's law, word frequency data have at least two other statistical properties."", 'one, known as heaps law, refers to the way that vocabulary size scales sub - linearly with corpus size ( raw word count ).', 'the n - gram data show heaps law in that, if n t is corpus size and v t is vocabulary size at time t, then v t ≈ n β t, with β ≈ 0. 5, for all english words in the corpus  #TAUTHOR_TAG.', 'if the n - gram corpus is truncated by a minimum word count, then as that minimum is raised the heaps scaling exponent increases from β < 0. 5, approaching β < 1  #TAUTHOR_TAG.', '']",0
"['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', 'in english,']","['has evolved continually over the centuries, in the branching off from antecedent languages in indo - european prehistory [ 34, 39 ], in the rates of regularisation of verbs [ 34 ] and in the waxing and waning in the popularity of individual words [ 3, 13, 37 ].', 'at a much finer scale of time and population, languages change through modifications and errors in the learning process [ 14, 27 ].', ""this continual change and diversity contrasts with the simplicity and consistency of zipf's law, by which the frequency a word, f, is inversely proportional to its rank k, as f ∼ k −γ and heaps law, by which vocabulary size scales sub - linearly with total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG."", 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', ""in english, the zipf's law in the n - gram data [ 41 ] exhibits two regimes : one among words with frequencies above about 0. 01 % ( zipf's exponent γ ≈ 1 ) and another ( γ ≈ 1. 4 ) among words with frequency below 0. 0001 %  #TAUTHOR_TAG."", ""the latter zipf's law exponent γ of 1. 4 is equivalent to a probability distribution function ( pdf ) exponent, α, of about 1. 7 ( α = 1 + 1 / γ )."", ""in addition to the well - known zipf's law, word frequency data have at least two other statistical properties."", 'one, known as heaps law, refers to the way that vocabulary size scales sub - linearly with corpus size ( raw word count ).', 'the n - gram data show heaps law in that, if n t is corpus size and v t is vocabulary size at time t, then v t ≈ n β t, with β ≈ 0. 5, for all english words in the corpus  #TAUTHOR_TAG.', 'if the n - gram corpus is truncated by a minimum word count, then as that minimum is raised the heaps scaling exponent increases from β < 0. 5, approaching β < 1  #TAUTHOR_TAG.', '']",0
"['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', 'in english,']","['has evolved continually over the centuries, in the branching off from antecedent languages in indo - european prehistory [ 34, 39 ], in the rates of regularisation of verbs [ 34 ] and in the waxing and waning in the popularity of individual words [ 3, 13, 37 ].', 'at a much finer scale of time and population, languages change through modifications and errors in the learning process [ 14, 27 ].', ""this continual change and diversity contrasts with the simplicity and consistency of zipf's law, by which the frequency a word, f, is inversely proportional to its rank k, as f ∼ k −γ and heaps law, by which vocabulary size scales sub - linearly with total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG."", 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', ""in english, the zipf's law in the n - gram data [ 41 ] exhibits two regimes : one among words with frequencies above about 0. 01 % ( zipf's exponent γ ≈ 1 ) and another ( γ ≈ 1. 4 ) among words with frequency below 0. 0001 %  #TAUTHOR_TAG."", ""the latter zipf's law exponent γ of 1. 4 is equivalent to a probability distribution function ( pdf ) exponent, α, of about 1. 7 ( α = 1 + 1 / γ )."", ""in addition to the well - known zipf's law, word frequency data have at least two other statistical properties."", 'one, known as heaps law, refers to the way that vocabulary size scales sub - linearly with corpus size ( raw word count ).', 'the n - gram data show heaps law in that, if n t is corpus size and v t is vocabulary size at time t, then v t ≈ n β t, with β ≈ 0. 5, for all english words in the corpus  #TAUTHOR_TAG.', 'if the n - gram corpus is truncated by a minimum word count, then as that minimum is raised the heaps scaling exponent increases from β < 0. 5, approaching β < 1  #TAUTHOR_TAG.', '']",0
"['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', 'in english,']","['has evolved continually over the centuries, in the branching off from antecedent languages in indo - european prehistory [ 34, 39 ], in the rates of regularisation of verbs [ 34 ] and in the waxing and waning in the popularity of individual words [ 3, 13, 37 ].', 'at a much finer scale of time and population, languages change through modifications and errors in the learning process [ 14, 27 ].', ""this continual change and diversity contrasts with the simplicity and consistency of zipf's law, by which the frequency a word, f, is inversely proportional to its rank k, as f ∼ k −γ and heaps law, by which vocabulary size scales sub - linearly with total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG."", 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', ""in english, the zipf's law in the n - gram data [ 41 ] exhibits two regimes : one among words with frequencies above about 0. 01 % ( zipf's exponent γ ≈ 1 ) and another ( γ ≈ 1. 4 ) among words with frequency below 0. 0001 %  #TAUTHOR_TAG."", ""the latter zipf's law exponent γ of 1. 4 is equivalent to a probability distribution function ( pdf ) exponent, α, of about 1. 7 ( α = 1 + 1 / γ )."", ""in addition to the well - known zipf's law, word frequency data have at least two other statistical properties."", 'one, known as heaps law, refers to the way that vocabulary size scales sub - linearly with corpus size ( raw word count ).', 'the n - gram data show heaps law in that, if n t is corpus size and v t is vocabulary size at time t, then v t ≈ n β t, with β ≈ 0. 5, for all english words in the corpus  #TAUTHOR_TAG.', 'if the n - gram corpus is truncated by a minimum word count, then as that minimum is raised the heaps scaling exponent increases from β < 0. 5, approaching β < 1  #TAUTHOR_TAG.', '']",0
,,,,0
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",3
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",3
,,,,3
"['-', 'observed in different english 1 - gram corpora  #TAUTHOR_TAG. among all features']","['. 54 -', 'observed in different english 1 - gram corpora  #TAUTHOR_TAG. among all features']","['. 54 -', 'observed in different english 1 - gram corpora  #TAUTHOR_TAG. among all features']","['and also because turnover in fnm should increase slightly with growing population, not decrease as we see in the 1 - gram data over 300 years. other hypotheses to modify the fnm, such as introducing', 'a conformity bias [ 2 ], can also be ruled out. in the case of conform', '##ity bias - where agents choose high - frequency words with even greater probability than just in proportion to frequency - both the zipf law and turnover deteriorate under strong conformity in ways that mis - match', 'with the data. what did ultimately work very well was our partial - sampling neutral model, or pnm ( fig 1b ), which models a growing sample from a fixed - sized fnm. our pnm, which takes exponentially increasing', ""sample sizes from a neutrally evolved latent population, replicated the zipf's law, heaps law, and turnover patterns in the 1 - gram data. although it did not replicate exactly the particular 1 - gram corpus we used here, the heaps law exponent yielded by the pnm does fall within the range - from 0. 44 to 0. 54 -"", 'observed in different english 1 - gram corpora  #TAUTHOR_TAG. among all features we attempted to replicate, the one mismatch between', '']",3
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",5
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",5
,,,,5
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],['turnover statistics we follow other studies  #TAUTHOR_TAG in being'],['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""1 - gram data are available as csv files directly from google's ngrams site [ 25 ]."", 'as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively.', 'as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using the yearly occurrences of the most common english word, the.', ""although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e. g., myfelf, yourfelf, provifions, increafe, afked etc )."", 'the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english - word - popularity']",5
['turnover statistics we follow other studies  #TAUTHOR_TAG in being ca'],"[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover']","[""turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github.']","[""follow a discrete zipf's law distribution with the probability a word is selected being proportional to the number of copies the word had in the previous population in time"", 'step t − 1 [ 7 ]. the pnm, represented schematically in fig 1, draws an exponentially increasing sample ( with replacement ) from a latent neutrally - evolving can', '##on. we designate the number of words in the sample as st, and the cumulative number of words in the canon as nt, which grows by a fixed number of words in', 'each time step. this exponentially increasing sample, s0e αt, has an initial population size s0 = 3000, growth exponent α = 0. 021, yielding a final sample size s300 = 1', '. 5 million, matching the fnm. the latent population evolves by the rules of the fnm, but with a constant population size of 10000 for each year t ( representing a', 'canonical literature from which the main body of authors sample ). the cumulative canon, nt, thus grows by 10, 000 words per year. the partial sample, st, at time t can copy words from all canonical literature, nt, up to that time step. we set [UNK] = 0. 00', '##3 and run for t = 301 time steps representing years between 1700 and 2000, which are the same parameters used in the fn', ""##m. the 1 - gram data are available as csv files directly from google's ngrams site [ 25 ]. as in a previous study [ 1 ], we removed 1 - grams that are common symbols or numbers, and 1 - grams containing the same consonant three or more times consecutively. as in our other studies [ 1, 8, 6 ], we normalized the count of 1 - grams using"", ""the yearly occurrences of the most common english word, the. although we track 1 - grams from the year 1700, for turnover statistics we follow other studies  #TAUTHOR_TAG in being cautious about the n - grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as's'and'f'( e"", '. g., myfelf, yourfelf, provifions, increafe, afked etc ). the code used for modeling is available at : https : / / github. com / dr2g08 / neutral - evolution - and - turnover - over - centuries - of - english', '- word - popularity']",4
"['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', '']","['total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG.', 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', 'in english,']","['has evolved continually over the centuries, in the branching off from antecedent languages in indo - european prehistory [ 34, 39 ], in the rates of regularisation of verbs [ 34 ] and in the waxing and waning in the popularity of individual words [ 3, 13, 37 ].', 'at a much finer scale of time and population, languages change through modifications and errors in the learning process [ 14, 27 ].', ""this continual change and diversity contrasts with the simplicity and consistency of zipf's law, by which the frequency a word, f, is inversely proportional to its rank k, as f ∼ k −γ and heaps law, by which vocabulary size scales sub - linearly with total number of words, across diverse textual and spoken samples [ 32, 41, 46, 49, 15, 21, 48,  #TAUTHOR_TAG."", 'the google ngram corpus [ 37 ] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [ 22, 41,  #TAUTHOR_TAG 1, 28 ].', 'with annual counts of n - grams - an n - gram being n consecutive character strings, separated by spaces - derived from millions of books over multiple centuries [ 35 ], the n - gram data now covers english books from the year 1500 to year 2008.', ""in english, the zipf's law in the n - gram data [ 41 ] exhibits two regimes : one among words with frequencies above about 0. 01 % ( zipf's exponent γ ≈ 1 ) and another ( γ ≈ 1. 4 ) among words with frequency below 0. 0001 %  #TAUTHOR_TAG."", ""the latter zipf's law exponent γ of 1. 4 is equivalent to a probability distribution function ( pdf ) exponent, α, of about 1. 7 ( α = 1 + 1 / γ )."", ""in addition to the well - known zipf's law, word frequency data have at least two other statistical properties."", 'one, known as heaps law, refers to the way that vocabulary size scales sub - linearly with corpus size ( raw word count ).', 'the n - gram data show heaps law in that, if n t is corpus size and v t is vocabulary size at time t, then v t ≈ n β t, with β ≈ 0. 5, for all english words in the corpus  #TAUTHOR_TAG.', 'if the n - gram corpus is truncated by a minimum word count, then as that minimum is raised the heaps scaling exponent increases from β < 0. 5, approaching β < 1  #TAUTHOR_TAG.', '']",4
"['among', 'the 1 - gram data for english  #TAUTHOR_TAG. in the fnm, the expected exponent β is 1']","['. 5 among', 'the 1 - gram data for english  #TAUTHOR_TAG. in the fnm, the expected exponent β is 1. 0, as']","['', 'the 1 - gram data for english  #TAUTHOR_TAG. in the fnm, the expected exponent β is 1']","['and growth of n t. the fnm does not, however, readily yield heaps law ( v t = n β t, where β < 1 ), for which β ≈ 0. 5 among', 'the 1 - gram data for english  #TAUTHOR_TAG. in the fnm, the expected exponent β is 1. 0, as the number of different variants ( vocabulary )', 'normally scales linearly with [UNK] t [ 11 ]. while the fnm has been a powerful null model, in the case of books, we can make a notable improvement to account for the fact that most published material goes unnot', '##iced while a relatively small portion of the corpus is highly visible. to name a few examples across the centuries, literally billions of copies of the bible and the works of shakespear', '##e have been read since the seventeenth century, as well as tens or hundreds of millions of copies of works by voltaire, swift, austen, dickens, tolkien, fleming, rawling and so on', '. while these and hundreds more books become considered part of the "" western canon', '']",4
"['-', 'observed in different english 1 - gram corpora  #TAUTHOR_TAG. among all features']","['. 54 -', 'observed in different english 1 - gram corpora  #TAUTHOR_TAG. among all features']","['. 54 -', 'observed in different english 1 - gram corpora  #TAUTHOR_TAG. among all features']","['and also because turnover in fnm should increase slightly with growing population, not decrease as we see in the 1 - gram data over 300 years. other hypotheses to modify the fnm, such as introducing', 'a conformity bias [ 2 ], can also be ruled out. in the case of conform', '##ity bias - where agents choose high - frequency words with even greater probability than just in proportion to frequency - both the zipf law and turnover deteriorate under strong conformity in ways that mis - match', 'with the data. what did ultimately work very well was our partial - sampling neutral model, or pnm ( fig 1b ), which models a growing sample from a fixed - sized fnm. our pnm, which takes exponentially increasing', ""sample sizes from a neutrally evolved latent population, replicated the zipf's law, heaps law, and turnover patterns in the 1 - gram data. although it did not replicate exactly the particular 1 - gram corpus we used here, the heaps law exponent yielded by the pnm does fall within the range - from 0. 44 to 0. 54 -"", 'observed in different english 1 - gram corpora  #TAUTHOR_TAG. among all features we attempted to replicate, the one mismatch between', '']",4
['tasks  #TAUTHOR_TAG'],['nlp tasks  #TAUTHOR_TAG'],"['as features in various nlp tasks  #TAUTHOR_TAG.', 'while these word representations do capture useful, dense relationships among known and unknown words, one']","['representations and more recently, word embeddings, learned from large amounts of text have been quite successful as features in various nlp tasks  #TAUTHOR_TAG.', '']",0
"['parsing  #TAUTHOR_TAG, inter ali']","['parsing  #TAUTHOR_TAG, inter alia.', 'in']","['parsing  #TAUTHOR_TAG, inter alia.', 'in']","['mentioned earlier, there has been a lot of useful, previous work on using word embeddings for nlp tasks such as similarity, tagging, ner, sentiment analysis, and parsing  #TAUTHOR_TAG, inter alia.', 'in related work,  #TAUTHOR_TAG also use dependency context to tailor word embeddings to dependency parsing.', 'however,  #TAUTHOR_TAG embedding features are still based on the sparse set of n - ary, word - based templates from previous work ( mc  #AUTHOR_TAG a ;  #AUTHOR_TAG.', 'our structured link embeddings achieve similar improvements  #TAUTHOR_TAG ( and better in the case of direct, per - dimension bucket features ) with a substantially smaller and simpler ( unary ) set of features that are aimed to directly capture hidden relationships between the substructures that dependency parsing factors on.', 'moreover, we hope that similar to word embeddings, these link embeddings will also prove useful when imported into various other nlp tasks as dense, continuous features, but now with additional syntactic information.', 'there has also been some recent, useful work on reducing the sparsity of features in dependency parsing, e. g., via low - rank tensors  #AUTHOR_TAG and via neural network parsers that learn tag and label embeddings  #AUTHOR_TAG.', 'in related work, learn dense feature embeddings for dependency parsing ; however, they still work with the large number of manuallydefined feature templates from previous work and train embeddings for all those templates, with an aim to discover hidden, shared information among the large set of sparse features.', 'we get similar improvements with a much smaller and simpler set of unary link features ; also, our link embeddings are more portable to other nlp tasks than template - based embeddings specific to dependency parsing.', 'other work includes learning distributed structured output via dense label vectors  #AUTHOR_TAG, learning bilexical operator embeddings  #AUTHOR_TAG, and learning joint word embeddings and composition functions based on predicate - argument compositionality  #AUTHOR_TAG.', 'our main goal is to directly learn embeddings on linguistically - intuitive units like dependency links, so that they can be used as non - sparse, unary features in dependency parsing, and also as off - theshelf, dense, syntactic features in other nlp tasks ( versus more intrinsic approaches based on feature embeddings or neural network parsers, which are harder to export )']",0
"['based on  #TAUTHOR_TAG follow  #AUTHOR_TAG  #AUTHOR_TAG ).', 'we have another feature that additionally includes the signed, bucketed']","['based on  #TAUTHOR_TAG follow  #AUTHOR_TAG  #AUTHOR_TAG ).', 'we have another feature that additionally includes the signed, bucketed']","['brown cluster features are based on  #TAUTHOR_TAG follow  #AUTHOR_TAG  #AUTHOR_TAG ).', 'we have another feature that additionally includes the signed, bucketed']","['brown cluster features are based on  #TAUTHOR_TAG follow  #AUTHOR_TAG  #AUTHOR_TAG ).', 'we have another feature that additionally includes the signed, bucketed distance of the particular link in the given sentence.', 'also note the difference of our unary bucket features from the binary bucket features of  #TAUTHOR_TAG had to work with pairwise, conjoined features of the head and the argument.', 'hence, they used features on conjunctions of the two bucket values from the head and argument word vectors, firing one pairwise feature per dimension, because firing features on all dimension pairs ( corresponding to an outer product ) led to an infeasible number of features.', 'the result discussion of these feature differences in presented in § 3. 2.', ""bit - string features : we first hierarchically cluster the link vectors via matlab's linkage function with { method = ward, metric = euclidean } to get 0 - 1 bit - strings ( similar to brown )."", ""next, we again fire a small set of unary indicator features that simply con - sist of the link's bit - string prefix, the prefix - length, and another feature that adds the signed, bucketed distance of that link in the sentence."", '']",5
[' #TAUTHOR_TAG skip dep'],[' #TAUTHOR_TAG skip dep result ( 92'],['the  #TAUTHOR_TAG skip dep'],[' #TAUTHOR_TAG'],5
['- art models  #AUTHOR_TAG b ;  #TAUTHOR_TAG have demonstrated large'],"['specified by the instruction ( e. g. the mirror ).', 'recent state - of - the - art models  #AUTHOR_TAG b ;  #TAUTHOR_TAG have demonstrated large']","['g. the mirror ).', 'recent state - of - the - art models  #AUTHOR_TAG b ;  #TAUTHOR_TAG have demonstrated large gains in accuracy on the vln task.', 'however, it is unclear']","['vision - and - language navigation ( vln ) task  #AUTHOR_TAG requires an agent to navigate to a particular location in a real - world environment, following complex, context - dependent instructions written by humans ( e. g. go down the second hallway on the left, enter the bedroom and stop by the mirror ).', 'the agent must navigate through the environment, conditioning on the instruction as well as the visual imagery that it observes along the route, to stop at the location specified by the instruction ( e. g. the mirror ).', 'recent state - of - the - art models  #AUTHOR_TAG b ;  #TAUTHOR_TAG have demonstrated large gains in accuracy on the vln task.', 'however, it is unclear which modality these go past the couch [UNK] figure 1 : we factor the grounding of language instructions into visual appearance, route structure, and object detections using a mixture - of - experts approach.', 'substantial increases in task metrics can be attributed to, and, in particular, whether the gains in performance are due to stronger grounding into visual context or e. g. simply into the discrete, geometric structure of possible routes, such as turning left or moving forward ( see fig.']",0
"['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['. without beam search, pragmatic', ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate']","['refer to the original', ""papers for details on the two models. to analyze the models'visual grounding ability, we focus on their core encoder - decoder components. in our experiments, we use models trained without data augmentation, and during inference predict actions with greedy search ( i. e. without beam search, pragmatic"", ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate how well these models ground instructions into visual features of the environment, by training and evaluating', 'them without access to the visual context : setting their visual feature vectors to zeroes during training and', 'testing. we compare performance on the validation sets of the r2r dataset : the val - seen split', ', consisting of the same environments as in training, and the', 'val - table 1 : success rate ( sr ) of the vision - based full agent ( "" rn "", using resnet ) and the non - visual agent ( "" no vis. "", setting all visual', 'features to zero ) on the r2r dataset under different model architectures (', 'speakerfollower ( sf )  #AUTHOR_TAG b ) and self -', 'monitoring ( sm )  #TAUTHOR_TAG and training schemes. unseen split of novel environments. since we aim to evaluate how', 'well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split. 2 the', ""results are shown in table 1. in each block, the two rows show the agent's"", 'performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn "" : resnet', '- 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and 3 ) outperforms', 'the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent ( lines 6 and 8', '). this indicates that these models do not learn generalizable visual perception, so', 'that the visual features may actually hurt them in unseen environments']",0
"['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['. without beam search, pragmatic', ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate']","['refer to the original', ""papers for details on the two models. to analyze the models'visual grounding ability, we focus on their core encoder - decoder components. in our experiments, we use models trained without data augmentation, and during inference predict actions with greedy search ( i. e. without beam search, pragmatic"", ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate how well these models ground instructions into visual features of the environment, by training and evaluating', 'them without access to the visual context : setting their visual feature vectors to zeroes during training and', 'testing. we compare performance on the validation sets of the r2r dataset : the val - seen split', ', consisting of the same environments as in training, and the', 'val - table 1 : success rate ( sr ) of the vision - based full agent ( "" rn "", using resnet ) and the non - visual agent ( "" no vis. "", setting all visual', 'features to zero ) on the r2r dataset under different model architectures (', 'speakerfollower ( sf )  #AUTHOR_TAG b ) and self -', 'monitoring ( sm )  #TAUTHOR_TAG and training schemes. unseen split of novel environments. since we aim to evaluate how', 'well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split. 2 the', ""results are shown in table 1. in each block, the two rows show the agent's"", 'performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn "" : resnet', '- 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and 3 ) outperforms', 'the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent ( lines 6 and 8', '). this indicates that these models do not learn generalizable visual perception, so', 'that the visual features may actually hurt them in unseen environments']",1
"['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['. without beam search, pragmatic', ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate']","['refer to the original', ""papers for details on the two models. to analyze the models'visual grounding ability, we focus on their core encoder - decoder components. in our experiments, we use models trained without data augmentation, and during inference predict actions with greedy search ( i. e. without beam search, pragmatic"", ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate how well these models ground instructions into visual features of the environment, by training and evaluating', 'them without access to the visual context : setting their visual feature vectors to zeroes during training and', 'testing. we compare performance on the validation sets of the r2r dataset : the val - seen split', ', consisting of the same environments as in training, and the', 'val - table 1 : success rate ( sr ) of the vision - based full agent ( "" rn "", using resnet ) and the non - visual agent ( "" no vis. "", setting all visual', 'features to zero ) on the r2r dataset under different model architectures (', 'speakerfollower ( sf )  #AUTHOR_TAG b ) and self -', 'monitoring ( sm )  #TAUTHOR_TAG and training schemes. unseen split of novel environments. since we aim to evaluate how', 'well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split. 2 the', ""results are shown in table 1. in each block, the two rows show the agent's"", 'performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn "" : resnet', '- 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and 3 ) outperforms', 'the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent ( lines 6 and 8', '). this indicates that these models do not learn generalizable visual perception, so', 'that the visual features may actually hurt them in unseen environments']",4
"['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['. without beam search, pragmatic', ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate']","['refer to the original', ""papers for details on the two models. to analyze the models'visual grounding ability, we focus on their core encoder - decoder components. in our experiments, we use models trained without data augmentation, and during inference predict actions with greedy search ( i. e. without beam search, pragmatic"", ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate how well these models ground instructions into visual features of the environment, by training and evaluating', 'them without access to the visual context : setting their visual feature vectors to zeroes during training and', 'testing. we compare performance on the validation sets of the r2r dataset : the val - seen split', ', consisting of the same environments as in training, and the', 'val - table 1 : success rate ( sr ) of the vision - based full agent ( "" rn "", using resnet ) and the non - visual agent ( "" no vis. "", setting all visual', 'features to zero ) on the r2r dataset under different model architectures (', 'speakerfollower ( sf )  #AUTHOR_TAG b ) and self -', 'monitoring ( sm )  #TAUTHOR_TAG and training schemes. unseen split of novel environments. since we aim to evaluate how', 'well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split. 2 the', ""results are shown in table 1. in each block, the two rows show the agent's"", 'performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn "" : resnet', '- 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and 3 ) outperforms', 'the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent ( lines 6 and 8', '). this indicates that these models do not learn generalizable visual perception, so', 'that the visual features may actually hurt them in unseen environments']",5
"['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['. without beam search, pragmatic', ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate']","['refer to the original', ""papers for details on the two models. to analyze the models'visual grounding ability, we focus on their core encoder - decoder components. in our experiments, we use models trained without data augmentation, and during inference predict actions with greedy search ( i. e. without beam search, pragmatic"", ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate how well these models ground instructions into visual features of the environment, by training and evaluating', 'them without access to the visual context : setting their visual feature vectors to zeroes during training and', 'testing. we compare performance on the validation sets of the r2r dataset : the val - seen split', ', consisting of the same environments as in training, and the', 'val - table 1 : success rate ( sr ) of the vision - based full agent ( "" rn "", using resnet ) and the non - visual agent ( "" no vis. "", setting all visual', 'features to zero ) on the r2r dataset under different model architectures (', 'speakerfollower ( sf )  #AUTHOR_TAG b ) and self -', 'monitoring ( sm )  #TAUTHOR_TAG and training schemes. unseen split of novel environments. since we aim to evaluate how', 'well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split. 2 the', ""results are shown in table 1. in each block, the two rows show the agent's"", 'performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn "" : resnet', '- 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and 3 ) outperforms', 'the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent ( lines 6 and 8', '). this indicates that these models do not learn generalizable visual perception, so', 'that the visual features may actually hurt them in unseen environments']",5
"['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['. without beam search, pragmatic', ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate']","['refer to the original', ""papers for details on the two models. to analyze the models'visual grounding ability, we focus on their core encoder - decoder components. in our experiments, we use models trained without data augmentation, and during inference predict actions with greedy search ( i. e. without beam search, pragmatic"", ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate how well these models ground instructions into visual features of the environment, by training and evaluating', 'them without access to the visual context : setting their visual feature vectors to zeroes during training and', 'testing. we compare performance on the validation sets of the r2r dataset : the val - seen split', ', consisting of the same environments as in training, and the', 'val - table 1 : success rate ( sr ) of the vision - based full agent ( "" rn "", using resnet ) and the non - visual agent ( "" no vis. "", setting all visual', 'features to zero ) on the r2r dataset under different model architectures (', 'speakerfollower ( sf )  #AUTHOR_TAG b ) and self -', 'monitoring ( sm )  #TAUTHOR_TAG and training schemes. unseen split of novel environments. since we aim to evaluate how', 'well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split. 2 the', ""results are shown in table 1. in each block, the two rows show the agent's"", 'performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn "" : resnet', '- 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and 3 ) outperforms', 'the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent ( lines 6 and 8', '). this indicates that these models do not learn generalizable visual perception, so', 'that the visual features may actually hurt them in unseen environments']",5
"['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['. without beam search, pragmatic', ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate']","['refer to the original', ""papers for details on the two models. to analyze the models'visual grounding ability, we focus on their core encoder - decoder components. in our experiments, we use models trained without data augmentation, and during inference predict actions with greedy search ( i. e. without beam search, pragmatic"", ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate how well these models ground instructions into visual features of the environment, by training and evaluating', 'them without access to the visual context : setting their visual feature vectors to zeroes during training and', 'testing. we compare performance on the validation sets of the r2r dataset : the val - seen split', ', consisting of the same environments as in training, and the', 'val - table 1 : success rate ( sr ) of the vision - based full agent ( "" rn "", using resnet ) and the non - visual agent ( "" no vis. "", setting all visual', 'features to zero ) on the r2r dataset under different model architectures (', 'speakerfollower ( sf )  #AUTHOR_TAG b ) and self -', 'monitoring ( sm )  #TAUTHOR_TAG and training schemes. unseen split of novel environments. since we aim to evaluate how', 'well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split. 2 the', ""results are shown in table 1. in each block, the two rows show the agent's"", 'performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn "" : resnet', '- 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and 3 ) outperforms', 'the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent ( lines 6 and 8', '). this indicates that these models do not learn generalizable visual perception, so', 'that the visual features may actually hurt them in unseen environments']",5
"['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['. without beam search, pragmatic', ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG']","['use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate']","['refer to the original', ""papers for details on the two models. to analyze the models'visual grounding ability, we focus on their core encoder - decoder components. in our experiments, we use models trained without data augmentation, and during inference predict actions with greedy search ( i. e. without beam search, pragmatic"", ', or progress monitorbased inference ). for sf, we use the', 'publicly released code. for sm, we use a reimplementation without the progress monitor, which was shown to be', 'most important for search in inference  #TAUTHOR_TAG. we investigate how well these models ground instructions into visual features of the environment, by training and evaluating', 'them without access to the visual context : setting their visual feature vectors to zeroes during training and', 'testing. we compare performance on the validation sets of the r2r dataset : the val - seen split', ', consisting of the same environments as in training, and the', 'val - table 1 : success rate ( sr ) of the vision - based full agent ( "" rn "", using resnet ) and the non - visual agent ( "" no vis. "", setting all visual', 'features to zero ) on the r2r dataset under different model architectures (', 'speakerfollower ( sf )  #AUTHOR_TAG b ) and self -', 'monitoring ( sm )  #TAUTHOR_TAG and training schemes. unseen split of novel environments. since we aim to evaluate how', 'well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split. 2 the', ""results are shown in table 1. in each block, the two rows show the agent's"", 'performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn "" : resnet', '- 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and 3 ) outperforms', 'the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent ( lines 6 and 8', '). this indicates that these models do not learn generalizable visual perception, so', 'that the visual features may actually hurt them in unseen environments']",5
['visual attention mechanism as in  #AUTHOR_TAG b ) and  #TAUTHOR_TAG to'],['visual attention mechanism as in  #AUTHOR_TAG b ) and  #TAUTHOR_TAG to'],['use the same visual attention mechanism as in  #AUTHOR_TAG b ) and  #TAUTHOR_TAG to'],"['', ""each vector x obj, j ( j - th detected object in the scene ) is a concatenation of summed glove vectors  #AUTHOR_TAG for the detected object label ( e. g. door ) and attribute labels ( e. g. white ) and a location vector from the object's bounding box coordinates."", 'we then use the same visual attention mechanism as in  #AUTHOR_TAG b ) and  #TAUTHOR_TAG to obtain an attended object representation x obj, att over these { x obj, j } vectors.', 'we either substitute the resnet cnn features x img, att ( "" rn "" ) with our object representation x obj, att ( "" obj "" ), or concatenate x img, att and x obj, att ( "" rn + obj "" ).', 'then we train the sf model or the sm model using this object representation, with results shown in table 2. 3 for sf ( lines 1 - 4 ), object representations substantially improve generalization ability : using either the object representation ( "" obj "" ) or the combined representation ( "" rn + obj "" ) obtains higher success rate on unseen environments than using']",5
[') model  #AUTHOR_TAG b ) and the self - monitoring ( sm ) model  #TAUTHOR_TAG which we analyze both use sequence'],['( sf ) model  #AUTHOR_TAG b ) and the self - monitoring ( sm ) model  #TAUTHOR_TAG which we analyze both use sequenceto - sequence model  #AUTHOR_TAG with attention  #AUTHOR_TAG as'],[') model  #AUTHOR_TAG b ) and the self - monitoring ( sm ) model  #TAUTHOR_TAG which we analyze both use sequence'],"['speaker - follower ( sf ) model  #AUTHOR_TAG b ) and the self - monitoring ( sm ) model  #TAUTHOR_TAG which we analyze both use sequenceto - sequence model  #AUTHOR_TAG with attention  #AUTHOR_TAG as their base instruction - following agent.', '']",5
"['- forward or more advanced neural networks.', 'recently, high quality and easy to train skip - gram shallow architectures were presented in  #TAUTHOR_TAG and considerably improved in']","['embeddings which are more compact representations obtained using feed - forward or more advanced neural networks.', 'recently, high quality and easy to train skip - gram shallow architectures were presented in  #TAUTHOR_TAG and considerably improved in [ 11 ] with the introduction of negative sampling and subsampling of frequent words.', 'the "" magical ""']","['- forward or more advanced neural networks.', 'recently, high quality and easy to train skip - gram shallow architectures were presented in  #TAUTHOR_TAG and considerably improved in']","['vector space models of language were developed in the 90s to predict joint probabilities of words that appear together in a sequence.', 'a particular upturn was proposed by bengio et al. in [ 1 ], replacing sparse n - gram models with word embeddings which are more compact representations obtained using feed - forward or more advanced neural networks.', 'recently, high quality and easy to train skip - gram shallow architectures were presented in  #TAUTHOR_TAG and considerably improved in [ 11 ] with the introduction of negative sampling and subsampling of frequent words.', 'the "" magical "" ability of word embeddings to capture syntactic and semantic regularities on text words is applicable in various applications like machine translations, error correcting systems, sentiment analyzers etc.', 'this ability has been tested in [ 12 ] and other studies with analogy question tests of the form "" a is to b as c is to "" or male / female relations.', 'a recent improved method for generating word embeddings is glove [ 15 ] which makes efficient use of global statistics of text words and preserves the linear substructure of skip - gram word2vec, the other popular method.', 'authors report that glove outperforms other methods such as skip - gram in several tasks like word similarity, word analogy etc.', 'in this paper we examine the quality of word embeddings on 2 sentiment analysis tasks : lyrics mood recognition and movie review polarity analysis.', 'we compare various models pretrained with glove and skip - gram, together with corpora we train ourself.', 'our goal is to report the best performing models as well as to observe the impact that certain factors like training method, corpus size and thematic relevance of texts might have on model quality.', 'according to the results, common crawl, twitter tweets and google news are the best performing models.', 'corpus size and thematic relevance have a significant role on the performance of the generated word vectors.', 'we noticed that models trained with glove slightly outperform those trained with skip - gram in most of experiments']",0
"['3 million words and phrases  #TAUTHOR_TAG.', 'it was']","['3 million words and phrases  #TAUTHOR_TAG.', 'it was']","['3 million words and phrases  #TAUTHOR_TAG.', 'it was trained using skipgram word2vec with negative sampling, windows size 5 and 300 dimensions.', 'even bigger is']","['this section we present the different word embedding models that we compare.', 'most of them are pretrained and publicly available.', 'two of them ( text8corpus and moody - corpus ) were trained by us.', 'the full list with some basic characteristics is presented in table 1.', 'wikipedia gigaword is a combination of wikipedia 2014 dump and gigaword 5 with about 6 billion tokens in total.', 'it was created by authors of [ 15 ] to evaluate glove performance.', 'wikipedia dependency corpus is a collection of 1 billion tokens from wikipedia.', 'the method used for training it is a modified version of skip - gram word2vec described in [ 7 ].', 'google news is one of the biggest and richest text sets with 100 billion tokens and a vocabulary of 3 million words and phrases  #TAUTHOR_TAG.', 'it was trained using skipgram word2vec with negative sampling, windows size 5 and 300 dimensions.', 'even bigger is common crawl 840, a huge corpus of 840 billion tokens and 2. 2 million word vectors also used at [ 15 ].', '']",0
[' #TAUTHOR_TAG gupta et'],[' #TAUTHOR_TAG gupta et'],"[', relation extraction  #TAUTHOR_TAG gupta et']","['interpretability of systems based on deep neural network is required to be able to explain the reasoning behind the network prediction ( s ), that offers to ( 1 ) verify that the network works as expected and identify the cause of incorrect decision ( s ) ( 2 ) understand the network in order to improve data or model with or without human intervention.', 'there is a long line of research in techniques of interpretability of deep neural networks ( dnns ) via different aspects, such as explaining network decisions, data generation, etc.', ' #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG and  #AUTHOR_TAG focused on model aspects to interpret neural networks via activation maximization approach by finding inputs that maximize activations of given neurons.', ' #AUTHOR_TAG interprets by generating adversarial examples.', ' #AUTHOR_TAG and  #AUTHOR_TAG ;  #AUTHOR_TAG explain neural network predictions by sensitivity analysis to different input features and decomposition of decision functions, respectively.', 'recurrent neural networks ( rnns )  #AUTHOR_TAG are temporal networks and cumulative in nature to effectively model sequential data such as text or speech.', 'rnns and their variants such as lstm  #AUTHOR_TAG have shown success in several natural language processing ( nlp ) tasks, such as entity extraction  #AUTHOR_TAG, relation extraction  #TAUTHOR_TAG gupta et al.,, 2018c, language modeling  #AUTHOR_TAG, slot filling  #AUTHOR_TAG b ), machine translation  #AUTHOR_TAG, sentiment analysis  #AUTHOR_TAG, semantic textual similarity  #AUTHOR_TAG a ) and dynamic topic modeling  #AUTHOR_TAG d ).', 'past works  #AUTHOR_TAG have mostly analyzed deep neural network, especially cnn in the field of computer vision to study and visualize the features learned by neurons.', 'recent studies have investigated visualization of rnn and its variants.', ' #AUTHOR_TAG visualized the memory vectors to understand the behavior of lstm and gated recurrent unit ( gru ) in speech recognition task.', 'for given words in a sentence, employed heat maps to study sensitivity and meaning composition in recurrent networks.', ' #AUTHOR_TAG', 'forward direction', 'figure 1 : connectionist bi - directional recurrent neural network ( c - brnn )  #AUTHOR_TAG a ) inputs.', ' #AUTHOR_TAG studied the internal states of deep bidirectional language model to learn contextualized word representations and observed that the higher - level hidden states capture word semantics, while lower - level states capture syntactical aspects.', 'despite the possibility of visualizing hidden state activations and performancebased analysis, there still remains a challenge for humans to interpret hidden behavior of the "" black box "" networks that raised questions in the nlp community as to verify that the network behaves as expected.', 'in this aspect, we address the cumulative nature of rnn with the text input and computed response to answer "" how does it aggregate and build the semantic meaning of a sentence word by word at each time point in the sequence for']",0
"['cases, the context in between the two nominals define the relationship.', 'however,  #TAUTHOR_TAG has shown that the extended context helps.', 'in this work, we focus on']","['cases, the context in between the two nominals define the relationship.', 'however,  #TAUTHOR_TAG has shown that the extended context helps.', 'in this work, we focus on']","['cases, the context in between the two nominals define the relationship.', 'however,  #TAUTHOR_TAG has shown that the extended context helps.', 'in this work, we focus on the building semantics']","['a sentence and two annotated nominals, the task of binary relation classification is to predict the semantic relations between the pairs of nominals.', 'in most cases, the context in between the two nominals define the relationship.', 'however,  #TAUTHOR_TAG has shown that the extended context helps.', 'in this work, we focus on the building semantics for a given sentence using relationship contexts between the two nominals.', '']",0
"['', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c -']","['', 'of the combined forward and backward network.  #AUTHOR_TAG during model training, we use 3 - gram and 5 - gram representation of each word w t at timestep t in the word sequence, where a 3 - gram for w t is obtained by concatenating the corresponding word embeddings, i. e., w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - brnn. the ranking scheme offers to maximize the distance between the true label y + and the best competitive label c − given a data point x. it is defined as - where s θ ( x ) y + and s θ ( x ) c − being the scores for the classes y + and', 'c −, respectively. the parameter γ controls the penalization of the prediction errors and m + and m are', 'margins for the correct and incorrect classes. following  #TAUTHOR_TAG, we set γ = 2, m + = 2. 5 and m − = 0. 5']",5
"['', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c -']","['', 'of the combined forward and backward network.  #AUTHOR_TAG during model training, we use 3 - gram and 5 - gram representation of each word w t at timestep t in the word sequence, where a 3 - gram for w t is obtained by concatenating the corresponding word embeddings, i. e., w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - brnn. the ranking scheme offers to maximize the distance between the true label y + and the best competitive label c − given a data point x. it is defined as - where s θ ( x ) y + and s θ ( x ) c − being the scores for the classes y + and', 'c −, respectively. the parameter γ controls the penalization of the prediction errors and m + and m are', 'margins for the correct and incorrect classes. following  #TAUTHOR_TAG, we set γ = 2, m + = 2. 5 and m − = 0. 5']",5
"['', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c -']","['', 'of the combined forward and backward network.  #AUTHOR_TAG during model training, we use 3 - gram and 5 - gram representation of each word w t at timestep t in the word sequence, where a 3 - gram for w t is obtained by concatenating the corresponding word embeddings, i. e., w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - brnn. the ranking scheme offers to maximize the distance between the true label y + and the best competitive label c − given a data point x. it is defined as - where s θ ( x ) y + and s θ ( x ) c − being the scores for the classes y + and', 'c −, respectively. the parameter γ controls the penalization of the prediction errors and m + and m are', 'margins for the correct and incorrect classes. following  #TAUTHOR_TAG, we set γ = 2, m + = 2. 5 and m − = 0. 5']",5
['( figure 1 )  #TAUTHOR_TAG model'],"['relation arguments are introduced.', 'in our analysis and interpretation of recurrent neural networks, we use the trained c - brnn ( figure 1 )  #TAUTHOR_TAG model']","['##1 >, < / e1 >, < e2 >, < / e2 > ) around the relation arguments are introduced.', 'in our analysis and interpretation of recurrent neural networks, we use the trained c - brnn ( figure 1 )  #TAUTHOR_TAG model']","['represent each word by the concatenation of its word embedding and position feature vectors.', 'we use word2vec  #AUTHOR_TAG embeddings, that are updated during model training.', 'as position features in relation classification experiments, we use position indicators ( pi )  #AUTHOR_TAG in c - brnn to annotate target entity / nominals in the word sequence, without necessity to change the input vectors, while it increases the length of the input word sequences, as four independent words, as position indicators ( < e1 >, < / e1 >, < e2 >, < / e2 > ) around the relation arguments are introduced.', 'in our analysis and interpretation of recurrent neural networks, we use the trained c - brnn ( figure 1 )  #TAUTHOR_TAG model']",5
"['following  #TAUTHOR_TAG, we use n - grams ( e']","['following  #TAUTHOR_TAG, we use n - grams ( e. g., tri - grams ) representation for each', 'word in']","['w t−1, w t, w t + 1 ] n t = 1 ], where w 0 and w n + 1 are padding ( zero ) vectors of embedding dimension. following  #TAUTHOR_TAG, we use n - grams ( e. g., tri - grams ) representation for each', 'word in each subsequence s ≤']","['', "", prediction score = 0. 77 ), where the next subsequence '... cause of < e2 >'adds in the score to get 0. 98. example2pattern for saliency pattern : to further interpret rnn, we seek to identify and extract the"", 'most likely input pattern ( or phrases ) for a given class that is discriminating enough in decision making. therefore,', 'each example input is transformed into a saliency pattern that informs us about the network learning. to do so, we first compute n - gram', 'for each word w t in the sentence s. for instance, a 3 - gram representation of w t is given by w t−1, w t, w t + 1. therefore, an n - gram ( for n = 3 ) sequence s of words is represented as [ [ w t−1, w t, w t + 1 ] n t = 1 ], where w 0 and w n + 1 are padding ( zero ) vectors of embedding dimension. following  #TAUTHOR_TAG, we use n - grams ( e. g., tri - grams ) representation for each', 'word in each subsequence s ≤k that is input to c - brnn to compute p ( r | s ≤k )', ', where the n - gram ( n = 3 ) subsequence s ≤k is given by, for k ∈ [ 1, n ]. observe that the 3 - gram tri k con - ( d ) lisa for s', '##4 < e 1 > c a r < / e 1 > l e f t t h e < e 2 > p l a n t < / e 2']",5
,,,,5
"['', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c -']","['', 'of the combined forward and backward network.  #AUTHOR_TAG during model training, we use 3 - gram and 5 - gram representation of each word w t at timestep t in the word sequence, where a 3 - gram for w t is obtained by concatenating the corresponding word embeddings, i. e., w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - brnn. the ranking scheme offers to maximize the distance between the true label y + and the best competitive label c − given a data point x. it is defined as - where s θ ( x ) y + and s θ ( x ) c − being the scores for the classes y + and', 'c −, respectively. the parameter γ controls the penalization of the prediction errors and m + and m are', 'margins for the correct and incorrect classes. following  #TAUTHOR_TAG, we set γ = 2, m + = 2. 5 and m − = 0. 5']",3
"['', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c -']","['', 'of the combined forward and backward network.  #AUTHOR_TAG during model training, we use 3 - gram and 5 - gram representation of each word w t at timestep t in the word sequence, where a 3 - gram for w t is obtained by concatenating the corresponding word embeddings, i. e., w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - brnn. the ranking scheme offers to maximize the distance between the true label y + and the best competitive label c − given a data point x. it is defined as - where s θ ( x ) y + and s θ ( x ) c − being the scores for the classes y + and', 'c −, respectively. the parameter γ controls the penalization of the prediction errors and m + and m are', 'margins for the correct and incorrect classes. following  #TAUTHOR_TAG, we set γ = 2, m + = 2. 5 and m − = 0. 5']",3
"['', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - br']","[', w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c -']","['', 'of the combined forward and backward network.  #AUTHOR_TAG during model training, we use 3 - gram and 5 - gram representation of each word w t at timestep t in the word sequence, where a 3 - gram for w t is obtained by concatenating the corresponding word embeddings, i. e., w t−1 w', 't w t + 1. ranking objective : similar to  #AUTHOR_TAG and  #TAUTHOR_TAG, we applied the ranking loss function to train', 'c - brnn. the ranking scheme offers to maximize the distance between the true label y + and the best competitive label c − given a data point x. it is defined as - where s θ ( x ) y + and s θ ( x ) c − being the scores for the classes y + and', 'c −, respectively. the parameter γ controls the penalization of the prediction errors and m + and m are', 'margins for the correct and incorrect classes. following  #TAUTHOR_TAG, we set γ = 2, m + = 2. 5 and m − = 0. 5']",3
['( figure 1 )  #TAUTHOR_TAG model'],"['relation arguments are introduced.', 'in our analysis and interpretation of recurrent neural networks, we use the trained c - brnn ( figure 1 )  #TAUTHOR_TAG model']","['##1 >, < / e1 >, < e2 >, < / e2 > ) around the relation arguments are introduced.', 'in our analysis and interpretation of recurrent neural networks, we use the trained c - brnn ( figure 1 )  #TAUTHOR_TAG model']","['represent each word by the concatenation of its word embedding and position feature vectors.', 'we use word2vec  #AUTHOR_TAG embeddings, that are updated during model training.', 'as position features in relation classification experiments, we use position indicators ( pi )  #AUTHOR_TAG in c - brnn to annotate target entity / nominals in the word sequence, without necessity to change the input vectors, while it increases the length of the input word sequences, as four independent words, as position indicators ( < e1 >, < / e1 >, < e2 >, < / e2 > ) around the relation arguments are introduced.', 'in our analysis and interpretation of recurrent neural networks, we use the trained c - brnn ( figure 1 )  #TAUTHOR_TAG model']",3
"['following  #TAUTHOR_TAG, we use n - grams ( e']","['following  #TAUTHOR_TAG, we use n - grams ( e. g., tri - grams ) representation for each', 'word in']","['w t−1, w t, w t + 1 ] n t = 1 ], where w 0 and w n + 1 are padding ( zero ) vectors of embedding dimension. following  #TAUTHOR_TAG, we use n - grams ( e. g., tri - grams ) representation for each', 'word in each subsequence s ≤']","['', "", prediction score = 0. 77 ), where the next subsequence '... cause of < e2 >'adds in the score to get 0. 98. example2pattern for saliency pattern : to further interpret rnn, we seek to identify and extract the"", 'most likely input pattern ( or phrases ) for a given class that is discriminating enough in decision making. therefore,', 'each example input is transformed into a saliency pattern that informs us about the network learning. to do so, we first compute n - gram', 'for each word w t in the sentence s. for instance, a 3 - gram representation of w t is given by w t−1, w t, w t + 1. therefore, an n - gram ( for n = 3 ) sequence s of words is represented as [ [ w t−1, w t, w t + 1 ] n t = 1 ], where w 0 and w n + 1 are padding ( zero ) vectors of embedding dimension. following  #TAUTHOR_TAG, we use n - grams ( e. g., tri - grams ) representation for each', 'word in each subsequence s ≤k that is input to c - brnn to compute p ( r | s ≤k )', ', where the n - gram ( n = 3 ) subsequence s ≤k is given by, for k ∈ [ 1, n ]. observe that the 3 - gram tri k con - ( d ) lisa for s', '##4 < e 1 > c a r < / e 1 > l e f t t h e < e 2 > p l a n t < / e 2']",3
,,,,3
['of  #TAUTHOR_TAG ; ( c ) two'],['of  #TAUTHOR_TAG ; ( c ) two'],['of  #TAUTHOR_TAG ; ( c ) two approaches to'],"['parsing is one of the mainstream research areas in natural language processing.', 'dependency representations are useful for a number of nlp applications, for example, machine translation  #AUTHOR_TAG, information extraction  #AUTHOR_TAG, analysis of typologically diverse languages  #AUTHOR_TAG and parser stacking ( [UNK] et al., 2009 ).', 'there were several shared tasks organized on dependency parsing ( conll 2006 ( conll - 2007 and labeled dependencies ( conll 2008 ( conll - 2009 ) and there were a number of attempts to compare various dependencies intrinsically, e. g.  #AUTHOR_TAG, and extrinsically, e. g.  #AUTHOR_TAG.', 'in this paper we focus on practical issues of data representation for dependency parsing.', ""the central aspects of our discussion are ( a ) three dependency formats : two'classic'representations for dependency parsing, namely, stanford basic ( sb ) and conll syntactic dependencies ( cd ), and bilexical dependencies from the hpsg english resource grammar ( erg ), so - called delph - in syntactic derivation tree ( dt ), proposed recently by  #AUTHOR_TAG ; ( b ) three state - of - the art statistical parsers : malt  #AUTHOR_TAG, mst ( mc  #AUTHOR_TAG and the parser of  #TAUTHOR_TAG ; ( c ) two approaches to wordcategory disambiguation, e. g. exploiting common ptb tags and using supertags ( i. e. specialized erg lexical types )."", 'we parse the formats and compare accuracies in all configurations in order to determine how parsers, dependency representations and grammatical tagging methods interact with each other in application to automatic syntactic analysis.', 'sb and cd are derived automatically from phrase structures of penn treebank to accommodate the needs of fast and accurate dependency parsing, whereas dt is rooted in the formal grammar theory hpsg and is independent from any specific treebank.', 'for dt we gain more expressivity from the underlying linguistic theory, which challenges parsing with statistical tools.', 'the structural analysis of the schemes in  #AUTHOR_TAG leads to the hypothesis that cd and dt are more similar to each other than sb to dt.', 'we recompute similarities on a larger treebank and check whether parsing results reflect them.', 'the paper has the following structure : an overview of related work is presented in section 2 ; treebanks, tagsets, dependency schemes and parsers used in the experiments are introduced in section 3 ; analysis of parsing results is discussed in section 4 ; conclusions and future work are outlined in section 5.', ' #AUTHOR_TAG investigate which dependency representations of several syntactic structures are easier to parse with supervised versions of the  #AUTHOR_TAG parser, clearparser  #AUTHOR_TAG, mst parser, malt and the easy first non - directional']",5
"['', ' #TAUTHOR_TAG parser : transitionbased']","['with global near - exhaustive search.', ' #TAUTHOR_TAG parser : transitionbased']","['with global near - exhaustive search.', ' #TAUTHOR_TAG parser : transitionbased']","['the experiments described in section 4 we used parsers that adopt different approaches and implement various algorithms.', 'malt  #AUTHOR_TAG : transition - based dependency parser with local learning and greedy search.', 'mst ( mc  #AUTHOR_TAG : graph - based dependency parser with global near - exhaustive search.', ' #TAUTHOR_TAG parser : transitionbased dependency parser with joint tagger that implements global learning and beam search']",5
"['this section we give a detailed analysis of parsing into sb, cd and dt dependencies with malt, mst and the  #TAUTHOR_TAG parser']","['this section we give a detailed analysis of parsing into sb, cd and dt dependencies with malt, mst and the  #TAUTHOR_TAG parser']","['this section we give a detailed analysis of parsing into sb, cd and dt dependencies with malt, mst and the  #TAUTHOR_TAG parser']","['this section we give a detailed analysis of parsing into sb, cd and dt dependencies with malt, mst and the  #TAUTHOR_TAG parser']",5
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['malt and mst we perform the experiments on gold pos tags, whereas the  #TAUTHOR_TAG parser predicts pos tags during testing.', 'prior to each experiment with malt, we used maltoptimizer to obtain settings and a feature model ; for mst we exploited default configuration ; for the  #TAUTHOR_TAG parser we set the beam parameter to 80 and otherwise employed the default setup.', 'with regards to evaluation metrics we use labelled attachment score ( las ), unlabeled attachment score ( uas ) and label accuracy ( lacc ) excluding punctuation.', 'our results cannot be directly compared to the state - of - the - art scores on the penn treebank because we train on sections 0 - 13 and test on section 15 of wsj.', 'also our results are not strictly inter - comparable because the setups we are using are different']",5
['##s + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],"['', 'corresponding supertags from the gold - standard training set.', 'for open word classes such as nouns, adjectives, adverbs and verbs the relation between ptb tags and supertags is many - to -', 'many. unique one - tomany correspondence holds only for possessive wh - pronoun and punctuation. thus, supertags do not provide extra level of detalization for ptb tags, but ptb tags and supertags are complementary. as discussed in section 3. 4, they contain bits of information that are different.', 'for this reason their combination results in slight increase of accuracy for all three parsers on all dependency formats ( table 1, gold ptb tags + gold supertags,', 'and table 2, predicted ptb + gold supertags and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average accuracy of 89. 73 % which is significantly lower than state - ofthe - art', '95 % ( ytrestøl, 2011 ). when we consider punctuation in the evaluation, all scores raise significantly for dt and at the same time decrease for', 'sb and cd for all three parsers. this is explained by the fact that punctuation in dt is always attached to the nearest token which is easy to learn for a statistical parser']",5
"['of malt, mst and the  #TAUTHOR_TAG parser']","['of malt, mst and the  #TAUTHOR_TAG parser']","['of malt, mst and the  #TAUTHOR_TAG parser']","['these three lexical categories we manually analyzed a random sample of sentences with errors and their corresponding gold - standard versions. in many cases such errors are related to the root of', 'the sentence when the verb is either treated as', 'complement or adjunct instead of having a root status or vice versa. errors with these groups of verbs mostly occur in the complex sentences that contain several verbs. sentences with coordination are particularly difficult for the correct attachment and labeling of the vbp ( see figure 2 for an example ). coordination. the error rate of malt, mst and the  #TAUTHOR_TAG parser for the coordination is not so high for sb and cd ( 1 % and 2 % correspondingly with maltparser, ptb tags ) whereas for dt the error rate on the', 'cpostags is especially high ( 26 % with maltparser, ptb tags ). it means that there are many errors on incoming dependency arcs for coordinating conjunctions when parsing dt. on outgoing arcs parsers also make more mistakes on dt than on sb and cd. this is related to the difference in choice of annotation principle ( see figure', '1 ). as it was shown in  #AUTHOR_TAG, it is harder to parse coordination headed by coordinating conjunction. although the approach used in dt is harder for parser to', 'learn, it has some advantages : using sb and cd annotations, we cannot distinguish the', 'two cases illustrated with the sentences ( a ) and ( b ) : a ) the fight is putting a tight squeeze on', '']",5
"['of malt, mst and the  #TAUTHOR_TAG parser']","['of malt, mst and the  #TAUTHOR_TAG parser']","['of malt, mst and the  #TAUTHOR_TAG parser']","['these three lexical categories we manually analyzed a random sample of sentences with errors and their corresponding gold - standard versions. in many cases such errors are related to the root of', 'the sentence when the verb is either treated as', 'complement or adjunct instead of having a root status or vice versa. errors with these groups of verbs mostly occur in the complex sentences that contain several verbs. sentences with coordination are particularly difficult for the correct attachment and labeling of the vbp ( see figure 2 for an example ). coordination. the error rate of malt, mst and the  #TAUTHOR_TAG parser for the coordination is not so high for sb and cd ( 1 % and 2 % correspondingly with maltparser, ptb tags ) whereas for dt the error rate on the', 'cpostags is especially high ( 26 % with maltparser, ptb tags ). it means that there are many errors on incoming dependency arcs for coordinating conjunctions when parsing dt. on outgoing arcs parsers also make more mistakes on dt than on sb and cd. this is related to the difference in choice of annotation principle ( see figure', '1 ). as it was shown in  #AUTHOR_TAG, it is harder to parse coordination headed by coordinating conjunction. although the approach used in dt is harder for parser to', 'learn, it has some advantages : using sb and cd annotations, we cannot distinguish the', 'two cases illustrated with the sentences ( a ) and ( b ) : a ) the fight is putting a tight squeeze on', '']",5
"['of malt, mst and the  #TAUTHOR_TAG parser']","['of malt, mst and the  #TAUTHOR_TAG parser']","['of malt, mst and the  #TAUTHOR_TAG parser']","['these three lexical categories we manually analyzed a random sample of sentences with errors and their corresponding gold - standard versions. in many cases such errors are related to the root of', 'the sentence when the verb is either treated as', 'complement or adjunct instead of having a root status or vice versa. errors with these groups of verbs mostly occur in the complex sentences that contain several verbs. sentences with coordination are particularly difficult for the correct attachment and labeling of the vbp ( see figure 2 for an example ). coordination. the error rate of malt, mst and the  #TAUTHOR_TAG parser for the coordination is not so high for sb and cd ( 1 % and 2 % correspondingly with maltparser, ptb tags ) whereas for dt the error rate on the', 'cpostags is especially high ( 26 % with maltparser, ptb tags ). it means that there are many errors on incoming dependency arcs for coordinating conjunctions when parsing dt. on outgoing arcs parsers also make more mistakes on dt than on sb and cd. this is related to the difference in choice of annotation principle ( see figure', '1 ). as it was shown in  #AUTHOR_TAG, it is harder to parse coordination headed by coordinating conjunction. although the approach used in dt is harder for parser to', 'learn, it has some advantages : using sb and cd annotations, we cannot distinguish the', 'two cases illustrated with the sentences ( a ) and ( b ) : a ) the fight is putting a tight squeeze on', '']",5
['the  #TAUTHOR_TAG'],['the  #TAUTHOR_TAG'],"['the  #TAUTHOR_TAG parser ( iii ) exploiting two different tagsets,']","['this survey we gave a comparative experimental overview of ( i ) parsing three dependency schemes, viz., stanford basic ( sb ), conll syntactic dependencies ( cd ) and delph - in syntactic derivation tree ( dt ), ( ii ) with three leading dependency parsers, viz., malt, mst and the  #TAUTHOR_TAG parser ( iii ) exploiting two different tagsets, viz., ptb tags and supertags.', 'from the parser perspective, the  #TAUTHOR_TAG parser performs better than malt and mst not only on conventional formats but also on the new representation, although this parser solves a harder task than malt and mst.', 'from the dependency format perspective, dt appeares to be a more difficult target dependency representation than sb and cd.', 'this suggests that the expressivity that we gain from the grammar theory ( e. g. for coordination ) is harder to learn with state - of - the - art dependency parsers.', 'cd and dt are structurally closer to each other than sb and dt ; however, we did not observe sound evidence of a correlation between structural similarity of cd and dt and their parsing accuracies regarding the tagset aspect, it is natural that ptb tags are good for sb and cd, whereas the more fine - grained set of supertags fits dt better.', 'ptb tags and supertags are complementary, and for all three parsers we observe slight benefits from being supplied with both types of tags.', 'as future work we would like to run more experiments with predicted supertags.', 'in the absence of a specialized supertagger, we can follow the pipeline of ( ytrestøl, 2011 ) who reached the stateof - the - art supertagging accuracy of 95 %.', 'another area of our interest is an extrinsic evaluation of sb, cd and dt, e. g. applied to semantic role labeling and question - answering in order to find out if the usage of the dt format grounded in the computational grammar theory is beneficial for such tasks']",5
"['', ' #TAUTHOR_TAG parser : transitionbased']","['with global near - exhaustive search.', ' #TAUTHOR_TAG parser : transitionbased']","['with global near - exhaustive search.', ' #TAUTHOR_TAG parser : transitionbased']","['the experiments described in section 4 we used parsers that adopt different approaches and implement various algorithms.', 'malt  #AUTHOR_TAG : transition - based dependency parser with local learning and greedy search.', 'mst ( mc  #AUTHOR_TAG : graph - based dependency parser with global near - exhaustive search.', ' #TAUTHOR_TAG parser : transitionbased dependency parser with joint tagger that implements global learning and beam search']",7
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['malt and mst we perform the experiments on gold pos tags, whereas the  #TAUTHOR_TAG parser predicts pos tags during testing.', 'prior to each experiment with malt, we used maltoptimizer to obtain settings and a feature model ; for mst we exploited default configuration ; for the  #TAUTHOR_TAG parser we set the beam parameter to 80 and otherwise employed the default setup.', 'with regards to evaluation metrics we use labelled attachment score ( las ), unlabeled attachment score ( uas ) and label accuracy ( lacc ) excluding punctuation.', 'our results cannot be directly compared to the state - of - the - art scores on the penn treebank because we train on sections 0 - 13 and test on section 15 of wsj.', 'also our results are not strictly inter - comparable because the setups we are using are different']",4
['##s + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],"['', 'corresponding supertags from the gold - standard training set.', 'for open word classes such as nouns, adjectives, adverbs and verbs the relation between ptb tags and supertags is many - to -', 'many. unique one - tomany correspondence holds only for possessive wh - pronoun and punctuation. thus, supertags do not provide extra level of detalization for ptb tags, but ptb tags and supertags are complementary. as discussed in section 3. 4, they contain bits of information that are different.', 'for this reason their combination results in slight increase of accuracy for all three parsers on all dependency formats ( table 1, gold ptb tags + gold supertags,', 'and table 2, predicted ptb + gold supertags and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average accuracy of 89. 73 % which is significantly lower than state - ofthe - art', '95 % ( ytrestøl, 2011 ). when we consider punctuation in the evaluation, all scores raise significantly for dt and at the same time decrease for', 'sb and cd for all three parsers. this is explained by the fact that punctuation in dt is always attached to the nearest token which is easy to learn for a statistical parser']",4
['##s + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],"['', 'corresponding supertags from the gold - standard training set.', 'for open word classes such as nouns, adjectives, adverbs and verbs the relation between ptb tags and supertags is many - to -', 'many. unique one - tomany correspondence holds only for possessive wh - pronoun and punctuation. thus, supertags do not provide extra level of detalization for ptb tags, but ptb tags and supertags are complementary. as discussed in section 3. 4, they contain bits of information that are different.', 'for this reason their combination results in slight increase of accuracy for all three parsers on all dependency formats ( table 1, gold ptb tags + gold supertags,', 'and table 2, predicted ptb + gold supertags and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average accuracy of 89. 73 % which is significantly lower than state - ofthe - art', '95 % ( ytrestøl, 2011 ). when we consider punctuation in the evaluation, all scores raise significantly for dt and at the same time decrease for', 'sb and cd for all three parsers. this is explained by the fact that punctuation in dt is always attached to the nearest token which is easy to learn for a statistical parser']",4
['##s + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],"['', 'corresponding supertags from the gold - standard training set.', 'for open word classes such as nouns, adjectives, adverbs and verbs the relation between ptb tags and supertags is many - to -', 'many. unique one - tomany correspondence holds only for possessive wh - pronoun and punctuation. thus, supertags do not provide extra level of detalization for ptb tags, but ptb tags and supertags are complementary. as discussed in section 3. 4, they contain bits of information that are different.', 'for this reason their combination results in slight increase of accuracy for all three parsers on all dependency formats ( table 1, gold ptb tags + gold supertags,', 'and table 2, predicted ptb + gold supertags and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average accuracy of 89. 73 % which is significantly lower than state - ofthe - art', '95 % ( ytrestøl, 2011 ). when we consider punctuation in the evaluation, all scores raise significantly for dt and at the same time decrease for', 'sb and cd for all three parsers. this is explained by the fact that punctuation in dt is always attached to the nearest token which is easy to learn for a statistical parser']",4
['the  #TAUTHOR_TAG'],['the  #TAUTHOR_TAG'],"['the  #TAUTHOR_TAG parser ( iii ) exploiting two different tagsets,']","['this survey we gave a comparative experimental overview of ( i ) parsing three dependency schemes, viz., stanford basic ( sb ), conll syntactic dependencies ( cd ) and delph - in syntactic derivation tree ( dt ), ( ii ) with three leading dependency parsers, viz., malt, mst and the  #TAUTHOR_TAG parser ( iii ) exploiting two different tagsets, viz., ptb tags and supertags.', 'from the parser perspective, the  #TAUTHOR_TAG parser performs better than malt and mst not only on conventional formats but also on the new representation, although this parser solves a harder task than malt and mst.', 'from the dependency format perspective, dt appeares to be a more difficult target dependency representation than sb and cd.', 'this suggests that the expressivity that we gain from the grammar theory ( e. g. for coordination ) is harder to learn with state - of - the - art dependency parsers.', 'cd and dt are structurally closer to each other than sb and dt ; however, we did not observe sound evidence of a correlation between structural similarity of cd and dt and their parsing accuracies regarding the tagset aspect, it is natural that ptb tags are good for sb and cd, whereas the more fine - grained set of supertags fits dt better.', 'ptb tags and supertags are complementary, and for all three parsers we observe slight benefits from being supplied with both types of tags.', 'as future work we would like to run more experiments with predicted supertags.', 'in the absence of a specialized supertagger, we can follow the pipeline of ( ytrestøl, 2011 ) who reached the stateof - the - art supertagging accuracy of 95 %.', 'another area of our interest is an extrinsic evaluation of sb, cd and dt, e. g. applied to semantic role labeling and question - answering in order to find out if the usage of the dt format grounded in the computational grammar theory is beneficial for such tasks']",4
['##s + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],"['', 'corresponding supertags from the gold - standard training set.', 'for open word classes such as nouns, adjectives, adverbs and verbs the relation between ptb tags and supertags is many - to -', 'many. unique one - tomany correspondence holds only for possessive wh - pronoun and punctuation. thus, supertags do not provide extra level of detalization for ptb tags, but ptb tags and supertags are complementary. as discussed in section 3. 4, they contain bits of information that are different.', 'for this reason their combination results in slight increase of accuracy for all three parsers on all dependency formats ( table 1, gold ptb tags + gold supertags,', 'and table 2, predicted ptb + gold supertags and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average accuracy of 89. 73 % which is significantly lower than state - ofthe - art', '95 % ( ytrestøl, 2011 ). when we consider punctuation in the evaluation, all scores raise significantly for dt and at the same time decrease for', 'sb and cd for all three parsers. this is explained by the fact that punctuation in dt is always attached to the nearest token which is easy to learn for a statistical parser']",0
['##s + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],"['', 'corresponding supertags from the gold - standard training set.', 'for open word classes such as nouns, adjectives, adverbs and verbs the relation between ptb tags and supertags is many - to -', 'many. unique one - tomany correspondence holds only for possessive wh - pronoun and punctuation. thus, supertags do not provide extra level of detalization for ptb tags, but ptb tags and supertags are complementary. as discussed in section 3. 4, they contain bits of information that are different.', 'for this reason their combination results in slight increase of accuracy for all three parsers on all dependency formats ( table 1, gold ptb tags + gold supertags,', 'and table 2, predicted ptb + gold supertags and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average accuracy of 89. 73 % which is significantly lower than state - ofthe - art', '95 % ( ytrestøl, 2011 ). when we consider punctuation in the evaluation, all scores raise significantly for dt and at the same time decrease for', 'sb and cd for all three parsers. this is explained by the fact that punctuation in dt is always attached to the nearest token which is easy to learn for a statistical parser']",6
['##s + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],['##s and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average'],"['', 'corresponding supertags from the gold - standard training set.', 'for open word classes such as nouns, adjectives, adverbs and verbs the relation between ptb tags and supertags is many - to -', 'many. unique one - tomany correspondence holds only for possessive wh - pronoun and punctuation. thus, supertags do not provide extra level of detalization for ptb tags, but ptb tags and supertags are complementary. as discussed in section 3. 4, they contain bits of information that are different.', 'for this reason their combination results in slight increase of accuracy for all three parsers on all dependency formats ( table 1, gold ptb tags + gold supertags,', 'and table 2, predicted ptb + gold supertags and predicted supertags + gold ptb ). the  #TAUTHOR_TAG parser predicts supertags with an average accuracy of 89. 73 % which is significantly lower than state - ofthe - art', '95 % ( ytrestøl, 2011 ). when we consider punctuation in the evaluation, all scores raise significantly for dt and at the same time decrease for', 'sb and cd for all three parsers. this is explained by the fact that punctuation in dt is always attached to the nearest token which is easy to learn for a statistical parser']",6
"['italy.', 'in  #TAUTHOR_TAG,']","['italy.', 'in  #TAUTHOR_TAG,']","['parisfrance + rome = italy.', 'in  #TAUTHOR_TAG,']","['', 'in  #TAUTHOR_TAG, the linear relation is extended to the bilingual scenario, where a linear transform is learned to project semantically identical words from one language to another.', 'the authors reported a high accuracy on a bilingual word translation task.', 'although promising, we argue that both the word embedding and the linear transform are ill - posed, due to the inconsistence among the objective function used to learn the word vectors ( maximum likelihood based on inner product ), the distance measurement for word vectors ( cosine distance ), and the objective function used to learn the linear transform ( mean square error ).', 'this inconsistence may lead to suboptimal estimation for both word vectors and the bilingual transform, as we will see shortly.', 'this paper solves the inconsistence by normalizing the word vectors.', 'specifically, we enforce the word vectors to be in a unit length during the learning of the embedding.', 'by this constraint, all the word vectors are located on a hypersphere and so the inner product falls back to the cosine distance.', 'this hence solves the inconsistence between the embedding and the distance measurement.', 'to respect the normalization constraint on word vectors, the linear transform in the bilingual projection has to be constrained as an orthogonal transform.', 'finally, the cosine distance is used']",0
['by  #TAUTHOR_TAG learns'],['by  #TAUTHOR_TAG learns'],['by  #TAUTHOR_TAG learns a linear transform'],"['bilingual word translation provided by  #TAUTHOR_TAG learns a linear transform from the source language to the target language by the linear regression.', 'the objective function is as follows :', '1 for efficiency, this normalization can be conducted every n mini - batches.', 'the performance is expected to be not much impacted, given that n is not too large.', 'where w is the projection matrix to be learned, and x i and z i are word vectors in the source and target language respectively.', 'the bilingual pair ( x i, z i ) indicates that x i and z i are identical in semantic meaning.', 'a high accuracy was reported on a word translation task, where a word projected to the vector space of the target language is expected to be as close as possible to its translation  #TAUTHOR_TAG.', ""however, we note that the'closeness'of words in the projection space is measured by the cosine distance, which is fundamentally different from the euler distance in the objective function ( 3 ) and hence causes inconsistence."", 'we solve this problem by using the cosine distance in the transform learning, so the optimization task can be redefined as follows :', '']",0
['by  #TAUTHOR_TAG learns'],['by  #TAUTHOR_TAG learns'],['by  #TAUTHOR_TAG learns a linear transform'],"['bilingual word translation provided by  #TAUTHOR_TAG learns a linear transform from the source language to the target language by the linear regression.', 'the objective function is as follows :', '1 for efficiency, this normalization can be conducted every n mini - batches.', 'the performance is expected to be not much impacted, given that n is not too large.', 'where w is the projection matrix to be learned, and x i and z i are word vectors in the source and target language respectively.', 'the bilingual pair ( x i, z i ) indicates that x i and z i are identical in semantic meaning.', 'a high accuracy was reported on a word translation task, where a word projected to the vector space of the target language is expected to be as close as possible to its translation  #TAUTHOR_TAG.', ""however, we note that the'closeness'of words in the projection space is measured by the cosine distance, which is fundamentally different from the euler distance in the objective function ( 3 ) and hence causes inconsistence."", 'we solve this problem by using the cosine distance in the transform learning, so the optimization task can be redefined as follows :', '']",0
"['and experimental settings of  #TAUTHOR_TAG, while we normalize']","['and experimental settings of  #TAUTHOR_TAG, while we normalize']","['follows the methodology and experimental settings of  #TAUTHOR_TAG, while we normalize the embedding']","['work largely follows the methodology and experimental settings of  #TAUTHOR_TAG, while we normalize the embedding and use an orthogonal transform to conduct bilingual translation.', 'multilingual learning can be categorized into projection - based approaches and regularizationbased approaches.', '']",5
"['##11 ) 2.', ""for an easy comparison, we largely follow mikolov's settings in  #TAUTHOR_TAG and set english and spanish as the source and target language, respectively."", 'the data preparation involves the following steps.', 'firstly, the text was token']","['emnlp 2011 smt workshop ( wmt11 ) 2.', ""for an easy comparison, we largely follow mikolov's settings in  #TAUTHOR_TAG and set english and spanish as the source and target language, respectively."", 'the data preparation involves the following steps.', 'firstly, the text was tokenized by the standard scripts provided by wmt11 3, and then duplicated sentences were']","['##11 ) 2.', ""for an easy comparison, we largely follow mikolov's settings in  #TAUTHOR_TAG and set english and spanish as the source and target language, respectively."", 'the data preparation involves the following steps.', 'firstly, the text was tokenized by the standard scripts provided by wm']","['monolingual word embedding is conducted with the data published by the emnlp 2011 smt workshop ( wmt11 ) 2.', ""for an easy comparison, we largely follow mikolov's settings in  #TAUTHOR_TAG and set english and spanish as the source and target language, respectively."", 'the data preparation involves the following steps.', 'firstly, the text was tokenized by the standard scripts provided by wmt11 3, and then duplicated sentences were removed.', ""the numerical expressions were tokenized as'num ', and special characters ( such as!?, : ) were removed."", 'the word2vector toolkit 4 was used to train the word embedding model.', 'we chose the skip - gram model and the text window was set to 5.', 'the training resulted in embedding of 169k english tokens and 116k spanish tokens']",5
"['and experimental settings of  #TAUTHOR_TAG, while we normalize']","['and experimental settings of  #TAUTHOR_TAG, while we normalize']","['follows the methodology and experimental settings of  #TAUTHOR_TAG, while we normalize the embedding']","['work largely follows the methodology and experimental settings of  #TAUTHOR_TAG, while we normalize the embedding and use an orthogonal transform to conduct bilingual translation.', 'multilingual learning can be categorized into projection - based approaches and regularizationbased approaches.', '']",3
"['and experimental settings of  #TAUTHOR_TAG, while we normalize']","['and experimental settings of  #TAUTHOR_TAG, while we normalize']","['follows the methodology and experimental settings of  #TAUTHOR_TAG, while we normalize the embedding']","['work largely follows the methodology and experimental settings of  #TAUTHOR_TAG, while we normalize the embedding and use an orthogonal transform to conduct bilingual translation.', 'multilingual learning can be categorized into projection - based approaches and regularizationbased approaches.', '']",3
"['##11 ) 2.', ""for an easy comparison, we largely follow mikolov's settings in  #TAUTHOR_TAG and set english and spanish as the source and target language, respectively."", 'the data preparation involves the following steps.', 'firstly, the text was token']","['emnlp 2011 smt workshop ( wmt11 ) 2.', ""for an easy comparison, we largely follow mikolov's settings in  #TAUTHOR_TAG and set english and spanish as the source and target language, respectively."", 'the data preparation involves the following steps.', 'firstly, the text was tokenized by the standard scripts provided by wmt11 3, and then duplicated sentences were']","['##11 ) 2.', ""for an easy comparison, we largely follow mikolov's settings in  #TAUTHOR_TAG and set english and spanish as the source and target language, respectively."", 'the data preparation involves the following steps.', 'firstly, the text was tokenized by the standard scripts provided by wm']","['monolingual word embedding is conducted with the data published by the emnlp 2011 smt workshop ( wmt11 ) 2.', ""for an easy comparison, we largely follow mikolov's settings in  #TAUTHOR_TAG and set english and spanish as the source and target language, respectively."", 'the data preparation involves the following steps.', 'firstly, the text was tokenized by the standard scripts provided by wmt11 3, and then duplicated sentences were removed.', ""the numerical expressions were tokenized as'num ', and special characters ( such as!?, : ) were removed."", 'the word2vector toolkit 4 was used to train the word embedding model.', 'we chose the skip - gram model and the text window was set to 5.', 'the training resulted in embedding of 169k english tokens and 116k spanish tokens']",3
"[', respectively.', 'these results are comparable with the results reported in']","['respectively.', 'these results are comparable with the results reported in']","[', respectively.', 'these results are comparable with the results reported in']","['', 'these results are comparable with the results reported in']",3
['beyond the model of  #AUTHOR_TAG a ;  #TAUTHOR_TAG ( significant at'],['beyond the model of  #AUTHOR_TAG a ;  #TAUTHOR_TAG ( significant at'],"['beyond the model of  #AUTHOR_TAG a ;  #TAUTHOR_TAG ( significant at p < 0. 001 ), which']","['', 'the reranking model makes use of syntactic features together with a parameter estimation method that is based on the perceptron algorithm.', 'we describe experiments on the switchboard speech recognition task.', 'the syntactic features provide an additional 0. 3 % reduction in test - set error rate beyond the model of  #AUTHOR_TAG a ;  #TAUTHOR_TAG ( significant at p < 0. 001 ), which makes use of a discriminatively trained n - gram model, giving a total reduction of 1. 2 % over the baseline switchboard system']",4
"['the two training algorithms described in  #TAUTHOR_TAG,']","['the two training algorithms described in  #TAUTHOR_TAG,']","['of examples ( a i, w i ) for i = 1...', ""m, where a i is the i'th acoustic input, and w i is the transcription of this input."", 'we briefly review the two training algorithms described in  #TAUTHOR_TAG,']","['now describe how the parameter vectorα is estimated from a set of training utterances.', 'the training set consists of examples ( a i, w i ) for i = 1...', ""m, where a i is the i'th acoustic input, and w i is the transcription of this input."", 'we briefly review the two training algorithms described in  #TAUTHOR_TAG, the perceptron algorithm and global conditional log - linear models ( gclms ).', '']",4
[' #AUTHOR_TAG a ;  #TAUTHOR_TAG has shown that discriminative methods within an ngram'],"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG has shown that discriminative methods within an ngram approach can lead to significant reductions in wer, in spite of the features being of']","['', 'end goal in speech recognition, i. e., word error rate. previous work  #AUTHOR_TAG a ;  #TAUTHOR_TAG has shown that discriminative methods within an ngram approach can lead to significant reductions in wer, in spite of the features being of']","['where the syntactic language model has the task of modeling a distribution over strings in the language, in a very similar way to traditional n - gram language models. the structured', 'language model  #AUTHOR_TAG makes use of an incremental shift - reduce parser to enable the probability of words to be conditioned on k previous c - commanding lexical heads, rather than simply on the previous k words. incremental topdown and left - corner parsing  #AUTHOR_TAG a ;  #AUTHOR_TAG b ) and head', '- driven parsing  #AUTHOR_TAG approaches have directly used generative pcfg models as language models. in the work of wen wang and mary harper  #AUTHOR_TAG, a constraint dependency grammar and a finite - state tagging model derived from that', 'grammar were used to exploit syntactic dependencies. our approach differs from previous work in a couple of important respects. first, through the featurevector representations φ', '( a, w ) we can essentially incorporate arbitrary sources of information from the string or parse tree into the model. we would argue that our method allows', 'considerably more flexibility in terms of the choice of features in the model ; in previous work', 'features were incorporated in the model through modification of the underlying generative parsing or', 'tagging model, and modifying a generative model is a rather indirect way of changing the features used by a', 'model. in this respect, our approach is similar to that advocated in  #AUTHOR_TAG, which used maximum', 'entropy modeling to allow for the use of shallow syntactic features for', 'language modeling. a second contrast between our work and previous work, including that of  #AUTHOR_TAG, is', 'in the use of discriminative parameter estimation techniques. the criterion we use to optimize the parameter vectorα is closely related to the', 'end goal in speech recognition, i. e., word error rate. previous work  #AUTHOR_TAG a ;  #TAUTHOR_TAG has shown that discriminative methods within an ngram approach can lead to significant reductions in wer, in spite of the features being of the same type as the original language model. in this paper we extend this approach, by including syntactic features that were not in the baseline speech recognizer. this paper describe experiments using a variety of syntactic features within this approach. we tested the model on the switchboard ( swb ) domain, using the recognizer of  #AUTHOR_TAG. the discriminative approach for n', '- gram modeling gave a 0. 9 % reduction in wer on this domain ; the syntactic features we describe give a further 0. 3 % reduction. in the remainder of this paper, section 2 describes previous work', ', including the parameter estimation methods we use, and section 3 describes the featurevector representations of parse trees that we used in our experiments. section 4 describes experiments using the approach']",6
"['the two training algorithms described in  #TAUTHOR_TAG,']","['the two training algorithms described in  #TAUTHOR_TAG,']","['of examples ( a i, w i ) for i = 1...', ""m, where a i is the i'th acoustic input, and w i is the transcription of this input."", 'we briefly review the two training algorithms described in  #TAUTHOR_TAG,']","['now describe how the parameter vectorα is estimated from a set of training utterances.', 'the training set consists of examples ( a i, w i ) for i = 1...', ""m, where a i is the i'th acoustic input, and w i is the transcription of this input."", 'we briefly review the two training algorithms described in  #TAUTHOR_TAG, the perceptron algorithm and global conditional log - linear models ( gclms ).', '']",6
[' #AUTHOR_TAG a ;  #TAUTHOR_TAG has shown that discriminative methods within an ngram'],"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG has shown that discriminative methods within an ngram approach can lead to significant reductions in wer, in spite of the features being of']","['', 'end goal in speech recognition, i. e., word error rate. previous work  #AUTHOR_TAG a ;  #TAUTHOR_TAG has shown that discriminative methods within an ngram approach can lead to significant reductions in wer, in spite of the features being of']","['where the syntactic language model has the task of modeling a distribution over strings in the language, in a very similar way to traditional n - gram language models. the structured', 'language model  #AUTHOR_TAG makes use of an incremental shift - reduce parser to enable the probability of words to be conditioned on k previous c - commanding lexical heads, rather than simply on the previous k words. incremental topdown and left - corner parsing  #AUTHOR_TAG a ;  #AUTHOR_TAG b ) and head', '- driven parsing  #AUTHOR_TAG approaches have directly used generative pcfg models as language models. in the work of wen wang and mary harper  #AUTHOR_TAG, a constraint dependency grammar and a finite - state tagging model derived from that', 'grammar were used to exploit syntactic dependencies. our approach differs from previous work in a couple of important respects. first, through the featurevector representations φ', '( a, w ) we can essentially incorporate arbitrary sources of information from the string or parse tree into the model. we would argue that our method allows', 'considerably more flexibility in terms of the choice of features in the model ; in previous work', 'features were incorporated in the model through modification of the underlying generative parsing or', 'tagging model, and modifying a generative model is a rather indirect way of changing the features used by a', 'model. in this respect, our approach is similar to that advocated in  #AUTHOR_TAG, which used maximum', 'entropy modeling to allow for the use of shallow syntactic features for', 'language modeling. a second contrast between our work and previous work, including that of  #AUTHOR_TAG, is', 'in the use of discriminative parameter estimation techniques. the criterion we use to optimize the parameter vectorα is closely related to the', 'end goal in speech recognition, i. e., word error rate. previous work  #AUTHOR_TAG a ;  #TAUTHOR_TAG has shown that discriminative methods within an ngram approach can lead to significant reductions in wer, in spite of the features being of the same type as the original language model. in this paper we extend this approach, by including syntactic features that were not in the baseline speech recognizer. this paper describe experiments using a variety of syntactic features within this approach. we tested the model on the switchboard ( swb ) domain, using the recognizer of  #AUTHOR_TAG. the discriminative approach for n', '- gram modeling gave a 0. 9 % reduction in wer on this domain ; the syntactic features we describe give a further 0. 3 % reduction. in the remainder of this paper, section 2 describes previous work', ', including the parameter estimation methods we use, and section 3 describes the featurevector representations of parse trees that we used in our experiments. section 4 describes experiments using the approach']",3
['to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG'],['to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG'],"['to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'the model we propose consists of the following components :', '• gen ( a ) is a set of candidate strings for an acoustic input a. in our case, gen ( a ) is a set of']","['follow the framework of  #AUTHOR_TAG ; 2004 ), recently applied to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'the model we propose consists of the following components :', '• gen ( a ) is a set of candidate strings for an acoustic input a. in our case, gen ( a ) is a set of 1000 - best strings from a first - pass recognizer.', '']",3
"['the two training algorithms described in  #TAUTHOR_TAG,']","['the two training algorithms described in  #TAUTHOR_TAG,']","['of examples ( a i, w i ) for i = 1...', ""m, where a i is the i'th acoustic input, and w i is the transcription of this input."", 'we briefly review the two training algorithms described in  #TAUTHOR_TAG,']","['now describe how the parameter vectorα is estimated from a set of training utterances.', 'the training set consists of examples ( a i, w i ) for i = 1...', ""m, where a i is the i'th acoustic input, and w i is the transcription of this input."", 'we briefly review the two training algorithms described in  #TAUTHOR_TAG, the perceptron algorithm and global conditional log - linear models ( gclms ).', '']",3
"['experimental set - up we use is very similar to that of  #AUTHOR_TAG a ;  #TAUTHOR_TAG, and the extensions to that work in  #AUTHOR_TAG.', 'we']","['experimental set - up we use is very similar to that of  #AUTHOR_TAG a ;  #TAUTHOR_TAG, and the extensions to that work in  #AUTHOR_TAG.', 'we']","['experimental set - up we use is very similar to that of  #AUTHOR_TAG a ;  #TAUTHOR_TAG, and the extensions to that work in  #AUTHOR_TAG.', 'we make use of the rich transcription 2002 evaluation test set (']","['experimental set - up we use is very similar to that of  #AUTHOR_TAG a ;  #TAUTHOR_TAG, and the extensions to that work in  #AUTHOR_TAG.', 'we make use of the rich transcription 2002 evaluation test set ( rt02 ) as our development set, and use the rich transcription 2003 spring evaluation cts test set ( rt03 ) as test set.', '']",3
['to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG'],['to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG'],"['to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'the model we propose consists of the following components :', '• gen ( a ) is a set of candidate strings for an acoustic input a. in our case, gen ( a ) is a set of']","['follow the framework of  #AUTHOR_TAG ; 2004 ), recently applied to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'the model we propose consists of the following components :', '• gen ( a ) is a set of candidate strings for an acoustic input a. in our case, gen ( a ) is a set of 1000 - best strings from a first - pass recognizer.', '']",5
"['the two training algorithms described in  #TAUTHOR_TAG,']","['the two training algorithms described in  #TAUTHOR_TAG,']","['of examples ( a i, w i ) for i = 1...', ""m, where a i is the i'th acoustic input, and w i is the transcription of this input."", 'we briefly review the two training algorithms described in  #TAUTHOR_TAG,']","['now describe how the parameter vectorα is estimated from a set of training utterances.', 'the training set consists of examples ( a i, w i ) for i = 1...', ""m, where a i is the i'th acoustic input, and w i is the transcription of this input."", 'we briefly review the two training algorithms described in  #TAUTHOR_TAG, the perceptron algorithm and global conditional log - linear models ( gclms ).', '']",5
"['experimental set - up we use is very similar to that of  #AUTHOR_TAG a ;  #TAUTHOR_TAG, and the extensions to that work in  #AUTHOR_TAG.', 'we']","['experimental set - up we use is very similar to that of  #AUTHOR_TAG a ;  #TAUTHOR_TAG, and the extensions to that work in  #AUTHOR_TAG.', 'we']","['experimental set - up we use is very similar to that of  #AUTHOR_TAG a ;  #TAUTHOR_TAG, and the extensions to that work in  #AUTHOR_TAG.', 'we make use of the rich transcription 2002 evaluation test set (']","['experimental set - up we use is very similar to that of  #AUTHOR_TAG a ;  #TAUTHOR_TAG, and the extensions to that work in  #AUTHOR_TAG.', 'we make use of the rich transcription 2002 evaluation test set ( rt02 ) as our development set, and use the rich transcription 2003 spring evaluation cts test set ( rt03 ) as test set.', '']",5
['to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG'],['to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG'],"['to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'the model we propose consists of the following components :', '• gen ( a ) is a set of candidate strings for an acoustic input a. in our case, gen ( a ) is a set of']","['follow the framework of  #AUTHOR_TAG ; 2004 ), recently applied to language modeling in  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'the model we propose consists of the following components :', '• gen ( a ) is a set of candidate strings for an acoustic input a. in our case, gen ( a ) is a set of 1000 - best strings from a first - pass recognizer.', '']",0
"['the two training algorithms described in  #TAUTHOR_TAG,']","['the two training algorithms described in  #TAUTHOR_TAG,']","['of examples ( a i, w i ) for i = 1...', ""m, where a i is the i'th acoustic input, and w i is the transcription of this input."", 'we briefly review the two training algorithms described in  #TAUTHOR_TAG,']","['now describe how the parameter vectorα is estimated from a set of training utterances.', 'the training set consists of examples ( a i, w i ) for i = 1...', ""m, where a i is the i'th acoustic input, and w i is the transcription of this input."", 'we briefly review the two training algorithms described in  #TAUTHOR_TAG, the perceptron algorithm and global conditional log - linear models ( gclms ).', '']",0
"['to explore the alternative parameter estimation methods described in  #AUTHOR_TAG a ;  #TAUTHOR_TAG, which']","['to explore the alternative parameter estimation methods described in  #AUTHOR_TAG a ;  #TAUTHOR_TAG, which']","['was provided by the n - gram features.', 'future work will include a further investigation of parserderived features.', 'in addition, we plan to explore the alternative parameter estimation methods described in  #AUTHOR_TAG a ;  #TAUTHOR_TAG, which were shown in this previous work to give further improvements over the perceptron']","['results presented in this paper are a first step in examining the potential utility of syntactic features for discriminative language modeling for speech recognition.', 'we tried two possible sets of features derived from the full annotation, as well as a variety of possible feature sets derived from shallow parse and pos tag sequences, the best of which gave a small but significant improvement beyond what was provided by the n - gram features.', 'future work will include a further investigation of parserderived features.', 'in addition, we plan to explore the alternative parameter estimation methods described in  #AUTHOR_TAG a ;  #TAUTHOR_TAG, which were shown in this previous work to give further improvements over the perceptron']",2
"['.', 'also, such embeddings are usually trained on indonesian wikipedia  #TAUTHOR_TAG whose size is relatively small,']","['semantic information as measured by analogy tasks.', 'also, such embeddings are usually trained on indonesian wikipedia  #TAUTHOR_TAG whose size is relatively small,']","['semantic information as measured by analogy tasks.', 'also, such embeddings are usually trained on indonesian wikipedia  #TAUTHOR_TAG whose size is relatively small, approximately 60m tokens.', 'therefore, in this work, we introduce kaw']","['the existence of various indonesian pretrained word embeddings, there are no publicly available indonesian analogy task datasets on which to evaluate these embeddings.', 'consequently, it is unknown if indonesian word embeddings introduced in, e. g., ( al -  #AUTHOR_TAG and  #AUTHOR_TAG, capture syntactic or semantic information as measured by analogy tasks.', 'also, such embeddings are usually trained on indonesian wikipedia  #TAUTHOR_TAG whose size is relatively small, approximately 60m tokens.', 'therefore, in this work, we introduce kawat ( kata word analogy task ), an indonesian word analogy task dataset, and new indonesian word embeddings pretrained on 160m tokens of online news corpus.', 'we evaluated these embeddings on kawat, and also tested them on pos tagging and text summarization as representatives of syntactic and semantic downstream task respectively']",0
"['.', 'also, such embeddings are usually trained on indonesian wikipedia  #TAUTHOR_TAG whose size is relatively small,']","['semantic information as measured by analogy tasks.', 'also, such embeddings are usually trained on indonesian wikipedia  #TAUTHOR_TAG whose size is relatively small,']","['semantic information as measured by analogy tasks.', 'also, such embeddings are usually trained on indonesian wikipedia  #TAUTHOR_TAG whose size is relatively small, approximately 60m tokens.', 'therefore, in this work, we introduce kaw']","['the existence of various indonesian pretrained word embeddings, there are no publicly available indonesian analogy task datasets on which to evaluate these embeddings.', 'consequently, it is unknown if indonesian word embeddings introduced in, e. g., ( al -  #AUTHOR_TAG and  #AUTHOR_TAG, capture syntactic or semantic information as measured by analogy tasks.', 'also, such embeddings are usually trained on indonesian wikipedia  #TAUTHOR_TAG whose size is relatively small, approximately 60m tokens.', 'therefore, in this work, we introduce kawat ( kata word analogy task ), an indonesian word analogy task dataset, and new indonesian word embeddings pretrained on 160m tokens of online news corpus.', 'we evaluated these embeddings on kawat, and also tested them on pos tagging and text summarization as representatives of syntactic and semantic downstream task respectively']",1
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[' #TAUTHOR_TAG.', 'however, to our knowledge no work has evaluated the usefulness of discourse relations']",[' #TAUTHOR_TAG'],0
"[',  #TAUTHOR_TAG experimentally showed that discourse relations']","['', 'in particular,  #TAUTHOR_TAG experimentally showed that discourse relations']","[',  #TAUTHOR_TAG experimentally showed that discourse relations']","['', 'in particular,  #TAUTHOR_TAG experimentally showed that discourse relations can improve the coherence of multi - document summaries.', ' #AUTHOR_TAG showed how discourse relations can be used effectively to incorporate additional contextual information for a given question in a query - based summarization.', '( blair - goldensohn and mc  #AUTHOR_TAG used discourse relations for content selection and organization of automatic summaries and achieved an improvement in both cases.', 'discourse relations were also used successfully by  #AUTHOR_TAG for news summarization.', 'however, the work described above have been developed for formal, well - written and factual documents.', 'most of these work show how discourse relations can be used in text summarization and show their overall usefulness.', 'to the best of our knowledge, our work is the first to measure the effect of specific relations on the summarization of informal and opinionated text']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],['the pdtb : penn discourse treebank research group  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],['the pdtb : penn discourse treebank research group  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],['the pdtb : penn discourse treebank research group  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],['the pdtb : penn discourse treebank research group  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
"['have proposed a new approach to tag attributive relations  #TAUTHOR_TAG.', 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a']","['have proposed a new approach to tag attributive relations  #TAUTHOR_TAG.', 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a']","['to identify topic - opinion relations ; and we have proposed a new approach to tag attributive relations  #TAUTHOR_TAG.', 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a sentence is tagged with all possible discourse relations that it contains']","['', 'however, at the time this research was done, the only publicly available discourse parser was spade  #AUTHOR_TAG which operates on individual sentences.', 'to identify illustration, contingency, comparison, and attribution relations, we have used spade discourse parser.', ""however, we have complemented this parser with three other approaches :  #AUTHOR_TAG's approach is used to identify intra - sentence comparison relations ; we have designed a tagger based on  #AUTHOR_TAG's approach to identify topic - opinion relations ; and we have proposed a new approach to tag attributive relations  #TAUTHOR_TAG."", 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a sentence is tagged with all possible discourse relations that it contains']",0
['summary ( details of blogsum can be found in  #TAUTHOR_TAG'],['summary ( details of blogsum can be found in  #TAUTHOR_TAG'],['to create the final summary ( details of blogsum can be found in  #TAUTHOR_TAG'],"['', 'according to this schema 8, one or more sentences containing a topic - opinion or attribution relation followed by zero or many sentences containing a contingency or comparison relation followed by zero or many sentences containing a attributive relation should be used.', 'finally the most appropriate schema is selected based on a given question type ; and candidate sentences fill particular slots in the selected schema based on which discourse relations they contain in order to create the final summary ( details of blogsum can be found in  #TAUTHOR_TAG']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],['the pdtb : penn discourse treebank research group  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],3
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],['the pdtb : penn discourse treebank research group  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],6
"['have proposed a new approach to tag attributive relations  #TAUTHOR_TAG.', 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a']","['have proposed a new approach to tag attributive relations  #TAUTHOR_TAG.', 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a']","['to identify topic - opinion relations ; and we have proposed a new approach to tag attributive relations  #TAUTHOR_TAG.', 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a sentence is tagged with all possible discourse relations that it contains']","['', 'however, at the time this research was done, the only publicly available discourse parser was spade  #AUTHOR_TAG which operates on individual sentences.', 'to identify illustration, contingency, comparison, and attribution relations, we have used spade discourse parser.', ""however, we have complemented this parser with three other approaches :  #AUTHOR_TAG's approach is used to identify intra - sentence comparison relations ; we have designed a tagger based on  #AUTHOR_TAG's approach to identify topic - opinion relations ; and we have proposed a new approach to tag attributive relations  #TAUTHOR_TAG."", 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a sentence is tagged with all possible discourse relations that it contains']",6
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],['the pdtb : penn discourse treebank research group  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],4
"['have proposed a new approach to tag attributive relations  #TAUTHOR_TAG.', 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a']","['have proposed a new approach to tag attributive relations  #TAUTHOR_TAG.', 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a']","['to identify topic - opinion relations ; and we have proposed a new approach to tag attributive relations  #TAUTHOR_TAG.', 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a sentence is tagged with all possible discourse relations that it contains']","['', 'however, at the time this research was done, the only publicly available discourse parser was spade  #AUTHOR_TAG which operates on individual sentences.', 'to identify illustration, contingency, comparison, and attribution relations, we have used spade discourse parser.', ""however, we have complemented this parser with three other approaches :  #AUTHOR_TAG's approach is used to identify intra - sentence comparison relations ; we have designed a tagger based on  #AUTHOR_TAG's approach to identify topic - opinion relations ; and we have proposed a new approach to tag attributive relations  #TAUTHOR_TAG."", 'a description and evaluation of these approaches can be found in  #TAUTHOR_TAG.', 'by combining these approaches, a sentence is tagged with all possible discourse relations that it contains']",5
"[': blogsum  #TAUTHOR_TAG, the best scoring']","['different summarizers : blogsum  #TAUTHOR_TAG, the best scoring']","['each relation with four different summarizers : blogsum  #TAUTHOR_TAG, the best scoring system']","['measure the usefulness of discourse relations for the summarization of informal texts, we have tested the effect of each relation with four different summarizers : blogsum  #TAUTHOR_TAG, the best scoring system at tac 2008 5 and the best scoring system at duc 2007 6.', 'we have evaluated the effect of each discourse relation on the summaries generated and compared the results.', 'let us first describe the blogsum summarizer']",5
"[' #TAUTHOR_TAG, a publicly available and a', 'widely used']","[' #TAUTHOR_TAG, a publicly available and a', 'widely used']","[' #TAUTHOR_TAG, a publicly available and a', 'widely used summarizer, and with']","['##4 to 0. 128. in order to verify if these improvements were statistically significant,', 'we performed a 2 - tailed ttest. the results of this test are indicated with the [UNK] symbol in tables 3 and 4. for example, the baseline setup of blogsum performed significantly lower for', 'both r - 2 and r - su4 compared to blogsum with all relations. this result indicates that the use of discourse relations as a whole helps to include more question relevant sentences', 'and improve the summary content. to ensure that the results were not specific to our summarizer, we performed the same experiments with two other systems : the mead summarizer  #TAUTHOR_TAG, a publicly available and a', '']",5
"['single - and multi - word disorder annotations  #TAUTHOR_TAG.', '']","['single - and multi - word disorder annotations  #TAUTHOR_TAG.', '']","['##7 single - and multi - word disorder annotations  #TAUTHOR_TAG.', '']","['dataset is a gold standard corpus of 1557 single - and multi - word disorder annotations  #TAUTHOR_TAG.', 'for training and testing the crf and svm models the iob ( inside - outside - begin ) notation  #AUTHOR_TAG was applied.', 'in our project, we used 1265 gold standard annotations for training and 292 for testing.', 'the features used for the learning process are described as follows.', 'dictionary look - up is a binary value feature that represents if the ne is in the dictionary ( snomed - ct ).', 'bag of words ( bow ) is a representation of the context by the unique words in it.', 'part - of - speech tags ( pos ) of bow is the pos tags of the context words.', 'window size is the number of tokens representing context surrounding the target word.', 'orientation ( left or right ) is the location of the feature in regard to the target word.', 'distance is the proximity of the feature in regard to the target word capitalization has one of the four token - based values : all upper case, all lower case, mixed _ case and initial upper case.', 'number features refer to the presence or absence of related numbers.', 'feature sets are in table 1']",5
"['', 'bidirectional encoder representations from transformers ( bert ;  #TAUTHOR_TAG represents one of the latest developments in this']","['similarity modeling, to name a few.', 'bidirectional encoder representations from transformers ( bert ;  #TAUTHOR_TAG represents one of the latest developments in this']","['similarity modeling, to name a few.', 'bidirectional encoder representations from transformers ( bert ;  #TAUTHOR_TAG represents one of the latest developments in this line']","['', 'bidirectional encoder representations from transformers ( bert ;  #TAUTHOR_TAG represents one of the latest developments in this line of work.', 'it outperforms its predecessors, elmo  #AUTHOR_TAG and gpt ( radford et al. ), staggeringly exceeding state of the art by a wide margin on multiple natural language understanding tasks.', '']",0
"['', 'bidirectional encoder representations from transformers ( bert ;  #TAUTHOR_TAG currently represents state of the']","['natural language inference, to name a few.', 'bidirectional encoder representations from transformers ( bert ;  #TAUTHOR_TAG currently represents state of the art, vastly outperforming']","['natural language inference, to name a few.', 'bidirectional encoder representations from transformers ( bert ;  #TAUTHOR_TAG currently represents state of the art, vastly outperforming previous models, such']","['', 'bidirectional encoder representations from transformers ( bert ;  #TAUTHOR_TAG currently represents state of the art, vastly outperforming previous models, such as the generative pretrained transformer ( gpt ; radford et al. ) and embeddings from language models ( elmo ;  #AUTHOR_TAG']",0
"['with  #TAUTHOR_TAG, we find that choosing a batch size of 16,']","['with  #TAUTHOR_TAG, we find that choosing a batch size of 16,']","['only one epoch.', 'as is the case with  #TAUTHOR_TAG, we find that choosing a batch size of 16, learning rate']","['tune the number of epochs, batch size, learning rate, and maximum sequence length ( msl ), the number of tokens that documents are truncated to.', 'we observe that model quality is quite sensitive to the number of epochs, and thus the number must be tailored for each dataset.', 'we finetune on reuters, aapd, and imdb for 30, 20 and 4 epochs, respectively.', 'due to resource constraints, we fine - tune on yelp for only one epoch.', 'as is the case with  #TAUTHOR_TAG, we find that choosing a batch size of 16, learning rate of 2×10 −5, and msl of 512 tokens yields optimal performance on the validation sets of all datasets.', 'hyperparameter study.', 'to gauge the improvement over the default hyperparameters, as well as to highlight the differences in fine - tuning bert for document classification, we explore varying several key hyperparameters : namely, the number of epochs and the msl.', 'originally,  #TAUTHOR_TAG find that fine - tuning for three or four epochs works well for both small and large datasets alike.', '']",0
"['##ing with  #TAUTHOR_TAG, bert large']","['##ing with  #TAUTHOR_TAG, bert large']","['##ing with  #TAUTHOR_TAG, bert large achieves']","['##ing with  #TAUTHOR_TAG, bert large achieves state - of - the - art results on all four datasets, followed by bert base ( see table 2, rows 11 and 12 ).', 'the considerably simpler lstm reg model ( row 10 ) achieves a high f 1 and accuracy of 87. 0 and 52. 8, respectively, coming close to the quality of bert base.', 'surprisingly, the lr and svm baselines yield competitive results for the multi - label datasets.', 'for instance, the svm approaches bert base results on reuters, with an f 1 score of 86. 1, astonishingly exceeding most of our neural baselines ( rows 2 - 11 ).', 'this can also be observed on aapd, where the svm surpasses most of the neural models, except sgm, lstm reg, and bert.', 'however, on the single - label datasets, both lr and svm perform worse than even our simple neural baselines, such as kimcnn.', 'it is worth noting that lr and svm take only a fraction of the time and resources for training our neural models']",0
"['large model variants  #TAUTHOR_TAG.', 'to adapt bert']","['large model variants  #TAUTHOR_TAG.', 'to adapt bert']","['large model variants  #TAUTHOR_TAG.', 'to adapt bert']","['begin with the pre - trained bert base and bert large models, which respectively represent the normal and large model variants  #TAUTHOR_TAG.', 'to adapt bert for document classifica - figure 1.', 'during fine - tuning, we optimize the entire model end - to - end, with the additional softmax classifier parameters w ∈ ir k×h, where h is the dimension of the hidden state vectors and k is the number of classes.', 'we minimize the crossentropy and binary cross - entropy loss for singlelabel and multi - label tasks, respectively']",5
"['large model variants  #TAUTHOR_TAG.', 'to adapt bert']","['large model variants  #TAUTHOR_TAG.', 'to adapt bert']","['large model variants  #TAUTHOR_TAG.', 'to adapt bert']","['begin with the pre - trained bert base and bert large models, which respectively represent the normal and large model variants  #TAUTHOR_TAG.', 'to adapt bert for document classifica - figure 1.', 'during fine - tuning, we optimize the entire model end - to - end, with the additional softmax classifier parameters w ∈ ir k×h, where h is the dimension of the hidden state vectors and k is the number of classes.', 'we minimize the crossentropy and binary cross - entropy loss for singlelabel and multi - label tasks, respectively']",6
"['with  #TAUTHOR_TAG, we find that choosing a batch size of 16,']","['with  #TAUTHOR_TAG, we find that choosing a batch size of 16,']","['only one epoch.', 'as is the case with  #TAUTHOR_TAG, we find that choosing a batch size of 16, learning rate']","['tune the number of epochs, batch size, learning rate, and maximum sequence length ( msl ), the number of tokens that documents are truncated to.', 'we observe that model quality is quite sensitive to the number of epochs, and thus the number must be tailored for each dataset.', 'we finetune on reuters, aapd, and imdb for 30, 20 and 4 epochs, respectively.', 'due to resource constraints, we fine - tune on yelp for only one epoch.', 'as is the case with  #TAUTHOR_TAG, we find that choosing a batch size of 16, learning rate of 2×10 −5, and msl of 512 tokens yields optimal performance on the validation sets of all datasets.', 'hyperparameter study.', 'to gauge the improvement over the default hyperparameters, as well as to highlight the differences in fine - tuning bert for document classification, we explore varying several key hyperparameters : namely, the number of epochs and the msl.', 'originally,  #TAUTHOR_TAG find that fine - tuning for three or four epochs works well for both small and large datasets alike.', '']",3
"['##ing with  #TAUTHOR_TAG, bert large']","['##ing with  #TAUTHOR_TAG, bert large']","['##ing with  #TAUTHOR_TAG, bert large achieves']","['##ing with  #TAUTHOR_TAG, bert large achieves state - of - the - art results on all four datasets, followed by bert base ( see table 2, rows 11 and 12 ).', 'the considerably simpler lstm reg model ( row 10 ) achieves a high f 1 and accuracy of 87. 0 and 52. 8, respectively, coming close to the quality of bert base.', 'surprisingly, the lr and svm baselines yield competitive results for the multi - label datasets.', 'for instance, the svm approaches bert base results on reuters, with an f 1 score of 86. 1, astonishingly exceeding most of our neural baselines ( rows 2 - 11 ).', 'this can also be observed on aapd, where the svm surpasses most of the neural models, except sgm, lstm reg, and bert.', 'however, on the single - label datasets, both lr and svm perform worse than even our simple neural baselines, such as kimcnn.', 'it is worth noting that lr and svm take only a fraction of the time and resources for training our neural models']",3
"['with  #TAUTHOR_TAG, we find that choosing a batch size of 16,']","['with  #TAUTHOR_TAG, we find that choosing a batch size of 16,']","['only one epoch.', 'as is the case with  #TAUTHOR_TAG, we find that choosing a batch size of 16, learning rate']","['tune the number of epochs, batch size, learning rate, and maximum sequence length ( msl ), the number of tokens that documents are truncated to.', 'we observe that model quality is quite sensitive to the number of epochs, and thus the number must be tailored for each dataset.', 'we finetune on reuters, aapd, and imdb for 30, 20 and 4 epochs, respectively.', 'due to resource constraints, we fine - tune on yelp for only one epoch.', 'as is the case with  #TAUTHOR_TAG, we find that choosing a batch size of 16, learning rate of 2×10 −5, and msl of 512 tokens yields optimal performance on the validation sets of all datasets.', 'hyperparameter study.', 'to gauge the improvement over the default hyperparameters, as well as to highlight the differences in fine - tuning bert for document classification, we explore varying several key hyperparameters : namely, the number of epochs and the msl.', 'originally,  #TAUTHOR_TAG find that fine - tuning for three or four epochs works well for both small and large datasets alike.', '']",1
"['##s.', 'contrary to  #TAUTHOR_TAG, who achieve']","['2 illustrate the f 1 score of bert fine - tuned using a various number of epochs for aapd and reuters.', 'contrary to  #TAUTHOR_TAG, who achieve']","['##s.', 'contrary to  #TAUTHOR_TAG, who achieve']","['', 'a decrease in the msl corresponds to only a minor loss in f 1 on reuters ( see leftmost chart in figure 2 ), possibly due to reuters having shorter sentences.', 'on imdb ( second subplot from left ), lowering the msl corresponds to a drastic fall in accuracy, suggesting that the entire document is necessary for this dataset.', 'on the one hand, these results appear obvious.', 'alternatively, one can argue that, since imdb contains longer documents, truncating tokens may hurt less.', 'figure 2 shows that this is not the case, since truncating to even 256 tokens causes accuracy to fall lower than that of the much smaller lstm reg ( see table 2 ).', 'from these results, we conclude that any amount of truncation is detrimental in document classification, but the level of degradation may differ.', 'epoch analysis.', 'the rightmost two subplots in figure 2 illustrate the f 1 score of bert fine - tuned using a various number of epochs for aapd and reuters.', 'contrary to  #TAUTHOR_TAG, who achieve state of the art on small datasets with only a few epochs of fine - tuning, we find that smaller datasets require many more epochs to converge.', 'on both the datasets ( see figure 2 ), we see a significant drop in model quality when the bert models are fine - tuned on only four epochs, as suggested in the original paper.', 'on reuters, using four epochs results in an f 1 worse than even logistic regression ( table 2, row 1 )']",4
"['( soa ) models of speaker commitment :  #TAUTHOR_TAG and.', 'the commitmentbank, restricted to specific linguistic constructions, is a good test case.', 'it allows us to']","['state - of - the - art ( soa ) models of speaker commitment :  #TAUTHOR_TAG and.', 'the commitmentbank, restricted to specific linguistic constructions, is a good test case.', 'it allows us to']","['( soa ) models of speaker commitment :  #TAUTHOR_TAG and.', 'the commitmentbank, restricted to specific linguistic constructions, is a good test case.', 'it allows us to']","['of speaker commitment 1 is the task of determining to what extent the speaker is committed to an event in a sentence as actual, nonactual, or uncertain.', 'this matters for downstream nlp applications, such as information extraction or question answering : for instance, we should extract from example ( 1 ) in table 1 that the speaker could wish someone dead, but from ( 3 ) that people should not be allowed to carry guns in their vehicles, even though both events are embedded under believe and negation.', 'there has been work on factors leading to speaker commitment in theoretical linguistics ( i. a.,  #AUTHOR_TAG ;  #AUTHOR_TAG ) and computational linguistics ( i. a.,  #AUTHOR_TAG ; sauri and  #AUTHOR_TAG ;  #AUTHOR_TAG ), but mostly on constructed or newswire examples, which may simplify the task by failing to reflect the lexical and syntactic diversity of naturally occurring utterances.', 'de  #AUTHOR_TAG introduced the commitmentbank, a dataset of naturally occurring sentences annotated with speaker commitment towards the content of complements of clause - embedding verbs under canceling - entailment environments ( negation, modal, question and conditional ), to study the linguistic correlates of speaker commitment.', 'in this paper, we use it to evaluate two state - of - the - art ( soa ) models of speaker commitment :  #TAUTHOR_TAG and.', 'the commitmentbank, restricted to specific linguistic constructions, is a good test case.', 'it allows us to evaluate whether current speaker commitment models achieve robust language understanding, by analyzing their performance on specific challenging linguistic constructions']",5
['##based model  #TAUTHOR_TAG'],['of two speaker commitment models on the commitmentbank : a rulebased model  #TAUTHOR_TAG'],['evaluate the performance of two speaker commitment models on the commitmentbank : a rulebased model  #TAUTHOR_TAG'],"['evaluate the performance of two speaker commitment models on the commitmentbank : a rulebased model  #TAUTHOR_TAG and a neuralbased one.', 'rule - based model  #TAUTHOR_TAG proposed a rule - based model based on a deterministic algorithm based on truthteller  #AUTHOR_TAG, which uses a top - down approach on a de - pendency tree and predicts speaker commitment score in [ −3, 3 ] according to the implicative signatures  #AUTHOR_TAG of the predicates, and whether the predicates are under the scope of negation and uncertainty modifiers.', 'for example, refuse p entails ¬p, so the factuality of its complement p gets flipped if encountered.', 'neural - based model introduced three neural models for speaker commitment : a linear bilstm, a dependency tree bil - stm, a hybrid model that ensembles the two. also proposed a multitask training scheme in which a model is trained on four factuality datasets : factbank ( sauri and  #AUTHOR_TAG, uw  #AUTHOR_TAG, mean - time  #AUTHOR_TAG and uds, all with annotations on a [ −3, 3 ] scale.', 'each dataset has shared bilstm weights but specific regression parameters.', 'reference datasets the factbank, uw, and meantime datasets all consist of sentences from news articles.', ""each event in factbank was annotated by 2 annotators, with 0. 81 cohen's κ."", 'uw has 5 annotations for each event, and meantime has 6.', 'uds contains sentences from the english web treebank  #AUTHOR_TAG, which contains weblogs, newsgroups, emails, reviews, and question - answers.', ""it has 2 annotations for each predicate, with 0. 66 cohen's κ."", 'all four datasets have annotations biased towards + 3, because ( 1 ) they are newswire - heavy with sentences describing known factual events, and ( 2 ) most annotations are for main - clause predicates instead of predicates in an embedded clause.', 'table 2 : the number of annotated predicates in each dataset, and previous state - of - the - art performance.', 'the score on uw with mae was obtained by  #TAUTHOR_TAG, while the other scores were obtained by.', ""and pearson's r correlation, measuring how well the model captures variability in the data."", ""pearson's r is considered more informative than mae because the reference sets are biased towards + 3""]",5
['##based model  #TAUTHOR_TAG'],['of two speaker commitment models on the commitmentbank : a rulebased model  #TAUTHOR_TAG'],['evaluate the performance of two speaker commitment models on the commitmentbank : a rulebased model  #TAUTHOR_TAG'],"['evaluate the performance of two speaker commitment models on the commitmentbank : a rulebased model  #TAUTHOR_TAG and a neuralbased one.', 'rule - based model  #TAUTHOR_TAG proposed a rule - based model based on a deterministic algorithm based on truthteller  #AUTHOR_TAG, which uses a top - down approach on a de - pendency tree and predicts speaker commitment score in [ −3, 3 ] according to the implicative signatures  #AUTHOR_TAG of the predicates, and whether the predicates are under the scope of negation and uncertainty modifiers.', 'for example, refuse p entails ¬p, so the factuality of its complement p gets flipped if encountered.', 'neural - based model introduced three neural models for speaker commitment : a linear bilstm, a dependency tree bil - stm, a hybrid model that ensembles the two. also proposed a multitask training scheme in which a model is trained on four factuality datasets : factbank ( sauri and  #AUTHOR_TAG, uw  #AUTHOR_TAG, mean - time  #AUTHOR_TAG and uds, all with annotations on a [ −3, 3 ] scale.', 'each dataset has shared bilstm weights but specific regression parameters.', 'reference datasets the factbank, uw, and meantime datasets all consist of sentences from news articles.', ""each event in factbank was annotated by 2 annotators, with 0. 81 cohen's κ."", 'uw has 5 annotations for each event, and meantime has 6.', 'uds contains sentences from the english web treebank  #AUTHOR_TAG, which contains weblogs, newsgroups, emails, reviews, and question - answers.', ""it has 2 annotations for each predicate, with 0. 66 cohen's κ."", 'all four datasets have annotations biased towards + 3, because ( 1 ) they are newswire - heavy with sentences describing known factual events, and ( 2 ) most annotations are for main - clause predicates instead of predicates in an embedded clause.', 'table 2 : the number of annotated predicates in each dataset, and previous state - of - the - art performance.', 'the score on uw with mae was obtained by  #TAUTHOR_TAG, while the other scores were obtained by.', ""and pearson's r correlation, measuring how well the model captures variability in the data."", ""pearson's r is considered more informative than mae because the reference sets are biased towards + 3""]",5
"['annotator  #TAUTHOR_TAG,']","['annotator  #TAUTHOR_TAG,']","['based annotator  #TAUTHOR_TAG,']","['on the restricted set, we perform detailed error analysis of the outputs of the rule - based and hybrid bilstm models, which achieved the best figure 3 : pearson r correlation and mean absolute error ( mae ) on all - 2. 0 baseline, rule - based annotator  #TAUTHOR_TAG, and three bilstm models in.', 'pearson r is undefined for all - 2. 0.', 'all correlations are statistically significant ( p < 0. 05 ).', 'correlation.', 'table 3 shows performance for the following linguistic features, and figure 4 shows scatterplots of gold judgments vs. predictions']",5
['##based model  #TAUTHOR_TAG'],['of two speaker commitment models on the commitmentbank : a rulebased model  #TAUTHOR_TAG'],['evaluate the performance of two speaker commitment models on the commitmentbank : a rulebased model  #TAUTHOR_TAG'],"['evaluate the performance of two speaker commitment models on the commitmentbank : a rulebased model  #TAUTHOR_TAG and a neuralbased one.', 'rule - based model  #TAUTHOR_TAG proposed a rule - based model based on a deterministic algorithm based on truthteller  #AUTHOR_TAG, which uses a top - down approach on a de - pendency tree and predicts speaker commitment score in [ −3, 3 ] according to the implicative signatures  #AUTHOR_TAG of the predicates, and whether the predicates are under the scope of negation and uncertainty modifiers.', 'for example, refuse p entails ¬p, so the factuality of its complement p gets flipped if encountered.', 'neural - based model introduced three neural models for speaker commitment : a linear bilstm, a dependency tree bil - stm, a hybrid model that ensembles the two. also proposed a multitask training scheme in which a model is trained on four factuality datasets : factbank ( sauri and  #AUTHOR_TAG, uw  #AUTHOR_TAG, mean - time  #AUTHOR_TAG and uds, all with annotations on a [ −3, 3 ] scale.', 'each dataset has shared bilstm weights but specific regression parameters.', 'reference datasets the factbank, uw, and meantime datasets all consist of sentences from news articles.', ""each event in factbank was annotated by 2 annotators, with 0. 81 cohen's κ."", 'uw has 5 annotations for each event, and meantime has 6.', 'uds contains sentences from the english web treebank  #AUTHOR_TAG, which contains weblogs, newsgroups, emails, reviews, and question - answers.', ""it has 2 annotations for each predicate, with 0. 66 cohen's κ."", 'all four datasets have annotations biased towards + 3, because ( 1 ) they are newswire - heavy with sentences describing known factual events, and ( 2 ) most annotations are for main - clause predicates instead of predicates in an embedded clause.', 'table 2 : the number of annotated predicates in each dataset, and previous state - of - the - art performance.', 'the score on uw with mae was obtained by  #TAUTHOR_TAG, while the other scores were obtained by.', ""and pearson's r correlation, measuring how well the model captures variability in the data."", ""pearson's r is considered more informative than mae because the reference sets are biased towards + 3""]",0
"['. 6 ), we choose to', 'use abstract images  #TAUTHOR_TAG 3, 39, 38, 40 ] as a test bed']","['of visual verification is applicable to real images ( more discussion in sec. 6 ), we choose to', 'use abstract images  #TAUTHOR_TAG 3, 39, 38, 40 ] as a test bed']","['. although our approach of visual verification is applicable to real images ( more discussion in sec. 6 ), we choose to', 'use abstract images  #TAUTHOR_TAG 3, 39, 38, 40 ] as a test bed']","['', 'ended questions. although our approach of visual verification is applicable to real images ( more discussion in sec. 6 ), we choose to', 'use abstract images  #TAUTHOR_TAG 3, 39, 38, 40 ] as a test bed because abstract scene images allow us to focus on high - level semantic reasoning. they also allow us to', 'balance the dataset by making changes to the images, something that would be difficult or impossible with real images. our main contributions are as follows : ( 1 ) we balance the existing abstract binary vqa dataset  #TAUTHOR_TAG', 'by creating complementary scenes so that all questions 1 have an answer of "" yes "" for one scene and an', 'answer of "" no "" for another closely related scene. we show that a languageonly', 'approach performs significantly worse on this balanced dataset. ( 2 ) we propose an approach that summarizes the content of the question in a tuple form which concisely describes the visual concept whose existence is to be verified in the scene. we answer the question by verifying if the tuple is depicted in the scene or not ( see fig. 1 ). we present results when training and testing on', 'the balanced and unbalanced datasets']",5
"['. 6 ), we choose to', 'use abstract images  #TAUTHOR_TAG 3, 39, 38, 40 ] as a test bed']","['of visual verification is applicable to real images ( more discussion in sec. 6 ), we choose to', 'use abstract images  #TAUTHOR_TAG 3, 39, 38, 40 ] as a test bed']","['. although our approach of visual verification is applicable to real images ( more discussion in sec. 6 ), we choose to', 'use abstract images  #TAUTHOR_TAG 3, 39, 38, 40 ] as a test bed']","['', 'ended questions. although our approach of visual verification is applicable to real images ( more discussion in sec. 6 ), we choose to', 'use abstract images  #TAUTHOR_TAG 3, 39, 38, 40 ] as a test bed because abstract scene images allow us to focus on high - level semantic reasoning. they also allow us to', 'balance the dataset by making changes to the images, something that would be difficult or impossible with real images. our main contributions are as follows : ( 1 ) we balance the existing abstract binary vqa dataset  #TAUTHOR_TAG', 'by creating complementary scenes so that all questions 1 have an answer of "" yes "" for one scene and an', 'answer of "" no "" for another closely related scene. we show that a languageonly', 'approach performs significantly worse on this balanced dataset. ( 2 ) we propose an approach that summarizes the content of the question in a tuple form which concisely describes the visual concept whose existence is to be verified in the scene. we answer the question by verifying if the tuple is depicted in the scene or not ( see fig. 1 ). we present results when training and testing on', 'the balanced and unbalanced datasets']",5
"['first describe the vqa dataset for abstract scenes collected by  #TAUTHOR_TAG.', 'we then describe how we balance this dataset by collecting more scenes']","['first describe the vqa dataset for abstract scenes collected by  #TAUTHOR_TAG.', 'we then describe how we balance this dataset by collecting more scenes']","['first describe the vqa dataset for abstract scenes collected by  #TAUTHOR_TAG.', 'we then describe how we balance this dataset by collecting more scenes']","['first describe the vqa dataset for abstract scenes collected by  #TAUTHOR_TAG.', 'we then describe how we balance this dataset by collecting more scenes']",5
['approach  #TAUTHOR_TAG'],['approach  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['have extracted prs tuples and aligned ps to the clipart objects in the image, we can now compute a score indicating the strength of visual evidence for the concept inquired in the question.', 'our scoring function measures compatibility between image and text features ( described in sec. 4. 4 ).', 'our model is an ensemble of two similar models - q - model and tuple - model, whose common architecture is inspired from a recently proposed vqa approach  #TAUTHOR_TAG.', 'specifically, each model takes two inputs ( image and question ), each along a different branch.', 'the two models ( q - model and tuple - model ) use the same image features, but different language features.', 'q - model encodes the sequential nature of the question by feeding it to an lstm and using its 256dim hidden representation as a language embedding, while tuple - model focuses on the important words in the question and uses concatenation of word2vec [ 27 ] embeddings ( 300dim ) of p, r and s as the language features.', 'if p, r or s consist of more than one word, we use the average of the corresponding word2vec embeddings.', '']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['', ') than on unbalanced ( 79 % ). note that the accuracy is higher than 50 % because this is not binary classification accuracy but', 'the vqa accuracy  #TAUTHOR_TAG, which provides partial credit when there is inter - human disagreement in the ground - truth answers. attention helps. when trained on balanced dataset ( where language biases are absent ),', 'our model q + tuple + a - img is able to outperform all baselines by a significant margin. specifically, our model gives improvement in performance relative to the state - of - the - art vqa model', 'from  #TAUTHOR_TAG ( q + tuple + h - img ),', 'showing that attending to relevant regions and', 'describing them in detail helps, as also seen in sec. 5. 2. role of balancing. we see clear improvements by reason', '- ing about vision in addition to', 'language. note that in addition to the lack of language bias, the visual reasoning is also harder on the balanced dataset because now there are pairs of scenes with fine - grained differences', '']",5
"['first describe the vqa dataset for abstract scenes collected by  #TAUTHOR_TAG.', 'we then describe how we balance this dataset by collecting more scenes']","['first describe the vqa dataset for abstract scenes collected by  #TAUTHOR_TAG.', 'we then describe how we balance this dataset by collecting more scenes']","['first describe the vqa dataset for abstract scenes collected by  #TAUTHOR_TAG.', 'we then describe how we balance this dataset by collecting more scenes']","['first describe the vqa dataset for abstract scenes collected by  #TAUTHOR_TAG.', 'we then describe how we balance this dataset by collecting more scenes']",6
"['models presented in  #TAUTHOR_TAG 25, 29, 14 ], except']","['models presented in  #TAUTHOR_TAG 25, 29, 14 ], except']","['presented in  #TAUTHOR_TAG 25, 29, 14 ], except']","['', 'the most common answer is "" yes "" in the unbalanced set, and "" no "" in the balanced set.', 'blind - q + tuple : a language - only baseline which has a similar architecture as our approach except that each model only accepts language input and does not utilize any visual information.', 'comparing our approach to blind - q + tuple quantifies to what extent our model has succeeded in leveraging the image to answer questions correctly.', 'sota q + tuple + h - img : this vqa model has a similar architecture as our approach, except that it uses holistic image features ( h - img ) that describe the entire scene layout, instead of focusing on specific regions in the scene as determined by p and s. this model is analogous to the state - ofthe - art models presented in  #TAUTHOR_TAG 25, 29, 14 ], except applied to abstract scenes.', 'these holistic features include a bag - of - words for clipart objects occurrence ( 150 - dim ), human expressions ( 8 - dim ), and human poses ( 7 - dim ).', 'the 7 human poses refer to 7 clusters obtained by clustering all the human pose vectors ( concatenation of ( x, y ) locations and global angles of all 15 deformable parts of human body ) in the training set.', 'we extract these 165 - dim holistic features for the complete scene and for four quadrants, and concatenate them together to create a 825 - dim vector.', 'these holistic image features are similar to decaf features for real images, which are good at capturing what is present where, but ( 1 ) do not attend to different parts of the image based on the questions, and ( 2 ) may not be capturing intricate interactions between objects.', 'comparing our model to sota q + tuple + h - img quantifies the improvement in performance by attending to specific regions in the image as dictated by the question being asked, and explicitly capturing the interactions between the relevant objects in the scene.', 'in other words, we quantify the improvement in performance obtained by pushing for a deeper understanding of the image than generic global image descriptors.', 'thus, we name our model q + tuple + a - img, where a is for attention']",3
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['', ') than on unbalanced ( 79 % ). note that the accuracy is higher than 50 % because this is not binary classification accuracy but', 'the vqa accuracy  #TAUTHOR_TAG, which provides partial credit when there is inter - human disagreement in the ground - truth answers. attention helps. when trained on balanced dataset ( where language biases are absent ),', 'our model q + tuple + a - img is able to outperform all baselines by a significant margin. specifically, our model gives improvement in performance relative to the state - of - the - art vqa model', 'from  #TAUTHOR_TAG ( q + tuple + h - img ),', 'showing that attending to relevant regions and', 'describing them in detail helps, as also seen in sec. 5. 2. role of balancing. we see clear improvements by reason', '- ing about vision in addition to', 'language. note that in addition to the lack of language bias, the visual reasoning is also harder on the balanced dataset because now there are pairs of scenes with fine - grained differences', '']",4
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['', ') than on unbalanced ( 79 % ). note that the accuracy is higher than 50 % because this is not binary classification accuracy but', 'the vqa accuracy  #TAUTHOR_TAG, which provides partial credit when there is inter - human disagreement in the ground - truth answers. attention helps. when trained on balanced dataset ( where language biases are absent ),', 'our model q + tuple + a - img is able to outperform all baselines by a significant margin. specifically, our model gives improvement in performance relative to the state - of - the - art vqa model', 'from  #TAUTHOR_TAG ( q + tuple + h - img ),', 'showing that attending to relevant regions and', 'describing them in detail helps, as also seen in sec. 5. 2. role of balancing. we see clear improvements by reason', '- ing about vision in addition to', 'language. note that in addition to the lack of language bias, the visual reasoning is also harder on the balanced dataset because now there are pairs of scenes with fine - grained differences', '']",4
['systems  #TAUTHOR_TAG.'],['systems  #TAUTHOR_TAG.'],['systems  #TAUTHOR_TAG.'],[' #TAUTHOR_TAG'],6
"['segmentation for sanskrit,  #TAUTHOR_TAG has released a dataset']","['segmentation for sanskrit,  #TAUTHOR_TAG has released a dataset']","['to a graph of possible candidates and desirable nodes are iteratively selected using path constrained random walks  #AUTHOR_TAG.', 'to further catalyse the research in word segmentation for sanskrit,  #TAUTHOR_TAG has released a dataset']","['number of methods have been proposed for word segmentation in sanskrit.', ' #AUTHOR_TAG treats the problem as a character level rnn sequence labelling task.', 'the author, in addition to reporting sandhi splits to upto 155 cases, additionally categorises the rules to 5 different types.', 'since, the results reported by the author are not at word - level, as is the standard with word segmentation systems in general, a direct comparison with the other systems is not meaningful.', ' #AUTHOR_TAG proposed a method based on finite state transducers by incorporating rules of sandhi.', 'the system generates all possible splits and then provides a ranking of various splits, based on probabilistic ranking inferred from a dataset of 25000 split points.', 'using the same dataset,  #AUTHOR_TAG proposed a sandhi splitter for sanskrit.', 'the method is an extension of bayesian word segmentation approach by  #AUTHOR_TAG.', ' #AUTHOR_TAG is currently the state of the art in sanskrit word segmentation.', 'the system treats the problem as an iterative query expansion problem.', 'using a shallow parser for sanskrit  #AUTHOR_TAG, an input sentence is first converted to a graph of possible candidates and desirable nodes are iteratively selected using path constrained random walks  #AUTHOR_TAG.', 'to further catalyse the research in word segmentation for sanskrit,  #TAUTHOR_TAG has released a dataset for the word segmentation task.', ' #TAUTHOR_TAG releases a dataset of 119, 000 sentences in sanskrit along with the lexical and morphological analysis from a shallow parser.', ' #TAUTHOR_TAG emphasises the need for not just predicting the inflected word form but also the prediction of the associated morphological information of the word.', 'the additional information will be beneficial in further processing of sanskrit texts, such as dependency parsing or summarisation  #TAUTHOR_TAG. so far, no system successfully predicts the morphological information of the words in addition to the final word form.', ' #AUTHOR_TAG has designed their system with this requirement in mind and outlined the possible extension of their system for the purpose, the system currently only predicts the final word - form']",2
"['by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is']","['linguistic', '##ally involved preprocessing steps that lead to human in the loop processing. the systems by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is']","['by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is to predict']","['search results without proper indexing. string matching approaches often result in low precision results. using a lexicon driven system might alleviate the said issues,', ""but can lead to possible splits which are not semantically compatible. for paramesvarah. ', it"", ""can be split as'parama'( ultimate ),'sva'( dog ) and'rah.'( to facilitate )"", '. though this is not', 'semantically meaningful it is lexically valid. such tools are put to use by some of the existing systems  #AUTHOR_TAG to obtain additional morphological', 'or syntactic information about the sentences. this limits the', 'scalability of those systems, as they cannot handle out of vocabulary words. scalability of such systems is further restricted as the', 'sentences often need to undergo linguistic', '##ally involved preprocessing steps that lead to human in the loop processing. the systems by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is to predict the final word - forms in a given sequence.  #TAUTHOR_TAG states that it is desirable to predict the', 'morphological information of a word from along with the final word - form as the information will', 'be helpful in further processing of sanskrit. the segmentation task is seen as a means and not an end itself. here, we overlo', '##ok this aspect and see the segmentation task as an end in itself. so we achieve scalability at the', 'cost of missing out on providing valuable linguistic information. models that use linguistic resources are at an advantage here. those systems such as  #AUTHOR_TAG', 'can be used to identify the morphological tags of the system as they currently store the morphological information of predicted candidates, but do not use them for evaluation as of now. currently, no', 'system exists that performs the prediction of wordform and morphological information jointly for', 'sanskrit. in our case, since we learn a new vocabulary altogether, the real', 'word boundaries are opaque to the system. the decoder predicts from its own vocabulary.', 'but predicting morphological information requires the knowledge of exact word boundaries', "". this should be seen as a multitask learning set up. one possible solution is to learn'gibberishvocab'on the set of words rather than sentences. but this"", 'leads to increased vocabulary at decoder which is not beneficial, given the scarcity of the data we have. given', 'the importance of morphological segmentation in morphologically rich languages such as hebrew and arabic ( seeker and c eti', '##noglu, 2015 ), the same', 'applies to the morphologically rich sanskrit as well  #TAUTHOR_TAG.', 'but, we leave this work for future']",2
"['', 'in our case we use 105, 000 parallel strings from the digital corpus of sanskrit as released in  #TAUTHOR_TAG']","['texts.', 'in our case we use 105, 000 parallel strings from the digital corpus of sanskrit as released in  #TAUTHOR_TAG']","['', 'in our case we use 105, 000 parallel strings from the digital corpus of sanskrit as released in  #TAUTHOR_TAG.', 'to handle the data sparsity, we adopt a purely engineering based approach for our model']","['', 'we then update the parameters via backpropagation and use adam optimiser  #AUTHOR_TAG for our model.', 'vocabulary enhancement for the model - sanskrit, being a resource poor language, the major challenge is to obtain enough data for the supervised task.', 'while there are plenty of sandhied texts available for sanskrit, it is hard to find parallel or unsandhied texts alone, as it is deterministic to get sandhied text from unsandhied texts.', 'in our case we use 105, 000 parallel strings from the digital corpus of sanskrit as released in  #TAUTHOR_TAG.', 'to handle the data sparsity, we adopt a purely engineering based approach for our model.', ""rather than relying on the real word boundaries, we use the'sentencepiece'model, an unsupervised text tokeniser  #AUTHOR_TAG to obtain a new vocabulary for the corpus."", 'the method was originally proposed for segmentation problem in japanese and korean speech recognition systems.', 'in the method, a greedy approach is used to identify new word units from a corpus that maximises the likelihood of the language model so learnt  #AUTHOR_TAG.', 'figure 1 shows the instance of words learnt from the sentencepiece model corresponding to the original input from the']",5
"['of 107, 000 sentences from the  #TAUTHOR_TAG.', 'the dataset is a subset of the digital corpus of sanskrit.', 'from the dataset we only use the input sentences and the']","['of 107, 000 sentences from the  #TAUTHOR_TAG.', 'the dataset is a subset of the digital corpus of sanskrit.', 'from the dataset we only use the input sentences and the']","['used a dataset of 107, 000 sentences from the  #TAUTHOR_TAG.', 'the dataset is a subset of the digital corpus of sanskrit.', 'from the dataset we only use the input sentences and the ground truth inflected']","['used a dataset of 107, 000 sentences from the  #TAUTHOR_TAG.', 'the dataset is a subset of the digital corpus of sanskrit.', 'from the dataset we only use the input sentences and the ground truth inflected word - forms.', 'we ignore all the other morphological and lemma information available in the dataset']",5
"['by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is']","['linguistic', '##ally involved preprocessing steps that lead to human in the loop processing. the systems by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is']","['by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is to predict']","['search results without proper indexing. string matching approaches often result in low precision results. using a lexicon driven system might alleviate the said issues,', ""but can lead to possible splits which are not semantically compatible. for paramesvarah. ', it"", ""can be split as'parama'( ultimate ),'sva'( dog ) and'rah.'( to facilitate )"", '. though this is not', 'semantically meaningful it is lexically valid. such tools are put to use by some of the existing systems  #AUTHOR_TAG to obtain additional morphological', 'or syntactic information about the sentences. this limits the', 'scalability of those systems, as they cannot handle out of vocabulary words. scalability of such systems is further restricted as the', 'sentences often need to undergo linguistic', '##ally involved preprocessing steps that lead to human in the loop processing. the systems by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is to predict the final word - forms in a given sequence.  #TAUTHOR_TAG states that it is desirable to predict the', 'morphological information of a word from along with the final word - form as the information will', 'be helpful in further processing of sanskrit. the segmentation task is seen as a means and not an end itself. here, we overlo', '##ok this aspect and see the segmentation task as an end in itself. so we achieve scalability at the', 'cost of missing out on providing valuable linguistic information. models that use linguistic resources are at an advantage here. those systems such as  #AUTHOR_TAG', 'can be used to identify the morphological tags of the system as they currently store the morphological information of predicted candidates, but do not use them for evaluation as of now. currently, no', 'system exists that performs the prediction of wordform and morphological information jointly for', 'sanskrit. in our case, since we learn a new vocabulary altogether, the real', 'word boundaries are opaque to the system. the decoder predicts from its own vocabulary.', 'but predicting morphological information requires the knowledge of exact word boundaries', "". this should be seen as a multitask learning set up. one possible solution is to learn'gibberishvocab'on the set of words rather than sentences. but this"", 'leads to increased vocabulary at decoder which is not beneficial, given the scarcity of the data we have. given', 'the importance of morphological segmentation in morphologically rich languages such as hebrew and arabic ( seeker and c eti', '##noglu, 2015 ), the same', 'applies to the morphologically rich sanskrit as well  #TAUTHOR_TAG.', 'but, we leave this work for future']",4
"['by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is']","['linguistic', '##ally involved preprocessing steps that lead to human in the loop processing. the systems by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is']","['by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is to predict']","['search results without proper indexing. string matching approaches often result in low precision results. using a lexicon driven system might alleviate the said issues,', ""but can lead to possible splits which are not semantically compatible. for paramesvarah. ', it"", ""can be split as'parama'( ultimate ),'sva'( dog ) and'rah.'( to facilitate )"", '. though this is not', 'semantically meaningful it is lexically valid. such tools are put to use by some of the existing systems  #AUTHOR_TAG to obtain additional morphological', 'or syntactic information about the sentences. this limits the', 'scalability of those systems, as they cannot handle out of vocabulary words. scalability of such systems is further restricted as the', 'sentences often need to undergo linguistic', '##ally involved preprocessing steps that lead to human in the loop processing. the systems by  #AUTHOR_TAG and  #TAUTHOR_TAG assume that the parser by  #AUTHOR_TAG, identifies all the possible candidate chunks', '. our proposed model is built with precisely one purpose in mind', ', which is to predict the final word - forms in a given sequence.  #TAUTHOR_TAG states that it is desirable to predict the', 'morphological information of a word from along with the final word - form as the information will', 'be helpful in further processing of sanskrit. the segmentation task is seen as a means and not an end itself. here, we overlo', '##ok this aspect and see the segmentation task as an end in itself. so we achieve scalability at the', 'cost of missing out on providing valuable linguistic information. models that use linguistic resources are at an advantage here. those systems such as  #AUTHOR_TAG', 'can be used to identify the morphological tags of the system as they currently store the morphological information of predicted candidates, but do not use them for evaluation as of now. currently, no', 'system exists that performs the prediction of wordform and morphological information jointly for', 'sanskrit. in our case, since we learn a new vocabulary altogether, the real', 'word boundaries are opaque to the system. the decoder predicts from its own vocabulary.', 'but predicting morphological information requires the knowledge of exact word boundaries', "". this should be seen as a multitask learning set up. one possible solution is to learn'gibberishvocab'on the set of words rather than sentences. but this"", 'leads to increased vocabulary at decoder which is not beneficial, given the scarcity of the data we have. given', 'the importance of morphological segmentation in morphologically rich languages such as hebrew and arabic ( seeker and c eti', '##noglu, 2015 ), the same', 'applies to the morphologically rich sanskrit as well  #TAUTHOR_TAG.', 'but, we leave this work for future']",4
"['stabilize training,  #TAUTHOR_TAG experimented with several additional terms in']","['of alternating optimization  #AUTHOR_TAG. to stabilize training,  #TAUTHOR_TAG experimented with several additional terms in']","['stabilize training,  #TAUTHOR_TAG experimented with several additional terms in the training objectives', ', finding']","['of alternating optimization  #AUTHOR_TAG. to stabilize training,  #TAUTHOR_TAG experimented with several additional terms in the training objectives', ', finding performance to be dependent on their inclusion. also, when using the approach of  #TAUTHOR_TAG, there is a mismatch between the training and', '']",0
"['stabilize training,  #TAUTHOR_TAG experimented with several additional terms in']","['of alternating optimization  #AUTHOR_TAG. to stabilize training,  #TAUTHOR_TAG experimented with several additional terms in']","['stabilize training,  #TAUTHOR_TAG experimented with several additional terms in the training objectives', ', finding']","['of alternating optimization  #AUTHOR_TAG. to stabilize training,  #TAUTHOR_TAG experimented with several additional terms in the training objectives', ', finding performance to be dependent on their inclusion. also, when using the approach of  #TAUTHOR_TAG, there is a mismatch between the training and', '']",0
"['stabilize training,  #TAUTHOR_TAG experimented with several additional terms in']","['of alternating optimization  #AUTHOR_TAG. to stabilize training,  #TAUTHOR_TAG experimented with several additional terms in']","['stabilize training,  #TAUTHOR_TAG experimented with several additional terms in the training objectives', ', finding']","['of alternating optimization  #AUTHOR_TAG. to stabilize training,  #TAUTHOR_TAG experimented with several additional terms in the training objectives', ', finding performance to be dependent on their inclusion. also, when using the approach of  #TAUTHOR_TAG, there is a mismatch between the training and', '']",0
"['stabilize training,  #TAUTHOR_TAG experimented with several additional terms in']","['of alternating optimization  #AUTHOR_TAG. to stabilize training,  #TAUTHOR_TAG experimented with several additional terms in']","['stabilize training,  #TAUTHOR_TAG experimented with several additional terms in the training objectives', ', finding']","['of alternating optimization  #AUTHOR_TAG. to stabilize training,  #TAUTHOR_TAG experimented with several additional terms in the training objectives', ', finding performance to be dependent on their inclusion. also, when using the approach of  #TAUTHOR_TAG, there is a mismatch between the training and', '']",0
"['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['denote the input space by x.', 'for an input x ∈ x, we denote the structured output space by y ( x ).', 'the entire space of structured outputs is denoted y = ∪ x∈x y ( x ).', 'a spen ( belanger and mc  #AUTHOR_TAG defines an energy function e θ : x × y → r parameterized by θ that computes a scalar energy for an input / output pair.', 'at test time, for a given input x, prediction is done by choosing the output with lowest energy :', 'however, solving equation ( 1 ) requires combinatorial algorithms because y is a structured, discrete space.', 'this becomes intractable when e θ does not decompose into a sum over small "" parts "" of y. belanger and mc  #AUTHOR_TAG relax this problem by allowing the discrete vector y to be continuous ; y r denotes the relaxed output space.', 'they solve the relaxed problem by using gradient descent to iteratively minimize the energy with respect to y. the energy function parameters θ are trained using a structured hinge loss which requires repeated cost - augmented inference during training.', 'using gradient descent for the repeated cost - augmented inference steps is time - consuming and makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG']",0
"['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['denote the input space by x.', 'for an input x ∈ x, we denote the structured output space by y ( x ).', 'the entire space of structured outputs is denoted y = ∪ x∈x y ( x ).', 'a spen ( belanger and mc  #AUTHOR_TAG defines an energy function e θ : x × y → r parameterized by θ that computes a scalar energy for an input / output pair.', 'at test time, for a given input x, prediction is done by choosing the output with lowest energy :', 'however, solving equation ( 1 ) requires combinatorial algorithms because y is a structured, discrete space.', 'this becomes intractable when e θ does not decompose into a sum over small "" parts "" of y. belanger and mc  #AUTHOR_TAG relax this problem by allowing the discrete vector y to be continuous ; y r denotes the relaxed output space.', 'they solve the relaxed problem by using gradient descent to iteratively minimize the energy with respect to y. the energy function parameters θ are trained using a structured hinge loss which requires repeated cost - augmented inference during training.', 'using gradient descent for the repeated cost - augmented inference steps is time - consuming and makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG']",0
"['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['denote the input space by x.', 'for an input x ∈ x, we denote the structured output space by y ( x ).', 'the entire space of structured outputs is denoted y = ∪ x∈x y ( x ).', 'a spen ( belanger and mc  #AUTHOR_TAG defines an energy function e θ : x × y → r parameterized by θ that computes a scalar energy for an input / output pair.', 'at test time, for a given input x, prediction is done by choosing the output with lowest energy :', 'however, solving equation ( 1 ) requires combinatorial algorithms because y is a structured, discrete space.', 'this becomes intractable when e θ does not decompose into a sum over small "" parts "" of y. belanger and mc  #AUTHOR_TAG relax this problem by allowing the discrete vector y to be continuous ; y r denotes the relaxed output space.', 'they solve the relaxed problem by using gradient descent to iteratively minimize the energy with respect to y. the energy function parameters θ are trained using a structured hinge loss which requires repeated cost - augmented inference during training.', 'using gradient descent for the repeated cost - augmented inference steps is time - consuming and makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG']",0
"['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['denote the input space by x.', 'for an input x ∈ x, we denote the structured output space by y ( x ).', 'the entire space of structured outputs is denoted y = ∪ x∈x y ( x ).', 'a spen ( belanger and mc  #AUTHOR_TAG defines an energy function e θ : x × y → r parameterized by θ that computes a scalar energy for an input / output pair.', 'at test time, for a given input x, prediction is done by choosing the output with lowest energy :', 'however, solving equation ( 1 ) requires combinatorial algorithms because y is a structured, discrete space.', 'this becomes intractable when e θ does not decompose into a sum over small "" parts "" of y. belanger and mc  #AUTHOR_TAG relax this problem by allowing the discrete vector y to be continuous ; y r denotes the relaxed output space.', 'they solve the relaxed problem by using gradient descent to iteratively minimize the energy with respect to y. the energy function parameters θ are trained using a structured hinge loss which requires repeated cost - augmented inference during training.', 'using gradient descent for the repeated cost - augmented inference steps is time - consuming and makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG']",0
"['original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameter']","['original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameter']","['. if we were to train independent inference networks a ψ and f φ, this new objective', 'could be much slower than the original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameterizations of the']","['parameterizations. if we were to train independent inference networks a ψ and f φ, this new objective', 'could be much slower than the original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameterizations of the two inference networks. we consider three options which are visualized in figure 1 and', 'described below : • separated : f φ and a ψ are two', 'independent networks with their own architectures and parameters as shown in figure 1', '( a', '). • shared : f φ and a', '']",0
['used'],['used'],"['used the following objective for the cost - augmented inference network ( maximizing it with respect to φ ) :', 'where']","['used the following objective for the cost - augmented inference network ( maximizing it with respect to φ ) :', 'where [ h ] + = max ( 0, h ).', 'however, there are two potential reasons why l will equal zero and therefore trigger no gradient update.', 'first, e θ ( the energy function, corresponding to the discriminator in a gan ) may already be well - trained, and it does a good job separating the gold standard output and the cost - augmented inference network output.', '']",0
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG. bottom :'],['by  #TAUTHOR_TAG. bottom :'],"['', 'φ ( on development sets', '). the "" marginrescaled "" row uses a spen with the local ce term and without zero', 'truncation, where a ψ is obtained by finetuning f', 'φ as done by  #TAUTHOR_TAG. bottom : most frequent output differences between a ψ and f φ on the development set. drops slightly for ner', ', likely due to the larger number of parameters. the shared and stacked options also have fewer parameters to train than the separated option,', '']",0
"['skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG,']","[' #AUTHOR_TAG and  #AUTHOR_TAG which contains 25 tags.', 'we use 100 - dimensional skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG,']","[' #AUTHOR_TAG and  #AUTHOR_TAG which contains 25 tags.', 'we use 100 - dimensional skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG, we use a bilstm']","['part - of - speech ( pos ) tagging.', 'we use the twitter pos data from  #AUTHOR_TAG and  #AUTHOR_TAG which contains 25 tags.', 'we use 100 - dimensional skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG, we use a bilstm to compute the input feature vector for each position, using hidden dimension of size 100.', 'we also use bil - stms for the inference networks.', 'the output of the inference network is a softmax function, so the inference network will produce a distribution over labels at each position.', 'the ∆ is l1 distance.', 'we train the inference network using stochastic gradient descent ( sgd ) with momentum and train the energy parameters using adam  #AUTHOR_TAG.', 'we also explore training the inference network using adam when we do not use the local ce loss.', '4 in experiments with the local ce term, its weight is set to 1.', 'named entity recognition ( ner ).', 'we use the conll 2003 english dataset  #AUTHOR_TAG.', 'we use the bioes tagging scheme, following previous work  #AUTHOR_TAG, resulting in 17 ner labels.', 'we use 100 - dimensional pretrained glove embeddings  #AUTHOR_TAG.', 'the task is evaluated using f1 score computed with the conlleval script.', '']",0
"['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['denote the input space by x.', 'for an input x ∈ x, we denote the structured output space by y ( x ).', 'the entire space of structured outputs is denoted y = ∪ x∈x y ( x ).', 'a spen ( belanger and mc  #AUTHOR_TAG defines an energy function e θ : x × y → r parameterized by θ that computes a scalar energy for an input / output pair.', 'at test time, for a given input x, prediction is done by choosing the output with lowest energy :', 'however, solving equation ( 1 ) requires combinatorial algorithms because y is a structured, discrete space.', 'this becomes intractable when e θ does not decompose into a sum over small "" parts "" of y. belanger and mc  #AUTHOR_TAG relax this problem by allowing the discrete vector y to be continuous ; y r denotes the relaxed output space.', 'they solve the relaxed problem by using gradient descent to iteratively minimize the energy with respect to y. the energy function parameters θ are trained using a structured hinge loss which requires repeated cost - augmented inference during training.', 'using gradient descent for the repeated cost - augmented inference steps is time - consuming and makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG']",5
"['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['denote the input space by x.', 'for an input x ∈ x, we denote the structured output space by y ( x ).', 'the entire space of structured outputs is denoted y = ∪ x∈x y ( x ).', 'a spen ( belanger and mc  #AUTHOR_TAG defines an energy function e θ : x × y → r parameterized by θ that computes a scalar energy for an input / output pair.', 'at test time, for a given input x, prediction is done by choosing the output with lowest energy :', 'however, solving equation ( 1 ) requires combinatorial algorithms because y is a structured, discrete space.', 'this becomes intractable when e θ does not decompose into a sum over small "" parts "" of y. belanger and mc  #AUTHOR_TAG relax this problem by allowing the discrete vector y to be continuous ; y r denotes the relaxed output space.', 'they solve the relaxed problem by using gradient descent to iteratively minimize the energy with respect to y. the energy function parameters θ are trained using a structured hinge loss which requires repeated cost - augmented inference during training.', 'using gradient descent for the repeated cost - augmented inference steps is time - consuming and makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG']",5
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG. bottom :'],['by  #TAUTHOR_TAG. bottom :'],"['', 'φ ( on development sets', '). the "" marginrescaled "" row uses a spen with the local ce term and without zero', 'truncation, where a ψ is obtained by finetuning f', 'φ as done by  #TAUTHOR_TAG. bottom : most frequent output differences between a ψ and f φ on the development set. drops slightly for ner', ', likely due to the larger number of parameters. the shared and stacked options also have fewer parameters to train than the separated option,', '']",5
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG. bottom :'],['by  #TAUTHOR_TAG. bottom :'],"['', 'φ ( on development sets', '). the "" marginrescaled "" row uses a spen with the local ce term and without zero', 'truncation, where a ψ is obtained by finetuning f', 'φ as done by  #TAUTHOR_TAG. bottom : most frequent output differences between a ψ and f φ on the development set. drops slightly for ner', ', likely due to the larger number of parameters. the shared and stacked options also have fewer parameters to train than the separated option,', '']",5
['sequence labeling  #TAUTHOR_TAG : where u j ∈'],['sequence labeling  #TAUTHOR_TAG : where u j ∈'],['sequence labeling  #TAUTHOR_TAG : where u j ∈'],"['yields improved performance overall. these developments offer promise for spens to be more easily', 'trained and deployed for a broad range of nlp tasks. future work will explore other structured prediction tasks, such as parsing and generation. we have taken initial steps in this direction, experimenting with', 'constituency parsing using the attentionaugmented sequence - to - sequence model of  #AUTHOR_TAG. preliminary experiments are positive, 3', 'but significant challenges remain, specifically our experiments in this paper consider sequence labeling tasks', ', so the input x is a length - t sequence of tokens where x t denotes the token at position t. the output y is a sequence', 'of labels also of length t. we use y t to denote the output label at position t, where y t is a vector of length l ( the number of labels in the label set ) and where y t, j is the jth entry of the vector y t. in the', 'original output space y ( x ), y t, j is 1 for a single j and 0 for all others. in the relaxed output space y r ( x ), y t, j can be interpreted as the probability of the tt', '##h position being labeled with label j. we then use the following energy for sequence labeling  #TAUTHOR_TAG : where u j ∈ r d is', 'a parameter vector for label j and the parameter matrix w ∈ r l×l contains label pair parameters. also, b ( x, t ) ∈ r d denotes the "" input feature vector "" for position t.', 'we define it to be the d - dimensional bilstm  #AUTHOR_TAG hidden vector at t. the full set of energy parameters θ includes the u j', 'vectors, w, and the parameters of the bilstm.  #TAUTHOR_TAG also added a global energy term that they referred to as a "" tag language model "" ( tlm ). we use h to denote an lstm tlm that takes a sequence of labels as input and returns a distribution over next labels. we', 'define y t = h ( y 0,..., y t−1 ). then, the energy term', 'is : where y 0 is the start - of - sequence symbol and y t + 1 is the end - of - sequence symbol', '. this energy returns the negative log - likelihood under the tlm of the candidate output y.', 'for inference networks, we use architectures', 'similar to those used by  #TAUTHOR_TAG. in particular, we choose bilstms as the inference network architectures in our experiments. we', 'also use bilstms for the baselines and both the inference networks and baseline models use', 'the same hidden sizes']",5
"['skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG,']","[' #AUTHOR_TAG and  #AUTHOR_TAG which contains 25 tags.', 'we use 100 - dimensional skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG,']","[' #AUTHOR_TAG and  #AUTHOR_TAG which contains 25 tags.', 'we use 100 - dimensional skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG, we use a bilstm']","['part - of - speech ( pos ) tagging.', 'we use the twitter pos data from  #AUTHOR_TAG and  #AUTHOR_TAG which contains 25 tags.', 'we use 100 - dimensional skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG, we use a bilstm to compute the input feature vector for each position, using hidden dimension of size 100.', 'we also use bil - stms for the inference networks.', 'the output of the inference network is a softmax function, so the inference network will produce a distribution over labels at each position.', 'the ∆ is l1 distance.', 'we train the inference network using stochastic gradient descent ( sgd ) with momentum and train the energy parameters using adam  #AUTHOR_TAG.', 'we also explore training the inference network using adam when we do not use the local ce loss.', '4 in experiments with the local ce term, its weight is set to 1.', 'named entity recognition ( ner ).', 'we use the conll 2003 english dataset  #AUTHOR_TAG.', 'we use the bioes tagging scheme, following previous work  #AUTHOR_TAG, resulting in 17 ner labels.', 'we use 100 - dimensional pretrained glove embeddings  #AUTHOR_TAG.', 'the task is evaluated using f1 score computed with the conlleval script.', '']",5
"['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['denote the input space by x.', 'for an input x ∈ x, we denote the structured output space by y ( x ).', 'the entire space of structured outputs is denoted y = ∪ x∈x y ( x ).', 'a spen ( belanger and mc  #AUTHOR_TAG defines an energy function e θ : x × y → r parameterized by θ that computes a scalar energy for an input / output pair.', 'at test time, for a given input x, prediction is done by choosing the output with lowest energy :', 'however, solving equation ( 1 ) requires combinatorial algorithms because y is a structured, discrete space.', 'this becomes intractable when e θ does not decompose into a sum over small "" parts "" of y. belanger and mc  #AUTHOR_TAG relax this problem by allowing the discrete vector y to be continuous ; y r denotes the relaxed output space.', 'they solve the relaxed problem by using gradient descent to iteratively minimize the energy with respect to y. the energy function parameters θ are trained using a structured hinge loss which requires repeated cost - augmented inference during training.', 'using gradient descent for the repeated cost - augmented inference steps is time - consuming and makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG']",3
"['original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameter']","['original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameter']","['. if we were to train independent inference networks a ψ and f φ, this new objective', 'could be much slower than the original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameterizations of the']","['parameterizations. if we were to train independent inference networks a ψ and f φ, this new objective', 'could be much slower than the original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameterizations of the two inference networks. we consider three options which are visualized in figure 1 and', 'described below : • separated : f φ and a ψ are two', 'independent networks with their own architectures and parameters as shown in figure 1', '( a', '). • shared : f φ and a', '']",3
"['form of eq. ( 9 ).', ' #TAUTHOR_TAG pre']","['form of eq. ( 9 ).', ' #TAUTHOR_TAG pretrained']","['capture long - distance dependencies, we include global energy ( ge ) terms in the form of eq. ( 9 ).', ' #TAUTHOR_TAG pre']","['addition to new training strategies, we also experiment with several global energy terms for sequence labeling.', 'eq. ( 8 ) in the appendix shows the base energy.', 'to capture long - distance dependencies, we include global energy ( ge ) terms in the form of eq. ( 9 ).', ' #TAUTHOR_TAG pretrained their tag language model ( tlm ) on a large, automatically - tagged corpus and fixed its parameters when optimizing θ. we instead do not pretrain the tlm and learn its parameters when training θ.', 'we also propose new global energy terms.', '']",3
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG. bottom :'],['by  #TAUTHOR_TAG. bottom :'],"['', 'φ ( on development sets', '). the "" marginrescaled "" row uses a spen with the local ce term and without zero', 'truncation, where a ψ is obtained by finetuning f', 'φ as done by  #TAUTHOR_TAG. bottom : most frequent output differences between a ψ and f φ on the development set. drops slightly for ner', ', likely due to the larger number of parameters. the shared and stacked options also have fewer parameters to train than the separated option,', '']",3
['sequence labeling  #TAUTHOR_TAG : where u j ∈'],['sequence labeling  #TAUTHOR_TAG : where u j ∈'],['sequence labeling  #TAUTHOR_TAG : where u j ∈'],"['yields improved performance overall. these developments offer promise for spens to be more easily', 'trained and deployed for a broad range of nlp tasks. future work will explore other structured prediction tasks, such as parsing and generation. we have taken initial steps in this direction, experimenting with', 'constituency parsing using the attentionaugmented sequence - to - sequence model of  #AUTHOR_TAG. preliminary experiments are positive, 3', 'but significant challenges remain, specifically our experiments in this paper consider sequence labeling tasks', ', so the input x is a length - t sequence of tokens where x t denotes the token at position t. the output y is a sequence', 'of labels also of length t. we use y t to denote the output label at position t, where y t is a vector of length l ( the number of labels in the label set ) and where y t, j is the jth entry of the vector y t. in the', 'original output space y ( x ), y t, j is 1 for a single j and 0 for all others. in the relaxed output space y r ( x ), y t, j can be interpreted as the probability of the tt', '##h position being labeled with label j. we then use the following energy for sequence labeling  #TAUTHOR_TAG : where u j ∈ r d is', 'a parameter vector for label j and the parameter matrix w ∈ r l×l contains label pair parameters. also, b ( x, t ) ∈ r d denotes the "" input feature vector "" for position t.', 'we define it to be the d - dimensional bilstm  #AUTHOR_TAG hidden vector at t. the full set of energy parameters θ includes the u j', 'vectors, w, and the parameters of the bilstm.  #TAUTHOR_TAG also added a global energy term that they referred to as a "" tag language model "" ( tlm ). we use h to denote an lstm tlm that takes a sequence of labels as input and returns a distribution over next labels. we', 'define y t = h ( y 0,..., y t−1 ). then, the energy term', 'is : where y 0 is the start - of - sequence symbol and y t + 1 is the end - of - sequence symbol', '. this energy returns the negative log - likelihood under the tlm of the candidate output y.', 'for inference networks, we use architectures', 'similar to those used by  #TAUTHOR_TAG. in particular, we choose bilstms as the inference network architectures in our experiments. we', 'also use bilstms for the baselines and both the inference networks and baseline models use', 'the same hidden sizes']",3
['sequence labeling  #TAUTHOR_TAG : where u j ∈'],['sequence labeling  #TAUTHOR_TAG : where u j ∈'],['sequence labeling  #TAUTHOR_TAG : where u j ∈'],"['yields improved performance overall. these developments offer promise for spens to be more easily', 'trained and deployed for a broad range of nlp tasks. future work will explore other structured prediction tasks, such as parsing and generation. we have taken initial steps in this direction, experimenting with', 'constituency parsing using the attentionaugmented sequence - to - sequence model of  #AUTHOR_TAG. preliminary experiments are positive, 3', 'but significant challenges remain, specifically our experiments in this paper consider sequence labeling tasks', ', so the input x is a length - t sequence of tokens where x t denotes the token at position t. the output y is a sequence', 'of labels also of length t. we use y t to denote the output label at position t, where y t is a vector of length l ( the number of labels in the label set ) and where y t, j is the jth entry of the vector y t. in the', 'original output space y ( x ), y t, j is 1 for a single j and 0 for all others. in the relaxed output space y r ( x ), y t, j can be interpreted as the probability of the tt', '##h position being labeled with label j. we then use the following energy for sequence labeling  #TAUTHOR_TAG : where u j ∈ r d is', 'a parameter vector for label j and the parameter matrix w ∈ r l×l contains label pair parameters. also, b ( x, t ) ∈ r d denotes the "" input feature vector "" for position t.', 'we define it to be the d - dimensional bilstm  #AUTHOR_TAG hidden vector at t. the full set of energy parameters θ includes the u j', 'vectors, w, and the parameters of the bilstm.  #TAUTHOR_TAG also added a global energy term that they referred to as a "" tag language model "" ( tlm ). we use h to denote an lstm tlm that takes a sequence of labels as input and returns a distribution over next labels. we', 'define y t = h ( y 0,..., y t−1 ). then, the energy term', 'is : where y 0 is the start - of - sequence symbol and y t + 1 is the end - of - sequence symbol', '. this energy returns the negative log - likelihood under the tlm of the candidate output y.', 'for inference networks, we use architectures', 'similar to those used by  #TAUTHOR_TAG. in particular, we choose bilstms as the inference network architectures in our experiments. we', 'also use bilstms for the baselines and both the inference networks and baseline models use', 'the same hidden sizes']",3
"['skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG,']","[' #AUTHOR_TAG and  #AUTHOR_TAG which contains 25 tags.', 'we use 100 - dimensional skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG,']","[' #AUTHOR_TAG and  #AUTHOR_TAG which contains 25 tags.', 'we use 100 - dimensional skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG, we use a bilstm']","['part - of - speech ( pos ) tagging.', 'we use the twitter pos data from  #AUTHOR_TAG and  #AUTHOR_TAG which contains 25 tags.', 'we use 100 - dimensional skip - gram  #AUTHOR_TAG embeddings from  #AUTHOR_TAG.', 'like  #TAUTHOR_TAG, we use a bilstm to compute the input feature vector for each position, using hidden dimension of size 100.', 'we also use bil - stms for the inference networks.', 'the output of the inference network is a softmax function, so the inference network will produce a distribution over labels at each position.', 'the ∆ is l1 distance.', 'we train the inference network using stochastic gradient descent ( sgd ) with momentum and train the energy parameters using adam  #AUTHOR_TAG.', 'we also explore training the inference network using adam when we do not use the local ce loss.', '4 in experiments with the local ce term, its weight is set to 1.', 'named entity recognition ( ner ).', 'we use the conll 2003 english dataset  #AUTHOR_TAG.', 'we use the bioes tagging scheme, following previous work  #AUTHOR_TAG, resulting in 17 ner labels.', 'we use 100 - dimensional pretrained glove embeddings  #AUTHOR_TAG.', 'the task is evaluated using f1 score computed with the conlleval script.', '']",3
"['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['denote the input space by x.', 'for an input x ∈ x, we denote the structured output space by y ( x ).', 'the entire space of structured outputs is denoted y = ∪ x∈x y ( x ).', 'a spen ( belanger and mc  #AUTHOR_TAG defines an energy function e θ : x × y → r parameterized by θ that computes a scalar energy for an input / output pair.', 'at test time, for a given input x, prediction is done by choosing the output with lowest energy :', 'however, solving equation ( 1 ) requires combinatorial algorithms because y is a structured, discrete space.', 'this becomes intractable when e θ does not decompose into a sum over small "" parts "" of y. belanger and mc  #AUTHOR_TAG relax this problem by allowing the discrete vector y to be continuous ; y r denotes the relaxed output space.', 'they solve the relaxed problem by using gradient descent to iteratively minimize the energy with respect to y. the energy function parameters θ are trained using a structured hinge loss which requires repeated cost - augmented inference during training.', 'using gradient descent for the repeated cost - augmented inference steps is time - consuming and makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG']",4
"['original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameter']","['original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameter']","['. if we were to train independent inference networks a ψ and f φ, this new objective', 'could be much slower than the original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameterizations of the']","['parameterizations. if we were to train independent inference networks a ψ and f φ, this new objective', 'could be much slower than the original approach', 'of  #TAUTHOR_TAG. however, the compound objective offers several natural options for defining joint parameterizations of the two inference networks. we consider three options which are visualized in figure 1 and', 'described below : • separated : f φ and a ψ are two', 'independent networks with their own architectures and parameters as shown in figure 1', '( a', '). • shared : f φ and a', '']",4
['used'],['used'],"['used the following objective for the cost - augmented inference network ( maximizing it with respect to φ ) :', 'where']","['used the following objective for the cost - augmented inference network ( maximizing it with respect to φ ) :', 'where [ h ] + = max ( 0, h ).', 'however, there are two potential reasons why l will equal zero and therefore trigger no gradient update.', 'first, e θ ( the energy function, corresponding to the discriminator in a gan ) may already be well - trained, and it does a good job separating the gold standard output and the cost - augmented inference network output.', '']",4
"['form of eq. ( 9 ).', ' #TAUTHOR_TAG pre']","['form of eq. ( 9 ).', ' #TAUTHOR_TAG pretrained']","['capture long - distance dependencies, we include global energy ( ge ) terms in the form of eq. ( 9 ).', ' #TAUTHOR_TAG pre']","['addition to new training strategies, we also experiment with several global energy terms for sequence labeling.', 'eq. ( 8 ) in the appendix shows the base energy.', 'to capture long - distance dependencies, we include global energy ( ge ) terms in the form of eq. ( 9 ).', ' #TAUTHOR_TAG pretrained their tag language model ( tlm ) on a large, automatically - tagged corpus and fixed its parameters when optimizing θ. we instead do not pretrain the tlm and learn its parameters when training θ.', 'we also propose new global energy terms.', '']",4
"['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG propose an alternative']","['denote the input space by x.', 'for an input x ∈ x, we denote the structured output space by y ( x ).', 'the entire space of structured outputs is denoted y = ∪ x∈x y ( x ).', 'a spen ( belanger and mc  #AUTHOR_TAG defines an energy function e θ : x × y → r parameterized by θ that computes a scalar energy for an input / output pair.', 'at test time, for a given input x, prediction is done by choosing the output with lowest energy :', 'however, solving equation ( 1 ) requires combinatorial algorithms because y is a structured, discrete space.', 'this becomes intractable when e θ does not decompose into a sum over small "" parts "" of y. belanger and mc  #AUTHOR_TAG relax this problem by allowing the discrete vector y to be continuous ; y r denotes the relaxed output space.', 'they solve the relaxed problem by using gradient descent to iteratively minimize the energy with respect to y. the energy function parameters θ are trained using a structured hinge loss which requires repeated cost - augmented inference during training.', 'using gradient descent for the repeated cost - augmented inference steps is time - consuming and makes learning unstable  #AUTHOR_TAG.', ' #TAUTHOR_TAG']",6
"['', ' #TAUTHOR_TAG propose a new architecture that avoids recurrence and convolution completely.', 'instead,']","['form of convolution or recursion.', ' #TAUTHOR_TAG propose a new architecture that avoids recurrence and convolution completely.', 'instead,']","['', ' #TAUTHOR_TAG propose a new architecture that avoids recurrence and convolution completely.', 'instead, it uses only']","['- of - the - art results on neural machine translation often use attentional sequence - to - sequence models with some form of convolution or recursion.', ' #TAUTHOR_TAG propose a new architecture that avoids recurrence and convolution completely.', 'instead, it uses only self - attention and feed - forward layers.', 'while the proposed architecture achieves state - of - the - art results on several machine translation tasks, it requires a large number of parameters and training iterations to converge.', 'we propose weighted transformer, a transformer with modified attention layers, that not only outperforms the baseline network in bleu score but also converges 15 − 40 % faster.', 'specifically, we replace the multi - head attention by multiple self - attention branches that the model learns to combine during the training process.', 'our model improves the state - of - the - art performance by 0. 5 bleu points on the wmt 2014 english - to - german translation task and by 0. 4 on the english - to - french translation task']",0
"['', 'in  #TAUTHOR_TAG, the authors introduce the transformer']","['', 'in  #TAUTHOR_TAG, the authors introduce the transformer network, a novel']","['of such dependencies  #AUTHOR_TAG.', 'in  #TAUTHOR_TAG, the authors introduce the transformer']","['', 'however, because of their auto - regressive property of requiring previous hidden states to be computed before the current time step, they cannot benefit from parallelization.', 'variants of recurrent networks that use strided convolutions eschew the traditional time - step based computation  #AUTHOR_TAG 2017 ;  #AUTHOR_TAG.', 'however, in these models, the operations needed to learn dependencies between distant positions can be difficult to learn  #AUTHOR_TAG.', 'attention mechanisms, often used in conjunction with recurrent models, have become an integral part of complex sequential tasks because they facilitate learning of such dependencies  #AUTHOR_TAG.', 'in  #TAUTHOR_TAG, the authors introduce the transformer network, a novel architecture that avoids the recurrence equation and maps the input sequences into hidden states solely using attention.', 'specifically, the authors use positional encodings in conjunction with a multi - head attention mechanism.', '']",0
[' #TAUTHOR_TAG avoids the recurrence completely'],[' #TAUTHOR_TAG avoids the recurrence completely'],"['a weighted sum  #AUTHOR_TAG, has also been a critical ingredient in modern nmt architectures.', 'the transformer network  #TAUTHOR_TAG avoids the recurrence completely']","['architectures for neural machine translation ( nmt ) use an encoder and a decoder that rely on deep recurrent neural networks like the lstm  #AUTHOR_TAG.', 'several architectures have been proposed to reduce the computational load associated with recurrence - based computation  #AUTHOR_TAG 2017 ;  #AUTHOR_TAG.', 'self - attention, which relies on dot - products between elements of the input sequence to compute a weighted sum  #AUTHOR_TAG, has also been a critical ingredient in modern nmt architectures.', 'the transformer network  #TAUTHOR_TAG avoids the recurrence completely and uses only self - attention.', 'we propose a modified transformer network wherein the multi - head attention layer is replaced by a branched self - attention layer.', 'the contributions of the various branches is learned as part of the training procedure.', 'the idea of multi - branch networks has been explored in several domains  #AUTHOR_TAG.', 'to the best of our knowledge, this is the first model using a branched structure in the transformer network.', 'in, the authors use a large network, with billions of weights, in conjunction with a sparse expert model to achieve competitive performance.', ' #AUTHOR_TAG analyze learned branching, through gates, in the context of computer vision while in  #AUTHOR_TAG, the author analyzes a two - branch model with randomly sampled weights in the context of image classification']",0
"['number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '##ly']","['number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '##ly']","['note that where h denotes the number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '']","[', concatenate the results, and project the concatenation with a feed - forward layer. this can be expressed in the same notation as equation ( 1 ) : where the w', 'i and w o are parameter projection', 'matrices that are learned. note that where h denotes the number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '##ly reduce d k = d v = d model so that the computational load of the multi - head attention is the same as simple self - attention.', '']",0
"['number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '##ly']","['number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '##ly']","['note that where h denotes the number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '']","[', concatenate the results, and project the concatenation with a feed - forward layer. this can be expressed in the same notation as equation ( 1 ) : where the w', 'i and w o are parameter projection', 'matrices that are learned. note that where h denotes the number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '##ly reduce d k = d v = d model so that the computational load of the multi - head attention is the same as simple self - attention.', '']",0
"['number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '##ly']","['number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '##ly']","['note that where h denotes the number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '']","[', concatenate the results, and project the concatenation with a feed - forward layer. this can be expressed in the same notation as equation ( 1 ) : where the w', 'i and w o are parameter projection', 'matrices that are learned. note that where h denotes the number of heads in the multi - head attention.  #TAUTHOR_TAG proportional', '##ly reduce d k = d v = d model so that the computational load of the multi - head attention is the same as simple self - attention.', '']",0
"['', 'in  #TAUTHOR_TAG, the authors introduce the transformer']","['', 'in  #TAUTHOR_TAG, the authors introduce the transformer network, a novel']","['of such dependencies  #AUTHOR_TAG.', 'in  #TAUTHOR_TAG, the authors introduce the transformer']","['', 'however, because of their auto - regressive property of requiring previous hidden states to be computed before the current time step, they cannot benefit from parallelization.', 'variants of recurrent networks that use strided convolutions eschew the traditional time - step based computation  #AUTHOR_TAG 2017 ;  #AUTHOR_TAG.', 'however, in these models, the operations needed to learn dependencies between distant positions can be difficult to learn  #AUTHOR_TAG.', 'attention mechanisms, often used in conjunction with recurrent models, have become an integral part of complex sequential tasks because they facilitate learning of such dependencies  #AUTHOR_TAG.', 'in  #TAUTHOR_TAG, the authors introduce the transformer network, a novel architecture that avoids the recurrence equation and maps the input sequences into hidden states solely using attention.', 'specifically, the authors use positional encodings in conjunction with a multi - head attention mechanism.', '']",6
[' #TAUTHOR_TAG avoids the recurrence completely'],[' #TAUTHOR_TAG avoids the recurrence completely'],"['a weighted sum  #AUTHOR_TAG, has also been a critical ingredient in modern nmt architectures.', 'the transformer network  #TAUTHOR_TAG avoids the recurrence completely']","['architectures for neural machine translation ( nmt ) use an encoder and a decoder that rely on deep recurrent neural networks like the lstm  #AUTHOR_TAG.', 'several architectures have been proposed to reduce the computational load associated with recurrence - based computation  #AUTHOR_TAG 2017 ;  #AUTHOR_TAG.', 'self - attention, which relies on dot - products between elements of the input sequence to compute a weighted sum  #AUTHOR_TAG, has also been a critical ingredient in modern nmt architectures.', 'the transformer network  #TAUTHOR_TAG avoids the recurrence completely and uses only self - attention.', 'we propose a modified transformer network wherein the multi - head attention layer is replaced by a branched self - attention layer.', 'the contributions of the various branches is learned as part of the training procedure.', 'the idea of multi - branch networks has been explored in several domains  #AUTHOR_TAG.', 'to the best of our knowledge, this is the first model using a branched structure in the transformer network.', 'in, the authors use a large network, with billions of weights, in conjunction with a sparse expert model to achieve competitive performance.', ' #AUTHOR_TAG analyze learned branching, through gates, in the context of computer vision while in  #AUTHOR_TAG, the author analyzes a two - branch model with randomly sampled weights in the context of image classification']",6
['in  #TAUTHOR_TAG comprising'],['in  #TAUTHOR_TAG comprising'],['in  #TAUTHOR_TAG comprising the multi - head attention sub - layer'],[' #TAUTHOR_TAG'],5
['( small )  #TAUTHOR_TAG'],['( small )  #TAUTHOR_TAG'],['( small )  #TAUTHOR_TAG'],"['( small )  #TAUTHOR_TAG 27. 3 38. 1 weighted transformer ( small ) 28. 4 38. 9', 'transformer ( large )  #TAUTHOR_TAG 28. 4 41. 0 weighted transformer ( large ) 28. 9 41. 4', 'bytenet  #AUTHOR_TAG 23. 7 - deep - att + posunk  #AUTHOR_TAG - 39. 2 gnmt + rl  #AUTHOR_TAG 24. 6 39. 9 convs2s  #AUTHOR_TAG 25. 2 40. 5 moe 26. 0 40. 6 table 1 : experimental results on the wmt 2014 english - to - german ( en - de ) and english - tofrench ( en - fr ) translation tasks.', 'our proposed model outperforms the state - of - the - art models including the transformer  #TAUTHOR_TAG.', 'the small model corresponds to configuration ( a ) in table 2 while large corresponds to configuration ( b ).', 'testing losses for the same training loss.', 'we see this effect in our experiments suggesting that the proposed architecture may have better regularizing properties.', 'this is not unexpected given similar outcomes for other branching - based strategies such as shake -  #AUTHOR_TAG and mixtureof - experts']",5
['( small )  #TAUTHOR_TAG'],['( small )  #TAUTHOR_TAG'],['( small )  #TAUTHOR_TAG'],"['( small )  #TAUTHOR_TAG 27. 3 38. 1 weighted transformer ( small ) 28. 4 38. 9', 'transformer ( large )  #TAUTHOR_TAG 28. 4 41. 0 weighted transformer ( large ) 28. 9 41. 4', 'bytenet  #AUTHOR_TAG 23. 7 - deep - att + posunk  #AUTHOR_TAG - 39. 2 gnmt + rl  #AUTHOR_TAG 24. 6 39. 9 convs2s  #AUTHOR_TAG 25. 2 40. 5 moe 26. 0 40. 6 table 1 : experimental results on the wmt 2014 english - to - german ( en - de ) and english - tofrench ( en - fr ) translation tasks.', 'our proposed model outperforms the state - of - the - art models including the transformer  #TAUTHOR_TAG.', 'the small model corresponds to configuration ( a ) in table 2 while large corresponds to configuration ( b ).', 'testing losses for the same training loss.', 'we see this effect in our experiments suggesting that the proposed architecture may have better regularizing properties.', 'this is not unexpected given similar outcomes for other branching - based strategies such as shake -  #AUTHOR_TAG and mixtureof - experts']",5
"['', 'as in  #TAUTHOR_TAG,']","['use label smoothing with ls = 0. 1, attention dropout, and residual dropout with probability p drop = 0. 1.', 'attention dropout randomly drops out elements  #AUTHOR_TAG from the softmax in ( 1 ).', 'as in  #TAUTHOR_TAG,']","['', 'as in  #TAUTHOR_TAG, we used']","['weights κ and α are initialized randomly, as with the rest of the transformer weights.', 'in addition to the layer normalization and residual connections, we use label smoothing with ls = 0. 1, attention dropout, and residual dropout with probability p drop = 0. 1.', 'attention dropout randomly drops out elements  #AUTHOR_TAG from the softmax in ( 1 ).', 'as in  #TAUTHOR_TAG, we used the adam optimizer  #AUTHOR_TAG with ( β 1, β 2 ) = ( 0. 9, 0. 98 ) and = 10 −9.', 'we also use the learning rate warm - up strategy for adam wherein the learning rate lr takes on the form :', 'for the all parameters except ( α, κ ) and', 'for ( α, κ ).', 'this corresponds to the warm - up strategy used for the original transformer network except that we use a larger peak learning rate for ( α, κ ) to compensate for their bounds.', 'further, we found that freezing the weights ( κ, α ) in the last 10k iterations aids convergence.', 'during this time, we continue training the rest of the network.', 'we hypothesize that this freezing process helps stabilize the rest of the network weights given the weighting scheme.', '']",3
"['', 'as in  #TAUTHOR_TAG,']","['use label smoothing with ls = 0. 1, attention dropout, and residual dropout with probability p drop = 0. 1.', 'attention dropout randomly drops out elements  #AUTHOR_TAG from the softmax in ( 1 ).', 'as in  #TAUTHOR_TAG,']","['', 'as in  #TAUTHOR_TAG, we used']","['weights κ and α are initialized randomly, as with the rest of the transformer weights.', 'in addition to the layer normalization and residual connections, we use label smoothing with ls = 0. 1, attention dropout, and residual dropout with probability p drop = 0. 1.', 'attention dropout randomly drops out elements  #AUTHOR_TAG from the softmax in ( 1 ).', 'as in  #TAUTHOR_TAG, we used the adam optimizer  #AUTHOR_TAG with ( β 1, β 2 ) = ( 0. 9, 0. 98 ) and = 10 −9.', 'we also use the learning rate warm - up strategy for adam wherein the learning rate lr takes on the form :', 'for the all parameters except ( α, κ ) and', 'for ( α, κ ).', 'this corresponds to the warm - up strategy used for the original transformer network except that we use a larger peak learning rate for ( α, κ ) to compensate for their bounds.', 'further, we found that freezing the weights ( κ, α ) in the last 10k iterations aids convergence.', 'during this time, we continue training the rest of the network.', 'we hypothesize that this freezing process helps stabilize the rest of the network weights given the weighting scheme.', '']",4
['( small )  #TAUTHOR_TAG'],['( small )  #TAUTHOR_TAG'],['( small )  #TAUTHOR_TAG'],"['( small )  #TAUTHOR_TAG 27. 3 38. 1 weighted transformer ( small ) 28. 4 38. 9', 'transformer ( large )  #TAUTHOR_TAG 28. 4 41. 0 weighted transformer ( large ) 28. 9 41. 4', 'bytenet  #AUTHOR_TAG 23. 7 - deep - att + posunk  #AUTHOR_TAG - 39. 2 gnmt + rl  #AUTHOR_TAG 24. 6 39. 9 convs2s  #AUTHOR_TAG 25. 2 40. 5 moe 26. 0 40. 6 table 1 : experimental results on the wmt 2014 english - to - german ( en - de ) and english - tofrench ( en - fr ) translation tasks.', 'our proposed model outperforms the state - of - the - art models including the transformer  #TAUTHOR_TAG.', 'the small model corresponds to configuration ( a ) in table 2 while large corresponds to configuration ( b ).', 'testing losses for the same training loss.', 'we see this effect in our experiments suggesting that the proposed architecture may have better regularizing properties.', 'this is not unexpected given similar outcomes for other branching - based strategies such as shake -  #AUTHOR_TAG and mixtureof - experts']",4
['by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier'],['by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier'],"['salient spatial patterns.', 'recent work by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier']","['', 'this final convolution is naturally biased to identify spatial patterns across word comparisons, which, in turn, biases learned word comparisons to pick up rhyming since rhymes are typically the most salient spatial patterns.', 'recent work by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier for learning the notion of rhyming : that a line ending word always rhymes with exactly one more ending word in the poem.', 'this limits the applicability of their method to other forms of poetry with different rhyming patterns.', 'they train the classifier along with a language model in a multi - task setup.', 'further, at generation time, they heavily rely on rejection sampling to produce quatrains which satisfy any valid rhyming pattern.', 'in contrast, we find that generators trained using our structured adversary produce samples that satisfy rhyming constraints with much higher frequency.', 'we propose a structured discriminator to learn a poetry generator in a generative adversarial setup.', 'similarities between pairs of end - of']",0
"['##d et al.,, 2017  #TAUTHOR_TAG.', ' #AUTHOR_TAG retrieve high']","['proposed  #AUTHOR_TAG ghazvininejad et al.,, 2017  #TAUTHOR_TAG.', ' #AUTHOR_TAG retrieve high']","['poetry generation have been proposed  #AUTHOR_TAG ghazvininejad et al.,, 2017  #TAUTHOR_TAG.', ' #AUTHOR_TAG retrieve high ranking sentences']","['works on poetry generation mostly used rule based methods ( gervas, 2000 ;  #AUTHOR_TAG.', 'more recently, neural models for poetry generation have been proposed  #AUTHOR_TAG ghazvininejad et al.,, 2017  #TAUTHOR_TAG.', ' #AUTHOR_TAG retrieve high ranking sentences for a given user query, and repeatedly swap words to satisfy poetry constraints.', ' #AUTHOR_TAG worked on poetry translation using an unconstrained machine translation model and separately learned finite state automata for enforcing rhythm and rhyme.', 'similar to rhyming and rhythm patterns in poetry, certain types of musical compositions showcase rhythm and repetition patterns, and some prior works model such patterns in music generation  #AUTHOR_TAG jhamtani and berg  #AUTHOR_TAG.', 'generative adversarial learning  #AUTHOR_TAG for text generation has been used in prior works  #AUTHOR_TAG wang et al.,, 2019 rao and daume iii, 2019 ), though has not been explored with regard to the similarity structure proposed in this paper']",0
['by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier'],['by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier'],"['salient spatial patterns.', 'recent work by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier']","['', 'this final convolution is naturally biased to identify spatial patterns across word comparisons, which, in turn, biases learned word comparisons to pick up rhyming since rhymes are typically the most salient spatial patterns.', 'recent work by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier for learning the notion of rhyming : that a line ending word always rhymes with exactly one more ending word in the poem.', 'this limits the applicability of their method to other forms of poetry with different rhyming patterns.', 'they train the classifier along with a language model in a multi - task setup.', 'further, at generation time, they heavily rely on rejection sampling to produce quatrains which satisfy any valid rhyming pattern.', 'in contrast, we find that generators trained using our structured adversary produce samples that satisfy rhyming constraints with much higher frequency.', 'we propose a structured discriminator to learn a poetry generator in a generative adversarial setup.', 'similarities between pairs of end - of']",1
['by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier'],['by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier'],"['salient spatial patterns.', 'recent work by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier']","['', 'this final convolution is naturally biased to identify spatial patterns across word comparisons, which, in turn, biases learned word comparisons to pick up rhyming since rhymes are typically the most salient spatial patterns.', 'recent work by  #TAUTHOR_TAG proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier for learning the notion of rhyming : that a line ending word always rhymes with exactly one more ending word in the poem.', 'this limits the applicability of their method to other forms of poetry with different rhyming patterns.', 'they train the classifier along with a language model in a multi - task setup.', 'further, at generation time, they heavily rely on rejection sampling to produce quatrains which satisfy any valid rhyming pattern.', 'in contrast, we find that generators trained using our structured adversary produce samples that satisfy rhyming constraints with much higher frequency.', 'we propose a structured discriminator to learn a poetry generator in a generative adversarial setup.', 'similarities between pairs of end - of']",4
"['', 'following prior work  #TAUTHOR_TAG, we generate words in']","['ending word generation as well line generation conditioned on ending words.', 'following prior work  #TAUTHOR_TAG, we generate words in']","['ending word generation as well line generation conditioned on ending words.', 'following prior work  #TAUTHOR_TAG, we generate words in each line in']","[""generator is a hierarchical neural language model ( figure 1 ) that first generates a sequence of line - ending words, and thereafter generates the poem's lines conditioned on the ending words."", 'we use recurrent neural networks for ending word generation as well line generation conditioned on ending words.', 'following prior work  #TAUTHOR_TAG, we generate words in each line in reverse order ( i. e. right to left ), and begin generation with the last line first.', 'letx represent a sample from the current generator distribution, denoted by p θ, where θ represents the generator parameters.', 'we initialize the word embeddings in the generator with pre - trained word embeddings  #TAUTHOR_TAG trained on a separate non - sonnet corpus']",5
"['', 'following prior work  #TAUTHOR_TAG, we generate words in']","['ending word generation as well line generation conditioned on ending words.', 'following prior work  #TAUTHOR_TAG, we generate words in']","['ending word generation as well line generation conditioned on ending words.', 'following prior work  #TAUTHOR_TAG, we generate words in each line in']","[""generator is a hierarchical neural language model ( figure 1 ) that first generates a sequence of line - ending words, and thereafter generates the poem's lines conditioned on the ending words."", 'we use recurrent neural networks for ending word generation as well line generation conditioned on ending words.', 'following prior work  #TAUTHOR_TAG, we generate words in each line in reverse order ( i. e. right to left ), and begin generation with the last line first.', 'letx represent a sample from the current generator distribution, denoted by p θ, where θ represents the generator parameters.', 'we initialize the word embeddings in the generator with pre - trained word embeddings  #TAUTHOR_TAG trained on a separate non - sonnet corpus']",5
['##peare sonnet dataset  #TAUTHOR_TAG and a new limeric'],"['work with the shakespeare sonnet dataset  #TAUTHOR_TAG and a new limerick corpus.', 'each sonnet in the sonnet']","['work with the shakespeare sonnet dataset  #TAUTHOR_TAG and a new limerick corpus.', 'each sonnet in the sonnet dataset is made up of 3 quatrains of 4 lines each, and a couplet.', 'the dataset']","['work with the shakespeare sonnet dataset  #TAUTHOR_TAG and a new limerick corpus.', 'each sonnet in the sonnet dataset is made up of 3 quatrains of 4 lines each, and a couplet.', 'the dataset consists of 2685 sonnets in train, and 335 each in validation and test splits.', 'the quatrains typically have one of the following rhyming structures : aabb, abab, abba, though some deviations are observed in the dataset.', 'this may be because rhyming patterns are not always strictly followed in writing quatrains, and there are possible inaccuracies in the word pronunciation dictionaries used ( e. g. some words can have multiple different pronunciations based on context ).', 'a limerick is a form of verse with five lines.', 'limericks typically follow a rhyming pattern of aabba.', 'we collect limericks from an online collection 1.', 'due to a large vocabulary in the full collection, we filter the dataset to retain only those limericks whose all the words are in a subset of 9k most frequent words.', 'our final dataset consists of 10, 400 limericks in train and 1300 each in validation and test splits.', 'we train and evaluate the models separately on each corpus']",5
['- lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the'],"['gan gets much better sampling efficiency scores than', 'rhyme - lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the line - ending words and then condition on them to generate the remaining words. the change', 'was']","['gan gets much better sampling efficiency scores than', 'rhyme - lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the']","['', '- similar to rhyme - gan - but then instead of computing pairwise similarity matrix, it utilizes a lstm on the', 'sequence of the computed representations. as can be observed from table 1, rhyme - gan needs fewer samples than other methods to produce an acceptable quatrain', 'or a limerick, indicating that it has learned natural rhyming structures', 'more effectively from data. note we do not report deep - speare on limerick due to their sonnet specific assumption that for a given end - of - line word there', 'is exactly one more rhyming word among other end - of - line words. additionally, rhyme - gan - ns performs worse than rhyme', '- gan, and the difference in performance is more prominent in limerick - demonstrating that the proposed structure in the discriminator provided useful inductive', 'bias. note that compared to 4 line quatrains in sonnet, limerick has 5', 'line poems and has arguably more complex rhyming pattern constraints. likelihood on held out data we report negative log likelihood ( nll ) on test splits ( table 2 ). for sonnet, rhyme - gan achieves a test set', 'nll of 3. 98. our model without adversarial learning i. e. rhyme - lm, achieves a test set nll of 3. 97. deep - speare reports a test set nll of 4.', '38. note that our language model is hierarchical while deep - speare has a linear model. the nll for rhyme - lm and rhyme - gan are very similar, though rhyme - gan gets much better sampling efficiency scores than', 'rhyme - lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the line - ending words and then condition on them to generate the remaining words. the change', 'was made to make it more amenable to our proposed discriminator. however, our hierarchical language model ( rhyme - lm ) performs worse than deep - speare', 'as per sampling efficiency. therefore, structured discriminator is the driving factor behind the observed improvement with rhyme -', 'gan. however, committing to the ending words of all lines before completing preceding lines can be', 'a limitation, and addressing it is a possible future direction']",5
['- lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the'],"['gan gets much better sampling efficiency scores than', 'rhyme - lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the line - ending words and then condition on them to generate the remaining words. the change', 'was']","['gan gets much better sampling efficiency scores than', 'rhyme - lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the']","['', '- similar to rhyme - gan - but then instead of computing pairwise similarity matrix, it utilizes a lstm on the', 'sequence of the computed representations. as can be observed from table 1, rhyme - gan needs fewer samples than other methods to produce an acceptable quatrain', 'or a limerick, indicating that it has learned natural rhyming structures', 'more effectively from data. note we do not report deep - speare on limerick due to their sonnet specific assumption that for a given end - of - line word there', 'is exactly one more rhyming word among other end - of - line words. additionally, rhyme - gan - ns performs worse than rhyme', '- gan, and the difference in performance is more prominent in limerick - demonstrating that the proposed structure in the discriminator provided useful inductive', 'bias. note that compared to 4 line quatrains in sonnet, limerick has 5', 'line poems and has arguably more complex rhyming pattern constraints. likelihood on held out data we report negative log likelihood ( nll ) on test splits ( table 2 ). for sonnet, rhyme - gan achieves a test set', 'nll of 3. 98. our model without adversarial learning i. e. rhyme - lm, achieves a test set nll of 3. 97. deep - speare reports a test set nll of 4.', '38. note that our language model is hierarchical while deep - speare has a linear model. the nll for rhyme - lm and rhyme - gan are very similar, though rhyme - gan gets much better sampling efficiency scores than', 'rhyme - lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the line - ending words and then condition on them to generate the remaining words. the change', 'was made to make it more amenable to our proposed discriminator. however, our hierarchical language model ( rhyme - lm ) performs worse than deep - speare', 'as per sampling efficiency. therefore, structured discriminator is the driving factor behind the observed improvement with rhyme -', 'gan. however, committing to the ending words of all lines before completing preceding lines can be', 'a limitation, and addressing it is a possible future direction']",5
"['prior work  #TAUTHOR_TAG, we requested human annotators to identify the humanwritten poem when presented with two samples at a time - a quatr']","['prior work  #TAUTHOR_TAG, we requested human annotators to identify the humanwritten poem when presented with two samples at a time - a quatrain from the sonnet corpus and a machine - generated quatrain, and report the annotator accuracy on this task.', 'note that a lower']","['prior work  #TAUTHOR_TAG, we requested human annotators to identify the humanwritten poem when presented with two samples at a time - a quatrain from the sonnet corpus and a machine - generated quatrain, and report the annotator accuracy on this task.', 'note that']","['prior work  #TAUTHOR_TAG, we requested human annotators to identify the humanwritten poem when presented with two samples at a time - a quatrain from the sonnet corpus and a machine - generated quatrain, and report the annotator accuracy on this task.', 'note that a lower accuracy value is favorable as it signifies higher quality of machine - generated samples.', ""using 150 valid samples ( i. e. samples belonging to one of the allowed rhyming patterns ), we observe 56. 0 % annotator accuracy for rhyme - gan, and 53. 3 % for deep - speare - indicating that the post - rejection sampling outputs from the two methods are of comparable quality ( the difference in annotator accuracy is not statistically significant as per mcnemar's test under p < 0. 05 )."", ""if we use pre - rejection samples, we observe 60. 0 % annotator accuracy for rhyme - gan, and 81. 3 % for deep - speare ( the difference being statistically significant as per mcnemar's test under p < 0. 05 ) - indicating that unfiltered samples from rhyme - gan are of higher quality compared to deep - speare""]",5
['- lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the'],"['gan gets much better sampling efficiency scores than', 'rhyme - lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the line - ending words and then condition on them to generate the remaining words. the change', 'was']","['gan gets much better sampling efficiency scores than', 'rhyme - lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the']","['', '- similar to rhyme - gan - but then instead of computing pairwise similarity matrix, it utilizes a lstm on the', 'sequence of the computed representations. as can be observed from table 1, rhyme - gan needs fewer samples than other methods to produce an acceptable quatrain', 'or a limerick, indicating that it has learned natural rhyming structures', 'more effectively from data. note we do not report deep - speare on limerick due to their sonnet specific assumption that for a given end - of - line word there', 'is exactly one more rhyming word among other end - of - line words. additionally, rhyme - gan - ns performs worse than rhyme', '- gan, and the difference in performance is more prominent in limerick - demonstrating that the proposed structure in the discriminator provided useful inductive', 'bias. note that compared to 4 line quatrains in sonnet, limerick has 5', 'line poems and has arguably more complex rhyming pattern constraints. likelihood on held out data we report negative log likelihood ( nll ) on test splits ( table 2 ). for sonnet, rhyme - gan achieves a test set', 'nll of 3. 98. our model without adversarial learning i. e. rhyme - lm, achieves a test set nll of 3. 97. deep - speare reports a test set nll of 4.', '38. note that our language model is hierarchical while deep - speare has a linear model. the nll for rhyme - lm and rhyme - gan are very similar, though rhyme - gan gets much better sampling efficiency scores than', 'rhyme - lm. our generator implementation is largely based on that of  #TAUTHOR_TAG. the main difference is that we first generate all the line - ending words and then condition on them to generate the remaining words. the change', 'was made to make it more amenable to our proposed discriminator. however, our hierarchical language model ( rhyme - lm ) performs worse than deep - speare', 'as per sampling efficiency. therefore, structured discriminator is the driving factor behind the observed improvement with rhyme -', 'gan. however, committing to the ending words of all lines before completing preceding lines can be', 'a limitation, and addressing it is a possible future direction']",6
['task  #TAUTHOR_TAG'],"['narrative chains, script - like structures that we evaluate with the "" narrative cloze "" task  #TAUTHOR_TAG']","['narrative chains, script - like structures that we evaluate with the "" narrative cloze "" task  #TAUTHOR_TAG']","['automatic induction of scripts  #AUTHOR_TAG has been the focus of many recent works.', 'in this paper, we employ a variety of these methods to learn schank and abelson\'s canonical restaurant script, using a novel dataset of restaurant narratives we have compiled from a website called "" dinners from hell. "" our models learn narrative chains, script - like structures that we evaluate with the "" narrative cloze "" task  #TAUTHOR_TAG']",5
"[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","['exists, previous work demonstrates the feasibility of assembling such a corpus by automatically retrieving relevant documents from a', 'larger collection. for example,  #AUTHOR_TAG use information retrieval techniques to gather a small number of bombing - related documents from the gigaword corpus, which they successfully use to learn a mucstyle  #AUTHOR_TAG', 'information extraction tem - plate for bombing events. following the work of  #AUTHOR_TAG in learning word associations via mutual information, and the dirt system introduced by  #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system for learning script - like structures called narrative chains. several followup', 'papers introduce variations and improvements on this original model for learning narrative chains  #AUTHOR_TAG. it is from this body of work that we borrow techniques to apply to the dinners from hell dataset. as defined by  #TAUTHOR_TAG, a narrative chain is', '"" a partially ordered set of narrative events that share a common actor, "" where a narrative event is "" a tuple of an event ( most simply a verb ) and its participants, represented as typed dependencies. "" to learn narrative chains', '']",5
"['insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts']","['insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts']","['insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts the event that maximizes unordered pmi,', 'where']","['order to perform the narrative cloze task, we need a model for predicting the missing narrative event, e, from a chain of observed narrative events, e 1...', 'e n, at insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts the event that maximizes unordered pmi,', 'where v is the set of all observed events ( the vocabulary ) and c ( e 1, e 2 ) is symmetric.', 'two additional models are introduced by  #AUTHOR_TAG and we use them here, as well.', 'first, the ordered pmi model,', 'pmi ( e, e i ) ( 4 ) where c ( e 1, e 2 ) is asymmetric, i. e., c ( e 1, e 2 ) counts only cases in which e 1 occurs before e 2.', 'second, the bigram probability model :', 'where p ( e 2 | e 1 ) = c ( e 1, e 2 )', 'c ( e 1, * ) and c ( e 1, e 2 ) is asymmetric.', 'discounting for each model, we add an option for discounting the computed scores.', 'in the case of the two pmi - based models, we use the discount score described in  #AUTHOR_TAG and used by  #TAUTHOR_TAG.', 'for the bigram probability model, this pmi discount score would be inappropriate, so we instead use absolute discounting.', 'document threshold we include a document threshold parameter, d, that ensures that, in any narrative cloze test, any event e that was observed during training in fewer than d distinct documents will receive a worse score ( i. e. be ranked behind ) any event e whose count meets the document threshold']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],5
"['of learning narrative chains from text corpora  #TAUTHOR_TAG.', 'these statistical']","['of learning narrative chains from text corpora  #TAUTHOR_TAG.', 'these statistical']","['of learning narrative chains from text corpora  #TAUTHOR_TAG.', 'these statistical approaches have focused on open - domain script acquisition, in which a large number of scripts may be learned, but the acquisition of any particular set of scripts is not guaranteed']","['well - known theory from the intersection of psychology and artificial intelligence posits that humans organize certain kinds of general knowledge in the form of scripts, or common sequences of events  #AUTHOR_TAG.', 'though many early ai systems employed hand - encoded scripts, more recent work has attempted to induce scripts with automatic and scalable techniques.', 'in particular, several related techniques approach the problem of script induction as one of learning narrative chains from text corpora  #TAUTHOR_TAG.', 'these statistical approaches have focused on open - domain script acquisition, in which a large number of scripts may be learned, but the acquisition of any particular set of scripts is not guaranteed.', 'for many specialized applications, however, knowledge of a few relevant scripts may be more useful than knowledge of many irrelevant scripts.', 'with this scenario in mind, we attempt to learn the famous "" restaurant script ""  #AUTHOR_TAG by applying the aforementioned narrative chain learning methods to a specialized corpus of dinner narratives we compile from the website "" dinners from hell. "" our results suggest that applying these techniques to a domain - specific dataset may be reasonable way to learn domain - specific scripts']",0
"[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","['exists, previous work demonstrates the feasibility of assembling such a corpus by automatically retrieving relevant documents from a', 'larger collection. for example,  #AUTHOR_TAG use information retrieval techniques to gather a small number of bombing - related documents from the gigaword corpus, which they successfully use to learn a mucstyle  #AUTHOR_TAG', 'information extraction tem - plate for bombing events. following the work of  #AUTHOR_TAG in learning word associations via mutual information, and the dirt system introduced by  #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system for learning script - like structures called narrative chains. several followup', 'papers introduce variations and improvements on this original model for learning narrative chains  #AUTHOR_TAG. it is from this body of work that we borrow techniques to apply to the dinners from hell dataset. as defined by  #TAUTHOR_TAG, a narrative chain is', '"" a partially ordered set of narrative events that share a common actor, "" where a narrative event is "" a tuple of an event ( most simply a verb ) and its participants, represented as typed dependencies. "" to learn narrative chains', '']",0
"[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","['exists, previous work demonstrates the feasibility of assembling such a corpus by automatically retrieving relevant documents from a', 'larger collection. for example,  #AUTHOR_TAG use information retrieval techniques to gather a small number of bombing - related documents from the gigaword corpus, which they successfully use to learn a mucstyle  #AUTHOR_TAG', 'information extraction tem - plate for bombing events. following the work of  #AUTHOR_TAG in learning word associations via mutual information, and the dirt system introduced by  #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system for learning script - like structures called narrative chains. several followup', 'papers introduce variations and improvements on this original model for learning narrative chains  #AUTHOR_TAG. it is from this body of work that we borrow techniques to apply to the dinners from hell dataset. as defined by  #TAUTHOR_TAG, a narrative chain is', '"" a partially ordered set of narrative events that share a common actor, "" where a narrative event is "" a tuple of an event ( most simply a verb ) and its participants, represented as typed dependencies. "" to learn narrative chains', '']",0
"['insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts']","['insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts']","['insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts the event that maximizes unordered pmi,', 'where']","['order to perform the narrative cloze task, we need a model for predicting the missing narrative event, e, from a chain of observed narrative events, e 1...', 'e n, at insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts the event that maximizes unordered pmi,', 'where v is the set of all observed events ( the vocabulary ) and c ( e 1, e 2 ) is symmetric.', 'two additional models are introduced by  #AUTHOR_TAG and we use them here, as well.', 'first, the ordered pmi model,', 'pmi ( e, e i ) ( 4 ) where c ( e 1, e 2 ) is asymmetric, i. e., c ( e 1, e 2 ) counts only cases in which e 1 occurs before e 2.', 'second, the bigram probability model :', 'where p ( e 2 | e 1 ) = c ( e 1, e 2 )', 'c ( e 1, * ) and c ( e 1, e 2 ) is asymmetric.', 'discounting for each model, we add an option for discounting the computed scores.', 'in the case of the two pmi - based models, we use the discount score described in  #AUTHOR_TAG and used by  #TAUTHOR_TAG.', 'for the bigram probability model, this pmi discount score would be inappropriate, so we instead use absolute discounting.', 'document threshold we include a document threshold parameter, d, that ensures that, in any narrative cloze test, any event e that was observed during training in fewer than d distinct documents will receive a worse score ( i. e. be ranked behind ) any event e whose count meets the document threshold']",0
"[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","[' #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system']","['exists, previous work demonstrates the feasibility of assembling such a corpus by automatically retrieving relevant documents from a', 'larger collection. for example,  #AUTHOR_TAG use information retrieval techniques to gather a small number of bombing - related documents from the gigaword corpus, which they successfully use to learn a mucstyle  #AUTHOR_TAG', 'information extraction tem - plate for bombing events. following the work of  #AUTHOR_TAG in learning word associations via mutual information, and the dirt system introduced by  #AUTHOR_TAG,  #TAUTHOR_TAG propose a pmi - based system for learning script - like structures called narrative chains. several followup', 'papers introduce variations and improvements on this original model for learning narrative chains  #AUTHOR_TAG. it is from this body of work that we borrow techniques to apply to the dinners from hell dataset. as defined by  #TAUTHOR_TAG, a narrative chain is', '"" a partially ordered set of narrative events that share a common actor, "" where a narrative event is "" a tuple of an event ( most simply a verb ) and its participants, represented as typed dependencies. "" to learn narrative chains', '']",3
"['insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts']","['insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts']","['insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts the event that maximizes unordered pmi,', 'where']","['order to perform the narrative cloze task, we need a model for predicting the missing narrative event, e, from a chain of observed narrative events, e 1...', 'e n, at insertion point k. the original model, proposed by  #TAUTHOR_TAG, predicts the event that maximizes unordered pmi,', 'where v is the set of all observed events ( the vocabulary ) and c ( e 1, e 2 ) is symmetric.', 'two additional models are introduced by  #AUTHOR_TAG and we use them here, as well.', 'first, the ordered pmi model,', 'pmi ( e, e i ) ( 4 ) where c ( e 1, e 2 ) is asymmetric, i. e., c ( e 1, e 2 ) counts only cases in which e 1 occurs before e 2.', 'second, the bigram probability model :', 'where p ( e 2 | e 1 ) = c ( e 1, e 2 )', 'c ( e 1, * ) and c ( e 1, e 2 ) is asymmetric.', 'discounting for each model, we add an option for discounting the computed scores.', 'in the case of the two pmi - based models, we use the discount score described in  #AUTHOR_TAG and used by  #TAUTHOR_TAG.', 'for the bigram probability model, this pmi discount score would be inappropriate, so we instead use absolute discounting.', 'document threshold we include a document threshold parameter, d, that ensures that, in any narrative cloze test, any event e that was observed during training in fewer than d distinct documents will receive a worse score ( i. e. be ranked behind ) any event e whose count meets the document threshold']",3
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],3
['original model  #TAUTHOR_TAG'],['original model  #TAUTHOR_TAG'],"['to learn narrative chains from the dinners from hell corpus, starting with the original model  #TAUTHOR_TAG']","['section provides an overview of each of the different methods and parameter settings we employ to learn narrative chains from the dinners from hell corpus, starting with the original model  #TAUTHOR_TAG and extending to the modifications of  #AUTHOR_TAG.', 'as part of this work, we are releasing a program called nachos, our integrated python implementation of each of the methods for learning narrative chains described in this section.', '']",4
['original model  #TAUTHOR_TAG'],['original model  #TAUTHOR_TAG'],"['to learn narrative chains from the dinners from hell corpus, starting with the original model  #TAUTHOR_TAG']","['section provides an overview of each of the different methods and parameter settings we employ to learn narrative chains from the dinners from hell corpus, starting with the original model  #TAUTHOR_TAG and extending to the modifications of  #AUTHOR_TAG.', 'as part of this work, we are releasing a program called nachos, our integrated python implementation of each of the methods for learning narrative chains described in this section.', '']",6
"['similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of']","['similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of']","['most popular test sets for similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of']","['referred to as count - based, as distinguished from the contextpredicting ones, which have been recently proposed in the literature  #AUTHOR_TAG. more commonly known as word embeddings, these secondgeneration models learn meaning representations through neural network training : the vectors dimensions are set to maximize the probability for the contexts that typically occur with the target word. vector', 'cosine is generally adopted by both types of models as a similarity measure. however, this metric has been found to suffer from several problems  #AUTHOR_TAG, such as a bias towards features with higher values', 'and the inability of considering how many features are actually shared by the vectors. finally, cosine is affected by the hubness effect  #AUTHOR_TAG, i. e. the fact that words with high frequency tend to be', 'universal neighbours. even though other measures have been proposed', 'in the literature  #AUTHOR_TAG, vector cosine is still by far the most popular one  #AUTHOR_TAG. however, in a recent paper of  #AUTHOR_TAG b )', ', the authors have claimed that vector cosine is outperformed by apsyn ( average precision for synonymy ), a metric based on', 'the extent of the intersection between the most salient contexts of two target words. the measure, tested on a window - based dsm, outperformed vector cosine on the es', '##l and on the toefl datasets. in the present work, we perform a systematic evaluation of apsyn, testing it on the most popular test sets for similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of twenty - eight models with different parameters settings, each of which differs according to corpus size, context window width, weighting scheme and', 'svd application. the new metric is shown to outperform vector cosine in most settings, except when the latter metric is applied on a ppmi - svd', 'reduced matrix  #AUTHOR_TAG, against which apsyn still obtains competitive performances. the results are also discussed in relation to the state -', 'of - the - art dsms, as reported in  #TAUTHOR_TAG. in such comparison, the best settings of our models outperform the word embeddings in almost all datasets. a pilot study was also carried out to investigate whether apsyn is scalable. results prove its high performance', 'also when calculated on large corpora, such as those used by. on top of the performance, apsyn seems not to be subject', 'to some of the biases that affect vector cosine. finally, considering the debate about the ability of dsms to calculate genuine similarity as opposed to word relatedness  #TAUTHOR_TAG, we test the ability of the models', 'to quantify genuine semantic similarity']",5
"['similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of']","['similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of']","['most popular test sets for similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of']","['referred to as count - based, as distinguished from the contextpredicting ones, which have been recently proposed in the literature  #AUTHOR_TAG. more commonly known as word embeddings, these secondgeneration models learn meaning representations through neural network training : the vectors dimensions are set to maximize the probability for the contexts that typically occur with the target word. vector', 'cosine is generally adopted by both types of models as a similarity measure. however, this metric has been found to suffer from several problems  #AUTHOR_TAG, such as a bias towards features with higher values', 'and the inability of considering how many features are actually shared by the vectors. finally, cosine is affected by the hubness effect  #AUTHOR_TAG, i. e. the fact that words with high frequency tend to be', 'universal neighbours. even though other measures have been proposed', 'in the literature  #AUTHOR_TAG, vector cosine is still by far the most popular one  #AUTHOR_TAG. however, in a recent paper of  #AUTHOR_TAG b )', ', the authors have claimed that vector cosine is outperformed by apsyn ( average precision for synonymy ), a metric based on', 'the extent of the intersection between the most salient contexts of two target words. the measure, tested on a window - based dsm, outperformed vector cosine on the es', '##l and on the toefl datasets. in the present work, we perform a systematic evaluation of apsyn, testing it on the most popular test sets for similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of twenty - eight models with different parameters settings, each of which differs according to corpus size, context window width, weighting scheme and', 'svd application. the new metric is shown to outperform vector cosine in most settings, except when the latter metric is applied on a ppmi - svd', 'reduced matrix  #AUTHOR_TAG, against which apsyn still obtains competitive performances. the results are also discussed in relation to the state -', 'of - the - art dsms, as reported in  #TAUTHOR_TAG. in such comparison, the best settings of our models outperform the word embeddings in almost all datasets. a pilot study was also carried out to investigate whether apsyn is scalable. results prove its high performance', 'also when calculated on large corpora, such as those used by. on top of the performance, apsyn seems not to be subject', 'to some of the biases that affect vector cosine. finally, considering the debate about the ability of dsms to calculate genuine similarity as opposed to word relatedness  #TAUTHOR_TAG, we test the ability of the models', 'to quantify genuine semantic similarity']",5
"['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['( i. e. similarity and association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores they had in wordsim - 353, which are known to be ambiguous in this regard. the men test collection  #AUTHOR_TAG includes 3, 000 word pairs divided in two sets ( one for training and one for testing ) together with human judgments,']",[' #TAUTHOR_TAG'],5
"['##s calculated on the neural language models ( nlm ) by  #TAUTHOR_TAG, who used the code ( or directly the embeddings ) shared by the original authors.', 'as we trained our models on']","['the vector cosines calculated on the neural language models ( nlm ) by  #TAUTHOR_TAG, who used the code ( or directly the embeddings ) shared by the original authors.', 'as we trained our models on']","['the vector cosines calculated on the neural language models ( nlm ) by  #TAUTHOR_TAG, who used the code ( or directly the embeddings ) shared by the original authors.', 'as we trained our models on almost the same corpora used by  #TAUTHOR_TAG, the results are perfectly comparable.', 'the three models we compare our results to are']","['order to compare our results with state - of - the - art dsms, we report the scores for the vector cosines calculated on the neural language models ( nlm ) by  #TAUTHOR_TAG, who used the code ( or directly the embeddings ) shared by the original authors.', 'as we trained our models on almost the same corpora used by  #TAUTHOR_TAG, the results are perfectly comparable.', 'the three models we compare our results to are : i ) the convolutional neural network of  #AUTHOR_TAG, which was trained on 852 million words of wikipedia ; ii ) the neural network of  #AUTHOR_TAG, which was trained on 990 million words of wikipedia ; and iii ) the word2vec of  #AUTHOR_TAG, which was trained on 1000 million words of wikipedia and on the rcv vol.', '1 corpus  #AUTHOR_TAG  #AUTHOR_TAG, as reported in  #AUTHOR_TAG']",5
"['. e. men, wordsim - 353 and  #TAUTHOR_TAG and the pos - tagged contexts having frequency above 100 in the two corpora.', 'we']","['of them include the pos - tagged target words used in the three datasets ( i. e. men, wordsim - 353 and  #TAUTHOR_TAG and the pos - tagged contexts having frequency above 100 in the two corpora.', 'we']","['. e. men, wordsim - 353 and  #TAUTHOR_TAG and the pos - tagged contexts having frequency above 100 in the two corpora.', 'we considered as contexts the content words (']","['our experiments, we implemented twenty - eight dsms, but for reasons of space only sixteen of them are reported in the tables.', 'all of them include the pos - tagged target words used in the three datasets ( i. e. men, wordsim - 353 and  #TAUTHOR_TAG and the pos - tagged contexts having frequency above 100 in the two corpora.', 'we considered as contexts the content words ( i. e. nouns, verbs and adjectives ) within a window of 2, 3 and 5, even though the latter was given up for its poor performances.', 'as for svd factorization, we found out that the best results were always achieved when the number of latent dimensions was between 300 and 500.', 'we report here only the scores for k = 300, since 300 is one of the most common choices for the dimensionality of svd - reduced spaces and it is always close to be an optimal value for the parameter.', 'fourteen out of twenty - eight models were developed for rcv1, while the others were developed for wikipedia.', 'for each corpus, the models differed according to the window size ( i. e. 2 and 3 ), to the statistical association measure used as a weighting scheme ( i. e. none, ppmi and lmi ) and to the application of svd to the previous combinations']",5
"[' #TAUTHOR_TAG, wordsim']","[' #TAUTHOR_TAG, wordsim - 353 and men.', 'in the bottom the']","[' #TAUTHOR_TAG, wordsim']","['the twenty - eight dsms, for each dataset we have measured the vector cosine and apsyn between the words in the test pairs.', 'table 2 : spearman correlation scores for our eight models trained on wikipedia, in the three datasets  #TAUTHOR_TAG, wordsim - 353 and men.', 'in the bottom the performance of the state - of - the - art models of  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG, as reported in  #TAUTHOR_TAG.', 'the spearman correlation between our scores and the gold standard was then computed for every model and it is reported in table 1 and table 2.', 'in particular, table 1 describes the performances on  #TAUTHOR_TAG, wordsim - 353 and men for the measures applied on rcv vol.', '1 models.', '']",5
"[' #TAUTHOR_TAG, wordsim']","[' #TAUTHOR_TAG, wordsim - 353 and men.', 'in the bottom the']","[' #TAUTHOR_TAG, wordsim']","['the twenty - eight dsms, for each dataset we have measured the vector cosine and apsyn between the words in the test pairs.', 'table 2 : spearman correlation scores for our eight models trained on wikipedia, in the three datasets  #TAUTHOR_TAG, wordsim - 353 and men.', 'in the bottom the performance of the state - of - the - art models of  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG, as reported in  #TAUTHOR_TAG.', 'the spearman correlation between our scores and the gold standard was then computed for every model and it is reported in table 1 and table 2.', 'in particular, table 1 describes the performances on  #TAUTHOR_TAG, wordsim - 353 and men for the measures applied on rcv vol.', '1 models.', '']",5
"[' #TAUTHOR_TAG, wordsim']","[' #TAUTHOR_TAG, wordsim - 353 and men.', 'in the bottom the']","[' #TAUTHOR_TAG, wordsim']","['the twenty - eight dsms, for each dataset we have measured the vector cosine and apsyn between the words in the test pairs.', 'table 2 : spearman correlation scores for our eight models trained on wikipedia, in the three datasets  #TAUTHOR_TAG, wordsim - 353 and men.', 'in the bottom the performance of the state - of - the - art models of  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG, as reported in  #TAUTHOR_TAG.', 'the spearman correlation between our scores and the gold standard was then computed for every model and it is reported in table 1 and table 2.', 'in particular, table 1 describes the performances on  #TAUTHOR_TAG, wordsim - 353 and men for the measures applied on rcv vol.', '1 models.', '']",5
"[' #TAUTHOR_TAG, wordsim']","[' #TAUTHOR_TAG, wordsim - 353 and men.', 'in the bottom the']","[' #TAUTHOR_TAG, wordsim']","['the twenty - eight dsms, for each dataset we have measured the vector cosine and apsyn between the words in the test pairs.', 'table 2 : spearman correlation scores for our eight models trained on wikipedia, in the three datasets  #TAUTHOR_TAG, wordsim - 353 and men.', 'in the bottom the performance of the state - of - the - art models of  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG, as reported in  #TAUTHOR_TAG.', 'the spearman correlation between our scores and the gold standard was then computed for every model and it is reported in table 1 and table 2.', 'in particular, table 1 describes the performances on  #TAUTHOR_TAG, wordsim - 353 and men for the measures applied on rcv vol.', '1 models.', '']",5
"['on  #TAUTHOR_TAG, while the']","['on  #TAUTHOR_TAG, while the']","['on  #TAUTHOR_TAG, while the latter seems to have some advantages on the other datasets. this table 3 : spearman correlation scores for our']","['##yn, which generally achieves the best results for n = 500. as a note about iii ), the results of using svd jointly with lmi spaces are less predictable than when combining it with ppmi. also, we can notice that the smaller window ( i. e. 2 ) does not always perform better than the larger one ( i. e. 3 ).', 'the former appears to perform better on  #TAUTHOR_TAG, while the latter seems to have some advantages on the other datasets. this table 3 : spearman correlation scores for our eight models trained on rcv1, in the two subsets of', ""might depend on the different type of similarity encoded in  #TAUTHOR_TAG ( i. e. genuine similarity ). on top of it, despite  #TAUTHOR_TAG's claim that no evidence supports the hypothesis that smaller context windows improve the ability of models to capture similarity  #AUTHOR_TAG, we need to mention that window 5 was abandoned because of its low performance. with reference to the hubness effect"", ', we have conducted a pilot study inspired to the one carried out by  #AUTHOR_TAG, using the words of the  #TAUTHOR_TAG dataset as query words and collecting', '']",5
"['on  #TAUTHOR_TAG, while the']","['on  #TAUTHOR_TAG, while the']","['on  #TAUTHOR_TAG, while the latter seems to have some advantages on the other datasets. this table 3 : spearman correlation scores for our']","['##yn, which generally achieves the best results for n = 500. as a note about iii ), the results of using svd jointly with lmi spaces are less predictable than when combining it with ppmi. also, we can notice that the smaller window ( i. e. 2 ) does not always perform better than the larger one ( i. e. 3 ).', 'the former appears to perform better on  #TAUTHOR_TAG, while the latter seems to have some advantages on the other datasets. this table 3 : spearman correlation scores for our eight models trained on rcv1, in the two subsets of', ""might depend on the different type of similarity encoded in  #TAUTHOR_TAG ( i. e. genuine similarity ). on top of it, despite  #TAUTHOR_TAG's claim that no evidence supports the hypothesis that smaller context windows improve the ability of models to capture similarity  #AUTHOR_TAG, we need to mention that window 5 was abandoned because of its low performance. with reference to the hubness effect"", ', we have conducted a pilot study inspired to the one carried out by  #AUTHOR_TAG, using the words of the  #TAUTHOR_TAG dataset as query words and collecting', '']",5
"['on  #TAUTHOR_TAG, while the']","['on  #TAUTHOR_TAG, while the']","['on  #TAUTHOR_TAG, while the latter seems to have some advantages on the other datasets. this table 3 : spearman correlation scores for our']","['##yn, which generally achieves the best results for n = 500. as a note about iii ), the results of using svd jointly with lmi spaces are less predictable than when combining it with ppmi. also, we can notice that the smaller window ( i. e. 2 ) does not always perform better than the larger one ( i. e. 3 ).', 'the former appears to perform better on  #TAUTHOR_TAG, while the latter seems to have some advantages on the other datasets. this table 3 : spearman correlation scores for our eight models trained on rcv1, in the two subsets of', ""might depend on the different type of similarity encoded in  #TAUTHOR_TAG ( i. e. genuine similarity ). on top of it, despite  #TAUTHOR_TAG's claim that no evidence supports the hypothesis that smaller context windows improve the ability of models to capture similarity  #AUTHOR_TAG, we need to mention that window 5 was abandoned because of its low performance. with reference to the hubness effect"", ', we have conducted a pilot study inspired to the one carried out by  #AUTHOR_TAG, using the words of the  #TAUTHOR_TAG dataset as query words and collecting', '']",5
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],5
"['similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of']","['similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of']","['most popular test sets for similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of']","['referred to as count - based, as distinguished from the contextpredicting ones, which have been recently proposed in the literature  #AUTHOR_TAG. more commonly known as word embeddings, these secondgeneration models learn meaning representations through neural network training : the vectors dimensions are set to maximize the probability for the contexts that typically occur with the target word. vector', 'cosine is generally adopted by both types of models as a similarity measure. however, this metric has been found to suffer from several problems  #AUTHOR_TAG, such as a bias towards features with higher values', 'and the inability of considering how many features are actually shared by the vectors. finally, cosine is affected by the hubness effect  #AUTHOR_TAG, i. e. the fact that words with high frequency tend to be', 'universal neighbours. even though other measures have been proposed', 'in the literature  #AUTHOR_TAG, vector cosine is still by far the most popular one  #AUTHOR_TAG. however, in a recent paper of  #AUTHOR_TAG b )', ', the authors have claimed that vector cosine is outperformed by apsyn ( average precision for synonymy ), a metric based on', 'the extent of the intersection between the most salient contexts of two target words. the measure, tested on a window - based dsm, outperformed vector cosine on the es', '##l and on the toefl datasets. in the present work, we perform a systematic evaluation of apsyn, testing it on the most popular test sets for similarity estimation - namely wordsim - 35', '##3  #AUTHOR_TAG, men  #AUTHOR_TAG and  #TAUTHOR_TAG. for comparison, vector cosine is also', 'calculated on several countbased dsms. we implement a total of twenty - eight models with different parameters settings, each of which differs according to corpus size, context window width, weighting scheme and', 'svd application. the new metric is shown to outperform vector cosine in most settings, except when the latter metric is applied on a ppmi - svd', 'reduced matrix  #AUTHOR_TAG, against which apsyn still obtains competitive performances. the results are also discussed in relation to the state -', 'of - the - art dsms, as reported in  #TAUTHOR_TAG. in such comparison, the best settings of our models outperform the word embeddings in almost all datasets. a pilot study was also carried out to investigate whether apsyn is scalable. results prove its high performance', 'also when calculated on large corpora, such as those used by. on top of the performance, apsyn seems not to be subject', 'to some of the biases that affect vector cosine. finally, considering the debate about the ability of dsms to calculate genuine similarity as opposed to word relatedness  #TAUTHOR_TAG, we test the ability of the models', 'to quantify genuine semantic similarity']",0
"['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['( i. e. similarity and association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores they had in wordsim - 353, which are known to be ambiguous in this regard. the men test collection  #AUTHOR_TAG includes 3, 000 word pairs divided in two sets ( one for training and one for testing ) together with human judgments,']",[' #TAUTHOR_TAG'],0
"['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['( i. e. similarity and association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores they had in wordsim - 353, which are known to be ambiguous in this regard. the men test collection  #AUTHOR_TAG includes 3, 000 word pairs divided in two sets ( one for training and one for testing ) together with human judgments,']",[' #TAUTHOR_TAG'],0
"['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['( i. e. similarity and association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores they had in wordsim - 353, which are known to be ambiguous in this regard. the men test collection  #AUTHOR_TAG includes 3, 000 word pairs divided in two sets ( one for training and one for testing ) together with human judgments,']",[' #TAUTHOR_TAG'],0
"['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['( i. e. similarity and association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores they had in wordsim - 353, which are known to be ambiguous in this regard. the men test collection  #AUTHOR_TAG includes 3, 000 word pairs divided in two sets ( one for training and one for testing ) together with human judgments,']",[' #TAUTHOR_TAG'],0
"['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['( i. e. similarity and association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores']","['association ),  #TAUTHOR_TAG argue that', 'these gold standards still carry the scores they had in wordsim - 353, which are known to be ambiguous in this regard. the men test collection  #AUTHOR_TAG includes 3, 000 word pairs divided in two sets ( one for training and one for testing ) together with human judgments,']",[' #TAUTHOR_TAG'],0
"['##s calculated on the neural language models ( nlm ) by  #TAUTHOR_TAG, who used the code ( or directly the embeddings ) shared by the original authors.', 'as we trained our models on']","['the vector cosines calculated on the neural language models ( nlm ) by  #TAUTHOR_TAG, who used the code ( or directly the embeddings ) shared by the original authors.', 'as we trained our models on']","['the vector cosines calculated on the neural language models ( nlm ) by  #TAUTHOR_TAG, who used the code ( or directly the embeddings ) shared by the original authors.', 'as we trained our models on almost the same corpora used by  #TAUTHOR_TAG, the results are perfectly comparable.', 'the three models we compare our results to are']","['order to compare our results with state - of - the - art dsms, we report the scores for the vector cosines calculated on the neural language models ( nlm ) by  #TAUTHOR_TAG, who used the code ( or directly the embeddings ) shared by the original authors.', 'as we trained our models on almost the same corpora used by  #TAUTHOR_TAG, the results are perfectly comparable.', 'the three models we compare our results to are : i ) the convolutional neural network of  #AUTHOR_TAG, which was trained on 852 million words of wikipedia ; ii ) the neural network of  #AUTHOR_TAG, which was trained on 990 million words of wikipedia ; and iii ) the word2vec of  #AUTHOR_TAG, which was trained on 1000 million words of wikipedia and on the rcv vol.', '1 corpus  #AUTHOR_TAG  #AUTHOR_TAG, as reported in  #AUTHOR_TAG']",3
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],3
"['on  #TAUTHOR_TAG, while the']","['on  #TAUTHOR_TAG, while the']","['on  #TAUTHOR_TAG, while the latter seems to have some advantages on the other datasets. this table 3 : spearman correlation scores for our']","['##yn, which generally achieves the best results for n = 500. as a note about iii ), the results of using svd jointly with lmi spaces are less predictable than when combining it with ppmi. also, we can notice that the smaller window ( i. e. 2 ) does not always perform better than the larger one ( i. e. 3 ).', 'the former appears to perform better on  #TAUTHOR_TAG, while the latter seems to have some advantages on the other datasets. this table 3 : spearman correlation scores for our eight models trained on rcv1, in the two subsets of', ""might depend on the different type of similarity encoded in  #TAUTHOR_TAG ( i. e. genuine similarity ). on top of it, despite  #TAUTHOR_TAG's claim that no evidence supports the hypothesis that smaller context windows improve the ability of models to capture similarity  #AUTHOR_TAG, we need to mention that window 5 was abandoned because of its low performance. with reference to the hubness effect"", ', we have conducted a pilot study inspired to the one carried out by  #AUTHOR_TAG, using the words of the  #TAUTHOR_TAG dataset as query words and collecting', '']",4
"['on  #TAUTHOR_TAG, while the']","['on  #TAUTHOR_TAG, while the']","['on  #TAUTHOR_TAG, while the latter seems to have some advantages on the other datasets. this table 3 : spearman correlation scores for our']","['##yn, which generally achieves the best results for n = 500. as a note about iii ), the results of using svd jointly with lmi spaces are less predictable than when combining it with ppmi. also, we can notice that the smaller window ( i. e. 2 ) does not always perform better than the larger one ( i. e. 3 ).', 'the former appears to perform better on  #TAUTHOR_TAG, while the latter seems to have some advantages on the other datasets. this table 3 : spearman correlation scores for our eight models trained on rcv1, in the two subsets of', ""might depend on the different type of similarity encoded in  #TAUTHOR_TAG ( i. e. genuine similarity ). on top of it, despite  #TAUTHOR_TAG's claim that no evidence supports the hypothesis that smaller context windows improve the ability of models to capture similarity  #AUTHOR_TAG, we need to mention that window 5 was abandoned because of its low performance. with reference to the hubness effect"", ', we have conducted a pilot study inspired to the one carried out by  #AUTHOR_TAG, using the words of the  #TAUTHOR_TAG dataset as query words and collecting', '']",4
"['- sequence models  #TAUTHOR_TAG, hr']","[""is able to ground the system's textual response with language and images by learning the semantic correspondence between them while modelling long - term dialogue context."", ' #AUTHOR_TAG.', 'in contrast to standard sequenceto - sequence models  #TAUTHOR_TAG, hreds model the dialogue context by introducing a context recurrent']","['- sequence models  #TAUTHOR_TAG, hr']","['work aims to learn strategies for textual response generation in a multimodal conversation directly from data.', 'conversational ai has great potential for online retail : it greatly enhances user experience and in turn directly affects user retention  #AUTHOR_TAG, especially if the interaction is multi - modal in nature.', 'so far, most conversational agents are uni - modal - ranging from opendomain conversation  #AUTHOR_TAG to task oriented dialogue systems  #AUTHOR_TAG 2011 ;  #AUTHOR_TAG.', 'while recent progress in deep learning has unified research at the intersection of vision and language, the availability of open - source multimodal dialogue datasets still remains a bottleneck.', 'this research makes use of a recently released multimodal dialogue ( mmd ) dataset  #AUTHOR_TAG, which contains multiple dialogue sessions in the fashion domain.', 'the mmd dataset provides an interesting new challenge, combining recent efforts on task - oriented dialogue systems, as well as visually grounded dialogue.', 'in contrast to simple qa tasks in visually grounded dialogue, e. g.  #AUTHOR_TAG, it contains conversations with a clear end - goal.', 'however, in contrast to previous slot - filling dialogue systems, e. g.  #AUTHOR_TAG, it heavily relies on the extra visual modality to drive the conversation forward ( see figure 1 ).', 'in the following, we propose a fully data - driven response generation model for this task.', ""our work is able to ground the system's textual response with language and images by learning the semantic correspondence between them while modelling long - term dialogue context."", ' #AUTHOR_TAG.', 'in contrast to standard sequenceto - sequence models  #TAUTHOR_TAG, hreds model the dialogue context by introducing a context recurrent neural network ( rnn ) over the encoder rnn, thus forming a hierarchical encoder.', 'we build on top of the hred architecture to include multimodality over multiple images.', 'a simple hred consists of three rnn modules : encoder, context and decoder.', 'in multimodal hred, we combine the output representations from the utterance encoder with concatenated multiple image representations and pass them as input to the context encoder ( see figure 2 ).', 'a dialogue is modelled as a sequence of utterances ( turns ), which in turn are modelled as sequences of words and images.', 'formally, a dialogue is generated according to the following :', 'where t n is the n - th utterance in a dialogue.', 'for each m = 1,..., m n, we have hidden states of each module defined as :', 'where f text θ, f cxt θ and f dec θ are gru cells  #TAUTHOR_TAG.', 'θ represent model parameters, w n, m is the m - th word in the n - th utterance and g enc θ is a convolutional neural']",4
"['- sequence models  #TAUTHOR_TAG, hr']","[""is able to ground the system's textual response with language and images by learning the semantic correspondence between them while modelling long - term dialogue context."", ' #AUTHOR_TAG.', 'in contrast to standard sequenceto - sequence models  #TAUTHOR_TAG, hreds model the dialogue context by introducing a context recurrent']","['- sequence models  #TAUTHOR_TAG, hr']","['work aims to learn strategies for textual response generation in a multimodal conversation directly from data.', 'conversational ai has great potential for online retail : it greatly enhances user experience and in turn directly affects user retention  #AUTHOR_TAG, especially if the interaction is multi - modal in nature.', 'so far, most conversational agents are uni - modal - ranging from opendomain conversation  #AUTHOR_TAG to task oriented dialogue systems  #AUTHOR_TAG 2011 ;  #AUTHOR_TAG.', 'while recent progress in deep learning has unified research at the intersection of vision and language, the availability of open - source multimodal dialogue datasets still remains a bottleneck.', 'this research makes use of a recently released multimodal dialogue ( mmd ) dataset  #AUTHOR_TAG, which contains multiple dialogue sessions in the fashion domain.', 'the mmd dataset provides an interesting new challenge, combining recent efforts on task - oriented dialogue systems, as well as visually grounded dialogue.', 'in contrast to simple qa tasks in visually grounded dialogue, e. g.  #AUTHOR_TAG, it contains conversations with a clear end - goal.', 'however, in contrast to previous slot - filling dialogue systems, e. g.  #AUTHOR_TAG, it heavily relies on the extra visual modality to drive the conversation forward ( see figure 1 ).', 'in the following, we propose a fully data - driven response generation model for this task.', ""our work is able to ground the system's textual response with language and images by learning the semantic correspondence between them while modelling long - term dialogue context."", ' #AUTHOR_TAG.', 'in contrast to standard sequenceto - sequence models  #TAUTHOR_TAG, hreds model the dialogue context by introducing a context recurrent neural network ( rnn ) over the encoder rnn, thus forming a hierarchical encoder.', 'we build on top of the hred architecture to include multimodality over multiple images.', 'a simple hred consists of three rnn modules : encoder, context and decoder.', 'in multimodal hred, we combine the output representations from the utterance encoder with concatenated multiple image representations and pass them as input to the context encoder ( see figure 2 ).', 'a dialogue is modelled as a sequence of utterances ( turns ), which in turn are modelled as sequences of words and images.', 'formally, a dialogue is generated according to the following :', 'where t n is the n - th utterance in a dialogue.', 'for each m = 1,..., m n, we have hidden states of each module defined as :', 'where f text θ, f cxt θ and f dec θ are gru cells  #TAUTHOR_TAG.', 'θ represent model parameters, w n, m is the m - th word in the n - th utterance and g enc θ is a convolutional neural']",5
['using grus  #TAUTHOR_TAG with tied embeddings for'],['the rnns using grus  #TAUTHOR_TAG with tied embeddings for'],"['use the pytorch 1 framework  #AUTHOR_TAG for our implementation.', '2 we used 512 as the word embedding size as well as hidden dimension for all the rnns using grus  #TAUTHOR_TAG with tied embeddings for']","['use the pytorch 1 framework  #AUTHOR_TAG for our implementation.', '2 we used 512 as the word embedding size as well as hidden dimension for all the rnns using grus  #TAUTHOR_TAG with tied embeddings for the ( bidirectional ) encoder and decoder.', 'the decoder uses luong - style attention mechanism  #AUTHOR_TAG with input feeding.', 'we trained our model with the adam optimizer  #AUTHOR_TAG, with a learning rate of 0. 0004 and clipping gradient norm over 5.', 'we perform early stopping by monitoring validation loss.', 'for image representations, we use the fc6 layer representations of the vgg - 19  #AUTHOR_TAG, pre - trained on imagenet.', '']",5
"['have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG']","['have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG']","['', 'recent studies on relation extraction have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'despite']","['', 'early work employed a diverse range of features in a linear classifier ( commonly referred to as "" feature - based "" approaches ), including lexical features, syntactic parse features, dependency features and semantic features  #AUTHOR_TAG.', 'these approaches were hindered by drawbacks such as limited feature space and excessive feature engineering.', 'kernel methods  #AUTHOR_TAG cristianini and shawe -  #AUTHOR_TAG on the other hand can explore a much larger feature space very efficiently.', 'recent studies on relation extraction have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'despite the large number of recently proposed kernels and their reported success, there lacks a clear understanding of their relative strength and weakness.', 'in this study, we provide a systematic comparison and analysis of three such kernels - subsequence kernel  #AUTHOR_TAG b ), dependency tree kernel  #AUTHOR_TAG and dependency path kernel  #TAUTHOR_TAG.', 'we replicated these kernels and conducted experiments on the standard ace 2003 news']",0
"['by  #TAUTHOR_TAG,']","['by  #TAUTHOR_TAG,']","['by  #TAUTHOR_TAG, they proposed a kernel']",[' #TAUTHOR_TAG'],0
['shortest path dependency kernel proposed by  #TAUTHOR_TAG also works with dependency parse'],"['shortest path dependency kernel proposed by  #TAUTHOR_TAG also works with dependency parse trees.', 'reuse our example in the previous section, the shortest']","['shortest path dependency kernel proposed by  #TAUTHOR_TAG also works with dependency parse trees.', 'reuse our example in the previous section,']","['shortest path dependency kernel proposed by  #TAUTHOR_TAG also works with dependency parse trees.', 'reuse our example in the previous section, the shortest dependency path between entity his and brcko in the first sentence is s = { his, prp, person }, { actions, nns, noun }, { in, in }, { brcko, nnp, noun, location } ; and the path between his and beijing in the second sentence is t = { his, prp, person }, { arrival, nn, noun }, { in, in }, { beijing, nnp, noun, location }.', 'since most dependency parser output connected trees, finding the shortest path between two nodes is trivial.', 'once the two paths are found, the kernel simply computes the product of the number of common features between a pair of nodes at each index along the path.', 'if the two paths have different number of nodes, the kernel assigns 0 ( no - match ) to the pair.', 'formally, the kernel is defined as']",0
"['have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG']","['have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG']","['', 'recent studies on relation extraction have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'despite']","['', 'early work employed a diverse range of features in a linear classifier ( commonly referred to as "" feature - based "" approaches ), including lexical features, syntactic parse features, dependency features and semantic features  #AUTHOR_TAG.', 'these approaches were hindered by drawbacks such as limited feature space and excessive feature engineering.', 'kernel methods  #AUTHOR_TAG cristianini and shawe -  #AUTHOR_TAG on the other hand can explore a much larger feature space very efficiently.', 'recent studies on relation extraction have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'despite the large number of recently proposed kernels and their reported success, there lacks a clear understanding of their relative strength and weakness.', 'in this study, we provide a systematic comparison and analysis of three such kernels - subsequence kernel  #AUTHOR_TAG b ), dependency tree kernel  #AUTHOR_TAG and dependency path kernel  #TAUTHOR_TAG.', 'we replicated these kernels and conducted experiments on the standard ace 2003 news']",1
"['have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG']","['have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG']","['', 'recent studies on relation extraction have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'despite']","['', 'early work employed a diverse range of features in a linear classifier ( commonly referred to as "" feature - based "" approaches ), including lexical features, syntactic parse features, dependency features and semantic features  #AUTHOR_TAG.', 'these approaches were hindered by drawbacks such as limited feature space and excessive feature engineering.', 'kernel methods  #AUTHOR_TAG cristianini and shawe -  #AUTHOR_TAG on the other hand can explore a much larger feature space very efficiently.', 'recent studies on relation extraction have shown that by combining kernels with support - vector machines ( svm ), one can obtain results superior to feature - based methods  #AUTHOR_TAG b ;  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'despite the large number of recently proposed kernels and their reported success, there lacks a clear understanding of their relative strength and weakness.', 'in this study, we provide a systematic comparison and analysis of three such kernels - subsequence kernel  #AUTHOR_TAG b ), dependency tree kernel  #AUTHOR_TAG and dependency path kernel  #TAUTHOR_TAG.', 'we replicated these kernels and conducted experiments on the standard ace 2003 news']",5
['kernel  #AUTHOR_TAG and shortest path dependency kernel  #TAUTHOR_TAG'],['kernel  #AUTHOR_TAG and shortest path dependency kernel  #TAUTHOR_TAG'],"['this section we first give a very brief introduction to kernel methods.', 'we then present the algorithms behind three kernels that we are particularly interested in : subsequence kernel  #AUTHOR_TAG b ), dependency tree kernel  #AUTHOR_TAG and shortest path dependency kernel  #TAUTHOR_TAG']","['this section we first give a very brief introduction to kernel methods.', 'we then present the algorithms behind three kernels that we are particularly interested in : subsequence kernel  #AUTHOR_TAG b ), dependency tree kernel  #AUTHOR_TAG and shortest path dependency kernel  #TAUTHOR_TAG']",5
"[', but it can often bring complementary information  #TAUTHOR_TAG']","['more difficult, compared to the sentiment analysis, but it can often bring complementary information  #TAUTHOR_TAG']","['more difficult, compared to the sentiment analysis, but it can often bring complementary information  #TAUTHOR_TAG.', 'there are many applications which could benefit from the automatic stance detection, including information retrieval,']","['detection has been defined as automatically detecting whether the author of a piece of text is in favor of the given target or against it.', 'in the third class, there are the cases, in which neither inference is likely.', 'it can be viewed as a subtask of opinion mining and it stands next to the sentiment analysis.', 'the significant difference is that in sentiment analysis, systems determine whether a piece of text is positive, negative, or neutral.', ""however, in stance detection, systems are to determine author's favorability towards a given target and the target even may not be explicitly mentioned in the text."", 'moreover, the text may express positive opinion about an entity contained in the text, but one can also infer that the author is against the defined target ( an entity or a topic ).', 'this makes the task more difficult, compared to the sentiment analysis, but it can often bring complementary information  #TAUTHOR_TAG.', 'there are many applications which could benefit from the automatic stance detection, including information retrieval, textual entailment, or text summarization, in particular opinion summarization']",0
"['original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover,']","['original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover,']","['as in the original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover, we stemmed the texts by hps - high precision stemmer [ 2 ].', 'the system is based']","['preprocessed the czech commentaries by the same rules as in the original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover, we stemmed the texts by hps - high precision stemmer [ 2 ].', 'the system is based on a standard maximum entropy classifier [ 4 ], trained separately for each topic, with the following features.', 'it has been showed that unigrams perform quite well in this task [ 6 ].', 'our model is based on tf - idf and uses the top 1000 words from the vocabulary.', 'the rest of the features can be turned on or off for each topic.', 'initial n - grams 4, as showed in [ 1 ] can be useful features.', 'out system supports initial unigrams to initial trigrams.', 'another surface feature was the comment length in words after preprocessing.', '']",5
"['original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover,']","['original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover,']","['as in the original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover, we stemmed the texts by hps - high precision stemmer [ 2 ].', 'the system is based']","['preprocessed the czech commentaries by the same rules as in the original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover, we stemmed the texts by hps - high precision stemmer [ 2 ].', 'the system is based on a standard maximum entropy classifier [ 4 ], trained separately for each topic, with the following features.', 'it has been showed that unigrams perform quite well in this task [ 6 ].', 'our model is based on tf - idf and uses the top 1000 words from the vocabulary.', 'the rest of the features can be turned on or off for each topic.', 'initial n - grams 4, as showed in [ 1 ] can be useful features.', 'out system supports initial unigrams to initial trigrams.', 'another surface feature was the comment length in words after preprocessing.', '']",4
"['original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover,']","['original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover,']","['as in the original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover, we stemmed the texts by hps - high precision stemmer [ 2 ].', 'the system is based']","['preprocessed the czech commentaries by the same rules as in the original system  #TAUTHOR_TAG ( for example : all urls were replaced by keyword url, links to images are replaced by imgurl, only letters are preserved, the rest of the characters is removed, [UNK] ).', 'moreover, we stemmed the texts by hps - high precision stemmer [ 2 ].', 'the system is based on a standard maximum entropy classifier [ 4 ], trained separately for each topic, with the following features.', 'it has been showed that unigrams perform quite well in this task [ 6 ].', 'our model is based on tf - idf and uses the top 1000 words from the vocabulary.', 'the rest of the features can be turned on or off for each topic.', 'initial n - grams 4, as showed in [ 1 ] can be useful features.', 'out system supports initial unigrams to initial trigrams.', 'another surface feature was the comment length in words after preprocessing.', '']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG bypassed this'],"['', 'previous approaches  #TAUTHOR_TAG bypassed this problem by']",[' #TAUTHOR_TAG'],0
"['.', 'since then, it has gain popularity  #TAUTHOR_TAG.', 'to tolerate noisy labels in positive examples,  #AUTHOR_TAG use multiple']","['biomedical domain.', 'since then, it has gain popularity  #TAUTHOR_TAG.', 'to tolerate noisy labels in positive examples,  #AUTHOR_TAG use multiple']","['', 'since then, it has gain popularity  #TAUTHOR_TAG.', 'to tolerate noisy labels in positive examples,  #AUTHOR_TAG use multiple instance learning ( mil ),']","['supervision was first proposed by  #AUTHOR_TAG in the biomedical domain.', 'since then, it has gain popularity  #TAUTHOR_TAG.', 'to tolerate noisy labels in positive examples,  #AUTHOR_TAG use multiple instance learning ( mil ), which assumes only at - least - one of the relation mentions in each "" bag "" of mentions sharing a pair of argument entities which bears a relation, indeed expresses the target relation.', 'multir  #AUTHOR_TAG and multi - instance multi - label ( miml ) learning  #TAUTHOR_TAG further improve it to support multiple relations expressed by different sentences in a bag.', ' #AUTHOR_TAG models the probabilities of a pattern showing relations, estimated from the heuristically labeled dataset.', 'their algorithm removes mentions that match lowprobability patterns.', ' #AUTHOR_TAG and  #AUTHOR_TAG b ) also estimate the probablities of patterns showing relations, but instead use them to relabel examples to their most likely classes.', 'their approach can correct highly - confident false negative matches']",0
"['.', 'since then, it has gain popularity  #TAUTHOR_TAG.', 'to tolerate noisy labels in positive examples,  #AUTHOR_TAG use multiple']","['biomedical domain.', 'since then, it has gain popularity  #TAUTHOR_TAG.', 'to tolerate noisy labels in positive examples,  #AUTHOR_TAG use multiple']","['', 'since then, it has gain popularity  #TAUTHOR_TAG.', 'to tolerate noisy labels in positive examples,  #AUTHOR_TAG use multiple instance learning ( mil ),']","['supervision was first proposed by  #AUTHOR_TAG in the biomedical domain.', 'since then, it has gain popularity  #TAUTHOR_TAG.', 'to tolerate noisy labels in positive examples,  #AUTHOR_TAG use multiple instance learning ( mil ), which assumes only at - least - one of the relation mentions in each "" bag "" of mentions sharing a pair of argument entities which bears a relation, indeed expresses the target relation.', 'multir  #AUTHOR_TAG and multi - instance multi - label ( miml ) learning  #TAUTHOR_TAG further improve it to support multiple relations expressed by different sentences in a bag.', ' #AUTHOR_TAG models the probabilities of a pattern showing relations, estimated from the heuristically labeled dataset.', 'their algorithm removes mentions that match lowprobability patterns.', ' #AUTHOR_TAG and  #AUTHOR_TAG b ) also estimate the probablities of patterns showing relations, but instead use them to relabel examples to their most likely classes.', 'their approach can correct highly - confident false negative matches']",0
"['from the previous iteration.', 'after fixed [UNK], we seek to maximize :', 'which can be solved with an approximate solution in  #TAUTHOR_TAG ( step 9 - 11 ) : update z i independently with :', 'more details can be found in  #TAUTHOR_TAG.', 'in the m - step, we retrain both of the mentionlevel and the']","['from the previous iteration.', 'after fixed [UNK], we seek to maximize :', 'which can be solved with an approximate solution in  #TAUTHOR_TAG ( step 9 - 11 ) : update z i independently with :', 'more details can be found in  #TAUTHOR_TAG.', 'in the m - step, we retrain both of the mentionlevel and the']","['from the previous iteration.', 'after fixed [UNK], we seek to maximize :', 'which can be solved with an approximate solution in  #TAUTHOR_TAG ( step 9 - 11 ) : update z i independently with :', 'more details can be found in  #TAUTHOR_TAG.', 'in the m - step, we retrain both of the mentionlevel and the aggregation level classifiers.', 'the full em algorithm is shown in algorithm 1']","['', 'for all ror do in the e - step, we do a greedy search ( steps 5 - 8 in algorithm 1 ) in all p ( [UNK] r i | x i ; w z, w [UNK] ) and update [UNK] r i until the second term is maximized.', 'w z, w [UNK] are the model weights learned from the previous iteration.', 'after fixed [UNK], we seek to maximize :', 'which can be solved with an approximate solution in  #TAUTHOR_TAG ( step 9 - 11 ) : update z i independently with :', 'more details can be found in  #TAUTHOR_TAG.', 'in the m - step, we retrain both of the mentionlevel and the aggregation level classifiers.', 'the full em algorithm is shown in algorithm 1']",0
"['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly,']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is']","['set : we use the kbp  #AUTHOR_TAG dataset 9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is the only dataset that has associated human - labeled ground truth.', 'any kb held - out evaluation without manual assessment will be significantly affected by kb incompleteness.', 'in kbp dataset, the training bags are generated by mapping wikipedia ( http : / / en. wikipedia. org ) infoboxes ( after merging similar types following the kbp 2011 task definition ) into a large unlabeled corpus ( consisting of 1. 5m documents from the kbp source corpus and a complete snapshot of wikipedia ).', 'the kbp shared task provided 200 query named entities with their associated slot values ( in total several thousand pairs ).', 'we use 40 queries as development dataset ( dev ), and the rest ( 160 queries ) as evaluation dataset.', 'we set θ = 0. 25 by tuning on the dev set and use it in the experiments.', 'for a fair comparison, we follow  #TAUTHOR_TAG and begin by downsampling the "" negative "" class to 5 %.', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG bypassed this'],"['', 'previous approaches  #TAUTHOR_TAG bypassed this problem by']",[' #TAUTHOR_TAG'],4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG bypassed this'],"['', 'previous approaches  #TAUTHOR_TAG bypassed this problem by']",[' #TAUTHOR_TAG'],6
"['( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['multi - instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ), we add a set of latent variables [UNK] which', 'models the true bag - level labels, to bridge the observed bag labels y and the miml layers. we consider this as our main', 'contribution to the model. our hierarchical model is shown in figure 1. ij | x ij ; w z ) and multi -', 'instance multi - label aggregation p ( [UNK] r i | z i', '; w r [UNK] ) in the bottom 3 layers. we define : • r is a relation label. ror ∪ { ot her }, in which other denotes no relation expressed. • y r i o { p, u } : r holds for ith bag or the bag is unlabeled. 6 we use the term semi - supervised because the algorithm uses', 'unlabeled bags but existing solutions requires bags to be labeled either positive or negative. • [UNK] r i o { p, n } : a hidden variable that denotes whether r holds for the ith bag. • θ is an observed constant controlling the total number of bags whose latent label is positive.', 'we define the following conditional probabilities : otherwise ; it encodes', 'the constraints between true baglevel labels and the entity pair labels in the kb. k ) where δ ( x, y ) = 1 if x = y, 0 otherwise. k is a large number. θ is the', 'fraction of the', 'bags that are positive. it is', 'an observed parameter that depends on both the source corpus and the kb used. similar', 'to  #TAUTHOR_TAG : • z ij or ∪ { ot her } : a latent variable that denotes the relation type of', 'the jth mention in the ith bag. • x ij is the feature representation of the jth relation mention in the ith bag. we use', 'the set of features in  #TAUTHOR_TAG. • w z is the weight vector for the multi - class relation mention - level classifier', '. • w r [UNK] is the weight vector for the rth binary toplevel aggregation classifier', '( from mention labels to bag -', 'level prediction ). we use w [UNK] to rep - where f [UNK] is probability produced by the rt', '##h top - level classifier, from the mention - label level to the baglabel level. • p ( z r ij |', 'x ij ; w z ) ∼ multi ( f z', '( w z, x ij ) ) where f z is probability produced by the mention', '- level classifier,', 'from the mentions to the mentionlabel level.']",6
"[' #TAUTHOR_TAG generated by ds, and we manually annotate']","[' #TAUTHOR_TAG generated by ds, and we manually annotate']","[' #TAUTHOR_TAG generated by ds, and we manually annotate all relation mentions in these bags.', 'the result is shown in']","['', 'we further investigate the rate of false negative matches, as the percentage of entity - pairs that are not listed in freebase but one of its mentions generated by ds does express a relation in the target set of types.', 'we randomly picked 200 unlabeled bags 5 from each of the two datasets  #TAUTHOR_TAG generated by ds, and we manually annotate all relation mentions in these bags.', 'the result is shown in table 2, along with a few examples that indicate a relation holds in the set of false negative matches ( bag - level ).', 'both datasets have around 10 % false negative matches in the unlabeled set of bags.', 'taking into consideration that the number of positive bags and unlabeled bags are highly imbalanced ( 1 : 134 and 1 : 37 in the riedel and kbp dataset respectively, before undersampling the unlabeled class ), the number of false negative matches are 11 and 4 times the number of positive bags in reidel and kbp dataset, respectively.', 'such a large ratio shows false negatives do have a significant impact on the learning process']",5
"['( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['multi - instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ), we add a set of latent variables [UNK] which', 'models the true bag - level labels, to bridge the observed bag labels y and the miml layers. we consider this as our main', 'contribution to the model. our hierarchical model is shown in figure 1. ij | x ij ; w z ) and multi -', 'instance multi - label aggregation p ( [UNK] r i | z i', '; w r [UNK] ) in the bottom 3 layers. we define : • r is a relation label. ror ∪ { ot her }, in which other denotes no relation expressed. • y r i o { p, u } : r holds for ith bag or the bag is unlabeled. 6 we use the term semi - supervised because the algorithm uses', 'unlabeled bags but existing solutions requires bags to be labeled either positive or negative. • [UNK] r i o { p, n } : a hidden variable that denotes whether r holds for the ith bag. • θ is an observed constant controlling the total number of bags whose latent label is positive.', 'we define the following conditional probabilities : otherwise ; it encodes', 'the constraints between true baglevel labels and the entity pair labels in the kb. k ) where δ ( x, y ) = 1 if x = y, 0 otherwise. k is a large number. θ is the', 'fraction of the', 'bags that are positive. it is', 'an observed parameter that depends on both the source corpus and the kb used. similar', 'to  #TAUTHOR_TAG : • z ij or ∪ { ot her } : a latent variable that denotes the relation type of', 'the jth mention in the ith bag. • x ij is the feature representation of the jth relation mention in the ith bag. we use', 'the set of features in  #TAUTHOR_TAG. • w z is the weight vector for the multi - class relation mention - level classifier', '. • w r [UNK] is the weight vector for the rth binary toplevel aggregation classifier', '( from mention labels to bag -', 'level prediction ). we use w [UNK] to rep - where f [UNK] is probability produced by the rt', '##h top - level classifier, from the mention - label level to the baglabel level. • p ( z r ij |', 'x ij ; w z ) ∼ multi ( f z', '( w z, x ij ) ) where f z is probability produced by the mention', '- level classifier,', 'from the mentions to the mentionlabel level.']",5
"['( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['multi - instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ), we add a set of latent variables [UNK] which', 'models the true bag - level labels, to bridge the observed bag labels y and the miml layers. we consider this as our main', 'contribution to the model. our hierarchical model is shown in figure 1. ij | x ij ; w z ) and multi -', 'instance multi - label aggregation p ( [UNK] r i | z i', '; w r [UNK] ) in the bottom 3 layers. we define : • r is a relation label. ror ∪ { ot her }, in which other denotes no relation expressed. • y r i o { p, u } : r holds for ith bag or the bag is unlabeled. 6 we use the term semi - supervised because the algorithm uses', 'unlabeled bags but existing solutions requires bags to be labeled either positive or negative. • [UNK] r i o { p, n } : a hidden variable that denotes whether r holds for the ith bag. • θ is an observed constant controlling the total number of bags whose latent label is positive.', 'we define the following conditional probabilities : otherwise ; it encodes', 'the constraints between true baglevel labels and the entity pair labels in the kb. k ) where δ ( x, y ) = 1 if x = y, 0 otherwise. k is a large number. θ is the', 'fraction of the', 'bags that are positive. it is', 'an observed parameter that depends on both the source corpus and the kb used. similar', 'to  #TAUTHOR_TAG : • z ij or ∪ { ot her } : a latent variable that denotes the relation type of', 'the jth mention in the ith bag. • x ij is the feature representation of the jth relation mention in the ith bag. we use', 'the set of features in  #TAUTHOR_TAG. • w z is the weight vector for the multi - class relation mention - level classifier', '. • w r [UNK] is the weight vector for the rth binary toplevel aggregation classifier', '( from mention labels to bag -', 'level prediction ). we use w [UNK] to rep - where f [UNK] is probability produced by the rt', '##h top - level classifier, from the mention - label level to the baglabel level. • p ( z r ij |', 'x ij ; w z ) ∼ multi ( f z', '( w z, x ij ) ) where f z is probability produced by the mention', '- level classifier,', 'from the mentions to the mentionlabel level.']",5
"['( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['multi - instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ), we add a set of latent variables [UNK] which', 'models the true bag - level labels, to bridge the observed bag labels y and the miml layers. we consider this as our main', 'contribution to the model. our hierarchical model is shown in figure 1. ij | x ij ; w z ) and multi -', 'instance multi - label aggregation p ( [UNK] r i | z i', '; w r [UNK] ) in the bottom 3 layers. we define : • r is a relation label. ror ∪ { ot her }, in which other denotes no relation expressed. • y r i o { p, u } : r holds for ith bag or the bag is unlabeled. 6 we use the term semi - supervised because the algorithm uses', 'unlabeled bags but existing solutions requires bags to be labeled either positive or negative. • [UNK] r i o { p, n } : a hidden variable that denotes whether r holds for the ith bag. • θ is an observed constant controlling the total number of bags whose latent label is positive.', 'we define the following conditional probabilities : otherwise ; it encodes', 'the constraints between true baglevel labels and the entity pair labels in the kb. k ) where δ ( x, y ) = 1 if x = y, 0 otherwise. k is a large number. θ is the', 'fraction of the', 'bags that are positive. it is', 'an observed parameter that depends on both the source corpus and the kb used. similar', 'to  #TAUTHOR_TAG : • z ij or ∪ { ot her } : a latent variable that denotes the relation type of', 'the jth mention in the ith bag. • x ij is the feature representation of the jth relation mention in the ith bag. we use', 'the set of features in  #TAUTHOR_TAG. • w z is the weight vector for the multi - class relation mention - level classifier', '. • w r [UNK] is the weight vector for the rth binary toplevel aggregation classifier', '( from mention labels to bag -', 'level prediction ). we use w [UNK] to rep - where f [UNK] is probability produced by the rt', '##h top - level classifier, from the mention - label level to the baglabel level. • p ( z r ij |', 'x ij ; w z ) ∼ multi ( f z', '( w z, x ij ) ) where f z is probability produced by the mention', '- level classifier,', 'from the mentions to the mentionlabel level.']",5
"['from the previous iteration.', 'after fixed [UNK], we seek to maximize :', 'which can be solved with an approximate solution in  #TAUTHOR_TAG ( step 9 - 11 ) : update z i independently with :', 'more details can be found in  #TAUTHOR_TAG.', 'in the m - step, we retrain both of the mentionlevel and the']","['from the previous iteration.', 'after fixed [UNK], we seek to maximize :', 'which can be solved with an approximate solution in  #TAUTHOR_TAG ( step 9 - 11 ) : update z i independently with :', 'more details can be found in  #TAUTHOR_TAG.', 'in the m - step, we retrain both of the mentionlevel and the']","['from the previous iteration.', 'after fixed [UNK], we seek to maximize :', 'which can be solved with an approximate solution in  #TAUTHOR_TAG ( step 9 - 11 ) : update z i independently with :', 'more details can be found in  #TAUTHOR_TAG.', 'in the m - step, we retrain both of the mentionlevel and the aggregation level classifiers.', 'the full em algorithm is shown in algorithm 1']","['', 'for all ror do in the e - step, we do a greedy search ( steps 5 - 8 in algorithm 1 ) in all p ( [UNK] r i | x i ; w z, w [UNK] ) and update [UNK] r i until the second term is maximized.', 'w z, w [UNK] are the model weights learned from the previous iteration.', 'after fixed [UNK], we seek to maximize :', 'which can be solved with an approximate solution in  #TAUTHOR_TAG ( step 9 - 11 ) : update z i independently with :', 'more details can be found in  #TAUTHOR_TAG.', 'in the m - step, we retrain both of the mentionlevel and the aggregation level classifiers.', 'the full em algorithm is shown in algorithm 1']",5
"[' #TAUTHOR_TAG code base.', '8']","['implement our model on top of the miml  #TAUTHOR_TAG code base.', '8']","['implement our model on top of the miml  #TAUTHOR_TAG code base.', '8 we use the']","['implement our model on top of the miml  #TAUTHOR_TAG code base.', '8 we use the same mention - level and aggregate - level feature sets as  #TAUTHOR_TAG.', 'we adopt the same idea of using cross validation for the e and m steps to avoid overfitting.', 'we initialize our algorithm by sampling 5 % unlabeled examples as negative, in essence using 1 epoch of miml to initialize.', 'empirically it performs well']",5
"[' #TAUTHOR_TAG code base.', '8']","['implement our model on top of the miml  #TAUTHOR_TAG code base.', '8']","['implement our model on top of the miml  #TAUTHOR_TAG code base.', '8 we use the']","['implement our model on top of the miml  #TAUTHOR_TAG code base.', '8 we use the same mention - level and aggregate - level feature sets as  #TAUTHOR_TAG.', 'we adopt the same idea of using cross validation for the e and m steps to avoid overfitting.', 'we initialize our algorithm by sampling 5 % unlabeled examples as negative, in essence using 1 epoch of miml to initialize.', 'empirically it performs well']",5
"['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly,']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is']","['set : we use the kbp  #AUTHOR_TAG dataset 9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is the only dataset that has associated human - labeled ground truth.', 'any kb held - out evaluation without manual assessment will be significantly affected by kb incompleteness.', 'in kbp dataset, the training bags are generated by mapping wikipedia ( http : / / en. wikipedia. org ) infoboxes ( after merging similar types following the kbp 2011 task definition ) into a large unlabeled corpus ( consisting of 1. 5m documents from the kbp source corpus and a complete snapshot of wikipedia ).', 'the kbp shared task provided 200 query named entities with their associated slot values ( in total several thousand pairs ).', 'we use 40 queries as development dataset ( dev ), and the rest ( 160 queries ) as evaluation dataset.', 'we set θ = 0. 25 by tuning on the dev set and use it in the experiments.', 'for a fair comparison, we follow  #TAUTHOR_TAG and begin by downsampling the "" negative "" class to 5 %.', '']",5
"['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly,']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is']","['set : we use the kbp  #AUTHOR_TAG dataset 9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is the only dataset that has associated human - labeled ground truth.', 'any kb held - out evaluation without manual assessment will be significantly affected by kb incompleteness.', 'in kbp dataset, the training bags are generated by mapping wikipedia ( http : / / en. wikipedia. org ) infoboxes ( after merging similar types following the kbp 2011 task definition ) into a large unlabeled corpus ( consisting of 1. 5m documents from the kbp source corpus and a complete snapshot of wikipedia ).', 'the kbp shared task provided 200 query named entities with their associated slot values ( in total several thousand pairs ).', 'we use 40 queries as development dataset ( dev ), and the rest ( 160 queries ) as evaluation dataset.', 'we set θ = 0. 25 by tuning on the dev set and use it in the experiments.', 'for a fair comparison, we follow  #TAUTHOR_TAG and begin by downsampling the "" negative "" class to 5 %.', '']",5
"['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly,']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is']","['set : we use the kbp  #AUTHOR_TAG dataset 9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is the only dataset that has associated human - labeled ground truth.', 'any kb held - out evaluation without manual assessment will be significantly affected by kb incompleteness.', 'in kbp dataset, the training bags are generated by mapping wikipedia ( http : / / en. wikipedia. org ) infoboxes ( after merging similar types following the kbp 2011 task definition ) into a large unlabeled corpus ( consisting of 1. 5m documents from the kbp source corpus and a complete snapshot of wikipedia ).', 'the kbp shared task provided 200 query named entities with their associated slot values ( in total several thousand pairs ).', 'we use 40 queries as development dataset ( dev ), and the rest ( 160 queries ) as evaluation dataset.', 'we set θ = 0. 25 by tuning on the dev set and use it in the experiments.', 'for a fair comparison, we follow  #TAUTHOR_TAG and begin by downsampling the "" negative "" class to 5 %.', '']",5
"['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly,']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is']","['set : we use the kbp  #AUTHOR_TAG dataset 9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is the only dataset that has associated human - labeled ground truth.', 'any kb held - out evaluation without manual assessment will be significantly affected by kb incompleteness.', 'in kbp dataset, the training bags are generated by mapping wikipedia ( http : / / en. wikipedia. org ) infoboxes ( after merging similar types following the kbp 2011 task definition ) into a large unlabeled corpus ( consisting of 1. 5m documents from the kbp source corpus and a complete snapshot of wikipedia ).', 'the kbp shared task provided 200 query named entities with their associated slot values ( in total several thousand pairs ).', 'we use 40 queries as development dataset ( dev ), and the rest ( 160 queries ) as evaluation dataset.', 'we set θ = 0. 25 by tuning on the dev set and use it in the experiments.', 'for a fair comparison, we follow  #TAUTHOR_TAG and begin by downsampling the "" negative "" class to 5 %.', '']",5
"['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly,']","['9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is']","['set : we use the kbp  #AUTHOR_TAG dataset 9 prepared and publicly released by  #TAUTHOR_TAG for our experiment since it is 1 ) large and realistic, 2 ) publicly available, 3 ) most importantly, it is the only dataset that has associated human - labeled ground truth.', 'any kb held - out evaluation without manual assessment will be significantly affected by kb incompleteness.', 'in kbp dataset, the training bags are generated by mapping wikipedia ( http : / / en. wikipedia. org ) infoboxes ( after merging similar types following the kbp 2011 task definition ) into a large unlabeled corpus ( consisting of 1. 5m documents from the kbp source corpus and a complete snapshot of wikipedia ).', 'the kbp shared task provided 200 query named entities with their associated slot values ( in total several thousand pairs ).', 'we use 40 queries as development dataset ( dev ), and the rest ( 160 queries ) as evaluation dataset.', 'we set θ = 0. 25 by tuning on the dev set and use it in the experiments.', 'for a fair comparison, we follow  #TAUTHOR_TAG and begin by downsampling the "" negative "" class to 5 %.', '']",5
"['( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ),']","['multi - instance multi - label ( miml ) model  #TAUTHOR_TAG. since the input to previous miml models are bags with perrelation binary labels of either positive ( p ) or negative (', 'n ), we add a set of latent variables [UNK] which', 'models the true bag - level labels, to bridge the observed bag labels y and the miml layers. we consider this as our main', 'contribution to the model. our hierarchical model is shown in figure 1. ij | x ij ; w z ) and multi -', 'instance multi - label aggregation p ( [UNK] r i | z i', '; w r [UNK] ) in the bottom 3 layers. we define : • r is a relation label. ror ∪ { ot her }, in which other denotes no relation expressed. • y r i o { p, u } : r holds for ith bag or the bag is unlabeled. 6 we use the term semi - supervised because the algorithm uses', 'unlabeled bags but existing solutions requires bags to be labeled either positive or negative. • [UNK] r i o { p, n } : a hidden variable that denotes whether r holds for the ith bag. • θ is an observed constant controlling the total number of bags whose latent label is positive.', 'we define the following conditional probabilities : otherwise ; it encodes', 'the constraints between true baglevel labels and the entity pair labels in the kb. k ) where δ ( x, y ) = 1 if x = y, 0 otherwise. k is a large number. θ is the', 'fraction of the', 'bags that are positive. it is', 'an observed parameter that depends on both the source corpus and the kb used. similar', 'to  #TAUTHOR_TAG : • z ij or ∪ { ot her } : a latent variable that denotes the relation type of', 'the jth mention in the ith bag. • x ij is the feature representation of the jth relation mention in the ith bag. we use', 'the set of features in  #TAUTHOR_TAG. • w z is the weight vector for the multi - class relation mention - level classifier', '. • w r [UNK] is the weight vector for the rth binary toplevel aggregation classifier', '( from mention labels to bag -', 'level prediction ). we use w [UNK] to rep - where f [UNK] is probability produced by the rt', '##h top - level classifier, from the mention - label level to the baglabel level. • p ( z r ij |', 'x ij ; w z ) ∼ multi ( f z', '( w z, x ij ) ) where f z is probability produced by the mention', '- level classifier,', 'from the mentions to the mentionlabel level.']",3
"[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","['', '- to - end machinetranslation ( sutskerev,  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG, image and video captioning  #AUTHOR_TAG', ', unsupervised learning of document representations by autoencoders  #AUTHOR_TAG. these recent deep learning breakthroughs along with massively parallel gpu computing allow addressing the media monitoring tasks in the completely new end - toend manner rather than relying on the legacy nlp pipelines. the novelty of the summa project approach is that all languages covered by the project ( table 1 ) can be embedded in the same vectorspace', 'by means of joint multitask learning  #AUTHOR_TAG of eight lstm - rnn translational autoencoders with hidden layer parameters shared as illustrated in fig. 2. sharing the same', 'vectorspace for sentences in all project languages enables accurate multilingual news story clustering without resorting to the clustering of the less accurate target ( english ) language machine translations. this shared vectorspace approach extends also to the unsupervised multi - task learning of language models from the large monolingual corpora ( fig. 3 ), which is crucial for low - resource', '##d languages : having a generic language model learned in parallel from the monolingual corpora reduces  #AUTHOR_TAG', 'the need for large supervised parallel corpora to achieve the same translational accuracy for the fig. 2 setup. the joint training of seventeen translational and samelanguage autoencoders with shared parameters ( fig. 2 and fig. 3 together ) to our knowledge has not been attempted so far. even training of a single state - of - the - art sentencelevel translational autoencoder requires days of gpu computing  #AUTHOR_TAG ) in tensorflow  #AUTHOR_TAG seq2seq model ( sutskerev,  #TAUTHOR_TAG. to', 'avoid complexities of asynchronous parallel training with shared parameter server  #AUTHOR_TAG, the architecture in fig. 2 and fig. 3 instead can be trained using the alternating training approach proposed in  #AUTHOR_TAG, where each task is optimized for a fixed number of parameter updates ( or mini - batches ) before switching to the next task ( which is a', 'different language pair ). although such alternating approach prolongs the training process, it is preferred for simplicity and robustness reasons. once', 'produced within summa project, these translational autoencoders with shared vectorspace will be a unique language resource of likely interest also to the wider nlp community for multilingual applications outside the media monitoring domain']",5
"[',  #TAUTHOR_TAG neural translation model.', '']","[' #AUTHOR_TAG seq2seq ( sutskerev,  #TAUTHOR_TAG neural translation model.', '']","[',  #TAUTHOR_TAG neural translation model.', 'the character - level neural translation is enabled by forcing tokenizer to treat each input symbol as a separate "" word "" leading to']","['translation attention mechanism  #AUTHOR_TAG has been shown to be highly beneficial for bi - lingual neural translation of long sentences, but it is not compatible with the multi - task multilingual translation models  #AUTHOR_TAG described in the previous section and character - level translation models  #AUTHOR_TAG described in this section.', 'for these reasons we replace the neural translation attention mechanism with much simpler sliding - window translation  #AUTHOR_TAG.', 'moving from wordlevel to character - level neural translation makes it even harder to cope with long sentences presenting additional reason to employ the sliding - window translation approach.', 'table 2 illustrates the character - level neural translation from english to latvian using modified 2 tensorflow  #AUTHOR_TAG seq2seq ( sutskerev,  #TAUTHOR_TAG neural translation model.', 'the character - level neural translation is enabled by forcing tokenizer to treat each input symbol as a separate "" word "" leading to the small and fixed "" vocabulary "" containing only 90 most frequently encountered characters.', 'another necessary change to the tensorflow default seq2seq settings is disabling the attention  #AUTHOR_TAG mechanism which is known to interfere with character - level translation  #AUTHOR_TAG because there are no mappings between the characters of the translated words.', 'the small vocabulary of 90 words automatically disables also the sampled softmax functionality of seq2seq improving the overall performance.', 'finally, we configure single bucket of size 100 characters, which will be the max translation window size.', 'other hyperparameters used are : 1 lstm 2 https : / / github. com / didzis / tensorflowamr layer of size 400, batch size 16.', 'training is performed on europarl v7 en - lv corpus 3 for 24h on titanx gpu.', 'the sliding - window mechanism is used only during decoding ( translation ), mapping a fragment of 6 english words into 5 latvian words ( latvian translations typically contain less words than english source - rich morphology substitutes for most prepositions and articles ).', 'the multiple sliding - window translations produced are later merged into the final translation consisting only of words appearing at least twice in the neighboring sliding window columns ( word suffixes are ignored if the initial 6 characters of the words match - this reduces word drop due to inflection errors ).', 'the final translation in table 2 ( bottom row ) is close to the manual verbatim translation ( top row ) and conveys the topic of the original sentence.', 'moreover, the slidingwindow translations are surprisingly fluent latvian phrases with correct word forms and mostly correct coordination.', 'the only non - latvian "" words "" fabricated by the characterlevel translation in the table 2 are "" transpa']",5
"[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","['', '- to - end machinetranslation ( sutskerev,  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG, image and video captioning  #AUTHOR_TAG', ', unsupervised learning of document representations by autoencoders  #AUTHOR_TAG. these recent deep learning breakthroughs along with massively parallel gpu computing allow addressing the media monitoring tasks in the completely new end - toend manner rather than relying on the legacy nlp pipelines. the novelty of the summa project approach is that all languages covered by the project ( table 1 ) can be embedded in the same vectorspace', 'by means of joint multitask learning  #AUTHOR_TAG of eight lstm - rnn translational autoencoders with hidden layer parameters shared as illustrated in fig. 2. sharing the same', 'vectorspace for sentences in all project languages enables accurate multilingual news story clustering without resorting to the clustering of the less accurate target ( english ) language machine translations. this shared vectorspace approach extends also to the unsupervised multi - task learning of language models from the large monolingual corpora ( fig. 3 ), which is crucial for low - resource', '##d languages : having a generic language model learned in parallel from the monolingual corpora reduces  #AUTHOR_TAG', 'the need for large supervised parallel corpora to achieve the same translational accuracy for the fig. 2 setup. the joint training of seventeen translational and samelanguage autoencoders with shared parameters ( fig. 2 and fig. 3 together ) to our knowledge has not been attempted so far. even training of a single state - of - the - art sentencelevel translational autoencoder requires days of gpu computing  #AUTHOR_TAG ) in tensorflow  #AUTHOR_TAG seq2seq model ( sutskerev,  #TAUTHOR_TAG. to', 'avoid complexities of asynchronous parallel training with shared parameter server  #AUTHOR_TAG, the architecture in fig. 2 and fig. 3 instead can be trained using the alternating training approach proposed in  #AUTHOR_TAG, where each task is optimized for a fixed number of parameter updates ( or mini - batches ) before switching to the next task ( which is a', 'different language pair ). although such alternating approach prolongs the training process, it is preferred for simplicity and robustness reasons. once', 'produced within summa project, these translational autoencoders with shared vectorspace will be a unique language resource of likely interest also to the wider nlp community for multilingual applications outside the media monitoring domain']",0
"[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","['', '- to - end machinetranslation ( sutskerev,  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG, image and video captioning  #AUTHOR_TAG', ', unsupervised learning of document representations by autoencoders  #AUTHOR_TAG. these recent deep learning breakthroughs along with massively parallel gpu computing allow addressing the media monitoring tasks in the completely new end - toend manner rather than relying on the legacy nlp pipelines. the novelty of the summa project approach is that all languages covered by the project ( table 1 ) can be embedded in the same vectorspace', 'by means of joint multitask learning  #AUTHOR_TAG of eight lstm - rnn translational autoencoders with hidden layer parameters shared as illustrated in fig. 2. sharing the same', 'vectorspace for sentences in all project languages enables accurate multilingual news story clustering without resorting to the clustering of the less accurate target ( english ) language machine translations. this shared vectorspace approach extends also to the unsupervised multi - task learning of language models from the large monolingual corpora ( fig. 3 ), which is crucial for low - resource', '##d languages : having a generic language model learned in parallel from the monolingual corpora reduces  #AUTHOR_TAG', 'the need for large supervised parallel corpora to achieve the same translational accuracy for the fig. 2 setup. the joint training of seventeen translational and samelanguage autoencoders with shared parameters ( fig. 2 and fig. 3 together ) to our knowledge has not been attempted so far. even training of a single state - of - the - art sentencelevel translational autoencoder requires days of gpu computing  #AUTHOR_TAG ) in tensorflow  #AUTHOR_TAG seq2seq model ( sutskerev,  #TAUTHOR_TAG. to', 'avoid complexities of asynchronous parallel training with shared parameter server  #AUTHOR_TAG, the architecture in fig. 2 and fig. 3 instead can be trained using the alternating training approach proposed in  #AUTHOR_TAG, where each task is optimized for a fixed number of parameter updates ( or mini - batches ) before switching to the next task ( which is a', 'different language pair ). although such alternating approach prolongs the training process, it is preferred for simplicity and robustness reasons. once', 'produced within summa project, these translational autoencoders with shared vectorspace will be a unique language resource of likely interest also to the wider nlp community for multilingual applications outside the media monitoring domain']",0
"[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","[',  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG,']","['', '- to - end machinetranslation ( sutskerev,  #TAUTHOR_TAG, efficient distributed vectorspace word embeddings  #AUTHOR_TAG, image and video captioning  #AUTHOR_TAG', ', unsupervised learning of document representations by autoencoders  #AUTHOR_TAG. these recent deep learning breakthroughs along with massively parallel gpu computing allow addressing the media monitoring tasks in the completely new end - toend manner rather than relying on the legacy nlp pipelines. the novelty of the summa project approach is that all languages covered by the project ( table 1 ) can be embedded in the same vectorspace', 'by means of joint multitask learning  #AUTHOR_TAG of eight lstm - rnn translational autoencoders with hidden layer parameters shared as illustrated in fig. 2. sharing the same', 'vectorspace for sentences in all project languages enables accurate multilingual news story clustering without resorting to the clustering of the less accurate target ( english ) language machine translations. this shared vectorspace approach extends also to the unsupervised multi - task learning of language models from the large monolingual corpora ( fig. 3 ), which is crucial for low - resource', '##d languages : having a generic language model learned in parallel from the monolingual corpora reduces  #AUTHOR_TAG', 'the need for large supervised parallel corpora to achieve the same translational accuracy for the fig. 2 setup. the joint training of seventeen translational and samelanguage autoencoders with shared parameters ( fig. 2 and fig. 3 together ) to our knowledge has not been attempted so far. even training of a single state - of - the - art sentencelevel translational autoencoder requires days of gpu computing  #AUTHOR_TAG ) in tensorflow  #AUTHOR_TAG seq2seq model ( sutskerev,  #TAUTHOR_TAG. to', 'avoid complexities of asynchronous parallel training with shared parameter server  #AUTHOR_TAG, the architecture in fig. 2 and fig. 3 instead can be trained using the alternating training approach proposed in  #AUTHOR_TAG, where each task is optimized for a fixed number of parameter updates ( or mini - batches ) before switching to the next task ( which is a', 'different language pair ). although such alternating approach prolongs the training process, it is preferred for simplicity and robustness reasons. once', 'produced within summa project, these translational autoencoders with shared vectorspace will be a unique language resource of likely interest also to the wider nlp community for multilingual applications outside the media monitoring domain']",0
"['12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['system ( nmt ) [ 12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['', 'lately, there have been a number of attempts to develop a purely neural machine translation system ( nmt ) [ 12, 5, 2,  #TAUTHOR_TAG.', '']",0
"['12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['system ( nmt ) [ 12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['', 'lately, there have been a number of attempts to develop a purely neural machine translation system ( nmt ) [ 12, 5, 2,  #TAUTHOR_TAG.', '']",0
"['12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['system ( nmt ) [ 12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['', 'lately, there have been a number of attempts to develop a purely neural machine translation system ( nmt ) [ 12, 5, 2,  #TAUTHOR_TAG.', '']",0
['.  #TAUTHOR_TAG used a large'],['al.  #TAUTHOR_TAG used a large'],['.  #TAUTHOR_TAG used a large'],"['neural machine translation system is any neural network that maps a source sentence, s 1,..., s n, to a target sentence, t 1,..., t m, where all sentences are assumed to terminate with a special "" end - ofsentence "" token < eos >. more concretely, an nmt system uses a neural network to parameterize the conditional distributions', 'for 1 ≤ j ≤ m. by doing so, it becomes possible to compute and therefore maximize the log probability of the target sentence given the source sentence', 'there are many ways to parameterize these conditional distributions.', 'for example, kalchbrenner et al. [ 12 ] used a combination of a convolutional neural network and a recurrent neural network, sutskever et al.  #TAUTHOR_TAG used a large and deep long short - term memory ( lstm ) model, cho et al. [ 5 ] used an architecture similar to the lstm, and bahdanau et al. [ 2 ] used a more elaborate neural network architecture that uses an attentional mechanism over the input sequence, similarly to graves [ 9 ] and graves et al. [ 10 ].', 'in this work, we use the exact model of sutskever et al.  #TAUTHOR_TAG, which has a large deep lstm to encodue the input sequence and a separate deep lstm to produce a translation from the input sequence.', 'the encoder reads the source sentence, one word at a time, and produces a large hidden state that represents the entire source sentence.', 'the decoder is initialized from that final hidden state and generates a target translation, one word at a time, until the end - of - sentence symbol < eos > is emitted.', 'despite the relatively large amount of work done on pure neural machine translation systems, there has been no work addressing the oov problem in nmt systems']",0
"['12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['system ( nmt ) [ 12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['12, 5, 2,  #TAUTHOR_TAG.', 'ntm systems']","['', 'lately, there have been a number of attempts to develop a purely neural machine translation system ( nmt ) [ 12, 5, 2,  #TAUTHOR_TAG.', '']",1
['.  #TAUTHOR_TAG used a large'],['al.  #TAUTHOR_TAG used a large'],['.  #TAUTHOR_TAG used a large'],"['neural machine translation system is any neural network that maps a source sentence, s 1,..., s n, to a target sentence, t 1,..., t m, where all sentences are assumed to terminate with a special "" end - ofsentence "" token < eos >. more concretely, an nmt system uses a neural network to parameterize the conditional distributions', 'for 1 ≤ j ≤ m. by doing so, it becomes possible to compute and therefore maximize the log probability of the target sentence given the source sentence', 'there are many ways to parameterize these conditional distributions.', 'for example, kalchbrenner et al. [ 12 ] used a combination of a convolutional neural network and a recurrent neural network, sutskever et al.  #TAUTHOR_TAG used a large and deep long short - term memory ( lstm ) model, cho et al. [ 5 ] used an architecture similar to the lstm, and bahdanau et al. [ 2 ] used a more elaborate neural network architecture that uses an attentional mechanism over the input sequence, similarly to graves [ 9 ] and graves et al. [ 10 ].', 'in this work, we use the exact model of sutskever et al.  #TAUTHOR_TAG, which has a large deep lstm to encodue the input sequence and a separate deep lstm to produce a translation from the input sequence.', 'the encoder reads the source sentence, one word at a time, and produces a large hidden state that represents the entire source sentence.', 'the decoder is initialized from that final hidden state and generates a target translation, one word at a time, until the end - of - sentence symbol < eos > is emitted.', 'despite the relatively large amount of work done on pure neural machine translation systems, there has been no work addressing the oov problem in nmt systems']",5
"['12,  #TAUTHOR_TAG 5 ] as a black box and train']","['nmt system [ 12,  #TAUTHOR_TAG 5 ] as a black box and train']",[' #TAUTHOR_TAG 5 ] as a black box and train'],"['', 'we present three annotation strategies that can easily be applied to any nmt system.', 'we treat the nmt system [ 12,  #TAUTHOR_TAG 5 ] as a black box and train it on a dataset annotated with alignment information specified by one of the models below.', 'such alignment data can be obtained from a parallel corpus using an unsupervised aligner.', 'from the alignment links, we construct a word dictionary that will be used for the word translations in the post - processing step.', '']",5
"['reported by previous work on neural machine translation systems  #TAUTHOR_TAG 5, 2 ], we train our models on the same training']","['reported by previous work on neural machine translation systems  #TAUTHOR_TAG 5, 2 ], we train our models on the same training']","['be comparable with the results reported by previous work on neural machine translation systems  #TAUTHOR_TAG 5, 2 ], we train our models on the same training data of 12m parallel sentences ( 348m french and 304m english words ).', ""the 12m subset was selected from the full wmt'14 parallel corpora using the method""]","['be comparable with the results reported by previous work on neural machine translation systems  #TAUTHOR_TAG 5, 2 ], we train our models on the same training data of 12m parallel sentences ( 348m french and 304m english words ).', ""the 12m subset was selected from the full wmt'14 parallel corpora using the method proposed in [ 1 ]."", '2 due to the computationally intensive nature of the naive softmax in the target language, we limit the french vocabulary to the 40k most frequent french words ( note that  #TAUTHOR_TAG used a vocabulary of 80k french words ).', 'on the source side, however, we can afford a much larger vocabulary, so we use the 200k most frequent english words.', 'the model treats all other words as unknowns.', 'when the french ( target ) vocabulary has 40k words, there are on average 1. 33 unknown words per sentence on the target side of the test set.', 'we annotate our training data using the three schemes described in the previous section.', 'the alignment is computed with the berkeley aligner [ 16 ] using its default settings.', 'we discard sentence pairs in which either the source or the target sentence exceed 100 tokens']",5
"['.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutsk']","['al.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutskever']","['.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutsk']","['training procedure and hyperparameter choices are similar to those used by sutskever et al.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutskever et al.  #TAUTHOR_TAG, we reverse the words in the source sentences which has been shown to improve lstm memory utilization and results in better translations of long sentences.', 'our hyperparameters can be summarized as follows : ( a ) the parameters are initialized uniformly in [ - 0. 08, 0. 08 ], ( b ) sgd has a fixed learning rate of 0. 7, ( c ) we train for 8 epochs ( after 5 epochs, we begin to halve the learning rate every 0. 5 epoch ), ( d ) the size of the mini - batch is 128, and ( e ) we rescale the normalized gradient to ensure that its norm does not exceed 5 [ 18 ].', 'we also follow the gpu parallelization scheme proposed in  #TAUTHOR_TAG, allowing us to reach a training speed of 9. 0k words per second ( [ 22 ] achieved 6. 3k words per second with a larger vocabulary of 80k ; our target vocabulary has 40k words ).', 'training takes about 7 - 10 days on an 8 - gpu machine']",5
"['.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutsk']","['al.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutskever']","['.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutsk']","['training procedure and hyperparameter choices are similar to those used by sutskever et al.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutskever et al.  #TAUTHOR_TAG, we reverse the words in the source sentences which has been shown to improve lstm memory utilization and results in better translations of long sentences.', 'our hyperparameters can be summarized as follows : ( a ) the parameters are initialized uniformly in [ - 0. 08, 0. 08 ], ( b ) sgd has a fixed learning rate of 0. 7, ( c ) we train for 8 epochs ( after 5 epochs, we begin to halve the learning rate every 0. 5 epoch ), ( d ) the size of the mini - batch is 128, and ( e ) we rescale the normalized gradient to ensure that its norm does not exceed 5 [ 18 ].', 'we also follow the gpu parallelization scheme proposed in  #TAUTHOR_TAG, allowing us to reach a training speed of 9. 0k words per second ( [ 22 ] achieved 6. 3k words per second with a larger vocabulary of 80k ; our target vocabulary has 40k words ).', 'training takes about 7 - 10 days on an 8 - gpu machine']",5
['.  #TAUTHOR_TAG'],['al.  #TAUTHOR_TAG'],['.  #TAUTHOR_TAG'],"['analyze the effect of rare words on translation quality, we follow sutskever et al.  #TAUTHOR_TAG and sort the sentences in newstest2014 by the average frequency rank of their words.', 'we split the test sentences into groups where the sentences within each group have a comparable number of rare words and evaluate each group independently.', ""we evaluate our systems before and after translating the oov words and compare with the standard mt systems - we use the state - of - the - art ( sota ) system from wmt'14 [ 7 ], and neural mt systems - we use the ensemble system described in  #TAUTHOR_TAG ( see section 4 )."", 'rare word translation is challenging for neural machine translation systems as shown in figure 5.', 'the translation quality of our model before applying the unknown word translations is shown by the green star line, and the current best nmt system  #TAUTHOR_TAG is the purple diamond line.', '']",5
['.  #TAUTHOR_TAG'],['al.  #TAUTHOR_TAG'],['.  #TAUTHOR_TAG'],"['analyze the effect of rare words on translation quality, we follow sutskever et al.  #TAUTHOR_TAG and sort the sentences in newstest2014 by the average frequency rank of their words.', 'we split the test sentences into groups where the sentences within each group have a comparable number of rare words and evaluate each group independently.', ""we evaluate our systems before and after translating the oov words and compare with the standard mt systems - we use the state - of - the - art ( sota ) system from wmt'14 [ 7 ], and neural mt systems - we use the ensemble system described in  #TAUTHOR_TAG ( see section 4 )."", 'rare word translation is challenging for neural machine translation systems as shown in figure 5.', 'the translation quality of our model before applying the unknown word translations is shown by the green star line, and the current best nmt system  #TAUTHOR_TAG is the purple diamond line.', '']",5
['.  #TAUTHOR_TAG'],['al.  #TAUTHOR_TAG'],['.  #TAUTHOR_TAG'],"['analyze the effect of rare words on translation quality, we follow sutskever et al.  #TAUTHOR_TAG and sort the sentences in newstest2014 by the average frequency rank of their words.', 'we split the test sentences into groups where the sentences within each group have a comparable number of rare words and evaluate each group independently.', ""we evaluate our systems before and after translating the oov words and compare with the standard mt systems - we use the state - of - the - art ( sota ) system from wmt'14 [ 7 ], and neural mt systems - we use the ensemble system described in  #TAUTHOR_TAG ( see section 4 )."", 'rare word translation is challenging for neural machine translation systems as shown in figure 5.', 'the translation quality of our model before applying the unknown word translations is shown by the green star line, and the current best nmt system  #TAUTHOR_TAG is the purple diamond line.', '']",5
['.  #TAUTHOR_TAG'],['al.  #TAUTHOR_TAG'],['.  #TAUTHOR_TAG'],"['analyze the effect of rare words on translation quality, we follow sutskever et al.  #TAUTHOR_TAG and sort the sentences in newstest2014 by the average frequency rank of their words.', 'we split the test sentences into groups where the sentences within each group have a comparable number of rare words and evaluate each group independently.', ""we evaluate our systems before and after translating the oov words and compare with the standard mt systems - we use the state - of - the - art ( sota ) system from wmt'14 [ 7 ], and neural mt systems - we use the ensemble system described in  #TAUTHOR_TAG ( see section 4 )."", 'rare word translation is challenging for neural machine translation systems as shown in figure 5.', 'the translation quality of our model before applying the unknown word translations is shown by the green star line, and the current best nmt system  #TAUTHOR_TAG is the purple diamond line.', '']",5
"['reported by previous work on neural machine translation systems  #TAUTHOR_TAG 5, 2 ], we train our models on the same training']","['reported by previous work on neural machine translation systems  #TAUTHOR_TAG 5, 2 ], we train our models on the same training']","['be comparable with the results reported by previous work on neural machine translation systems  #TAUTHOR_TAG 5, 2 ], we train our models on the same training data of 12m parallel sentences ( 348m french and 304m english words ).', ""the 12m subset was selected from the full wmt'14 parallel corpora using the method""]","['be comparable with the results reported by previous work on neural machine translation systems  #TAUTHOR_TAG 5, 2 ], we train our models on the same training data of 12m parallel sentences ( 348m french and 304m english words ).', ""the 12m subset was selected from the full wmt'14 parallel corpora using the method proposed in [ 1 ]."", '2 due to the computationally intensive nature of the naive softmax in the target language, we limit the french vocabulary to the 40k most frequent french words ( note that  #TAUTHOR_TAG used a vocabulary of 80k french words ).', 'on the source side, however, we can afford a much larger vocabulary, so we use the 200k most frequent english words.', 'the model treats all other words as unknowns.', 'when the french ( target ) vocabulary has 40k words, there are on average 1. 33 unknown words per sentence on the target side of the test set.', 'we annotate our training data using the three schemes described in the previous section.', 'the alignment is computed with the berkeley aligner [ 16 ] using its default settings.', 'we discard sentence pairs in which either the source or the target sentence exceed 100 tokens']",4
"['nmt system  #TAUTHOR_TAG.', 'we compare the']","['nmt system  #TAUTHOR_TAG.', 'we compare the']","['the current best nmt system  #TAUTHOR_TAG.', 'we compare the other rare word translation schemes in']","['', 'our best result ( 36. 9 bleu ) outperforms all other nmt systems by a large margin, and in particular, it outperforms the current best nmt system  #TAUTHOR_TAG.', 'we compare the other rare word translation schemes in the next section.', 'it is notable that the more accurate nmt systems obtain greater improvements from our postprocessing step.', ""it is the case because the usefulness of the posunk model depends directly on the nmt's ability to correctly locate, for a given oov target word, the word in the source sentence that is responsible for it."", 'an ensemble of large models identifies these source words with greater accuracy, so it is not surprising that the posunk model provides the greatest improvement in performance for the best models']",4
['.  #TAUTHOR_TAG'],['al.  #TAUTHOR_TAG'],['.  #TAUTHOR_TAG'],"['analyze the effect of rare words on translation quality, we follow sutskever et al.  #TAUTHOR_TAG and sort the sentences in newstest2014 by the average frequency rank of their words.', 'we split the test sentences into groups where the sentences within each group have a comparable number of rare words and evaluate each group independently.', ""we evaluate our systems before and after translating the oov words and compare with the standard mt systems - we use the state - of - the - art ( sota ) system from wmt'14 [ 7 ], and neural mt systems - we use the ensemble system described in  #TAUTHOR_TAG ( see section 4 )."", 'rare word translation is challenging for neural machine translation systems as shown in figure 5.', 'the translation quality of our model before applying the unknown word translations is shown by the green star line, and the current best nmt system  #TAUTHOR_TAG is the purple diamond line.', '']",4
"['.  #TAUTHOR_TAG.', 'a technique like ours is likely necessary if an nmt system is to']","['al.  #TAUTHOR_TAG.', 'a technique like ours is likely necessary if an nmt system is to']","['.  #TAUTHOR_TAG.', 'a technique like ours is likely necessary if an nmt system is to']","['have shown that a simple alignment - based technique can mitigate and even overcome one of the main weaknesses of current nmt systems, which is their inability to translate words that are not in their vocabulary.', 'a key advantage of our technique is the fact that it is applicable to any nmt system and not only to the deep lstm model of sutskever et al.  #TAUTHOR_TAG.', 'a technique like ours is likely necessary if an nmt system is to achieve state - of - the - art performance on machine translation.', ""we have demonstrated empirically that on the wmt'14 english - french translation task, our technique yields a consistent and substantial improvement of 2 - 3 bleu points over various ntm sys - sample translations - the table shows the source ( src ) and the translations of our best model before ( trans ) and after ( + unk ) unknown word translations."", 'we also show the human translations ( tgt ) and italicize words that are involved in the unknown word translation process']",4
"['.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutsk']","['al.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutskever']","['.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutsk']","['training procedure and hyperparameter choices are similar to those used by sutskever et al.  #TAUTHOR_TAG.', 'in more details, we train multi - layer deep lstms, each of which has 1000 cells, with 1000 dimensional embeddings.', 'like sutskever et al.  #TAUTHOR_TAG, we reverse the words in the source sentences which has been shown to improve lstm memory utilization and results in better translations of long sentences.', 'our hyperparameters can be summarized as follows : ( a ) the parameters are initialized uniformly in [ - 0. 08, 0. 08 ], ( b ) sgd has a fixed learning rate of 0. 7, ( c ) we train for 8 epochs ( after 5 epochs, we begin to halve the learning rate every 0. 5 epoch ), ( d ) the size of the mini - batch is 128, and ( e ) we rescale the normalized gradient to ensure that its norm does not exceed 5 [ 18 ].', 'we also follow the gpu parallelization scheme proposed in  #TAUTHOR_TAG, allowing us to reach a training speed of 9. 0k words per second ( [ 22 ] achieved 6. 3k words per second with a larger vocabulary of 80k ; our target vocabulary has 40k words ).', 'training takes about 7 - 10 days on an 8 - gpu machine']",3
"['work [ 5, 2, 19,  #TAUTHOR_TAG.', 'thus, to']","['work [ 5, 2, 19,  #TAUTHOR_TAG.', 'thus, to']","[""on the english to french language pair on wmt'14."", 'this numerical score is based on detokenized translations.', 'however, all other systems that we compared against have been evaluated on the tokenized translations using the multi - bleu. pl script, which is consistent with previous work [ 5, 2, 19,  #TAUTHOR_TAG.', 'thus, to']","[""website http : / / matrix. statmt. org / matrix states that the state - of - the - art ( sota ) system [ 7 ] achieves a bleu score of 35. 8 on the english to french language pair on wmt'14."", 'this numerical score is based on detokenized translations.', 'however, all other systems that we compared against have been evaluated on the tokenized translations using the multi - bleu. pl script, which is consistent with previous work [ 5, 2, 19,  #TAUTHOR_TAG.', 'thus, to make it possible to compare our system against the system of durrani et al. [ 7 ], we evaluated its tokenized predictions ( which can be downloaded from statmt. org [ 7 ] ) on the test set ( newstest2014 ) and arrived at the bleu score of 37. 0 points  #TAUTHOR_TAG']",3
"['work [ 5, 2, 19,  #TAUTHOR_TAG.', 'thus, to']","['work [ 5, 2, 19,  #TAUTHOR_TAG.', 'thus, to']","[""on the english to french language pair on wmt'14."", 'this numerical score is based on detokenized translations.', 'however, all other systems that we compared against have been evaluated on the tokenized translations using the multi - bleu. pl script, which is consistent with previous work [ 5, 2, 19,  #TAUTHOR_TAG.', 'thus, to']","[""website http : / / matrix. statmt. org / matrix states that the state - of - the - art ( sota ) system [ 7 ] achieves a bleu score of 35. 8 on the english to french language pair on wmt'14."", 'this numerical score is based on detokenized translations.', 'however, all other systems that we compared against have been evaluated on the tokenized translations using the multi - bleu. pl script, which is consistent with previous work [ 5, 2, 19,  #TAUTHOR_TAG.', 'thus, to make it possible to compare our system against the system of durrani et al. [ 7 ], we evaluated its tokenized predictions ( which can be downloaded from statmt. org [ 7 ] ) on the test set ( newstest2014 ) and arrived at the bleu score of 37. 0 points  #TAUTHOR_TAG']",3
['by domain variation -  #TAUTHOR_TAG report that'],['by domain variation -  #TAUTHOR_TAG report that'],['by domain variation -  #TAUTHOR_TAG report that'],"['', 'it is, however, affected by domain variation -  #TAUTHOR_TAG report that its f - score drops by approximately 8 percentage points when applied to the bnc domain.', 'our training size is 500, 000 sentences.', 'we conduct two experiments : the first, in which 500, 000 sentences are extracted randomly from the bnc ( minus the test set sentences ), and the second in which only shorter sentences, of length ≤ 20 words, are chosen as training material.', 'the rationale behind the second experiment is that shorter sentences are less likely to contain parser errors.', 'we use the bleu evaluation metric for our experiments.', 'we measure both coverage and full coverage.', 'coverage measures the number of cases for which the generator produced some kind of output.', 'full coverage measures the number of cases for which the generator produced a tree spanning all of the words in the input']",0
['to bnc data  #TAUTHOR_TAG'],['to bnc data  #TAUTHOR_TAG'],"['to bnc data  #TAUTHOR_TAG.', '']","['', 'for the baseline system, the generator is trained on f - structure - annotated trees derived from gold trees.', ""the new system is trained on f - structureannotated parser output trees, and the performance of charniak and johnson's parser degrades when applied to bnc data  #TAUTHOR_TAG."", 'the second reason has been suggested by  #AUTHOR_TAG : wsj data is easier to learn than the more varied data in the brown corpus or bnc.', 'perhaps even if gold standard bnc parse trees were available for training, the system would not behave as well as it does for wsj material.', 'it is interesting to note that training on 500, 000 shorter sentences does not appear to help.', 'we hypothesized that it would improve results because shorter sentences are less likely to contain parser errors.', 'the drop in full coverage from 86. 69 % to 79. 58 % suggests that the number of short sentences needs to be increased so that the size of the training material stays constant']",0
"['parser  #TAUTHOR_TAG.', '']","['by a bnc - self - trained version of the charniak and johnson reranking parser  #TAUTHOR_TAG.', '']","['by a bnc - self - trained version of the charniak and johnson reranking parser  #TAUTHOR_TAG.', '']","['', 'encouragingly, we have also shown that domain - specific training material produced by a parser can be used to claw back a significant portion of this performance degradation.', 'our method is general and could be applied to other wsj - trained generators ( e. g. ( nakanishi et, 2007 ) ).', 'we intend to continue this research by training our generator on parse trees produced by a bnc - self - trained version of the charniak and johnson reranking parser  #TAUTHOR_TAG.', 'we also hope to extend the evaluation beyond the bleu metric by carrying out a human judgement evaluation']",6
['##bank  #TAUTHOR_TAG'],['##bank  #TAUTHOR_TAG'],['annotated treebank  #TAUTHOR_TAG. we observe that supertag prediction does not take full advantage of the complex structural'],"['prediction task from this annotated data and is able to then assign the most likely sequence of supertags to an input sequence of words  #AUTHOR_TAG. once the right supertag is assigned then parsing is a much easier task and may not even be needed for', 'many applications where information about syntax is needed but a full parse is unnecessary. supertagging has been shown to be useful for both tree adjoining grammar ( tag )  #AUTHOR_TAG and combinatory', 'categorial grammar ( ccg )  #AUTHOR_TAG parsing. in this paper we aim to improve the state - of - the - art for the task of learning a tag supertagger from', 'an annotated treebank  #TAUTHOR_TAG. we observe that supertag prediction does not take full advantage of the complex structural information contained within each supertag. neural models have been used', 'to learn embeddings over these supertags and thereby share weights among similar supertags.  #AUTHOR_TAG provide tree - structured neural models over supertags which can learn', 'interesting relationships between supertags but the approach does not lead to higher supertagging accuracy. our main contribution', 'is to provide several novel ways to deconstruct supertags to create multiple alternative auxiliary tasks, which we then combine', 'using a multi - task prediction framework and we show that this can lead to a significant improvement in supertagging accuracy. multi - task learning ( mtl )  #AUTHOR_TAG', 'learns multiple heterogenous tasks in parallel with a shared representation so that what is learned for one task can be shared for another task. in most cases the improvement is due to weight sharing between different tasks  #AUTHOR_TAG. while some combinations may not provide any benefit', 'in mtl ( bingel and søgaard, 2017 ) and the improvements might be simply due to training on more data. however, mtl can be effective even when using', 'large pretrained models  #AUTHOR_TAG. unlike most other work in multi - task learning', 'with neural models we do not use different annotated datasets for each task. similar to the approach to combining different representations for phrase structure parsing in  #AUTHOR_TAG we also construct multiple tasks from', 'exactly the same training data set. our approach is also distinct in that we take', 'advantage of the structure of the supertags by deconstructing the tree structure implicit in each supertag. our', 'experimental results show that our novel multi - task learning framework leads to a new state - of - the - art accuracy score of 91.', '39 % for tag supertagging on the penn treebank dataset  #AUTHOR_TAG which is a significant improvement over the previous multi - task result for supertagging that', 'combines supertagging with graph - based parsing  #TAUTHOR_TAG']",4
"['.', ' #TAUTHOR_TAG we use two components in']","['sentence.', 'see section 2 for more details on the notation used to define the supertags and how the supertags can be combined to form a parse tree.', ' #TAUTHOR_TAG we use two components in']","['', 'see section 2 for more details on the notation used to define the supertags and how the supertags can be combined to form a parse tree.', ' #TAUTHOR_TAG we use two components in the word embedding :', '• a 30 - dimensional character level embedding vector computed using a char - cnn which captures the morphological information  #TAUTHOR_TAG.', 'each character is encoded as a 30 - dimensional vector, and then']","['', 'see section 2 for more details on the notation used to define the supertags and how the supertags can be combined to form a parse tree.', ' #TAUTHOR_TAG we use two components in the word embedding :', '• a 30 - dimensional character level embedding vector computed using a char - cnn which captures the morphological information  #TAUTHOR_TAG.', 'each character is encoded as a 30 - dimensional vector, and then we apply 30 convolutional filters with a window size of 5.', 'this produces a 30 - dimensional character embedding.', '• a 100 / 200 / 300 size word embedding which is initialized using glove  #AUTHOR_TAG.', 'for words that do not appear in glove, we randomly initialized the word embedding.', 'a start of sentence token and an end of sentence token is added into the beginning and ending position of each sentence, but is not included in the computation of loss and accuracy.', 'unlike  #TAUTHOR_TAG we do not use predicted part of speech ( pos ) tags as part of the input sequence.', 'in our experiments, the improvement was negligible and there was a significant overhead of having to do part of speech predictions at test time']",4
"['core of this base model is a bidirectional recurrent neural network, in particular a long short - term memory neural network  #AUTHOR_TAG.', 'for the hyperparameters, we use the settings in  #TAUTHOR_TAG in order to ensure a fair comparison.', 'unlike  #TAUTHOR_TAG']","['core of this base model is a bidirectional recurrent neural network, in particular a long short - term memory neural network  #AUTHOR_TAG.', 'for the hyperparameters, we use the settings in  #TAUTHOR_TAG in order to ensure a fair comparison.', 'unlike  #TAUTHOR_TAG']","['core of this base model is a bidirectional recurrent neural network, in particular a long short - term memory neural network  #AUTHOR_TAG.', 'for the hyperparameters, we use the settings in  #TAUTHOR_TAG in order to ensure a fair comparison.', 'unlike  #TAUTHOR_TAG']","['core of this base model is a bidirectional recurrent neural network, in particular a long short - term memory neural network  #AUTHOR_TAG.', 'for the hyperparameters, we use the settings in  #TAUTHOR_TAG in order to ensure a fair comparison.', 'unlike  #TAUTHOR_TAG we do not use highway connections in our model.', 'we did experiment with the addition of highway connections but we found no improvement in accuracy over the baseline bilstm - only model with a significant increase in training time.', 'the bidirectional representation has 1024 units, a combination of the 512 forward and backward units each.', 'dropout layers  #AUTHOR_TAG are inserted between the input and bilstm layer, between bilstm layers, and between recurrent time steps.', 'the dropout rate used was 0. 5.', 'we used 2 - 3 bilstm layers.', ' #AUTHOR_TAG provide some reasons why > 3 layers do not provide any additional accuracy even with highway connections']",4
"['based supertag', '##ging models in tag  #TAUTHOR_TAG and cc']","['neural network based supertag', '##ging models in tag  #TAUTHOR_TAG and cc']","['based supertag', '##ging models in tag  #TAUTHOR_TAG and ccg  #AUTHOR_TAG have shown substantial']","['', 'spine ( s - punct for t20 and s - prn - punct for t132 ) and sketch. the joint effort of various models', 'plays a significant role in getting the prediction right.  #AUTHOR_TAG and  #AUTHOR_TAG trained a feature based classification', 'model for tag supertags, that extract', 'features using lexical, part - of - speech attributes from the left and right context in a 6 - word window and the lexical, orthographic ( e. g. capitalization,', 'prefix, suffix, digit ) and part - of - speech attributes of the word being supertagged. neural network based supertag', '##ging models in tag  #TAUTHOR_TAG and ccg  #AUTHOR_TAG have shown substantial improvement in performance', ', but the supertagging models are all quite similar as they all use a bi - directional rnn feeding into a prediction layer. structural features of supertags are heavily used in pre - neural statistical parsing', 'methods  #AUTHOR_TAG and proved to be useful. the use of supertag structure was explored in  #AUTHOR_TAG where they', 'adopt grammar features into a tree - structured neural model over the supertags but this model was unable to', 'beat the state - of - the - art.  #TAUTHOR_TAG combines supertagging with parsing which', '']",4
"['initial step  #TAUTHOR_TAG.', 'an']","['initial step  #TAUTHOR_TAG.', 'an']","['use supertagging as the initial step  #TAUTHOR_TAG.', 'an example of the supertagging task for']","['##tagging assigns complex structural descriptions to each word in the sentence.', 'the complex structural descriptions come from grammar formalisms that are more expressive than context - free grammars for phrase structure trees or dependency trees.', 'in tree adjoining grammar ( tag ), the supertags are tree fragments that can express various syntactic facts such as transitive verb, wh - extraction, relative clauses, appositive clauses, light verbs, prepositional phrase attachment and many other syntactic phenomena.', 'in combinatory categorial grammar ( ccg ) the supertags are types and their type - raised variants which also capture similar syntactic phenomena as in tag supertags.', 'supertagging can be viewed as "" almost parsing ""  #AUTHOR_TAG and can provide the benefits of syntactic parsing without a full parser.', 'in this paper we focus on the tag supertagging task, however, our proposed methods can likely be used to improve ccg supertagging as well.', 'supertagging is a relatively simple linear time sequence prediction task similar to part of speech tagging.', 'supertagging can be useful in many applications such as machine translation, grammatical error detection, disfluency prediction, and many others while being a much simpler task than full parsing.', 'in addition, for both tag and ccg, supertagging is an essential first step to parsing so any improvements in supertag prediction will benefit parsing as well.', 'for all these reasons, in this paper we focus on the supertagging task.', 'tag and ccg can be parsed using graph - parsing methods in o ( n 3 ) but the complexity of unrestricted parsing for both formalisms is o ( n 6 ) which is prohibitive on real - world data.', 'neural linear - time transition based parsers are still not accurate enough to compete with the state - of - the - art supertagging models or parsers that use supertagging as the initial step  #TAUTHOR_TAG.', 'an example of the supertagging task for tree adjoining grammars ( tags ) is shown in fig. 1.', 'the ↓ symbol on a leaf node represents a substitu - tion node which can be expanded by a tree rooted in the same label, e. g. t3 rooted in np substitutes into the np↓ node in t46.', '']",0
"['based supertag', '##ging models in tag  #TAUTHOR_TAG and cc']","['neural network based supertag', '##ging models in tag  #TAUTHOR_TAG and cc']","['based supertag', '##ging models in tag  #TAUTHOR_TAG and ccg  #AUTHOR_TAG have shown substantial']","['', 'spine ( s - punct for t20 and s - prn - punct for t132 ) and sketch. the joint effort of various models', 'plays a significant role in getting the prediction right.  #AUTHOR_TAG and  #AUTHOR_TAG trained a feature based classification', 'model for tag supertags, that extract', 'features using lexical, part - of - speech attributes from the left and right context in a 6 - word window and the lexical, orthographic ( e. g. capitalization,', 'prefix, suffix, digit ) and part - of - speech attributes of the word being supertagged. neural network based supertag', '##ging models in tag  #TAUTHOR_TAG and ccg  #AUTHOR_TAG have shown substantial improvement in performance', ', but the supertagging models are all quite similar as they all use a bi - directional rnn feeding into a prediction layer. structural features of supertags are heavily used in pre - neural statistical parsing', 'methods  #AUTHOR_TAG and proved to be useful. the use of supertag structure was explored in  #AUTHOR_TAG where they', 'adopt grammar features into a tree - structured neural model over the supertags but this model was unable to', 'beat the state - of - the - art.  #TAUTHOR_TAG combines supertagging with parsing which', '']",0
"['based supertag', '##ging models in tag  #TAUTHOR_TAG and cc']","['neural network based supertag', '##ging models in tag  #TAUTHOR_TAG and cc']","['based supertag', '##ging models in tag  #TAUTHOR_TAG and ccg  #AUTHOR_TAG have shown substantial']","['', 'spine ( s - punct for t20 and s - prn - punct for t132 ) and sketch. the joint effort of various models', 'plays a significant role in getting the prediction right.  #AUTHOR_TAG and  #AUTHOR_TAG trained a feature based classification', 'model for tag supertags, that extract', 'features using lexical, part - of - speech attributes from the left and right context in a 6 - word window and the lexical, orthographic ( e. g. capitalization,', 'prefix, suffix, digit ) and part - of - speech attributes of the word being supertagged. neural network based supertag', '##ging models in tag  #TAUTHOR_TAG and ccg  #AUTHOR_TAG have shown substantial improvement in performance', ', but the supertagging models are all quite similar as they all use a bi - directional rnn feeding into a prediction layer. structural features of supertags are heavily used in pre - neural statistical parsing', 'methods  #AUTHOR_TAG and proved to be useful. the use of supertag structure was explored in  #AUTHOR_TAG where they', 'adopt grammar features into a tree - structured neural model over the supertags but this model was unable to', 'beat the state - of - the - art.  #TAUTHOR_TAG combines supertagging with parsing which', '']",0
"['based supertag', '##ging models in tag  #TAUTHOR_TAG and cc']","['neural network based supertag', '##ging models in tag  #TAUTHOR_TAG and cc']","['based supertag', '##ging models in tag  #TAUTHOR_TAG and ccg  #AUTHOR_TAG have shown substantial']","['', 'spine ( s - punct for t20 and s - prn - punct for t132 ) and sketch. the joint effort of various models', 'plays a significant role in getting the prediction right.  #AUTHOR_TAG and  #AUTHOR_TAG trained a feature based classification', 'model for tag supertags, that extract', 'features using lexical, part - of - speech attributes from the left and right context in a 6 - word window and the lexical, orthographic ( e. g. capitalization,', 'prefix, suffix, digit ) and part - of - speech attributes of the word being supertagged. neural network based supertag', '##ging models in tag  #TAUTHOR_TAG and ccg  #AUTHOR_TAG have shown substantial improvement in performance', ', but the supertagging models are all quite similar as they all use a bi - directional rnn feeding into a prediction layer. structural features of supertags are heavily used in pre - neural statistical parsing', 'methods  #AUTHOR_TAG and proved to be useful. the use of supertag structure was explored in  #AUTHOR_TAG where they', 'adopt grammar features into a tree - structured neural model over the supertags but this model was unable to', 'beat the state - of - the - art.  #TAUTHOR_TAG combines supertagging with parsing which', '']",0
"['dataset  #TAUTHOR_TAG.', 'for']","['penn treebank dataset  #TAUTHOR_TAG.', 'for']","['currently has the highest accuracy on the penn treebank dataset  #TAUTHOR_TAG.', 'for the supertagging model the main contribution of  #TAUTHOR_TAG was two - fold :']","['our baseline supertagging model we use the state - of - the - art model that currently has the highest accuracy on the penn treebank dataset  #TAUTHOR_TAG.', 'for the supertagging model the main contribution of  #TAUTHOR_TAG was two - fold : the first was to add a character cnn for modeling word embeddings using subword features, and the second was to add highway connections to add more layers to a standard bidirectional lstm.', 'the output layer was a standard multi - layer perceptron that had a softmax output over the set of supertags.', 'another extension to the standard sequence prediction model in  #TAUTHOR_TAG was to combine supertagging with graph - based parsing.', 'in this paper, we focus on the supertagging model and compare only on supertagging accuracy.', 'the neural model for supertagging that we use as a baseline uses graph - based parsing as an auxiliary task and has the current highest accuracy score on the penn treebank ( 90. 81 % ).', 'the model has three main components : the input layer, the bidirectional lstm component, and the output layer which computes a softmax over the set of supertags.', 'the input to the model is a sequence of words and the output is a sequence of supertags, one per word, which makes it a standard tagging aka sequence prediction task']",6
"['based supertag', '##ging models in tag  #TAUTHOR_TAG and cc']","['neural network based supertag', '##ging models in tag  #TAUTHOR_TAG and cc']","['based supertag', '##ging models in tag  #TAUTHOR_TAG and ccg  #AUTHOR_TAG have shown substantial']","['', 'spine ( s - punct for t20 and s - prn - punct for t132 ) and sketch. the joint effort of various models', 'plays a significant role in getting the prediction right.  #AUTHOR_TAG and  #AUTHOR_TAG trained a feature based classification', 'model for tag supertags, that extract', 'features using lexical, part - of - speech attributes from the left and right context in a 6 - word window and the lexical, orthographic ( e. g. capitalization,', 'prefix, suffix, digit ) and part - of - speech attributes of the word being supertagged. neural network based supertag', '##ging models in tag  #TAUTHOR_TAG and ccg  #AUTHOR_TAG have shown substantial improvement in performance', ', but the supertagging models are all quite similar as they all use a bi - directional rnn feeding into a prediction layer. structural features of supertags are heavily used in pre - neural statistical parsing', 'methods  #AUTHOR_TAG and proved to be useful. the use of supertag structure was explored in  #AUTHOR_TAG where they', 'adopt grammar features into a tree - structured neural model over the supertags but this model was unable to', 'beat the state - of - the - art.  #TAUTHOR_TAG combines supertagging with parsing which', '']",7
"['', 'one promising approach is based on exact search and structural learning  #TAUTHOR_TAG']","['in recent years.', 'one promising approach is based on exact search and structural learning  #TAUTHOR_TAG']","['in recent years.', 'one promising approach is based on exact search and structural learning  #TAUTHOR_TAG.', 'in this work we also pursue this approach.', 'our system makes no provisions for non - projective edges.', 'in contrast']","['parsing is a topic that has engendered increasing interest in recent years.', 'one promising approach is based on exact search and structural learning  #TAUTHOR_TAG.', 'in this work we also pursue this approach.', 'our system makes no provisions for non - projective edges.', 'in contrast to previous work, we aim to learn labelled dependency trees at one fell swoop.', ""this is done by maintaining several copies of feature vectors that capture the features'impact on predicting different dependency relations ( deprels )."", ""in order to preserve the strength of  #TAUTHOR_TAG's approach in terms of unlabelled attachment score, we add feature vectors for generalizations over deprels."", 'we also employ various reversible transformations to reach treebank formats that better match our feature representation and that reduce the complexity of the learning task.', 'the paper first presents the methodology used, goes on to describing experiments and results and finally concludes']",0
"['', 'one promising approach is based on exact search and structural learning  #TAUTHOR_TAG']","['in recent years.', 'one promising approach is based on exact search and structural learning  #TAUTHOR_TAG']","['in recent years.', 'one promising approach is based on exact search and structural learning  #TAUTHOR_TAG.', 'in this work we also pursue this approach.', 'our system makes no provisions for non - projective edges.', 'in contrast']","['parsing is a topic that has engendered increasing interest in recent years.', 'one promising approach is based on exact search and structural learning  #TAUTHOR_TAG.', 'in this work we also pursue this approach.', 'our system makes no provisions for non - projective edges.', 'in contrast to previous work, we aim to learn labelled dependency trees at one fell swoop.', ""this is done by maintaining several copies of feature vectors that capture the features'impact on predicting different dependency relations ( deprels )."", ""in order to preserve the strength of  #TAUTHOR_TAG's approach in terms of unlabelled attachment score, we add feature vectors for generalizations over deprels."", 'we also employ various reversible transformations to reach treebank formats that better match our feature representation and that reduce the complexity of the learning task.', 'the paper first presents the methodology used, goes on to describing experiments and results and finally concludes']",7
"[""- parsing algorithm in  #TAUTHOR_TAG's formulation, which""]","[""our approach, we adopt  #AUTHOR_TAG's bottomup chart - parsing algorithm in  #TAUTHOR_TAG's formulation, which""]","[""##up chart - parsing algorithm in  #TAUTHOR_TAG's formulation, which""]","[""our approach, we adopt  #AUTHOR_TAG's bottomup chart - parsing algorithm in  #TAUTHOR_TAG's formulation, which finds the best projective dependency tree for an input string"", 'we assume that every possible headdependent pair [UNK] is described by a feature vector', ""eisner's algorithm achieves optimal tree packing by storing partial structures in two matrices and."", 'first the diagonals of the matrices are initiated with 0 ; then all other cells are filled according to eqs. ( 1 ) and ( 2 ) and their symmetric variants']",6
['set of features as  #TAUTHOR_TAG'],['set of features as  #TAUTHOR_TAG'],"['know ).', 'we essentially employ the same set of features as  #TAUTHOR_TAG']","[""deriving features, we used all information given in the treebanks, i. e. words ( w ), fine - grained pos tags ( fp ), combinations of lemmas and coarsegrained pos tags ( lcp ), and whether two tokens agree 1 ( agr = yes, no, don't know )."", 'we essentially employ the same set of features as  #TAUTHOR_TAG']",5
"[""is easier to implement and more efficient than the mira algorithm used by  #TAUTHOR_TAG, although it achieves a performance comparable to mira's on many problems  #AUTHOR_TAG""]","['ergative, other case ).', ""having a closed - form solution, opal is easier to implement and more efficient than the mira algorithm used by  #TAUTHOR_TAG, although it achieves a performance comparable to mira's on many problems  #AUTHOR_TAG""]","[', other case ).', ""having a closed - form solution, opal is easier to implement and more efficient than the mira algorithm used by  #TAUTHOR_TAG, although it achieves a performance comparable to mira's on many problems  #AUTHOR_TAG""]","['determining feature weights &, we used online passive - aggressive learning ( opal )  #AUTHOR_TAG.', 'opal iterates repeatedly over all training instances, adapting weights after each parse.', 'it tries to change weights as little as possible ( passiveness ), while ensuring that ( 1 )', '1 agreement was computed from morphological features, viz. gender, number and person, and case.', 'in languages with subject - verb agreement, we added a nominative case feature to finite verbs.', 'in basque, agreement is case - specific ( absolutive, dative, ergative, other case ).', ""having a closed - form solution, opal is easier to implement and more efficient than the mira algorithm used by  #TAUTHOR_TAG, although it achieves a performance comparable to mira's on many problems  #AUTHOR_TAG""]",4
"['of  #TAUTHOR_TAG, only predicts unlabelled dependency trees']","['of  #TAUTHOR_TAG, only predicts unlabelled dependency trees.', 'to derive a labeling, we departed from their approach : we split each feature along the deprel label dimension,']","['of  #TAUTHOR_TAG, only predicts unlabelled dependency trees.', 'to derive a labeling, we departed from their']","['far, the presented system, which follows closely the approach of  #TAUTHOR_TAG, only predicts unlabelled dependency trees.', 'to derive a labeling, we departed from their approach : we split each feature along the deprel label dimension, so that each deprel u is associated with its own feature vector ( cf.', 'eq. ( 4 ), where v is the tensor product and', '']",4
"['of  #TAUTHOR_TAG, only predicts unlabelled dependency trees']","['of  #TAUTHOR_TAG, only predicts unlabelled dependency trees.', 'to derive a labeling, we departed from their approach : we split each feature along the deprel label dimension,']","['of  #TAUTHOR_TAG, only predicts unlabelled dependency trees.', 'to derive a labeling, we departed from their']","['far, the presented system, which follows closely the approach of  #TAUTHOR_TAG, only predicts unlabelled dependency trees.', 'to derive a labeling, we departed from their approach : we split each feature along the deprel label dimension, so that each deprel u is associated with its own feature vector ( cf.', 'eq. ( 4 ), where v is the tensor product and', '']",1
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['model ( fe', ') of  #TAUTHOR_TAG']","['', 'do not appear in the kb. in this paper, we propose core, a flexible open re model that leverages contextual information. core is inspired by the combined factorization and entity model ( fe', ') of  #TAUTHOR_TAG. as fe, core associates latent semantic representations', 'with entities, relations, and arguments. in contrast to fe, core uses factorization machines  #AUTHOR_TAG as its underlying framework, which allows us to incorporate context', 'in a flexible way. core is able to leverage and integrate arbitrary contextual information associated with the input facts into its open re factorization model. to', 'support reasoning under the openworld assumption, we propose an efficient method for parameter estimation in factorization machines based on bayesian personalized ranking  #AUTHOR_TAG', '. we conducted an experimental study on a realworld dataset using contextual information along the lines mentioned above. our', 'model is extensible, i. e., additional contextual information can be integrated when available. even', 'with limited amount of contextual information used in our experiments, our core model provided higher prediction performance than previous models. our findings validate the usefulness of contextual information for the open re task']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['model ( fe', ') of  #TAUTHOR_TAG']","['', 'do not appear in the kb. in this paper, we propose core, a flexible open re model that leverages contextual information. core is inspired by the combined factorization and entity model ( fe', ') of  #TAUTHOR_TAG. as fe, core associates latent semantic representations', 'with entities, relations, and arguments. in contrast to fe, core uses factorization machines  #AUTHOR_TAG as its underlying framework, which allows us to incorporate context', 'in a flexible way. core is able to leverage and integrate arbitrary contextual information associated with the input facts into its open re factorization model. to', 'support reasoning under the openworld assumption, we propose an efficient method for parameter estimation in factorization machines based on bayesian personalized ranking  #AUTHOR_TAG', '. we conducted an experimental study on a realworld dataset using contextual information along the lines mentioned above. our', 'model is extensible, i. e., additional contextual information can be integrated when available. even', 'with limited amount of contextual information used in our experiments, our core model provided higher prediction performance than previous models. our findings validate the usefulness of contextual information for the open re task']",0
"['of  #TAUTHOR_TAG,']","['of  #TAUTHOR_TAG, which combines']","['of  #TAUTHOR_TAG,']","['', '- and ( 2 ) that they scale much better with the number of relations', '. examples of', 'such matrix factorization models include  #AUTHOR_TAG. have also shown that a combination of matrix and tensor factorization models can be fruitful. closest to our work is the "" universal schema ""', 'matrix factorization approach of  #TAUTHOR_TAG, which combines a latent features model, a neighborhood model and an entity model but does not incorporate context. our core model follows the universal schema idea, but uses a more general factorization model, which includes the information captured', 'by the latent features and entity model ( but not the neighborhood model ), and incorporates contextual information. using contextual information. it is well known', 'that contextual information can improve ie methods. information such as bag - of - words, part - ofspeech tags, entity types, or parse trees have been', 'integrated into many', 'existing systems  #AUTHOR_TAG de  #AUTHOR_TAG. our work differs in that we integrate contextual information into an open re system. to', 'do so, we leverage factorization machines  #AUTHOR_TAG, which have been successfully applied to exploit contextual information', 'in the context of recommender systems. we show how to model open re data and context with factorization machines and provide a method for parameter estimation under the open - world assumption']",0
"['of  #TAUTHOR_TAG,']","['of  #TAUTHOR_TAG, which combines']","['of  #TAUTHOR_TAG,']","['', '- and ( 2 ) that they scale much better with the number of relations', '. examples of', 'such matrix factorization models include  #AUTHOR_TAG. have also shown that a combination of matrix and tensor factorization models can be fruitful. closest to our work is the "" universal schema ""', 'matrix factorization approach of  #TAUTHOR_TAG, which combines a latent features model, a neighborhood model and an entity model but does not incorporate context. our core model follows the universal schema idea, but uses a more general factorization model, which includes the information captured', 'by the latent features and entity model ( but not the neighborhood model ), and incorporates contextual information. using contextual information. it is well known', 'that contextual information can improve ie methods. information such as bag - of - words, part - ofspeech tags, entity types, or parse trees have been', 'integrated into many', 'existing systems  #AUTHOR_TAG de  #AUTHOR_TAG. our work differs in that we integrate contextual information into an open re system. to', 'do so, we leverage factorization machines  #AUTHOR_TAG, which have been successfully applied to exploit contextual information', 'in the context of recommender systems. we show how to model open re data and context with factorization machines and provide a method for parameter estimation under the open - world assumption']",0
['experimental study of  #TAUTHOR_TAG'],"['experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing by the amount of context being used. we consider as context the article metadata (', 'm ), the tuple types ( t', ') and', 'the bag - of - words ( w ). each tuple type is', 'a pair of subject - object types of ( e. g. ( person, location ) ). the basic core model uses relations, tuples and entities', 'as variables. we additionally consider the core + t, core + w, core + mt,', 'and core + mtw models, where the suffix indicates which contextual information has been included. the total number of variables in the resulting models varied between 300k ( core ) to 350k ( core + mtw ). we used a modified version of libfm for training. 4 our version adds support for bpr and parallelizes the training algorithm. methodology. to evaluate the prediction performance of each method, we followed  #TAUTHOR_TAG. we considered a collection of 19 freebase relations ( tab. 2 )', 'and 10 surface', 'relations ( tab. 3 ) and restrict predictions to tuples in the evaluation set. evaluation metrics. for each relation and method, we computed the top - 100 evaluation', 'set predictions', 'and labeled them manually. we used as', '']",0
['experimental study of  #TAUTHOR_TAG'],"['experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing by the amount of context being used. we consider as context the article metadata (', 'm ), the tuple types ( t', ') and', 'the bag - of - words ( w ). each tuple type is', 'a pair of subject - object types of ( e. g. ( person, location ) ). the basic core model uses relations, tuples and entities', 'as variables. we additionally consider the core + t, core + w, core + mt,', 'and core + mtw models, where the suffix indicates which contextual information has been included. the total number of variables in the resulting models varied between 300k ( core ) to 350k ( core + mtw ). we used a modified version of libfm for training. 4 our version adds support for bpr and parallelizes the training algorithm. methodology. to evaluate the prediction performance of each method, we followed  #TAUTHOR_TAG. we considered a collection of 19 freebase relations ( tab. 2 )', 'and 10 surface', 'relations ( tab. 3 ) and restrict predictions to tuples in the evaluation set. evaluation metrics. for each relation and method, we computed the top - 100 evaluation', 'set predictions', 'and labeled them manually. we used as', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['model ( fe', ') of  #TAUTHOR_TAG']","['', 'do not appear in the kb. in this paper, we propose core, a flexible open re model that leverages contextual information. core is inspired by the combined factorization and entity model ( fe', ') of  #TAUTHOR_TAG. as fe, core associates latent semantic representations', 'with entities, relations, and arguments. in contrast to fe, core uses factorization machines  #AUTHOR_TAG as its underlying framework, which allows us to incorporate context', 'in a flexible way. core is able to leverage and integrate arbitrary contextual information associated with the input facts into its open re factorization model. to', 'support reasoning under the openworld assumption, we propose an efficient method for parameter estimation in factorization machines based on bayesian personalized ranking  #AUTHOR_TAG', '. we conducted an experimental study on a realworld dataset using contextual information along the lines mentioned above. our', 'model is extensible, i. e., additional contextual information can be integrated when available. even', 'with limited amount of contextual information used in our experiments, our core model provided higher prediction performance than previous models. our findings validate the usefulness of contextual information for the open re task']",6
"['.', 'we made use of the dataset of  #TAUTHOR_TAG, but extended']","['.', 'we made use of the dataset of  #TAUTHOR_TAG, but extended']","['.', 'we made use of the dataset of  #TAUTHOR_TAG, but extended']","['.', 'we made use of the dataset of  #TAUTHOR_TAG, but extended it with contextual information.', 'the dataset consisted of 2. 5m surface facts extracted from the new york times corpus  #AUTHOR_TAG, as well as 16k facts from freebase.', 'surface facts have been obtained by using a named - entity recognizer, which additionally labeled each named entity mention with its coarse - grained type ( i. e., person, organization, location, miscellaneous ).', 'for each pair of entities found within a sentence, the shortest dependency path between these pairs was taken as surface relation.', 'the entity mentions in each surface fact were linked to freebase using a simple string']",6
"['of  #TAUTHOR_TAG,']","['of  #TAUTHOR_TAG, which combines']","['of  #TAUTHOR_TAG,']","['', '- and ( 2 ) that they scale much better with the number of relations', '. examples of', 'such matrix factorization models include  #AUTHOR_TAG. have also shown that a combination of matrix and tensor factorization models can be fruitful. closest to our work is the "" universal schema ""', 'matrix factorization approach of  #TAUTHOR_TAG, which combines a latent features model, a neighborhood model and an entity model but does not incorporate context. our core model follows the universal schema idea, but uses a more general factorization model, which includes the information captured', 'by the latent features and entity model ( but not the neighborhood model ), and incorporates contextual information. using contextual information. it is well known', 'that contextual information can improve ie methods. information such as bag - of - words, part - ofspeech tags, entity types, or parse trees have been', 'integrated into many', 'existing systems  #AUTHOR_TAG de  #AUTHOR_TAG. our work differs in that we integrate contextual information into an open re system. to', 'do so, we leverage factorization machines  #AUTHOR_TAG, which have been successfully applied to exploit contextual information', 'in the context of recommender systems. we show how to model open re data and context with factorization machines and provide a method for parameter estimation under the open - world assumption']",3
"[' #TAUTHOR_TAG. in more detail, we ( conceptually ) build a negative sample set']","[' #TAUTHOR_TAG. in more detail, we ( conceptually ) build a negative sample set x']","[' #TAUTHOR_TAG. in more detail, we ( conceptually ) build a negative sample set']",[' #TAUTHOR_TAG'],5
"[' #TAUTHOR_TAG. in more detail, we ( conceptually ) build a negative sample set']","[' #TAUTHOR_TAG. in more detail, we ( conceptually ) build a negative sample set x']","[' #TAUTHOR_TAG. in more detail, we ( conceptually ) build a negative sample set']",[' #TAUTHOR_TAG'],5
"['approaches.', '2 our experimental study closely follows the one of  #TAUTHOR_TAG']","['core model with other state - of - the - art approaches.', '2 our experimental study closely follows the one of  #TAUTHOR_TAG']","['core model with other state - of - the - art approaches.', '2 our experimental study closely follows the one of  #TAUTHOR_TAG']","['conducted an experimental study on realworld data to compare our core model with other state - of - the - art approaches.', '2 our experimental study closely follows the one of  #TAUTHOR_TAG']",5
['experimental study of  #TAUTHOR_TAG'],"['experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing by the amount of context being used. we consider as context the article metadata (', 'm ), the tuple types ( t', ') and', 'the bag - of - words ( w ). each tuple type is', 'a pair of subject - object types of ( e. g. ( person, location ) ). the basic core model uses relations, tuples and entities', 'as variables. we additionally consider the core + t, core + w, core + mt,', 'and core + mtw models, where the suffix indicates which contextual information has been included. the total number of variables in the resulting models varied between 300k ( core ) to 350k ( core + mtw ). we used a modified version of libfm for training. 4 our version adds support for bpr and parallelizes the training algorithm. methodology. to evaluate the prediction performance of each method, we followed  #TAUTHOR_TAG. we considered a collection of 19 freebase relations ( tab. 2 )', 'and 10 surface', 'relations ( tab. 3 ) and restrict predictions to tuples in the evaluation set. evaluation metrics. for each relation and method, we computed the top - 100 evaluation', 'set predictions', 'and labeled them manually. we used as', '']",5
['experimental study of  #TAUTHOR_TAG'],"['experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing by the amount of context being used. we consider as context the article metadata (', 'm ), the tuple types ( t', ') and', 'the bag - of - words ( w ). each tuple type is', 'a pair of subject - object types of ( e. g. ( person, location ) ). the basic core model uses relations, tuples and entities', 'as variables. we additionally consider the core + t, core + w, core + mt,', 'and core + mtw models, where the suffix indicates which contextual information has been included. the total number of variables in the resulting models varied between 300k ( core ) to 350k ( core + mtw ). we used a modified version of libfm for training. 4 our version adds support for bpr and parallelizes the training algorithm. methodology. to evaluate the prediction performance of each method, we followed  #TAUTHOR_TAG. we considered a collection of 19 freebase relations ( tab. 2 )', 'and 10 surface', 'relations ( tab. 3 ) and restrict predictions to tuples in the evaluation set. evaluation metrics. for each relation and method, we computed the top - 100 evaluation', 'set predictions', 'and labeled them manually. we used as', '']",5
['experimental study of  #TAUTHOR_TAG'],"['experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing by the amount of context being used. we consider as context the article metadata (', 'm ), the tuple types ( t', ') and', 'the bag - of - words ( w ). each tuple type is', 'a pair of subject - object types of ( e. g. ( person, location ) ). the basic core model uses relations, tuples and entities', 'as variables. we additionally consider the core + t, core + w, core + mt,', 'and core + mtw models, where the suffix indicates which contextual information has been included. the total number of variables in the resulting models varied between 300k ( core ) to 350k ( core + mtw ). we used a modified version of libfm for training. 4 our version adds support for bpr and parallelizes the training algorithm. methodology. to evaluate the prediction performance of each method, we followed  #TAUTHOR_TAG. we considered a collection of 19 freebase relations ( tab. 2 )', 'and 10 surface', 'relations ( tab. 3 ) and restrict predictions to tuples in the evaluation set. evaluation metrics. for each relation and method, we computed the top - 100 evaluation', 'set predictions', 'and labeled them manually. we used as', '']",5
['experimental study of  #TAUTHOR_TAG'],"['experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing by the amount of context being used. we consider as context the article metadata (', 'm ), the tuple types ( t', ') and', 'the bag - of - words ( w ). each tuple type is', 'a pair of subject - object types of ( e. g. ( person, location ) ). the basic core model uses relations, tuples and entities', 'as variables. we additionally consider the core + t, core + w, core + mt,', 'and core + mtw models, where the suffix indicates which contextual information has been included. the total number of variables in the resulting models varied between 300k ( core ) to 350k ( core + mtw ). we used a modified version of libfm for training. 4 our version adds support for bpr and parallelizes the training algorithm. methodology. to evaluate the prediction performance of each method, we followed  #TAUTHOR_TAG. we considered a collection of 19 freebase relations ( tab. 2 )', 'and 10 surface', 'relations ( tab. 3 ) and restrict predictions to tuples in the evaluation set. evaluation metrics. for each relation and method, we computed the top - 100 evaluation', 'set predictions', 'and labeled them manually. we used as', '']",5
['experimental study of  #TAUTHOR_TAG'],"['experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing by the amount of context being used. we consider as context the article metadata (', 'm ), the tuple types ( t', ') and', 'the bag - of - words ( w ). each tuple type is', 'a pair of subject - object types of ( e. g. ( person, location ) ). the basic core model uses relations, tuples and entities', 'as variables. we additionally consider the core + t, core + w, core + mt,', 'and core + mtw models, where the suffix indicates which contextual information has been included. the total number of variables in the resulting models varied between 300k ( core ) to 350k ( core + mtw ). we used a modified version of libfm for training. 4 our version adds support for bpr and parallelizes the training algorithm. methodology. to evaluate the prediction performance of each method, we followed  #TAUTHOR_TAG. we considered a collection of 19 freebase relations ( tab. 2 )', 'and 10 surface', 'relations ( tab. 3 ) and restrict predictions to tuples in the evaluation set. evaluation metrics. for each relation and method, we computed the top - 100 evaluation', 'set predictions', 'and labeled them manually. we used as', '']",5
['experimental study of  #TAUTHOR_TAG'],"['experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing by the amount of context being used. we consider as context the article metadata (', 'm ), the tuple types ( t', ') and', 'the bag - of - words ( w ). each tuple type is', 'a pair of subject - object types of ( e. g. ( person, location ) ). the basic core model uses relations, tuples and entities', 'as variables. we additionally consider the core + t, core + w, core + mt,', 'and core + mtw models, where the suffix indicates which contextual information has been included. the total number of variables in the resulting models varied between 300k ( core ) to 350k ( core + mtw ). we used a modified version of libfm for training. 4 our version adds support for bpr and parallelizes the training algorithm. methodology. to evaluate the prediction performance of each method, we followed  #TAUTHOR_TAG. we considered a collection of 19 freebase relations ( tab. 2 )', 'and 10 surface', 'relations ( tab. 3 ) and restrict predictions to tuples in the evaluation set. evaluation metrics. for each relation and method, we computed the top - 100 evaluation', 'set predictions', 'and labeled them manually. we used as', '']",4
['experimental study of  #TAUTHOR_TAG'],"['experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing by the amount of context being used. we consider as context the article metadata (', 'm ), the tuple types ( t', ') and', 'the bag - of - words ( w ). each tuple type is', 'a pair of subject - object types of ( e. g. ( person, location ) ). the basic core model uses relations, tuples and entities', 'as variables. we additionally consider the core + t, core + w, core + mt,', 'and core + mtw models, where the suffix indicates which contextual information has been included. the total number of variables in the resulting models varied between 300k ( core ) to 350k ( core + mtw ). we used a modified version of libfm for training. 4 our version adds support for bpr and parallelizes the training algorithm. methodology. to evaluate the prediction performance of each method, we followed  #TAUTHOR_TAG. we considered a collection of 19 freebase relations ( tab. 2 )', 'and 10 surface', 'relations ( tab. 3 ) and restrict predictions to tuples in the evaluation set. evaluation metrics. for each relation and method, we computed the top - 100 evaluation', 'set predictions', 'and labeled them manually. we used as', '']",4
['experimental study of  #TAUTHOR_TAG'],"['experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing']","['models as well as clustering methods and distantly supervised methods in the experimental study of  #TAUTHOR_TAG for', 'open re tasks. we use the original source code of  #TAUTHOR_TAG for training. core. we include multiple variants of our model in the experimental study', ', each differing by the amount of context being used. we consider as context the article metadata (', 'm ), the tuple types ( t', ') and', 'the bag - of - words ( w ). each tuple type is', 'a pair of subject - object types of ( e. g. ( person, location ) ). the basic core model uses relations, tuples and entities', 'as variables. we additionally consider the core + t, core + w, core + mt,', 'and core + mtw models, where the suffix indicates which contextual information has been included. the total number of variables in the resulting models varied between 300k ( core ) to 350k ( core + mtw ). we used a modified version of libfm for training. 4 our version adds support for bpr and parallelizes the training algorithm. methodology. to evaluate the prediction performance of each method, we followed  #TAUTHOR_TAG. we considered a collection of 19 freebase relations ( tab. 2 )', 'and 10 surface', 'relations ( tab. 3 ) and restrict predictions to tuples in the evaluation set. evaluation metrics. for each relation and method, we computed the top - 100 evaluation', 'set predictions', 'and labeled them manually. we used as', '']",4
"['have taken into consideration previously studied features of readability ( francois and  #TAUTHOR_TAG, l2 swedish curric']","['have taken into consideration previously studied features of readability ( francois and  #TAUTHOR_TAG, l2 swedish curricula  #AUTHOR_TAG and']","['the selection of linguistic indicators, we have taken into consideration previously studied features of readability ( francois and  #TAUTHOR_TAG, l2 swedish curricula  #AUTHOR_TAG and']","['', 'we propose a rule - based as well as a combination of rule - based and machine learning methods for the identification of sentences understandable by l2 learners and suitable as exercise items.', 'during the selection of linguistic indicators, we have taken into consideration previously studied features of readability ( francois and  #TAUTHOR_TAG, l2 swedish curricula  #AUTHOR_TAG and aspects of good dictionary examples ( gdex ) ( husak, 2010 ;  #AUTHOR_TAG, being that we believe they have some properties in common with exercise items.', 'the current version of the machine learning model distinguishes sentences readable by students at an intermediate level of proficiency from sentences of a higher readability level.', 'the approaches have been implemented and integrated into an online intelligent computerassisted language learning ( icall ) platform, larka.', 'besides a module where users can experiment with the filtering of corpus hits, a module with inflectional and vocabulary exercises ( making use of the selected sentences with our method ) is also available.', 'an initial evaluation with students, teachers and linguists indicated that more than 70 % of the sentences selected were understandable, and about 60 % of them would be suitable as exercise items according']",3
"[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","['similarly to heimann muhlenbock ( 2013 ). variation features ( modvar, advvar ) measured the ratio of a morph', '##osyntactic category to the number of lexical ( content ) words in the sentence', ', as in  #AUTHOR_TAG. these lexical categories comprised nouns, verbs, adverbs and adjectives. subordinates (', '11 ) were detected on the basis of the "" ua "" ( subordinate clause minus sub', '##ordinating conjunction ) dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability at the text level in heimann muhlenbock (', '2013 ) and  #TAUTHOR_TAG respectively. the lexical - morphological features ( features 13 - 25 ) constituted the largest group. difficulty at', 'the lexical level was determined based on both the ttr feature mentioned above, expressing vocabulary diversity, and on the basis of the', 'rarity of words ( features 13 - 17 ) according to', 'the kelly list and the wikipedia word list. an analogous approach was adopted also by francois and  #AUTHOR_TAG,  #AUTHOR_TAG and heimann muhlenbock ( 2013 ) with positive results. the lexd feature considers the ratio of lexical words ( nouns, verbs, adjectives and', 'adverbs ) to the sum of tokens in the sentence  #AUTHOR_TAG. the nn / vb ratio feature, which has a higher value in written text, can also indicate a more complex sentence', ' #TAUTHOR_TAG. features 21 - 25 are based on evidence from the content of', 'l2 swedish course syllabuses  #AUTHOR_TAG and course books  #AUTHOR_TAG, part of them being language - dependent, namely s - vb / vb and s - vb', '%. these two features cover different types of swedish verbs ending in - s which can indicate either a reciprocal verb, a passive construction or a deponent verb, active in meaning but passive in form  #AUTHOR_TAG. our feature', 'set included three semantic features ( 26 - 28 ). the intuition behind 28 is', 'that words with multiple senses ( polysemous words ), increase reading complexity as, in order to understand the sentence, word senses need to be disambiguated  #AUTHOR_TAG. this feature was computed by counting the number of sense ids per token according to a', 'lexical - semantic resource for swedish, saldo  #AUTHOR_TAG, and dividing this value by the number of tokens in the sentence. as pronouns indicate', 'a potentially more difficult text  #AUTHOR_TAG, we included pn / nn in our set. both nomr and pn / nn capture idea density, i. e.', 'how complex the relation between the ideas expressed are  #TAUTHOR_TAG']",3
"[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","['similarly to heimann muhlenbock ( 2013 ). variation features ( modvar, advvar ) measured the ratio of a morph', '##osyntactic category to the number of lexical ( content ) words in the sentence', ', as in  #AUTHOR_TAG. these lexical categories comprised nouns, verbs, adverbs and adjectives. subordinates (', '11 ) were detected on the basis of the "" ua "" ( subordinate clause minus sub', '##ordinating conjunction ) dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability at the text level in heimann muhlenbock (', '2013 ) and  #TAUTHOR_TAG respectively. the lexical - morphological features ( features 13 - 25 ) constituted the largest group. difficulty at', 'the lexical level was determined based on both the ttr feature mentioned above, expressing vocabulary diversity, and on the basis of the', 'rarity of words ( features 13 - 17 ) according to', 'the kelly list and the wikipedia word list. an analogous approach was adopted also by francois and  #AUTHOR_TAG,  #AUTHOR_TAG and heimann muhlenbock ( 2013 ) with positive results. the lexd feature considers the ratio of lexical words ( nouns, verbs, adjectives and', 'adverbs ) to the sum of tokens in the sentence  #AUTHOR_TAG. the nn / vb ratio feature, which has a higher value in written text, can also indicate a more complex sentence', ' #TAUTHOR_TAG. features 21 - 25 are based on evidence from the content of', 'l2 swedish course syllabuses  #AUTHOR_TAG and course books  #AUTHOR_TAG, part of them being language - dependent, namely s - vb / vb and s - vb', '%. these two features cover different types of swedish verbs ending in - s which can indicate either a reciprocal verb, a passive construction or a deponent verb, active in meaning but passive in form  #AUTHOR_TAG. our feature', 'set included three semantic features ( 26 - 28 ). the intuition behind 28 is', 'that words with multiple senses ( polysemous words ), increase reading complexity as, in order to understand the sentence, word senses need to be disambiguated  #AUTHOR_TAG. this feature was computed by counting the number of sense ids per token according to a', 'lexical - semantic resource for swedish, saldo  #AUTHOR_TAG, and dividing this value by the number of tokens in the sentence. as pronouns indicate', 'a potentially more difficult text  #AUTHOR_TAG, we included pn / nn in our set. both nomr and pn / nn capture idea density, i. e.', 'how complex the relation between the ideas expressed are  #TAUTHOR_TAG']",3
"[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","['similarly to heimann muhlenbock ( 2013 ). variation features ( modvar, advvar ) measured the ratio of a morph', '##osyntactic category to the number of lexical ( content ) words in the sentence', ', as in  #AUTHOR_TAG. these lexical categories comprised nouns, verbs, adverbs and adjectives. subordinates (', '11 ) were detected on the basis of the "" ua "" ( subordinate clause minus sub', '##ordinating conjunction ) dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability at the text level in heimann muhlenbock (', '2013 ) and  #TAUTHOR_TAG respectively. the lexical - morphological features ( features 13 - 25 ) constituted the largest group. difficulty at', 'the lexical level was determined based on both the ttr feature mentioned above, expressing vocabulary diversity, and on the basis of the', 'rarity of words ( features 13 - 17 ) according to', 'the kelly list and the wikipedia word list. an analogous approach was adopted also by francois and  #AUTHOR_TAG,  #AUTHOR_TAG and heimann muhlenbock ( 2013 ) with positive results. the lexd feature considers the ratio of lexical words ( nouns, verbs, adjectives and', 'adverbs ) to the sum of tokens in the sentence  #AUTHOR_TAG. the nn / vb ratio feature, which has a higher value in written text, can also indicate a more complex sentence', ' #TAUTHOR_TAG. features 21 - 25 are based on evidence from the content of', 'l2 swedish course syllabuses  #AUTHOR_TAG and course books  #AUTHOR_TAG, part of them being language - dependent, namely s - vb / vb and s - vb', '%. these two features cover different types of swedish verbs ending in - s which can indicate either a reciprocal verb, a passive construction or a deponent verb, active in meaning but passive in form  #AUTHOR_TAG. our feature', 'set included three semantic features ( 26 - 28 ). the intuition behind 28 is', 'that words with multiple senses ( polysemous words ), increase reading complexity as, in order to understand the sentence, word senses need to be disambiguated  #AUTHOR_TAG. this feature was computed by counting the number of sense ids per token according to a', 'lexical - semantic resource for swedish, saldo  #AUTHOR_TAG, and dividing this value by the number of tokens in the sentence. as pronouns indicate', 'a potentially more difficult text  #AUTHOR_TAG, we included pn / nn in our set. both nomr and pn / nn capture idea density, i. e.', 'how complex the relation between the ideas expressed are  #TAUTHOR_TAG']",3
"['##ois and  #TAUTHOR_TAG.', 'lexical - morphological features based on information']","[""studies  #AUTHOR_TAG dell' #AUTHOR_TAG francois and  #TAUTHOR_TAG."", 'lexical - morphological features based on information']","[""'  #AUTHOR_TAG francois and  #TAUTHOR_TAG."", 'lexical - morphological features based on information']","['experimenting with the complete feature set, groups of features were also separately tested.', 'the results are presented in table 4.', 'terestingly, although semantic features represented the smallest group, they performed 2 % better than traditional or syntactic features.', 'the largest group of features including lexical - morphological indicators performed around 10 % more accurately than other feature groups.', 'among the 10 features that influenced most the decisions of our svm classifier, we can find attributes from different feature groups.', 'the id of these features together with the svm weights are reported in table 5.', ""an informative traditional measure was sentence length, similarly to the results of previous studies  #AUTHOR_TAG dell' #AUTHOR_TAG francois and  #TAUTHOR_TAG."", 'lexical - morphological features based on information about the frequency and the cefr level of items in the kelly list ( diffw %, diffws and kellyfr ) also proved to be influential for the classification, as well as advvar.', 'two out of our three semantic features, namely nomr and, in particular, sense / w, were also highly predictive.', 'syntactic features ddep / sentlen and deepdep, based on information about dependency arcs, were also among the ten features with highest weights, but they were somewhat less useful, as the weights in table 5 show.', 'contrary to our results, francois and  #AUTHOR_TAG found syntactic features more informative than semantic ones for l2 french.', 'this may depend either on the difference between the features used or the target languages.', 'moreover, in the case of swedish l1 text readability the noun / pronoun ratio and modifiers proved to be indicative of textlevel difficulty  #TAUTHOR_TAG, but at the sentence level from the l2 perspective only the latter seemed influential in our experiments.', 'the data used for the experiments was labeled for cefr levels at the text level, not at the sentence level.', 'this introduced some noise in the data and made the classification task somewhat harder.', 'in the future, the availability of data labeled at the sentence level could contribute to more accurate results.', ""excluding potentially lower level sentences from those appearing in higher level texts based on the distance between feature vectors could also be explored, in a similar fashion to dell' #AUTHOR_TAG."", '5 heuristics : gdex parameters for sentence filtering and ranking', 'besides svm classification, our sentence selection module, hit - ex, offers also a number of heuristic parameter options 5, usable either in combination or as an alternative to the machine learning model ( for further details see section 6 ).', 'part of these search parameters are generic preferences including the keyword to search for, its pos, the corpora from korp to be used during']",3
"['have taken into consideration previously studied features of readability ( francois and  #TAUTHOR_TAG, l2 swedish curric']","['have taken into consideration previously studied features of readability ( francois and  #TAUTHOR_TAG, l2 swedish curricula  #AUTHOR_TAG and']","['the selection of linguistic indicators, we have taken into consideration previously studied features of readability ( francois and  #TAUTHOR_TAG, l2 swedish curricula  #AUTHOR_TAG and']","['', 'we propose a rule - based as well as a combination of rule - based and machine learning methods for the identification of sentences understandable by l2 learners and suitable as exercise items.', 'during the selection of linguistic indicators, we have taken into consideration previously studied features of readability ( francois and  #TAUTHOR_TAG, l2 swedish curricula  #AUTHOR_TAG and aspects of good dictionary examples ( gdex ) ( husak, 2010 ;  #AUTHOR_TAG, being that we believe they have some properties in common with exercise items.', 'the current version of the machine learning model distinguishes sentences readable by students at an intermediate level of proficiency from sentences of a higher readability level.', 'the approaches have been implemented and integrated into an online intelligent computerassisted language learning ( icall ) platform, larka.', 'besides a module where users can experiment with the filtering of corpus hits, a module with inflectional and vocabulary exercises ( making use of the selected sentences with our method ) is also available.', 'an initial evaluation with students, teachers and linguists indicated that more than 70 % of the sentences selected were understandable, and about 60 % of them would be suitable as exercise items according']",5
"[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","['similarly to heimann muhlenbock ( 2013 ). variation features ( modvar, advvar ) measured the ratio of a morph', '##osyntactic category to the number of lexical ( content ) words in the sentence', ', as in  #AUTHOR_TAG. these lexical categories comprised nouns, verbs, adverbs and adjectives. subordinates (', '11 ) were detected on the basis of the "" ua "" ( subordinate clause minus sub', '##ordinating conjunction ) dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability at the text level in heimann muhlenbock (', '2013 ) and  #TAUTHOR_TAG respectively. the lexical - morphological features ( features 13 - 25 ) constituted the largest group. difficulty at', 'the lexical level was determined based on both the ttr feature mentioned above, expressing vocabulary diversity, and on the basis of the', 'rarity of words ( features 13 - 17 ) according to', 'the kelly list and the wikipedia word list. an analogous approach was adopted also by francois and  #AUTHOR_TAG,  #AUTHOR_TAG and heimann muhlenbock ( 2013 ) with positive results. the lexd feature considers the ratio of lexical words ( nouns, verbs, adjectives and', 'adverbs ) to the sum of tokens in the sentence  #AUTHOR_TAG. the nn / vb ratio feature, which has a higher value in written text, can also indicate a more complex sentence', ' #TAUTHOR_TAG. features 21 - 25 are based on evidence from the content of', 'l2 swedish course syllabuses  #AUTHOR_TAG and course books  #AUTHOR_TAG, part of them being language - dependent, namely s - vb / vb and s - vb', '%. these two features cover different types of swedish verbs ending in - s which can indicate either a reciprocal verb, a passive construction or a deponent verb, active in meaning but passive in form  #AUTHOR_TAG. our feature', 'set included three semantic features ( 26 - 28 ). the intuition behind 28 is', 'that words with multiple senses ( polysemous words ), increase reading complexity as, in order to understand the sentence, word senses need to be disambiguated  #AUTHOR_TAG. this feature was computed by counting the number of sense ids per token according to a', 'lexical - semantic resource for swedish, saldo  #AUTHOR_TAG, and dividing this value by the number of tokens in the sentence. as pronouns indicate', 'a potentially more difficult text  #AUTHOR_TAG, we included pn / nn in our set. both nomr and pn / nn capture idea density, i. e.', 'how complex the relation between the ideas expressed are  #TAUTHOR_TAG']",5
"[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","['similarly to heimann muhlenbock ( 2013 ). variation features ( modvar, advvar ) measured the ratio of a morph', '##osyntactic category to the number of lexical ( content ) words in the sentence', ', as in  #AUTHOR_TAG. these lexical categories comprised nouns, verbs, adverbs and adjectives. subordinates (', '11 ) were detected on the basis of the "" ua "" ( subordinate clause minus sub', '##ordinating conjunction ) dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability at the text level in heimann muhlenbock (', '2013 ) and  #TAUTHOR_TAG respectively. the lexical - morphological features ( features 13 - 25 ) constituted the largest group. difficulty at', 'the lexical level was determined based on both the ttr feature mentioned above, expressing vocabulary diversity, and on the basis of the', 'rarity of words ( features 13 - 17 ) according to', 'the kelly list and the wikipedia word list. an analogous approach was adopted also by francois and  #AUTHOR_TAG,  #AUTHOR_TAG and heimann muhlenbock ( 2013 ) with positive results. the lexd feature considers the ratio of lexical words ( nouns, verbs, adjectives and', 'adverbs ) to the sum of tokens in the sentence  #AUTHOR_TAG. the nn / vb ratio feature, which has a higher value in written text, can also indicate a more complex sentence', ' #TAUTHOR_TAG. features 21 - 25 are based on evidence from the content of', 'l2 swedish course syllabuses  #AUTHOR_TAG and course books  #AUTHOR_TAG, part of them being language - dependent, namely s - vb / vb and s - vb', '%. these two features cover different types of swedish verbs ending in - s which can indicate either a reciprocal verb, a passive construction or a deponent verb, active in meaning but passive in form  #AUTHOR_TAG. our feature', 'set included three semantic features ( 26 - 28 ). the intuition behind 28 is', 'that words with multiple senses ( polysemous words ), increase reading complexity as, in order to understand the sentence, word senses need to be disambiguated  #AUTHOR_TAG. this feature was computed by counting the number of sense ids per token according to a', 'lexical - semantic resource for swedish, saldo  #AUTHOR_TAG, and dividing this value by the number of tokens in the sentence. as pronouns indicate', 'a potentially more difficult text  #AUTHOR_TAG, we included pn / nn in our set. both nomr and pn / nn capture idea density, i. e.', 'how complex the relation between the ideas expressed are  #TAUTHOR_TAG']",5
"['##bock ( 2013 ) and  #TAUTHOR_TAG.', 'he']","['also cohesion in texts.', 'research on l1 readability for swedish, using machine learning, is described in heimann muhlenbock ( 2013 ) and  #TAUTHOR_TAG.', 'heimann muhlenbock ( 2013 ) examined readability']","['##n muhlenbock ( 2013 ) and  #TAUTHOR_TAG.', 'he']","['##ability of texts in different languages has been the subject of several studies and they range from simpler formulas, taking into account superficial text properties, to more sophisticated nlp methods.', 'traditional readability measures for l1 swedish at the text level include lix ( lasbarthetsindex, "" readability index "" ) ( bjornsson, 1968 ) and the nominal ratio  #AUTHOR_TAG.', 'in recent years a number of studies, mostly focusing on the l1 context, appeared which take into consideration linguistic features based on a deeper text processing.', ""morphosyntactic aspects informative for l1 readability include, among others, parse tree depth, subordination features and dependency link depth ( length ) ( dell' #AUTHOR_TAG."", 'language models have also been commonly used for readability predictions ( collins -  #AUTHOR_TAG.', 'a recently proposed measure, the coh - metrix  #AUTHOR_TAG, aims at a multilevel analysis of texts, inspired by psycholinguistic principles.', 'it measures not only linguistic difficulty, but also cohesion in texts.', 'research on l1 readability for swedish, using machine learning, is described in heimann muhlenbock ( 2013 ) and  #TAUTHOR_TAG.', 'heimann muhlenbock ( 2013 ) examined readability along five dimensions : surface features, word usage, sentence structure, idea density and human interest.', 'mean dependency distance, subordinate clauses and modifiers proved good predictors for l1 swedish.', 'although a number of readability formulas exist for native language users, these might not be suitable predictors of l2 difficulty being that the acquisition processes of l1 and l2 present a number of differences  #AUTHOR_TAG.', 'studies focusing on l2 readability are considerably fewer in the literature.', 'the linguistic features in this context include, among others, relative clauses, passive voice  #AUTHOR_TAG and the number of coordinate phrases per clause  #AUTHOR_TAG.', ' #AUTHOR_TAG applied some coh - metrix indicators to english l2 readability.', 'the authors found that lexical coreferentiality, syntactic similarity and word frequency measures outperformed traditional l1 readability formulas.', 'a language - independent approach to l2 readability assessment, using an online machine learning algorithm, is presented by  #AUTHOR_TAG which, however, employed only the surface features of average sentence and word length, and word frequencies as lexical feature.', 'the authors found that none of the features in isolation was able to clearly distinguish between the levels.', 'in the second language teaching scenario, a widely used scale is the common european framework of reference for languages ( cefr ) ( council of  #AUTHOR_TAG, which, however, has been less frequently adopted so far in readability studies']",0
"[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","['similarly to heimann muhlenbock ( 2013 ). variation features ( modvar, advvar ) measured the ratio of a morph', '##osyntactic category to the number of lexical ( content ) words in the sentence', ', as in  #AUTHOR_TAG. these lexical categories comprised nouns, verbs, adverbs and adjectives. subordinates (', '11 ) were detected on the basis of the "" ua "" ( subordinate clause minus sub', '##ordinating conjunction ) dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability at the text level in heimann muhlenbock (', '2013 ) and  #TAUTHOR_TAG respectively. the lexical - morphological features ( features 13 - 25 ) constituted the largest group. difficulty at', 'the lexical level was determined based on both the ttr feature mentioned above, expressing vocabulary diversity, and on the basis of the', 'rarity of words ( features 13 - 17 ) according to', 'the kelly list and the wikipedia word list. an analogous approach was adopted also by francois and  #AUTHOR_TAG,  #AUTHOR_TAG and heimann muhlenbock ( 2013 ) with positive results. the lexd feature considers the ratio of lexical words ( nouns, verbs, adjectives and', 'adverbs ) to the sum of tokens in the sentence  #AUTHOR_TAG. the nn / vb ratio feature, which has a higher value in written text, can also indicate a more complex sentence', ' #TAUTHOR_TAG. features 21 - 25 are based on evidence from the content of', 'l2 swedish course syllabuses  #AUTHOR_TAG and course books  #AUTHOR_TAG, part of them being language - dependent, namely s - vb / vb and s - vb', '%. these two features cover different types of swedish verbs ending in - s which can indicate either a reciprocal verb, a passive construction or a deponent verb, active in meaning but passive in form  #AUTHOR_TAG. our feature', 'set included three semantic features ( 26 - 28 ). the intuition behind 28 is', 'that words with multiple senses ( polysemous words ), increase reading complexity as, in order to understand the sentence, word senses need to be disambiguated  #AUTHOR_TAG. this feature was computed by counting the number of sense ids per token according to a', 'lexical - semantic resource for swedish, saldo  #AUTHOR_TAG, and dividing this value by the number of tokens in the sentence. as pronouns indicate', 'a potentially more difficult text  #AUTHOR_TAG, we included pn / nn in our set. both nomr and pn / nn capture idea density, i. e.', 'how complex the relation between the ideas expressed are  #TAUTHOR_TAG']",0
"[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability']","[') dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub']","['similarly to heimann muhlenbock ( 2013 ). variation features ( modvar, advvar ) measured the ratio of a morph', '##osyntactic category to the number of lexical ( content ) words in the sentence', ', as in  #AUTHOR_TAG. these lexical categories comprised nouns, verbs, adverbs and adjectives. subordinates (', '11 ) were detected on the basis of the "" ua "" ( subordinate clause minus sub', '##ordinating conjunction ) dependency relation tag  #TAUTHOR_TAG. features depdepth, mod, sub and rightdep, prepcomp', 'have previously been empoyed for swedish l1 readability at the text level in heimann muhlenbock (', '2013 ) and  #TAUTHOR_TAG respectively. the lexical - morphological features ( features 13 - 25 ) constituted the largest group. difficulty at', 'the lexical level was determined based on both the ttr feature mentioned above, expressing vocabulary diversity, and on the basis of the', 'rarity of words ( features 13 - 17 ) according to', 'the kelly list and the wikipedia word list. an analogous approach was adopted also by francois and  #AUTHOR_TAG,  #AUTHOR_TAG and heimann muhlenbock ( 2013 ) with positive results. the lexd feature considers the ratio of lexical words ( nouns, verbs, adjectives and', 'adverbs ) to the sum of tokens in the sentence  #AUTHOR_TAG. the nn / vb ratio feature, which has a higher value in written text, can also indicate a more complex sentence', ' #TAUTHOR_TAG. features 21 - 25 are based on evidence from the content of', 'l2 swedish course syllabuses  #AUTHOR_TAG and course books  #AUTHOR_TAG, part of them being language - dependent, namely s - vb / vb and s - vb', '%. these two features cover different types of swedish verbs ending in - s which can indicate either a reciprocal verb, a passive construction or a deponent verb, active in meaning but passive in form  #AUTHOR_TAG. our feature', 'set included three semantic features ( 26 - 28 ). the intuition behind 28 is', 'that words with multiple senses ( polysemous words ), increase reading complexity as, in order to understand the sentence, word senses need to be disambiguated  #AUTHOR_TAG. this feature was computed by counting the number of sense ids per token according to a', 'lexical - semantic resource for swedish, saldo  #AUTHOR_TAG, and dividing this value by the number of tokens in the sentence. as pronouns indicate', 'a potentially more difficult text  #AUTHOR_TAG, we included pn / nn in our set. both nomr and pn / nn capture idea density, i. e.', 'how complex the relation between the ideas expressed are  #TAUTHOR_TAG']",0
"['##1 swedish text - level readability study  #TAUTHOR_TAG.', 'another classification']","['of easy - to - read texts within an l1 swedish text - level readability study  #TAUTHOR_TAG.', 'another classification']","['- read texts within an l1 swedish text - level readability study  #TAUTHOR_TAG.', 'another classification']","['results obtained using the complete set of 28 features is shown in table 3.', 'the results of the svm are presented in comparison to a baseline classifier assigning the most frequent output label in the dataset to each instance.', 'classes was about 50 - 50 %.', 'the svm classified 7 out of 10 sentences accurately.', 'the precision and recall values for the identification of b1 sentences was 73 % and 68 %.', 'previous classification results for a similar task obtained an average of 77. 25 % of precision for the classification of easy - to - read texts within an l1 swedish text - level readability study  #TAUTHOR_TAG.', ""another classification at the sentence level, but for italian and from an l1 perspective achieved an accuracy of 78. 2 %, thus 7 % higher compared to our results ( dell' #AUTHOR_TAG."", '']",4
"['##ois and  #TAUTHOR_TAG.', 'lexical - morphological features based on information']","[""studies  #AUTHOR_TAG dell' #AUTHOR_TAG francois and  #TAUTHOR_TAG."", 'lexical - morphological features based on information']","[""'  #AUTHOR_TAG francois and  #TAUTHOR_TAG."", 'lexical - morphological features based on information']","['experimenting with the complete feature set, groups of features were also separately tested.', 'the results are presented in table 4.', 'terestingly, although semantic features represented the smallest group, they performed 2 % better than traditional or syntactic features.', 'the largest group of features including lexical - morphological indicators performed around 10 % more accurately than other feature groups.', 'among the 10 features that influenced most the decisions of our svm classifier, we can find attributes from different feature groups.', 'the id of these features together with the svm weights are reported in table 5.', ""an informative traditional measure was sentence length, similarly to the results of previous studies  #AUTHOR_TAG dell' #AUTHOR_TAG francois and  #TAUTHOR_TAG."", 'lexical - morphological features based on information about the frequency and the cefr level of items in the kelly list ( diffw %, diffws and kellyfr ) also proved to be influential for the classification, as well as advvar.', 'two out of our three semantic features, namely nomr and, in particular, sense / w, were also highly predictive.', 'syntactic features ddep / sentlen and deepdep, based on information about dependency arcs, were also among the ten features with highest weights, but they were somewhat less useful, as the weights in table 5 show.', 'contrary to our results, francois and  #AUTHOR_TAG found syntactic features more informative than semantic ones for l2 french.', 'this may depend either on the difference between the features used or the target languages.', 'moreover, in the case of swedish l1 text readability the noun / pronoun ratio and modifiers proved to be indicative of textlevel difficulty  #TAUTHOR_TAG, but at the sentence level from the l2 perspective only the latter seemed influential in our experiments.', 'the data used for the experiments was labeled for cefr levels at the text level, not at the sentence level.', 'this introduced some noise in the data and made the classification task somewhat harder.', 'in the future, the availability of data labeled at the sentence level could contribute to more accurate results.', ""excluding potentially lower level sentences from those appearing in higher level texts based on the distance between feature vectors could also be explored, in a similar fashion to dell' #AUTHOR_TAG."", '5 heuristics : gdex parameters for sentence filtering and ranking', 'besides svm classification, our sentence selection module, hit - ex, offers also a number of heuristic parameter options 5, usable either in combination or as an alternative to the machine learning model ( for further details see section 6 ).', 'part of these search parameters are generic preferences including the keyword to search for, its pos, the corpora from korp to be used during']",4
['posed by the results of  #TAUTHOR_TAG :'],['posed by the results of  #TAUTHOR_TAG :'],"['posed by the results of  #TAUTHOR_TAG : how much, if']",[' #TAUTHOR_TAG'],0
['posed by the results of  #TAUTHOR_TAG :'],['posed by the results of  #TAUTHOR_TAG :'],"['posed by the results of  #TAUTHOR_TAG : how much, if']",[' #TAUTHOR_TAG'],0
['posed by the results of  #TAUTHOR_TAG :'],['posed by the results of  #TAUTHOR_TAG :'],"['posed by the results of  #TAUTHOR_TAG : how much, if']",[' #TAUTHOR_TAG'],0
"['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of']","['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i. e., sentences which']","['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of']","['research into rst - dt segmentation and parsing has focused on subsets of the 991 sentence test set during evaluation.', ' #AUTHOR_TAG omitted sentences that were not exactly spanned by a subtree of the treebank, so that they could focus on sentence - level discourse parsing.', 'by our count, this eliminates 40 of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i. e., sentences which themselves are atomic edus.', 'since the primary focus of this paper is on segmentation, there is no strong reason to omit any sentences from the test set, hence our results will evaluate on all 991 test sentences, with two exceptions.', 'first, in section 2. 3, we compare spade results under our configuration with results from  #TAUTHOR_TAG in order to establish comparability, and this is done on their 608 sentence subset.', 'second, in section 3. 2, we investigate feeding our segmentation into the spade system, in order to evaluate the impact of segmentation improvements on their sentence - level discourse parsing performance.', 'for those trials, the 951 sentence subset from  #AUTHOR_TAG is used.', '']",0
"['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of']","['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i. e., sentences which']","['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of']","['research into rst - dt segmentation and parsing has focused on subsets of the 991 sentence test set during evaluation.', ' #AUTHOR_TAG omitted sentences that were not exactly spanned by a subtree of the treebank, so that they could focus on sentence - level discourse parsing.', 'by our count, this eliminates 40 of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i. e., sentences which themselves are atomic edus.', 'since the primary focus of this paper is on segmentation, there is no strong reason to omit any sentences from the test set, hence our results will evaluate on all 991 test sentences, with two exceptions.', 'first, in section 2. 3, we compare spade results under our configuration with results from  #TAUTHOR_TAG in order to establish comparability, and this is done on their 608 sentence subset.', 'second, in section 3. 2, we investigate feeding our segmentation into the spade system, in order to evaluate the impact of segmentation improvements on their sentence - level discourse parsing performance.', 'for those trials, the 951 sentence subset from  #AUTHOR_TAG is used.', '']",0
['automatically created summary or compressed sentence  #TAUTHOR_TAG'],['automatically created summary or compressed sentence  #TAUTHOR_TAG'],"['automatically created summary or compressed sentence  #TAUTHOR_TAG.', 'once again, the finite - state system does not perform statistically significantly different from']","['has been shown that accurate discourse segmentation within a sentence greatly improves the overall parsing accuracy to near human levels  #AUTHOR_TAG.', 'given our improved segmentation results presented in the previous section, improvements would be expected in full sentencelevel discourse parsing.', 'to achieve this, we modified the spade script to accept our segmentations when building the fully hierarchical discourse tree.', 'the results for three systems are presented in table 3 : spade, our "" full finite - state "" system, and our system with all features.', 'results for unlabeled bracketing are presented, along with results for labeled bracketing, where the label is either nucleus or satellite, depending upon whether or not the node is more central ( nucleus ) to the coherence of the text than its sibling ( s ) ( satellite ).', 'this label set has been shown to be of particular utility for indicating which segments are more important to include in an automatically created summary or compressed sentence  #TAUTHOR_TAG.', 'once again, the finite - state system does not perform statistically significantly different from spade on either labeled or unlabeled discourse parsing.', 'using all features, however, results in greater than 5 % absolute accuracy improvement over both of these systems, which is significant, in all cases, at p < 0. 001']",0
['posed by the results of  #TAUTHOR_TAG :'],['posed by the results of  #TAUTHOR_TAG :'],"['posed by the results of  #TAUTHOR_TAG : how much, if']",[' #TAUTHOR_TAG'],1
"['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of']","['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i. e., sentences which']","['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of']","['research into rst - dt segmentation and parsing has focused on subsets of the 991 sentence test set during evaluation.', ' #AUTHOR_TAG omitted sentences that were not exactly spanned by a subtree of the treebank, so that they could focus on sentence - level discourse parsing.', 'by our count, this eliminates 40 of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i. e., sentences which themselves are atomic edus.', 'since the primary focus of this paper is on segmentation, there is no strong reason to omit any sentences from the test set, hence our results will evaluate on all 991 test sentences, with two exceptions.', 'first, in section 2. 3, we compare spade results under our configuration with results from  #TAUTHOR_TAG in order to establish comparability, and this is done on their 608 sentence subset.', 'second, in section 3. 2, we investigate feeding our segmentation into the spade system, in order to evaluate the impact of segmentation improvements on their sentence - level discourse parsing performance.', 'for those trials, the 951 sentence subset from  #AUTHOR_TAG is used.', '']",4
"['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of']","['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i. e., sentences which']","['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of']","['research into rst - dt segmentation and parsing has focused on subsets of the 991 sentence test set during evaluation.', ' #AUTHOR_TAG omitted sentences that were not exactly spanned by a subtree of the treebank, so that they could focus on sentence - level discourse parsing.', 'by our count, this eliminates 40 of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i. e., sentences which themselves are atomic edus.', 'since the primary focus of this paper is on segmentation, there is no strong reason to omit any sentences from the test set, hence our results will evaluate on all 991 test sentences, with two exceptions.', 'first, in section 2. 3, we compare spade results under our configuration with results from  #TAUTHOR_TAG in order to establish comparability, and this is done on their 608 sentence subset.', 'second, in section 3. 2, we investigate feeding our segmentation into the spade system, in order to evaluate the impact of segmentation improvements on their sentence - level discourse parsing performance.', 'for those trials, the 951 sentence subset from  #AUTHOR_TAG is used.', '']",5
"['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of']","['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i. e., sentences which']","['of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of']","['research into rst - dt segmentation and parsing has focused on subsets of the 991 sentence test set during evaluation.', ' #AUTHOR_TAG omitted sentences that were not exactly spanned by a subtree of the treebank, so that they could focus on sentence - level discourse parsing.', 'by our count, this eliminates 40 of the 991 sentences in the test set from consideration.', ' #TAUTHOR_TAG went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i. e., sentences which themselves are atomic edus.', 'since the primary focus of this paper is on segmentation, there is no strong reason to omit any sentences from the test set, hence our results will evaluate on all 991 test sentences, with two exceptions.', 'first, in section 2. 3, we compare spade results under our configuration with results from  #TAUTHOR_TAG in order to establish comparability, and this is done on their 608 sentence subset.', 'second, in section 3. 2, we investigate feeding our segmentation into the spade system, in order to evaluate the impact of segmentation improvements on their sentence - level discourse parsing performance.', 'for those trials, the 951 sentence subset from  #AUTHOR_TAG is used.', '']",5
['three systems on the  #TAUTHOR_TAG'],['three systems on the  #TAUTHOR_TAG 608 sentence subset of the evaluation data :'],['three systems on the  #TAUTHOR_TAG 608 sentence subset of the evaluation data : ('],"['', 'table 1 compares segmentation results of three systems on the  #TAUTHOR_TAG 608 sentence subset of the evaluation data : ( 1 ) their best reported system ; ( 2 ) the spade system results reported in that paper ; and ( 3 ) the spade system results with our current configuration.', 'the evaluation uses the unlabeled f1 measure as defined in that paper, which counts sentence initial boundaries in the scoring, as discussed in the previous section.', 'as can be seen from these results, our improved configuration of spade gives us large improvements over the previously reported spade performance on this subset.', 'as a result, we feel that we can use spade 490 as a very strong baseline for evaluation on the entire test set.', 'additionally, we modified the spade script to allow us to provide our segmentations to the full discourse parsing that it performs, in order to evaluate the improvements to discourse parsing yielded by any improvements to segmentation']",5
"['shallow tag sequences as well, to define tag n - gram features. this feature set is very close to that used in  #TAUTHOR_TAG, but not identical. their n - gram feature definitions', 'were different ( though similar ), and they']","['shallow tag sequences as well, to define tag n - gram features. this feature set is very close to that used in  #TAUTHOR_TAG, but not identical. their n - gram feature definitions', 'were different ( though similar ), and they made use of cue phrases from  #AUTHOR_TAG. in addition, they used a rulebased clauser', 'that we did not. despite such differences, this feature set is quite close to']","['n - gram are included as features. in other words, all n - grams in a', 'six word window of boundary position i are included as features, except those that include neither w i nor w i +', '1 in the n - gram. the identical feature templates are used with pos - tag and shallow tag sequences as well, to define tag n - gram features. this feature set is very close to that used in  #TAUTHOR_TAG, but not identical. their n - gram feature definitions', 'were different ( though similar ), and they']","[', at position i, we round i / k to two decimal places and provide a value of 1 for the corresponding quantized position feature and 0 for the other position features. 2. 5. 1 basic finite - state features our baseline finite - state feature set includes simple tag', '##ger derived features, as well as features based on position in the string and n - grams 4. we', 'annotate tag sequences onto the word sequence via a competitive discriminatively trained tagger  #AUTHOR_TAG, trained for each of two kinds of tag sequences', ': part - of - speech ( pos )', 'tags and shallow parse tags. the shallow parse tags define nonhierarc', '##hical base constituents ( "" chunks "" ), as defined for the conll - 2000 shared task  #AUTHOR_TAG. these can either be used as tag or chunk sequences', '. for example, the tree in figure 2 represents a shallow ( non - hierarchical ) parse tree,', 'with four base constituents. each base constituent x begins with a word', 'labeled with b x, which signifies that this word begins the constituent. all other words within a constituent x are labeled and i ( nside ) tags i x, and words outside of any base constituent', 'are labeled o. in such a way, each word is labeled with both a pos - tag and a b / i / o tag. for our three sequences ( lexical, pos - tag and shallow', 'tag ), we define n - gram features surrounding the potential discourse boundary. if the current word is w i, the hypothesized boundary will occur between w i and w i + 1. for this boundary position, the', '6 - gram including the three words before and the three words after the boundary is included as a feature ; additionally, all n - grams for n < 6', 'such that either w i or w i + 1 (', 'or both ) is in the n - gram are included as features. in other words, all n - grams in a', 'six word window of boundary position i are included as features, except those that include neither w i nor w i +', '1 in the n - gram. the identical feature templates are used with pos - tag and shallow tag sequences as well, to define tag n - gram features. this feature set is very close to that used in  #TAUTHOR_TAG, but not identical. their n - gram feature definitions', 'were different ( though similar ), and they made use of cue phrases from  #AUTHOR_TAG. in addition, they used a rulebased clauser', 'that we did not. despite such differences, this feature set is quite close to what is described in that paper', '']",3
"[', a soft - alignment probability matrix is generated.', 'we use average normalized entropy ( ane )  #TAUTHOR_TAG computed over these matrices']","['by all these models ( total agreement ).', 'the second method is ane selection.', 'for every language pair and aligned sentence in the dataset, a soft - alignment probability matrix is generated.', 'we use average normalized entropy ( ane )  #TAUTHOR_TAG computed over these matrices']","['by all these models ( total agreement ).', 'the second method is ane selection.', 'for every language pair and aligned sentence in the dataset, a soft - alignment probability matrix is generated.', 'we use average normalized entropy ( ane )  #TAUTHOR_TAG computed over these matrices']","['multilingual mboshi parallel corpus : in this work we extend the bilingual mboshi - french parallel corpus  #AUTHOR_TAG, fruit of the documentation process of mboshi ( bantu c25 ), an endangered language spoken in congo - brazzaville.', 'the corpus contains 5, 130 utterances, for which it provides audio, transcriptions and translations in french.', 'we translate the french into four other well - resourced languages through the use of the deepl translator.', '1 the languages added to the dataset are : english, german, portuguese and spanish.', 'table 1 shows some statistics for the produced multilingual mboshi parallel corpus.', '2 bilingual unsupervised word segmentation / discovery approach : we use the bilingual neuralbased unsupervised word segmentation ( uws ) approach from  #AUTHOR_TAG to discover words in mboshi.', 'in this approach, neural machine translation ( nmt ) models are trained between language pairs, using as source language the translation ( word - level ) and as target, the language to document ( unsegmented phonemic sequence ).', 'due to the attention mechanism present in these networks  #AUTHOR_TAG, posterior to training, it is possible to retrieve soft - alignment probability matrices between source and target sequences.', 'these matrices give us sentence - level source - to - target alignment information, and by using it for clustering neighbor phonemes aligned to the same translation word, we are able to create segmentation in the target side.', 'the product of this approach is a set of ( discovered - units, translation words ) pairs.', 'multilingual leveraging : in this work we apply two simple methods for including multilingual information into the bilingual models from  #AUTHOR_TAG.', 'the first one, multilingual voting, consists of merging the information learned by models trained with different language pairs by performing a voting over the final discovered boundaries.', 'the voting is performed by applying an agreement threshold t over the output boundaries.', 'this threshold balances between accepting all boundaries from all the bilingual models ( zero agreement ) and accepting only input boundaries discovered by all these models ( total agreement ).', 'the second method is ane selection.', 'for every language pair and aligned sentence in the dataset, a soft - alignment probability matrix is generated.', 'we use average normalized entropy ( ane )  #TAUTHOR_TAG computed over these matrices for selecting the most confident one for segmenting each phoneme sequence.', 'this exploits the idea that models trained on different language pairs will have language - related behavior, thus differing on the resulting alignment and segmentation over the same phoneme sequence']",5
['- scores using the zrc speech reference ) are the same from  #TAUTHOR_TAG'],['experiment settings from this paper and evaluation protocol for the mboshi corpus ( boundary f - scores using the zrc speech reference ) are the same from  #TAUTHOR_TAG'],"['experiment settings from this paper and evaluation protocol for the mboshi corpus ( boundary f - scores using the zrc speech reference ) are the same from  #TAUTHOR_TAG.', 'table 2 presents the results for bilingual uws and multilingual leveraging.', '']","['experiment settings from this paper and evaluation protocol for the mboshi corpus ( boundary f - scores using the zrc speech reference ) are the same from  #TAUTHOR_TAG.', 'table 2 presents the results for bilingual uws and multilingual leveraging.', 'for the former, we reach our best result by using as aligned information the french, the original aligned language for this dataset.', 'languages closely related to french ( spanish and portuguese ) ranked better, while our worst result used german.', 'english also performs notably well in our experiments.', 'we believe this is due to the statistics features of the resulting text.', 'we observe in table 1 that the english portion of the dataset contains the smallest vocabulary among all languages.', ""since we train our systems in very low - resource settings, vocabularyrelated features can impact greatly the system's capacity to language - model, and consequently the final quality of the produced alignments."", 'even in high - resource settings, it was already attested that some languages are more difficult to model than others  #AUTHOR_TAG.', '']",5
['- scores using the zrc speech reference ) are the same from  #TAUTHOR_TAG'],['experiment settings from this paper and evaluation protocol for the mboshi corpus ( boundary f - scores using the zrc speech reference ) are the same from  #TAUTHOR_TAG'],"['experiment settings from this paper and evaluation protocol for the mboshi corpus ( boundary f - scores using the zrc speech reference ) are the same from  #TAUTHOR_TAG.', 'table 2 presents the results for bilingual uws and multilingual leveraging.', '']","['experiment settings from this paper and evaluation protocol for the mboshi corpus ( boundary f - scores using the zrc speech reference ) are the same from  #TAUTHOR_TAG.', 'table 2 presents the results for bilingual uws and multilingual leveraging.', 'for the former, we reach our best result by using as aligned information the french, the original aligned language for this dataset.', 'languages closely related to french ( spanish and portuguese ) ranked better, while our worst result used german.', 'english also performs notably well in our experiments.', 'we believe this is due to the statistics features of the resulting text.', 'we observe in table 1 that the english portion of the dataset contains the smallest vocabulary among all languages.', ""since we train our systems in very low - resource settings, vocabularyrelated features can impact greatly the system's capacity to language - model, and consequently the final quality of the produced alignments."", 'even in high - resource settings, it was already attested that some languages are more difficult to model than others  #AUTHOR_TAG.', '']",5
['##uan chen  #TAUTHOR_TAG ever proposed a approach to'],"['some new words with sentiment orientation.', 'zhiyuan chen  #TAUTHOR_TAG ever proposed a approach to']",['##uan chen  #TAUTHOR_TAG ever proposed a approach to'],"['', 'to achieve the goal of "" strong ai "", we need to convert our learning goal to discover which words have sentiment orientation and check whether the orientation just valid in specific domains.', 'if we can achieve this learning goal, the algorithms will be able to solve new tasks without teaching and explore new domain to find some new words with sentiment orientation.', 'zhiyuan chen  #TAUTHOR_TAG ever proposed a approach to determine which domain dose a word have the sentiment orientation to achieve the goal of lifelong learning.', 'he made a big progress but the supervised learning still is needed.', 'hence, we will make it forward to let the learning to star with supervised learning but continue with unsupervised learning in the future tasks']",0
['##uan and bing  #TAUTHOR_TAG improved'],"['[ 1 ], ella is much more efficient.', 'zhiyuan and bing  #TAUTHOR_TAG improved']",['##uan and bing  #TAUTHOR_TAG improved'],"['was firstly called as lifelong machine learning since 1995 by thrun [ 6, 8 ].', 'efficient lifelong machine learning ( ella ) [ 5 ] raised by ruvolo and eaton.', 'comparing with the multi - task learning [ 1 ], ella is much more efficient.', 'zhiyuan and bing  #TAUTHOR_TAG improved the sentiment classification by involving knowledge.', 'the object function was modified with two penalty terms which corresponding with previous tasks.', 'the knowledge system contains the following components']",0
[' #TAUTHOR_TAG mainly'],[' #TAUTHOR_TAG mainly'],[' #TAUTHOR_TAG mainly'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG mainly'],[' #TAUTHOR_TAG mainly'],[' #TAUTHOR_TAG mainly'],[' #TAUTHOR_TAG'],0
"['it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose the']","['it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose the']","['it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose']","['and etc. [ 3 ] ever discussed that the nlp field is most suitable for the researches of the lifelong learning due to it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose the sentiment classification as the learning target because it is could be regarded as a task as well as a group of subtasks in different domain.', 'these sub - tasks related to each other but a model trained on a domain is unable to perform well in rest domains.', 'the sub - tasked is related means that the knowledge transform among tasks is possible to improve performance. and the distribution of distribution is different requires that our algorithms could know when the knowledge can be used and when can not.', '']",0
"['it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose the']","['it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose the']","['it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose']","['and etc. [ 3 ] ever discussed that the nlp field is most suitable for the researches of the lifelong learning due to it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose the sentiment classification as the learning target because it is could be regarded as a task as well as a group of subtasks in different domain.', 'these sub - tasks related to each other but a model trained on a domain is unable to perform well in rest domains.', 'the sub - tasked is related means that the knowledge transform among tasks is possible to improve performance. and the distribution of distribution is different requires that our algorithms could know when the knowledge can be used and when can not.', '']",0
"['all documents.', 'however, above three key components are different in different domains.', 'lsc  #TAUTHOR_TAG discussed a possible solution of p ( w']","['all documents.', 'however, above three key components are different in different domains.', 'lsc  #TAUTHOR_TAG discussed a possible solution of p ( w | c j ).', 'as we known, not']","['all documents.', 'however, above three key components are different in different domains.', 'lsc  #TAUTHOR_TAG discussed a possible solution of p ( w | c j ).', 'as we known, not all words have']","[', if we know the p ( c + ), p ( c − ) and p ( w | c j ) for all words, we can predict the sentiment orientation for all documents.', 'however, above three key components are different in different domains.', 'lsc  #TAUTHOR_TAG discussed a possible solution of p ( w | c j ).', 'as we known, not all words have sentimental orientation like "" a "", "" one "" and etc.', '']",0
['##uan chen  #TAUTHOR_TAG ever proposed a approach to'],"['some new words with sentiment orientation.', 'zhiyuan chen  #TAUTHOR_TAG ever proposed a approach to']",['##uan chen  #TAUTHOR_TAG ever proposed a approach to'],"['', 'to achieve the goal of "" strong ai "", we need to convert our learning goal to discover which words have sentiment orientation and check whether the orientation just valid in specific domains.', 'if we can achieve this learning goal, the algorithms will be able to solve new tasks without teaching and explore new domain to find some new words with sentiment orientation.', 'zhiyuan chen  #TAUTHOR_TAG ever proposed a approach to determine which domain dose a word have the sentiment orientation to achieve the goal of lifelong learning.', 'he made a big progress but the supervised learning still is needed.', 'hence, we will make it forward to let the learning to star with supervised learning but continue with unsupervised learning in the future tasks']",1
"['it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose the']","['it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose the']","['it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose']","['and etc. [ 3 ] ever discussed that the nlp field is most suitable for the researches of the lifelong learning due to it is easier to extract knowledge and be understood by human.', 'previous classical paper  #TAUTHOR_TAG chose the sentiment classification as the learning target because it is could be regarded as a task as well as a group of subtasks in different domain.', 'these sub - tasks related to each other but a model trained on a domain is unable to perform well in rest domains.', 'the sub - tasked is related means that the knowledge transform among tasks is possible to improve performance. and the distribution of distribution is different requires that our algorithms could know when the knowledge can be used and when can not.', '']",1
"['lsc  #TAUTHOR_TAG already raised a lifelong approach,']","['lsc  #TAUTHOR_TAG already raised a lifelong approach,']","['lsc  #TAUTHOR_TAG already raised a lifelong approach,']","['lsc  #TAUTHOR_TAG already raised a lifelong approach, it only aims to improve the classification accuracy.', 'it will not deliver a summary that which words are influence sentiment which is most important to us and can be used for future learning.', '']",1
"['lsc  #TAUTHOR_TAG considered the difference among domains,']","['lsc  #TAUTHOR_TAG considered the difference among domains,']","['lsc  #TAUTHOR_TAG considered the difference among domains,']","['lsc  #TAUTHOR_TAG considered the difference among domains, it still is a typical supervised learning approach.', 'in this paper, we proposed to learn as two stages :', '( 1 ) initial learning stage : to explore a basic set of sentiment orientation words.', 'after that, the model should be able to basically classify a new domain with a good performance.', '( 2 ) self - study stage : use the knowledge accumulated from the initial stage to handle new domains, also fine - tune and consolidate the knowledge generated from initial learning stage']",1
"['as lsc  #TAUTHOR_TAG used below.', 'p (']","['as lsc  #TAUTHOR_TAG used below.', 'p ( w | c j ) is the probability of a']","['as lsc  #TAUTHOR_TAG used below.', 'p (']","['this paper, we define a word has sentiment orientation by calculating the probability that it will appears in a positive or negative content ( sentence or document ).', 'if a word has high probability with sentiment orientation, it also will leads to the document have higher probability of sentiment orientation based on the naive bayesian ( nb ) formula.', 'nb text classification [ 4 ] will calculate the probability of each word w given a sentiment orientation ( positive or negative ).', 'use use the same formula as lsc  #TAUTHOR_TAG used below.', 'p ( w | c j ) is the probability of a word appears in a class :', '']",5
"[' #TAUTHOR_TAG used.', 'it contains the reviews']","['datasets as lsc  #TAUTHOR_TAG used.', 'it contains the reviews']","['the experiment, we use the same datasets as lsc  #TAUTHOR_TAG used.', 'it contains the reviews']","['the experiment, we use the same datasets as lsc  #TAUTHOR_TAG used.', 'it contains the reviews from 20 domains crawled from amazon. com and each domain has 1, 000 reviews ( the distribution of positive and negative reviews is imbalanced )']",5
"['', 'according to  #TAUTHOR_TAG, the single bid']","['presence of adversarial sentences in articles.', 'according to  #TAUTHOR_TAG, the single bidaf system  #AUTHOR_TAG only achieves']","['', 'according to  #TAUTHOR_TAG, the single bidaf system  #AUTHOR_TAG only achieves']","['answering systems deteriorate dramatically in the presence of adversarial sentences in articles.', 'according to  #TAUTHOR_TAG, the single bidaf system  #AUTHOR_TAG only achieves an f1 score of 4. 8 on the addany adversarial dataset.', 'in this paper, we present a method to tackle this problem via answer sentence selection.', 'given a paragraph of an article and a corresponding query, instead of directly feeding the whole paragraph to the single bidaf system, a sentence that most likely contains the answer to the query is first selected, which is done via a deep neural network based on tree - lstm  #AUTHOR_TAG.', 'experiments on addany adversarial dataset validate the effectiveness of our method.', 'the f1 score has been improved to 52. 3']",0
"[' #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that']","[' #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that']","['', 'recently, many systems have achieved great results on this task  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that these systems']","['', 'recently, many systems have achieved great results on this task  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that these systems are very vulnerable to paragraphs with adversarial sentences.', '']",0
"[' #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that']","[' #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that']","['', 'recently, many systems have achieved great results on this task  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that these systems']","['', 'recently, many systems have achieved great results on this task  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that these systems are very vulnerable to paragraphs with adversarial sentences.', '']",0
"['', 'however, following the idea of adversarial examples in image recognition  #AUTHOR_TAG,  #TAUTHOR_TAG point out the unreliability']","['', 'however, following the idea of adversarial examples in image recognition  #AUTHOR_TAG,  #TAUTHOR_TAG point out the unreliability']","['', 'however, following the idea of adversarial examples in image recognition  #AUTHOR_TAG,  #TAUTHOR_TAG point out the unreliability']","['the help of deep learning, many techniques have been investigated to achieve exciting results on answer sentence selection and qa.', ' #AUTHOR_TAG measure the relevance between sentences through a stacked bidirectional lstm network.', 'they show that these scores are effective in answer sentence selection.', ' #AUTHOR_TAG embed sentences with cnn at multiple levels of granularity to model the similarity between sentences.', ' #AUTHOR_TAG extend the method of noise - contrastive estimation to questions paired with positive and negative sentences.', 'based on that, they present a pairwise ranking approach to select an answer from multiple candidate sentences.', ' #AUTHOR_TAG propose a bilateral multi - perspective matching model which achieves rivaling results in the task of answer sentence selection.', ' #AUTHOR_TAG a ) measure the similarity between sentences by utilizing the word level 4 the x - axis is truncated to save the space.', 'similarity matrix.', 'this approach is validated in answer selection.', 'to efficiently tackle question answering for long documents,  #AUTHOR_TAG propose a method based on answer sentence selection to first narrow down a document and then use rnn to generate an answer.', 'however, following the idea of adversarial examples in image recognition  #AUTHOR_TAG,  #TAUTHOR_TAG point out the unreliability of existing question answering models in the presence of adversarial sentences.', '']",0
"['', 'according to  #TAUTHOR_TAG, the single bid']","['presence of adversarial sentences in articles.', 'according to  #TAUTHOR_TAG, the single bidaf system  #AUTHOR_TAG only achieves']","['', 'according to  #TAUTHOR_TAG, the single bidaf system  #AUTHOR_TAG only achieves']","['answering systems deteriorate dramatically in the presence of adversarial sentences in articles.', 'according to  #TAUTHOR_TAG, the single bidaf system  #AUTHOR_TAG only achieves an f1 score of 4. 8 on the addany adversarial dataset.', 'in this paper, we present a method to tackle this problem via answer sentence selection.', 'given a paragraph of an article and a corresponding query, instead of directly feeding the whole paragraph to the single bidaf system, a sentence that most likely contains the answer to the query is first selected, which is done via a deep neural network based on tree - lstm  #AUTHOR_TAG.', 'experiments on addany adversarial dataset validate the effectiveness of our method.', 'the f1 score has been improved to 52. 3']",1
"[' #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that']","[' #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that']","['', 'recently, many systems have achieved great results on this task  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that these systems']","['', 'recently, many systems have achieved great results on this task  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'however,  #TAUTHOR_TAG show that these systems are very vulnerable to paragraphs with adversarial sentences.', '']",1
"['', 'however, following the idea of adversarial examples in image recognition  #AUTHOR_TAG,  #TAUTHOR_TAG point out the unreliability']","['', 'however, following the idea of adversarial examples in image recognition  #AUTHOR_TAG,  #TAUTHOR_TAG point out the unreliability']","['', 'however, following the idea of adversarial examples in image recognition  #AUTHOR_TAG,  #TAUTHOR_TAG point out the unreliability']","['the help of deep learning, many techniques have been investigated to achieve exciting results on answer sentence selection and qa.', ' #AUTHOR_TAG measure the relevance between sentences through a stacked bidirectional lstm network.', 'they show that these scores are effective in answer sentence selection.', ' #AUTHOR_TAG embed sentences with cnn at multiple levels of granularity to model the similarity between sentences.', ' #AUTHOR_TAG extend the method of noise - contrastive estimation to questions paired with positive and negative sentences.', 'based on that, they present a pairwise ranking approach to select an answer from multiple candidate sentences.', ' #AUTHOR_TAG propose a bilateral multi - perspective matching model which achieves rivaling results in the task of answer sentence selection.', ' #AUTHOR_TAG a ) measure the similarity between sentences by utilizing the word level 4 the x - axis is truncated to save the space.', 'similarity matrix.', 'this approach is validated in answer selection.', 'to efficiently tackle question answering for long documents,  #AUTHOR_TAG propose a method based on answer sentence selection to first narrow down a document and then use rnn to generate an answer.', 'however, following the idea of adversarial examples in image recognition  #AUTHOR_TAG,  #TAUTHOR_TAG point out the unreliability of existing question answering models in the presence of adversarial sentences.', '']",1
"['testing.', ""our test set is  #TAUTHOR_TAG's addany adversarial dataset""]","['testing.', ""our test set is  #TAUTHOR_TAG's addany adversarial dataset."", '']","['testing.', ""our test set is  #TAUTHOR_TAG's addany adversarial dataset."", '']","['', 'this operation is repeated until we get 45, 000 positive instances and 45, 000 negative instances.', 'finally, two different training sets are generated by pair - level sampling and paragraphlevel sampling.', 'each set has 90, 000 instances.', 'the validation set with 3, 000 instances are sampled through these two methods as well.', 'dataset for testing.', ""our test set is  #TAUTHOR_TAG's addany adversarial dataset."", 'it includes 1, 000 paragraphs and each paragraph refers to only one query, i. e., 1, 000 ( c, q ) pairs.', 'by splitting and combining, 6, 154 sentence pairs are obtained.', 'experimental settings.', 'the dimension of glove word vectors  #AUTHOR_TAG is set as 300.', 'the sentence scoring neural network is trained by adagrad  #AUTHOR_TAG with a learning rate of 0. 01 and a batch size of 25.', 'model parameters are regularized by a 10 −4 strength of per - minibatch l 2 regularization']",5
"['##1 score ( rajpurkar  #TAUTHOR_TAG.', 'it measures the average overlap between the predicted']","['macro - averaged f1 score ( rajpurkar  #TAUTHOR_TAG.', 'it measures the average overlap between the predicted answera and real']","['is evaluated by the macro - averaged f1 score ( rajpurkar  #TAUTHOR_TAG.', 'it measures the average overlap between the predicted']","['performance of question answering is evaluated by the macro - averaged f1 score ( rajpurkar  #TAUTHOR_TAG.', 'it measures the average overlap between the predicted answera and real answers on token - level.', 'we also compute the macro - averaged precision and recall following the same procedure.', '']",5
"['', 'however,  #TAUTHOR_TAG also present the deterioration of qa systems on another dataset, addsent adversarial dataset.', 'question']","['with adversarial examples on addany adversarial dataset.', 'however,  #TAUTHOR_TAG also present the deterioration of qa systems on another dataset, addsent adversarial dataset.', 'question answer - ing on this dataset remains']","['with adversarial examples on addany adversarial dataset.', 'however,  #TAUTHOR_TAG also present the deterioration of qa systems on another dataset, addsent adversarial dataset.', 'question answer - ing on this dataset remains']","['', 'to the best of our knowledge, we are the first to apply treelstms in answer sentence selection and the first to tackle question answering with adversarial examples on addany adversarial dataset.', 'however,  #TAUTHOR_TAG also present the deterioration of qa systems on another dataset, addsent adversarial dataset.', 'question answer - ing on this dataset remains unsolved.', 'we leave it as a future work']",3
['of  #TAUTHOR_TAG by using paraphrases'],"['of  #TAUTHOR_TAG by using paraphrases.', 'second,']","['of  #TAUTHOR_TAG by using paraphrases.', 'second,']","['', ""first, we consider  #AUTHOR_TAG's own extension of the semantic parser of  #TAUTHOR_TAG by using paraphrases."", 'second, we apply wordnet synonyms  #AUTHOR_TAG for selected parts of speech to the queries in the free917 dataset.', 'the new pairs of queries and logical forms are added to the dataset on which the semantic parsers are retrained.', 'we find that both techniques of enhancing the lexical coverage of the semantic parsers result in improved parsing performance, and that the improvements add up nicely.', 'however, improved parsing performance does not correspond to improved f1 - score in answer retrieval when using the respective parser in a response - based learning framework.', 'we show that in order to produce helpful feedback for responsebased learning, parser performance on incorrect en - glish queries needs to be taken into account, which is standardly ignored in parser evaluation.', 'that is, for the purpose of parsing translated queries, a parser should retrieve correct answers for correct english queries ( true positives ),']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['main challenge of grounding smt in semantic parsing for freebase lies in scaling the semantic parser to the lexical diversity of the open - domain database.', 'our baseline system is the parser of  #TAUTHOR_TAG, called sempre.', 'we first consider the approach presented by  #AUTHOR_TAG to scale the baseline to open - domain database queries :', '']",5
['of  #TAUTHOR_TAG and  #AUTHOR_TAG which were'],['of  #TAUTHOR_TAG and  #AUTHOR_TAG which were'],"['semantic parsing we use the sempre and parasempre tools of  #TAUTHOR_TAG and  #AUTHOR_TAG which were trained on the training portion of the free917 corpus 7.', 'further models use the training data enhanced with synonyms']","['', 'the translation of the english queries in free917 into german, in order to provide a set of source sentences for smt, was done by the authors.', 'the smt framework used is cdec  #AUTHOR_TAG with standard dense features and additional sparse features as described in  #AUTHOR_TAG 4.', 'training of the baseline smt system was performed on the common crawl 5  #AUTHOR_TAG dataset consisting of 7. 5m parallel english - german segments extracted from the web.', 'response - based learning for smt uses the code described in  #AUTHOR_TAG 6.', 'for semantic parsing we use the sempre and parasempre tools of  #TAUTHOR_TAG and  #AUTHOR_TAG which were trained on the training portion of the free917 corpus 7.', 'further models use the training data enhanced with synonyms from wordnet as described in section 4.', '']",5
"[' #AUTHOR_TAG,  #TAUTHOR_TAG,  #AUTHOR_TAG, inter ali']","['itself (  #AUTHOR_TAG,  #TAUTHOR_TAG,  #AUTHOR_TAG, inter alia ).', 'in these works, extrinsic responses in']","[' #AUTHOR_TAG,  #TAUTHOR_TAG,  #AUTHOR_TAG, inter alia ).', 'in these works, extrinsic responses in']","['work is most closely related to  #AUTHOR_TAG.', 'we extend their application of responsebased learning for smt to a larger and lexically more diverse dataset and show how to perform model selection in the environment from which response signals are obtained.', 'in contrast to their work where a monolingual smt - based approach  #AUTHOR_TAG is used as semantic parser, our work builds on existing parsers for freebase, with a focus on exploiting paraphrasing and synonym extension for scaling semantic parsers to open - domain database queries.', 'response - based learning has been applied in previous work to semantic parsing itself (  #AUTHOR_TAG,  #TAUTHOR_TAG,  #AUTHOR_TAG, inter alia ).', 'in these works, extrinsic responses in form of correct answers from a database are used to alleviate the problem of manual data annotation in semantic parsing.', ' #AUTHOR_TAG integrate human binary feedback on the quality of an smt system output into a discriminative learner.', 'further work on learning from weak supervision signals has been presented in the machine learning community, e. g., in form of coactive learning  #AUTHOR_TAG, reinforcement learning  #AUTHOR_TAG, or online learning with limited feedback ( cesa -  #AUTHOR_TAG']",0
"['authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['- of - the - art models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks. modifying or extending can need enormous coding. in this paper, we present neural crf + + ( ncrf + + ) 3, a neural sequence', 'labeling toolkit based on pytorch, which is designed for solving general sequence labeling tasks with effective and efficient neural models', '. it can be regarded as the neural version of crf + +, with both take the conll data format as input and can add hand - crafted features', 'to crf framework conveniently. we take the layerwise implementation, which includes character sequence layer, word sequence layer and inference layer. ncrf + +', 'is : • fully configurable : users can design their neural models only through a configuration file without any code work. figure 1 shows a segment of the configuration file. it builds a lstm - crf framework with cnn to encode character sequence ( the same structure as  #TAUTHOR_TAG, plus pos and cap features, within 10', 'lines. this demonstrates the convenience of designing neural models using ncrf + +.', '• flexible with features : human - defined features have been proved useful in neural sequence labeling  #AUTHOR_TAG. similar to the statistical toolkits, nc', '##rf + + supports user - defined features', 'but using distributed representations through lookup tables, which can be initialized randomly or from external pretrained embeddings ( embedding directory : emb dir in figure 1 ). in addition, ncrf + + integrates several state - of - the -', 'art automatic feature extractors, such as cnn and lstm for character sequences, leading easy reproduction of many recent work  #TAUTHOR_TAG. • effective and efficient : we reimplement several state - of', '- the - art neural models  #TAUTHOR_TAG using ncrf + +. experiments show models built in ncrf', '+ + give comparable performance with', 'reported results in the literature. besides, ncrf + + is implemented using batch calculation, which can be', 'accelerated using gpu. our experiments demonstrate that ncrf', '+ + as an effective and efficient toolkit. • function enriched : ncrf + + extends the viterbi algorithm  #AUTHOR_TAG to enable decoding n best sequence labels', 'with their probabilities. taking ner, chunking and pos tagging as typical', 'examples, we investigate the performance of models built in ncrf + +, the influence of human', '##defined and automatic features, the performance of nbest decoding and the running speed with the batch size. detail results are shown in section 3']",0
"['authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['- of - the - art models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks. modifying or extending can need enormous coding. in this paper, we present neural crf + + ( ncrf + + ) 3, a neural sequence', 'labeling toolkit based on pytorch, which is designed for solving general sequence labeling tasks with effective and efficient neural models', '. it can be regarded as the neural version of crf + +, with both take the conll data format as input and can add hand - crafted features', 'to crf framework conveniently. we take the layerwise implementation, which includes character sequence layer, word sequence layer and inference layer. ncrf + +', 'is : • fully configurable : users can design their neural models only through a configuration file without any code work. figure 1 shows a segment of the configuration file. it builds a lstm - crf framework with cnn to encode character sequence ( the same structure as  #TAUTHOR_TAG, plus pos and cap features, within 10', 'lines. this demonstrates the convenience of designing neural models using ncrf + +.', '• flexible with features : human - defined features have been proved useful in neural sequence labeling  #AUTHOR_TAG. similar to the statistical toolkits, nc', '##rf + + supports user - defined features', 'but using distributed representations through lookup tables, which can be initialized randomly or from external pretrained embeddings ( embedding directory : emb dir in figure 1 ). in addition, ncrf + + integrates several state - of - the -', 'art automatic feature extractors, such as cnn and lstm for character sequences, leading easy reproduction of many recent work  #TAUTHOR_TAG. • effective and efficient : we reimplement several state - of', '- the - art neural models  #TAUTHOR_TAG using ncrf + +. experiments show models built in ncrf', '+ + give comparable performance with', 'reported results in the literature. besides, ncrf + + is implemented using batch calculation, which can be', 'accelerated using gpu. our experiments demonstrate that ncrf', '+ + as an effective and efficient toolkit. • function enriched : ncrf + + extends the viterbi algorithm  #AUTHOR_TAG to enable decoding n best sequence labels', 'with their probabilities. taking ner, chunking and pos tagging as typical', 'examples, we investigate the performance of models built in ncrf + +, the influence of human', '##defined and automatic features, the performance of nbest decoding and the running speed with the batch size. detail results are shown in section 3']",0
"['authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['- of - the - art models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks. modifying or extending can need enormous coding. in this paper, we present neural crf + + ( ncrf + + ) 3, a neural sequence', 'labeling toolkit based on pytorch, which is designed for solving general sequence labeling tasks with effective and efficient neural models', '. it can be regarded as the neural version of crf + +, with both take the conll data format as input and can add hand - crafted features', 'to crf framework conveniently. we take the layerwise implementation, which includes character sequence layer, word sequence layer and inference layer. ncrf + +', 'is : • fully configurable : users can design their neural models only through a configuration file without any code work. figure 1 shows a segment of the configuration file. it builds a lstm - crf framework with cnn to encode character sequence ( the same structure as  #TAUTHOR_TAG, plus pos and cap features, within 10', 'lines. this demonstrates the convenience of designing neural models using ncrf + +.', '• flexible with features : human - defined features have been proved useful in neural sequence labeling  #AUTHOR_TAG. similar to the statistical toolkits, nc', '##rf + + supports user - defined features', 'but using distributed representations through lookup tables, which can be initialized randomly or from external pretrained embeddings ( embedding directory : emb dir in figure 1 ). in addition, ncrf + + integrates several state - of - the -', 'art automatic feature extractors, such as cnn and lstm for character sequences, leading easy reproduction of many recent work  #TAUTHOR_TAG. • effective and efficient : we reimplement several state - of', '- the - art neural models  #TAUTHOR_TAG using ncrf + +. experiments show models built in ncrf', '+ + give comparable performance with', 'reported results in the literature. besides, ncrf + + is implemented using batch calculation, which can be', 'accelerated using gpu. our experiments demonstrate that ncrf', '+ + as an effective and efficient toolkit. • function enriched : ncrf + + extends the viterbi algorithm  #AUTHOR_TAG to enable decoding n best sequence labels', 'with their probabilities. taking ner, chunking and pos tagging as typical', 'examples, we investigate the performance of models built in ncrf + +, the influence of human', '##defined and automatic features, the performance of nbest decoding and the running speed with the batch size. detail results are shown in section 3']",0
"['authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['- of - the - art models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks. modifying or extending can need enormous coding. in this paper, we present neural crf + + ( ncrf + + ) 3, a neural sequence', 'labeling toolkit based on pytorch, which is designed for solving general sequence labeling tasks with effective and efficient neural models', '. it can be regarded as the neural version of crf + +, with both take the conll data format as input and can add hand - crafted features', 'to crf framework conveniently. we take the layerwise implementation, which includes character sequence layer, word sequence layer and inference layer. ncrf + +', 'is : • fully configurable : users can design their neural models only through a configuration file without any code work. figure 1 shows a segment of the configuration file. it builds a lstm - crf framework with cnn to encode character sequence ( the same structure as  #TAUTHOR_TAG, plus pos and cap features, within 10', 'lines. this demonstrates the convenience of designing neural models using ncrf + +.', '• flexible with features : human - defined features have been proved useful in neural sequence labeling  #AUTHOR_TAG. similar to the statistical toolkits, nc', '##rf + + supports user - defined features', 'but using distributed representations through lookup tables, which can be initialized randomly or from external pretrained embeddings ( embedding directory : emb dir in figure 1 ). in addition, ncrf + + integrates several state - of - the -', 'art automatic feature extractors, such as cnn and lstm for character sequences, leading easy reproduction of many recent work  #TAUTHOR_TAG. • effective and efficient : we reimplement several state - of', '- the - art neural models  #TAUTHOR_TAG using ncrf + +. experiments show models built in ncrf', '+ + give comparable performance with', 'reported results in the literature. besides, ncrf + + is implemented using batch calculation, which can be', 'accelerated using gpu. our experiments demonstrate that ncrf', '+ + as an effective and efficient toolkit. • function enriched : ncrf + + extends the viterbi algorithm  #AUTHOR_TAG to enable decoding n best sequence labels', 'with their probabilities. taking ner, chunking and pos tagging as typical', 'examples, we investigate the performance of models built in ncrf + +, the influence of human', '##defined and automatic features, the performance of nbest decoding and the running speed with the batch size. detail results are shown in section 3']",0
"['together with gru and lstm are available in ncrf + +, which are popular structures in the recent literature  #TAUTHOR_TAG.', 'bidirectional rn']","['', '• word rnn together with gru and lstm are available in ncrf + +, which are popular structures in the recent literature  #TAUTHOR_TAG.', 'bidirectional rnns']","['##ed neural features ( the combination depends on the configuration file ).', 'the word sequence layer can be stacked, building a deeper feature extractor.', '• word rnn together with gru and lstm are available in ncrf + +, which are popular structures in the recent literature  #TAUTHOR_TAG.', 'bidirectional rnns are supported']","['to the character sequence layer, ncrf + + supports both rnn and cnn as the word sequence feature extractor.', 'the selection can be configurated through word seq feature in figure 1.', 'the input of the word sequence layer is a word representation, which may include word embeddings, character sequence representations and handcrafted neural features ( the combination depends on the configuration file ).', 'the word sequence layer can be stacked, building a deeper feature extractor.', '• word rnn together with gru and lstm are available in ncrf + +, which are popular structures in the recent literature  #TAUTHOR_TAG.', 'bidirectional rnns are supported to capture the left and right contexted information of each word.', 'the hidden vectors for both directions on each word are concatenated to represent the corresponding word.', '• word cnn utilizes the same sliding window as character cnn, while a nonlinear function  #AUTHOR_TAG is attached with the extracted features.', 'batch normalization  #AUTHOR_TAG and dropout  #AUTHOR_TAG are also supported to follow the features']",0
"['+ wlstm + crf "" of our models )  #TAUTHOR_TAG.', 'our implementations can']","['"" clstm + wlstm + crf "" and "" ccnn + wlstm + crf "" of our models )  #TAUTHOR_TAG.', 'our implementations can']","['+ wlstm + crf "" of our models )  #TAUTHOR_TAG.', 'our implementations can achieve comparable results, with better ner and']","['shown in table 1, "" wcnn "" based models consistently underperform the "" wlstm "" based models, showing the advantages of lstm on capturing global features.', 'character information can improve model performance significantly, while using lstm or cnn give similar improvement.', 'most of state - of - the - art models utilize the framework of word lstm - crf with character lstm or cnn features ( correspond to "" clstm + wlstm + crf "" and "" ccnn + wlstm + crf "" of our models )  #TAUTHOR_TAG.', 'our implementations can achieve comparable results, with better ner and chunking performances and slightly lower pos tagging accuracy.', 'note that we use almost the same hyperparameters across all the experiments to achieve the results, which demonstrates the robustness of our implementation.', 'the full experimental results and analysis are published in  #AUTHOR_TAG']",0
"['authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['- of - the - art models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks. modifying or extending can need enormous coding. in this paper, we present neural crf + + ( ncrf + + ) 3, a neural sequence', 'labeling toolkit based on pytorch, which is designed for solving general sequence labeling tasks with effective and efficient neural models', '. it can be regarded as the neural version of crf + +, with both take the conll data format as input and can add hand - crafted features', 'to crf framework conveniently. we take the layerwise implementation, which includes character sequence layer, word sequence layer and inference layer. ncrf + +', 'is : • fully configurable : users can design their neural models only through a configuration file without any code work. figure 1 shows a segment of the configuration file. it builds a lstm - crf framework with cnn to encode character sequence ( the same structure as  #TAUTHOR_TAG, plus pos and cap features, within 10', 'lines. this demonstrates the convenience of designing neural models using ncrf + +.', '• flexible with features : human - defined features have been proved useful in neural sequence labeling  #AUTHOR_TAG. similar to the statistical toolkits, nc', '##rf + + supports user - defined features', 'but using distributed representations through lookup tables, which can be initialized randomly or from external pretrained embeddings ( embedding directory : emb dir in figure 1 ). in addition, ncrf + + integrates several state - of - the -', 'art automatic feature extractors, such as cnn and lstm for character sequences, leading easy reproduction of many recent work  #TAUTHOR_TAG. • effective and efficient : we reimplement several state - of', '- the - art neural models  #TAUTHOR_TAG using ncrf + +. experiments show models built in ncrf', '+ + give comparable performance with', 'reported results in the literature. besides, ncrf + + is implemented using batch calculation, which can be', 'accelerated using gpu. our experiments demonstrate that ncrf', '+ + as an effective and efficient toolkit. • function enriched : ncrf + + extends the viterbi algorithm  #AUTHOR_TAG to enable decoding n best sequence labels', 'with their probabilities. taking ner, chunking and pos tagging as typical', 'examples, we investigate the performance of models built in ncrf + +, the influence of human', '##defined and automatic features, the performance of nbest decoding and the running speed with the batch size. detail results are shown in section 3']",3
"['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are']","['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are']","['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are mostly following  #TAUTHOR_TAG']","['evaluate the performance of our toolkit, we conduct the experiments on several datasets.', ' #AUTHOR_TAG, data split is following  #AUTHOR_TAG.', 'for pos tagging, we use the same data and split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', '']",3
"['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are']","['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are']","['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are mostly following  #TAUTHOR_TAG']","['evaluate the performance of our toolkit, we conduct the experiments on several datasets.', ' #AUTHOR_TAG, data split is following  #AUTHOR_TAG.', 'for pos tagging, we use the same data and split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', '']",3
"['authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks']","['- of - the - art models. on the other hand, there is limited choice for neural sequence labeling toolkits. although many authors released their code along with their sequence labeling papers  #TAUTHOR_TAG, the implementations are mostly', 'focused on specific model structures and specific tasks. modifying or extending can need enormous coding. in this paper, we present neural crf + + ( ncrf + + ) 3, a neural sequence', 'labeling toolkit based on pytorch, which is designed for solving general sequence labeling tasks with effective and efficient neural models', '. it can be regarded as the neural version of crf + +, with both take the conll data format as input and can add hand - crafted features', 'to crf framework conveniently. we take the layerwise implementation, which includes character sequence layer, word sequence layer and inference layer. ncrf + +', 'is : • fully configurable : users can design their neural models only through a configuration file without any code work. figure 1 shows a segment of the configuration file. it builds a lstm - crf framework with cnn to encode character sequence ( the same structure as  #TAUTHOR_TAG, plus pos and cap features, within 10', 'lines. this demonstrates the convenience of designing neural models using ncrf + +.', '• flexible with features : human - defined features have been proved useful in neural sequence labeling  #AUTHOR_TAG. similar to the statistical toolkits, nc', '##rf + + supports user - defined features', 'but using distributed representations through lookup tables, which can be initialized randomly or from external pretrained embeddings ( embedding directory : emb dir in figure 1 ). in addition, ncrf + + integrates several state - of - the -', 'art automatic feature extractors, such as cnn and lstm for character sequences, leading easy reproduction of many recent work  #TAUTHOR_TAG. • effective and efficient : we reimplement several state - of', '- the - art neural models  #TAUTHOR_TAG using ncrf + +. experiments show models built in ncrf', '+ + give comparable performance with', 'reported results in the literature. besides, ncrf + + is implemented using batch calculation, which can be', 'accelerated using gpu. our experiments demonstrate that ncrf', '+ + as an effective and efficient toolkit. • function enriched : ncrf + + extends the viterbi algorithm  #AUTHOR_TAG to enable decoding n best sequence labels', 'with their probabilities. taking ner, chunking and pos tagging as typical', 'examples, we investigate the performance of models built in ncrf + +, the influence of human', '##defined and automatic features, the performance of nbest decoding and the running speed with the batch size. detail results are shown in section 3']",5
"['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are']","['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are']","['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are mostly following  #TAUTHOR_TAG']","['evaluate the performance of our toolkit, we conduct the experiments on several datasets.', ' #AUTHOR_TAG, data split is following  #AUTHOR_TAG.', 'for pos tagging, we use the same data and split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', '']",5
"['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are']","['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are']","['split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', 'hyperparameters are mostly following  #TAUTHOR_TAG']","['evaluate the performance of our toolkit, we conduct the experiments on several datasets.', ' #AUTHOR_TAG, data split is following  #AUTHOR_TAG.', 'for pos tagging, we use the same data and split with  #TAUTHOR_TAG.', 'we test different combinations of character representations and word sequence representations on these three benchmarks.', '']",5
"['- spell ( las )  #TAUTHOR_TAG,']","['listenattend - spell ( las )  #TAUTHOR_TAG,']","['- spell ( las )  #TAUTHOR_TAG,']","['', 'time - restricted self - attention was used as a drop - in replacement for individual layers in the state - of - theart lattice - free mmi model [ 26 ], an hmm - nn system.', 'hybrid self - attention / lstm encoders were studied in the context of listenattend - spell ( las )  #TAUTHOR_TAG, and the transformer was directly adapted to speech in [ 19, 28, 29 ] ; both are encoder - decoder systems.', '']",0
"['incorporation of noise / speaker contexts, as  #TAUTHOR_TAG suggest regarding the broad - context attention heads in the first layer of their self - attentional las model']","['incorporation of noise / speaker contexts, as  #TAUTHOR_TAG suggest regarding the broad - context attention heads in the first layer of their self - attentional las model']","['. g., english characters [ 36 ] ).', 'wide contexts also enable incorporation of noise / speaker contexts, as  #TAUTHOR_TAG suggest regarding the broad - context attention heads in the first layer of their self - attentional las model']","['practice, one models p ( π, t | x ) with a neural network.', 'as inspired by hmms, the model simplification of conditional independence can be tempered by multiple layers of ( recurrent ) bidirectional long short - term memory units ( blstms ) [ 1 ] [ 2 ] [ 3 ] [ 4 ].', 'however, these are computationally expensive ( table 1 ), leading to simplifications like gated recurrent units ( grus ) [ 8, 32 ] ; furthermore, the success of the relu ( x ) = max ( 0, x ) nonlinearity in preventing vanishing gradients enabled the use of vanilla bidirectional recurrent deep neural networks ( brdnns ) [ 5, 6, 33 ] to further reduce operations per layer.', 'convolutions over time and / or frequency were first used as initial layers to recurrent neural models, beginning with hmm - nns [ 34 ] and later with ctc, where they are viewed as promoting invariance to temporal and spectral translation in asr [ 8 ], or image translation in handwriting recognition [ 35 ] ; they also serve as a form of dimensionality reduction ( section 2. 4 ).', 'however, these networks were still bottlenecked by the sequentiality of operations at the recurrent layers, leading [ 8 ] to propose row convolutions for unidirectional rnns, which had finite lookaheads to enable online processing while having some future context.', 'this led to convolution - only ctc models for long - range temporal dependencies [ 9 ] [ 10 ] [ 11 ].', 'however, these models have to be very deep ( e. g., 17 - 19 convolutional layers on librispeech [ 23 ] ) to cover the same context ( table 1 ).', 'while in theory, a relatively local context could suffices for asr, this is complicated by alphabets l which violate the conditional independence assumption of ctc ( e. g., english characters [ 36 ] ).', 'wide contexts also enable incorporation of noise / speaker contexts, as  #TAUTHOR_TAG suggest regarding the broad - context attention heads in the first layer of their self - attentional las model']",0
"[').', 'one can also assign interpretations ; for example,  #TAUTHOR_TAG argue their las self - attention heads are differentiated phoneme detectors.', 'further inductive biases like filter widths and causality could be expressed through time - restricted']","['to suffice ).', 'one can also assign interpretations ; for example,  #TAUTHOR_TAG argue their las self - attention heads are differentiated phoneme detectors.', 'further inductive biases like filter widths and causality could be expressed through time - restricted self - attention [ 26 ] and directed self - attention [ 25 ], respectively']","[').', 'one can also assign interpretations ; for example,  #TAUTHOR_TAG argue their las self - attention heads are differentiated phoneme detectors.', 'further inductive biases like filter widths and causality could be expressed through time - restricted self - attention [ 26 ] and directed']","['path length table 1 : operation complexity of each layer type, based on [ 22 ].', 't is input length, d is no. of hidden units, and k is filter / context width.', 'we also see inspiration from convolutional blocks : residual connections, layer normalization, and tied dense layers with relu for representation learning.', 'in particular, multi - head attention is akin to having a number of infinitely - wide filters whose weights adapt to the content ( allowing fewer "" filters "" to suffice ).', 'one can also assign interpretations ; for example,  #TAUTHOR_TAG argue their las self - attention heads are differentiated phoneme detectors.', 'further inductive biases like filter widths and causality could be expressed through time - restricted self - attention [ 26 ] and directed self - attention [ 25 ], respectively']",0
"['- spell ( las )  #TAUTHOR_TAG,']","['listenattend - spell ( las )  #TAUTHOR_TAG,']","['- spell ( las )  #TAUTHOR_TAG,']","['', 'time - restricted self - attention was used as a drop - in replacement for individual layers in the state - of - theart lattice - free mmi model [ 26 ], an hmm - nn system.', 'hybrid self - attention / lstm encoders were studied in the context of listenattend - spell ( las )  #TAUTHOR_TAG, and the transformer was directly adapted to speech in [ 19, 28, 29 ] ; both are encoder - decoder systems.', '']",4
['one concatenates k consecutive frames into one  #TAUTHOR_TAG'],['one concatenates k consecutive frames into one  #TAUTHOR_TAG'],"['one concatenates k consecutive frames into one  #TAUTHOR_TAG.', 'note that ctc will still require u ≤ t / k, however']","['speech, the input length t of frames can be many times larger than the output length u, in contrast to the roughly word - to - word setting of machine translation.', 'this is especially prohibitive for self - attention in terms of memory : recall that an attention matrix of dimension', '∈ r t ×t is created, giving the t 2 factor in table 1.', 'a convolutional frontend is a typical downsampling strategy [ 8, 19 ] ; however, we leave integrating other layer types into san - ctc as future work.', 'instead, we consider three fixed approaches, from least - to most - preserving of the input data : subsampling, which only takes every k - th frame ; pooling, which aggregates every k consecutive frames via a statistic ( average, maximum ) ; reshaping, where one concatenates k consecutive frames into one  #TAUTHOR_TAG.', 'note that ctc will still require u ≤ t / k, however']",4
"['latter was found necessary for self - attentional las  #TAUTHOR_TAG, as additive encodings did not give convergence.', 'however, the monotonicity of ctc is a further positional inductive bias, which may enable the success of content - only and additive encodings']","['latter was found necessary for self - attentional las  #TAUTHOR_TAG, as additive encodings did not give convergence.', 'however, the monotonicity of ctc is a further positional inductive bias, which may enable the success of content - only and additive encodings']","['adds the encoding to the embedding ; and concatenative, where one takes demb = 40 and concatenates it to the embedding.', 'the latter was found necessary for self - attentional las  #TAUTHOR_TAG, as additive encodings did not give convergence.', 'however, the monotonicity of ctc is a further positional inductive bias, which may enable the success of content - only and additive encodings']","['- attention is inherently content - based [ 22 ], and so one often encodes position into the post - embedding vectors.', 'we use standard trigonometric embeddings, where for 0 ≤ i ≤ demb / 2, we define', 'for position t. we consider three approaches : content - only [ 21 ], which forgoes position encodings ; additive [ 19 ], which takes demb = dh and adds the encoding to the embedding ; and concatenative, where one takes demb = 40 and concatenates it to the embedding.', 'the latter was found necessary for self - attentional las  #TAUTHOR_TAG, as additive encodings did not give convergence.', 'however, the monotonicity of ctc is a further positional inductive bias, which may enable the success of content - only and additive encodings']",4
"['- attentional las  #TAUTHOR_TAG, san']","['self - attentional las  #TAUTHOR_TAG, san - ctc works respectably']","['- attentional las  #TAUTHOR_TAG, san']","['train both character - and phoneme - label systems on the 80 - hour wsj training set to validate our architectural choices.', 'similar to [ 17, 19 ], we use 40 - dim.', 'mel - scale filter banks and hence 120 - dim.', 'features.', 'we warmup for 8000 steps, use a dropout of 0. 2, and switch schedules at epoch 40.', 'for the wsj dataset, we compare with similar mle - trained, end - to - end, open - vocabulary systems in table 2.', 'we get an eval92 cer of 4. 7 %, outdoing all previous ctc - like results except 4. 6 % with a trainable frontend [ 40 ].', 'we use the provided extended 3 - gram lm to retrieve wers.', 'for phoneme training, our labels come from the cmu pronunciation lexicon ( table 3 ).', 'these models train in one day ( tesla v100 ), comparable to the speech transformer [ 19 ] ; however, san - ctc gives further benefits at inference time as token predictions are generated in parallel.', 'we also evaluate design choices in table 4.', 'here, we consider the effects of downsampling and position encoding on accuracy for our fixed training regime.', 'we see that unlike self - attentional las  #TAUTHOR_TAG, san - ctc works respectably even with no position en - coding ; in fact, the contribution of position is relatively minor ( compare with [ 21 ], where location in an encoder - decoder system improved cer by 3 % absolute ).', 'lossy downsampling appears to preserve performance in cer while degrading wer ( as information about frame transitions is lost ).', 'we believe these observations align with the monotonicity and independence assumptions of ctc.', 'inspired by  #TAUTHOR_TAG, we plot the standard deviation of attention weights for each head as training progresses ; see figure 2 for details.', 'in the first layers, we similarly observe a differentiation of variances, along with wide - context heads ; in later layers, unlike  #TAUTHOR_TAG we still see mild differentiation of variances.', 'inspired by [ 26 ], we further plot the attention weights relative to the current time position ( here, per head ).', 'character labels gave forward - and backward - attending heads ( incidentally, averaging these would retrieve the bimodal distribution in [ 26 ] ) at all layers.', 'this suggests a gradual expansion of context over depth, as is often engineered in convolutional ctc.', 'this also suggests possibly using fewer heads, directed self - attention [ 25 ], and restricted contexts for faster training ( table 1 ).', 'phoneme labels gave a sharp backward - attending']",4
"['- attentional las  #TAUTHOR_TAG, san']","['self - attentional las  #TAUTHOR_TAG, san - ctc works respectably']","['- attentional las  #TAUTHOR_TAG, san']","['train both character - and phoneme - label systems on the 80 - hour wsj training set to validate our architectural choices.', 'similar to [ 17, 19 ], we use 40 - dim.', 'mel - scale filter banks and hence 120 - dim.', 'features.', 'we warmup for 8000 steps, use a dropout of 0. 2, and switch schedules at epoch 40.', 'for the wsj dataset, we compare with similar mle - trained, end - to - end, open - vocabulary systems in table 2.', 'we get an eval92 cer of 4. 7 %, outdoing all previous ctc - like results except 4. 6 % with a trainable frontend [ 40 ].', 'we use the provided extended 3 - gram lm to retrieve wers.', 'for phoneme training, our labels come from the cmu pronunciation lexicon ( table 3 ).', 'these models train in one day ( tesla v100 ), comparable to the speech transformer [ 19 ] ; however, san - ctc gives further benefits at inference time as token predictions are generated in parallel.', 'we also evaluate design choices in table 4.', 'here, we consider the effects of downsampling and position encoding on accuracy for our fixed training regime.', 'we see that unlike self - attentional las  #TAUTHOR_TAG, san - ctc works respectably even with no position en - coding ; in fact, the contribution of position is relatively minor ( compare with [ 21 ], where location in an encoder - decoder system improved cer by 3 % absolute ).', 'lossy downsampling appears to preserve performance in cer while degrading wer ( as information about frame transitions is lost ).', 'we believe these observations align with the monotonicity and independence assumptions of ctc.', 'inspired by  #TAUTHOR_TAG, we plot the standard deviation of attention weights for each head as training progresses ; see figure 2 for details.', 'in the first layers, we similarly observe a differentiation of variances, along with wide - context heads ; in later layers, unlike  #TAUTHOR_TAG we still see mild differentiation of variances.', 'inspired by [ 26 ], we further plot the attention weights relative to the current time position ( here, per head ).', 'character labels gave forward - and backward - attending heads ( incidentally, averaging these would retrieve the bimodal distribution in [ 26 ] ) at all layers.', 'this suggests a gradual expansion of context over depth, as is often engineered in convolutional ctc.', 'this also suggests possibly using fewer heads, directed self - attention [ 25 ], and restricted contexts for faster training ( table 1 ).', 'phoneme labels gave a sharp backward - attending']",4
"['22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2']","['in the transformer encoder [ 22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2. 3.', 'the other stages are downsampling,']","['in the transformer encoder [ 22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2. 3.', 'the other stages are downsampling,']","['now replace recurrent and convolutional layers for ctc with self - attention [ 24 ].', 'our proposed framework ( figure 1a ) is built around self - attention layers, as used in the transformer encoder [ 22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2. 3.', 'the other stages are downsampling, which reduces input length t via methods like those in section 2. 4 ; embedding, which learns a dh - dim. embedding that also describes token position ( section 2. 5 ) ; and projection, where each final representation is mapped framewise to logits over the intermediate alphabet l.', ""the first implements self - attention, where the success of attention in ctc and encoder - decoder models [ 14, 31 ] is parallelized by using each position's representation to attend to all others, giving a contextualized representation for that position."", 'hence, the full receptive field is immediately available at the cost of o ( t 2 ) inner products ( table 1 ), enabling richer representations in fewer layers']",3
"['- attentional las  #TAUTHOR_TAG, san']","['self - attentional las  #TAUTHOR_TAG, san - ctc works respectably']","['- attentional las  #TAUTHOR_TAG, san']","['train both character - and phoneme - label systems on the 80 - hour wsj training set to validate our architectural choices.', 'similar to [ 17, 19 ], we use 40 - dim.', 'mel - scale filter banks and hence 120 - dim.', 'features.', 'we warmup for 8000 steps, use a dropout of 0. 2, and switch schedules at epoch 40.', 'for the wsj dataset, we compare with similar mle - trained, end - to - end, open - vocabulary systems in table 2.', 'we get an eval92 cer of 4. 7 %, outdoing all previous ctc - like results except 4. 6 % with a trainable frontend [ 40 ].', 'we use the provided extended 3 - gram lm to retrieve wers.', 'for phoneme training, our labels come from the cmu pronunciation lexicon ( table 3 ).', 'these models train in one day ( tesla v100 ), comparable to the speech transformer [ 19 ] ; however, san - ctc gives further benefits at inference time as token predictions are generated in parallel.', 'we also evaluate design choices in table 4.', 'here, we consider the effects of downsampling and position encoding on accuracy for our fixed training regime.', 'we see that unlike self - attentional las  #TAUTHOR_TAG, san - ctc works respectably even with no position en - coding ; in fact, the contribution of position is relatively minor ( compare with [ 21 ], where location in an encoder - decoder system improved cer by 3 % absolute ).', 'lossy downsampling appears to preserve performance in cer while degrading wer ( as information about frame transitions is lost ).', 'we believe these observations align with the monotonicity and independence assumptions of ctc.', 'inspired by  #TAUTHOR_TAG, we plot the standard deviation of attention weights for each head as training progresses ; see figure 2 for details.', 'in the first layers, we similarly observe a differentiation of variances, along with wide - context heads ; in later layers, unlike  #TAUTHOR_TAG we still see mild differentiation of variances.', 'inspired by [ 26 ], we further plot the attention weights relative to the current time position ( here, per head ).', 'character labels gave forward - and backward - attending heads ( incidentally, averaging these would retrieve the bimodal distribution in [ 26 ] ) at all layers.', 'this suggests a gradual expansion of context over depth, as is often engineered in convolutional ctc.', 'this also suggests possibly using fewer heads, directed self - attention [ 25 ], and restricted contexts for faster training ( table 1 ).', 'phoneme labels gave a sharp backward - attending']",3
"['22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2']","['in the transformer encoder [ 22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2. 3.', 'the other stages are downsampling,']","['in the transformer encoder [ 22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2. 3.', 'the other stages are downsampling,']","['now replace recurrent and convolutional layers for ctc with self - attention [ 24 ].', 'our proposed framework ( figure 1a ) is built around self - attention layers, as used in the transformer encoder [ 22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2. 3.', 'the other stages are downsampling, which reduces input length t via methods like those in section 2. 4 ; embedding, which learns a dh - dim. embedding that also describes token position ( section 2. 5 ) ; and projection, where each final representation is mapped framewise to logits over the intermediate alphabet l.', ""the first implements self - attention, where the success of attention in ctc and encoder - decoder models [ 14, 31 ] is parallelized by using each position's representation to attend to all others, giving a contextualized representation for that position."", 'hence, the full receptive field is immediately available at the cost of o ( t 2 ) inner products ( table 1 ), enabling richer representations in fewer layers']",5
"['- attentional las  #TAUTHOR_TAG, san']","['self - attentional las  #TAUTHOR_TAG, san - ctc works respectably']","['- attentional las  #TAUTHOR_TAG, san']","['train both character - and phoneme - label systems on the 80 - hour wsj training set to validate our architectural choices.', 'similar to [ 17, 19 ], we use 40 - dim.', 'mel - scale filter banks and hence 120 - dim.', 'features.', 'we warmup for 8000 steps, use a dropout of 0. 2, and switch schedules at epoch 40.', 'for the wsj dataset, we compare with similar mle - trained, end - to - end, open - vocabulary systems in table 2.', 'we get an eval92 cer of 4. 7 %, outdoing all previous ctc - like results except 4. 6 % with a trainable frontend [ 40 ].', 'we use the provided extended 3 - gram lm to retrieve wers.', 'for phoneme training, our labels come from the cmu pronunciation lexicon ( table 3 ).', 'these models train in one day ( tesla v100 ), comparable to the speech transformer [ 19 ] ; however, san - ctc gives further benefits at inference time as token predictions are generated in parallel.', 'we also evaluate design choices in table 4.', 'here, we consider the effects of downsampling and position encoding on accuracy for our fixed training regime.', 'we see that unlike self - attentional las  #TAUTHOR_TAG, san - ctc works respectably even with no position en - coding ; in fact, the contribution of position is relatively minor ( compare with [ 21 ], where location in an encoder - decoder system improved cer by 3 % absolute ).', 'lossy downsampling appears to preserve performance in cer while degrading wer ( as information about frame transitions is lost ).', 'we believe these observations align with the monotonicity and independence assumptions of ctc.', 'inspired by  #TAUTHOR_TAG, we plot the standard deviation of attention weights for each head as training progresses ; see figure 2 for details.', 'in the first layers, we similarly observe a differentiation of variances, along with wide - context heads ; in later layers, unlike  #TAUTHOR_TAG we still see mild differentiation of variances.', 'inspired by [ 26 ], we further plot the attention weights relative to the current time position ( here, per head ).', 'character labels gave forward - and backward - attending heads ( incidentally, averaging these would retrieve the bimodal distribution in [ 26 ] ) at all layers.', 'this suggests a gradual expansion of context over depth, as is often engineered in convolutional ctc.', 'this also suggests possibly using fewer heads, directed self - attention [ 25 ], and restricted contexts for faster training ( table 1 ).', 'phoneme labels gave a sharp backward - attending']",5
['one concatenates k consecutive frames into one  #TAUTHOR_TAG'],['one concatenates k consecutive frames into one  #TAUTHOR_TAG'],"['one concatenates k consecutive frames into one  #TAUTHOR_TAG.', 'note that ctc will still require u ≤ t / k, however']","['speech, the input length t of frames can be many times larger than the output length u, in contrast to the roughly word - to - word setting of machine translation.', 'this is especially prohibitive for self - attention in terms of memory : recall that an attention matrix of dimension', '∈ r t ×t is created, giving the t 2 factor in table 1.', 'a convolutional frontend is a typical downsampling strategy [ 8, 19 ] ; however, we leave integrating other layer types into san - ctc as future work.', 'instead, we consider three fixed approaches, from least - to most - preserving of the input data : subsampling, which only takes every k - th frame ; pooling, which aggregates every k consecutive frames via a statistic ( average, maximum ) ; reshaping, where one concatenates k consecutive frames into one  #TAUTHOR_TAG.', 'note that ctc will still require u ≤ t / k, however']",6
['not able to incorporate temporal information when checking time - dependent claims  #TAUTHOR_TAG'],['not able to incorporate temporal information when checking time - dependent claims  #TAUTHOR_TAG'],"['are not able to incorporate temporal information when checking time - dependent claims  #TAUTHOR_TAG.', 'in this paper we introduce our fact checking']","['', 'existing fact checking systems are capable of detecting fact - check - worthy claims in text  #AUTHOR_TAG b ), returning semantically similar textual claims  #AUTHOR_TAG ; and scoring the truth of triples on a knowledge graph through semantic distance  #AUTHOR_TAG.', 'however, neither of these are suitable for fact checking a claim made in natural language against a database.', 'previous works appropriate for this task operate on a limited domain and are not able to incorporate temporal information when checking time - dependent claims  #TAUTHOR_TAG.', 'in this paper we introduce our fact checking tool, describe its architecture and design decisions, evaluate its accuracy and discuss future work.', 'we highlight the ease of incorporating new information sources to fact check, which may be unavailable during training.', 'to validate the extensibility of the system, we complete an additional evaluation of the system using claims taken from  #TAUTHOR_TAG.', 'we make the source code publicly available to the community']",0
['not able to incorporate temporal information when checking time - dependent claims  #TAUTHOR_TAG'],['not able to incorporate temporal information when checking time - dependent claims  #TAUTHOR_TAG'],"['are not able to incorporate temporal information when checking time - dependent claims  #TAUTHOR_TAG.', 'in this paper we introduce our fact checking']","['', 'existing fact checking systems are capable of detecting fact - check - worthy claims in text  #AUTHOR_TAG b ), returning semantically similar textual claims  #AUTHOR_TAG ; and scoring the truth of triples on a knowledge graph through semantic distance  #AUTHOR_TAG.', 'however, neither of these are suitable for fact checking a claim made in natural language against a database.', 'previous works appropriate for this task operate on a limited domain and are not able to incorporate temporal information when checking time - dependent claims  #TAUTHOR_TAG.', 'in this paper we introduce our fact checking tool, describe its architecture and design decisions, evaluate its accuracy and discuss future work.', 'we highlight the ease of incorporating new information sources to fact check, which may be unavailable during training.', 'to validate the extensibility of the system, we complete an additional evaluation of the system using claims taken from  #TAUTHOR_TAG.', 'we make the source code publicly available to the community']",5
"['by  #TAUTHOR_TAG.', 'of the 4']","['by  #TAUTHOR_TAG.', 'of the']","['by  #TAUTHOR_TAG.', 'of']","['', 'we further validate the system by evaluating the ability of this fact checking system to make veracity assessments on simple numerical claims from the data set collected by  #TAUTHOR_TAG.', 'of the 4, 255 claims about numerical properties about countries and geographical areas in this data set, our kb contained information to fact check 3, 418.', 'the system presented recalled kb entries for 3, 045 claims ( 89. 1 % ).', 'we observed that the system was consistently unable to fact check two properties ( undernourishment and renewable freshwater per capita ).', 'analysis of these failure cases revealed too great a lexical difference between the test claims and the training data our system generated ; the claims in the test cases were comparative in nature ( e. g. country x has higher rate of undernourishment than country y ) whereas the training data generated using the method described in section 3. 2 are absolute claims.', 'a high number of false positive matches were generated, e. g. for a claim about population, other irrelevant properties were also recalled in addition.', 'for the 3, 045 matched claims, 17, 770 properties were matched from the kb that had a score greater than or equal to the logistic score of the correct property.', 'this means that for every claim, there were, on average, 5. 85 incorrect properties also extracted from the']",5
['set  #TAUTHOR_TAG and on real - world claims presented as part of'],['set  #TAUTHOR_TAG and on real - world claims presented as part of'],"['has been evaluated on a published data set  #TAUTHOR_TAG and on real - world claims presented as part of the herox fact checking challenge.', 'in future work, we will extend the semantic parsing technique used']","['core capability of the system demonstration we presented is to fact check natural language claims against relations stored in a kb.', 'although the range of claims is limited, the system is a fieldtested prototype and has been evaluated on a published data set  #TAUTHOR_TAG and on real - world claims presented as part of the herox fact checking challenge.', 'in future work, we will extend the semantic parsing technique used and apply our system to more complex claim types.', 'additionally, further work is required to reduce the number of candidate relations recalled from the kb.', 'while this was not an issue in our case, we believe that ameliorating this issue will enhance the ability of the system to assign a correct truth label where there exist properties with similar numerical values']",5
"['of  #TAUTHOR_TAG who used distant supervision  #AUTHOR_TAG to generate training data, ob']","['of  #TAUTHOR_TAG who used distant supervision  #AUTHOR_TAG to generate training data,']","['a semantic parsing task ), we extend the work of  #TAUTHOR_TAG who used distant supervision  #AUTHOR_TAG to generate training data, obviating the need for manual labeling.', 'in']","['developed our fact - checking approach in the context of the herox challenge 2 - a competition organised by the fact checking organization fullfact 3.', 'the types of claims the system presented can fact check was restricted to those which require looking up a value in a kb, similar to the one in figure 1.', 'to learn a model to perform the kb look up ( essentially a semantic parsing task ), we extend the work of  #TAUTHOR_TAG who used distant supervision  #AUTHOR_TAG to generate training data, obviating the need for manual labeling.', 'in particular, we extend it to handle simple temporal expressions in order to fact check time - dependent claims appropriately, i. e. population in 2015.', 'while the recently proposed semantic parser of  #AUTHOR_TAG is also able to handle temporal expressions, it makes the assumption that the table against which the claim needs to be interpreted is known, which is unrealistic in the context of fact checking.', 'furthermore, the system we propose can predict relations from the kb on which the semantic parser has not been trained, a paradigm referred to as zero - shot learning  #AUTHOR_TAG.', 'we achieve this by learning a binary classifier that assesses how well the claim "" matches "" each relation in the kb.', 'finally, another consideration in our design is algorithmic accountability  #AUTHOR_TAG so that the predictions and the decision process used by the system are interpretable by a human']",6
['embeddings  #TAUTHOR_TAG. for a'],['embeddings  #TAUTHOR_TAG. for a'],"['embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is']","['in the original kbs. consequently, a promising new research direction is to use relation paths to learn knowledge embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is a semantic interpretation via composition of the meaning of the component elements. each relation path contains its respective consistent semantics. however, the consistent semantics expressed by some relation paths p is unreliable for reasoning', 'new facts of that entity pair  #TAUTHOR_TAG. for instance, there is a common relation path h but this path is meaning', '']",0
['embeddings  #TAUTHOR_TAG. for a'],['embeddings  #TAUTHOR_TAG. for a'],"['embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is']","['in the original kbs. consequently, a promising new research direction is to use relation paths to learn knowledge embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is a semantic interpretation via composition of the meaning of the component elements. each relation path contains its respective consistent semantics. however, the consistent semantics expressed by some relation paths p is unreliable for reasoning', 'new facts of that entity pair  #TAUTHOR_TAG. for instance, there is a common relation path h but this path is meaning', '']",0
['embeddings  #TAUTHOR_TAG. for a'],['embeddings  #TAUTHOR_TAG. for a'],"['embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is']","['in the original kbs. consequently, a promising new research direction is to use relation paths to learn knowledge embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is a semantic interpretation via composition of the meaning of the component elements. each relation path contains its respective consistent semantics. however, the consistent semantics expressed by some relation paths p is unreliable for reasoning', 'new facts of that entity pair  #TAUTHOR_TAG. for instance, there is a common relation path h but this path is meaning', '']",0
['embeddings  #TAUTHOR_TAG. for a'],['embeddings  #TAUTHOR_TAG. for a'],"['embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is']","['in the original kbs. consequently, a promising new research direction is to use relation paths to learn knowledge embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is a semantic interpretation via composition of the meaning of the component elements. each relation path contains its respective consistent semantics. however, the consistent semantics expressed by some relation paths p is unreliable for reasoning', 'new facts of that entity pair  #TAUTHOR_TAG. for instance, there is a common relation path h but this path is meaning', '']",0
"['is ptranse  #TAUTHOR_TAG.', 'ptrans']","['is ptranse  #TAUTHOR_TAG.', 'ptranse considers relation paths as translations between head and tail entities and primarily addresses two problems : 1 ) exploit a variant of pra to select reliable relation paths, and 2 ) explore three path representations by compositions of relation embeddings.', 'pra, as one of the most promising research innovations for']","['distinguish similar embeddings in latent space.', 'a third current related work is ptranse  #TAUTHOR_TAG.', 'ptranse considers relation paths as translations between head and tail entities and primarily addresses two problems : 1 ) exploit a variant of pra to select reliable relation paths, and 2 ) explore three path representations by compositions of relation embeddings.', 'pra, as one of the most promising research innovations for knowledge base completion, has also attracted considerable attention  #TAUTHOR_TAG']","['', 'the projected entity vectors are h r = m r h and t r = m r t ; thus, the new score function is defined as s ( h, r, t ) = h r + r − t r.', 'another research direction focuses on improving the prediction performance by using prior knowledge in the form of relation - specific type constraints [  #AUTHOR_TAG ].', 'note that each relation should possess domain and range fields to indicate the subject and object types, respectively.', ""for example, the relation haschildren's domain and range types both belong to a person."", 'by exploiting these limited rules, the harmful influence of a merely data - driven pattern can be avoided.', 'typeconstrained transe [  #AUTHOR_TAG ] imposes these constraints on the global margin - loss function to better distinguish similar embeddings in latent space.', 'a third current related work is ptranse  #TAUTHOR_TAG.', 'ptranse considers relation paths as translations between head and tail entities and primarily addresses two problems : 1 ) exploit a variant of pra to select reliable relation paths, and 2 ) explore three path representations by compositions of relation embeddings.', 'pra, as one of the most promising research innovations for knowledge base completion, has also attracted considerable attention  #TAUTHOR_TAG']",0
"['is ptranse  #TAUTHOR_TAG.', 'ptrans']","['is ptranse  #TAUTHOR_TAG.', 'ptranse considers relation paths as translations between head and tail entities and primarily addresses two problems : 1 ) exploit a variant of pra to select reliable relation paths, and 2 ) explore three path representations by compositions of relation embeddings.', 'pra, as one of the most promising research innovations for']","['distinguish similar embeddings in latent space.', 'a third current related work is ptranse  #TAUTHOR_TAG.', 'ptranse considers relation paths as translations between head and tail entities and primarily addresses two problems : 1 ) exploit a variant of pra to select reliable relation paths, and 2 ) explore three path representations by compositions of relation embeddings.', 'pra, as one of the most promising research innovations for knowledge base completion, has also attracted considerable attention  #TAUTHOR_TAG']","['', 'the projected entity vectors are h r = m r h and t r = m r t ; thus, the new score function is defined as s ( h, r, t ) = h r + r − t r.', 'another research direction focuses on improving the prediction performance by using prior knowledge in the form of relation - specific type constraints [  #AUTHOR_TAG ].', 'note that each relation should possess domain and range fields to indicate the subject and object types, respectively.', ""for example, the relation haschildren's domain and range types both belong to a person."", 'by exploiting these limited rules, the harmful influence of a merely data - driven pattern can be avoided.', 'typeconstrained transe [  #AUTHOR_TAG ] imposes these constraints on the global margin - loss function to better distinguish similar embeddings in latent space.', 'a third current related work is ptranse  #TAUTHOR_TAG.', 'ptranse considers relation paths as translations between head and tail entities and primarily addresses two problems : 1 ) exploit a variant of pra to select reliable relation paths, and 2 ) explore three path representations by compositions of relation embeddings.', 'pra, as one of the most promising research innovations for knowledge base completion, has also attracted considerable attention  #TAUTHOR_TAG']",0
['embeddings  #TAUTHOR_TAG. for a'],['embeddings  #TAUTHOR_TAG. for a'],"['embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is']","['in the original kbs. consequently, a promising new research direction is to use relation paths to learn knowledge embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is a semantic interpretation via composition of the meaning of the component elements. each relation path contains its respective consistent semantics. however, the consistent semantics expressed by some relation paths p is unreliable for reasoning', 'new facts of that entity pair  #TAUTHOR_TAG. for instance, there is a common relation path h but this path is meaning', '']",1
['embeddings  #TAUTHOR_TAG. for a'],['embeddings  #TAUTHOR_TAG. for a'],"['embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is']","['in the original kbs. consequently, a promising new research direction is to use relation paths to learn knowledge embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is a semantic interpretation via composition of the meaning of the component elements. each relation path contains its respective consistent semantics. however, the consistent semantics expressed by some relation paths p is unreliable for reasoning', 'new facts of that entity pair  #TAUTHOR_TAG. for instance, there is a common relation path h but this path is meaning', '']",1
['embeddings  #TAUTHOR_TAG. for a'],['embeddings  #TAUTHOR_TAG. for a'],"['embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is']","['in the original kbs. consequently, a promising new research direction is to use relation paths to learn knowledge embeddings  #TAUTHOR_TAG. for a relation path', ', consistent semantics is a semantic interpretation via composition of the meaning of the component elements. each relation path contains its respective consistent semantics. however, the consistent semantics expressed by some relation paths p is unreliable for reasoning', 'new facts of that entity pair  #TAUTHOR_TAG. for instance, there is a common relation path h but this path is meaning', '']",1
"[' #TAUTHOR_TAG.', 'first, for']","['used in [  #TAUTHOR_TAG.', 'first, for']","[' #TAUTHOR_TAG.', 'first, for']","['follow the same evaluation procedures as used in [  #TAUTHOR_TAG.', 'first, for each test triple ( h, r, t ), we replace h or t with every entity in ζ.', 'second, each corrupted triple is calculated by the corresponding score function s ( h, r, t ).', 'the final step is to rank the original correct entity with these scores in descending order.', '']",5
"[' #TAUTHOR_TAG.', 'first, for']","['used in [  #TAUTHOR_TAG.', 'first, for']","[' #TAUTHOR_TAG.', 'first, for']","['follow the same evaluation procedures as used in [  #TAUTHOR_TAG.', 'first, for each test triple ( h, r, t ), we replace h or t with every entity in ζ.', 'second, each corrupted triple is calculated by the corresponding score function s ( h, r, t ).', 'the final step is to rank the original correct entity with these scores in descending order.', '']",5
"['directly compare our model with prior work using the results about knowledge embedding models reported in  #TAUTHOR_TAG n = 50, m = 50, γ 1 =']","['directly compare our model with prior work using the results about knowledge embedding models reported in  #TAUTHOR_TAG n = 50, m = 50, γ 1 = 5, γ 2 = 6, α = 0. 0001, b = 1440, λ = 0. 8, and η = 0. 05, taking the']","['directly compare our model with prior work using the results about knowledge embedding models reported in  #TAUTHOR_TAG n = 50, m = 50, γ 1 =']","['directly compare our model with prior work using the results about knowledge embedding models reported in  #TAUTHOR_TAG n = 50, m = 50, γ 1 = 5, γ 2 = 6, α = 0. 0001, b = 1440, λ = 0. 8, and η = 0. 05, taking the l 1 norm on wn11 ; n = 100, m = 100, γ 1 = 3, γ 2 = 6, α = 0. 0001, b = 960, λ = 0. 8, and η = 0. 05, taking the l 1 norm on fb13 ; and n = 100, m = 100, γ 1 = 4, γ 2 = 5, α = 0. 0001, b = 4800, λ = 1, and η = 0. 05, taking the l 1 norm on fb15k.', 'we exploit rpe ( initial ) for initiation, and we set the path length as 2 and the maximum epoch as 500.', 'table 4 lists the results for triple classification on different datasets, and the evaluation metric is classification accuracy.', 'the results demonstrate that 1 ) rpe ( pc + acom ) achieves the best performance on all datasets, which takes good advantage of path - specific projection and type constraints ; 2 ) rpe ( pc ) improves the performance of rpe ( initial ) by 4. 5 %, 6. 0 %, and 13. 2 %, particularly on fb15k ; thus, we consider that lengthening the distances for similar entities in embedding space is essential to specific problems.', 'the results of experiments also indicate that although lcwa can compensate for the loss for type information, real relation - type information is predominant']",5
['transr ( unif )  #TAUTHOR_TAG 80 that pla'],['3 85. 8 transr ( unif )  #TAUTHOR_TAG 80 that pla'],['transr ( unif )  #TAUTHOR_TAG 80 that pla'],"['', 'transh ( bern ) [  #AUTHOR_TAG ] 78. 8 83. 3 85. 8 transr ( unif )  #TAUTHOR_TAG 80 that plague knowledge embedding models', '']",4
[' #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional'],['et al.  #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional'],"[' #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional architecture that computes a scattering transform and can be initialized as an approximation of mel - filterbanks, and obtained promising results']","['by gammatone filterbanks of hoshen et al. and sainath et al. [ 3, 4 ] achieved similar or better results than comparable', 'mel - filterbanks on multichannel speech recognition and on far - field / noisy recording conditions. more recently, zeghidour et al.  #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional architecture that computes a scattering transform and can be initialized as an approximation of mel - filterbanks, and obtained promising results on endto - end phone recognition on timit. however, these approaches have not been proven to improve on speech features on largescale, end - to - end speech recognition in clean recording conditions on english - admittedly one of the tasks for which melfilterbank', '##s have been the most extensively tuned. we present a systematic comparison of the two previous architectures of', 'learnable filterbanks, which we will ( coarsely ) refer to as gammatone - based and scattering - based, and evaluate them', 'against mel - filterbanks within an end - to - end training pipeline on letter error rate and word error rate on the wall street journal dataset. our main contributions and results are the following : 1. a mean - variance normalization layer on top of the log nonlinearity of learnable', '']",0
[' #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional'],['et al.  #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional'],"[' #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional architecture that computes a scattering transform and can be initialized as an approximation of mel - filterbanks, and obtained promising results']","['by gammatone filterbanks of hoshen et al. and sainath et al. [ 3, 4 ] achieved similar or better results than comparable', 'mel - filterbanks on multichannel speech recognition and on far - field / noisy recording conditions. more recently, zeghidour et al.  #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional architecture that computes a scattering transform and can be initialized as an approximation of mel - filterbanks, and obtained promising results on endto - end phone recognition on timit. however, these approaches have not been proven to improve on speech features on largescale, end - to - end speech recognition in clean recording conditions on english - admittedly one of the tasks for which melfilterbank', '##s have been the most extensively tuned. we present a systematic comparison of the two previous architectures of', 'learnable filterbanks, which we will ( coarsely ) refer to as gammatone - based and scattering - based, and evaluate them', 'against mel - filterbanks within an end - to - end training pipeline on letter error rate and word error rate on the wall street journal dataset. our main contributions and results are the following : 1. a mean - variance normalization layer on top of the log nonlinearity of learnable', '']",0
"['from  #TAUTHOR_TAG.', 'they are described in']","['from  #TAUTHOR_TAG.', 'they are described in']","['3, 4 ], the second one is taken from  #TAUTHOR_TAG.', 'they are described in table 1.', 'in both architectures, a convolutional layer with window length 25ms ( to match the standard frame size used in melfilterbank']","['two approaches that we consider for learning filterbanks from the raw waveform can be used as direct replacement for mel - filterbanks in any end - to - end learning pipeline : they are convolutional architectures that take the raw waveform as input and output 40 channels every 10ms.', 'as such, they can directly be compared with standard mel - filterbanks, simply by changing the features stage of a neural - network - based acoustic model.', 'the filters are then nothing more than an additional layer to the neural network and are learnt by backpropagation with the rest of the acoustic model.', 'the first architecture we consider is inspired by [ 3, 4 ], the second one is taken from  #TAUTHOR_TAG.', 'they are described in table 1.', 'in both architectures, a convolutional layer with window length 25ms ( to match the standard frame size used in melfilterbanks ) is applied with a stride of 1 sample, and is followed by a nonlinearity to give 40 output channels for each sample.', '']",0
[' #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional'],['et al.  #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional'],"[' #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional architecture that computes a scattering transform and can be initialized as an approximation of mel - filterbanks, and obtained promising results']","['by gammatone filterbanks of hoshen et al. and sainath et al. [ 3, 4 ] achieved similar or better results than comparable', 'mel - filterbanks on multichannel speech recognition and on far - field / noisy recording conditions. more recently, zeghidour et al.  #TAUTHOR_TAG proposed an alternative learnable architecture based on a convolutional architecture that computes a scattering transform and can be initialized as an approximation of mel - filterbanks, and obtained promising results on endto - end phone recognition on timit. however, these approaches have not been proven to improve on speech features on largescale, end - to - end speech recognition in clean recording conditions on english - admittedly one of the tasks for which melfilterbank', '##s have been the most extensively tuned. we present a systematic comparison of the two previous architectures of', 'learnable filterbanks, which we will ( coarsely ) refer to as gammatone - based and scattering - based, and evaluate them', 'against mel - filterbanks within an end - to - end training pipeline on letter error rate and word error rate on the wall street journal dataset. our main contributions and results are the following : 1. a mean - variance normalization layer on top of the log nonlinearity of learnable', '']",4
"['.  #TAUTHOR_TAG, who']","['fixed while learning the convolution filter weights, a setting that was not explored by zeghidour et al.  #TAUTHOR_TAG, who learnt the lowpass filter weights when randomly initializing the convolutions']","['.  #TAUTHOR_TAG, who']","['original papers describing the gammatone - based trainable filterbanks used max - pooling as low - pass filter, whereas the scattering - based approach uses a squared hanning window per channel.', 'to make sure the low - pass filter is not responsible for notable differences between the two approaches we experiment with the squared hanning window on both architectures.', 'for both architectures, we also propose to keep this low - pass filter fixed while learning the convolution filter weights, a setting that was not explored by zeghidour et al.  #TAUTHOR_TAG, who learnt the lowpass filter weights when randomly initializing the convolutions']",4
"['[ 3, 4, 7,  #TAUTHOR_TAG but is used in our baseline.', '']","['[ 3, 4, 7,  #TAUTHOR_TAG but is used in our baseline.', '']","['[ 3, 4, 7,  #TAUTHOR_TAG but is used in our baseline.', 'figure 1 shows training ler']","['described in section 2. 2, we evaluate the integration of instance normalization after the log - compression in the trainable filterbanks, which was not used in previous work [ 3, 4, 7,  #TAUTHOR_TAG but is used in our baseline.', '']",4
['in  #TAUTHOR_TAG where'],['in  #TAUTHOR_TAG where'],['with the gabor wavelet initialization that was observed in  #TAUTHOR_TAG where the lowpass filter was also initialized randomly'],"['low - pass filtering, we first compare the han - fixed setting to max - pooling for gammatone - based filterbanks ( as max - pooling was previously used in [ 3, 4 ] ), and to han - learnt for scattering, all with instance normalization.', 'the tendency is that the han - fixed setting consistently improves the results in ler and wer of both trainable filterbanks.', 'more importantly, using either an han - fixed or han - learnt filter when learning scatteringbased filterbanks from a random initialization removes the gap in performance with the gabor wavelet initialization that was observed in  #TAUTHOR_TAG where the lowpass filter was also initialized randomly.', 'this is an important result since carefully initializing the convolutional filters is both technically non - trivial, and also relies on the prior knowledge of mel - filterbanks.', 'we believe the ability to use random initialization is an important first step for more extensive tuning of trainable filterbanks ( e. g., trying different numbers of filters, decimation or convolution width ).', 'compared to the literature, replacing the max - pooling by a low - pass filter and adding an instance normalization layer leads to a 23 % relative improvement in ler and a 33 % relative improvement in wer on nov92 - eval on the gammatone - based trainable filterbanks, a significant improvement compared to the existing approach [ 3, 4 ].', 'our models trained on the waveform also exhibit a gain in performance in ler of 22 − 31 % relative compared to the state - of - the - art end - to - end model trained on the waveform with its first 6 layers being pre - trained for melfilterbanks reconstruction [ 26 ], and outperform various end - toend models trained on speech features, both in ler [ 24, 25 ] and wer [ 21, 22, 23 ]']",4
"['from  #TAUTHOR_TAG.', 'they are described in']","['from  #TAUTHOR_TAG.', 'they are described in']","['3, 4 ], the second one is taken from  #TAUTHOR_TAG.', 'they are described in table 1.', 'in both architectures, a convolutional layer with window length 25ms ( to match the standard frame size used in melfilterbank']","['two approaches that we consider for learning filterbanks from the raw waveform can be used as direct replacement for mel - filterbanks in any end - to - end learning pipeline : they are convolutional architectures that take the raw waveform as input and output 40 channels every 10ms.', 'as such, they can directly be compared with standard mel - filterbanks, simply by changing the features stage of a neural - network - based acoustic model.', 'the filters are then nothing more than an additional layer to the neural network and are learnt by backpropagation with the rest of the acoustic model.', 'the first architecture we consider is inspired by [ 3, 4 ], the second one is taken from  #TAUTHOR_TAG.', 'they are described in table 1.', 'in both architectures, a convolutional layer with window length 25ms ( to match the standard frame size used in melfilterbanks ) is applied with a stride of 1 sample, and is followed by a nonlinearity to give 40 output channels for each sample.', '']",5
"['emulate a complex - valued convolution with 40 filters followed by a squared modulus operator.', 'thus, after the nonlinearity, both architectures have 40 filters.', '2  #TAUTHOR_TAG use 1 to prevent log ( 0 ) and [ 3, 4 ] use 0. 01.', 'we kept the values initially used by the authors of the respective papers and did not try alternatives.', 'we believe it has little impact on the final performance']","['emulate a complex - valued convolution with 40 filters followed by a squared modulus operator.', 'thus, after the nonlinearity, both architectures have 40 filters.', '2  #TAUTHOR_TAG use 1 to prevent log ( 0 ) and [ 3, 4 ] use 0. 01.', 'we kept the values initially used by the authors of the respective papers and did not try alternatives.', 'we believe it has little impact on the final performance']","['emulate a complex - valued convolution with 40 filters followed by a squared modulus operator.', 'thus, after the nonlinearity, both architectures have 40 filters.', '2  #TAUTHOR_TAG use 1 to prevent log ( 0 ) and [ 3, 4 ] use 0. 01.', 'we kept the values initially used by the authors of the respective papers and did not try alternatives.', 'we believe it has little impact on the final performance']","['experiments compare different versions of the trainable architectures against log mel - filterbanks on a single deep convolutional network architecture for the acoustic model.', 'the experiments are carried out on the open vocabulary task of the wall street journal dataset [ 13 ], using the subset si284 for training, nov93 - dev for validation, and nov92 - eval for testing.', 'training is performed end - to - end on letters.', 'we evaluate in both letter and word error rates.', 'all our experiments use the open source code of wav2letter [ 14 ].', 'in the next subsections, we describe the model, the different variants we tested and the hyperparameters.', '1 the convolution for the scattering - based architecture uses 80 - real valued output channels and squared l2 - pooling on the feature dimension to emulate a complex - valued convolution with 40 filters followed by a squared modulus operator.', 'thus, after the nonlinearity, both architectures have 40 filters.', '2  #TAUTHOR_TAG use 1 to prevent log ( 0 ) and [ 3, 4 ] use 0. 01.', 'we kept the values initially used by the authors of the respective papers and did not try alternatives.', 'we believe it has little impact on the final performance']",5
"['not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models']","['not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models']","['not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models']","["": mediku # aren # era more specifically, mbert's subwords tend to be shorter and less interpret"", ""##able, while our subwords are closer to linguistically interpretable strings, like mediku ( doctor ) aren ('s ) and era ( to the ). furthermore, most of the"", 'time the released models have been thoroughly tested only in english. alternatively, multilingual versions have been tested in transfer', 'learning scenarios for other languages, where they have not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models for basque with analogous models which have been trained with a larger, better quality corpus. this has been possible', 'for the fasttext and flair models. in the case of bert, only the multilingual version for 104 languages is available for basque. we focus on four downstream nlp tasks', ', namely, topic classification, sentiment classification, partof - speech ( pos ) tagging and', '']",0
"['not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models']","['not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models']","['not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models']","["": mediku # aren # era more specifically, mbert's subwords tend to be shorter and less interpret"", ""##able, while our subwords are closer to linguistically interpretable strings, like mediku ( doctor ) aren ('s ) and era ( to the ). furthermore, most of the"", 'time the released models have been thoroughly tested only in english. alternatively, multilingual versions have been tested in transfer', 'learning scenarios for other languages, where they have not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models for basque with analogous models which have been trained with a larger, better quality corpus. this has been possible', 'for the fasttext and flair models. in the case of bert, only the multilingual version for 104 languages is available for basque. we focus on four downstream nlp tasks', ', namely, topic classification, sentiment classification, partof - speech ( pos ) tagging and', '']",0
"['not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models']","['not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models']","['not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models']","["": mediku # aren # era more specifically, mbert's subwords tend to be shorter and less interpret"", ""##able, while our subwords are closer to linguistically interpretable strings, like mediku ( doctor ) aren ('s ) and era ( to the ). furthermore, most of the"", 'time the released models have been thoroughly tested only in english. alternatively, multilingual versions have been tested in transfer', 'learning scenarios for other languages, where they have not been compared to monolingual versions  #TAUTHOR_TAG. the goal of this paper is to', 'compare publicly available models for basque with analogous models which have been trained with a larger, better quality corpus. this has been possible', 'for the fasttext and flair models. in the case of bert, only the multilingual version for 104 languages is available for basque. we focus on four downstream nlp tasks', ', namely, topic classification, sentiment classification, partof - speech ( pos ) tagging and', '']",0
['bert and elmo  #TAUTHOR_TAG'],['bert and elmo  #TAUTHOR_TAG'],"['bert and elmo  #TAUTHOR_TAG.', 'in any case, flair is of interest to us']","['##air refers to both a deep learning system and to a specific type of character - based contextual word embeddings.', 'flair ( embeddings and system ) have been successfully applied to sequence labeling tasks obtaining state - of - the - art results for a number of english named entity recognition ( ner ) and part - of - speech tagging benchmarks  #AUTHOR_TAG, outperforming other well - known approaches such as bert and elmo  #TAUTHOR_TAG.', 'in any case, flair is of interest to us because they distribute their own basque pre - trained embedding models obtained from a corpus of 36m tokens ( combining opus and wikipedia ).', 'flair - bmc models : we train our own flair embeddings using the bmc corpus with the following parameters : hidden size 2048, sequence length of 250, and a mini - batch size of 100.', 'the rest of the parameters are left in their default setting.', 'training was done for 5 epochs over the full training corpus.', 'the training of each model took 48h on a nvidia titan v gpu.', ""flair embeddings : flair's embeddings model words as sequences of characters."", '']",0
"['and trained as language models.', 'more recently,  #TAUTHOR_TAG introduced bert, a model based on the transformer architecture trained as a masked language model, which has obtained very good']","['and trained as language models.', 'more recently,  #TAUTHOR_TAG introduced bert, a model based on the transformer architecture trained as a masked language model, which has obtained very good']","['upon lstm - based architectures and trained as language models.', 'more recently,  #TAUTHOR_TAG introduced bert, a model based on the transformer architecture trained as a masked language model, which has obtained very good results on a variety of nlp tasks.', 'the multilingual counterpart of bert, called mb']","['', 'examples of such contextual representations are elmo  #AUTHOR_TAG and flair  #AUTHOR_TAG, which are built upon lstm - based architectures and trained as language models.', 'more recently,  #TAUTHOR_TAG introduced bert, a model based on the transformer architecture trained as a masked language model, which has obtained very good results on a variety of nlp tasks.', 'the multilingual counterpart of bert, called mbert, is a single language model pre - trained from corpora in more than 100 languages.', 'mbert enables to perform transfer knowledge techniques among languages, so that systems can be trained on datasets in languages different to the one used to fine tune them  #AUTHOR_TAG.', 'when pre - training mbert the corpora sizes in different languages are very diverse, with english corpora being order of magnitudes larger than that of the minority languages.', 'the authors alleviate this issue by oversampling examples of lower resource languages.', 'however, as the parameters and vocabulary is shared across the languages, this means that each language has to share the quota of substrings and parameters with the rest of the languages.', 'as shown in the introduction, this causes tokenization problems for']",1
['sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with'],['sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with'],['the sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with learning rate'],"['', '. in order to create input examples for the nsp task, we take two segments, a and b, from the training corpus, where b is the true next segment for a only for', '50 % of the cases. for the rest, b is just a random segment from the corpus. at the end, the', 'model is trained to optimize the sum of the means', 'of the mlm and nsp likelihoods. as our vocabulary consists of sub - word units, we use whole - word masking ( ww', '##m ), that applies the masking to whole words instead of sub - word units. this new masking strategy makes the mlm task more difficult for the system as it', 'has to predict the whole word instead of predicting just part of it. an upgraded version of bert large 7 has proven that wwm has substantial benefits in', 'comparison with previous masking that was done after the sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with learning rate of 1e − 4, β 1 =', '0. 9, β 2 = 0. 999, l2 weight decay of 0. 01, learning rate warmup over the first 10, 0000 steps, and linear decay', 'of the learning rate. the dropout probability is fixed to 0. 1 on all the layers. as the attentions are quadratic to the sequence length, making longer sequences much more expensive, we', 'pre - train the model with sequence length of 128 for 90 % of the steps and sequence length of 512 for 10 % of the steps. in total we train for 1, 000, 000 steps and a batch', 'size of 256. the first 90 % steps are trained using cloud v', '##2 tpus and for the rest of the steps we use cloud v3 tpus 8']",5
['official multilingual bert  #TAUTHOR_TAG model and with our berteus model ( trained as described in section 3'],"['official multilingual bert  #TAUTHOR_TAG model and with our berteus model ( trained as described in section 3. 3. ).', '']","['of the four tasks with both the official multilingual bert  #TAUTHOR_TAG model and with our berteus model ( trained as described in section 3. 3. ).', '']","['', 'the datasets used for each task are described in their respective sections.', 'we train our systems to perform the following comparisons : ( i ) fasttext official models ( wikipedia and common crawl ) vs fasttext - bmc model ; ( ii ) the official flair embedding models vs our flair - bmc model and, ( iii ) berteus with respect to multilingual bert.', 'to train the flair system we use the parameters specified in  #AUTHOR_TAG for pooled contextual embeddings.', 'flair is tuned on the development data using the test only for the final evaluation.', 'we do not use the development set for training.', 'for comparison between bert models we fine - tune on the training data provided for each of the four tasks with both the official multilingual bert  #TAUTHOR_TAG model and with our berteus model ( trained as described in section 3. 3. ).', 'every reported result for every system is the average of five randomly initialized runs.', 'the pos and ner experiments using mbert and berteus are performed using the transformers library  #AUTHOR_TAG where it is recommended to remove the seed for random initialization']",5
['sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with'],['sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with'],['the sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with learning rate'],"['', '. in order to create input examples for the nsp task, we take two segments, a and b, from the training corpus, where b is the true next segment for a only for', '50 % of the cases. for the rest, b is just a random segment from the corpus. at the end, the', 'model is trained to optimize the sum of the means', 'of the mlm and nsp likelihoods. as our vocabulary consists of sub - word units, we use whole - word masking ( ww', '##m ), that applies the masking to whole words instead of sub - word units. this new masking strategy makes the mlm task more difficult for the system as it', 'has to predict the whole word instead of predicting just part of it. an upgraded version of bert large 7 has proven that wwm has substantial benefits in', 'comparison with previous masking that was done after the sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with learning rate of 1e − 4, β 1 =', '0. 9, β 2 = 0. 999, l2 weight decay of 0. 01, learning rate warmup over the first 10, 0000 steps, and linear decay', 'of the learning rate. the dropout probability is fixed to 0. 1 on all the layers. as the attentions are quadratic to the sequence length, making longer sequences much more expensive, we', 'pre - train the model with sequence length of 128 for 90 % of the steps and sequence length of 512 for 10 % of the steps. in total we train for 1, 000, 000 steps and a batch', 'size of 256. the first 90 % steps are trained using cloud v', '##2 tpus and for the rest of the steps we use cloud v3 tpus 8']",4
['sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with'],['sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with'],['the sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with learning rate'],"['', '. in order to create input examples for the nsp task, we take two segments, a and b, from the training corpus, where b is the true next segment for a only for', '50 % of the cases. for the rest, b is just a random segment from the corpus. at the end, the', 'model is trained to optimize the sum of the means', 'of the mlm and nsp likelihoods. as our vocabulary consists of sub - word units, we use whole - word masking ( ww', '##m ), that applies the masking to whole words instead of sub - word units. this new masking strategy makes the mlm task more difficult for the system as it', 'has to predict the whole word instead of predicting just part of it. an upgraded version of bert large 7 has proven that wwm has substantial benefits in', 'comparison with previous masking that was done after the sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with learning rate of 1e − 4, β 1 =', '0. 9, β 2 = 0. 999, l2 weight decay of 0. 01, learning rate warmup over the first 10, 0000 steps, and linear decay', 'of the learning rate. the dropout probability is fixed to 0. 1 on all the layers. as the attentions are quadratic to the sequence length, making longer sequences much more expensive, we', 'pre - train the model with sequence length of 128 for 90 % of the steps and sequence length of 512 for 10 % of the steps. in total we train for 1, 000, 000 steps and a batch', 'size of 256. the first 90 % steps are trained using cloud v', '##2 tpus and for the rest of the steps we use cloud v3 tpus 8']",6
['sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with'],['sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with'],['the sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with learning rate'],"['', '. in order to create input examples for the nsp task, we take two segments, a and b, from the training corpus, where b is the true next segment for a only for', '50 % of the cases. for the rest, b is just a random segment from the corpus. at the end, the', 'model is trained to optimize the sum of the means', 'of the mlm and nsp likelihoods. as our vocabulary consists of sub - word units, we use whole - word masking ( ww', '##m ), that applies the masking to whole words instead of sub - word units. this new masking strategy makes the mlm task more difficult for the system as it', 'has to predict the whole word instead of predicting just part of it. an upgraded version of bert large 7 has proven that wwm has substantial benefits in', 'comparison with previous masking that was done after the sub - word tokenization. pre - training procedure similar to  #TAUTHOR_TAG we use adam with learning rate of 1e − 4, β 1 =', '0. 9, β 2 = 0. 999, l2 weight decay of 0. 01, learning rate warmup over the first 10, 0000 steps, and linear decay', 'of the learning rate. the dropout probability is fixed to 0. 1 on all the layers. as the attentions are quadratic to the sequence length, making longer sequences much more expensive, we', 'pre - train the model with sequence length of 128 for 90 % of the steps and sequence length of 512 for 10 % of the steps. in total we train for 1, 000, 000 steps and a batch', 'size of 256. the first 90 % steps are trained using cloud v', '##2 tpus and for the rest of the steps we use cloud v3 tpus 8']",3
['official multilingual bert  #TAUTHOR_TAG model and with our berteus model ( trained as described in section 3'],"['official multilingual bert  #TAUTHOR_TAG model and with our berteus model ( trained as described in section 3. 3. ).', '']","['of the four tasks with both the official multilingual bert  #TAUTHOR_TAG model and with our berteus model ( trained as described in section 3. 3. ).', '']","['', 'the datasets used for each task are described in their respective sections.', 'we train our systems to perform the following comparisons : ( i ) fasttext official models ( wikipedia and common crawl ) vs fasttext - bmc model ; ( ii ) the official flair embedding models vs our flair - bmc model and, ( iii ) berteus with respect to multilingual bert.', 'to train the flair system we use the parameters specified in  #AUTHOR_TAG for pooled contextual embeddings.', 'flair is tuned on the development data using the test only for the final evaluation.', 'we do not use the development set for training.', 'for comparison between bert models we fine - tune on the training data provided for each of the four tasks with both the official multilingual bert  #TAUTHOR_TAG model and with our berteus model ( trained as described in section 3. 3. ).', 'every reported result for every system is the average of five randomly initialized runs.', 'the pos and ner experiments using mbert and berteus are performed using the transformers library  #AUTHOR_TAG where it is recommended to remove the seed for random initialization']",3
"['. recently,', ' #TAUTHOR_TAG presented a model of']","['. recently,', ' #TAUTHOR_TAG presented a model of']","['. recently,', ' #TAUTHOR_TAG presented a model of eye']","['', ' #TAUTHOR_TAG presented a model of eye movement control in reading that directly models the process of identifying the text from visual input, and makes eye movements to maximize the efficiency of the identification', '']",0
"['. recently,', ' #TAUTHOR_TAG presented a model of']","['. recently,', ' #TAUTHOR_TAG presented a model of']","['. recently,', ' #TAUTHOR_TAG presented a model of eye']","['', ' #TAUTHOR_TAG presented a model of eye movement control in reading that directly models the process of identifying the text from visual input, and makes eye movements to maximize the efficiency of the identification', '']",0
['rational model presented in  #TAUTHOR_TAG'],['rational model presented in  #TAUTHOR_TAG'],['the rational model presented in  #TAUTHOR_TAG'],"['this paper, we argued that the success of major models of eye movements in reading to reproduce the ( positive ) human effect of word length via acuity limitations may be a result of not including opposing factors such as the negative correlation between visual neighborhood size and word length.', 'we described the failure of the rational model presented in  #TAUTHOR_TAG to obtain humanlike effects of word length, despite including all of these factors, suggesting that our understanding of word length effects in reading is incomplete.', ""we proposed a new reason for word length effects - uncertainty about word length that is larger for longer wordsand noted that this reason was not implemented in bicknell and levy's model because of a simplifying assumption."", 'we presented an extension of the model relaxing this assumption, in which readers obtain noisy information about word length, and showed through two sets of simulations that the new model produces effects of word length that look more like those of human readers.', 'interestingly, while adding length uncertainty made both models more humanlike, it was only in simulation 2 - in which words had more realistic visual neighborhoods - that all measures of the effect of word length on eye movements showed the human pattern, underscoring the importance of the structure of the language for this account of word length effects.', 'we take these results as evidence that word length effects cannot be completely explained through limitations on visual acuity.', 'rather, they suggest that a full understanding of the reasons underlying word length effects on eye movements in reading should include a notion of uncertainty about the number of letters in a word, which grows with word length']",0
"['. recently,', ' #TAUTHOR_TAG presented a model of']","['. recently,', ' #TAUTHOR_TAG presented a model of']","['. recently,', ' #TAUTHOR_TAG presented a model of eye']","['', ' #TAUTHOR_TAG presented a model of eye movement control in reading that directly models the process of identifying the text from visual input, and makes eye movements to maximize the efficiency of the identification', '']",4
"['of this paper', ', we describe an extension of  #TAUTHOR_TAG']","['of this paper', ', we describe an extension of  #TAUTHOR_TAG model in which visual input provides stochastic -']","['of this paper', ', we describe an extension of  #TAUTHOR_TAG model in which visual input provides stochastic -']","['', 'early in processing. if readers have uncertainty about the length of words, we may expect that the amount of uncertainty would grow proportionally to length, as uncertainty is proportional to set size in other tasks of', 'number estimation  #AUTHOR_TAG. this would agree with the intuition that an 8 - character word should be more easily confused with a 9 - character word than a 3 - character word with a 4 - character word. including uncertainty about word length that is larger for longer', 'words would have the effect of increasing the number of visual neighbors for longer words more than for shorter words, providing another reason ( in addition to visual acuity limitations ) that longer words may require more and longer fixations. in the remainder of this paper', ', we describe an extension of  #TAUTHOR_TAG model in which visual input provides stochastic - rather than veridical - information about the length of words, yielding uncertainty about word length, and in which the amount of uncertainty grows with length. we then present two sets of simulations with this extended model demonstrating that it produces more humanlike effects of word length, suggesting that uncertainty about word length may be an', 'important component of a full understanding of the effects of word length in reading']",4
"['test the model on a corpus of 33 sentences from the schilling corpus slightly modified by  #TAUTHOR_TAG so that every bigram occurred in the bnc, ensuring that the results']","['test the model on a corpus of 33 sentences from the schilling corpus slightly modified by  #TAUTHOR_TAG so that every bigram occurred in the bnc, ensuring that the results']","['test the model on a corpus of 33 sentences from the schilling corpus slightly modified by  #TAUTHOR_TAG so that every bigram occurred in the bnc, ensuring that the results do not depend on smoothing']","['test the model on a corpus of 33 sentences from the schilling corpus slightly modified by  #TAUTHOR_TAG so that every bigram occurred in the bnc, ensuring that the results do not depend on smoothing']",4
"['. recently,', ' #TAUTHOR_TAG presented a model of']","['. recently,', ' #TAUTHOR_TAG presented a model of']","['. recently,', ' #TAUTHOR_TAG presented a model of eye']","['', ' #TAUTHOR_TAG presented a model of eye movement control in reading that directly models the process of identifying the text from visual input, and makes eye movements to maximize the efficiency of the identification', '']",6
"['of this paper', ', we describe an extension of  #TAUTHOR_TAG']","['of this paper', ', we describe an extension of  #TAUTHOR_TAG model in which visual input provides stochastic -']","['of this paper', ', we describe an extension of  #TAUTHOR_TAG model in which visual input provides stochastic -']","['', 'early in processing. if readers have uncertainty about the length of words, we may expect that the amount of uncertainty would grow proportionally to length, as uncertainty is proportional to set size in other tasks of', 'number estimation  #AUTHOR_TAG. this would agree with the intuition that an 8 - character word should be more easily confused with a 9 - character word than a 3 - character word with a 4 - character word. including uncertainty about word length that is larger for longer', 'words would have the effect of increasing the number of visual neighbors for longer words more than for shorter words, providing another reason ( in addition to visual acuity limitations ) that longer words may require more and longer fixations. in the remainder of this paper', ', we describe an extension of  #TAUTHOR_TAG model in which visual input provides stochastic - rather than veridical - information about the length of words, yielding uncertainty about word length, and in which the amount of uncertainty grows with length. we then present two sets of simulations with this extended model demonstrating that it produces more humanlike effects of word length, suggesting that uncertainty about word length may be an', 'important component of a full understanding of the effects of word length in reading']",6
"['this section, we describe our extension of  #TAUTHOR_TAG rational model of eye movement control in reading.', 'except for']","['this section, we describe our extension of  #TAUTHOR_TAG rational model of eye movement control in reading.', 'except for']","['this section, we describe our extension of  #TAUTHOR_TAG rational model of eye movement control in reading.', 'except for the visual input system, and a small change to the behavior policy to allow for uncertainty']","['this section, we describe our extension of  #TAUTHOR_TAG rational model of eye movement control in reading.', 'except for the visual input system, and a small change to the behavior policy to allow for uncertainty about word length, the model is identical to that described by bicknell and levy.', 'the reader is referred to that paper for further computational details beyond what is described here.', 'in this model, the goal of reading is taken to be efficient text identification.', 'while it is clear that this is not all that readers do - inferring the underlying structural relationships among words in a sentence and discourse relationships between sentences that determine text meaning is a fundamental part of most reading - all reader goals necessarily involve identification of at least part of the text, so text identification is taken to be a reasonable first approximation.', 'there are two sources of information relevant to this goal : visual input and language knowledge, which the model combines via bayesian inference.', ""specifically, it begins with a prior distribution over possible identities of the text given by its language model, and combines this with noisy visual input about the text at the eyes'position, giving the likelihood term, to form a posterior distribution over the identity of the text taking into account both the language model and the visual input obtained thus far."", 'on the basis of the posterior distribution, the model decides whether or not to move its eyes ( and if so where to move them to ) and the cycle repeats.', '']",6
"['test the model on a corpus of 33 sentences from the schilling corpus slightly modified by  #TAUTHOR_TAG so that every bigram occurred in the bnc, ensuring that the results']","['test the model on a corpus of 33 sentences from the schilling corpus slightly modified by  #TAUTHOR_TAG so that every bigram occurred in the bnc, ensuring that the results']","['test the model on a corpus of 33 sentences from the schilling corpus slightly modified by  #TAUTHOR_TAG so that every bigram occurred in the bnc, ensuring that the results do not depend on smoothing']","['test the model on a corpus of 33 sentences from the schilling corpus slightly modified by  #TAUTHOR_TAG so that every bigram occurred in the bnc, ensuring that the results do not depend on smoothing']",6
"['of this paper', ', we describe an extension of  #TAUTHOR_TAG']","['of this paper', ', we describe an extension of  #TAUTHOR_TAG model in which visual input provides stochastic -']","['of this paper', ', we describe an extension of  #TAUTHOR_TAG model in which visual input provides stochastic -']","['', 'early in processing. if readers have uncertainty about the length of words, we may expect that the amount of uncertainty would grow proportionally to length, as uncertainty is proportional to set size in other tasks of', 'number estimation  #AUTHOR_TAG. this would agree with the intuition that an 8 - character word should be more easily confused with a 9 - character word than a 3 - character word with a 4 - character word. including uncertainty about word length that is larger for longer', 'words would have the effect of increasing the number of visual neighbors for longer words more than for shorter words, providing another reason ( in addition to visual acuity limitations ) that longer words may require more and longer fixations. in the remainder of this paper', ', we describe an extension of  #TAUTHOR_TAG model in which visual input provides stochastic - rather than veridical - information about the length of words, yielding uncertainty about word length, and in which the amount of uncertainty grows with length. we then present two sets of simulations with this extended model demonstrating that it produces more humanlike effects of word length, suggesting that uncertainty about word length may be an', 'important component of a full understanding of the effects of word length in reading']",3
"[' #TAUTHOR_TAG, we use very simple probabilistic models of language knowledge : word n - gram models  #AUTHOR_TAG, which encode the probability of each word conditional on the n − 1 previous words']","[' #TAUTHOR_TAG, we use very simple probabilistic models of language knowledge : word n - gram models  #AUTHOR_TAG, which encode the probability of each word conditional on the n − 1 previous words']","[' #TAUTHOR_TAG, we use very simple probabilistic models of language knowledge : word n - gram models  #AUTHOR_TAG, which encode the probability of each word conditional on the n − 1 previous words']","[' #TAUTHOR_TAG, we use very simple probabilistic models of language knowledge : word n - gram models  #AUTHOR_TAG, which encode the probability of each word conditional on the n − 1 previous words']",3
"['these ( δ = 0 ) corresponds to  #TAUTHOR_TAG model, which has no uncertainty about word length.', 'we predict that increasing']","['these ( δ = 0 ) corresponds to  #TAUTHOR_TAG model, which has no uncertainty about word length.', 'we predict that increasing']","['these ( δ = 0 ) corresponds to  #TAUTHOR_TAG model, which has no uncertainty about word length.', 'we predict that']","['now assess the effects of word length produced by the extended version of the model.', ' #AUTHOR_TAG, we use the model to simulate reading of a modified version of the  #AUTHOR_TAG corpus of typical sentences used in reading experiments.', 'we compare three levels of length uncertainty : δ ∈ { 0,. 05,. 1 }. the first of these ( δ = 0 ) corresponds to  #TAUTHOR_TAG model, which has no uncertainty about word length.', ""we predict that increasing the amount of length uncertainty will make effects of word length more like those of humans, and we compare the model's length effects to those of human readers of the schilling corpus""]",3
"[' #TAUTHOR_TAG, we use very simple probabilistic models of language knowledge : word n - gram models  #AUTHOR_TAG, which encode the probability of each word conditional on the n − 1 previous words']","[' #TAUTHOR_TAG, we use very simple probabilistic models of language knowledge : word n - gram models  #AUTHOR_TAG, which encode the probability of each word conditional on the n − 1 previous words']","[' #TAUTHOR_TAG, we use very simple probabilistic models of language knowledge : word n - gram models  #AUTHOR_TAG, which encode the probability of each word conditional on the n − 1 previous words']","[' #TAUTHOR_TAG, we use very simple probabilistic models of language knowledge : word n - gram models  #AUTHOR_TAG, which encode the probability of each word conditional on the n − 1 previous words']",5
"['across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset']","['across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset']","['across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset']","['task of semantic parsing is highly useful for tasks such as dialogue  #AUTHOR_TAG and question answering  #AUTHOR_TAG.', 'among a wide range of possible semantic representations, sql offers a standardized interface to knowledge bases across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset for parsing natural language questions into complex sql, which facilitates related research.', "" #TAUTHOR_TAG's dataset is exclusive for english questions."", 'intuitively, the same semantic parsing task can be applied cross - lingual, since sql is a universal semantic representation and database interface.', 'however, for languages other than english, there can be added difficulties parsing into sql.', 'take chinese for example, the additional challenges can be at least two - fold.', '']",1
"['across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset']","['across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset']","['across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset']","['task of semantic parsing is highly useful for tasks such as dialogue  #AUTHOR_TAG and question answering  #AUTHOR_TAG.', 'among a wide range of possible semantic representations, sql offers a standardized interface to knowledge bases across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset for parsing natural language questions into complex sql, which facilitates related research.', "" #TAUTHOR_TAG's dataset is exclusive for english questions."", 'intuitively, the same semantic parsing task can be applied cross - lingual, since sql is a universal semantic representation and database interface.', 'however, for languages other than english, there can be added difficulties parsing into sql.', 'take chinese for example, the additional challenges can be at least two - fold.', '']",6
"['across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset']","['across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset']","['across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset']","['task of semantic parsing is highly useful for tasks such as dialogue  #AUTHOR_TAG and question answering  #AUTHOR_TAG.', 'among a wide range of possible semantic representations, sql offers a standardized interface to knowledge bases across tasks  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a manually labelled dataset for parsing natural language questions into complex sql, which facilitates related research.', "" #TAUTHOR_TAG's dataset is exclusive for english questions."", 'intuitively, the same semantic parsing task can be applied cross - lingual, since sql is a universal semantic representation and database interface.', 'however, for languages other than english, there can be added difficulties parsing into sql.', 'take chinese for example, the additional challenges can be at least two - fold.', '']",4
"['sentences only.', 'following the database split setting of  #TAUTHOR_TAG, we']","['sentences only.', 'following the database split setting of  #TAUTHOR_TAG, we']","['development sets are publicly available.', 'we thus translated these sentences only.', 'following the database split setting of  #TAUTHOR_TAG, we make training, development and test sets split in a way that no database overlaps in']","['translate all english questions in the spider dataset into chinese.', '1 the work is undertaken by 2 nlp researchers and 1 computer science student.', 'each question is first translated by one annotator, and then cross - checked and corrected by a second annotator.', 'finally, a third annotator verifies the original and corrected versions.', 'statistics of the dataset are shown in table 1.', 'there are originally 10181 questions from spider, but only 9691 for the training and development sets are publicly available.', 'we thus translated these sentences only.', 'following the database split setting of  #TAUTHOR_TAG, we make training, development and test sets split in a way that no database overlaps in them as shown in table 1.', 'the translation work is performed on a database to database basis.', '']",5
"['embedding matrix.', 'evaluation metrics.', 'we follow  #TAUTHOR_TAG, evaluating the results using']","['cross - lingual word embeddings.', 'to this end, the tencent multilingual embeddings are chosen, which contain both chinese and english words in a multi - lingual embedding matrix.', 'evaluation metrics.', 'we follow  #TAUTHOR_TAG, evaluating the results using']","['directly use the cross - lingual word embeddings.', 'to this end, the tencent multilingual embeddings are chosen, which contain both chinese and english words in a multi - lingual embedding matrix.', 'evaluation metrics.', 'we follow  #TAUTHOR_TAG, evaluating the results using two']","['focus on comparing different word segmentation methods and different embedding representations.', 'as discussed above, column names are selected by attention over column embeddings using sentence representation as a key.', 'hence there must be a link between the embeddings of columns and those of the questions.', 'since columns are written in english and questions in chinese, we consider two embedding methods.', 'the first method is to use two separate sets of embeddings for chinese and english, respectively.', 'we use glove  #AUTHOR_TAG 2 for embeddings of english keywords, column names etc., and tencent embeddings  #AUTHOR_TAG 3 for chinese.', 'the second method is to directly use the cross - lingual word embeddings.', 'to this end, the tencent multilingual embeddings are chosen, which contain both chinese and english words in a multi - lingual embedding matrix.', 'evaluation metrics.', 'we follow  #TAUTHOR_TAG, evaluating the results using two major 2 https : / / nlp. stanford. edu / projects / glove / 3 https : / / ai. tencent. com / ailab / nlp / embedding. html types of metrics.', 'the first is exact matching accuracy, namely the percentage of questions that have exactly the same sql output as its reference.', 'the second is component matching f1, namely the f1 scores for select, where, group by, order by and all keywords, respectively.', 'hyperparameters.', 'our hyperparameters are mostly taken from  #AUTHOR_TAG a ), but tuned on the chinese spider development set.', 'we use character and word embeddings from tencent embedding ; both of them are not fine - tuned during model training.', 'embedding sizes are set to 200 for both characters and words.', 'for the different choices of keywords and column names embeddings, sizes are set to 200 and 300, respectively.', 'adam  #AUTHOR_TAG is used for optimization, with a learning rate of 1e - 4.', 'dropout is used for the output of lstm with a rate of 0. 5.', 'for word - based models, segmentation is necessary.', 'we take two segmentors with different performances, including the jieba segmentor and the model of  #AUTHOR_TAG, which we name jieba and yz, respectively.', 'to verify their accuracy, we manually segment the first 100 sentences from the test set.', 'jieba and yz give f1 scores of 89. 8 % and 91. 7 %, respectively']",5
"[' #TAUTHOR_TAG.', 'it is']","[' #TAUTHOR_TAG.', 'it is']","['on input data  #TAUTHOR_TAG.', 'it is traditionally']","['- to - text generation, a classic task of natural language generation is to convert the structured input data ( i. e., a table ) into descriptions that adequately and fluently describes the data  #AUTHOR_TAG perez -  #AUTHOR_TAG.', 'datato - document generation is a slightly more challenging setting in which a system generates multisentence summaries based on input data  #TAUTHOR_TAG.', '']",0
"[' #TAUTHOR_TAG.', 'it is']","[' #TAUTHOR_TAG.', 'it is']","['on input data  #TAUTHOR_TAG.', 'it is traditionally']","['- to - text generation, a classic task of natural language generation is to convert the structured input data ( i. e., a table ) into descriptions that adequately and fluently describes the data  #AUTHOR_TAG perez -  #AUTHOR_TAG.', 'datato - document generation is a slightly more challenging setting in which a system generates multisentence summaries based on input data  #TAUTHOR_TAG.', '']",0
"[' #TAUTHOR_TAG.', 'it is']","[' #TAUTHOR_TAG.', 'it is']","['on input data  #TAUTHOR_TAG.', 'it is traditionally']","['- to - text generation, a classic task of natural language generation is to convert the structured input data ( i. e., a table ) into descriptions that adequately and fluently describes the data  #AUTHOR_TAG perez -  #AUTHOR_TAG.', 'datato - document generation is a slightly more challenging setting in which a system generates multisentence summaries based on input data  #TAUTHOR_TAG.', '']",4
"['work  #TAUTHOR_TAG.', 'the differences between']","['work  #TAUTHOR_TAG.', 'the differences between']","['baseline model and achieve comparable results on rotowire dataset w. r. t.', 'the previous work  #TAUTHOR_TAG.', 'the differences between']","['', 'they were led by victor oladipo, who scored a game - high 28 points on 9 - of - 17 shooting from the field and 13 - of - 15 from the free throw line · · · proposed model', 'the orlando magic ( 7 - 8 ) defeated the new york knicks ( 8 - 8 ) 100 - 91 on friday.', 'orlando has won two straight and six of their last eight games.', 'they were led by carmelo anthony, who scored a game - high 28 points on 9 - of - 17 shooting from the field and 3 - of - 4 shooting from beyond the arc · · · table 3 : top : partial input data of one game.', 'below : first three sentences produced by baseline and our proposed model.', 'blue words denotes facts consistency with input, red words denotes facts contradicting with input and italic words denote facts not mentioned in input mle training on our baseline model and achieve comparable results on rotowire dataset w. r. t.', 'the previous work  #TAUTHOR_TAG.', 'the differences between our method and  #TAUTHOR_TAG uses a table encoder similar to  #AUTHOR_TAG.', 'template based 3 method performs poorly than all neural based method in terms of bleu score, but it performs quite well on the extractive metrics, as input data is directly feed into placeholders of template by rules, which provides the upper - bound for how domain knowledge could help content selection and generation.', 'for neural based methods, our proposed two verification signals can improve both bleu and rg metric, which indicates the effectiveness of incorporating the verification constraints during training.', 'in addition, with these two signals, our method achieves further improvements on bleu and rg metric.', 'for cs metric which measures the consistency between the generated texts and reference text, when incorporating the content reward with fidelity rewards, the overall f1 score of our method is improved.', 'qualitative analysis : table 3 shows a validation set game statistics with generation results by original seq2seq model and our proposed method 4.', ""the original seq2seq model is more likely to produce incorrect facts ( e. g., wrong score points and in their paper and rerun this baseline with the author's code."", '3 hand crafted templates from  #TAUTHOR_TAG ft ) 4 the whole']",4
"[' #TAUTHOR_TAG.', 'it is']","[' #TAUTHOR_TAG.', 'it is']","['on input data  #TAUTHOR_TAG.', 'it is traditionally']","['- to - text generation, a classic task of natural language generation is to convert the structured input data ( i. e., a table ) into descriptions that adequately and fluently describes the data  #AUTHOR_TAG perez -  #AUTHOR_TAG.', 'datato - document generation is a slightly more challenging setting in which a system generates multisentence summaries based on input data  #TAUTHOR_TAG.', '']",5
"[': we use rotowire dataset  #TAUTHOR_TAG, which is a']","[': we use rotowire dataset  #TAUTHOR_TAG, which is a']","[': we use rotowire dataset  #TAUTHOR_TAG, which is a collection of articles summarizing nba basketball games, paired with']","[': we use rotowire dataset  #TAUTHOR_TAG, which is a collection of articles summarizing nba basketball games, paired with their corresponding box - and line - score tables.', 'it consists of 3, 398, 727, and 728 summaries for training, validation and testing respectively.', ""training : for both mle and rl training, we use the sgd optimizer with starting learning rate as 1 and last mle epoch's learning rate respectively, the dimension of trainable word embeddings and hidden units in lstms are all set to 512, and the mini - batch size is set to 16."", 'we apply the truncated backpropagation with window size 100  #AUTHOR_TAG.', 'for rl training, we set the sample size to 1, γ to 0, λ 1, λ 2 to 1, b f, b c to 2 3 and α, β to 1. 5 according to the validation set 1.', 'for gaussian smoothing on context reward, we set its variance to 1 and truncate size to 5.', 'we subtract mean reward as baseline for content reward and bound both type of rewards to [ - 2, 1 ].', '']",5
"[': we use rotowire dataset  #TAUTHOR_TAG, which is a']","[': we use rotowire dataset  #TAUTHOR_TAG, which is a']","[': we use rotowire dataset  #TAUTHOR_TAG, which is a collection of articles summarizing nba basketball games, paired with']","[': we use rotowire dataset  #TAUTHOR_TAG, which is a collection of articles summarizing nba basketball games, paired with their corresponding box - and line - score tables.', 'it consists of 3, 398, 727, and 728 summaries for training, validation and testing respectively.', ""training : for both mle and rl training, we use the sgd optimizer with starting learning rate as 1 and last mle epoch's learning rate respectively, the dimension of trainable word embeddings and hidden units in lstms are all set to 512, and the mini - batch size is set to 16."", 'we apply the truncated backpropagation with window size 100  #AUTHOR_TAG.', 'for rl training, we set the sample size to 1, γ to 0, λ 1, λ 2 to 1, b f, b c to 2 3 and α, β to 1. 5 according to the validation set 1.', 'for gaussian smoothing on context reward, we set its variance to 1 and truncate size to 5.', 'we subtract mean reward as baseline for content reward and bound both type of rewards to [ - 2, 1 ].', '']",5
"[': we use rotowire dataset  #TAUTHOR_TAG, which is a']","[': we use rotowire dataset  #TAUTHOR_TAG, which is a']","[': we use rotowire dataset  #TAUTHOR_TAG, which is a collection of articles summarizing nba basketball games, paired with']","[': we use rotowire dataset  #TAUTHOR_TAG, which is a collection of articles summarizing nba basketball games, paired with their corresponding box - and line - score tables.', 'it consists of 3, 398, 727, and 728 summaries for training, validation and testing respectively.', ""training : for both mle and rl training, we use the sgd optimizer with starting learning rate as 1 and last mle epoch's learning rate respectively, the dimension of trainable word embeddings and hidden units in lstms are all set to 512, and the mini - batch size is set to 16."", 'we apply the truncated backpropagation with window size 100  #AUTHOR_TAG.', 'for rl training, we set the sample size to 1, γ to 0, λ 1, λ 2 to 1, b f, b c to 2 3 and α, β to 1. 5 according to the validation set 1.', 'for gaussian smoothing on context reward, we set its variance to 1 and truncate size to 5.', 'we subtract mean reward as baseline for content reward and bound both type of rewards to [ - 2, 1 ].', '']",5
"['work  #TAUTHOR_TAG.', 'the differences between']","['work  #TAUTHOR_TAG.', 'the differences between']","['baseline model and achieve comparable results on rotowire dataset w. r. t.', 'the previous work  #TAUTHOR_TAG.', 'the differences between']","['', 'they were led by victor oladipo, who scored a game - high 28 points on 9 - of - 17 shooting from the field and 13 - of - 15 from the free throw line · · · proposed model', 'the orlando magic ( 7 - 8 ) defeated the new york knicks ( 8 - 8 ) 100 - 91 on friday.', 'orlando has won two straight and six of their last eight games.', 'they were led by carmelo anthony, who scored a game - high 28 points on 9 - of - 17 shooting from the field and 3 - of - 4 shooting from beyond the arc · · · table 3 : top : partial input data of one game.', 'below : first three sentences produced by baseline and our proposed model.', 'blue words denotes facts consistency with input, red words denotes facts contradicting with input and italic words denote facts not mentioned in input mle training on our baseline model and achieve comparable results on rotowire dataset w. r. t.', 'the previous work  #TAUTHOR_TAG.', 'the differences between our method and  #TAUTHOR_TAG uses a table encoder similar to  #AUTHOR_TAG.', 'template based 3 method performs poorly than all neural based method in terms of bleu score, but it performs quite well on the extractive metrics, as input data is directly feed into placeholders of template by rules, which provides the upper - bound for how domain knowledge could help content selection and generation.', 'for neural based methods, our proposed two verification signals can improve both bleu and rg metric, which indicates the effectiveness of incorporating the verification constraints during training.', 'in addition, with these two signals, our method achieves further improvements on bleu and rg metric.', 'for cs metric which measures the consistency between the generated texts and reference text, when incorporating the content reward with fidelity rewards, the overall f1 score of our method is improved.', 'qualitative analysis : table 3 shows a validation set game statistics with generation results by original seq2seq model and our proposed method 4.', ""the original seq2seq model is more likely to produce incorrect facts ( e. g., wrong score points and in their paper and rerun this baseline with the author's code."", '3 hand crafted templates from  #TAUTHOR_TAG ft ) 4 the whole']",5
"['work  #TAUTHOR_TAG.', 'the differences between']","['work  #TAUTHOR_TAG.', 'the differences between']","['baseline model and achieve comparable results on rotowire dataset w. r. t.', 'the previous work  #TAUTHOR_TAG.', 'the differences between']","['', 'they were led by victor oladipo, who scored a game - high 28 points on 9 - of - 17 shooting from the field and 13 - of - 15 from the free throw line · · · proposed model', 'the orlando magic ( 7 - 8 ) defeated the new york knicks ( 8 - 8 ) 100 - 91 on friday.', 'orlando has won two straight and six of their last eight games.', 'they were led by carmelo anthony, who scored a game - high 28 points on 9 - of - 17 shooting from the field and 3 - of - 4 shooting from beyond the arc · · · table 3 : top : partial input data of one game.', 'below : first three sentences produced by baseline and our proposed model.', 'blue words denotes facts consistency with input, red words denotes facts contradicting with input and italic words denote facts not mentioned in input mle training on our baseline model and achieve comparable results on rotowire dataset w. r. t.', 'the previous work  #TAUTHOR_TAG.', 'the differences between our method and  #TAUTHOR_TAG uses a table encoder similar to  #AUTHOR_TAG.', 'template based 3 method performs poorly than all neural based method in terms of bleu score, but it performs quite well on the extractive metrics, as input data is directly feed into placeholders of template by rules, which provides the upper - bound for how domain knowledge could help content selection and generation.', 'for neural based methods, our proposed two verification signals can improve both bleu and rg metric, which indicates the effectiveness of incorporating the verification constraints during training.', 'in addition, with these two signals, our method achieves further improvements on bleu and rg metric.', 'for cs metric which measures the consistency between the generated texts and reference text, when incorporating the content reward with fidelity rewards, the overall f1 score of our method is improved.', 'qualitative analysis : table 3 shows a validation set game statistics with generation results by original seq2seq model and our proposed method 4.', ""the original seq2seq model is more likely to produce incorrect facts ( e. g., wrong score points and in their paper and rerun this baseline with the author's code."", '3 hand crafted templates from  #TAUTHOR_TAG ft ) 4 the whole']",5
['system similar to  #TAUTHOR_TAG'],['system similar to  #TAUTHOR_TAG'],"['extract information describing the input data from the generated texts, we apply a simple information extraction system similar to  #TAUTHOR_TAG.', 'given a generated texty 1 : t, we']","['extract information describing the input data from the generated texts, we apply a simple information extraction system similar to  #TAUTHOR_TAG.', 'given a generated texty 1 : t, we first extract candidate entity r e ( e. g., name ) and value r m ( e. g., number ) pairs in the generated texts with lexical rules and then predict the type r t ( e. g., points ) of each candidate pair using a re model ( dos  #AUTHOR_TAG.', 'we train the re model in a distant supervision manner  #AUTHOR_TAG, with training data constructed from reference text and input data']",3
['transformer  #TAUTHOR_TAG'],['transformer  #TAUTHOR_TAG'],"['transformer  #TAUTHOR_TAG.', 'training deep networks has always been a challenging problem, mainly']","['machine translation ( briefly, nmt ), which is built upon deep neural networks, has gained rapid progress in recent years  #AUTHOR_TAG b ;  #AUTHOR_TAG a ;  #AUTHOR_TAG a ;  #AUTHOR_TAG and achieved significant improvement in translation quality  #AUTHOR_TAG.', 'variants of network structures have been applied in nmt such as lstm  #AUTHOR_TAG, cnn  #AUTHOR_TAG and transformer  #TAUTHOR_TAG.', 'training deep networks has always been a challenging problem, mainly due to the difficulties in optimization for deep architecture.', 'breakthroughs have been made in computer vision to enable deeper model construction via advanced initialization schemes  #AUTHOR_TAG, multi - stage training strategy  #AUTHOR_TAG, and figure 1 : performances of transformer models with different number of encoder / decoder blocks ( recorded on x - axis ) on wmt14 en→de translation task.', '† denotes the result reported in  #TAUTHOR_TAG.', 'novel model architectures  #AUTHOR_TAG b ).', 'while constructing very deep neural networks with tens and even more than a hundred blocks have shown effectiveness in image recognition  #AUTHOR_TAG b ), question answering and text classification  #AUTHOR_TAG, scaling up model capacity with very deep network remains challenging for nmt.', 'the nmt models are generally constructed with up to 6 encoder and decoder blocks in both state - of - the - art research work and champion systems of machine translation competition.', 'for example, the lstm - based models are usually stacked for 4  #AUTHOR_TAG or 6  #AUTHOR_TAG blocks, and the state - of - the - art transformer models are equipped with a 6 - block encoder and decoder  #TAUTHOR_TAG.', 'increasing the nmt model depth by directly stacking more blocks results in no improvement or performance drop ( figure 1 ), and even leads to optimization failure.', 'there have been a few attempts in previous works on constructing deeper nmt models.', ' #AUTHOR_TAG and  #AUTHOR_TAG propose increasing the depth of lstm - based models by introducing linear units between internal hidden states to eliminate the problem of gradient vanishing.', '']",0
['transformer  #TAUTHOR_TAG'],['transformer  #TAUTHOR_TAG'],"['transformer  #TAUTHOR_TAG.', 'training deep networks has always been a challenging problem, mainly']","['machine translation ( briefly, nmt ), which is built upon deep neural networks, has gained rapid progress in recent years  #AUTHOR_TAG b ;  #AUTHOR_TAG a ;  #AUTHOR_TAG a ;  #AUTHOR_TAG and achieved significant improvement in translation quality  #AUTHOR_TAG.', 'variants of network structures have been applied in nmt such as lstm  #AUTHOR_TAG, cnn  #AUTHOR_TAG and transformer  #TAUTHOR_TAG.', 'training deep networks has always been a challenging problem, mainly due to the difficulties in optimization for deep architecture.', 'breakthroughs have been made in computer vision to enable deeper model construction via advanced initialization schemes  #AUTHOR_TAG, multi - stage training strategy  #AUTHOR_TAG, and figure 1 : performances of transformer models with different number of encoder / decoder blocks ( recorded on x - axis ) on wmt14 en→de translation task.', '† denotes the result reported in  #TAUTHOR_TAG.', 'novel model architectures  #AUTHOR_TAG b ).', 'while constructing very deep neural networks with tens and even more than a hundred blocks have shown effectiveness in image recognition  #AUTHOR_TAG b ), question answering and text classification  #AUTHOR_TAG, scaling up model capacity with very deep network remains challenging for nmt.', 'the nmt models are generally constructed with up to 6 encoder and decoder blocks in both state - of - the - art research work and champion systems of machine translation competition.', 'for example, the lstm - based models are usually stacked for 4  #AUTHOR_TAG or 6  #AUTHOR_TAG blocks, and the state - of - the - art transformer models are equipped with a 6 - block encoder and decoder  #TAUTHOR_TAG.', 'increasing the nmt model depth by directly stacking more blocks results in no improvement or performance drop ( figure 1 ), and even leads to optimization failure.', 'there have been a few attempts in previous works on constructing deeper nmt models.', ' #AUTHOR_TAG and  #AUTHOR_TAG propose increasing the depth of lstm - based models by introducing linear units between internal hidden states to eliminate the problem of gradient vanishing.', '']",0
['transformer  #TAUTHOR_TAG'],['transformer  #TAUTHOR_TAG'],"['transformer  #TAUTHOR_TAG.', 'training deep networks has always been a challenging problem, mainly']","['machine translation ( briefly, nmt ), which is built upon deep neural networks, has gained rapid progress in recent years  #AUTHOR_TAG b ;  #AUTHOR_TAG a ;  #AUTHOR_TAG a ;  #AUTHOR_TAG and achieved significant improvement in translation quality  #AUTHOR_TAG.', 'variants of network structures have been applied in nmt such as lstm  #AUTHOR_TAG, cnn  #AUTHOR_TAG and transformer  #TAUTHOR_TAG.', 'training deep networks has always been a challenging problem, mainly due to the difficulties in optimization for deep architecture.', 'breakthroughs have been made in computer vision to enable deeper model construction via advanced initialization schemes  #AUTHOR_TAG, multi - stage training strategy  #AUTHOR_TAG, and figure 1 : performances of transformer models with different number of encoder / decoder blocks ( recorded on x - axis ) on wmt14 en→de translation task.', '† denotes the result reported in  #TAUTHOR_TAG.', 'novel model architectures  #AUTHOR_TAG b ).', 'while constructing very deep neural networks with tens and even more than a hundred blocks have shown effectiveness in image recognition  #AUTHOR_TAG b ), question answering and text classification  #AUTHOR_TAG, scaling up model capacity with very deep network remains challenging for nmt.', 'the nmt models are generally constructed with up to 6 encoder and decoder blocks in both state - of - the - art research work and champion systems of machine translation competition.', 'for example, the lstm - based models are usually stacked for 4  #AUTHOR_TAG or 6  #AUTHOR_TAG blocks, and the state - of - the - art transformer models are equipped with a 6 - block encoder and decoder  #TAUTHOR_TAG.', 'increasing the nmt model depth by directly stacking more blocks results in no improvement or performance drop ( figure 1 ), and even leads to optimization failure.', 'there have been a few attempts in previous works on constructing deeper nmt models.', ' #AUTHOR_TAG and  #AUTHOR_TAG propose increasing the depth of lstm - based models by introducing linear units between internal hidden states to eliminate the problem of gradient vanishing.', '']",5
"['strong transformer model.', 'we adopt the big transformer configuration following  #TAUTHOR_TAG, with the dimension of word embeddings, hidden states and non - linear layer set as 1024, 1024 and']","['strong transformer model.', 'we adopt the big transformer configuration following  #TAUTHOR_TAG, with the dimension of word embeddings, hidden states and non - linear layer set as 1024, 1024 and 4096 respectively.', 'the dropout rate is 0. 3 for']","['and en→fr respectively.', 'architecture the basic encoder - decoder framework we use is the strong transformer model.', 'we adopt the big transformer configuration following  #TAUTHOR_TAG, with the dimension of word embeddings, hidden states and non - linear layer set as 1024, 1024 and']","['', 'we use the concatenation of newstest2012 and newstest2013 as the validation set, and newstest2014 as the test set.', 'all words are segmented into sub - word units using byte pair encoding ( bpe ) 4  #AUTHOR_TAG b ), forming a vocabulary shared by the source and target languages with 32k and 45k tokens for en→de and en→fr respectively.', 'architecture the basic encoder - decoder framework we use is the strong transformer model.', 'we adopt the big transformer configuration following  #TAUTHOR_TAG, with the dimension of word embeddings, hidden states and non - linear layer set as 1024, 1024 and 4096 respectively.', 'the dropout rate is 0. 3 for en→de and 0. 1 for en→fr.', 'we set the number of encoder / decoder blocks for the bottom module as n = 6 following the common practice, and set the number of additionally stacked blocks of the top module as m = 2.', 'our models are implemented based on the pytorch implementation of transformer 5 and the code can be found in the supplementary materials.', 'training we use adam  #AUTHOR_TAG optimizer following the optimization settings and default learning rate schedule in  #TAUTHOR_TAG for model training.', 'all models are trained on 8 m40 gpus.', 'evaluation we evaluate the model performances with tokenized case - sensitive bleu 6 score  #AUTHOR_TAG for the two translation tasks.', 'we use beam search with a beam size of 5 and with no length penalty']",5
"['strong transformer model.', 'we adopt the big transformer configuration following  #TAUTHOR_TAG, with the dimension of word embeddings, hidden states and non - linear layer set as 1024, 1024 and']","['strong transformer model.', 'we adopt the big transformer configuration following  #TAUTHOR_TAG, with the dimension of word embeddings, hidden states and non - linear layer set as 1024, 1024 and 4096 respectively.', 'the dropout rate is 0. 3 for']","['and en→fr respectively.', 'architecture the basic encoder - decoder framework we use is the strong transformer model.', 'we adopt the big transformer configuration following  #TAUTHOR_TAG, with the dimension of word embeddings, hidden states and non - linear layer set as 1024, 1024 and']","['', 'we use the concatenation of newstest2012 and newstest2013 as the validation set, and newstest2014 as the test set.', 'all words are segmented into sub - word units using byte pair encoding ( bpe ) 4  #AUTHOR_TAG b ), forming a vocabulary shared by the source and target languages with 32k and 45k tokens for en→de and en→fr respectively.', 'architecture the basic encoder - decoder framework we use is the strong transformer model.', 'we adopt the big transformer configuration following  #TAUTHOR_TAG, with the dimension of word embeddings, hidden states and non - linear layer set as 1024, 1024 and 4096 respectively.', 'the dropout rate is 0. 3 for en→de and 0. 1 for en→fr.', 'we set the number of encoder / decoder blocks for the bottom module as n = 6 following the common practice, and set the number of additionally stacked blocks of the top module as m = 2.', 'our models are implemented based on the pytorch implementation of transformer 5 and the code can be found in the supplementary materials.', 'training we use adam  #AUTHOR_TAG optimizer following the optimization settings and default learning rate schedule in  #TAUTHOR_TAG for model training.', 'all models are trained on 8 m40 gpus.', 'evaluation we evaluate the model performances with tokenized case - sensitive bleu 6 score  #AUTHOR_TAG for the two translation tasks.', 'we use beam search with a beam size of 5 and with no length penalty']",5
"[' #TAUTHOR_TAG, and show a close correspondence between this matrix - space model and weighted finite automata.', 'we conclude that the']","[' #TAUTHOR_TAG, and show a close correspondence between this matrix - space model and weighted finite automata.', 'we conclude that the']","[' #TAUTHOR_TAG, and show a close correspondence between this matrix - space model and weighted finite automata.', 'we conclude that the problem of learning compositional matrix - space models can be mapped to the problem of learning weighted finite automata over the real numbers']","['matrix - space models of language were recently proposed for the task of meaning representation of complex text structures in natural language processing.', 'these models have been shown to be a theoretically elegant way to model compositionality in natural language.', 'however, in practical cases, appropriate methods are required to learn such models by automatically acquiring the necessary token - to - matrix assignments.', 'in this paper, we introduce graded matrix grammars of natural language, a variant of the matrix grammars proposed by  #TAUTHOR_TAG, and show a close correspondence between this matrix - space model and weighted finite automata.', 'we conclude that the problem of learning compositional matrix - space models can be mapped to the problem of learning weighted finite automata over the real numbers']",6
"['vsms,  #TAUTHOR_TAG proposed compositional matrix - space models ( cmsm ) as a recent alternative model to work with distributional approaches.', 'these models employ matrices']","['vsms,  #TAUTHOR_TAG proposed compositional matrix - space models ( cmsm ) as a recent alternative model to work with distributional approaches.', 'these models employ matrices']","['vsms,  #TAUTHOR_TAG proposed compositional matrix - space models ( cmsm ) as a recent alternative model to work with distributional approaches.', 'these models employ matrices']","['models of language have recently received considerable research attention in the field of natural language processing ( nlp ).', 'in the application of meaning representation of text in nlp, much effort has been spent on semantic vector space models ( vsms ).', 'such models capture word meanings quantitatively, based on their statistical co - occurrences in the documents.', 'the basic idea is to represent words as vectors in a highdimensional space, where each dimension corresponds to a separate feature.', 'in this way, semantic similarities can be computed based on measuring the distance between vectors in the vector * supported by dfg graduiertenkolleg 1763 ( quantla ) space  #AUTHOR_TAG.', 'vectors which are close together in this space have similar meanings and vectors which are far away are distant in meaning  #AUTHOR_TAG.', 'vsms typically represent each word separately, without considering representations of phrases or sentences.', 'so, the compositionality properties of the language is lost in vsms  #AUTHOR_TAG.', 'recently, some approaches have been developed in the area of compositionality and distributional semantics in nlp.', 'these approaches introduce different word representations and ways of combining those words.', ' #AUTHOR_TAG propose a framework for vector - based semantic composition.', 'they define additive or multiplicative function for the composition of two vectors and show that compositional approaches generally outperform non - compositional approaches which treat the phrase as the union of single lexical items.', 'however, vsms still have some limitations in the task of modeling complex conceptual text structures.', 'for example, in the bag - of - words model, the words order and therefore the structure of the language is lost.', 'to overcome the limitations of vsms,  #TAUTHOR_TAG proposed compositional matrix - space models ( cmsm ) as a recent alternative model to work with distributional approaches.', 'these models employ matrices instead of vectors and make use of iterated matrix multiplication as the only composition operation.', 'they show that these models are powerful enough to subsume many known models, both quantitative ( vector - space models with diverse composition operations ) and qualitative ones ( such as regular languages ).', 'it is also proved theoretically that this framework is an elegant way to model compositional, symbolic and distributional aspects of natural language.', 'however, in practical cases, methods are needed to automatically acquire the token - to - matrix assignments from available data.', 'therefore, methods for training such models should be developed e. g. by leveraging appropriate machine learning methods.', 'in this paper, we are concerned with graded matrix grammars, a variant of the matrix grammars of  #TAUTHOR_TAG, where instead of the "" yes or no "" decision, if a sequence is part of a language, a real - valued score']",6
['a slight variation of matrix grammars as introduced by  #TAUTHOR_TAG'],['a slight variation of matrix grammars as introduced by  #TAUTHOR_TAG'],"['a slight variation of matrix grammars as introduced by  #TAUTHOR_TAG.', 'definition 1 ( graded matrix grammars ).', 'let σ be an alphabet.', 'a graded matrix grammar m of degree n is defined as the tuple ·,']","['some applications of nlp, we need to derive the meaning of a sequence of words in a language, which can be done with cmsms as described in section 2. 2.', 'in this section, we introduce the notion of a graded matrix grammar which constitutes a slight variation of matrix grammars as introduced by  #TAUTHOR_TAG.', 'definition 1 ( graded matrix grammars ).', 'let σ be an alphabet.', 'a graded matrix grammar m of degree n is defined as the tuple ·, σ, α, β where · is a function mapping tokens in σ to n × n matrices of real numbers.', 'moreover, α, β ∈ r n.', '']",6
"['vsms,  #TAUTHOR_TAG proposed compositional matrix - space models ( cmsm ) as a recent alternative model to work with distributional approaches.', 'these models employ matrices']","['vsms,  #TAUTHOR_TAG proposed compositional matrix - space models ( cmsm ) as a recent alternative model to work with distributional approaches.', 'these models employ matrices']","['vsms,  #TAUTHOR_TAG proposed compositional matrix - space models ( cmsm ) as a recent alternative model to work with distributional approaches.', 'these models employ matrices']","['models of language have recently received considerable research attention in the field of natural language processing ( nlp ).', 'in the application of meaning representation of text in nlp, much effort has been spent on semantic vector space models ( vsms ).', 'such models capture word meanings quantitatively, based on their statistical co - occurrences in the documents.', 'the basic idea is to represent words as vectors in a highdimensional space, where each dimension corresponds to a separate feature.', 'in this way, semantic similarities can be computed based on measuring the distance between vectors in the vector * supported by dfg graduiertenkolleg 1763 ( quantla ) space  #AUTHOR_TAG.', 'vectors which are close together in this space have similar meanings and vectors which are far away are distant in meaning  #AUTHOR_TAG.', 'vsms typically represent each word separately, without considering representations of phrases or sentences.', 'so, the compositionality properties of the language is lost in vsms  #AUTHOR_TAG.', 'recently, some approaches have been developed in the area of compositionality and distributional semantics in nlp.', 'these approaches introduce different word representations and ways of combining those words.', ' #AUTHOR_TAG propose a framework for vector - based semantic composition.', 'they define additive or multiplicative function for the composition of two vectors and show that compositional approaches generally outperform non - compositional approaches which treat the phrase as the union of single lexical items.', 'however, vsms still have some limitations in the task of modeling complex conceptual text structures.', 'for example, in the bag - of - words model, the words order and therefore the structure of the language is lost.', 'to overcome the limitations of vsms,  #TAUTHOR_TAG proposed compositional matrix - space models ( cmsm ) as a recent alternative model to work with distributional approaches.', 'these models employ matrices instead of vectors and make use of iterated matrix multiplication as the only composition operation.', 'they show that these models are powerful enough to subsume many known models, both quantitative ( vector - space models with diverse composition operations ) and qualitative ones ( such as regular languages ).', 'it is also proved theoretically that this framework is an elegant way to model compositional, symbolic and distributional aspects of natural language.', 'however, in practical cases, methods are needed to automatically acquire the token - to - matrix assignments from available data.', 'therefore, methods for training such models should be developed e. g. by leveraging appropriate machine learning methods.', 'in this paper, we are concerned with graded matrix grammars, a variant of the matrix grammars of  #TAUTHOR_TAG, where instead of the "" yes or no "" decision, if a sequence is part of a language, a real - valued score']",0
"['of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given']","['of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given']","['is that the meaning of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given a mapping · : σ → s']","['general principle of compositionality is that the meaning of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given a mapping · : σ → s from a set of tokens in σ into some semantical space s, the composition operation is defined by mapping sequences of meanings to meanings : : s → s. so, the meaning of the sequence of tokens σ 1 · · · σ n can be obtained by first applying the function · to each token and then to the sequence σ 1 · · · σ n, as shown in figure 2 "".', 'figure 2 : principle of compositionality, illustration taken from  #TAUTHOR_TAG in compositional matrix - space models, this general idea is instantiated as follows : we have s = r n×n, i. e., the semantical space consists of quadratic matrices of real numbers.', 'the mapping function · maps the tokens into matrices so that the semantics of simple tokens is expressed by matrices.', 'then, using the standard matrix multiplication as the only composition operation, the semantics of complex phrases are also described by matrices.', ' #TAUTHOR_TAG showed theoretically that by employing matrices instead of vectors, cmsms subsume a wide range of linguistic models such as statistical models ( vector - space models and word space models )']",0
"['of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given']","['of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given']","['is that the meaning of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given a mapping · : σ → s']","['general principle of compositionality is that the meaning of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given a mapping · : σ → s from a set of tokens in σ into some semantical space s, the composition operation is defined by mapping sequences of meanings to meanings : : s → s. so, the meaning of the sequence of tokens σ 1 · · · σ n can be obtained by first applying the function · to each token and then to the sequence σ 1 · · · σ n, as shown in figure 2 "".', 'figure 2 : principle of compositionality, illustration taken from  #TAUTHOR_TAG in compositional matrix - space models, this general idea is instantiated as follows : we have s = r n×n, i. e., the semantical space consists of quadratic matrices of real numbers.', 'the mapping function · maps the tokens into matrices so that the semantics of simple tokens is expressed by matrices.', 'then, using the standard matrix multiplication as the only composition operation, the semantics of complex phrases are also described by matrices.', ' #TAUTHOR_TAG showed theoretically that by employing matrices instead of vectors, cmsms subsume a wide range of linguistic models such as statistical models ( vector - space models and word space models )']",0
"['of  #TAUTHOR_TAG they use cmsms to model composition, and present an algorithm for learning a matrix for each word via ordered logistic']","['of  #TAUTHOR_TAG they use cmsms to model composition, and present an algorithm for learning a matrix for each word via ordered logistic regression, which is']","['phraselevel sentiment analysis.', 'inspired by the work of  #TAUTHOR_TAG they use cmsms to model composition, and present an algorithm for learning a matrix for each word via ordered logistic regression, which is evaluated with promising results.', 'however, it is not trivial to']","['application of cmsm has been shown in the work of  #AUTHOR_TAG.', 'they proposed a learning - based approach for phraselevel sentiment analysis.', 'inspired by the work of  #TAUTHOR_TAG they use cmsms to model composition, and present an algorithm for learning a matrix for each word via ordered logistic regression, which is evaluated with promising results.', 'however, it is not trivial to learn a matrix - space model.', 'since the final optimization problem is non - convex, the matrix initialization for this method is not done perfectly.', ' #AUTHOR_TAG introduce a matrix - vector recursive neural network ( mv - rnn ) model that learns compositional vector representations for phrases and sentences.', 'the model assigns a vector and a matrix to every node in a parse tree.', 'the vector represents the meaning of the constituent, while the matrix captures how it affects the meaning of neighboring constituent.', 'the model needs to parse the tree to learn the vectors and matrices.', 'recently, new approaches are proposed in learning weighted finite automata in nlp.', ' #AUTHOR_TAG and  #AUTHOR_TAG introduce a new family of algorithms for learning general wfa and stochastic wfa based on the combination of matrix completion problem and spectral methods.', 'these algorithms are designed for learning an arbitrary weighted automaton from sample data of strings and assigned labels.', 'they formulate the missing information from the sample data as a hankel matrix completion problem.', '']",0
"['this section, we provide the definitions of weighted automata in  #AUTHOR_TAG and matrix - space models of language in  #TAUTHOR_TAG']","['this section, we provide the definitions of weighted automata in  #AUTHOR_TAG and matrix - space models of language in  #TAUTHOR_TAG']","['this section, we provide the definitions of weighted automata in  #AUTHOR_TAG and matrix - space models of language in  #TAUTHOR_TAG']","['this section, we provide the definitions of weighted automata in  #AUTHOR_TAG and matrix - space models of language in  #TAUTHOR_TAG']",7
"['of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given']","['of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given']","['is that the meaning of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given a mapping · : σ → s']","['general principle of compositionality is that the meaning of a complex expression is a function of the meaning of its constituent tokens and some rules used to combine them ( frege, 1884 ).', 'more formally, according to  #TAUTHOR_TAG, the underlying idea can be described as follows : "" given a mapping · : σ → s from a set of tokens in σ into some semantical space s, the composition operation is defined by mapping sequences of meanings to meanings : : s → s. so, the meaning of the sequence of tokens σ 1 · · · σ n can be obtained by first applying the function · to each token and then to the sequence σ 1 · · · σ n, as shown in figure 2 "".', 'figure 2 : principle of compositionality, illustration taken from  #TAUTHOR_TAG in compositional matrix - space models, this general idea is instantiated as follows : we have s = r n×n, i. e., the semantical space consists of quadratic matrices of real numbers.', 'the mapping function · maps the tokens into matrices so that the semantics of simple tokens is expressed by matrices.', 'then, using the standard matrix multiplication as the only composition operation, the semantics of complex phrases are also described by matrices.', ' #TAUTHOR_TAG showed theoretically that by employing matrices instead of vectors, cmsms subsume a wide range of linguistic models such as statistical models ( vector - space models and word space models )']",5
"['combination of these  #TAUTHOR_TAG, a ).', 'the strong geographical bias, most obviously']","['combination of these  #TAUTHOR_TAG, a ).', 'the strong geographical bias, most obviously']","['based on profile data, text content, friendship graphs  #AUTHOR_TAG or some combination of these  #TAUTHOR_TAG, a ).', 'the strong geographical bias, most obviously']","['', 'explicit user geolocation metadata ( e. g. gps tags, wifi footprint, ip address ) is not usually available to third - party consumers, giving rise to the need for geolocation based on profile data, text content, friendship graphs  #AUTHOR_TAG or some combination of these  #TAUTHOR_TAG, a ).', 'the strong geographical bias, most obviously at the language level ( e. g. finland vs. japan ), and more subtly at the dialect level ( e. g. in english used in north - west england vs. north - east usa vs. texas, usa ), clearly reflected in language use in social media services such as twitter, has been used extensively either for geolocation of users  #AUTHOR_TAG or dialectology  #AUTHOR_TAG.', 'in these methods, a user is often represented by the concatenation of their tweets, and the geolocation model is trained on a very small percentage of explicitly geotagged tweets, noting the potential biases implicit in geotagged tweets  #AUTHOR_TAG.', 'lexical dialectology is ( in part ) the converse of user geolocation  #AUTHOR_TAG : given text associated with a variety of regions, the task is to identify terms that are distinctive of particular regions.', 'the complexity of the task is two - fold : ( 1 ) localised named entities ( e. g. sporting team names ) are not of interest ; and ( 2 ) without semantic knowledge it is difficult to detect terms that are in general use but have a special meaning in a region.', 'in this paper we propose a text - based geolocation method based on neural networks.', ""our contributions are as follows : ( 1 ) we achieve state - of - the - art results on benchmark twitter geolocation datasets ; ( 2 ) we show that the model is less sensitive to the specific location discretisation method ; ( 3 ) we release the first broad - coverage dataset for evaluation of lexical dialectology models ; ( 4 ) we incorporate our text - based model into a network - based model  #AUTHOR_TAG a ) and improve the performance utilising both network and text ; and ( 5 ) we use the model's embeddings for extraction of local terms and show that it outperforms two baselines""]",0
[' #TAUTHOR_TAG ; 2015a ) for twitter - world were over a superset of the dataset ; the results reported here are based on'],"[' #TAUTHOR_TAG ; 2015a ) for twitter - world were over a superset of the dataset ; the results reported here are based on the actual dataset. while the focus of this paper', 'is text - based user geolocation,']","[' #TAUTHOR_TAG ; 2015a ) for twitter - world were over a superset of the dataset ; the results reported here are based on the actual dataset. while the focus of this paper', 'is text']","[' #TAUTHOR_TAG ; 2015a ) for twitter - world were over a superset of the dataset ; the results reported here are based on the actual dataset. while the focus of this paper', '']",4
"['text - based methods based on a flat  #TAUTHOR_TAG or hierarchical  #AUTHOR_TAG geospatial representation.', 'our method']","['tree and k - means discretisation over the three datasets is shown in table 1.', 'the results are also compared with state - of - the - art text - based methods based on a flat  #TAUTHOR_TAG or hierarchical  #AUTHOR_TAG geospatial representation.', 'our method']","['- art text - based methods based on a flat  #TAUTHOR_TAG or hierarchical  #AUTHOR_TAG geospatial representation.', 'our method']","['performance of the text - based mlp model with k - d tree and k - means discretisation over the three datasets is shown in table 1.', 'the results are also compared with state - of - the - art text - based methods based on a flat  #TAUTHOR_TAG or hierarchical  #AUTHOR_TAG geospatial representation.', '']",4
['logistic regression ( lr )'],['logistic regression ( lr )'],['logistic regression ( lr )'],"['quantitatively tested the quality of the geographical embeddings by calculating the micro - average recall of the k - nearest dialect terms ( in terms of the proportion of retrieved dialect terms ) given a dialect region, as shown in figure 4.', 'recall at 0. 5 % is about 3. 6 %, meaning that we were able to retrieve 3. 6 % of the dialect terms given the dialect region name in the geographical embedding space.', 'the embeddings slightly outperform the output layer of logistic regression ( lr )']",4
[' #TAUTHOR_TAG ; 2015a ) for twitter - world were over a superset of the dataset ; the results reported here are based on'],"[' #TAUTHOR_TAG ; 2015a ) for twitter - world were over a superset of the dataset ; the results reported here are based on the actual dataset. while the focus of this paper', 'is text - based user geolocation,']","[' #TAUTHOR_TAG ; 2015a ) for twitter - world were over a superset of the dataset ; the results reported here are based on the actual dataset. while the focus of this paper', 'is text']","[' #TAUTHOR_TAG ; 2015a ) for twitter - world were over a superset of the dataset ; the results reported here are based on the actual dataset. while the focus of this paper', '']",7
['on the  #TAUTHOR_TAG'],['on the  #TAUTHOR_TAG'],"['on the  #TAUTHOR_TAG.', ""moreover, inspired by the ncca's objective function, we extend classical cnn + lstm approach""]","['present mean box pooling, a novel visual representation that pools over cnn representations of a large number, highly overlapping object proposals.', 'we show that such representation together with ncca, a successful multimodal embedding technique, achieves state - of - the - art performance on the  #TAUTHOR_TAG.', ""moreover, inspired by the ncca's objective function, we extend classical cnn + lstm approach to train the network by directly maximizing the similarity between the internal representation of the deep learning architecture and candidate answers."", 'again, such approach achieves a significant improvement over the prior work that also uses cnn + lstm approach on  #TAUTHOR_TAG']",4
"['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation']","['', 'although related ideas have been explored for visual question answering [ 22 ], and even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation by using object proposals.', 'more precisely, we argue for an approach that pools over a large number, highly overlapping object proposals.', 'this, arguably, increases the recall of extracting bounding boxes that describe an object, but also allows for multi - scale and multi - parts object representation.', 'our approach in the combination with the normalized correlation analysis embedding technique improves on the state - of - the - art of the  #TAUTHOR_TAG.', 'text - embedding loss : motivated by the popularity of deep architectures for visual question answering, that combine a global cnn image representation with an lstm [ 7 ] question representation [ 4, 13, 17, 20, 29, 30, 31 ], as well as the leading performance of ncca on the multi - choice  #TAUTHOR_TAG, we propose a novel extension of the cnn + lstm architecture that chooses a prompt completion out of four candidates ( see figure 4 ) by measuring similarities directly in the embedding space.', 'this contrasts with the prior approach of  #TAUTHOR_TAG that uses a post - hoc comparison between the discrete output of the cnn + lstm method and all four candidates.', 'to achieve this, we directly train an lstm with a cosine similarity loss between the output embedding of the network and language representation of the ground truth completion.', 'such an approach integrates more tightly with the multi - choice filling the blanks task, and significantly outperforms the prior cnn + lstm method  #TAUTHOR_TAG']",4
"['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation']","['', 'although related ideas have been explored for visual question answering [ 22 ], and even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation by using object proposals.', 'more precisely, we argue for an approach that pools over a large number, highly overlapping object proposals.', 'this, arguably, increases the recall of extracting bounding boxes that describe an object, but also allows for multi - scale and multi - parts object representation.', 'our approach in the combination with the normalized correlation analysis embedding technique improves on the state - of - the - art of the  #TAUTHOR_TAG.', 'text - embedding loss : motivated by the popularity of deep architectures for visual question answering, that combine a global cnn image representation with an lstm [ 7 ] question representation [ 4, 13, 17, 20, 29, 30, 31 ], as well as the leading performance of ncca on the multi - choice  #TAUTHOR_TAG, we propose a novel extension of the cnn + lstm architecture that chooses a prompt completion out of four candidates ( see figure 4 ) by measuring similarities directly in the embedding space.', 'this contrasts with the prior approach of  #TAUTHOR_TAG that uses a post - hoc comparison between the discrete output of the cnn + lstm method and all four candidates.', 'to achieve this, we directly train an lstm with a cosine similarity loss between the output embedding of the network and language representation of the ground truth completion.', 'such an approach integrates more tightly with the multi - choice filling the blanks task, and significantly outperforms the prior cnn + lstm method  #TAUTHOR_TAG']",4
"['with a tighter integration with the multi - choice  #TAUTHOR_TAG.', 'this approach is depicted in']","['closer to ncca with a tighter integration with the multi - choice  #TAUTHOR_TAG.', 'this approach is depicted in']","['with a tighter integration with the multi - choice  #TAUTHOR_TAG.', 'this approach is depicted in figure 3']","['', 'figure 1 illustrates the proposed mean box pooling image representation and figure 2 illustrates our whole method.', 'in section 3. 3, we describe ncca approach to encode two modalities into a joint space in greater details.', 'in section 3. 4, we also investigate a cnn + lstm architecture.', 'instead of generating a prompt completion that is next compared against candidate completions in a post - hoc process, we propose to choose a candidate completion by directly comparing candidates in the embedding space.', 'this puts cnn + lstm approach closer to ncca with a tighter integration with the multi - choice  #TAUTHOR_TAG.', 'this approach is depicted in figure 3']",4
"[' #TAUTHOR_TAG, instead of comparing the discrete']","[' #TAUTHOR_TAG, instead of comparing the discrete']","[' #TAUTHOR_TAG, instead of comparing the discrete output of']","['', 'similarly to prior work, we encode an image with a cnn encoder that is next concatenated with ( learnable ) word embeddings of the prompt sentence, and fed to a recurrent neural network.', ""we use a special'< blank >'token to denote the empty blank space in the image description."", 'on the other side, for each completion candidate s we compute its representation by averaging over word2vec [ 18 ] representations of the words contributing to s. however, in contrast to the prior work  #TAUTHOR_TAG, instead of comparing the discrete output of the network with the representation of s, we directly optimize an objective in the embedding space.', 'during training we maximize the similarity measure between the output embedding and the representation of σ by optimizing the following objective :', 'which is a cosine similarity between the representation of the available during the training correct completions i, and an output embedding vector of the i - th image - prompt training table 4 : bleu - 1 and bleu - 2 computed on  #TAUTHOR_TAG for different approaches.', 'imagenet using r - cnn [ 13 ], covering 42 ms coco categories.', '']",4
"[' #TAUTHOR_TAG, instead of comparing the discrete']","[' #TAUTHOR_TAG, instead of comparing the discrete']","[' #TAUTHOR_TAG, instead of comparing the discrete output of']","['', 'similarly to prior work, we encode an image with a cnn encoder that is next concatenated with ( learnable ) word embeddings of the prompt sentence, and fed to a recurrent neural network.', ""we use a special'< blank >'token to denote the empty blank space in the image description."", 'on the other side, for each completion candidate s we compute its representation by averaging over word2vec [ 18 ] representations of the words contributing to s. however, in contrast to the prior work  #TAUTHOR_TAG, instead of comparing the discrete output of the network with the representation of s, we directly optimize an objective in the embedding space.', 'during training we maximize the similarity measure between the output embedding and the representation of σ by optimizing the following objective :', 'which is a cosine similarity between the representation of the available during the training correct completions i, and an output embedding vector of the i - th image - prompt training table 4 : bleu - 1 and bleu - 2 computed on  #TAUTHOR_TAG for different approaches.', 'imagenet using r - cnn [ 13 ], covering 42 ms coco categories.', '']",4
['( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],['( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],"['ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes,']","['', 'consistently outperforms state - of - the - art on every category except the', ""' scenes'category. this suggests that better localized object oriented representation is beneficial. however, edge boxes only roughly localize objects. this naturally leads to the following question if better localization helps. to see the"", 'limits, we compare ncca ( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes, and hence they can', 'be seen as an upper bound for a detection method trained to detect objects on ms coco ). surprisingly, ncca ( ours )', 'outperforms ncca ( bbox ) by a large margin as table 4 shows. arguably, object proposals have better recall and captures multi', '- scale, multi - parts phenomena. cnn + lstm with comparison in the output embedding space. on one hand', 'ncca tops the leaderboard on the  #TAUTHOR_TAG. table 5 : comparison between our embedded cnn + lstm approach that computes the similarity between input and candidate answers in the embedding space,', 'and the plain cnn + lstm original approach from  #TAUTHOR_TAG. since the accuracies', 'of cnn + lstm  #TAUTHOR_TAG', 'are unavailable for two categories, we report average over 10 categories in this case. results in %. completion of the prompt sentence out', 'of four candidates, the comparison between the candidate completions should be directly done in the output', 'embedding space. this', 'contrasts to a post - hoc', 'process used in  #TAUTHOR_TAG where an image description architecture ( cnn + lstm ) first generates a completion that', 'is next compared against the candidates in the word2vec space ( see section 3', 'for more details ). moreover, since the "" ask your neurons "" architecture [ 17 ] is more suitable for the question answering task, we extend that method to do comparisons directly in the', 'embedding space ( "" embedded cnn + lstm "" in table 5 ). note', 'that, here we feed the sentence prompt to lstm even though it is fixed per category. table', '5 shows the performance of different methods. our "" embedded', 'cnn + lstm "" outperforms other methods on both tasks confirming our hypothesis. "" ask your neurons "" [ 17 ] is also slightly better than the original cnn + lstm  #TAUTHOR_TAG (', 'on the 10 categories that the results for cnn + lstm are available it achieves 49. 8 % accuracy on the easy task, which is 2. 1', 'percentage points higher than cnn + lstm )']",4
['( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],['( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],"['ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes,']","['', 'consistently outperforms state - of - the - art on every category except the', ""' scenes'category. this suggests that better localized object oriented representation is beneficial. however, edge boxes only roughly localize objects. this naturally leads to the following question if better localization helps. to see the"", 'limits, we compare ncca ( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes, and hence they can', 'be seen as an upper bound for a detection method trained to detect objects on ms coco ). surprisingly, ncca ( ours )', 'outperforms ncca ( bbox ) by a large margin as table 4 shows. arguably, object proposals have better recall and captures multi', '- scale, multi - parts phenomena. cnn + lstm with comparison in the output embedding space. on one hand', 'ncca tops the leaderboard on the  #TAUTHOR_TAG. table 5 : comparison between our embedded cnn + lstm approach that computes the similarity between input and candidate answers in the embedding space,', 'and the plain cnn + lstm original approach from  #TAUTHOR_TAG. since the accuracies', 'of cnn + lstm  #TAUTHOR_TAG', 'are unavailable for two categories, we report average over 10 categories in this case. results in %. completion of the prompt sentence out', 'of four candidates, the comparison between the candidate completions should be directly done in the output', 'embedding space. this', 'contrasts to a post - hoc', 'process used in  #TAUTHOR_TAG where an image description architecture ( cnn + lstm ) first generates a completion that', 'is next compared against the candidates in the word2vec space ( see section 3', 'for more details ). moreover, since the "" ask your neurons "" architecture [ 17 ] is more suitable for the question answering task, we extend that method to do comparisons directly in the', 'embedding space ( "" embedded cnn + lstm "" in table 5 ). note', 'that, here we feed the sentence prompt to lstm even though it is fixed per category. table', '5 shows the performance of different methods. our "" embedded', 'cnn + lstm "" outperforms other methods on both tasks confirming our hypothesis. "" ask your neurons "" [ 17 ] is also slightly better than the original cnn + lstm  #TAUTHOR_TAG (', 'on the 10 categories that the results for cnn + lstm are available it achieves 49. 8 % accuracy on the easy task, which is 2. 1', 'percentage points higher than cnn + lstm )']",4
['( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],['( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],"['ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes,']","['', 'consistently outperforms state - of - the - art on every category except the', ""' scenes'category. this suggests that better localized object oriented representation is beneficial. however, edge boxes only roughly localize objects. this naturally leads to the following question if better localization helps. to see the"", 'limits, we compare ncca ( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes, and hence they can', 'be seen as an upper bound for a detection method trained to detect objects on ms coco ). surprisingly, ncca ( ours )', 'outperforms ncca ( bbox ) by a large margin as table 4 shows. arguably, object proposals have better recall and captures multi', '- scale, multi - parts phenomena. cnn + lstm with comparison in the output embedding space. on one hand', 'ncca tops the leaderboard on the  #TAUTHOR_TAG. table 5 : comparison between our embedded cnn + lstm approach that computes the similarity between input and candidate answers in the embedding space,', 'and the plain cnn + lstm original approach from  #TAUTHOR_TAG. since the accuracies', 'of cnn + lstm  #TAUTHOR_TAG', 'are unavailable for two categories, we report average over 10 categories in this case. results in %. completion of the prompt sentence out', 'of four candidates, the comparison between the candidate completions should be directly done in the output', 'embedding space. this', 'contrasts to a post - hoc', 'process used in  #TAUTHOR_TAG where an image description architecture ( cnn + lstm ) first generates a completion that', 'is next compared against the candidates in the word2vec space ( see section 3', 'for more details ). moreover, since the "" ask your neurons "" architecture [ 17 ] is more suitable for the question answering task, we extend that method to do comparisons directly in the', 'embedding space ( "" embedded cnn + lstm "" in table 5 ). note', 'that, here we feed the sentence prompt to lstm even though it is fixed per category. table', '5 shows the performance of different methods. our "" embedded', 'cnn + lstm "" outperforms other methods on both tasks confirming our hypothesis. "" ask your neurons "" [ 17 ] is also slightly better than the original cnn + lstm  #TAUTHOR_TAG (', 'on the 10 categories that the results for cnn + lstm are available it achieves 49. 8 % accuracy on the easy task, which is 2. 1', 'percentage points higher than cnn + lstm )']",4
['( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],['( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],"['ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes,']","['', 'consistently outperforms state - of - the - art on every category except the', ""' scenes'category. this suggests that better localized object oriented representation is beneficial. however, edge boxes only roughly localize objects. this naturally leads to the following question if better localization helps. to see the"", 'limits, we compare ncca ( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes, and hence they can', 'be seen as an upper bound for a detection method trained to detect objects on ms coco ). surprisingly, ncca ( ours )', 'outperforms ncca ( bbox ) by a large margin as table 4 shows. arguably, object proposals have better recall and captures multi', '- scale, multi - parts phenomena. cnn + lstm with comparison in the output embedding space. on one hand', 'ncca tops the leaderboard on the  #TAUTHOR_TAG. table 5 : comparison between our embedded cnn + lstm approach that computes the similarity between input and candidate answers in the embedding space,', 'and the plain cnn + lstm original approach from  #TAUTHOR_TAG. since the accuracies', 'of cnn + lstm  #TAUTHOR_TAG', 'are unavailable for two categories, we report average over 10 categories in this case. results in %. completion of the prompt sentence out', 'of four candidates, the comparison between the candidate completions should be directly done in the output', 'embedding space. this', 'contrasts to a post - hoc', 'process used in  #TAUTHOR_TAG where an image description architecture ( cnn + lstm ) first generates a completion that', 'is next compared against the candidates in the word2vec space ( see section 3', 'for more details ). moreover, since the "" ask your neurons "" architecture [ 17 ] is more suitable for the question answering task, we extend that method to do comparisons directly in the', 'embedding space ( "" embedded cnn + lstm "" in table 5 ). note', 'that, here we feed the sentence prompt to lstm even though it is fixed per category. table', '5 shows the performance of different methods. our "" embedded', 'cnn + lstm "" outperforms other methods on both tasks confirming our hypothesis. "" ask your neurons "" [ 17 ] is also slightly better than the original cnn + lstm  #TAUTHOR_TAG (', 'on the 10 categories that the results for cnn + lstm are available it achieves 49. 8 % accuracy on the easy task, which is 2. 1', 'percentage points higher than cnn + lstm )']",4
['( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],['( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],"['ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes,']","['', 'consistently outperforms state - of - the - art on every category except the', ""' scenes'category. this suggests that better localized object oriented representation is beneficial. however, edge boxes only roughly localize objects. this naturally leads to the following question if better localization helps. to see the"", 'limits, we compare ncca ( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes, and hence they can', 'be seen as an upper bound for a detection method trained to detect objects on ms coco ). surprisingly, ncca ( ours )', 'outperforms ncca ( bbox ) by a large margin as table 4 shows. arguably, object proposals have better recall and captures multi', '- scale, multi - parts phenomena. cnn + lstm with comparison in the output embedding space. on one hand', 'ncca tops the leaderboard on the  #TAUTHOR_TAG. table 5 : comparison between our embedded cnn + lstm approach that computes the similarity between input and candidate answers in the embedding space,', 'and the plain cnn + lstm original approach from  #TAUTHOR_TAG. since the accuracies', 'of cnn + lstm  #TAUTHOR_TAG', 'are unavailable for two categories, we report average over 10 categories in this case. results in %. completion of the prompt sentence out', 'of four candidates, the comparison between the candidate completions should be directly done in the output', 'embedding space. this', 'contrasts to a post - hoc', 'process used in  #TAUTHOR_TAG where an image description architecture ( cnn + lstm ) first generates a completion that', 'is next compared against the candidates in the word2vec space ( see section 3', 'for more details ). moreover, since the "" ask your neurons "" architecture [ 17 ] is more suitable for the question answering task, we extend that method to do comparisons directly in the', 'embedding space ( "" embedded cnn + lstm "" in table 5 ). note', 'that, here we feed the sentence prompt to lstm even though it is fixed per category. table', '5 shows the performance of different methods. our "" embedded', 'cnn + lstm "" outperforms other methods on both tasks confirming our hypothesis. "" ask your neurons "" [ 17 ] is also slightly better than the original cnn + lstm  #TAUTHOR_TAG (', 'on the 10 categories that the results for cnn + lstm are available it achieves 49. 8 % accuracy on the easy task, which is 2. 1', 'percentage points higher than cnn + lstm )']",4
['on the  #TAUTHOR_TAG'],['on the  #TAUTHOR_TAG'],"['on the  #TAUTHOR_TAG.', ""moreover, inspired by the ncca's objective function, we extend classical cnn + lstm approach""]","['present mean box pooling, a novel visual representation that pools over cnn representations of a large number, highly overlapping object proposals.', 'we show that such representation together with ncca, a successful multimodal embedding technique, achieves state - of - the - art performance on the  #TAUTHOR_TAG.', ""moreover, inspired by the ncca's objective function, we extend classical cnn + lstm approach to train the network by directly maximizing the similarity between the internal representation of the deep learning architecture and candidate answers."", 'again, such approach achieves a significant improvement over the prior work that also uses cnn + lstm approach on  #TAUTHOR_TAG']",1
"['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation']","['', 'although related ideas have been explored for visual question answering [ 22 ], and even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation by using object proposals.', 'more precisely, we argue for an approach that pools over a large number, highly overlapping object proposals.', 'this, arguably, increases the recall of extracting bounding boxes that describe an object, but also allows for multi - scale and multi - parts object representation.', 'our approach in the combination with the normalized correlation analysis embedding technique improves on the state - of - the - art of the  #TAUTHOR_TAG.', 'text - embedding loss : motivated by the popularity of deep architectures for visual question answering, that combine a global cnn image representation with an lstm [ 7 ] question representation [ 4, 13, 17, 20, 29, 30, 31 ], as well as the leading performance of ncca on the multi - choice  #TAUTHOR_TAG, we propose a novel extension of the cnn + lstm architecture that chooses a prompt completion out of four candidates ( see figure 4 ) by measuring similarities directly in the embedding space.', 'this contrasts with the prior approach of  #TAUTHOR_TAG that uses a post - hoc comparison between the discrete output of the cnn + lstm method and all four candidates.', 'to achieve this, we directly train an lstm with a cosine similarity loss between the output embedding of the network and language representation of the ground truth completion.', 'such an approach integrates more tightly with the multi - choice filling the blanks task, and significantly outperforms the prior cnn + lstm method  #TAUTHOR_TAG']",1
"['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation']","['', 'although related ideas have been explored for visual question answering [ 22 ], and even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation by using object proposals.', 'more precisely, we argue for an approach that pools over a large number, highly overlapping object proposals.', 'this, arguably, increases the recall of extracting bounding boxes that describe an object, but also allows for multi - scale and multi - parts object representation.', 'our approach in the combination with the normalized correlation analysis embedding technique improves on the state - of - the - art of the  #TAUTHOR_TAG.', 'text - embedding loss : motivated by the popularity of deep architectures for visual question answering, that combine a global cnn image representation with an lstm [ 7 ] question representation [ 4, 13, 17, 20, 29, 30, 31 ], as well as the leading performance of ncca on the multi - choice  #TAUTHOR_TAG, we propose a novel extension of the cnn + lstm architecture that chooses a prompt completion out of four candidates ( see figure 4 ) by measuring similarities directly in the embedding space.', 'this contrasts with the prior approach of  #TAUTHOR_TAG that uses a post - hoc comparison between the discrete output of the cnn + lstm method and all four candidates.', 'to achieve this, we directly train an lstm with a cosine similarity loss between the output embedding of the network and language representation of the ground truth completion.', 'such an approach integrates more tightly with the multi - choice filling the blanks task, and significantly outperforms the prior cnn + lstm method  #TAUTHOR_TAG']",6
"['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation']","['', 'although related ideas have been explored for visual question answering [ 22 ], and even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation by using object proposals.', 'more precisely, we argue for an approach that pools over a large number, highly overlapping object proposals.', 'this, arguably, increases the recall of extracting bounding boxes that describe an object, but also allows for multi - scale and multi - parts object representation.', 'our approach in the combination with the normalized correlation analysis embedding technique improves on the state - of - the - art of the  #TAUTHOR_TAG.', 'text - embedding loss : motivated by the popularity of deep architectures for visual question answering, that combine a global cnn image representation with an lstm [ 7 ] question representation [ 4, 13, 17, 20, 29, 30, 31 ], as well as the leading performance of ncca on the multi - choice  #TAUTHOR_TAG, we propose a novel extension of the cnn + lstm architecture that chooses a prompt completion out of four candidates ( see figure 4 ) by measuring similarities directly in the embedding space.', 'this contrasts with the prior approach of  #TAUTHOR_TAG that uses a post - hoc comparison between the discrete output of the cnn + lstm method and all four candidates.', 'to achieve this, we directly train an lstm with a cosine similarity loss between the output embedding of the network and language representation of the ground truth completion.', 'such an approach integrates more tightly with the multi - choice filling the blanks task, and significantly outperforms the prior cnn + lstm method  #TAUTHOR_TAG']",6
"['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant']","['even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation']","['', 'although related ideas have been explored for visual question answering [ 22 ], and even have been used in  #TAUTHOR_TAG, we are first to show a significant improvement of such representation by using object proposals.', 'more precisely, we argue for an approach that pools over a large number, highly overlapping object proposals.', 'this, arguably, increases the recall of extracting bounding boxes that describe an object, but also allows for multi - scale and multi - parts object representation.', 'our approach in the combination with the normalized correlation analysis embedding technique improves on the state - of - the - art of the  #TAUTHOR_TAG.', 'text - embedding loss : motivated by the popularity of deep architectures for visual question answering, that combine a global cnn image representation with an lstm [ 7 ] question representation [ 4, 13, 17, 20, 29, 30, 31 ], as well as the leading performance of ncca on the multi - choice  #TAUTHOR_TAG, we propose a novel extension of the cnn + lstm architecture that chooses a prompt completion out of four candidates ( see figure 4 ) by measuring similarities directly in the embedding space.', 'this contrasts with the prior approach of  #TAUTHOR_TAG that uses a post - hoc comparison between the discrete output of the cnn + lstm method and all four candidates.', 'to achieve this, we directly train an lstm with a cosine similarity loss between the output embedding of the network and language representation of the ground truth completion.', 'such an approach integrates more tightly with the multi - choice filling the blanks task, and significantly outperforms the prior cnn + lstm method  #TAUTHOR_TAG']",6
['( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],['( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes'],"['ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes,']","['', 'consistently outperforms state - of - the - art on every category except the', ""' scenes'category. this suggests that better localized object oriented representation is beneficial. however, edge boxes only roughly localize objects. this naturally leads to the following question if better localization helps. to see the"", 'limits, we compare ncca ( ours ) against ncca ( bbox )  #TAUTHOR_TAG shows that ground truth bounding boxes outperforms automatically detected bounding boxes, and hence they can', 'be seen as an upper bound for a detection method trained to detect objects on ms coco ). surprisingly, ncca ( ours )', 'outperforms ncca ( bbox ) by a large margin as table 4 shows. arguably, object proposals have better recall and captures multi', '- scale, multi - parts phenomena. cnn + lstm with comparison in the output embedding space. on one hand', 'ncca tops the leaderboard on the  #TAUTHOR_TAG. table 5 : comparison between our embedded cnn + lstm approach that computes the similarity between input and candidate answers in the embedding space,', 'and the plain cnn + lstm original approach from  #TAUTHOR_TAG. since the accuracies', 'of cnn + lstm  #TAUTHOR_TAG', 'are unavailable for two categories, we report average over 10 categories in this case. results in %. completion of the prompt sentence out', 'of four candidates, the comparison between the candidate completions should be directly done in the output', 'embedding space. this', 'contrasts to a post - hoc', 'process used in  #TAUTHOR_TAG where an image description architecture ( cnn + lstm ) first generates a completion that', 'is next compared against the candidates in the word2vec space ( see section 3', 'for more details ). moreover, since the "" ask your neurons "" architecture [ 17 ] is more suitable for the question answering task, we extend that method to do comparisons directly in the', 'embedding space ( "" embedded cnn + lstm "" in table 5 ). note', 'that, here we feed the sentence prompt to lstm even though it is fixed per category. table', '5 shows the performance of different methods. our "" embedded', 'cnn + lstm "" outperforms other methods on both tasks confirming our hypothesis. "" ask your neurons "" [ 17 ] is also slightly better than the original cnn + lstm  #TAUTHOR_TAG (', 'on the 10 categories that the results for cnn + lstm are available it achieves 49. 8 % accuracy on the easy task, which is 2. 1', 'percentage points higher than cnn + lstm )']",6
"['on the  #TAUTHOR_TAG.', 'at']","['on the  #TAUTHOR_TAG.', 'at']","['textual answers, into a joint embedding space.', 'this embedding method has shown outstanding performance on the  #TAUTHOR_TAG.', 'at the test time, given']","['use the normalized canonical correlation analysis ( ncca ) to learn a mapping from two modalities : image and textual answers, into a joint embedding space.', 'this embedding method has shown outstanding performance on the  #TAUTHOR_TAG.', 'at the test time, given the encoded image, we choose an answer ( encoded by the mean pooling over word2vec words representations ) from the set of four candidate answers that is the most similar to the encoded image in the multimodal embedding space.', 'formally, the canonical correlation analysis ( cca ) maximizes the cosine similarity between two modalities ( also called views ) in the embedding space, that is :', 'where tr is the matrix trace, x : = xw 1, y : = yw 2, and x, y are two views ( encoded images, and textual answers in our case ).', 'normalized canonical correlation analysis ( ncca ) [ 6 ] has been reported to work significantly better than the plain cca.', 'here, columns of the projection matrices w 1 and w 2 are scaled by the p - th power ( p = 4 ) of the corresponding eigen values.', 'the improvement is consistent with the findings of  #TAUTHOR_TAG, where ncca performs better than cca by about five percentage points in average on the hard task']",3
"['systems  #TAUTHOR_TAG, but also contribute to']","['systems  #TAUTHOR_TAG, but also contribute to']","['intelligent tutoring systems  #TAUTHOR_TAG, but also contribute to']","['learning dialogue structure from corpora is an active area of research driven by a recognition of the value offered by data - driven approaches ( e. g.,  #AUTHOR_TAG.', 'dialogue structure information is of particular importance when the interaction is centered around a learning task, such as in natural language tutoring, because techniques that support empirical identification of dialogue strategies can inform not only the design of intelligent tutoring systems  #TAUTHOR_TAG, but also contribute to our understanding of the cognitive and affective processes involved in learning through tutoring ( van  #AUTHOR_TAG.', 'although traditional top - down approaches ( e. g.,  #AUTHOR_TAG and some empirical work on analyzing the structure of tutorial dialogue  #TAUTHOR_TAG have yielded significant results, the field is limited by the lack of an automatic, data - driven approach to identifying dialogue structure.', 'an empirical approach to identifying tutorial dialogue strategies, or modes, could address this limitation by providing a mechanism for describing in succinct probabilistic terms the tutorial strategies that actually occur in a corpus.', 'just as early work on dialogue act interpretation utilized hidden markov models ( hmms ) to capture linguistic structure  #AUTHOR_TAG, we propose a system that uses hmms to capture the structure of tutorial dialogue implicit within sequences of already - tagged dialogue acts.', 'this approach operates on the premise that at any given point in the tutorial dialogue, the collaborative interaction is in a dialogue mode that characterizes the nature of the exchanges between tutor and student.', 'in our model, a dialogue mode is defined by a probability distribution over the observed symbols ( e. g., dialogue acts and adjacency pairs ).', 'our previous work has noted some limitations of first - order hmms as applied to sequences of individual dialogue acts ( boyer et al., in press ).', 'chief among these is that hmms allow arbitrarily frequent transitions between hidden states, which does not conform well to human intuition about how tutoring strategies are applied.', 'training an hmm on a sequence of adjacency pairs rather than individual dialogue acts is one way to generate a more descriptive model without increasing model complexity more than is required to accommodate the expanded set of observation symbols.', 'to this end, we apply the approach of  #AUTHOR_TAG for empirically identifying significant adjacency pairs within dialogue, and proceed by treating adjacency pairs as atomic units for the purposes of training the hmm']",0
"['systems  #TAUTHOR_TAG, but also contribute to']","['systems  #TAUTHOR_TAG, but also contribute to']","['intelligent tutoring systems  #TAUTHOR_TAG, but also contribute to']","['learning dialogue structure from corpora is an active area of research driven by a recognition of the value offered by data - driven approaches ( e. g.,  #AUTHOR_TAG.', 'dialogue structure information is of particular importance when the interaction is centered around a learning task, such as in natural language tutoring, because techniques that support empirical identification of dialogue strategies can inform not only the design of intelligent tutoring systems  #TAUTHOR_TAG, but also contribute to our understanding of the cognitive and affective processes involved in learning through tutoring ( van  #AUTHOR_TAG.', 'although traditional top - down approaches ( e. g.,  #AUTHOR_TAG and some empirical work on analyzing the structure of tutorial dialogue  #TAUTHOR_TAG have yielded significant results, the field is limited by the lack of an automatic, data - driven approach to identifying dialogue structure.', 'an empirical approach to identifying tutorial dialogue strategies, or modes, could address this limitation by providing a mechanism for describing in succinct probabilistic terms the tutorial strategies that actually occur in a corpus.', 'just as early work on dialogue act interpretation utilized hidden markov models ( hmms ) to capture linguistic structure  #AUTHOR_TAG, we propose a system that uses hmms to capture the structure of tutorial dialogue implicit within sequences of already - tagged dialogue acts.', 'this approach operates on the premise that at any given point in the tutorial dialogue, the collaborative interaction is in a dialogue mode that characterizes the nature of the exchanges between tutor and student.', 'in our model, a dialogue mode is defined by a probability distribution over the observed symbols ( e. g., dialogue acts and adjacency pairs ).', 'our previous work has noted some limitations of first - order hmms as applied to sequences of individual dialogue acts ( boyer et al., in press ).', 'chief among these is that hmms allow arbitrarily frequent transitions between hidden states, which does not conform well to human intuition about how tutoring strategies are applied.', 'training an hmm on a sequence of adjacency pairs rather than individual dialogue acts is one way to generate a more descriptive model without increasing model complexity more than is required to accommodate the expanded set of observation symbols.', 'to this end, we apply the approach of  #AUTHOR_TAG for empirically identifying significant adjacency pairs within dialogue, and proceed by treating adjacency pairs as atomic units for the purposes of training the hmm']",0
"['as well  #TAUTHOR_TAG.', 'for the current corpus, bigram analysis of dialogue acts']","['importance of adjacency pairs is wellestablished in natural language dialogue ( e. g.,  #AUTHOR_TAG, and adjacency pair analysis has illuminated important phenomena in tutoring as well  #TAUTHOR_TAG.', 'for the current corpus, bigram analysis of dialogue acts']","['. g.,  #AUTHOR_TAG, and adjacency pair analysis has illuminated important phenomena in tutoring as well  #TAUTHOR_TAG.', 'for the current corpus, bigram analysis of dialogue acts']","['importance of adjacency pairs is wellestablished in natural language dialogue ( e. g.,  #AUTHOR_TAG, and adjacency pair analysis has illuminated important phenomena in tutoring as well  #TAUTHOR_TAG.', 'for the current corpus, bigram analysis of dialogue acts yielded a set of commonly - occurring pairs.', 'however, as noted in  #AUTHOR_TAG, in order to establish that two dialogue acts are truly related as an adjacency pair, it is important to determine whether the presence of the first member of the pair is associated with a significantly higher probability of the second member occurring.', 'for this analysis we utilize a χ 2 test for independence of the categorical variables act i and act i + 1 for all two - way combinations of dialogue act tags.', 'only pairs in which speaker ( act i ) = speaker ( act i + 1 ) were considered.', 'other dialogue acts were treated as atomic elements in subsequent analysis, as discussed in section 3.', 'table 2 displays a list of the dependent pairs sorted by descending ( unadjusted ) statistical significance ; the subscript indicates tutor ( t ) or student ( s ).', 'acti acti +']",0
"['systems  #TAUTHOR_TAG, but also contribute to']","['systems  #TAUTHOR_TAG, but also contribute to']","['intelligent tutoring systems  #TAUTHOR_TAG, but also contribute to']","['learning dialogue structure from corpora is an active area of research driven by a recognition of the value offered by data - driven approaches ( e. g.,  #AUTHOR_TAG.', 'dialogue structure information is of particular importance when the interaction is centered around a learning task, such as in natural language tutoring, because techniques that support empirical identification of dialogue strategies can inform not only the design of intelligent tutoring systems  #TAUTHOR_TAG, but also contribute to our understanding of the cognitive and affective processes involved in learning through tutoring ( van  #AUTHOR_TAG.', 'although traditional top - down approaches ( e. g.,  #AUTHOR_TAG and some empirical work on analyzing the structure of tutorial dialogue  #TAUTHOR_TAG have yielded significant results, the field is limited by the lack of an automatic, data - driven approach to identifying dialogue structure.', 'an empirical approach to identifying tutorial dialogue strategies, or modes, could address this limitation by providing a mechanism for describing in succinct probabilistic terms the tutorial strategies that actually occur in a corpus.', 'just as early work on dialogue act interpretation utilized hidden markov models ( hmms ) to capture linguistic structure  #AUTHOR_TAG, we propose a system that uses hmms to capture the structure of tutorial dialogue implicit within sequences of already - tagged dialogue acts.', 'this approach operates on the premise that at any given point in the tutorial dialogue, the collaborative interaction is in a dialogue mode that characterizes the nature of the exchanges between tutor and student.', 'in our model, a dialogue mode is defined by a probability distribution over the observed symbols ( e. g., dialogue acts and adjacency pairs ).', 'our previous work has noted some limitations of first - order hmms as applied to sequences of individual dialogue acts ( boyer et al., in press ).', 'chief among these is that hmms allow arbitrarily frequent transitions between hidden states, which does not conform well to human intuition about how tutoring strategies are applied.', 'training an hmm on a sequence of adjacency pairs rather than individual dialogue acts is one way to generate a more descriptive model without increasing model complexity more than is required to accommodate the expanded set of observation symbols.', 'to this end, we apply the approach of  #AUTHOR_TAG for empirically identifying significant adjacency pairs within dialogue, and proceed by treating adjacency pairs as atomic units for the purposes of training the hmm']",1
['( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG'],['networks ( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG'],"['between tokens  #AUTHOR_TAG, while the other uses', 'multiple parallel temporal convolutional neural networks ( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG. although these approaches focus']","['to combine the token representations into a single segment representation that captures relevant information for the task. of the two state - of - the - art approaches on dialog act recognition, one uses a deep stack of recurrent neural networks', '( rnns )  #AUTHOR_TAG to capture long distance relations between tokens  #AUTHOR_TAG, while the other uses', 'multiple parallel temporal convolutional neural networks ( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG. although these approaches focus on capturing different information, both have been proved successful on', '']",0
['( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG'],['networks ( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG'],"['between tokens  #AUTHOR_TAG, while the other uses', 'multiple parallel temporal convolutional neural networks ( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG. although these approaches focus']","['to combine the token representations into a single segment representation that captures relevant information for the task. of the two state - of - the - art approaches on dialog act recognition, one uses a deep stack of recurrent neural networks', '( rnns )  #AUTHOR_TAG to capture long distance relations between tokens  #AUTHOR_TAG, while the other uses', 'multiple parallel temporal convolutional neural networks ( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG. although these approaches focus on capturing different information, both have been proved successful on', '']",0
['( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG'],['networks ( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG'],"['between tokens  #AUTHOR_TAG, while the other uses', 'multiple parallel temporal convolutional neural networks ( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG. although these approaches focus']","['to combine the token representations into a single segment representation that captures relevant information for the task. of the two state - of - the - art approaches on dialog act recognition, one uses a deep stack of recurrent neural networks', '( rnns )  #AUTHOR_TAG to capture long distance relations between tokens  #AUTHOR_TAG, while the other uses', 'multiple parallel temporal convolutional neural networks ( cnns )  #AUTHOR_TAG to capture relevant functional patterns with different length  #TAUTHOR_TAG. although these approaches focus on capturing different information, both have been proved successful on', '']",0
"['convolutional side,  #TAUTHOR_TAG generated']","['convolutional side,  #TAUTHOR_TAG generated the segment representation by combining']","['convolutional side,  #TAUTHOR_TAG generated']","['the use of a single recurrent or convolutional layer to generate the segment representation from those of its words', '. however, as stated in section 1, the approaches which currently have top performance on the task explore the use of multiple', 'of those layers. on the recurrent side,  #AUTHOR_TAG achieved their best results using a segment representation generated by concatenating the outputs of a stack of 10 lstm units at the last time step. this way', ', the model is able to capture long distance relations', 'between tokens. on the convolutional side,  #TAUTHOR_TAG generated the segment representation by combining the outputs of three parallel cnns with different context window sizes, in order to capture different functional patterns.', 'in both cases, pre - trained word - embeddings were used as input to the network.  #AUTHOR_TAG compared the performance', 'of embeddings with different dimensionality trained on multiple corpora using glove and word2vec  #AUTHOR_TAG. the best results were achieved when', 'using 150 - dimensional embeddings trained on wikipedia data using word2vec.  #TAUTHOR_TAG used 200 - dimensional word2vec embeddings trained on facebook data. overall, from the reported results, it is not possible to state which is the top performing segment representation approach since the evaluation was performed on different subsets of the corpus.', '']",0
"['convolutional side,  #TAUTHOR_TAG generated']","['convolutional side,  #TAUTHOR_TAG generated the segment representation by combining']","['convolutional side,  #TAUTHOR_TAG generated']","['the use of a single recurrent or convolutional layer to generate the segment representation from those of its words', '. however, as stated in section 1, the approaches which currently have top performance on the task explore the use of multiple', 'of those layers. on the recurrent side,  #AUTHOR_TAG achieved their best results using a segment representation generated by concatenating the outputs of a stack of 10 lstm units at the last time step. this way', ', the model is able to capture long distance relations', 'between tokens. on the convolutional side,  #TAUTHOR_TAG generated the segment representation by combining the outputs of three parallel cnns with different context window sizes, in order to capture different functional patterns.', 'in both cases, pre - trained word - embeddings were used as input to the network.  #AUTHOR_TAG compared the performance', 'of embeddings with different dimensionality trained on multiple corpora using glove and word2vec  #AUTHOR_TAG. the best results were achieved when', 'using 150 - dimensional embeddings trained on wikipedia data using word2vec.  #TAUTHOR_TAG used 200 - dimensional word2vec embeddings trained on facebook data. overall, from the reported results, it is not possible to state which is the top performing segment representation approach since the evaluation was performed on different subsets of the corpus.', '']",0
"['convolutional side,  #TAUTHOR_TAG generated']","['convolutional side,  #TAUTHOR_TAG generated the segment representation by combining']","['convolutional side,  #TAUTHOR_TAG generated']","['the use of a single recurrent or convolutional layer to generate the segment representation from those of its words', '. however, as stated in section 1, the approaches which currently have top performance on the task explore the use of multiple', 'of those layers. on the recurrent side,  #AUTHOR_TAG achieved their best results using a segment representation generated by concatenating the outputs of a stack of 10 lstm units at the last time step. this way', ', the model is able to capture long distance relations', 'between tokens. on the convolutional side,  #TAUTHOR_TAG generated the segment representation by combining the outputs of three parallel cnns with different context window sizes, in order to capture different functional patterns.', 'in both cases, pre - trained word - embeddings were used as input to the network.  #AUTHOR_TAG compared the performance', 'of embeddings with different dimensionality trained on multiple corpora using glove and word2vec  #AUTHOR_TAG. the best results were achieved when', 'using 150 - dimensional embeddings trained on wikipedia data using word2vec.  #TAUTHOR_TAG used 200 - dimensional word2vec embeddings trained on facebook data. overall, from the reported results, it is not possible to state which is the top performing segment representation approach since the evaluation was performed on different subsets of the corpus.', '']",0
"['convolutional side,  #TAUTHOR_TAG generated']","['convolutional side,  #TAUTHOR_TAG generated the segment representation by combining']","['convolutional side,  #TAUTHOR_TAG generated']","['the use of a single recurrent or convolutional layer to generate the segment representation from those of its words', '. however, as stated in section 1, the approaches which currently have top performance on the task explore the use of multiple', 'of those layers. on the recurrent side,  #AUTHOR_TAG achieved their best results using a segment representation generated by concatenating the outputs of a stack of 10 lstm units at the last time step. this way', ', the model is able to capture long distance relations', 'between tokens. on the convolutional side,  #TAUTHOR_TAG generated the segment representation by combining the outputs of three parallel cnns with different context window sizes, in order to capture different functional patterns.', 'in both cases, pre - trained word - embeddings were used as input to the network.  #AUTHOR_TAG compared the performance', 'of embeddings with different dimensionality trained on multiple corpora using glove and word2vec  #AUTHOR_TAG. the best results were achieved when', 'using 150 - dimensional embeddings trained on wikipedia data using word2vec.  #TAUTHOR_TAG used 200 - dimensional word2vec embeddings trained on facebook data. overall, from the reported results, it is not possible to state which is the top performing segment representation approach since the evaluation was performed on different subsets of the corpus.', '']",0
"['convolutional side,  #TAUTHOR_TAG generated']","['convolutional side,  #TAUTHOR_TAG generated the segment representation by combining']","['convolutional side,  #TAUTHOR_TAG generated']","['the use of a single recurrent or convolutional layer to generate the segment representation from those of its words', '. however, as stated in section 1, the approaches which currently have top performance on the task explore the use of multiple', 'of those layers. on the recurrent side,  #AUTHOR_TAG achieved their best results using a segment representation generated by concatenating the outputs of a stack of 10 lstm units at the last time step. this way', ', the model is able to capture long distance relations', 'between tokens. on the convolutional side,  #TAUTHOR_TAG generated the segment representation by combining the outputs of three parallel cnns with different context window sizes, in order to capture different functional patterns.', 'in both cases, pre - trained word - embeddings were used as input to the network.  #AUTHOR_TAG compared the performance', 'of embeddings with different dimensionality trained on multiple corpora using glove and word2vec  #AUTHOR_TAG. the best results were achieved when', 'using 150 - dimensional embeddings trained on wikipedia data using word2vec.  #TAUTHOR_TAG used 200 - dimensional word2vec embeddings trained on facebook data. overall, from the reported results, it is not possible to state which is the top performing segment representation approach since the evaluation was performed on different subsets of the corpus.', '']",0
"['convolutional side,  #TAUTHOR_TAG generated']","['convolutional side,  #TAUTHOR_TAG generated the segment representation by combining']","['convolutional side,  #TAUTHOR_TAG generated']","['the use of a single recurrent or convolutional layer to generate the segment representation from those of its words', '. however, as stated in section 1, the approaches which currently have top performance on the task explore the use of multiple', 'of those layers. on the recurrent side,  #AUTHOR_TAG achieved their best results using a segment representation generated by concatenating the outputs of a stack of 10 lstm units at the last time step. this way', ', the model is able to capture long distance relations', 'between tokens. on the convolutional side,  #TAUTHOR_TAG generated the segment representation by combining the outputs of three parallel cnns with different context window sizes, in order to capture different functional patterns.', 'in both cases, pre - trained word - embeddings were used as input to the network.  #AUTHOR_TAG compared the performance', 'of embeddings with different dimensionality trained on multiple corpora using glove and word2vec  #AUTHOR_TAG. the best results were achieved when', 'using 150 - dimensional embeddings trained on wikipedia data using word2vec.  #TAUTHOR_TAG used 200 - dimensional word2vec embeddings trained on facebook data. overall, from the reported results, it is not possible to state which is the top performing segment representation approach since the evaluation was performed on different subsets of the corpus.', '']",0
"['based on cnns  #TAUTHOR_TAG.', 'both have']","['based on cnns  #TAUTHOR_TAG.', 'both have']","['based on cnns  #TAUTHOR_TAG.', 'both have']","['stated in the previous section, the segment representation step is the one which introduces higher variability in the network.', 'consequently, it is where the main differences between previous dialog act recognition approaches occur.', 'thus, we start our study by exploring different approaches for this step.', 'as stated in section 3, of the two state - of - the - art approaches on dialog act recognition, one uses a rnn - based approach  #AUTHOR_TAG for segment representation, while the other uses one based on cnns  #TAUTHOR_TAG.', 'both have their own advantages, as while the first focuses on capturing information from relevant sequences of tokens, the latter focuses on the context surrounding each token and, thus, captures information concerning neighboring tokens.', 'concerning the task at hand, this is relevant since, among other aspects, while some dialog acts are distinguishable due to the order of the tokens in the segment ( e. g. subject - auxiliary inversion in questions ), others are distinguishable due to the presence of certain tokens or sequences of tokens independently of where they occur in the segment ( e. g. greetings ).', 'thus, and since the two approaches were not compared directly and were evaluated on different sets, we included both of them in our experiments.', '']",0
"['by  #TAUTHOR_TAG uses a set of parallel temporal cnns with different window size, each followed']","['by  #TAUTHOR_TAG uses a set of parallel temporal cnns with different window size, each followed']","['described in section 3, the convolutional approach by  #TAUTHOR_TAG uses a set of parallel temporal cnns with different window size, each followed']","['described in section 3, the convolutional approach by  #TAUTHOR_TAG uses a set of parallel temporal cnns with different window size, each followed by a max pooling operation.', 'the segment representation is given by the concatenation of the results of the pooling operations.', 'this way, the representation contains information concerning groups of tokens with different sizes.', 'to achieve the results presented in  #TAUTHOR_TAG used three cnns with 100 filters and 1, 2, and 3 as context window sizes.', 'in a previous study using the same architecture for different tasks,  #AUTHOR_TAG used 3, 4, and 5 as window sizes.', 'both setups performed similarly in our experiments.', 'however, their combination, that is, five parallel cnns with window sizes between 1 and 5, led to better results, which means that both small and large groups of tokens provide relevant information.', 'the process to generate a segment representation using this approach is shown in figure 4.', 'the cnn - based segment representation approach.', 'e i corresponds to the embedding representation of the i - th token']",0
"['by  #TAUTHOR_TAG uses a set of parallel temporal cnns with different window size, each followed']","['by  #TAUTHOR_TAG uses a set of parallel temporal cnns with different window size, each followed']","['described in section 3, the convolutional approach by  #TAUTHOR_TAG uses a set of parallel temporal cnns with different window size, each followed']","['described in section 3, the convolutional approach by  #TAUTHOR_TAG uses a set of parallel temporal cnns with different window size, each followed by a max pooling operation.', 'the segment representation is given by the concatenation of the results of the pooling operations.', 'this way, the representation contains information concerning groups of tokens with different sizes.', 'to achieve the results presented in  #TAUTHOR_TAG used three cnns with 100 filters and 1, 2, and 3 as context window sizes.', 'in a previous study using the same architecture for different tasks,  #AUTHOR_TAG used 3, 4, and 5 as window sizes.', 'both setups performed similarly in our experiments.', 'however, their combination, that is, five parallel cnns with window sizes between 1 and 5, led to better results, which means that both small and large groups of tokens provide relevant information.', 'the process to generate a segment representation using this approach is shown in figure 4.', 'the cnn - based segment representation approach.', 'e i corresponds to the embedding representation of the i - th token']",0
"['150 led to the best results.', ' #TAUTHOR_TAG.', 'in our experiments we explored the use of the four different dimensionality values']","['150 led to the best results.', ' #TAUTHOR_TAG.', 'in our experiments we explored the use of the four different dimensionality values']","['leads to ambiguity in the representation.', 'however, up to a certain level, ambiguity is not necessarily harmful.', 'as stated in section 3,  #AUTHOR_TAG explored embedding spaces with dimensionality 75, 150, and 300 together with different embedding approaches.', 'in every case, the embedding space with dimensionality 150 led to the best results.', ' #TAUTHOR_TAG.', 'in our experiments we explored the use of the four different dimensionality values']","['dimensionality of the embedding space is the factor that defines the trade - off between ambiguity and sparseness.', 'on the one hand, higher dimensionality leads to increased sparseness and memory requirements.', 'at the limit, one can have dimensionality equal to the number of words in the vocabulary and use a one - hot approach to represent words.', 'on the other hand, lower dimensionality leads to ambiguity in the representation.', 'however, up to a certain level, ambiguity is not necessarily harmful.', 'as stated in section 3,  #AUTHOR_TAG explored embedding spaces with dimensionality 75, 150, and 300 together with different embedding approaches.', 'in every case, the embedding space with dimensionality 150 led to the best results.', ' #TAUTHOR_TAG.', 'in our experiments we explored the use of the four different dimensionality values']",0
"['.', ' #TAUTHOR_TAG also used word2vec embeddings, but trained on facebook']","['best results using word2vec embeddings trained on wikipedia data.', ' #TAUTHOR_TAG also used word2vec embeddings, but trained on facebook data.', 'since we have access to the embeddings']","['best results using word2vec embeddings trained on wikipedia data.', ' #TAUTHOR_TAG also used word2vec embeddings, but trained on facebook data.', 'since we have access to the embeddings']","['previously stated, there has been extensive research on means to generate word - embedding representations.', 'the most common approaches are the continuous bag of words ( cbow ) model  #AUTHOR_TAG, commonly known as word2vec, and the glove  #AUTHOR_TAG.', ' #AUTHOR_TAG used pre - trained embeddings using both approaches in their study and achieved their best results using word2vec embeddings trained on wikipedia data.', ' #TAUTHOR_TAG also used word2vec embeddings, but trained on facebook data.', 'since we have access to the embeddings trained on wikipedia data, but not to those trained on facebook data, we used the first in our experiments.', 'the cbow model generates word representations based on the co - occurrence of adjacent words.', 'however, as previously stated, many dialog acts are related to the structure of the segment and not sequences of specific words.', 'thus, we also explored the dependency - based embedding approach by  #AUTHOR_TAG, which takes that structure into account and not only word co - occurrences.', 'it does so by introducing information concerning syntactic dependencies between words in the embedding generation process.', 'first, it generalizes the skip - gram model  #AUTHOR_TAG by allowing it to use arbitrary contexts instead of just those based on adjacent words.', '']",0
"[': accuracy results using pos tags.', 'for dialog act recognition is the dialog history, with influence decaying with distance  #TAUTHOR_TAG.', 'however, information concerning the speakers and, more specifically, turn - taking has also been proved important  #TAUTHOR_TAG.', 'thus, in our study, we explore both the surrounding segments and speaker information as sources of context information']","[': accuracy results using pos tags.', 'for dialog act recognition is the dialog history, with influence decaying with distance  #TAUTHOR_TAG.', 'however, information concerning the speakers and, more specifically, turn - taking has also been proved important  #TAUTHOR_TAG.', 'thus, in our study, we explore both the surrounding segments and speaker information as sources of context information']","[': accuracy results using pos tags.', 'for dialog act recognition is the dialog history, with influence decaying with distance  #TAUTHOR_TAG.', 'however, information concerning the speakers and, more specifically, turn - taking has also been proved important  #TAUTHOR_TAG.', 'thus, in our study, we explore both the surrounding segments and speaker information as sources of context information']","['a dialog act represents the intention behind a set of words, that intention is not constrained to a specific segment and its context provides relevant cues.', 'as described in section 3, previous studies have shown that the most important source of context information table 8 : accuracy results using pos tags.', 'for dialog act recognition is the dialog history, with influence decaying with distance  #TAUTHOR_TAG.', 'however, information concerning the speakers and, more specifically, turn - taking has also been proved important  #TAUTHOR_TAG.', 'thus, in our study, we explore both the surrounding segments and speaker information as sources of context information']",0
"[': accuracy results using pos tags.', 'for dialog act recognition is the dialog history, with influence decaying with distance  #TAUTHOR_TAG.', 'however, information concerning the speakers and, more specifically, turn - taking has also been proved important  #TAUTHOR_TAG.', 'thus, in our study, we explore both the surrounding segments and speaker information as sources of context information']","[': accuracy results using pos tags.', 'for dialog act recognition is the dialog history, with influence decaying with distance  #TAUTHOR_TAG.', 'however, information concerning the speakers and, more specifically, turn - taking has also been proved important  #TAUTHOR_TAG.', 'thus, in our study, we explore both the surrounding segments and speaker information as sources of context information']","[': accuracy results using pos tags.', 'for dialog act recognition is the dialog history, with influence decaying with distance  #TAUTHOR_TAG.', 'however, information concerning the speakers and, more specifically, turn - taking has also been proved important  #TAUTHOR_TAG.', 'thus, in our study, we explore both the surrounding segments and speaker information as sources of context information']","['a dialog act represents the intention behind a set of words, that intention is not constrained to a specific segment and its context provides relevant cues.', 'as described in section 3, previous studies have shown that the most important source of context information table 8 : accuracy results using pos tags.', 'for dialog act recognition is the dialog history, with influence decaying with distance  #TAUTHOR_TAG.', 'however, information concerning the speakers and, more specifically, turn - taking has also been proved important  #TAUTHOR_TAG.', 'thus, in our study, we explore both the surrounding segments and speaker information as sources of context information']",0
"['form of words.', ' #TAUTHOR_TAG further showed that using a single label per segment is']","['form of words.', ' #TAUTHOR_TAG further showed that using a single label per segment is']","['than in the form of words.', ' #TAUTHOR_TAG further showed that using a single label per segment is']","['dialog is a structured sequence of segments, in which each segment typically depends on both what has been said before and what is expected to be said in future.', 'thus, the surrounding segments are the most important sources of context information for dialog act recognition.', ""in the context of a dialog system identifying its conversational partner's intention, the system only has access to the preceding segments."", 'thus, we focus on approaches able to capture information from those segments.', 'still, in order to assess the importance of future information and simulate the annotation environment, we also performed some experiments using that information.', 'as stated in section 3, considering the preceding segments, we have shown in a previous study  #AUTHOR_TAG that providing information in the form of segment classifications leads to better results than in the form of words.', ' #TAUTHOR_TAG further showed that using a single label per segment is better than using the probability of each class.', 'furthermore, both studies showed that using automatic predictions leads to a decrease in performance around 2 percentage points in comparison to using the manual annotations.', 'thus, in order to simplify the experiments and obtain an upper bound for the approach, in this study we just use the manual annotations.', '']",0
"['.', ' #TAUTHOR_TAG also used word2vec embeddings, but trained on facebook']","['best results using word2vec embeddings trained on wikipedia data.', ' #TAUTHOR_TAG also used word2vec embeddings, but trained on facebook data.', 'since we have access to the embeddings']","['best results using word2vec embeddings trained on wikipedia data.', ' #TAUTHOR_TAG also used word2vec embeddings, but trained on facebook data.', 'since we have access to the embeddings']","['previously stated, there has been extensive research on means to generate word - embedding representations.', 'the most common approaches are the continuous bag of words ( cbow ) model  #AUTHOR_TAG, commonly known as word2vec, and the glove  #AUTHOR_TAG.', ' #AUTHOR_TAG used pre - trained embeddings using both approaches in their study and achieved their best results using word2vec embeddings trained on wikipedia data.', ' #TAUTHOR_TAG also used word2vec embeddings, but trained on facebook data.', 'since we have access to the embeddings trained on wikipedia data, but not to those trained on facebook data, we used the first in our experiments.', 'the cbow model generates word representations based on the co - occurrence of adjacent words.', 'however, as previously stated, many dialog acts are related to the structure of the segment and not sequences of specific words.', 'thus, we also explored the dependency - based embedding approach by  #AUTHOR_TAG, which takes that structure into account and not only word co - occurrences.', 'it does so by introducing information concerning syntactic dependencies between words in the embedding generation process.', 'first, it generalizes the skip - gram model  #AUTHOR_TAG by allowing it to use arbitrary contexts instead of just those based on adjacent words.', '']",1
"['form of words.', ' #TAUTHOR_TAG further showed that using a single label per segment is']","['form of words.', ' #TAUTHOR_TAG further showed that using a single label per segment is']","['than in the form of words.', ' #TAUTHOR_TAG further showed that using a single label per segment is']","['dialog is a structured sequence of segments, in which each segment typically depends on both what has been said before and what is expected to be said in future.', 'thus, the surrounding segments are the most important sources of context information for dialog act recognition.', ""in the context of a dialog system identifying its conversational partner's intention, the system only has access to the preceding segments."", 'thus, we focus on approaches able to capture information from those segments.', 'still, in order to assess the importance of future information and simulate the annotation environment, we also performed some experiments using that information.', 'as stated in section 3, considering the preceding segments, we have shown in a previous study  #AUTHOR_TAG that providing information in the form of segment classifications leads to better results than in the form of words.', ' #TAUTHOR_TAG further showed that using a single label per segment is better than using the probability of each class.', 'furthermore, both studies showed that using automatic predictions leads to a decrease in performance around 2 percentage points in comparison to using the manual annotations.', 'thus, in order to simplify the experiments and obtain an upper bound for the approach, in this study we just use the manual annotations.', '']",1
"['dialog act recognition.', 'in fact, this has been confirmed in the study by  #TAUTHOR_TAG.', 'thus, we also use turn - taking information in this study.', 'it is provided as a flag that states whether the speaker is different from that of the preceding segment']","['dialog act recognition.', 'in fact, this has been confirmed in the study by  #TAUTHOR_TAG.', 'thus, we also use turn - taking information in this study.', 'it is provided as a flag that states whether the speaker is different from that of the preceding segment']","['dialog act recognition.', 'in fact, this has been confirmed in the study by  #TAUTHOR_TAG.', 'thus, we also use turn - taking information in this study.', 'it is provided as a flag that states whether the speaker is different from that of the preceding segment']","['previously stated, information concerning the speakers is also relevant for dialog act recognition.', 'however, specific information about speaker characteristics may not be available.', 'still, information about the speaker of each segment, that is, who said what, is always available.', 'in this sense, intentions may vary if two sequential segments are uttered by the same or different speakers.', 'thus, turn - taking information is relevant for dialog act recognition.', 'in fact, this has been confirmed in the study by  #TAUTHOR_TAG.', 'thus, we also use turn - taking information in this study.', 'it is provided as a flag that states whether the speaker is different from that of the preceding segment']",1
"[' #TAUTHOR_TAG.', 'considering the architecture in']","[' #TAUTHOR_TAG.', 'considering the architecture in']","[' #TAUTHOR_TAG.', 'considering the architecture in figure 2, our']","['the previous section, we have discussed that different embedding approaches capture different kinds of information.', 'for instance, while the cbow model captures information concerning sets of words that occur together frequently, the dependency - based approach captures information concerning syntactic dependencies.', 'furthermore, if no pre - trained embeddings are used, the generated representation is task specific, while when pre - trained embeddings are used, the representation captures information from larger amounts of data and is more generic.', 'adaptable embeddings attempt to balance the trade - off between the two.', 'however, all those kinds of information may be complementary and relevant for the task.', 'thus, we assessed whether it is advantageous to combine multiple embedding representations.', 'to do so, we used the approach suggested by  #AUTHOR_TAG in the paper that inspired the cnn approach used by  #TAUTHOR_TAG.', 'considering the architecture in figure 2, our approach replicates all the steps up to segment representation, inclusively, for each embedding approach, and then concatenates the generated segment representations before passing them to the dimensionality reduction layer.', 'in our experiments, we combined both the fixed word2vec and dependency - based embeddings with their adaptable counterparts, as well as with each other and the version without pre - trained embeddings']",7
"['of  #TAUTHOR_TAG, direct result comparison with', '']","['case of  #TAUTHOR_TAG, direct result comparison with', '']","['in the case of  #TAUTHOR_TAG, direct result comparison with', '']",[' #TAUTHOR_TAG'],6
"['of  #TAUTHOR_TAG, direct result comparison with', '']","['case of  #TAUTHOR_TAG, direct result comparison with', '']","['in the case of  #TAUTHOR_TAG, direct result comparison with', '']",[' #TAUTHOR_TAG'],5
"['of  #TAUTHOR_TAG, direct result comparison with', '']","['case of  #TAUTHOR_TAG, direct result comparison with', '']","['in the case of  #TAUTHOR_TAG, direct result comparison with', '']",[' #TAUTHOR_TAG'],4
['2016 twi er stance detection corpus  #TAUTHOR_TAG. in'],['2016 twi er stance detection corpus  #TAUTHOR_TAG. in'],"['2016 twi er stance detection corpus  #TAUTHOR_TAG. in [ 3 ], a stance - community']","['two baseline approaches [ 5 ]. in [ 4 ], the author claims that wikipedia can be used to determine stances about controversial topics based on', 'their previous work regarding controversy extraction on the web. among more recent related work, in [ 1 ] stance detection for unseen targets is studied and bidirectional conditional encoding is employed. e authors state that their approach achieves stateof - the art performance rates', '[ 1 ] on semeval 2016 twi er stance detection corpus  #TAUTHOR_TAG. in [ 3 ], a stance - community detection approach called scifnet is proposed. scifnet creates networks of people who are stance targets, automatically from the related document collections', '[ 3 ] using stance expansion and re nement techniques to arrive at stance', '- coherent networks. a tweet data set annotated with stance information regarding', 'six prede ned targets is proposed in [ 11 ] where this data set is annotated through crowdsourcing. e authors indicate that the data set is also annotated with sentiment', ""information in addition to stance, so it can help sideways'17, july 2017, prague, czech republic"", ""d. kucuk reveal associations between stance and sentiment [ 11 ]. lastly, in  #TAUTHOR_TAG, semeval 2016's aforementioned shared task on twi er stance detection is described. also provided are the results of the evaluations of 19 systems participating in two subtasks ( one with training data set provided and the other"", 'without an annotated data set ) of the shared task [ 12 ]. in this paper, we present a', 'tweet data set in turkish annotated with stance information, where the corresponding annotations are made publicly available. e domain of the tweets comprises two popular football club', '##s which constitute the targets of the tweets included. we also provide the evaluation results of svm classi ers (', 'for each target ) on this data set using unigram, bigram, and hashtag features. to the best', 'of our knowledge, the current study is the rst one to target at stance detection in turkish tweets. together with the provided annotated data set and the corresponding evaluations with the aforementioned svm classi ers which can be used as baseline systems, our study will', 'hopefully help increase social media analysis studies on turkish content. e rest of the paper is organized as follows : in section 2, we describe our tweet data set annotated', 'with the target and stance information. section 3 includes the details of our svm - based stance classi ers and their evaluation results with discussions. section 4', '']",0
['2016 twi er stance detection corpus  #TAUTHOR_TAG. in'],['2016 twi er stance detection corpus  #TAUTHOR_TAG. in'],"['2016 twi er stance detection corpus  #TAUTHOR_TAG. in [ 3 ], a stance - community']","['two baseline approaches [ 5 ]. in [ 4 ], the author claims that wikipedia can be used to determine stances about controversial topics based on', 'their previous work regarding controversy extraction on the web. among more recent related work, in [ 1 ] stance detection for unseen targets is studied and bidirectional conditional encoding is employed. e authors state that their approach achieves stateof - the art performance rates', '[ 1 ] on semeval 2016 twi er stance detection corpus  #TAUTHOR_TAG. in [ 3 ], a stance - community detection approach called scifnet is proposed. scifnet creates networks of people who are stance targets, automatically from the related document collections', '[ 3 ] using stance expansion and re nement techniques to arrive at stance', '- coherent networks. a tweet data set annotated with stance information regarding', 'six prede ned targets is proposed in [ 11 ] where this data set is annotated through crowdsourcing. e authors indicate that the data set is also annotated with sentiment', ""information in addition to stance, so it can help sideways'17, july 2017, prague, czech republic"", ""d. kucuk reveal associations between stance and sentiment [ 11 ]. lastly, in  #TAUTHOR_TAG, semeval 2016's aforementioned shared task on twi er stance detection is described. also provided are the results of the evaluations of 19 systems participating in two subtasks ( one with training data set provided and the other"", 'without an annotated data set ) of the shared task [ 12 ]. in this paper, we present a', 'tweet data set in turkish annotated with stance information, where the corresponding annotations are made publicly available. e domain of the tweets comprises two popular football club', '##s which constitute the targets of the tweets included. we also provide the evaluation results of svm classi ers (', 'for each target ) on this data set using unigram, bigram, and hashtag features. to the best', 'of our knowledge, the current study is the rst one to target at stance detection in turkish tweets. together with the provided annotated data set and the corresponding evaluations with the aforementioned svm classi ers which can be used as baseline systems, our study will', 'hopefully help increase social media analysis studies on turkish content. e rest of the paper is organized as follows : in section 2, we describe our tweet data set annotated', 'with the target and stance information. section 3 includes the details of our svm - based stance classi ers and their evaluation results with discussions. section 4', '']",0
['2016 twi er stance detection corpus  #TAUTHOR_TAG. in'],['2016 twi er stance detection corpus  #TAUTHOR_TAG. in'],"['2016 twi er stance detection corpus  #TAUTHOR_TAG. in [ 3 ], a stance - community']","['two baseline approaches [ 5 ]. in [ 4 ], the author claims that wikipedia can be used to determine stances about controversial topics based on', 'their previous work regarding controversy extraction on the web. among more recent related work, in [ 1 ] stance detection for unseen targets is studied and bidirectional conditional encoding is employed. e authors state that their approach achieves stateof - the art performance rates', '[ 1 ] on semeval 2016 twi er stance detection corpus  #TAUTHOR_TAG. in [ 3 ], a stance - community detection approach called scifnet is proposed. scifnet creates networks of people who are stance targets, automatically from the related document collections', '[ 3 ] using stance expansion and re nement techniques to arrive at stance', '- coherent networks. a tweet data set annotated with stance information regarding', 'six prede ned targets is proposed in [ 11 ] where this data set is annotated through crowdsourcing. e authors indicate that the data set is also annotated with sentiment', ""information in addition to stance, so it can help sideways'17, july 2017, prague, czech republic"", ""d. kucuk reveal associations between stance and sentiment [ 11 ]. lastly, in  #TAUTHOR_TAG, semeval 2016's aforementioned shared task on twi er stance detection is described. also provided are the results of the evaluations of 19 systems participating in two subtasks ( one with training data set provided and the other"", 'without an annotated data set ) of the shared task [ 12 ]. in this paper, we present a', 'tweet data set in turkish annotated with stance information, where the corresponding annotations are made publicly available. e domain of the tweets comprises two popular football club', '##s which constitute the targets of the tweets included. we also provide the evaluation results of svm classi ers (', 'for each target ) on this data set using unigram, bigram, and hashtag features. to the best', 'of our knowledge, the current study is the rst one to target at stance detection in turkish tweets. together with the provided annotated data set and the corresponding evaluations with the aforementioned svm classi ers which can be used as baseline systems, our study will', 'hopefully help increase social media analysis studies on turkish content. e rest of the paper is organized as follows : in section 2, we describe our tweet data set annotated', 'with the target and stance information. section 3 includes the details of our svm - based stance classi ers and their evaluation results with discussions. section 4', '']",0
['2016 twi er stance detection corpus  #TAUTHOR_TAG. in'],['2016 twi er stance detection corpus  #TAUTHOR_TAG. in'],"['2016 twi er stance detection corpus  #TAUTHOR_TAG. in [ 3 ], a stance - community']","['two baseline approaches [ 5 ]. in [ 4 ], the author claims that wikipedia can be used to determine stances about controversial topics based on', 'their previous work regarding controversy extraction on the web. among more recent related work, in [ 1 ] stance detection for unseen targets is studied and bidirectional conditional encoding is employed. e authors state that their approach achieves stateof - the art performance rates', '[ 1 ] on semeval 2016 twi er stance detection corpus  #TAUTHOR_TAG. in [ 3 ], a stance - community detection approach called scifnet is proposed. scifnet creates networks of people who are stance targets, automatically from the related document collections', '[ 3 ] using stance expansion and re nement techniques to arrive at stance', '- coherent networks. a tweet data set annotated with stance information regarding', 'six prede ned targets is proposed in [ 11 ] where this data set is annotated through crowdsourcing. e authors indicate that the data set is also annotated with sentiment', ""information in addition to stance, so it can help sideways'17, july 2017, prague, czech republic"", ""d. kucuk reveal associations between stance and sentiment [ 11 ]. lastly, in  #TAUTHOR_TAG, semeval 2016's aforementioned shared task on twi er stance detection is described. also provided are the results of the evaluations of 19 systems participating in two subtasks ( one with training data set provided and the other"", 'without an annotated data set ) of the shared task [ 12 ]. in this paper, we present a', 'tweet data set in turkish annotated with stance information, where the corresponding annotations are made publicly available. e domain of the tweets comprises two popular football club', '##s which constitute the targets of the tweets included. we also provide the evaluation results of svm classi ers (', 'for each target ) on this data set using unigram, bigram, and hashtag features. to the best', 'of our knowledge, the current study is the rst one to target at stance detection in turkish tweets. together with the provided annotated data set and the corresponding evaluations with the aforementioned svm classi ers which can be used as baseline systems, our study will', 'hopefully help increase social media analysis studies on turkish content. e rest of the paper is organized as follows : in section 2, we describe our tweet data set annotated', 'with the target and stance information. section 3 includes the details of our svm - based stance classi ers and their evaluation results with discussions. section 4', '']",0
"['problem  #TAUTHOR_TAG. however,']","['problem  #TAUTHOR_TAG. however,']","['stance detection problem  #TAUTHOR_TAG. however,']","['', '##rams as features, as ngram - based classi ers have been reported to perform be er for the stance detection problem  #TAUTHOR_TAG. however, we have observed that using bigrams as the', 'sole features of the svm classi ers leads to quite poor results. is observation may be due to the relatively limited size of the tweet data set employed.', 'still, we can conclude that unigram - based features lead to superior results compared to the results obtained using bigrams as features, based on our experiments', '']",0
"['problem  #TAUTHOR_TAG. however,']","['problem  #TAUTHOR_TAG. however,']","['stance detection problem  #TAUTHOR_TAG. however,']","['', '##rams as features, as ngram - based classi ers have been reported to perform be er for the stance detection problem  #TAUTHOR_TAG. however, we have observed that using bigrams as the', 'sole features of the svm classi ers leads to quite poor results. is observation may be due to the relatively limited size of the tweet data set employed.', 'still, we can conclude that unigram - based features lead to superior results compared to the results obtained using bigrams as features, based on our experiments', '']",4
"['problem  #TAUTHOR_TAG. however,']","['problem  #TAUTHOR_TAG. however,']","['stance detection problem  #TAUTHOR_TAG. however,']","['', '##rams as features, as ngram - based classi ers have been reported to perform be er for the stance detection problem  #TAUTHOR_TAG. however, we have observed that using bigrams as the', 'sole features of the svm classi ers leads to quite poor results. is observation may be due to the relatively limited size of the tweet data set employed.', 'still, we can conclude that unigram - based features lead to superior results compared to the results obtained using bigrams as features, based on our experiments', '']",4
"['problem  #TAUTHOR_TAG. however,']","['problem  #TAUTHOR_TAG. however,']","['stance detection problem  #TAUTHOR_TAG. however,']","['', '##rams as features, as ngram - based classi ers have been reported to perform be er for the stance detection problem  #TAUTHOR_TAG. however, we have observed that using bigrams as the', 'sole features of the svm classi ers leads to quite poor results. is observation may be due to the relatively limited size of the tweet data set employed.', 'still, we can conclude that unigram - based features lead to superior results compared to the results obtained using bigrams as features, based on our experiments', '']",4
"['problem  #TAUTHOR_TAG. however,']","['problem  #TAUTHOR_TAG. however,']","['stance detection problem  #TAUTHOR_TAG. however,']","['', '##rams as features, as ngram - based classi ers have been reported to perform be er for the stance detection problem  #TAUTHOR_TAG. however, we have observed that using bigrams as the', 'sole features of the svm classi ers leads to quite poor results. is observation may be due to the relatively limited size of the tweet data set employed.', 'still, we can conclude that unigram - based features lead to superior results compared to the results obtained using bigrams as features, based on our experiments', '']",4
"['problem  #TAUTHOR_TAG. however,']","['problem  #TAUTHOR_TAG. however,']","['stance detection problem  #TAUTHOR_TAG. however,']","['', '##rams as features, as ngram - based classi ers have been reported to perform be er for the stance detection problem  #TAUTHOR_TAG. however, we have observed that using bigrams as the', 'sole features of the svm classi ers leads to quite poor results. is observation may be due to the relatively limited size of the tweet data set employed.', 'still, we can conclude that unigram - based features lead to superior results compared to the results obtained using bigrams as features, based on our experiments', '']",5
['as  #TAUTHOR_TAG'],['as  #TAUTHOR_TAG'],"['as  #TAUTHOR_TAG can be tested on our data set.', '•']","['', 'particularly, related methods presented in recent studies such as  #TAUTHOR_TAG can be tested on our data set.', '• lastly, the svm classi ers utilized in this study and their prospective versions utilizing other features can be tested on stance data sets in other languages ( such as english ) for comparison purposes']",5
['as  #TAUTHOR_TAG'],['as  #TAUTHOR_TAG'],"['as  #TAUTHOR_TAG can be tested on our data set.', '•']","['', 'particularly, related methods presented in recent studies such as  #TAUTHOR_TAG can be tested on our data set.', '• lastly, the svm classi ers utilized in this study and their prospective versions utilizing other features can be tested on stance data sets in other languages ( such as english ) for comparison purposes']",2
"['with other concepts )  #TAUTHOR_TAG 18, 19 ]']","['with other concepts )  #TAUTHOR_TAG 18, 19 ]']","['with other concepts )  #TAUTHOR_TAG 18, 19 ].', 'a first work  #TAUTHOR_TAG proposes a "" retrofitting "" technique consisting in']",[' #TAUTHOR_TAG'],0
"['with other concepts )  #TAUTHOR_TAG 18, 19 ]']","['with other concepts )  #TAUTHOR_TAG 18, 19 ]']","['with other concepts )  #TAUTHOR_TAG 18, 19 ].', 'a first work  #TAUTHOR_TAG proposes a "" retrofitting "" technique consisting in']",[' #TAUTHOR_TAG'],0
"['with other concepts )  #TAUTHOR_TAG 18, 19 ]']","['with other concepts )  #TAUTHOR_TAG 18, 19 ]']","['with other concepts )  #TAUTHOR_TAG 18, 19 ].', 'a first work  #TAUTHOR_TAG proposes a "" retrofitting "" technique consisting in']",[' #TAUTHOR_TAG'],0
['the kb distributed representation  #TAUTHOR_TAG 18 ] as input of the deep neural'],"['the kb distributed representation  #TAUTHOR_TAG 18 ] as input of the deep neural network,']",['the kb distributed representation  #TAUTHOR_TAG 18 ] as input of the deep neural'],"['first approach that we suggest for integrating kb within a deep neural network focuses on an enhanced representation of documents and queries as illustrated in figure 2a.', 'while a naive approach would be to exploit the concept embeddings learned from the kb distributed representation  #TAUTHOR_TAG 18 ] as input of the deep neural network, we believe that a hybrid representation of the distributional semantic ( namely, word embeddings ) and the symbolic semantics ( namely, concept embeddings taking into account the graph structure ) would allow enhancing the document - query matching.', 'indeed, simply considering concepts belonging to the kb may lead to a partial mismatch with the text of queries and / or documents [ 4 ].', 'with this in mind, the document and query representations could be enhanced with a symbolic semantic layer expressing the projection of the plain text on the kb with the consideration of concepts and their relationships within the kb.', 'on one hand, the representation of the plain text might be, as used in several previous work, a high - dimensional vector of terms [ 8, 17 ] or of their corresponding word embeddings [ 16 ].', 'on the other hand, the semantic layer could be built by the representation of concepts ( and their relationships ) extracted from the plain text through a concept embedding  #TAUTHOR_TAG or a richer embedding representation of a kb sub - graph, as suggested in [ 2 ].', 'the latter presents the advantage to model the compositionality of concepts within the document.', 'similarly to previous approaches [ 8, 16, 17 ], the enhanced representations of both document and query would be transformed into low - dimensional semantic feature vectors used within a similarity function']",0
['the kb distributed representation  #TAUTHOR_TAG 18 ] as input of the deep neural'],"['the kb distributed representation  #TAUTHOR_TAG 18 ] as input of the deep neural network,']",['the kb distributed representation  #TAUTHOR_TAG 18 ] as input of the deep neural'],"['first approach that we suggest for integrating kb within a deep neural network focuses on an enhanced representation of documents and queries as illustrated in figure 2a.', 'while a naive approach would be to exploit the concept embeddings learned from the kb distributed representation  #TAUTHOR_TAG 18 ] as input of the deep neural network, we believe that a hybrid representation of the distributional semantic ( namely, word embeddings ) and the symbolic semantics ( namely, concept embeddings taking into account the graph structure ) would allow enhancing the document - query matching.', 'indeed, simply considering concepts belonging to the kb may lead to a partial mismatch with the text of queries and / or documents [ 4 ].', 'with this in mind, the document and query representations could be enhanced with a symbolic semantic layer expressing the projection of the plain text on the kb with the consideration of concepts and their relationships within the kb.', 'on one hand, the representation of the plain text might be, as used in several previous work, a high - dimensional vector of terms [ 8, 17 ] or of their corresponding word embeddings [ 16 ].', 'on the other hand, the semantic layer could be built by the representation of concepts ( and their relationships ) extracted from the plain text through a concept embedding  #TAUTHOR_TAG or a richer embedding representation of a kb sub - graph, as suggested in [ 2 ].', 'the latter presents the advantage to model the compositionality of concepts within the document.', 'similarly to previous approaches [ 8, 16, 17 ], the enhanced representations of both document and query would be transformed into low - dimensional semantic feature vectors used within a similarity function']",4
"['encoding part as in  #TAUTHOR_TAG.', 'however,  #TAUTHOR_TAG leave the decoder randomly initialized']","['encoding part as in  #TAUTHOR_TAG.', 'however,  #TAUTHOR_TAG leave the decoder randomly initialized.', 'in this paper, we aim to pretrain both the encoder']","['part as in  #TAUTHOR_TAG.', 'however,  #TAUTHOR_TAG leave the decoder randomly initialized']","['', 'as mentioned earlier, we can take advantage of recent pre - trained transformer encoders for the document encoding part as in  #TAUTHOR_TAG.', 'however,  #TAUTHOR_TAG leave the decoder randomly initialized.', 'in this paper, we aim to pretrain both the encoder ( i. e., the encoding part ) and decoder ( i. e., the generation part ) of a seq2seq transformer, which is able to improve abstractive summarization performance.', 'based on the above observations, we propose step ( as shorthand for sequence - to - sequence transformer pre - training ), which can be pretrained on large scale unlabeled documents.', 'specifically, we design three tasks for seq2seq model pre - training, namely sentence reordering ( sr ), next sentence generation ( nsg ), and masked document generation ( mdg ).', '']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG, we use the non - anonymized version of cnn']","['', 'following previous work  #TAUTHOR_TAG, we use the non - anonymized version of cnndm.', '']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG, we use the non - anonymized version of cnn']","['', 'following previous work  #TAUTHOR_TAG, we use the non - anonymized version of cnndm.', '']",5
"['encoding part as in  #TAUTHOR_TAG.', 'however,  #TAUTHOR_TAG leave the decoder randomly initialized']","['encoding part as in  #TAUTHOR_TAG.', 'however,  #TAUTHOR_TAG leave the decoder randomly initialized.', 'in this paper, we aim to pretrain both the encoder']","['part as in  #TAUTHOR_TAG.', 'however,  #TAUTHOR_TAG leave the decoder randomly initialized']","['', 'as mentioned earlier, we can take advantage of recent pre - trained transformer encoders for the document encoding part as in  #TAUTHOR_TAG.', 'however,  #TAUTHOR_TAG leave the decoder randomly initialized.', 'in this paper, we aim to pretrain both the encoder ( i. e., the encoding part ) and decoder ( i. e., the generation part ) of a seq2seq transformer, which is able to improve abstractive summarization performance.', 'based on the above observations, we propose step ( as shorthand for sequence - to - sequence transformer pre - training ), which can be pretrained on large scale unlabeled documents.', 'specifically, we design three tasks for seq2seq model pre - training, namely sentence reordering ( sr ), next sentence generation ( nsg ), and masked document generation ( mdg ).', '']",3
['transformers  #TAUTHOR_TAG that'],['was replaced again with pretrained transformers  #TAUTHOR_TAG that'],['was replaced again with pretrained transformers  #TAUTHOR_TAG that'],"['', 'this task is usually viewed as a sentence ranking problem  #AUTHOR_TAG using scores from a binary ( sequence ) classification model, which predicts whether a sentence is in the summary or not.', 'extractive neural models employ hierarchical lstms / cnns as the feature learning part of the binary ( sequence ) classifier  #AUTHOR_TAG, which largely outperforms discrete feature based models  #AUTHOR_TAG.', 'very recently, the feature learning part was replaced again with pretrained transformers  #TAUTHOR_TAG that lead to another huge improvement of summarization performance.', 'however, extractive models have their own limitations.', '']",0
"['pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9']","['step model ( i. e., pre - training on the giga', '- cm dataset using sr task ) with human references ( denoted as gold ), roberta - s2s, and two pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9']","['pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9. participants were asked to rank the outputs of these systems from best to worst. we report the proportions of system rankings and mean']","['', '- cm dataset using sr task ) with human references ( denoted as gold ), roberta - s2s, and two pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9. participants were asked to rank the outputs of these systems from best to worst. we report the proportions of system rankings and mean rank ( lower is better ) in table 3. the output of step is selected as the best for', ""the 25 % of cases and we obtained lower mean rank than all systems except for gold, which shows the participants'preference for our model."", 'then we converted ranking numbers into ratings ( i. e., rank i is converted into 6 − i ) and applied the student t - test', 'on the ratings. step is significantly better than all other systems in comparison with p < 0. 05. but it still lags behind human. one possible reason is that step ( as well as other systems ) only takes the first', '512 tokens of a long document as input and', 'thus may lose information residing in the following tokens']",0
"['pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9']","['step model ( i. e., pre - training on the giga', '- cm dataset using sr task ) with human references ( denoted as gold ), roberta - s2s, and two pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9']","['pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9. participants were asked to rank the outputs of these systems from best to worst. we report the proportions of system rankings and mean']","['', '- cm dataset using sr task ) with human references ( denoted as gold ), roberta - s2s, and two pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9. participants were asked to rank the outputs of these systems from best to worst. we report the proportions of system rankings and mean rank ( lower is better ) in table 3. the output of step is selected as the best for', ""the 25 % of cases and we obtained lower mean rank than all systems except for gold, which shows the participants'preference for our model."", 'then we converted ranking numbers into ratings ( i. e., rank i is converted into 6 − i ) and applied the student t - test', 'on the ratings. step is significantly better than all other systems in comparison with p < 0. 05. but it still lags behind human. one possible reason is that step ( as well as other systems ) only takes the first', '512 tokens of a long document as input and', 'thus may lose information residing in the following tokens']",0
"['pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9']","['step model ( i. e., pre - training on the giga', '- cm dataset using sr task ) with human references ( denoted as gold ), roberta - s2s, and two pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9']","['pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9. participants were asked to rank the outputs of these systems from best to worst. we report the proportions of system rankings and mean']","['', '- cm dataset using sr task ) with human references ( denoted as gold ), roberta - s2s, and two pre - training based', 'models, bertabs  #TAUTHOR_TAG and unilm  #AUTHOR_TAG 9. participants were asked to rank the outputs of these systems from best to worst. we report the proportions of system rankings and mean rank ( lower is better ) in table 3. the output of step is selected as the best for', ""the 25 % of cases and we obtained lower mean rank than all systems except for gold, which shows the participants'preference for our model."", 'then we converted ranking numbers into ratings ( i. e., rank i is converted into 6 − i ) and applied the student t - test', 'on the ratings. step is significantly better than all other systems in comparison with p < 0. 05. but it still lags behind human. one possible reason is that step ( as well as other systems ) only takes the first', '512 tokens of a long document as input and', 'thus may lose information residing in the following tokens']",7
"[""in using penn treebank function labels in training. the two existing systems that use function labels sucessfully, either inherit collins'modelling of the notion of complement  #AUTHOR_TAG or model function labels directly  #TAUTHOR_TAG. furthermore, our results indicate that""]","[""in using penn treebank function labels in training. the two existing systems that use function labels sucessfully, either inherit collins'modelling of the notion of complement  #AUTHOR_TAG or model function labels directly  #TAUTHOR_TAG. furthermore, our results indicate that""]","[""in using penn treebank function labels in training. the two existing systems that use function labels sucessfully, either inherit collins'modelling of the notion of complement  #AUTHOR_TAG or model function labels directly  #TAUTHOR_TAG. furthermore, our results indicate that the proposed models are robust. to model our task accurately"", ', additional parameters must be estimated. however, given the current limited availability of annotated treebanks, this more complex']","['', 'nominal temporal modifiers occupy an object position without being objects, like tuesday in the penn treebank representation', 'of the sentence above. the indirectness of the relation is also confirmed by the difficulty in exploiting semantic information for parsing. previous attempts have not been successful.  #AUTHOR_TAG report a reduction in parsing accuracy of an unlexicalised pcfg from', ""77. 8 % to 72. 9 % in using penn treebank function labels in training. the two existing systems that use function labels sucessfully, either inherit collins'modelling of the notion of complement  #AUTHOR_TAG or model function labels directly  #TAUTHOR_TAG. furthermore, our results indicate that the proposed models are robust. to model our task accurately"", "", additional parameters must be estimated. however, given the current limited availability of annotated treebanks, this more complex task will have to be solved with the same overall amount of data, aggravating the difficulty of estimating the model's"", 'parameters due to sparse data']",5
"['across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing']","['across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing']","['across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing. given the hidden history representation h ( d 1, · · ·,']","['next move i, virtually any information about the derivation history could flow from history representation to history representation and be used to estimate the probability', 'of a derivation move. in our experiments, the set d of earlier history representations is modified to yield a model that is', 'sensitive to regularities in structurally defined sequences of nodes bearing semantic role labels, within and across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing. given the hidden history representation h ( d 1, · · ·, d i−1 ) of a derivation, a normalized exponential output function is computed by the ssns to estimate a probability distribution over the possible next derivation moves d i. to exploit the intuition that semantic role labels are', 'predictive of syntactic structure, we must pro - vide semantic role information as early', 'as possible to the parser. extending a technique presented in  #AUTHOR_TAG and adopted in  #TAUTHOR_TAG for function labels with stateof - the - art results, we split some part - of - speech tags into tags marked with am - x semantic role labels. as', 'a result, 240 new pos tags were introduced to partition the original tag set which consisted of 45 tags. our augmented model has a total of 613 nonterminals to represent both the ptb and propbank labels, instead of the 33 of the original ssn parser. the 580 newly introduced labels consist of a', 'standard ptb label followed by one or more propbank semantic roles, such as pp - am - tmp or np - a0 -', 'a1. these augmented tags and the new non - terminals are included in the set f, and will', 'influence bottomup projection of structure directly. these newly introduced fine - grained labels fragment our propbank data. to alleviate this problem, we enlarge the set f with two additional binary features. one feature decides whether a given preterminal or non', '##terminal label is a semantic role label belonging to the set comprising the labels a0 - a5 and aa. the other feature indicates if a given label is a semantic role label of type am - x, or otherwise. these features allow the ssn to generalise in several', 'ways. all the constituents bearing an a0 - a5 and aa labels will have a common feature. the same will be true for all nodes bearing an am - x label. thus, the', 'ssn can generalise across these two types of labels. finally, all constituents that do not bear any label', 'will now constitute a class, the class of the nodes for which these two features are false']",5
"[""in using penn treebank function labels in training. the two existing systems that use function labels sucessfully, either inherit collins'modelling of the notion of complement  #AUTHOR_TAG or model function labels directly  #TAUTHOR_TAG. furthermore, our results indicate that""]","[""in using penn treebank function labels in training. the two existing systems that use function labels sucessfully, either inherit collins'modelling of the notion of complement  #AUTHOR_TAG or model function labels directly  #TAUTHOR_TAG. furthermore, our results indicate that""]","[""in using penn treebank function labels in training. the two existing systems that use function labels sucessfully, either inherit collins'modelling of the notion of complement  #AUTHOR_TAG or model function labels directly  #TAUTHOR_TAG. furthermore, our results indicate that the proposed models are robust. to model our task accurately"", ', additional parameters must be estimated. however, given the current limited availability of annotated treebanks, this more complex']","['', 'nominal temporal modifiers occupy an object position without being objects, like tuesday in the penn treebank representation', 'of the sentence above. the indirectness of the relation is also confirmed by the difficulty in exploiting semantic information for parsing. previous attempts have not been successful.  #AUTHOR_TAG report a reduction in parsing accuracy of an unlexicalised pcfg from', ""77. 8 % to 72. 9 % in using penn treebank function labels in training. the two existing systems that use function labels sucessfully, either inherit collins'modelling of the notion of complement  #AUTHOR_TAG or model function labels directly  #TAUTHOR_TAG. furthermore, our results indicate that the proposed models are robust. to model our task accurately"", "", additional parameters must be estimated. however, given the current limited availability of annotated treebanks, this more complex task will have to be solved with the same overall amount of data, aggravating the difficulty of estimating the model's"", 'parameters due to sparse data']",3
"['across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing']","['across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing']","['across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing. given the hidden history representation h ( d 1, · · ·,']","['next move i, virtually any information about the derivation history could flow from history representation to history representation and be used to estimate the probability', 'of a derivation move. in our experiments, the set d of earlier history representations is modified to yield a model that is', 'sensitive to regularities in structurally defined sequences of nodes bearing semantic role labels, within and across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing. given the hidden history representation h ( d 1, · · ·, d i−1 ) of a derivation, a normalized exponential output function is computed by the ssns to estimate a probability distribution over the possible next derivation moves d i. to exploit the intuition that semantic role labels are', 'predictive of syntactic structure, we must pro - vide semantic role information as early', 'as possible to the parser. extending a technique presented in  #AUTHOR_TAG and adopted in  #TAUTHOR_TAG for function labels with stateof - the - art results, we split some part - of - speech tags into tags marked with am - x semantic role labels. as', 'a result, 240 new pos tags were introduced to partition the original tag set which consisted of 45 tags. our augmented model has a total of 613 nonterminals to represent both the ptb and propbank labels, instead of the 33 of the original ssn parser. the 580 newly introduced labels consist of a', 'standard ptb label followed by one or more propbank semantic roles, such as pp - am - tmp or np - a0 -', 'a1. these augmented tags and the new non - terminals are included in the set f, and will', 'influence bottomup projection of structure directly. these newly introduced fine - grained labels fragment our propbank data. to alleviate this problem, we enlarge the set f with two additional binary features. one feature decides whether a given preterminal or non', '##terminal label is a semantic role label belonging to the set comprising the labels a0 - a5 and aa. the other feature indicates if a given label is a semantic role label of type am - x, or otherwise. these features allow the ssn to generalise in several', 'ways. all the constituents bearing an a0 - a5 and aa labels will have a common feature. the same will be true for all nodes bearing an am - x label. thus, the', 'ssn can generalise across these two types of labels. finally, all constituents that do not bear any label', 'will now constitute a class, the class of the nodes for which these two features are false']",0
"['across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing']","['across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing']","['across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing. given the hidden history representation h ( d 1, · · ·,']","['next move i, virtually any information about the derivation history could flow from history representation to history representation and be used to estimate the probability', 'of a derivation move. in our experiments, the set d of earlier history representations is modified to yield a model that is', 'sensitive to regularities in structurally defined sequences of nodes bearing semantic role labels, within and across constituents. for more information on this technique to capture structural domains, see  #TAUTHOR_TAG where the technique was applied to function parsing. given the hidden history representation h ( d 1, · · ·, d i−1 ) of a derivation, a normalized exponential output function is computed by the ssns to estimate a probability distribution over the possible next derivation moves d i. to exploit the intuition that semantic role labels are', 'predictive of syntactic structure, we must pro - vide semantic role information as early', 'as possible to the parser. extending a technique presented in  #AUTHOR_TAG and adopted in  #TAUTHOR_TAG for function labels with stateof - the - art results, we split some part - of - speech tags into tags marked with am - x semantic role labels. as', 'a result, 240 new pos tags were introduced to partition the original tag set which consisted of 45 tags. our augmented model has a total of 613 nonterminals to represent both the ptb and propbank labels, instead of the 33 of the original ssn parser. the 580 newly introduced labels consist of a', 'standard ptb label followed by one or more propbank semantic roles, such as pp - am - tmp or np - a0 -', 'a1. these augmented tags and the new non - terminals are included in the set f, and will', 'influence bottomup projection of structure directly. these newly introduced fine - grained labels fragment our propbank data. to alleviate this problem, we enlarge the set f with two additional binary features. one feature decides whether a given preterminal or non', '##terminal label is a semantic role label belonging to the set comprising the labels a0 - a5 and aa. the other feature indicates if a given label is a semantic role label of type am - x, or otherwise. these features allow the ssn to generalise in several', 'ways. all the constituents bearing an a0 - a5 and aa labels will have a common feature. the same will be true for all nodes bearing an am - x label. thus, the', 'ssn can generalise across these two types of labels. finally, all constituents that do not bear any label', 'will now constitute a class, the class of the nodes for which these two features are false']",6
"['targeting  #TAUTHOR_TAG.', 'however, search queries differ']","['targeting  #TAUTHOR_TAG.', 'however, search queries differ']","['better ad targeting  #TAUTHOR_TAG.', 'however, search queries differ substantially from traditional forms of written language (']","['analysis of search queries is important for a variety of tasks including better query refinement, improved matching and better ad targeting  #TAUTHOR_TAG.', 'however, search queries differ substantially from traditional forms of written language ( e. g., no capitalization, few function words, fairly free word order, etc. ), and are therefore difficult to process with natural language processing tools trained on standard corpora  #TAUTHOR_TAG.', 'in this paper we focus on part - of - speech ( pos ) tagging queries entered into commercial search engines and compare different strategies for learning from search logs.', '']",0
['in  #TAUTHOR_TAG'],['in  #TAUTHOR_TAG'],['analysis in  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
"['targeting  #TAUTHOR_TAG.', 'however, search queries differ']","['targeting  #TAUTHOR_TAG.', 'however, search queries differ']","['better ad targeting  #TAUTHOR_TAG.', 'however, search queries differ substantially from traditional forms of written language (']","['analysis of search queries is important for a variety of tasks including better query refinement, improved matching and better ad targeting  #TAUTHOR_TAG.', 'however, search queries differ substantially from traditional forms of written language ( e. g., no capitalization, few function words, fairly free word order, etc. ), and are therefore difficult to process with natural language processing tools trained on standard corpora  #TAUTHOR_TAG.', 'in this paper we focus on part - of - speech ( pos ) tagging queries entered into commercial search engines and compare different strategies for learning from search logs.', '']",1
"['', 'as a reference,  #TAUTHOR_TAG report 79. 3']","['', 'as a reference,  #TAUTHOR_TAG report 79. 3 %']","['', 'as a reference,  #TAUTHOR_TAG report 79. 3 %']","['use two data sets for evaluation.', 'the first is the set of 251 queries from microsoft search logs ( ms - 251 ) used in  #AUTHOR_TAG bendersky et al. (, 2011.', 'the queries are annotated with three pos tags representing nouns, verbs and "" other "" tags ( ms - 251 nvx ).', 'we additionally refine the annotation to cover 14 pos tags comprising the 12 universal tags of  #AUTHOR_TAG, as well as proper nouns and a special tag for search operator symbols such as "" - "" ( for excluding the subsequent word ).', 'we refer to this evaluation set as ms - 251 in our experiments.', 'we had two annotators annotate the whole of the ms - 251 data set.', 'before arbitration, the inter - annotator agreement was 90. 2 %.', 'as a reference,  #TAUTHOR_TAG report 79. 3 % when annotating queries with 19 pos tags.', 'we then examined all the instances where the annotators disagreed, and corrected the discrepancy.', 'our annotations are available at http : / / code. google. com / p / query - syntax /.', 'the second evaluation set consists of 500 so called "" long - tail "" queries.', 'these are queries that occurred rarely in the search logs, and are typically difficult to tag because they are searching for lessfrequent information.', 'they do not contain navigational queries']",5
"['', 'as a reference,  #TAUTHOR_TAG report 79. 3']","['', 'as a reference,  #TAUTHOR_TAG report 79. 3 %']","['', 'as a reference,  #TAUTHOR_TAG report 79. 3 %']","['use two data sets for evaluation.', 'the first is the set of 251 queries from microsoft search logs ( ms - 251 ) used in  #AUTHOR_TAG bendersky et al. (, 2011.', 'the queries are annotated with three pos tags representing nouns, verbs and "" other "" tags ( ms - 251 nvx ).', 'we additionally refine the annotation to cover 14 pos tags comprising the 12 universal tags of  #AUTHOR_TAG, as well as proper nouns and a special tag for search operator symbols such as "" - "" ( for excluding the subsequent word ).', 'we refer to this evaluation set as ms - 251 in our experiments.', 'we had two annotators annotate the whole of the ms - 251 data set.', 'before arbitration, the inter - annotator agreement was 90. 2 %.', 'as a reference,  #TAUTHOR_TAG report 79. 3 % when annotating queries with 19 pos tags.', 'we then examined all the instances where the annotators disagreed, and corrected the discrepancy.', 'our annotations are available at http : / / code. google. com / p / query - syntax /.', 'the second evaluation set consists of 500 so called "" long - tail "" queries.', 'these are queries that occurred rarely in the search logs, and are typically difficult to tag because they are searching for lessfrequent information.', 'they do not contain navigational queries']",4
['in  #TAUTHOR_TAG'],['in  #TAUTHOR_TAG'],['analysis in  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],3
"['3,  #TAUTHOR_TAG 14, 17, 19 ].', 'some exarnpies']","['cue pttr. ases, clue words, discourse mai : tkers ~ arid discourse particles [ 3,  #TAUTHOR_TAG 14, 17, 19 ].', 'some exarnpies']","['cue pttr. ases, clue words, discourse mai : tkers ~ arid discourse particles [ 3,  #TAUTHOR_TAG 14, 17, 19 ].', 'some exarnpies']","['and phrases that may directly mark the structure of a discourse have been termed cue pttr. ases, clue words, discourse mai : tkers ~ arid discourse particles [ 3,  #TAUTHOR_TAG 14, 17, 19 ].', '']",0
"['5,  #TAUTHOR_TAG 17 ] and in']","['of anaphora [ 5,  #TAUTHOR_TAG 17 ] and in']","['of anaphora [ 5,  #TAUTHOR_TAG 17 ] and in']","['important role that cue phrases play in understanding and generating discourse has been well documented in the computational linguistics literature.', 'for example, by indicating the presence of a structural boundary or a relationship between parts of a discourse, cue phrases caa assist in the resolution of anaphora [ 5,  #TAUTHOR_TAG 17 ] and in the identification of rhetorical relations [ 10, 12, 17 ].', 'cue phrases have also been used to reduce the complexity of discourse processing and to increase textual coherence [ 3, 11, 21 ].', '']",0
"['5,  #TAUTHOR_TAG 17 ] and in']","['of anaphora [ 5,  #TAUTHOR_TAG 17 ] and in']","['of anaphora [ 5,  #TAUTHOR_TAG 17 ] and in']","['important role that cue phrases play in understanding and generating discourse has been well documented in the computational linguistics literature.', 'for example, by indicating the presence of a structural boundary or a relationship between parts of a discourse, cue phrases caa assist in the resolution of anaphora [ 5,  #TAUTHOR_TAG 17 ] and in the identification of rhetorical relations [ 10, 12, 17 ].', 'cue phrases have also been used to reduce the complexity of discourse processing and to increase textual coherence [ 3, 11, 21 ].', '']",0
"['5,  #TAUTHOR_TAG 17 ] and in']","['of anaphora [ 5,  #TAUTHOR_TAG 17 ] and in']","['of anaphora [ 5,  #TAUTHOR_TAG 17 ] and in']","['important role that cue phrases play in understanding and generating discourse has been well documented in the computational linguistics literature.', 'for example, by indicating the presence of a structural boundary or a relationship between parts of a discourse, cue phrases caa assist in the resolution of anaphora [ 5,  #TAUTHOR_TAG 17 ] and in the identification of rhetorical relations [ 10, 12, 17 ].', 'cue phrases have also been used to reduce the complexity of discourse processing and to increase textual coherence [ 3, 11, 21 ].', '']",0
"["",'speaking off and so on."", '8our set of cue phrases was derived from extensional definitions provided by ourselves and othel ~ [ 3,  #TAUTHOR_TAG 17, 18, 21 ].', 'tim following lexicel items, although also cue phrases,']","[""discourse a ~ nl ( l aententiel uses of multl - word cue phrases, e. g'that reminds me ','first o ] all ','speaking off and so on."", '8our set of cue phrases was derived from extensional definitions provided by ourselves and othel ~ [ 3,  #TAUTHOR_TAG 17, 18, 21 ].', 'tim following lexicel items, although also cue phrases,']","["",'speaking off and so on."", '8our set of cue phrases was derived from extensional definitions provided by ourselves and othel ~ [ 3,  #TAUTHOR_TAG 17, 18, 21 ].', 'tim following lexicel items, although also cue phrases, are not present in the portion of the ax']","[""test whether our prosodic model of discourse and sentential uses of'now'and'well'extended to cue phrases in general, we examined intonational chm'- acteristics of all single - word cue phrases 7 used in a keynote, address given by i ~ onald brachman at the first lnlernalional conference on expert database syslems in 1986."", 'the address provides approximately 75 minutes of speech t¥om a single speaker.', 'for our first sample, we examined the 211 cue phrases uttered during the first 17 minutes of the address.', ""our tokens had the following distribution : s actually ( 6 ), also ( 2 ), although ( 1 ), and ( 68 ), basically ( 1 ), because ( 2 ), but ( 12 ), finally ( 1 ), ] i,'sl ( 1 ), further ( 4 ), however ( 2 ), like ( 11 ), look ( 11 ), next ( 4 ), now ( 26 ), ok ( 1 ), or ( 19 ), say ( 12 ), second ( 1 ), see ( 5 ), since ( 1 ), so ( 9 ), then ( 3 ), therefore ( 1 ), well ( 7 )."", 'to determine the classification of each token ( ms - course, sentential, or ambiguous ), the authors separately. judged each token by listening to the taped address while marking a transcription.', '9 rwe exmnined o ~ fly single - word cue plu, asea in tiffs study since our current prosodic model applies only to such items.', ""in future work we plan to develop additional models for discourse a ~ nl ( l aententiel uses of multl - word cue phrases, e. g'that reminds me ','first o ] all ','speaking off and so on."", '8our set of cue phrases was derived from extensional definitions provided by ourselves and othel ~ [ 3,  #TAUTHOR_TAG 17, 18, 21 ].', 'tim following lexicel items, although also cue phrases, are not present in the portion of the axlch - ess examined to date : 9the address was transcribed independently of our study by a meraber of the text processing pool at at & t bell laboratories.', ""we found that 20 cite phrases had been omitted by the traalscriber :'and ','now ','ok ','so ', and'well '."", ""significantly, ell but two of these were termed '""]",4
"["",'speaking off and so on."", '8our set of cue phrases was derived from extensional definitions provided by ourselves and othel ~ [ 3,  #TAUTHOR_TAG 17, 18, 21 ].', 'tim following lexicel items, although also cue phrases,']","[""discourse a ~ nl ( l aententiel uses of multl - word cue phrases, e. g'that reminds me ','first o ] all ','speaking off and so on."", '8our set of cue phrases was derived from extensional definitions provided by ourselves and othel ~ [ 3,  #TAUTHOR_TAG 17, 18, 21 ].', 'tim following lexicel items, although also cue phrases,']","["",'speaking off and so on."", '8our set of cue phrases was derived from extensional definitions provided by ourselves and othel ~ [ 3,  #TAUTHOR_TAG 17, 18, 21 ].', 'tim following lexicel items, although also cue phrases, are not present in the portion of the ax']","[""test whether our prosodic model of discourse and sentential uses of'now'and'well'extended to cue phrases in general, we examined intonational chm'- acteristics of all single - word cue phrases 7 used in a keynote, address given by i ~ onald brachman at the first lnlernalional conference on expert database syslems in 1986."", 'the address provides approximately 75 minutes of speech t¥om a single speaker.', 'for our first sample, we examined the 211 cue phrases uttered during the first 17 minutes of the address.', ""our tokens had the following distribution : s actually ( 6 ), also ( 2 ), although ( 1 ), and ( 68 ), basically ( 1 ), because ( 2 ), but ( 12 ), finally ( 1 ), ] i,'sl ( 1 ), further ( 4 ), however ( 2 ), like ( 11 ), look ( 11 ), next ( 4 ), now ( 26 ), ok ( 1 ), or ( 19 ), say ( 12 ), second ( 1 ), see ( 5 ), since ( 1 ), so ( 9 ), then ( 3 ), therefore ( 1 ), well ( 7 )."", 'to determine the classification of each token ( ms - course, sentential, or ambiguous ), the authors separately. judged each token by listening to the taped address while marking a transcription.', '9 rwe exmnined o ~ fly single - word cue plu, asea in tiffs study since our current prosodic model applies only to such items.', ""in future work we plan to develop additional models for discourse a ~ nl ( l aententiel uses of multl - word cue phrases, e. g'that reminds me ','first o ] all ','speaking off and so on."", '8our set of cue phrases was derived from extensional definitions provided by ourselves and othel ~ [ 3,  #TAUTHOR_TAG 17, 18, 21 ].', 'tim following lexicel items, although also cue phrases, are not present in the portion of the axlch - ess examined to date : 9the address was transcribed independently of our study by a meraber of the text processing pool at at & t bell laboratories.', ""we found that 20 cite phrases had been omitted by the traalscriber :'and ','now ','ok ','so ', and'well '."", ""significantly, ell but two of these were termed '""]",6
"['as elmo  #AUTHOR_TAG, ulmfit  #AUTHOR_TAG and  #TAUTHOR_TAG.', ' #TAUTHOR_TAG train a deep - learning language model on large']","['as elmo  #AUTHOR_TAG, ulmfit  #AUTHOR_TAG and  #TAUTHOR_TAG.', ' #TAUTHOR_TAG train a deep - learning language model on large']","['as elmo  #AUTHOR_TAG, ulmfit  #AUTHOR_TAG and  #TAUTHOR_TAG.', ' #TAUTHOR_TAG train a deep - learning language model on large volumes of unlabeled text, which is subsequently fine -']","['the past year, the field of natural language processing ( nlp ) has seen the rise of pretrained language models such as as elmo  #AUTHOR_TAG, ulmfit  #AUTHOR_TAG and  #TAUTHOR_TAG.', ' #TAUTHOR_TAG train a deep - learning language model on large volumes of unlabeled text, which is subsequently fine - tuned for particular nlp tasks.', 'applying  #TAUTHOR_TAG.', 'the benefit of  #TAUTHOR_TAG has also been demonstrated in specialized nlp domains.', 'biobert  #AUTHOR_TAG, a version of bert trained exclusively on biomedical text, was able to significantly increase performance on biomedical named entity recognition.', 'further refining this model on clinical text produced an increase in performance in medical natural language inference ( alsentzer et al. 2019 ).', 'while large pretrained models offer significantly increased performance, they come with their own constraints, as the number of parameters in the  #TAUTHOR_TAG exceeds 100 million.', 'as such,  #TAUTHOR_TAG.', ""more recent work has addressed this challenge by'distilling'the models, training smaller versions of  #TAUTHOR_TAG which reduce the number of parameters to train by 40 % while retaining more than 95 % of the full model performance and even outperforming it on two out of eleven glue tasks."", 'this paper shows that using pretrained models in learning analytics holds great potential for advancing the field.', 'we apply the  #TAUTHOR_TAG approach to the following three previously explored lak tasks on mooc forum data  #AUTHOR_TAG : confusion detection, urgency of teacher intervention and sentimentality classification.', 'in all three of these tasks, we are able to improve performance past the state of the art']",6
"['to 7 ( high ).', 'language models : we constructed two models, edubert and edudistilbert, which respectively refine  #TAUTHOR_TAG.', 'both models are initialized from']","['to 7 ( high ).', 'language models : we constructed two models, edubert and edudistilbert, which respectively refine  #TAUTHOR_TAG.', 'both models are initialized from']","['to 7 ( high ).', 'language models : we constructed two models, edubert and edudistilbert, which respectively refine  #TAUTHOR_TAG.', 'both models are initialized from']","['trained the language model on a large unannotated data set from two sources : student forum data from the stanford moocposts dataset  #AUTHOR_TAG which includes about 30, 000 forum posts from 11 courses among three subject domains ; and forum data from multiple instances of 18 courses from large public universities in the uk and usa.', 'in total, this dataset is comprised of more than 12 million tokens.', 'the data used for the classification tasks was from the same stanford moocposts dataset.', 'the posts are annotated by domain experts and given scores for sentiment ( the degree of emotionality exhibited by the post ), confusion expressed by the student and urgency for the post to receive a response from an instructor.', 'scores are given on a likert scale from 1 ( low ) to 7 ( high ).', 'language models : we constructed two models, edubert and edudistilbert, which respectively refine  #TAUTHOR_TAG.', 'both models are initialized from their base model and finetuned on educational data, using the transformers library.', 'the fine - tuning step allows the model to better capture how words are used in an educational context.', 'training of the models was performed on a titan x gpu.', 'we set the maximum input sequence length to the default value ( 512 ) ; the learning rate was set to 5e - 5 ; the batch size ( the number of input sequences processed at one time ) was set to 8 for edubert and 16 for edudistilbert.', 'the best performance was achieved after 5 training epochs']",6
"['classifiers  #TAUTHOR_TAG, distil']","['classifiers  #TAUTHOR_TAG, distilbert, edubert and edudistilbert.', 'we evaluated multiple sets of parameters.', 'best results for these']","['by  #AUTHOR_TAG, we split the data into a 2 / 3 training set and 1 / 3 test set and consider a post to express sentiment, urgency or confusion if and only if its respective score is ≥ 4.', 'we compare between the four classifiers  #TAUTHOR_TAG, distil']","['encourage easily comparable results, we evaluated the models on three wellexplored classification tasks on the standfordmooc dataset.', 'following previous work by  #AUTHOR_TAG, we split the data into a 2 / 3 training set and 1 / 3 test set and consider a post to express sentiment, urgency or confusion if and only if its respective score is ≥ 4.', 'we compare between the four classifiers  #TAUTHOR_TAG, distilbert, edubert and edudistilbert.', 'we evaluated multiple sets of parameters.', 'best results for these tasks were achieved with the following parameters : two learning epochs, maximal sequence length of 300  #TAUTHOR_TAG, edubert ) and 512 for the distilled models, all other parameter values were equal to the ones used for pre - training.', 'table 1 compares edubert, edudistilbert to  #TAUTHOR_TAG, as well as the state - of - the - art ( soa ) for urgency detection ( guo et al. 2019 ).', 'the table shows that all pretraining approaches outperformed the soa for f1 and weighted f1 measures, with our distilled model edudistilbert achieving the best overall performance.', '']",5
"['classifiers  #TAUTHOR_TAG, distil']","['classifiers  #TAUTHOR_TAG, distilbert, edubert and edudistilbert.', 'we evaluated multiple sets of parameters.', 'best results for these']","['by  #AUTHOR_TAG, we split the data into a 2 / 3 training set and 1 / 3 test set and consider a post to express sentiment, urgency or confusion if and only if its respective score is ≥ 4.', 'we compare between the four classifiers  #TAUTHOR_TAG, distil']","['encourage easily comparable results, we evaluated the models on three wellexplored classification tasks on the standfordmooc dataset.', 'following previous work by  #AUTHOR_TAG, we split the data into a 2 / 3 training set and 1 / 3 test set and consider a post to express sentiment, urgency or confusion if and only if its respective score is ≥ 4.', 'we compare between the four classifiers  #TAUTHOR_TAG, distilbert, edubert and edudistilbert.', 'we evaluated multiple sets of parameters.', 'best results for these tasks were achieved with the following parameters : two learning epochs, maximal sequence length of 300  #TAUTHOR_TAG, edubert ) and 512 for the distilled models, all other parameter values were equal to the ones used for pre - training.', 'table 1 compares edubert, edudistilbert to  #TAUTHOR_TAG, as well as the state - of - the - art ( soa ) for urgency detection ( guo et al. 2019 ).', 'the table shows that all pretraining approaches outperformed the soa for f1 and weighted f1 measures, with our distilled model edudistilbert achieving the best overall performance.', '']",5
"['classifiers  #TAUTHOR_TAG, distil']","['classifiers  #TAUTHOR_TAG, distilbert, edubert and edudistilbert.', 'we evaluated multiple sets of parameters.', 'best results for these']","['by  #AUTHOR_TAG, we split the data into a 2 / 3 training set and 1 / 3 test set and consider a post to express sentiment, urgency or confusion if and only if its respective score is ≥ 4.', 'we compare between the four classifiers  #TAUTHOR_TAG, distil']","['encourage easily comparable results, we evaluated the models on three wellexplored classification tasks on the standfordmooc dataset.', 'following previous work by  #AUTHOR_TAG, we split the data into a 2 / 3 training set and 1 / 3 test set and consider a post to express sentiment, urgency or confusion if and only if its respective score is ≥ 4.', 'we compare between the four classifiers  #TAUTHOR_TAG, distilbert, edubert and edudistilbert.', 'we evaluated multiple sets of parameters.', 'best results for these tasks were achieved with the following parameters : two learning epochs, maximal sequence length of 300  #TAUTHOR_TAG, edubert ) and 512 for the distilled models, all other parameter values were equal to the ones used for pre - training.', 'table 1 compares edubert, edudistilbert to  #TAUTHOR_TAG, as well as the state - of - the - art ( soa ) for urgency detection ( guo et al. 2019 ).', 'the table shows that all pretraining approaches outperformed the soa for f1 and weighted f1 measures, with our distilled model edudistilbert achieving the best overall performance.', '']",5
[' #AUTHOR_TAG ;  #TAUTHOR_TAG first introduced a neural mention'],[' #AUTHOR_TAG ;  #TAUTHOR_TAG first introduced a neural mention'],[' #AUTHOR_TAG ;  #TAUTHOR_TAG first introduced a neural mention detector as a part'],"['', 'advantage of these advances and still heavily rely on parse trees ( bjorkelund and  #AUTHOR_TAG a ;  #AUTHOR_TAG b ). they either use all the nps as candidate mentions ( bjorkelund and  #AUTHOR_TAG or use the rule - based mention detector from the stanford deterministic system  #AUTHOR_TAG to extract mentions from nps, named entity mentions and pronouns  #AUTHOR_TAG b ). there are only very few studies that attempt to apply', 'neural network approaches to the md task.  #AUTHOR_TAG ;  #TAUTHOR_TAG first introduced a neural mention detector as a part of their end - to - end coreference', 'system ; however, the system does not output intermediate mentions, hence the mention detector cannot be used by other coreference systems directly. to the best of our knowledge,  #AUTHOR_TAG introduced the only standalone neural mention detector. by using a', '']",0
"['later extended by  #AUTHOR_TAG and  #TAUTHOR_TAG.', ' #AUTHOR_TAG added biaffine attention to']","['later extended by  #AUTHOR_TAG and  #TAUTHOR_TAG.', ' #AUTHOR_TAG added biaffine attention to']","['', 'the system has been later extended by  #AUTHOR_TAG and  #TAUTHOR_TAG.', ' #AUTHOR_TAG added biaffine attention to the coreference part of']","['detection.', 'despite neural networks having shown high performance in many natural language processing tasks, the rule - based mention detector of the stanford deterministic system  #AUTHOR_TAG remains frequently used in top performing coreference systems  #AUTHOR_TAG a ;  #AUTHOR_TAG b ), including the best pipeline system itself based on neural networks  #AUTHOR_TAG a ).', 'this mention detector uses a set of predefined heuristic rules to select mentions from nps, pronouns and named entity mentions.', 'many other coreference systems simply use all the nps as the candidate mentions ( bjorkelund and  #AUTHOR_TAG.', ' #AUTHOR_TAG first introduced a neural network based end - to - end coreference system in which the neural mention detection part is not separated.', 'this move proved very effective ; however, as a result the mention detection part of their system needs to be trained jointly with the coreference resolution part, hence can not be used separately.', 'the system has been later extended by  #AUTHOR_TAG and  #TAUTHOR_TAG.', ' #AUTHOR_TAG added biaffine attention to the coreference part of the  #AUTHOR_TAG system, improving the system by 0. 6 %.', 'biaffine attention is also used in one of our approaches ( biaffine md ), but in a totally different manner, i. e. we use biaffine attention for mention detection while in  #AUTHOR_TAG biaffine attention was used for computing mention - pair scores.', '']",0
[' #TAUTHOR_TAG'],"['system. we further evaluated the  #TAUTHOR_TAG system on the crac', '']","['system. we further evaluated the  #TAUTHOR_TAG system on the crac', '']","['. 7 % and this is 0. 5 better than the original end - to - end  #AUTHOR_TAG system ( see table 4 ). this confirms our second', 'hypothesis that a larger gain on mention recall is needed', 'in order to show improvement on the overall system. we further evaluated the  #TAUTHOR_TAG system on the crac', 'data set. we first train the original  #TAUTHOR_TAG on the reduced version ( with singletons', 'removed ) of the crac data set to create a baseline. as we can see from table 4, the baseline system has an average f', '']",0
[' #AUTHOR_TAG ;  #TAUTHOR_TAG first introduced a neural mention'],[' #AUTHOR_TAG ;  #TAUTHOR_TAG first introduced a neural mention'],[' #AUTHOR_TAG ;  #TAUTHOR_TAG first introduced a neural mention detector as a part'],"['', 'advantage of these advances and still heavily rely on parse trees ( bjorkelund and  #AUTHOR_TAG a ;  #AUTHOR_TAG b ). they either use all the nps as candidate mentions ( bjorkelund and  #AUTHOR_TAG or use the rule - based mention detector from the stanford deterministic system  #AUTHOR_TAG to extract mentions from nps, named entity mentions and pronouns  #AUTHOR_TAG b ). there are only very few studies that attempt to apply', 'neural network approaches to the md task.  #AUTHOR_TAG ;  #TAUTHOR_TAG first introduced a neural mention detector as a part of their end - to - end coreference', 'system ; however, the system does not output intermediate mentions, hence the mention detector cannot be used by other coreference systems directly. to the best of our knowledge,  #AUTHOR_TAG introduced the only standalone neural mention detector. by using a', '']",6
['we use the  #TAUTHOR_TAG system as baseline'],"['we use the  #TAUTHOR_TAG system as baseline.', 'the baseline is']",['we use the  #TAUTHOR_TAG system as baseline'],"['the mention detection evaluation we use the  #TAUTHOR_TAG system as baseline.', 'the baseline is trained end - toend on the coreference task and we use as baseline the mentions predicted by the system before carrying out coreference resolution.', 'for the coreference evaluation we use the state - of - the - art  #TAUTHOR_TAG system as our baseline for the end - to - end system, and the  #AUTHOR_TAG a ) system as our baseline for the pipeline system.', 'during the evaluation, we slightly modified the  #TAUTHOR_TAG system to allow the system to take the mentions predicted by our model instead of its internal mention detector.', 'other than that we keep the system unchanged']",6
['best model from  #TAUTHOR_TAG and use'],['best model from  #TAUTHOR_TAG and use'],['we first take the best model from  #TAUTHOR_TAG and use'],"['', 'for mention detection on the conll data set, we first take the best model from  #TAUTHOR_TAG and use its default mention / token ratio ( λ = 0. 4 ) to output predicted mentions before coreference resolution.', 'we use this as our baseline for the high re - call setting.', '']",4
[' #TAUTHOR_TAG'],"['system. we further evaluated the  #TAUTHOR_TAG system on the crac', '']","['system. we further evaluated the  #TAUTHOR_TAG system on the crac', '']","['. 7 % and this is 0. 5 better than the original end - to - end  #AUTHOR_TAG system ( see table 4 ). this confirms our second', 'hypothesis that a larger gain on mention recall is needed', 'in order to show improvement on the overall system. we further evaluated the  #TAUTHOR_TAG system on the crac', 'data set. we first train the original  #TAUTHOR_TAG on the reduced version ( with singletons', 'removed ) of the crac data set to create a baseline. as we can see from table 4, the baseline system has an average f', '']",4
"['a given product.', 'leveraging the recent advancements  #TAUTHOR_TAG in pre - trained language encoders, we attempt to predict negotiation outcomes early on in the conversation, in a completely data - driven']","['a given product.', 'leveraging the recent advancements  #TAUTHOR_TAG in pre - trained language encoders, we attempt to predict negotiation outcomes early on in the conversation, in a completely data - driven']","['a given product.', 'leveraging the recent advancements  #TAUTHOR_TAG in pre - trained language encoders, we attempt to predict negotiation outcomes early on in the conversation, in a completely data - driven manner ( figure 1 ).', 'early prediction of outcomes is essential']","[', either between individuals or entities, are ubiquitous in everyday human interactions ranging from sales to legal proceedings.', ""being a good negotiator is a complex skill, requiring the ability to understand the partner's motives, ability to reason and to communicate effectively, making it a challenging task for an automated system."", 'while research in building automatically negotiating agents has primarily focused on agent - agent negotiations  #AUTHOR_TAG, there is a recent interest in agent - human negotiations  #AUTHOR_TAG as well.', 'such agents may act as mediators or can be helpful for pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #AUTHOR_TAG recently studied natural language negotiations in buyer - seller bargaining setup, which is comparatively less restricted than previously studied game environments  #AUTHOR_TAG.', 'lack of a well - defined structure in such negotiations allows humans or agents to express themselves more freely, which better emulates a realistic scenario.', 'interestingly, this also provides an exciting research opportunity : how can an agent leverage the behavioral cues in natural language to direct its negotiation strategies? understanding the impact of natural language on negotiation outcomes through a data - driven neural framework is the primary objective of this work.', 'we focus on buyer - seller negotiations  #AUTHOR_TAG where two individuals negotiate the price of a given product.', 'leveraging the recent advancements  #TAUTHOR_TAG in pre - trained language encoders, we attempt to predict negotiation outcomes early on in the conversation, in a completely data - driven manner ( figure 1 ).', 'early prediction of outcomes is essential for effective planning of an automatically negotiating agent.', 'although there have been attempts to gain insights into negotiations  #AUTHOR_TAG, to the best of our knowledge, we are the first to study early natural language cues through a datadriven neural system ( section 3 ).', 'our evaluations show that natural language allows the models to make better predictions by looking at only a fraction of the negotiation.', 'rather than just realizing the strategy in natural language, our empirical results suggest that language can be crucial in the planning as well.', 'we provide a sample negotiation from the test set  #AUTHOR_TAG along with our model predictions in table 1']",5
"['use bertbase  #TAUTHOR_TAG, having']","['use bertbase  #TAUTHOR_TAG, having']","['', 'training details : given the multiple segments in our model input and small data size, we use bertbase  #TAUTHOR_TAG, having output dimension']","['', 'we compare two variants for bert - based models.', 'first, for the bert method, we keep only the first [CLS] token in the input and then train the model with fine - tuning using a single feedforward network on top of the [CLS] representation.', 'secondly, we call our complete approach as bert + gru, where we use a recurrent network with bert fine - tuning, as depicted in figure 1.', 'training details : given the multiple segments in our model input and small data size, we use bertbase  #TAUTHOR_TAG, having output dimension of 768.', 'to tackle the variance in product prices across different categories, all prices in the inputs and outputs were normalized by the listing price.', 'the predictions were unnormalized before final evaluations.', 'further, we only considered the negotiations where an agreement was reached.', 'these were the instances for which ground truth was available ( ∼ 75 % of the data ).', 'we use a two - layer gru with a dropout of 0. 1 and 50 hidden units.', 'the models were trained for a maximum of 5000 iterations, with adamw optimizer  #AUTHOR_TAG, a learning rate of 2x10 − 5 and a batch size of 4.', 'we used a linear warmup schedule for the first 0. 1 fraction of the steps.', 'all the hyper - parameters were optimized on the provided development set.', 'evaluation metrics : we study the']",5
['bert  #TAUTHOR_TAG have recently gained huge'],['bert  #TAUTHOR_TAG have recently gained huge'],"['bert  #TAUTHOR_TAG have recently gained huge success on a wide range of nlp tasks.', 'however, since our']","['- trained language models, such as bert  #TAUTHOR_TAG have recently gained huge success on a wide range of nlp tasks.', 'however, since our framework deals with various auxiliary pieces ( category, price, etc. ), we cannot directly leverage these language models, which have only been trained on natural language inputs.', 'instead of relying on additional representations along with bert outputs, we propose a simple, yet effective way to incorporate the auxiliary information into the same embedding space.', 'our model hierarchically builds a representation for the given negotiation to finally predict the agreed price.', 'we present our complete architecture in figure 1.', 'encoding the input : in order to effectively capture the natural language dialogue and the associated auxiliary information, we make use of predefined sentence templates.', 'table 2 shows how we represent the category, target price and the product title in natural language sentences.', 'these sentences are concatenated to form our scenario s. moving ahead in a similar manner, we define templates to capture the negotiator identity ( buyer / seller ) and any message which is conveyed.', 'as shown in figure 1, the scenario s and the events are separated with the usage of [SEP] tokens.', ' #AUTHOR_TAG, who use bert for extractive text summarization, we add a [CLS] token at the beginning of each segment.', 'we also alternate between a sequence of 0s and 1s for segment embeddings to differentiate between the scenario and the events.', 'architecture and learning : bert representation for each [CLS] token is a contextualized encoding for the associated word sequence after it.', 'in order to further capture the sequential nature of negotiation events, we pass these [CLS] representations through gated - recurrent units ( gru ).', 'recurrent networks have been shown to be useful along with transformer architectures.', 'finally, a feed - forward network is applied to predict the agreed price for the negotiation.', 'the model is end - to - end trained and fine - tuned using the mean squared error ( mse ) loss between the predicted price and the ground - truth']",0
['bert  #TAUTHOR_TAG have recently gained huge'],['bert  #TAUTHOR_TAG have recently gained huge'],"['bert  #TAUTHOR_TAG have recently gained huge success on a wide range of nlp tasks.', 'however, since our']","['- trained language models, such as bert  #TAUTHOR_TAG have recently gained huge success on a wide range of nlp tasks.', 'however, since our framework deals with various auxiliary pieces ( category, price, etc. ), we cannot directly leverage these language models, which have only been trained on natural language inputs.', 'instead of relying on additional representations along with bert outputs, we propose a simple, yet effective way to incorporate the auxiliary information into the same embedding space.', 'our model hierarchically builds a representation for the given negotiation to finally predict the agreed price.', 'we present our complete architecture in figure 1.', 'encoding the input : in order to effectively capture the natural language dialogue and the associated auxiliary information, we make use of predefined sentence templates.', 'table 2 shows how we represent the category, target price and the product title in natural language sentences.', 'these sentences are concatenated to form our scenario s. moving ahead in a similar manner, we define templates to capture the negotiator identity ( buyer / seller ) and any message which is conveyed.', 'as shown in figure 1, the scenario s and the events are separated with the usage of [SEP] tokens.', ' #AUTHOR_TAG, who use bert for extractive text summarization, we add a [CLS] token at the beginning of each segment.', 'we also alternate between a sequence of 0s and 1s for segment embeddings to differentiate between the scenario and the events.', 'architecture and learning : bert representation for each [CLS] token is a contextualized encoding for the associated word sequence after it.', 'in order to further capture the sequential nature of negotiation events, we pass these [CLS] representations through gated - recurrent units ( gru ).', 'recurrent networks have been shown to be useful along with transformer architectures.', 'finally, a feed - forward network is applied to predict the agreed price for the negotiation.', 'the model is end - to - end trained and fine - tuned using the mean squared error ( mse ) loss between the predicted price and the ground - truth']",4
[') model by  #TAUTHOR_TAG which uses global modules'],['model by  #TAUTHOR_TAG which uses global modules'],[') model by  #TAUTHOR_TAG which uses global modules'],"['latency in the current neural based dialogue state tracking models prohibits them from being used efficiently for deployment in production systems, albeit their highly accurate performance.', 'this paper proposes a new scalable and accurate neural dialogue state tracking model, based on the recently proposed global - local self - attention encoder ( glad ) model by  #TAUTHOR_TAG which uses global modules to share parameters between estimators for different types ( called slots ) of dialogue states, and uses local modules to learn slot - specific features.', 'by using only one recurrent networks with global conditioning, compared to ( 1 + # slots ) recurrent networks with global and local conditioning used in the glad model, our proposed model reduces the latency in training and inference times by 35 % on average, while preserving performance of belief state tracking, by 97. 38 % on turn request and 88. 51 % on joint goal and accuracy.', 'evaluation on multi - domain dataset ( multi - woz ) also demonstrates that our model outperforms glad on turn inform and joint goal accuracy']",5
"['', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary']","['system response.', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary']","['', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary classifier for each slot - value, global - locally self attentive encoder (']","['', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary classifier for each slot - value, global - locally self attentive encoder ( glad, by employing recurrent and self attention for each utterance and previous system actions, and measuring similaity of these computed representation to each slot - value, which achieve state of the art results on woz and dstc2  #AUTHOR_TAG datasets.', 'although the proposed neural based models achieves state of the art results on several benchmark, they are still inefficient for deployment in production system, due to their latency which stems from using recurrent networks.', 'in this paper, we propose a new encoder, by improving glad architecture  #TAUTHOR_TAG.', 'the proposed encoder is based on removing slot - dependent recurrent network for utterance and system action encoder, and employing a global conditioning of aforementioned encoder on the slot type embedding vector.', 'by removing the slot - dependent recurrent network']",5
"['glad encoder  #TAUTHOR_TAG architecture,']","['glad encoder  #TAUTHOR_TAG architecture,']","['glad encoder  #TAUTHOR_TAG architecture,']","['this section, we describe the proposed model.', 'first, section 2. 1 explains the recently proposed glad encoder  #TAUTHOR_TAG architecture, followed by our proposed encoder in section 2. 2']",5
"[' #TAUTHOR_TAG.', 'however, we emphasize the limitation of']","['user utterance and system actions, as proposed in glad  #TAUTHOR_TAG.', 'however, we emphasize the limitation of glad encoder in using slot - specific recurrent and self - attention layers in their encoders.', '']","['user utterance and system actions, as proposed in glad  #TAUTHOR_TAG.', 'however, we emphasize the limitation of']","['this section, we describe the proposed globally - conditioned encoder ( gce ) model.', 'here, we employ the similar approach of learning slot - specific temporal and context representation of user utterance and system actions, as proposed in glad  #TAUTHOR_TAG.', 'however, we emphasize the limitation of glad encoder in using slot - specific recurrent and self - attention layers in their encoders.', 'our proposed encoder is based on improving the latency and speed of inference by remving the inefficient recurrent layers and self - attention layers, without degrading the performance.', 'the proposed model is based on removing slot - specific recurrent and self - attention layers, and using only slot embedding vector ( i. e. s k for k - th slot ), as a conditioning vector to the temporal and context extraction layers, as shown in figure 1.', 'to compute k - th slot - based representation h k, the slot embedding s k is concatenated with sequence tokens x, i. e. user utterance or previous system actions, as input to the recurrent layer, where concatenation denoted as f ( x, s k ).', '']",5
"[' #TAUTHOR_TAG.', 'however, we emphasize the limitation of']","['user utterance and system actions, as proposed in glad  #TAUTHOR_TAG.', 'however, we emphasize the limitation of glad encoder in using slot - specific recurrent and self - attention layers in their encoders.', '']","['user utterance and system actions, as proposed in glad  #TAUTHOR_TAG.', 'however, we emphasize the limitation of']","['this section, we describe the proposed globally - conditioned encoder ( gce ) model.', 'here, we employ the similar approach of learning slot - specific temporal and context representation of user utterance and system actions, as proposed in glad  #TAUTHOR_TAG.', 'however, we emphasize the limitation of glad encoder in using slot - specific recurrent and self - attention layers in their encoders.', 'our proposed encoder is based on improving the latency and speed of inference by remving the inefficient recurrent layers and self - attention layers, without degrading the performance.', 'the proposed model is based on removing slot - specific recurrent and self - attention layers, and using only slot embedding vector ( i. e. s k for k - th slot ), as a conditioning vector to the temporal and context extraction layers, as shown in figure 1.', 'to compute k - th slot - based representation h k, the slot embedding s k is concatenated with sequence tokens x, i. e. user utterance or previous system actions, as input to the recurrent layer, where concatenation denoted as f ( x, s k ).', '']",5
"['of turn goals as described in  #TAUTHOR_TAG.', 'the fixed pre']","['of turn goals as described in  #TAUTHOR_TAG.', 'the fixed pretrained glove embedding  #AUTHOR_TAG with character - n gram embedding  #AUTHOR_TAG are used in embedding layer.', 'the implementation details and code of the gce model can be found']","['of turn goals as described in  #TAUTHOR_TAG.', 'the fixed pre']","['', 'the joint goal is the accumulation of turn goals as described in  #TAUTHOR_TAG.', 'the fixed pretrained glove embedding  #AUTHOR_TAG with character - n gram embedding  #AUTHOR_TAG are used in embedding layer.', 'the implementation details and code of the gce model can be found at https : / / github. com / elnaaz / gce - model.', 'single - domain : table 1 shows the evaluation performance on woz dataset.', 'it is indicated that our proposed gce model performance is on par with glad model.', '']",5
"['', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary']","['system response.', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary']","['', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary classifier for each slot - value, global - locally self attentive encoder (']","['', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary classifier for each slot - value, global - locally self attentive encoder ( glad, by employing recurrent and self attention for each utterance and previous system actions, and measuring similaity of these computed representation to each slot - value, which achieve state of the art results on woz and dstc2  #AUTHOR_TAG datasets.', 'although the proposed neural based models achieves state of the art results on several benchmark, they are still inefficient for deployment in production system, due to their latency which stems from using recurrent networks.', 'in this paper, we propose a new encoder, by improving glad architecture  #TAUTHOR_TAG.', 'the proposed encoder is based on removing slot - dependent recurrent network for utterance and system action encoder, and employing a global conditioning of aforementioned encoder on the slot type embedding vector.', 'by removing the slot - dependent recurrent network']",0
"['glad encoder  #TAUTHOR_TAG architecture,']","['glad encoder  #TAUTHOR_TAG architecture,']","['glad encoder  #TAUTHOR_TAG architecture,']","['this section, we describe the proposed model.', 'first, section 2. 1 explains the recently proposed glad encoder  #TAUTHOR_TAG architecture, followed by our proposed encoder in section 2. 2']",0
"['', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary']","['system response.', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary']","['', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary classifier for each slot - value, global - locally self attentive encoder (']","['', 'recently,  #TAUTHOR_TAG proposed a model based on training a binary classifier for each slot - value, global - locally self attentive encoder ( glad, by employing recurrent and self attention for each utterance and previous system actions, and measuring similaity of these computed representation to each slot - value, which achieve state of the art results on woz and dstc2  #AUTHOR_TAG datasets.', 'although the proposed neural based models achieves state of the art results on several benchmark, they are still inefficient for deployment in production system, due to their latency which stems from using recurrent networks.', 'in this paper, we propose a new encoder, by improving glad architecture  #TAUTHOR_TAG.', 'the proposed encoder is based on removing slot - dependent recurrent network for utterance and system action encoder, and employing a global conditioning of aforementioned encoder on the slot type embedding vector.', 'by removing the slot - dependent recurrent network']",1
"['of turn goals as described in  #TAUTHOR_TAG.', 'the fixed pre']","['of turn goals as described in  #TAUTHOR_TAG.', 'the fixed pretrained glove embedding  #AUTHOR_TAG with character - n gram embedding  #AUTHOR_TAG are used in embedding layer.', 'the implementation details and code of the gce model can be found']","['of turn goals as described in  #TAUTHOR_TAG.', 'the fixed pre']","['', 'the joint goal is the accumulation of turn goals as described in  #TAUTHOR_TAG.', 'the fixed pretrained glove embedding  #AUTHOR_TAG with character - n gram embedding  #AUTHOR_TAG are used in embedding layer.', 'the implementation details and code of the gce model can be found at https : / / github. com / elnaaz / gce - model.', 'single - domain : table 1 shows the evaluation performance on woz dataset.', 'it is indicated that our proposed gce model performance is on par with glad model.', '']",3
"['indicative words ( liws ) in tweets  #TAUTHOR_TAG, and user - declared location and time zone metadata.', '']","['indicative words ( liws ) in tweets  #TAUTHOR_TAG, and user - declared location and time zone metadata.', '']","['indicative words ( liws ) in tweets  #TAUTHOR_TAG, and user - declared location and time zone metadata.', '']","['this paper, we present and evaluate a geolocation prediction method for twitter users.', '1 given a user\'s tweet data as input, the task of user level geolocation prediction is to infer a primary location ( i. e., "" home location "" :  #AUTHOR_TAG ) for the user from a discrete set of pre - defined locations  #AUTHOR_TAG.', ""for instance, president obama's location might be predicted to be washington d. c., usa, based on his public tweets and profile metadata."", 'geolocation information is essential to locationbased applications, like targeted advertising and local event detection  #AUTHOR_TAG mac  #AUTHOR_TAG.', 'however, the means to obtain such information are limited.', 'although twitter allows users to specify a plain text description of their location in their profile, these descriptions tend to be ad hoc and unreliable  #AUTHOR_TAG.', ""recently, user geolocation prediction based on a user's tweets has become popular  #AUTHOR_TAG, based on the assumption that tweets implicitly contain locating information, and with appropriate statistical modeling, the true location can be inferred."", 'for instance, if a user frequently mentions nyc, jfk and yankees, it is likely that they are from new york city, usa.', 'in this paper, we discuss an implementation of a global city - level geolocation prediction system for english twitter users.', 'the system utilises both tweet text and public profile metadata for modeling and inference.', 'specifically, we train multinomial bayes classifiers based on location indicative words ( liws ) in tweets  #TAUTHOR_TAG, and user - declared location and time zone metadata.', 'these base classifiers are further stacked  #AUTHOR_TAG using logistic regression as the meta - classifier.', 'the proposed stacking model is compared with benchmarks on a public geolocation dataset.', 'experimental results demonstrate that our stacking model outperforms benchmark methods by a large margin, achieving 49 % accuracy on the test data.', 'we further evaluate the stacking model on a more recent crawl of public tweets.', 'this experiment tests the effectiveness of a geolocation model trained on "" old "" data when applied to "" new "" data.', 'the results reveal that user - declared locations are more variable over time than tweet text and time zone data']",5
"['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with the largest nearby city.', ' #TAUTHOR_TAG found that using feature selection to identify "" location indicative words "" led to improvements in geolocation performance.', 'we use the same feature selection technique that they did.', '']",5
"['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with the largest nearby city.', ' #TAUTHOR_TAG found that using feature selection to identify "" location indicative words "" led to improvements in geolocation performance.', 'we use the same feature selection technique that they did.', '']",5
"['our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains']","['our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains 1. 4m users whose tweets are primarily identified as english based on the output']","['base our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains']","['base our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains 1. 4m users whose tweets are primarily identified as english based on the output of the langid. py language identification tool  #AUTHOR_TAG, and who have posted at least 10 geotagged tweets.', '']",5
"['our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains']","['our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains 1. 4m users whose tweets are primarily identified as english based on the output']","['base our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains']","['base our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains 1. 4m users whose tweets are primarily identified as english based on the output of the langid. py language identification tool  #AUTHOR_TAG, and who have posted at least 10 geotagged tweets.', '']",5
"['tweets are from urban areas,  #TAUTHOR_TAG']","['tweets are from urban areas,  #TAUTHOR_TAG consider a citybased class division, and explore different feature selection methods']","['tweets are from urban areas,  #TAUTHOR_TAG']","['', '. based on this observation,  #AUTHOR_TAG introduced an adaptive grid representation in which cells contain approximately the same number of users, based on', 'a kdtree partition. given that most tweets are from urban areas,  #TAUTHOR_TAG consider a citybased class division, and explore different feature selection methods to extract "" location indicative words "", which they show to improve prediction accuracy. additionally, time zone information has been incorporated in', 'a coarse - to - fine hierarchical model by first determining the time zone, and then disambiguating locations within it  #AUTHOR_TAG.', 'topic models have also been applied to the task, in capturing regional linguistic differences  #AUTHOR_TAG. when designing a practical geolocation system, simple models such as naive bayes', 'and nearest prototype methods ( e. g., based on kl divergence ) have clear advantages in terms of training and classification throughput, given', 'the size of the class set ( often numbering in the thousands of classes ) and sheer volume of training data ( potentially in the terabytes', 'of data ). this is particularly important for online systems and downstream', 'applications that require timely predictions. as such, we build off the text - based naive bayes - based geolocation system of  #TAUTHOR_TAG, which', 'our experiments have shown to have a good balance of tractability and accuracy. by selecting a reduced set of "" location indicative words "", prediction can', 'be further accelerated']",0
"['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with the largest nearby city.', ' #TAUTHOR_TAG found that using feature selection to identify "" location indicative words "" led to improvements in geolocation performance.', 'we use the same feature selection technique that they did.', '']",0
"['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with the largest nearby city.', ' #TAUTHOR_TAG found that using feature selection to identify "" location indicative words "" led to improvements in geolocation performance.', 'we use the same feature selection technique that they did.', '']",0
"['tweets are from urban areas,  #TAUTHOR_TAG']","['tweets are from urban areas,  #TAUTHOR_TAG consider a citybased class division, and explore different feature selection methods']","['tweets are from urban areas,  #TAUTHOR_TAG']","['', '. based on this observation,  #AUTHOR_TAG introduced an adaptive grid representation in which cells contain approximately the same number of users, based on', 'a kdtree partition. given that most tweets are from urban areas,  #TAUTHOR_TAG consider a citybased class division, and explore different feature selection methods to extract "" location indicative words "", which they show to improve prediction accuracy. additionally, time zone information has been incorporated in', 'a coarse - to - fine hierarchical model by first determining the time zone, and then disambiguating locations within it  #AUTHOR_TAG.', 'topic models have also been applied to the task, in capturing regional linguistic differences  #AUTHOR_TAG. when designing a practical geolocation system, simple models such as naive bayes', 'and nearest prototype methods ( e. g., based on kl divergence ) have clear advantages in terms of training and classification throughput, given', 'the size of the class set ( often numbering in the thousands of classes ) and sheer volume of training data ( potentially in the terabytes', 'of data ). this is particularly important for online systems and downstream', 'applications that require timely predictions. as such, we build off the text - based naive bayes - based geolocation system of  #TAUTHOR_TAG, which', 'our experiments have shown to have a good balance of tractability and accuracy. by selecting a reduced set of "" location indicative words "", prediction can', 'be further accelerated']",6
"['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with the largest nearby city.', ' #TAUTHOR_TAG found that using feature selection to identify "" location indicative words "" led to improvements in geolocation performance.', 'we use the same feature selection technique that they did.', '']",3
"['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with the largest nearby city.', ' #TAUTHOR_TAG found that using feature selection to identify "" location indicative words "" led to improvements in geolocation performance.', 'we use the same feature selection technique that they did.', '']",3
"['our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains']","['our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains 1. 4m users whose tweets are primarily identified as english based on the output']","['base our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains']","['base our evaluation on the publicly - available world dataset of  #TAUTHOR_TAG.', 'the dataset contains 1. 4m users whose tweets are primarily identified as english based on the output of the langid. py language identification tool  #AUTHOR_TAG, and who have posted at least 10 geotagged tweets.', '']",3
"['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3,']","['this study, we adopt the same city - based representation and multinomial naive bayes learner as  #TAUTHOR_TAG.', 'the city - based representation consists of 3, 709 cities throughout the world, and is obtained by aggregating smaller cities with the largest nearby city.', ' #TAUTHOR_TAG found that using feature selection to identify "" location indicative words "" led to improvements in geolocation performance.', 'we use the same feature selection technique that they did.', '']",1
"['in a multi - label setting, allowing multiple relations per entity ( see  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'the core']","['in a multi - label setting, allowing multiple relations per entity ( see  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'the core']","[') we model relation extraction in a multi - label setting, allowing multiple relations per entity ( see  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'the core contribution of the paper is the use of at as an extension in the training procedure']","['', 'previously proposed models ( summarized in section 2 ) exhibit several issues that the neural network - based baseline approach ( detailed in section 3. 1 ) overcomes : ( i ) our model uses automatically extracted features without the need of external parsers nor manually extracted features ( see  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ), ( ii ) all entities and the corresponding relations within the sentence are extracted at once, instead of examining one pair of entities at a time ( see adel and schutze ( 2017 ) ), and ( iii ) we model relation extraction in a multi - label setting, allowing multiple relations per entity ( see  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'the core contribution of the paper is the use of at as an extension in the training procedure for the joint extraction task ( section 3. 2 ).', 'to evaluate the proposed at method, we perform a large scale experimental study in this joint task ( see section 4 ), using datasets from different contexts ( i. e., news, biomedical, real estate ) and languages ( i. e., english, dutch ).', 'we use a strong baseline that outperforms all previous models that rely on automatically extracted features, achieving state - of - the - art performance ( section 5 ).', 'compared to the baseline model, applying at during training leads to a consistent additional increase in joint extraction effectiveness']",4
"[',  #TAUTHOR_TAG use lstms in a joint model']","['layer.', ' #AUTHOR_TAG investigate rnns with attention without taking into account that relation labels are not mutually exclusive.', 'finally,  #TAUTHOR_TAG use lstms in a joint model']","[',  #TAUTHOR_TAG use lstms in a joint model']","['', 'these methods rely on the availability of nlp tools ( e. g., pos taggers ) or manually designed features leading to additional complexity.', 'neural network methods have been exploited to overcome this feature design issue and usually involve rnns and cnns  #AUTHOR_TAG.', ' #AUTHOR_TAG as well as  #AUTHOR_TAG apply bidirectional tree - structured rnns for different contexts ( i. e., news, biomedical ) to capture syntactic information ( using external dependency parsers ).', ' #AUTHOR_TAG propose the use of various manually extracted features along with rnns.', 'adel and schutze ( 2017 ) solve the simpler problem of entity classification ( ec, assuming entity boundaries are given ), instead of ner, and they replicate the context around the entities, feeding entity pairs to the relation extraction layer.', ' #AUTHOR_TAG investigate rnns with attention without taking into account that relation labels are not mutually exclusive.', 'finally,  #TAUTHOR_TAG use lstms in a joint model for extracting just one relation at a time, but increase the complexity of the ner part.', '']",4
"['compared to  #TAUTHOR_TAG, whose quadratic scoring layer compl']","['compared to  #TAUTHOR_TAG, whose quadratic scoring layer compl']","['tasks compared to  #TAUTHOR_TAG, whose quadratic scoring layer complicates ner. table 1 and fig. 2 show the effectiveness of the adversarial training on top of the baseline model. in']","['', 'two evaluation methods. in the boundaries evaluation, the baseline has an improvement of ∼3 % on both tasks compared to  #TAUTHOR_TAG, whose quadratic scoring layer complicates ner. table 1 and fig. 2 show the effectiveness of the adversarial training on top of the baseline model. in all of the experiments, at improves the predictive performance of the baseline model in the joint setting. moreover, as seen in fig. 2, the performance of the models using at is closer to maximum even from the early training epochs. specifically, for ace04, there is an improvement in both tasks as well as in the overall f 1 performance ( 0', '']",4
"[',  #TAUTHOR_TAG use lstms in a joint model']","['layer.', ' #AUTHOR_TAG investigate rnns with attention without taking into account that relation labels are not mutually exclusive.', 'finally,  #TAUTHOR_TAG use lstms in a joint model']","[',  #TAUTHOR_TAG use lstms in a joint model']","['', 'these methods rely on the availability of nlp tools ( e. g., pos taggers ) or manually designed features leading to additional complexity.', 'neural network methods have been exploited to overcome this feature design issue and usually involve rnns and cnns  #AUTHOR_TAG.', ' #AUTHOR_TAG as well as  #AUTHOR_TAG apply bidirectional tree - structured rnns for different contexts ( i. e., news, biomedical ) to capture syntactic information ( using external dependency parsers ).', ' #AUTHOR_TAG propose the use of various manually extracted features along with rnns.', 'adel and schutze ( 2017 ) solve the simpler problem of entity classification ( ec, assuming entity boundaries are given ), instead of ner, and they replicate the context around the entities, feeding entity pairs to the relation extraction layer.', ' #AUTHOR_TAG investigate rnns with attention without taking into account that relation labels are not mutually exclusive.', 'finally,  #TAUTHOR_TAG use lstms in a joint model for extracting just one relation at a time, but increase the complexity of the ner part.', '']",0
"[',  #TAUTHOR_TAG use lstms in a joint model']","['layer.', ' #AUTHOR_TAG investigate rnns with attention without taking into account that relation labels are not mutually exclusive.', 'finally,  #TAUTHOR_TAG use lstms in a joint model']","[',  #TAUTHOR_TAG use lstms in a joint model']","['', 'these methods rely on the availability of nlp tools ( e. g., pos taggers ) or manually designed features leading to additional complexity.', 'neural network methods have been exploited to overcome this feature design issue and usually involve rnns and cnns  #AUTHOR_TAG.', ' #AUTHOR_TAG as well as  #AUTHOR_TAG apply bidirectional tree - structured rnns for different contexts ( i. e., news, biomedical ) to capture syntactic information ( using external dependency parsers ).', ' #AUTHOR_TAG propose the use of various manually extracted features along with rnns.', 'adel and schutze ( 2017 ) solve the simpler problem of entity classification ( ec, assuming entity boundaries are given ), instead of ner, and they replicate the context around the entities, feeding entity pairs to the relation extraction layer.', ' #AUTHOR_TAG investigate rnns with attention without taking into account that relation labels are not mutually exclusive.', 'finally,  #TAUTHOR_TAG use lstms in a joint model for extracting just one relation at a time, but increase the complexity of the ner part.', '']",6
"['compared to  #TAUTHOR_TAG, whose quadratic scoring layer compl']","['compared to  #TAUTHOR_TAG, whose quadratic scoring layer compl']","['tasks compared to  #TAUTHOR_TAG, whose quadratic scoring layer complicates ner. table 1 and fig. 2 show the effectiveness of the adversarial training on top of the baseline model. in']","['', 'two evaluation methods. in the boundaries evaluation, the baseline has an improvement of ∼3 % on both tasks compared to  #TAUTHOR_TAG, whose quadratic scoring layer complicates ner. table 1 and fig. 2 show the effectiveness of the adversarial training on top of the baseline model. in all of the experiments, at improves the predictive performance of the baseline model in the joint setting. moreover, as seen in fig. 2, the performance of the models using at is closer to maximum even from the early training epochs. specifically, for ace04, there is an improvement in both tasks as well as in the overall f 1 performance ( 0', '']",5
"['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important']","['simplification is the task to find and substitute a complex word or phrase in a sentence with its simpler synonymous expression.', 'we define complex word as a word that has lexical and subjective difficulty in a sentence.', 'it can help in reading comprehension for children and language learners  #AUTHOR_TAG.', 'this task is a rather easier task which prepare a pair of complex and simple representations than a challenging task which changes the substitute pair in a given context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important to ensure the reliability and reproducibility of evaluation.', 'however, few resources are available for the automatic evaluation of lexical simplification.', ' #AUTHOR_TAG and  #AUTHOR_TAG created benchmark datasets for evaluating english lexical simplification.', 'in addition,  #AUTHOR_TAG extracted simplification candidates and constructed an evaluation dataset using english wikipedia and simple english wikipedia.', 'in contrast, such a parallel corpus does not exist in japanese.', ' #AUTHOR_TAG constructed an evaluation dataset for japanese lexical simplification 1 in languages other than english.', 'however, there are four drawbacks in the dataset of  #AUTHOR_TAG : ( 1 ) they extracted sentences only from a newswire corpus ; ( 2 ) they substituted only a single target word ; ( 3 ) they did not allow ties ; and ( 4 ) they did not integrate simplification ranking considering the quality.', 'hence, we propose a new dataset addressing the problems in the dataset of  #AUTHOR_TAG.', 'the main contributions of our study are as follows :', '• it is the first controlled and balanced dataset for japanese lexical simplification.', 'we extract sentences from a balanced corpus and control sentences to have only one complex word.', 'experimental results show that our dataset is more suitable than previous datasets for evaluating systems with respect to correlation with human judgment.', '• the consistency of simplification ranking is greatly improved by allowing candidates to have ties and by considering the reliability of annotators.', 'our dataset is available at github 2']",0
[' #TAUTHOR_TAG by 0'],"['of  #TAUTHOR_TAG by 0. 064. thus, there', 'was a big blur between annotators, and the simplification ranking collected using crowdsourcing', '']",[' #TAUTHOR_TAG by 0'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG by 0'],"['of  #TAUTHOR_TAG by 0. 064. thus, there', 'was a big blur between annotators, and the simplification ranking collected using crowdsourcing', '']",[' #TAUTHOR_TAG by 0'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG by 0'],"['of  #TAUTHOR_TAG by 0. 064. thus, there', 'was a big blur between annotators, and the simplification ranking collected using crowdsourcing', '']",[' #TAUTHOR_TAG by 0'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG by 0'],"['of  #TAUTHOR_TAG by 0. 064. thus, there', 'was a big blur between annotators, and the simplification ranking collected using crowdsourcing', '']",[' #TAUTHOR_TAG by 0'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG by 0'],"['of  #TAUTHOR_TAG by 0. 064. thus, there', 'was a big blur between annotators, and the simplification ranking collected using crowdsourcing', '']",[' #TAUTHOR_TAG by 0'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG by 0'],"['of  #TAUTHOR_TAG by 0. 064. thus, there', 'was a big blur between annotators, and the simplification ranking collected using crowdsourcing', '']",[' #TAUTHOR_TAG by 0'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG by 0'],"['of  #TAUTHOR_TAG by 0. 064. thus, there', 'was a big blur between annotators, and the simplification ranking collected using crowdsourcing', '']",[' #TAUTHOR_TAG by 0'],[' #TAUTHOR_TAG'],4
"['of allowing ties during the substitute ranking task.', 'table 2 shows the results of the ranking integration.', 'our method achieved better accuracy in ranking integration than previous methods  #TAUTHOR_TAG and is']","['of allowing ties during the substitute ranking task.', 'table 2 shows the results of the ranking integration.', 'our method achieved better accuracy in ranking integration than previous methods  #TAUTHOR_TAG and is']","[' #AUTHOR_TAG by 0. 190.', 'this clearly shows the importance of allowing ties during the substitute ranking task.', 'table 2 shows the results of the ranking integration.', 'our method achieved better accuracy in ranking integration than previous methods  #TAUTHOR_TAG and is']","['', 'this score is higher than that from  #AUTHOR_TAG by 0. 190.', 'this clearly shows the importance of allowing ties during the substitute ranking task.', 'table 2 shows the results of the ranking integration.', 'our method achieved better accuracy in ranking integration than previous methods  #TAUTHOR_TAG and is similar to the results from  #AUTHOR_TAG.', 'this shows that the reliability score can be used for improving the quality.', 'table 3 shows the number of sentences and average substitutes in each genre.', 'in our dataset, the number of acquired substitutes is 8, 636 words and the average number of substitutes is 4. 30 words per sentence.', 'figure 6 illustrates a part of our dataset.', 'substitutes that include particles are found in 75 context ( 3. 7 % ).', 'it is shown that if particles are not permitted in substitutes, we obtain only two substitutes ( 4 and 7 ).', 'by permitting substitutes to include particles, we are able to obtain 7 substitutes.', ""in ranking substitutes, spearman rank correlation coefficient is 0. 729, which is substantially higher than crowdsourcing's score."", 'thus, it is necessary to consider annotation method']",4
[' #TAUTHOR_TAG by 0'],"['of  #TAUTHOR_TAG by 0. 064. thus, there', 'was a big blur between annotators, and the simplification ranking collected using crowdsourcing', '']",[' #TAUTHOR_TAG by 0'],[' #TAUTHOR_TAG'],5
[' #TAUTHOR_TAG by 0'],"['of  #TAUTHOR_TAG by 0. 064. thus, there', 'was a big blur between annotators, and the simplification ranking collected using crowdsourcing', '']",[' #TAUTHOR_TAG by 0'],[' #TAUTHOR_TAG'],1
"[' #TAUTHOR_TAG.', 'our dataset has two advantages : ( 1']","[' #TAUTHOR_TAG.', 'our dataset has two advantages : ( 1 ) improved correlation with human']","['previous work  #TAUTHOR_TAG.', 'our dataset has two advantages : ( 1']","[""##ators'rankings were integrated into one ranking, using a maximum likelihood estimation  #AUTHOR_TAG to penalize deceptive annotators as was done by  #AUTHOR_TAG."", 'this method estimates the reliability of annotators in addition to determining the true order of rankings.', 'we applied the reliability score to exclude extraordinary annotators.', 'table 1 shows the characteristics of our dataset.', 'it is about the same size as previous work  #TAUTHOR_TAG.', 'our dataset has two advantages : ( 1 ) improved correlation with human judgment by making a controlled and balanced dataset, and ( 2 ) enhanced consistency by allowing ties in ranking and removing outlier annotators.', 'in the following subsections, we evaluate our dataset in detail']",3
[' #TAUTHOR_TAG'],['of successful approaches have been proposed for both extractive  #AUTHOR_TAG and abstractive  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['summarization aims to produce a shorter, informative version of an input text.', 'while extractive summarization only selects important sentences from the input, abstractive summarization generates content without explicitly re - using whole sentences  #AUTHOR_TAG resulting summaries that are more fluent.', 'in recent years, a number of successful approaches have been proposed for both extractive  #AUTHOR_TAG and abstractive  #TAUTHOR_TAG summarization paradigms.', 'state - of - the - art abstractive approaches are supervised, relying on large collections of paired articles and summaries.', 'however, competitive performance of abstractive systems remains a challenge when availability of parallel data is limited, such as in low - resource domains or for languages other than english.', 'even when parallel data is limited, we may have access to example summaries and to large collections of articles on similar topics.', 'examples are blog posts or scientific press releases, for which the original articles may be unavailable or behind a paywall.', 'in this paper, we develop a system for abstractive document summarization that only relies on having access to example summaries and nonmatching articles, bypassing the need for largescale parallel corpora.', 'our system consists of two components : an unsupervised sentence extractor first selects salient sentences.', '']",0
['- sentence  #TAUTHOR_TAG'],['sentence - by - sentence  #TAUTHOR_TAG'],"['- sentence  #TAUTHOR_TAG.', 'both approaches rely on large collections of article - summary pairs']",[' #TAUTHOR_TAG'],0
"['hierarchical model from  #TAUTHOR_TAG, consisting of']","['hierarchical model from  #TAUTHOR_TAG, consisting of']","['abs is the hierarchical model from  #TAUTHOR_TAG, consisting of a supervised lstm extractor']",[' #TAUTHOR_TAG'],0
"['is similar to  #TAUTHOR_TAG, except that they use parallel data']","['is similar to  #TAUTHOR_TAG, except that they use parallel data']","['is similar to  #TAUTHOR_TAG, except that they use parallel data']","['', 'our approach is similar to  #TAUTHOR_TAG, except that they use parallel data to train their extractors and abstractors.', 'in contrast, during training, we only assume access to example summaries s s s = { s s s 0,.., s s s m } without matching articles.', 'during testing, given an input article a a a = { a 0,..., a n } consisting of n sentences, our system is capable of generating a multi - sentence abstractive summary consisting of k sentences ( where k is a hyperparameter )']",3
"['preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287']","['preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287k / 11k / 11k pairs for training / validation / testing.', 'note that']","['the preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287']","['', 'we choose this dataset because it allows us to compare our approach to existing fully supervised methods and to measure the gap between unsupervised and supervised summarization.', 'we follow the preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287k / 11k / 11k pairs for training / validation / testing.', 'note that our method relies only on the bullet - point summaries from this training set.', 'obtaining synthetic data.', 'to obtain training data for our sentence abstractor p pm, we follow the procedure from section 3. 2.', 'we align all summaries from the cnn / dm training set to 8. 5m news articles from the gigaword dataset  #AUTHOR_TAG, which contains no articles from cnn or daily mail.', '']",3
"['hierarchical model from  #TAUTHOR_TAG, consisting of']","['hierarchical model from  #TAUTHOR_TAG, consisting of']","['abs is the hierarchical model from  #TAUTHOR_TAG, consisting of a supervised lstm extractor']",[' #TAUTHOR_TAG'],3
"['is similar to  #TAUTHOR_TAG, except that they use parallel data']","['is similar to  #TAUTHOR_TAG, except that they use parallel data']","['is similar to  #TAUTHOR_TAG, except that they use parallel data']","['', 'our approach is similar to  #TAUTHOR_TAG, except that they use parallel data to train their extractors and abstractors.', 'in contrast, during training, we only assume access to example summaries s s s = { s s s 0,.., s s s m } without matching articles.', 'during testing, given an input article a a a = { a 0,..., a n } consisting of n sentences, our system is capable of generating a multi - sentence abstractive summary consisting of k sentences ( where k is a hyperparameter )']",4
"['hierarchical model from  #TAUTHOR_TAG, consisting of']","['hierarchical model from  #TAUTHOR_TAG, consisting of']","['abs is the hierarchical model from  #TAUTHOR_TAG, consisting of a supervised lstm extractor']",[' #TAUTHOR_TAG'],4
"['preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287']","['preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287k / 11k / 11k pairs for training / validation / testing.', 'note that']","['the preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287']","['', 'we choose this dataset because it allows us to compare our approach to existing fully supervised methods and to measure the gap between unsupervised and supervised summarization.', 'we follow the preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287k / 11k / 11k pairs for training / validation / testing.', 'note that our method relies only on the bullet - point summaries from this training set.', 'obtaining synthetic data.', 'to obtain training data for our sentence abstractor p pm, we follow the procedure from section 3. 2.', 'we align all summaries from the cnn / dm training set to 8. 5m news articles from the gigaword dataset  #AUTHOR_TAG, which contains no articles from cnn or daily mail.', '']",5
"['preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287']","['preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287k / 11k / 11k pairs for training / validation / testing.', 'note that']","['the preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287']","['', 'we choose this dataset because it allows us to compare our approach to existing fully supervised methods and to measure the gap between unsupervised and supervised summarization.', 'we follow the preprocessing pipeline of  #TAUTHOR_TAG, splitting the dataset into 287k / 11k / 11k pairs for training / validation / testing.', 'note that our method relies only on the bullet - point summaries from this training set.', 'obtaining synthetic data.', 'to obtain training data for our sentence abstractor p pm, we follow the procedure from section 3. 2.', 'we align all summaries from the cnn / dm training set to 8. 5m news articles from the gigaword dataset  #AUTHOR_TAG, which contains no articles from cnn or daily mail.', '']",5
"['hierarchical model from  #TAUTHOR_TAG, consisting of']","['hierarchical model from  #TAUTHOR_TAG, consisting of']","['abs is the hierarchical model from  #TAUTHOR_TAG, consisting of a supervised lstm extractor']",[' #TAUTHOR_TAG'],5
"['code - switched version ( hinglish ) of the two  #TAUTHOR_TAG.', 'this is']","['code - switched version ( hinglish ) of the two  #TAUTHOR_TAG.', 'this is']","['##n.', 'specifically, in the indian subcontinent, number of internet users has crossed 500 mi 1, and is rising rapidly due to inexpensive data 2.', 'with this rise, comes the problem of hate speech, offensive and abusive posts on social media.', 'although there are many previous works which deal with hindi and english hate speech ( the top two languages in india ), but very few on the code - switched version ( hinglish ) of the two  #TAUTHOR_TAG.', 'this is partially']","['the penetration of internet among masses, the content being posted on social media channels has uptaken.', 'specifically, in the indian subcontinent, number of internet users has crossed 500 mi 1, and is rising rapidly due to inexpensive data 2.', 'with this rise, comes the problem of hate speech, offensive and abusive posts on social media.', 'although there are many previous works which deal with hindi and english hate speech ( the top two languages in india ), but very few on the code - switched version ( hinglish ) of the two  #TAUTHOR_TAG.', 'this is partially due to the following reasons : ( i ) hinglish consists of no - fixed grammar and vocabulary.', '']",1
"['code - switched version ( hinglish ) of the two  #TAUTHOR_TAG.', 'this is']","['code - switched version ( hinglish ) of the two  #TAUTHOR_TAG.', 'this is']","['##n.', 'specifically, in the indian subcontinent, number of internet users has crossed 500 mi 1, and is rising rapidly due to inexpensive data 2.', 'with this rise, comes the problem of hate speech, offensive and abusive posts on social media.', 'although there are many previous works which deal with hindi and english hate speech ( the top two languages in india ), but very few on the code - switched version ( hinglish ) of the two  #TAUTHOR_TAG.', 'this is partially']","['the penetration of internet among masses, the content being posted on social media channels has uptaken.', 'specifically, in the indian subcontinent, number of internet users has crossed 500 mi 1, and is rising rapidly due to inexpensive data 2.', 'with this rise, comes the problem of hate speech, offensive and abusive posts on social media.', 'although there are many previous works which deal with hindi and english hate speech ( the top two languages in india ), but very few on the code - switched version ( hinglish ) of the two  #TAUTHOR_TAG.', 'this is partially due to the following reasons : ( i ) hinglish consists of no - fixed grammar and vocabulary.', '']",4
['on ( davidson et al. 2017 ) ) with two types of embeddings in comparison to the models by  #TAUTHOR_TAG and ( davidson et al. 2017 ) on the heot'],['on ( davidson et al. 2017 ) ) with two types of embeddings in comparison to the models by  #TAUTHOR_TAG and ( davidson et al. 2017 ) on the heot'],"['on ( davidson et al. 2017 ) ) with two types of embeddings in comparison to the models by  #TAUTHOR_TAG and ( davidson et al. 2017 ) on the heot dataset averaged over three runs.', 'we also compare']","['the heot and ( davidson et al. 2017 ) datasets contain tweets which are annotated in three categories : offensive, abusive and none ( or benign ).', 'some examples from the dataset are shown in table 2.', 'we use a lstm based classifier model for training our model to classify these tweets into these three categories.', 'an overview of the model is given in the figure 1.', 'the model consists of one layer of lstm followed by three dense layers.', 'the lstm layer uses a dropout value of 0. 2.', 'categorical crossentropy loss was used for the last layer due to the presence of multiple classes.', 'we use adam optimizer along with l2 regularisation to prevent overfitting.', 'as indicated by the figure 1, the model was initially trained on the dataset provided by ( davidson et al. 2017 ), and then re - trained on the heot dataset so as to benefit from the transfer of learned features in the last stage.', 'the model hyperparameters were experimentally selected by trying out a large number of combinations through grid search.', 'results table 3 shows the performance of our model ( after getting trained on ( davidson et al. 2017 ) ) with two types of embeddings in comparison to the models by  #TAUTHOR_TAG and ( davidson et al. 2017 ) on the heot dataset averaged over three runs.', 'we also compare results on pre - trained embeddings.', 'as shown in the table, our model when given glove embeddings performs better than all other models.', 'for comparison purposes, in table 4 we have also evaluated our results on the dataset by ( davidson et al. 2017 )']",4
"['by  #TAUTHOR_TAG.', 'the datasets obtained']","['by  #TAUTHOR_TAG.', 'the datasets obtained']","['by  #TAUTHOR_TAG.', 'the datasets obtained']","['this work, we use the datasets released by ( davidson et al. 2017 ) and heot dataset provided by  #TAUTHOR_TAG.', 'the datasets obtained pass through these steps of processing : ( i ) removal of punctuatios, stopwords, urls, numbers, emoticons, etc.', 'this was then followed by transliteration using the xlit - crowd conversion dictionary 3 and translation of each word to english using hindi to english dictionary 4.', 'to deal with the spelling variations, we manually added some common variations of popular hinglish words.', 'final dictionary comprised of 7200 word pairs.', 'additionally, to deal with profane words, which are not present in xlit - crowd, we had to make a profanity dictionary ( with 209 profane words ) as well.', 'table 1 gives some examples from the dictionary']",5
"[',, 2018  #TAUTHOR_TAG']","[', 2018  #TAUTHOR_TAG']","[', 2018  #TAUTHOR_TAG.', 'such approaches']","['embeddings are a crucial component in many nlp approaches  #AUTHOR_TAG since they capture latent semantics of words and thus allow models to better train and generalize.', 'recent work has moved away from the original "" one word, one embedding "" paradigm to investigate contextualized embedding models  #AUTHOR_TAG ( peters et al.,, 2018  #TAUTHOR_TAG.', 'such approaches produce different embeddings for the same word depending on its context and are thus capable of capturing latent contextualized semantics of ambiguous words.', 'recently,  #TAUTHOR_TAG proposed a character - level contextualized embeddings ap - context.', '']",0
"[',, 2018  #TAUTHOR_TAG']","[', 2018  #TAUTHOR_TAG']","[', 2018  #TAUTHOR_TAG.', 'such approaches']","['embeddings are a crucial component in many nlp approaches  #AUTHOR_TAG since they capture latent semantics of words and thus allow models to better train and generalize.', 'recent work has moved away from the original "" one word, one embedding "" paradigm to investigate contextualized embedding models  #AUTHOR_TAG ( peters et al.,, 2018  #TAUTHOR_TAG.', 'such approaches produce different embeddings for the same word depending on its context and are thus capable of capturing latent contextualized semantics of ambiguous words.', 'recently,  #TAUTHOR_TAG proposed a character - level contextualized embeddings ap - context.', '']",0
['outlined in  #TAUTHOR_TAG'],['outlined in  #TAUTHOR_TAG'],['outlined in  #TAUTHOR_TAG'],"['use the open source flair framework in all our experiments.', 'it implements the standard bilstm - crf sequence labeling architecture  #AUTHOR_TAG and includes pre - trained contextual string embeddings for many languages.', 'to flair, we add an implementation of our proposed pooled contextualized embeddings.', 'hyperparameters.', 'for our experiments, we follow the training and evaluation procedure outlined in  #TAUTHOR_TAG and follow most hyperparameter suggestions as given by the in - depth study presented in  #AUTHOR_TAG.', 'that is, we use an lstm with 256 hidden states and one layer  #AUTHOR_TAG, a locked dropout value of 0. 5, a word dropout of 0. 05, and train using sgd with an annealing rate of 0. 5 and a patience of 3.', 'we perform model selection over the learning rate ∈ { 0. 01, 0. 05, 0. 1 } and mini - batch size ∈ { 8, 16, 32 }, choosing the model with the best f - measure on the validation set.', ' #AUTHOR_TAG, we then repeat the experiment 5 times with different random seeds, and train using both train and development set, reporting both average performance and standard deviation over these runs on the test set as final performance.', 'standard word embeddings.', 'the default setup of  #TAUTHOR_TAG recommends contextual string embeddings to be used in combination with standard word embeddings.', '']",0
"[',, 2018  #TAUTHOR_TAG']","[', 2018  #TAUTHOR_TAG']","[', 2018  #TAUTHOR_TAG.', 'such approaches']","['embeddings are a crucial component in many nlp approaches  #AUTHOR_TAG since they capture latent semantics of words and thus allow models to better train and generalize.', 'recent work has moved away from the original "" one word, one embedding "" paradigm to investigate contextualized embedding models  #AUTHOR_TAG ( peters et al.,, 2018  #TAUTHOR_TAG.', 'such approaches produce different embeddings for the same word depending on its context and are thus capable of capturing latent contextualized semantics of ambiguous words.', 'recently,  #TAUTHOR_TAG proposed a character - level contextualized embeddings ap - context.', '']",1
['sentence context ( see  #TAUTHOR_TAG'],['sentence context ( see  #TAUTHOR_TAG'],['sentence context ( see  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],5
['sentence context ( see  #TAUTHOR_TAG'],['sentence context ( see  #TAUTHOR_TAG'],['sentence context ( see  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],5
['outlined in  #TAUTHOR_TAG'],['outlined in  #TAUTHOR_TAG'],['outlined in  #TAUTHOR_TAG'],"['use the open source flair framework in all our experiments.', 'it implements the standard bilstm - crf sequence labeling architecture  #AUTHOR_TAG and includes pre - trained contextual string embeddings for many languages.', 'to flair, we add an implementation of our proposed pooled contextualized embeddings.', 'hyperparameters.', 'for our experiments, we follow the training and evaluation procedure outlined in  #TAUTHOR_TAG and follow most hyperparameter suggestions as given by the in - depth study presented in  #AUTHOR_TAG.', 'that is, we use an lstm with 256 hidden states and one layer  #AUTHOR_TAG, a locked dropout value of 0. 5, a word dropout of 0. 05, and train using sgd with an annealing rate of 0. 5 and a patience of 3.', 'we perform model selection over the learning rate ∈ { 0. 01, 0. 05, 0. 1 } and mini - batch size ∈ { 8, 16, 32 }, choosing the model with the best f - measure on the validation set.', ' #AUTHOR_TAG, we then repeat the experiment 5 times with different random seeds, and train using both train and development set, reporting both average performance and standard deviation over these runs on the test set as final performance.', 'standard word embeddings.', 'the default setup of  #TAUTHOR_TAG recommends contextual string embeddings to be used in combination with standard word embeddings.', '']",5
['outlined in  #TAUTHOR_TAG'],['outlined in  #TAUTHOR_TAG'],['outlined in  #TAUTHOR_TAG'],"['use the open source flair framework in all our experiments.', 'it implements the standard bilstm - crf sequence labeling architecture  #AUTHOR_TAG and includes pre - trained contextual string embeddings for many languages.', 'to flair, we add an implementation of our proposed pooled contextualized embeddings.', 'hyperparameters.', 'for our experiments, we follow the training and evaluation procedure outlined in  #TAUTHOR_TAG and follow most hyperparameter suggestions as given by the in - depth study presented in  #AUTHOR_TAG.', 'that is, we use an lstm with 256 hidden states and one layer  #AUTHOR_TAG, a locked dropout value of 0. 5, a word dropout of 0. 05, and train using sgd with an annealing rate of 0. 5 and a patience of 3.', 'we perform model selection over the learning rate ∈ { 0. 01, 0. 05, 0. 1 } and mini - batch size ∈ { 8, 16, 32 }, choosing the model with the best f - measure on the validation set.', ' #AUTHOR_TAG, we then repeat the experiment 5 times with different random seeds, and train using both train and development set, reporting both average performance and standard deviation over these runs on the test set as final performance.', 'standard word embeddings.', 'the default setup of  #TAUTHOR_TAG recommends contextual string embeddings to be used in combination with standard word embeddings.', '']",5
['outlined in  #TAUTHOR_TAG'],['outlined in  #TAUTHOR_TAG'],['outlined in  #TAUTHOR_TAG'],"['use the open source flair framework in all our experiments.', 'it implements the standard bilstm - crf sequence labeling architecture  #AUTHOR_TAG and includes pre - trained contextual string embeddings for many languages.', 'to flair, we add an implementation of our proposed pooled contextualized embeddings.', 'hyperparameters.', 'for our experiments, we follow the training and evaluation procedure outlined in  #TAUTHOR_TAG and follow most hyperparameter suggestions as given by the in - depth study presented in  #AUTHOR_TAG.', 'that is, we use an lstm with 256 hidden states and one layer  #AUTHOR_TAG, a locked dropout value of 0. 5, a word dropout of 0. 05, and train using sgd with an annealing rate of 0. 5 and a patience of 3.', 'we perform model selection over the learning rate ∈ { 0. 01, 0. 05, 0. 1 } and mini - batch size ∈ { 8, 16, 32 }, choosing the model with the best f - measure on the validation set.', ' #AUTHOR_TAG, we then repeat the experiment 5 times with different random seeds, and train using both train and development set, reporting both average performance and standard deviation over these runs on the test set as final performance.', 'standard word embeddings.', 'the default setup of  #TAUTHOR_TAG recommends contextual string embeddings to be used in combination with standard word embeddings.', '']",5
['outlined in  #TAUTHOR_TAG'],['outlined in  #TAUTHOR_TAG'],['outlined in  #TAUTHOR_TAG'],"['use the open source flair framework in all our experiments.', 'it implements the standard bilstm - crf sequence labeling architecture  #AUTHOR_TAG and includes pre - trained contextual string embeddings for many languages.', 'to flair, we add an implementation of our proposed pooled contextualized embeddings.', 'hyperparameters.', 'for our experiments, we follow the training and evaluation procedure outlined in  #TAUTHOR_TAG and follow most hyperparameter suggestions as given by the in - depth study presented in  #AUTHOR_TAG.', 'that is, we use an lstm with 256 hidden states and one layer  #AUTHOR_TAG, a locked dropout value of 0. 5, a word dropout of 0. 05, and train using sgd with an annealing rate of 0. 5 and a patience of 3.', 'we perform model selection over the learning rate ∈ { 0. 01, 0. 05, 0. 1 } and mini - batch size ∈ { 8, 16, 32 }, choosing the model with the best f - measure on the validation set.', ' #AUTHOR_TAG, we then repeat the experiment 5 times with different random seeds, and train using both train and development set, reporting both average performance and standard deviation over these runs on the test set as final performance.', 'standard word embeddings.', 'the default setup of  #TAUTHOR_TAG recommends contextual string embeddings to be used in combination with standard word embeddings.', '']",3
"['task  #TAUTHOR_TAG,']","['2013 multilingual wsd task  #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['a decade ago,  #AUTHOR_TAG suggested the promising potential for wsd that could exploit the interdependencies between senses in an interactive manner.', 'in other words, this would be a wsd system which allows the disambiguation of word a to directly influence the consecutive disambiguation of word b. this is analogous to treating wsd as a deterministic problem, much like the sudoku puzzle in which the final solution is reached by adhering to a set of pre - determined constraints.', 'conventional approaches to wsd often overlook the potential to exploit sense interdependencies, and simply disambiguate all senses in one pass based on a context window ( e. g. a sentence or document ).', 'for this task the author proposes an iterative approach which makes several passes based on a set of constraints.', 'for a more formal distinction between the conventional and iterative approach to wsd, please refer to this paper  #AUTHOR_TAG table 1 : parts of speech disambiguated ( as percentages ) for each semeval task ( denoted by its year ).', 'in - degree centrality as implemented in  #AUTHOR_TAG observes f - score improvement ( f + ∆f ) by applying the iterative approach.', 'the author found in the investigations of his thesis  #AUTHOR_TAG that the iterative approach performed best on the semeval 2013 multilingual wsd task  #TAUTHOR_TAG, as opposed to earlier tasks such as senseval 2004 english all words wsd task  #AUTHOR_TAG and the semeval 2010 all words wsd task on a specific domain  #AUTHOR_TAG.', 'while these earlier tasks also experienced improvement, f - scores remained lower overall.', 'table 1 depicted above are distributions for each domain and language, detailing the probability ( y - axis ) of specific parts of speech at increasing degrees of polysemy ( x - axis ).', 'these distributions were produced from the gold keys ( or synsets ) of the test documents by querying babelnet for the polysemy of each word.', 'each distribution was normalised with one sense per discourse assumed, therefore duplicate synsets were ignored.', 'lastly the difference in f - score between the conventional run1 and the iterative run2 and run3 is listed beside each distribution.', 'firstly wsd tasks before 2013 generally relied on only a lexicon, such as wordnet  #AUTHOR_TAG or an alternative equivalent, whereas semeval 2013 task 12 wsd and this task  #AUTHOR_TAG included entity linking ( el ) using the encyclopaedia wikipedia via babelnet  #AUTHOR_TAG.', 'secondly, as shown by  #AUTHOR_TAG with a simple linear regression, the iterative approach increases wsd performance for documents that have a higher degree of document monosemy - the percentage']",0
['task  #TAUTHOR_TAG team umcc dlsi  #AUTHOR_TAG implemented this method and achieved the best'],['wsd task  #TAUTHOR_TAG team umcc dlsi  #AUTHOR_TAG implemented this method and achieved the best'],"['.', 'in the previous semeval wsd task  #TAUTHOR_TAG team umcc dlsi  #AUTHOR_TAG implemented this method and achieved the best performance by']","['', 'this idea is taken from personalised pagerank ( ppr )  #AUTHOR_TAG, which applies the method put forward by  #AUTHOR_TAG to the field of wsd.', 'in the previous semeval wsd task  #TAUTHOR_TAG team umcc dlsi  #AUTHOR_TAG implemented this method and achieved the best performance by biasing probability mass based on semcor  #AUTHOR_TAG sense frequencies.', 'as the winning method for this task, ppr was selected to test the iterative approach on.', ""for sudoku's implementation to be unsupervised, all runs biased probability mass towards senses from monosemous lemmas."", 'additionally for run2 and run3, once a lemma is disambiguated it is considered to be monosemous.', 'therefore with each iteration of run2 and run3, probability mass is redistributed across the surfing vector to acknowledge these newly appointed monosemous lemmas.', 'all system runs are applied at the document level, across all languages and domains, for all named entities, nouns, verbs, adverbs, and adjectives.', 'semantic subgraphs are constructed from babelnet via a depth first search ( dfs ) up to 2 hops in path length.', ""pagerank's damping factor is set to 0. 85, with a maximum of 30 iterations 1."", 'in order to avoid masking the effect of using the iterative approach, a back - off strategy ( see ( mc  #AUTHOR_TAG ) was not used.', 'multiword units were found by finding lemma sequences that contained at least one noun and at the same time could return a result from babelnet.', 'lemma sequences beginning with definite / indefinite articles ( e. g. the, a, il, la, and el ) were']",0
"['##ed to lexicographic sorting in the absence of wordnet syn', '##sets - see  #TAUTHOR_TAG']","['##ed to lexicographic sorting in the absence of wordnet syn', '##sets - see  #TAUTHOR_TAG']","['##ed to lexicographic sorting in the absence of wordnet syn', ""##sets - see  #TAUTHOR_TAG. the author's baseline - independent submissions were unaffected by this, which on reviewing results"", 'in  #AUTHOR_TAG appears to have helped sudoku do best for these languages. table 3 :', 'f1 scores for each domain / language for sudoku and limsi. in summary, the inclusion of named entities in disambiguation tasks certainly improves', 'results, as']","['', ""while remaining with the conventional approach on others. to the right in table 3 the author's sudoku runs are compared against the team with the most competitive results - limsi. the author could not improve on their superior results achieved in english, however for spanish"", 'and italian the babelnet first sense ( bfs ) baseline was much lower since it often', 'resorted to lexicographic sorting in the absence of wordnet syn', ""##sets - see  #TAUTHOR_TAG. the author's baseline - independent submissions were unaffected by this, which on reviewing results"", 'in  #AUTHOR_TAG appears to have helped sudoku do best for these languages. table 3 :', 'f1 scores for each domain / language for sudoku and limsi. in summary, the inclusion of named entities in disambiguation tasks certainly improves', 'results, as well as the effectiveness of the iterative approach. furthermore in table 3 above, the iterative run3 for the english biomedical domain is', '0. 1 short of achieving the best result of 71. 3. investigating exactly which factors contributed to the success of this unsupervised result is a top priority for future work']",0
"[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","['to improve both speech synthesis and broader inference tasks. different from', '[  #TAUTHOR_TAG ], in [ 7 ], the authors propose a supervised approach based on adversarial training [ 11, 12, 13, 14 ] ( illustrated in figure 2 ( left ) ). in addition to a regular autoencoder, the authors add a regularization term in its objective function to force the latent variables (', 'i. e., the encoding ) to not contain speaker information. this is done by introducing an auxiliary speaker verification classifier c. c is trained to correctly identify the speaker y from the latent variables z (', 'i. e., minimizing the misclassification loss lc = −logp ( y | z ) ), while the encoder is trained to maximize lc, i. e., to avoid encoding speaker information in z. both z and speaker label y are fed', '']",5
"[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","['to improve both speech synthesis and broader inference tasks. different from', '[  #TAUTHOR_TAG ], in [ 7 ], the authors propose a supervised approach based on adversarial training [ 11, 12, 13, 14 ] ( illustrated in figure 2 ( left ) ). in addition to a regular autoencoder, the authors add a regularization term in its objective function to force the latent variables (', 'i. e., the encoding ) to not contain speaker information. this is done by introducing an auxiliary speaker verification classifier c. c is trained to correctly identify the speaker y from the latent variables z (', 'i. e., minimizing the misclassification loss lc = −logp ( y | z ) ), while the encoder is trained to maximize lc, i. e., to avoid encoding speaker information in z. both z and speaker label y are fed', '']",0
"[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","['to improve both speech synthesis and broader inference tasks. different from', '[  #TAUTHOR_TAG ], in [ 7 ], the authors propose a supervised approach based on adversarial training [ 11, 12, 13, 14 ] ( illustrated in figure 2 ( left ) ). in addition to a regular autoencoder, the authors add a regularization term in its objective function to force the latent variables (', 'i. e., the encoding ) to not contain speaker information. this is done by introducing an auxiliary speaker verification classifier c. c is trained to correctly identify the speaker y from the latent variables z (', 'i. e., minimizing the misclassification loss lc = −logp ( y | z ) ), while the encoder is trained to maximize lc, i. e., to avoid encoding speaker information in z. both z and speaker label y are fed', '']",0
"[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","['to improve both speech synthesis and broader inference tasks. different from', '[  #TAUTHOR_TAG ], in [ 7 ], the authors propose a supervised approach based on adversarial training [ 11, 12, 13, 14 ] ( illustrated in figure 2 ( left ) ). in addition to a regular autoencoder, the authors add a regularization term in its objective function to force the latent variables (', 'i. e., the encoding ) to not contain speaker information. this is done by introducing an auxiliary speaker verification classifier c. c is trained to correctly identify the speaker y from the latent variables z (', 'i. e., minimizing the misclassification loss lc = −logp ( y | z ) ), while the encoder is trained to maximize lc, i. e., to avoid encoding speaker information in z. both z and speaker label y are fed', '']",0
"[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","['to improve both speech synthesis and broader inference tasks. different from', '[  #TAUTHOR_TAG ], in [ 7 ], the authors propose a supervised approach based on adversarial training [ 11, 12, 13, 14 ] ( illustrated in figure 2 ( left ) ). in addition to a regular autoencoder, the authors add a regularization term in its objective function to force the latent variables (', 'i. e., the encoding ) to not contain speaker information. this is done by introducing an auxiliary speaker verification classifier c. c is trained to correctly identify the speaker y from the latent variables z (', 'i. e., minimizing the misclassification loss lc = −logp ( y | z ) ), while the encoder is trained to maximize lc, i. e., to avoid encoding speaker information in z. both z and speaker label y are fed', '']",0
"[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","[' #TAUTHOR_TAG ], in']","['to improve both speech synthesis and broader inference tasks. different from', '[  #TAUTHOR_TAG ], in [ 7 ], the authors propose a supervised approach based on adversarial training [ 11, 12, 13, 14 ] ( illustrated in figure 2 ( left ) ). in addition to a regular autoencoder, the authors add a regularization term in its objective function to force the latent variables (', 'i. e., the encoding ) to not contain speaker information. this is done by introducing an auxiliary speaker verification classifier c. c is trained to correctly identify the speaker y from the latent variables z (', 'i. e., minimizing the misclassification loss lc = −logp ( y | z ) ), while the encoder is trained to maximize lc, i. e., to avoid encoding speaker information in z. both z and speaker label y are fed', '']",4
"[' #TAUTHOR_TAG, 7 ]']","[' #TAUTHOR_TAG, 7 ]']","[' #TAUTHOR_TAG, 7 ]']",[' #TAUTHOR_TAG'],4
"['ncm is too simple to capture more complicated language structure.', 'in order to alleviate this problem, we follow  #TAUTHOR_TAG by training lms on different corpora, but we apply']","['ncm is too simple to capture more complicated language structure.', 'in order to alleviate this problem, we follow  #TAUTHOR_TAG by training lms on different corpora, but we apply state - ofthe - art recurrent']","['a bigram lm.', 'the bigram lm within the ncm is too simple to capture more complicated language structure.', 'in order to alleviate this problem, we follow  #TAUTHOR_TAG by training lms on different corpora, but we apply']","['language model of the ncm evaluates the fluency of the sentence with disfluency removed.', 'the language model is expected to assign a very high probability to a fluent sentence x ( e. g. a flight to denver ) and a lower probability to a sentence y which still contains disfluency ( e. g. a flight to boston uh i mean to denver ).', 'however, it is computationally complex to use an effective language model within the ncm.', 'the reason is the polynomial - time dynamic programming parsing algorithms of tag can be used to search for likely repairs if they are used with simple language models such as a bigram lm.', 'the bigram lm within the ncm is too simple to capture more complicated language structure.', 'in order to alleviate this problem, we follow  #TAUTHOR_TAG by training lms on different corpora, but we apply state - ofthe - art recurrent neural network ( rnn ) language models']",6
"['proposed by.', 'we use the feature set introduced by  #TAUTHOR_TAG, but instead of n - gram scores,']","['proposed by.', 'we use the feature set introduced by  #TAUTHOR_TAG, but instead of n - gram scores,']","['order to rank the the 25 - best candidate disfluency analyses of the ncm and select the most suitable one, we apply the maxent reranker proposed by.', 'we use the feature set introduced by  #TAUTHOR_TAG, but instead of n - gram scores,']","['order to rank the the 25 - best candidate disfluency analyses of the ncm and select the most suitable one, we apply the maxent reranker proposed by.', 'we use the feature set introduced by  #TAUTHOR_TAG, but instead of n - gram scores, we apply the lstm language model probabilities.', 'the features are so good that the reranker without any external language model is already a state - of - the - art system, providing a very strong baseline for our work.', 'the reranker uses both model - based scores ( including ncm scores and lm probabilities ) and surface pattern features ( which are boolean indicators ) as described in table 1.', 'our reranker optimizes the expected f - score approximation described in  #TAUTHOR_TAG with l2 regularisation']",6
"['proposed by.', 'we use the feature set introduced by  #TAUTHOR_TAG, but instead of n - gram scores,']","['proposed by.', 'we use the feature set introduced by  #TAUTHOR_TAG, but instead of n - gram scores,']","['order to rank the the 25 - best candidate disfluency analyses of the ncm and select the most suitable one, we apply the maxent reranker proposed by.', 'we use the feature set introduced by  #TAUTHOR_TAG, but instead of n - gram scores,']","['order to rank the the 25 - best candidate disfluency analyses of the ncm and select the most suitable one, we apply the maxent reranker proposed by.', 'we use the feature set introduced by  #TAUTHOR_TAG, but instead of n - gram scores, we apply the lstm language model probabilities.', 'the features are so good that the reranker without any external language model is already a state - of - the - art system, providing a very strong baseline for our work.', 'the reranker uses both model - based scores ( including ncm scores and lm probabilities ) and surface pattern features ( which are boolean indicators ) as described in table 1.', 'our reranker optimizes the expected f - score approximation described in  #TAUTHOR_TAG with l2 regularisation']",5
"['the fluent sentence itself is part of the language model  #TAUTHOR_TAG.', 'as a solution,']","['the fluent sentence itself is part of the language model  #TAUTHOR_TAG.', 'as a solution,']","['the fluent sentence itself is part of the language model  #TAUTHOR_TAG.', 'as a solution,']","['', 'sum of the log lm probability & the log channel model probability plus number of edits in the sentence 9.', 'channel model probability  #AUTHOR_TAG.', 'weight related to the lm features extracted from switchboard.', 'this is because the fluent sentence itself is part of the language model  #TAUTHOR_TAG.', 'as a solution, we apply a k - fold cross - validation ( k = 20 ) to train the lstm language models when using switchboard corpus.', 'we follow  #AUTHOR_TAG in splitting switchboard corpus into training, development and test set.', 'the training data consists of all sw [ 23 ] *. dps files, development training consists of all sw4 [ 5 - 9 ] *. dps files and test data consists of all sw4 [ 0 - 1 ] *. dps files.', 'following, we remove all partial words and punctuation from the training data.', 'although partial words are very strong indicators of disfluency, standard speech recognizers never produce them in their outputs, so this makes our evaluation both harder and more realistic']",5
"['the fluent sentence itself is part of the language model  #TAUTHOR_TAG.', 'as a solution,']","['the fluent sentence itself is part of the language model  #TAUTHOR_TAG.', 'as a solution,']","['the fluent sentence itself is part of the language model  #TAUTHOR_TAG.', 'as a solution,']","['', 'sum of the log lm probability & the log channel model probability plus number of edits in the sentence 9.', 'channel model probability  #AUTHOR_TAG.', 'weight related to the lm features extracted from switchboard.', 'this is because the fluent sentence itself is part of the language model  #TAUTHOR_TAG.', 'as a solution, we apply a k - fold cross - validation ( k = 20 ) to train the lstm language models when using switchboard corpus.', 'we follow  #AUTHOR_TAG in splitting switchboard corpus into training, development and test set.', 'the training data consists of all sw [ 23 ] *. dps files, development training consists of all sw4 [ 5 - 9 ] *. dps files and test data consists of all sw4 [ 0 - 1 ] *. dps files.', 'following, we remove all partial words and punctuation from the training data.', 'although partial words are very strong indicators of disfluency, standard speech recognizers never produce them in their outputs, so this makes our evaluation both harder and more realistic']",7
"[').', 'the example is taken from the simple english wikipedia corpus  #TAUTHOR_TAG connectives']","['', 'the example is taken from the simple english wikipedia corpus  #TAUTHOR_TAG connectives']","[').', 'the example is taken from the simple english wikipedia corpus  #TAUTHOR_TAG connectives do not belong to any linguistic class and except for a few discourse connectives']","['', 'the example is taken from the simple english wikipedia corpus  #TAUTHOR_TAG connectives do not belong to any linguistic class and except for a few discourse connectives such as oh and well, most carry meaning.', ' #AUTHOR_TAG revised this definition ; even though she agreed that discourse connectives have meaning by themselves, she argued that they should contribute to the semantic interpretations of the discourse.', 'apart from research efforts aiming at defining discourse connectives, another line of research has focused on providing a list of discourse connectives in english  #AUTHOR_TAG and other languages  #AUTHOR_TAG.', 'while most of these inventories have been built by hand, some work has attempted to identify them automatically.', ' #AUTHOR_TAG used the europal parallel corpus and collocation techniques to induce french connectives from their english counterparts.', 'following this work, hidey and mc  #AUTHOR_TAG built a parallel corpus of causal and non - causal altlexes using word alignment with pdtb discourse connectives as initial seeds.', 'our work is different from these as we use already existing parallel corpora in text simplification and extract discourse information automatically using the state of the art discourse parser.', 'in addition, instead of focusing on only one relation, we generalize the problem to all pdtb relations.', 'we also use external resources which are shown to have advantages over word alignment  #AUTHOR_TAG in similar tasks.', 'lastly, the pdtb altlexes only captures inter - sentence relations.', 'our contribution overcomes this limitation by identifying intra - sentence relations']",0
"['corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple']","['corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple']","['discover altlexes automatically, we created two sentence - aligned data sets using standard corpora in text simplification.', 'the first data set was created from the simple english wikipedia corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', '']","['discover altlexes automatically, we created two sentence - aligned data sets using standard corpora in text simplification.', 'the first data set was created from the simple english wikipedia corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple english wikipedia ( sew ) corpus  #TAUTHOR_TAG contains two sections : 1 ) article - aligned and 2 ) sentence - aligned.', 'here, we used the sentence - aligned section, which contains 167, 686 pairs of aligned sentences.', 'in order not to overfit to a specific corpus, we also used the newsela ( news ) corpus  #AUTHOR_TAG.', 'this corpus contains 1, 911 english news articles which have been manually re - written at most 5 times, each time with decreasing complexity level.', 'we used this article - aligned corpus to align it at the sentence - level using an approach similar to  #TAUTHOR_TAG.', 'then, two native english speakers evaluated the alignments.', 'the kappa inter - annotation agreement was 0. 898 computed on 100 randomly chosen alignments']",6
"['corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple']","['corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple']","['discover altlexes automatically, we created two sentence - aligned data sets using standard corpora in text simplification.', 'the first data set was created from the simple english wikipedia corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', '']","['discover altlexes automatically, we created two sentence - aligned data sets using standard corpora in text simplification.', 'the first data set was created from the simple english wikipedia corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple english wikipedia ( sew ) corpus  #TAUTHOR_TAG contains two sections : 1 ) article - aligned and 2 ) sentence - aligned.', 'here, we used the sentence - aligned section, which contains 167, 686 pairs of aligned sentences.', 'in order not to overfit to a specific corpus, we also used the newsela ( news ) corpus  #AUTHOR_TAG.', 'this corpus contains 1, 911 english news articles which have been manually re - written at most 5 times, each time with decreasing complexity level.', 'we used this article - aligned corpus to align it at the sentence - level using an approach similar to  #TAUTHOR_TAG.', 'then, two native english speakers evaluated the alignments.', 'the kappa inter - annotation agreement was 0. 898 computed on 100 randomly chosen alignments']",6
"['corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple']","['corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple']","['discover altlexes automatically, we created two sentence - aligned data sets using standard corpora in text simplification.', 'the first data set was created from the simple english wikipedia corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', '']","['discover altlexes automatically, we created two sentence - aligned data sets using standard corpora in text simplification.', 'the first data set was created from the simple english wikipedia corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple english wikipedia ( sew ) corpus  #TAUTHOR_TAG contains two sections : 1 ) article - aligned and 2 ) sentence - aligned.', 'here, we used the sentence - aligned section, which contains 167, 686 pairs of aligned sentences.', 'in order not to overfit to a specific corpus, we also used the newsela ( news ) corpus  #AUTHOR_TAG.', 'this corpus contains 1, 911 english news articles which have been manually re - written at most 5 times, each time with decreasing complexity level.', 'we used this article - aligned corpus to align it at the sentence - level using an approach similar to  #TAUTHOR_TAG.', 'then, two native english speakers evaluated the alignments.', 'the kappa inter - annotation agreement was 0. 898 computed on 100 randomly chosen alignments']",5
"['corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple']","['corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple']","['discover altlexes automatically, we created two sentence - aligned data sets using standard corpora in text simplification.', 'the first data set was created from the simple english wikipedia corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', '']","['discover altlexes automatically, we created two sentence - aligned data sets using standard corpora in text simplification.', 'the first data set was created from the simple english wikipedia corpus  #TAUTHOR_TAG ; the other was created from the newsela corpus  #AUTHOR_TAG.', 'the simple english wikipedia ( sew ) corpus  #TAUTHOR_TAG contains two sections : 1 ) article - aligned and 2 ) sentence - aligned.', 'here, we used the sentence - aligned section, which contains 167, 686 pairs of aligned sentences.', 'in order not to overfit to a specific corpus, we also used the newsela ( news ) corpus  #AUTHOR_TAG.', 'this corpus contains 1, 911 english news articles which have been manually re - written at most 5 times, each time with decreasing complexity level.', 'we used this article - aligned corpus to align it at the sentence - level using an approach similar to  #TAUTHOR_TAG.', 'then, two native english speakers evaluated the alignments.', 'the kappa inter - annotation agreement was 0. 898 computed on 100 randomly chosen alignments']",3
['to affect has been also exploited  #TAUTHOR_TAG ; hernandez'],['to affect has been also exploited  #TAUTHOR_TAG ; hernandez'],['to affect has been also exploited  #TAUTHOR_TAG ; hern'],"['use social media platforms as a forum to share and express themselves by using the language in creative ways and employing figurative language devices such as irony to achieve different communication purposes.', 'irony is closely associated with the indirect expression of feelings, emotions and evaluations, and detecting the presence of irony in social media texts is considered a challenge for research in computational linguistics, also for the impact on sentiment analysis, where irony detection is important to avoid misinterpreting the polarity of ironic statements.', 'broadly speaking, under the umbrella term of irony two main concepts are covered : verbal irony and situational irony.', 'verbal irony is commonly defined as a figure of speech where the speaker intends to communicate the opposite of what is literally said  #AUTHOR_TAG.', 'situational irony, instead refers to a contradictory or unexpected outcome of events  #AUTHOR_TAG.', 'in twitter we can find many examples both of verbal irony and of posts where users describe aspects of an ironic situation.', 'most of the proposed approaches to the automatic detection of irony in social media  #AUTHOR_TAG ptacek et al., 2014 ) take advantage of lexical factors such as n - grams, punctuation marks, among others.', 'information related to affect has been also exploited  #TAUTHOR_TAG ; hernandez farias et al., 2015 ).', 'other scholars proposed methods exploiting the context surrounding an ironic utterance  #AUTHOR_TAG.', 'recently, also deep learning techniques have been applied  #AUTHOR_TAG.', 'this paper describes our participation in the semeval - 2018 task 3.', 'the aim of this task is to identify ironic tweets.', 'valento exploited an extended version of emotidm, an irony detection model based mainly on affective information.', 'in particular, we experimented the use of a wide range of affectrelated features for characterizing the presence of ironic content, covering different facets of affect, from sentiment to finer - grained emotions.', 'most theorist  #AUTHOR_TAG alba -  #AUTHOR_TAG recognized, indeed, the important role of affective information for irony communication - comprehension']",0
[' #TAUTHOR_TAG ptace'],"[' #TAUTHOR_TAG ptacek et al., 2014 ;  #AUTHOR_TAG.', 'the']","['irony detection  #TAUTHOR_TAG ptacek et al., 2014 ;  #AUTHOR_TAG.', '']","['##y is a very subjective language device that involves the expression of affective contents such as emotions, attitudes, or evaluations towards a particular target.', 'attempting to take advantage of the emotionally - laden characteristics of ironic expressions, we relied on emotidm, an irony detection model that, taking advantage of several affective resources available for english  #AUTHOR_TAG, exploits various facets of affective information from sentiment to finer - grained emotions for characterizing the presence of irony in twitter.', 'in ) the robustness of emotidm was assessed over different twitter state - of - the - art corpora for irony detection  #TAUTHOR_TAG ptacek et al., 2014 ;  #AUTHOR_TAG.', '']",0
"['of sentipolc - 2014  #AUTHOR_TAG.', 'furthermore,  #TAUTHOR_TAG exploited a feature']","['of sentipolc - 2014  #AUTHOR_TAG.', 'furthermore,  #TAUTHOR_TAG exploited a feature']","['of sentipolc - 2014  #AUTHOR_TAG.', 'furthermore,  #TAUTHOR_TAG exploited a feature']","['decided to participate to the shared task by using emotidm.', 'by analyzing the training data, an interesting characteristic was found : 857 out of 3, 834 tweets contain an url.', 'from these tweets, 265 were belonging to the ironic class, while 592 were labeled as non - ironic.', 'notice that, in ( hernandez -  #AUTHOR_TAG, the authors found a similar behavior regarding url information in the dataset provided by the organizers of sentipolc - 2014  #AUTHOR_TAG.', 'furthermore,  #TAUTHOR_TAG exploited a feature for alerting the existence of an url in a tweet ; such feature was ranked among the most discriminative ones according to an information gain analysis.', 'since, information regarding to the presence of url in a tweet has proven to be useful for detecting irony in twitter, we decided to enrich emotidm by adding a binary feature for reflecting the presence of url in a tweet.', 'below, we describe our participation in the task']",0
"['between different kinds of ironic devices is still a controversial issue.', 'in computational linguistics, only few research works have attempted to address such a difficult task  #TAUTHOR_TAG.', 'we are interested in assessing the']","['between different kinds of ironic devices is still a controversial issue.', 'in computational linguistics, only few research works have attempted to address such a difficult task  #TAUTHOR_TAG.', 'we are interested in assessing the']","['between different kinds of ironic devices is still a controversial issue.', 'in computational linguistics, only few research works have attempted to address such a difficult task  #TAUTHOR_TAG.', 'we are interested in assessing the performance']","['between different kinds of ironic devices is still a controversial issue.', 'in computational linguistics, only few research works have attempted to address such a difficult task  #TAUTHOR_TAG.', 'we are interested in assessing the performance of emotidm when it deals with different types of irony, in order to test if a wide variety of affective features can help in discriminating also in the finer - grained classification task here proposed.', 'this could give some insights on the role of affective content among ironic devices having different communication purposes.', 'emotidm + url was trained with the dataset provided for task b ( constrained setting ) to test the effectiveness of affective features in such finergrained task.', '']",0
"[' #TAUTHOR_TAG,  #AUTHOR_TAG, ( ptace']","[' #TAUTHOR_TAG,  #AUTHOR_TAG, ( ptacek']","[' #TAUTHOR_TAG,  #AUTHOR_TAG, ( ptace']","['', 'we exploited data from a set of corpora collected exploiting different approaches : self - tagging or manual annotation or crowd - sourcing 3.', 'we exploited the corpora developed by  #AUTHOR_TAG,  #TAUTHOR_TAG,  #AUTHOR_TAG, ( ptacek et al., 2014 ),  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG, and  #AUTHOR_TAG.', 'besides, we also take advantage of an in - house collection of tweets containing the hashtags # irony and # sarcasm 4.', 'table 1 shows the obtained results during the developing phase for task a. we experimented with different sets of features and classifiers considering a five fold - cross validation setting.', 'svm emerges as the classifier with the best performance in both c and u scenarios.', 'we noticed that, when using svm, adding the url feature to emotidm helps to improve the overall performance of our system.', 'when we experimented by removing a set of features in emotidm, a drop in the performance ( in most of the cases ) is observed.', 'the results of the experiments with external data are higher than those using only the training data.', 'the last row in table 1 shows the obtained results when only affect - related features were used ; even though there is a drop in the performance respect to the experiments using structural features, it seems that affective features on their own provide useful information for irony detection.', 'we participated in the subtask a by submitting two runs ( constrained and unconstrained ) exploiting the experimental setting with the best performance : emotidm + url with a svm as classifier']",5
"['between different kinds of ironic devices is still a controversial issue.', 'in computational linguistics, only few research works have attempted to address such a difficult task  #TAUTHOR_TAG.', 'we are interested in assessing the']","['between different kinds of ironic devices is still a controversial issue.', 'in computational linguistics, only few research works have attempted to address such a difficult task  #TAUTHOR_TAG.', 'we are interested in assessing the']","['between different kinds of ironic devices is still a controversial issue.', 'in computational linguistics, only few research works have attempted to address such a difficult task  #TAUTHOR_TAG.', 'we are interested in assessing the performance']","['between different kinds of ironic devices is still a controversial issue.', 'in computational linguistics, only few research works have attempted to address such a difficult task  #TAUTHOR_TAG.', 'we are interested in assessing the performance of emotidm when it deals with different types of irony, in order to test if a wide variety of affective features can help in discriminating also in the finer - grained classification task here proposed.', 'this could give some insights on the role of affective content among ironic devices having different communication purposes.', 'emotidm + url was trained with the dataset provided for task b ( constrained setting ) to test the effectiveness of affective features in such finergrained task.', '']",1
"['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and']","['. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['work suggests that a large network is crucial to achieve the state - of - the - art', 'performance. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better performance. however,  #TAUTHOR_TAG stop at', 'a hidden layer size of 1024. albert  #AUTHOR_TAG showed that it is not the case that simply increasing the model size would lead to better accuracy.', 'in fact, they observed that simply increasing the hidden layer size of a model such as bert - large can lead to significantly worse performance. on the', 'other hand, model distillation  #AUTHOR_TAG has been proposed to reduce the bert model size while maintaining high performance. in', 'this paper, we attempt to improve the performance of bert via architecture enhancement. bert is based on the encoder of the transformer model  #AUTHOR_TAG, which has been proven to obtain state -', '']",0
"['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and']","['. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['work suggests that a large network is crucial to achieve the state - of - the - art', 'performance. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better performance. however,  #TAUTHOR_TAG stop at', 'a hidden layer size of 1024. albert  #AUTHOR_TAG showed that it is not the case that simply increasing the model size would lead to better accuracy.', 'in fact, they observed that simply increasing the hidden layer size of a model such as bert - large can lead to significantly worse performance. on the', 'other hand, model distillation  #AUTHOR_TAG has been proposed to reduce the bert model size while maintaining high performance. in', 'this paper, we attempt to improve the performance of bert via architecture enhancement. bert is based on the encoder of the transformer model  #AUTHOR_TAG, which has been proven to obtain state -', '']",0
"['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and']","['. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['work suggests that a large network is crucial to achieve the state - of - the - art', 'performance. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better performance. however,  #TAUTHOR_TAG stop at', 'a hidden layer size of 1024. albert  #AUTHOR_TAG showed that it is not the case that simply increasing the model size would lead to better accuracy.', 'in fact, they observed that simply increasing the hidden layer size of a model such as bert - large can lead to significantly worse performance. on the', 'other hand, model distillation  #AUTHOR_TAG has been proposed to reduce the bert model size while maintaining high performance. in', 'this paper, we attempt to improve the performance of bert via architecture enhancement. bert is based on the encoder of the transformer model  #AUTHOR_TAG, which has been proven to obtain state -', '']",0
"['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and']","['. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['work suggests that a large network is crucial to achieve the state - of - the - art', 'performance. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better performance. however,  #TAUTHOR_TAG stop at', 'a hidden layer size of 1024. albert  #AUTHOR_TAG showed that it is not the case that simply increasing the model size would lead to better accuracy.', 'in fact, they observed that simply increasing the hidden layer size of a model such as bert - large can lead to significantly worse performance. on the', 'other hand, model distillation  #AUTHOR_TAG has been proposed to reduce the bert model size while maintaining high performance. in', 'this paper, we attempt to improve the performance of bert via architecture enhancement. bert is based on the encoder of the transformer model  #AUTHOR_TAG, which has been proven to obtain state -', '']",0
"['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and']","['. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['work suggests that a large network is crucial to achieve the state - of - the - art', 'performance. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better performance. however,  #TAUTHOR_TAG stop at', 'a hidden layer size of 1024. albert  #AUTHOR_TAG showed that it is not the case that simply increasing the model size would lead to better accuracy.', 'in fact, they observed that simply increasing the hidden layer size of a model such as bert - large can lead to significantly worse performance. on the', 'other hand, model distillation  #AUTHOR_TAG has been proposed to reduce the bert model size while maintaining high performance. in', 'this paper, we attempt to improve the performance of bert via architecture enhancement. bert is based on the encoder of the transformer model  #AUTHOR_TAG, which has been proven to obtain state -', '']",1
"['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and']","['. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better']","['work suggests that a large network is crucial to achieve the state - of - the - art', 'performance. for example,  #TAUTHOR_TAG has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better performance. however,  #TAUTHOR_TAG stop at', 'a hidden layer size of 1024. albert  #AUTHOR_TAG showed that it is not the case that simply increasing the model size would lead to better accuracy.', 'in fact, they observed that simply increasing the hidden layer size of a model such as bert - large can lead to significantly worse performance. on the', 'other hand, model distillation  #AUTHOR_TAG has been proposed to reduce the bert model size while maintaining high performance. in', 'this paper, we attempt to improve the performance of bert via architecture enhancement. bert is based on the encoder of the transformer model  #AUTHOR_TAG, which has been proven to obtain state -', '']",1
"['loss objective, i. e., masked lm prediction and next sentence prediction, from the bert paper  #TAUTHOR_TAG']","['loss objective, i. e., masked lm prediction and next sentence prediction, from the bert paper  #TAUTHOR_TAG']","['. e., the embedding and positional encoding, and the same loss objective, i. e., masked lm prediction and next sentence prediction, from the bert paper  #TAUTHOR_TAG']","['', 'we used the same multi - head selfattention from the original paper  #AUTHOR_TAG.', 'we used the same input and output representations, i. e., the embedding and positional encoding, and the same loss objective, i. e., masked lm prediction and next sentence prediction, from the bert paper  #TAUTHOR_TAG']",5
"['the bert  #TAUTHOR_TAG,']","['the bert  #TAUTHOR_TAG,']","['the bert  #TAUTHOR_TAG, we use masked language model loss']","['the bert  #TAUTHOR_TAG, we use masked language model loss and next sentence prediction ( nsp ) loss to train the models.', 'the masked lm ( mlm ) is often referred to as a cloze task in the literature  #AUTHOR_TAG.', 'the encoder output, corresponding to the mask tokens, are fed into an output softmax over the vocabulary.', 'in our experiments, we randomly mask 15 % of all whole word wordpiece tokens in each sequence  #AUTHOR_TAG.', 'we also use the next sentence prediction loss as introduced in  #TAUTHOR_TAG to train our models.', 'specifically, when choosing the sentences a and b for each pre - training example, 50 % of the time b is the actual next sentence that follows a, and 50 % of the time it is a random sentence from the corpus.', 'we note that recent work  #AUTHOR_TAG a ;  #AUTHOR_TAG has argued that the nsp loss may not be useful in improving model accuracy.', 'nevertheless, we used the nsp loss in our experiments to have a fair comparison between the proposed models and the original bert models.', 'table 1 shows the model parameter size and training speedup for trans / bert ( trans and bert are exchangeable in this paper ), trans - blstm - small, and trans - blstm respectively.', 'here, the trans - blstm - small and trans - blstm models are 50 % and 100 % larger than the trans model ( base, large ) respec - tively.', '']",5
"['the bert  #TAUTHOR_TAG,']","['the bert  #TAUTHOR_TAG,']","['the bert  #TAUTHOR_TAG, we use masked language model loss']","['the bert  #TAUTHOR_TAG, we use masked language model loss and next sentence prediction ( nsp ) loss to train the models.', 'the masked lm ( mlm ) is often referred to as a cloze task in the literature  #AUTHOR_TAG.', 'the encoder output, corresponding to the mask tokens, are fed into an output softmax over the vocabulary.', 'in our experiments, we randomly mask 15 % of all whole word wordpiece tokens in each sequence  #AUTHOR_TAG.', 'we also use the next sentence prediction loss as introduced in  #TAUTHOR_TAG to train our models.', 'specifically, when choosing the sentences a and b for each pre - training example, 50 % of the time b is the actual next sentence that follows a, and 50 % of the time it is a random sentence from the corpus.', 'we note that recent work  #AUTHOR_TAG a ;  #AUTHOR_TAG has argued that the nsp loss may not be useful in improving model accuracy.', 'nevertheless, we used the nsp loss in our experiments to have a fair comparison between the proposed models and the original bert models.', 'table 1 shows the model parameter size and training speedup for trans / bert ( trans and bert are exchangeable in this paper ), trans - blstm - small, and trans - blstm respectively.', 'here, the trans - blstm - small and trans - blstm models are 50 % and 100 % larger than the trans model ( base, large ) respec - tively.', '']",5
"['original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['masking setting, we are able to fairly', 'compare the proposed trans - blstm models to the original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['##x large trans / bert 334m 24 1024 1024 16 2. 8x trans - blstm - small 487m 24 1024 1024 16 1. 4x trans - blstm 789m 24 1024 1024 16 1 table 1', ': parameter size and training speed for trans / bert,', 'trans - blstm - small, and trans - blstm on base and large settings respectively. x 1 = x 11, x 12... and x 2 = x 21, x 22... are two segments. to reduce the training memory consumption, we set the maximum input length to 256 ( as opposed to 512 in the original bert paper ). we note that this setting may adversely affect the best accuracy we report in our paper 1, but the relative accuracy gain by the proposed models are still valid. similar to bert, we use a vocabulary size of 30k with wordpiece tokenization. we generate the masked input from the mlm targets using unigram masking, which is', 'denoted as whole word masking. that is, each masking applies to a whole word at one time. we note that using n - gram', 'masking ( for example, with n = 3 )  #AUTHOR_TAG with the length of each n - gram mask selected randomly can further improve the downstream', 'task accuracy ( for example, 2 % f1 score increase was observed on squad 1. 1 data set with n - gram masking and span boundary representation', 'prediction  #AUTHOR_TAG ). however, in the whole word masking setting, we are able to fairly', 'compare the proposed trans - blstm models to the original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '15 % of the token positions at random for making. if the i', '- th token is chosen, we replace the i - th token with ( 1 ) the [MASK] token 80 % of the time ( 2 ) a random token 10 % of the time ( 3 ) the unchanged i - th token 10 % of the time. the model updates use a batch size of 256 and adam optimizer with learning rate starting from', '1e - 4. training was done on a cluster of nodes, where each node consists of 8 nvidia tesla v100 gpus', '. we vary the node size from 1 to 8 depending on the model size. our trans - bl', '##stm is implemented on top of pytorch transformer repository 2. 1 nevertheless, our implementation of baseline bert model obtained higher accuracy than that reported by the original bert paper  #TAUTHOR_TAG. 2 https : / / github. com / huggingface / pytorch -', 'transformers']",5
"['original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['masking setting, we are able to fairly', 'compare the proposed trans - blstm models to the original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['##x large trans / bert 334m 24 1024 1024 16 2. 8x trans - blstm - small 487m 24 1024 1024 16 1. 4x trans - blstm 789m 24 1024 1024 16 1 table 1', ': parameter size and training speed for trans / bert,', 'trans - blstm - small, and trans - blstm on base and large settings respectively. x 1 = x 11, x 12... and x 2 = x 21, x 22... are two segments. to reduce the training memory consumption, we set the maximum input length to 256 ( as opposed to 512 in the original bert paper ). we note that this setting may adversely affect the best accuracy we report in our paper 1, but the relative accuracy gain by the proposed models are still valid. similar to bert, we use a vocabulary size of 30k with wordpiece tokenization. we generate the masked input from the mlm targets using unigram masking, which is', 'denoted as whole word masking. that is, each masking applies to a whole word at one time. we note that using n - gram', 'masking ( for example, with n = 3 )  #AUTHOR_TAG with the length of each n - gram mask selected randomly can further improve the downstream', 'task accuracy ( for example, 2 % f1 score increase was observed on squad 1. 1 data set with n - gram masking and span boundary representation', 'prediction  #AUTHOR_TAG ). however, in the whole word masking setting, we are able to fairly', 'compare the proposed trans - blstm models to the original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '15 % of the token positions at random for making. if the i', '- th token is chosen, we replace the i - th token with ( 1 ) the [MASK] token 80 % of the time ( 2 ) a random token 10 % of the time ( 3 ) the unchanged i - th token 10 % of the time. the model updates use a batch size of 256 and adam optimizer with learning rate starting from', '1e - 4. training was done on a cluster of nodes, where each node consists of 8 nvidia tesla v100 gpus', '. we vary the node size from 1 to 8 depending on the model size. our trans - bl', '##stm is implemented on top of pytorch transformer repository 2. 1 nevertheless, our implementation of baseline bert model obtained higher accuracy than that reported by the original bert paper  #TAUTHOR_TAG. 2 https : / / github. com / huggingface / pytorch -', 'transformers']",5
"[' #TAUTHOR_TAG a ;  #AUTHOR_TAG, we evaluate our models on the general language understanding']","[' #TAUTHOR_TAG a ;  #AUTHOR_TAG, we evaluate our models on the general language understanding']","['the previous work  #TAUTHOR_TAG a ;  #AUTHOR_TAG, we evaluate our models on the general language understanding evaluation (']","['the previous work  #TAUTHOR_TAG a ;  #AUTHOR_TAG, we evaluate our models on the general language understanding evaluation ( glue ) benchmark and the stanford question answering dataset ( squad 1. 1 )  #AUTHOR_TAG.', 'glue is the general language understanding evaluation benchmark consisting of a diverse collection of natural language understanding tasks.', 'glue is model - agnostic and the tasks are selected to incentivize the development of general and robust nlu systems.', '']",5
"['original bert - base model in  #TAUTHOR_TAG and our implementation, and the bidirectional ls']","['original bert - base model in  #TAUTHOR_TAG and our implementation, and the bidirectional lstm model accuracy over squad 1. 1 development dataset.', 'our implementation results in']","['the 12 transformer layers with 12 blstm layers.', 'table 2 shows the bert base models, including the original bert - base model in  #TAUTHOR_TAG and our implementation, and the bidirectional lstm model accuracy over squad 1. 1 development dataset.', 'our implementation results in']","['', 'that is, we replace the 12 transformer layers with 12 blstm layers.', 'table 2 shows the bert base models, including the original bert - base model in  #TAUTHOR_TAG and our implementation, and the bidirectional lstm model accuracy over squad 1. 1 development dataset.', '']",5
['f1 bert - base'],['f1 bert - base'],['f1 bert - base'],['f1 bert - base'],5
"[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for all glue tasks.', 'for each task, we selected the best fine - tuning learning rate ( among 5']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for all glue tasks.', 'for each task, we selected the best fine - tuning learning rate ( among 5e - 5, 4e - 5, 3e - 5, and 2e - 5 ) on the development set.', 'additionally similar to  #TAUTHOR_TAG, for large bert and trans - blstm models, we found that finetuning was sometimes unstable on small datasets, so we ran several random restarts and selected the best model on the development set.', 'table 5 shows the results of glue datasets for original bert  #TAUTHOR_TAG, ours trans / bert, trans - blstm - small and trans - blstm on base and large settings respectively.', 'following the bert setting  #TAUTHOR_TAG, we exclude the problematic wnli set.', 'f1 scores are reported for qqp and mrpc, spearman correlations are reported for sts - b, and accuracy scores are reported for the other tasks.', 'unlike the evaluation on squad dataset, we do not apply the blstm layer to the decoder.', 'this is because that the tasks on glue are classification tasks based on the [CLS] token, and are not sequential prediction tasks ( for example the squad dataset ) which may benefit more from including a blstm layer.', 'we note again the accuracy discrepancy between the original bert and our implementation of bert, which may be due to the fact that the former uses partial word masking while the later uses whole word masking.', '']",5
"[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for all glue tasks.', 'for each task, we selected the best fine - tuning learning rate ( among 5']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for all glue tasks.', 'for each task, we selected the best fine - tuning learning rate ( among 5e - 5, 4e - 5, 3e - 5, and 2e - 5 ) on the development set.', 'additionally similar to  #TAUTHOR_TAG, for large bert and trans - blstm models, we found that finetuning was sometimes unstable on small datasets, so we ran several random restarts and selected the best model on the development set.', 'table 5 shows the results of glue datasets for original bert  #TAUTHOR_TAG, ours trans / bert, trans - blstm - small and trans - blstm on base and large settings respectively.', 'following the bert setting  #TAUTHOR_TAG, we exclude the problematic wnli set.', 'f1 scores are reported for qqp and mrpc, spearman correlations are reported for sts - b, and accuracy scores are reported for the other tasks.', 'unlike the evaluation on squad dataset, we do not apply the blstm layer to the decoder.', 'this is because that the tasks on glue are classification tasks based on the [CLS] token, and are not sequential prediction tasks ( for example the squad dataset ) which may benefit more from including a blstm layer.', 'we note again the accuracy discrepancy between the original bert and our implementation of bert, which may be due to the fact that the former uses partial word masking while the later uses whole word masking.', '']",5
"[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for all glue tasks.', 'for each task, we selected the best fine - tuning learning rate ( among 5']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for all glue tasks.', 'for each task, we selected the best fine - tuning learning rate ( among 5e - 5, 4e - 5, 3e - 5, and 2e - 5 ) on the development set.', 'additionally similar to  #TAUTHOR_TAG, for large bert and trans - blstm models, we found that finetuning was sometimes unstable on small datasets, so we ran several random restarts and selected the best model on the development set.', 'table 5 shows the results of glue datasets for original bert  #TAUTHOR_TAG, ours trans / bert, trans - blstm - small and trans - blstm on base and large settings respectively.', 'following the bert setting  #TAUTHOR_TAG, we exclude the problematic wnli set.', 'f1 scores are reported for qqp and mrpc, spearman correlations are reported for sts - b, and accuracy scores are reported for the other tasks.', 'unlike the evaluation on squad dataset, we do not apply the blstm layer to the decoder.', 'this is because that the tasks on glue are classification tasks based on the [CLS] token, and are not sequential prediction tasks ( for example the squad dataset ) which may benefit more from including a blstm layer.', 'we note again the accuracy discrepancy between the original bert and our implementation of bert, which may be due to the fact that the former uses partial word masking while the later uses whole word masking.', '']",5
"['original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['masking setting, we are able to fairly', 'compare the proposed trans - blstm models to the original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['##x large trans / bert 334m 24 1024 1024 16 2. 8x trans - blstm - small 487m 24 1024 1024 16 1. 4x trans - blstm 789m 24 1024 1024 16 1 table 1', ': parameter size and training speed for trans / bert,', 'trans - blstm - small, and trans - blstm on base and large settings respectively. x 1 = x 11, x 12... and x 2 = x 21, x 22... are two segments. to reduce the training memory consumption, we set the maximum input length to 256 ( as opposed to 512 in the original bert paper ). we note that this setting may adversely affect the best accuracy we report in our paper 1, but the relative accuracy gain by the proposed models are still valid. similar to bert, we use a vocabulary size of 30k with wordpiece tokenization. we generate the masked input from the mlm targets using unigram masking, which is', 'denoted as whole word masking. that is, each masking applies to a whole word at one time. we note that using n - gram', 'masking ( for example, with n = 3 )  #AUTHOR_TAG with the length of each n - gram mask selected randomly can further improve the downstream', 'task accuracy ( for example, 2 % f1 score increase was observed on squad 1. 1 data set with n - gram masking and span boundary representation', 'prediction  #AUTHOR_TAG ). however, in the whole word masking setting, we are able to fairly', 'compare the proposed trans - blstm models to the original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '15 % of the token positions at random for making. if the i', '- th token is chosen, we replace the i - th token with ( 1 ) the [MASK] token 80 % of the time ( 2 ) a random token 10 % of the time ( 3 ) the unchanged i - th token 10 % of the time. the model updates use a batch size of 256 and adam optimizer with learning rate starting from', '1e - 4. training was done on a cluster of nodes, where each node consists of 8 nvidia tesla v100 gpus', '. we vary the node size from 1 to 8 depending on the model size. our trans - bl', '##stm is implemented on top of pytorch transformer repository 2. 1 nevertheless, our implementation of baseline bert model obtained higher accuracy than that reported by the original bert paper  #TAUTHOR_TAG. 2 https : / / github. com / huggingface / pytorch -', 'transformers']",3
"[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for all glue tasks.', 'for each task, we selected the best fine - tuning learning rate ( among 5']","[' #TAUTHOR_TAG, we use a batch size of 32 and 3 - epoch fine - tuning over the data for all glue tasks.', 'for each task, we selected the best fine - tuning learning rate ( among 5e - 5, 4e - 5, 3e - 5, and 2e - 5 ) on the development set.', 'additionally similar to  #TAUTHOR_TAG, for large bert and trans - blstm models, we found that finetuning was sometimes unstable on small datasets, so we ran several random restarts and selected the best model on the development set.', 'table 5 shows the results of glue datasets for original bert  #TAUTHOR_TAG, ours trans / bert, trans - blstm - small and trans - blstm on base and large settings respectively.', 'following the bert setting  #TAUTHOR_TAG, we exclude the problematic wnli set.', 'f1 scores are reported for qqp and mrpc, spearman correlations are reported for sts - b, and accuracy scores are reported for the other tasks.', 'unlike the evaluation on squad dataset, we do not apply the blstm layer to the decoder.', 'this is because that the tasks on glue are classification tasks based on the [CLS] token, and are not sequential prediction tasks ( for example the squad dataset ) which may benefit more from including a blstm layer.', 'we note again the accuracy discrepancy between the original bert and our implementation of bert, which may be due to the fact that the former uses partial word masking while the later uses whole word masking.', '']",3
"['original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['masking setting, we are able to fairly', 'compare the proposed trans - blstm models to the original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '']","['##x large trans / bert 334m 24 1024 1024 16 2. 8x trans - blstm - small 487m 24 1024 1024 16 1. 4x trans - blstm 789m 24 1024 1024 16 1 table 1', ': parameter size and training speed for trans / bert,', 'trans - blstm - small, and trans - blstm on base and large settings respectively. x 1 = x 11, x 12... and x 2 = x 21, x 22... are two segments. to reduce the training memory consumption, we set the maximum input length to 256 ( as opposed to 512 in the original bert paper ). we note that this setting may adversely affect the best accuracy we report in our paper 1, but the relative accuracy gain by the proposed models are still valid. similar to bert, we use a vocabulary size of 30k with wordpiece tokenization. we generate the masked input from the mlm targets using unigram masking, which is', 'denoted as whole word masking. that is, each masking applies to a whole word at one time. we note that using n - gram', 'masking ( for example, with n = 3 )  #AUTHOR_TAG with the length of each n - gram mask selected randomly can further improve the downstream', 'task accuracy ( for example, 2 % f1 score increase was observed on squad 1. 1 data set with n - gram masking and span boundary representation', 'prediction  #AUTHOR_TAG ). however, in the whole word masking setting, we are able to fairly', 'compare the proposed trans - blstm models to the original bert models. similar to  #TAUTHOR_TAG, the training data generator chooses', '15 % of the token positions at random for making. if the i', '- th token is chosen, we replace the i - th token with ( 1 ) the [MASK] token 80 % of the time ( 2 ) a random token 10 % of the time ( 3 ) the unchanged i - th token 10 % of the time. the model updates use a batch size of 256 and adam optimizer with learning rate starting from', '1e - 4. training was done on a cluster of nodes, where each node consists of 8 nvidia tesla v100 gpus', '. we vary the node size from 1 to 8 depending on the model size. our trans - bl', '##stm is implemented on top of pytorch transformer repository 2. 1 nevertheless, our implementation of baseline bert model obtained higher accuracy than that reported by the original bert paper  #TAUTHOR_TAG. 2 https : / / github. com / huggingface / pytorch -', 'transformers']",4
['f1 bert - base'],['f1 bert - base'],['f1 bert - base'],['f1 bert - base'],7
"['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that']","['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that "" the current state of the']","['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that']","['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that "" the current state of the art is far from being able to produce a robust parser of general english "" and advocate "" steady and quantifiable, "" empirically corpus - driven grammar development and testing.', 'black et al. are addressing a community in which armchair introspection has been and still is the dominant methodology in many quarters, but in some parts of europe, corpus linguistics never died.', 'for nearly two decades, the nijmegen group led by jan aarts have been undertaking corpus analyses that, although motivated primarily by the desire to study language variation using corpus data, are particularly relevant to the issue of broad - coverage grammar development.', 'in distinction to other groups undertaking corpus - based work ( e. g., garside, leech, and sampson 1987 ), the nijmegen group has consistently adopted the position that it is possible and desirable to develop a formal, generative grammar that characterizes the syntactic properties of a given corpus and can be used to assign appropriate analyses to each of its sentences.', ""nelleke oostdijk's book provides a detailed description of the cumulative development of a grammar capable of analyzing a one million - word corpus of english written texts, drawn from a wide but balanced variety of sources."", '']",0
"['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that']","['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that "" the current state of the']","['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that']","['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that "" the current state of the art is far from being able to produce a robust parser of general english "" and advocate "" steady and quantifiable, "" empirically corpus - driven grammar development and testing.', 'black et al. are addressing a community in which armchair introspection has been and still is the dominant methodology in many quarters, but in some parts of europe, corpus linguistics never died.', 'for nearly two decades, the nijmegen group led by jan aarts have been undertaking corpus analyses that, although motivated primarily by the desire to study language variation using corpus data, are particularly relevant to the issue of broad - coverage grammar development.', 'in distinction to other groups undertaking corpus - based work ( e. g., garside, leech, and sampson 1987 ), the nijmegen group has consistently adopted the position that it is possible and desirable to develop a formal, generative grammar that characterizes the syntactic properties of a given corpus and can be used to assign appropriate analyses to each of its sentences.', ""nelleke oostdijk's book provides a detailed description of the cumulative development of a grammar capable of analyzing a one million - word corpus of english written texts, drawn from a wide but balanced variety of sources."", '']",0
"['.,  #TAUTHOR_TAG.']","['not grammar induction ( e. g.,  #TAUTHOR_TAG.']",[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
"['.,  #TAUTHOR_TAG.']","['not grammar induction ( e. g.,  #TAUTHOR_TAG.']",[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
"['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that']","['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that "" the current state of the']","['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that']","['a recent paper advocating a corpus - based and probabilistic approach to grammar development,  #TAUTHOR_TAG argue that "" the current state of the art is far from being able to produce a robust parser of general english "" and advocate "" steady and quantifiable, "" empirically corpus - driven grammar development and testing.', 'black et al. are addressing a community in which armchair introspection has been and still is the dominant methodology in many quarters, but in some parts of europe, corpus linguistics never died.', 'for nearly two decades, the nijmegen group led by jan aarts have been undertaking corpus analyses that, although motivated primarily by the desire to study language variation using corpus data, are particularly relevant to the issue of broad - coverage grammar development.', 'in distinction to other groups undertaking corpus - based work ( e. g., garside, leech, and sampson 1987 ), the nijmegen group has consistently adopted the position that it is possible and desirable to develop a formal, generative grammar that characterizes the syntactic properties of a given corpus and can be used to assign appropriate analyses to each of its sentences.', ""nelleke oostdijk's book provides a detailed description of the cumulative development of a grammar capable of analyzing a one million - word corpus of english written texts, drawn from a wide but balanced variety of sources."", '']",1
"['recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine']","['recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine']","['recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine translation builds two initial translation models at first (']","['machine translation has become an emerging research interest in recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine translation builds two initial translation models at first ( i. e., source to target and target to source ), and then does iterative back - translation  #AUTHOR_TAG a ;  #AUTHOR_TAG with the two models using pseudo data generated by each other.', '']",0
"['recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine']","['recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine']","['recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine translation builds two initial translation models at first (']","['machine translation has become an emerging research interest in recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine translation builds two initial translation models at first ( i. e., source to target and target to source ), and then does iterative back - translation  #AUTHOR_TAG a ;  #AUTHOR_TAG with the two models using pseudo data generated by each other.', '']",0
"['on bert,  #TAUTHOR_TAG propose a cross - lingu']","['on bert,  #TAUTHOR_TAG propose a cross - lingual version called xlm']","['on bert,  #TAUTHOR_TAG propose a cross - lingual version called xlm']","['on bert,  #TAUTHOR_TAG propose a cross - lingual version called xlm and reach the state - of - the - art performance on some crosslingual nlp tasks including cross - lingual classification, machine translation, and unsupervised cross - lingual word embedding.', 'the basic points of xlm are mainly two folds.', 'the first one is to use a shared vocabulary of bpe  #AUTHOR_TAG b ) to provide potential crosslingual information between two languages just as mentioned in, in an inexplicit way though.', 'the second point is a newly proposed training task called translation language modeling ( tlm ), which extends mlm by concatenating parallel sentences into a single training text stream.', 'in this way, the model can leverage the cross - lingual information provided by parallel sentences to predict the masked tokens.', 'however, for unsupervised machine translation, tlm cannot be used due to the lack of parallel sentences.', 'different from them, we are motivated to give the model more explicit and strong cross - lingual information and propose a new pre - training method by ( 1 ) masking source n - grams and ( 2 ) predicting their corresponding translation candidates.', 'the second one is pre - training with our proposed objective cross - lingual masked language model ( cmlm ) which is to predict the translation candidates of randomly masked n - grams.', 'the last step is to leverage the pre - trained cross - lingual language models as the encoder and decoder of a neural machine translation model and fine - tune the translation model iteratively']",0
"['of posterior regularization.', 'more recently,  #TAUTHOR_TAG']","['of posterior regularization.', 'more recently,  #TAUTHOR_TAG']","['nmt models with the framework of posterior regularization.', 'more recently,  #TAUTHOR_TAG']","['machine translation dates back to  #AUTHOR_TAG ;  #AUTHOR_TAG, but becomes a hot research topic in recent years.', 'as the pioneering methods,  #AUTHOR_TAG ; ;  #AUTHOR_TAG are mainly the modifications of the encoder - decoder structure.', 'the core idea is to constrain outputs of encoders of two languages into a same latent space with a weight sharing mechanism such as using a shared encoder.', 'denoising auto - encoder  #AUTHOR_TAG and adversarial training methods are also leveraged.', 'besides, they apply iterative backtranslation to generated pseudo data for crosslingual training.', 'in addition to nmt methods for unsupervised machine translation, some following work shows that smt methods and the hybrid of nmt and smt can be more effective  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'they all build unsupervised pbsmt systems, and all of their models are initialized with language models and phrase tables inferred from cross - lingual word or n - gram embeddings and then use the initial pbsmt models to do iterative back - translation.', 'also build a hybrid system by combining the best pseudo data that smt models generate into the training of the nmt model while  #AUTHOR_TAG alternately train smt and nmt models with the framework of posterior regularization.', 'more recently,  #TAUTHOR_TAG reach new state - of - the - art performance on unsupervised en - fr and en - de translation tasks.', '']",0
"['recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine']","['recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine']","['recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine translation builds two initial translation models at first (']","['machine translation has become an emerging research interest in recent years  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'the common framework of unsupervised machine translation builds two initial translation models at first ( i. e., source to target and target to source ), and then does iterative back - translation  #AUTHOR_TAG a ;  #AUTHOR_TAG with the two models using pseudo data generated by each other.', '']",1
"[' #AUTHOR_TAG ;  #TAUTHOR_TAG, in our cmlm objective, we randomly sample']","['monolingual sentences together during pre - training.  #AUTHOR_TAG ;  #TAUTHOR_TAG, in our cmlm objective, we randomly sample']","[' #AUTHOR_TAG ;  #TAUTHOR_TAG, in our cmlm objective, we randomly sample 15 % of the bpe ngrams from the text streams, and replace them by [MASK] tokens 70 % of the time.', 'during pretraining, in each iteration, a batch is composed of sentences sampled from the same language, and we alternate between mlm', 'and cmlm objectives. different from the original mlm in bert, in the half of the mlm time,']","['', 'k translation candidates are used to calculate the cross entropy loss, which are weighted with their', 'translation probabilities in the n - gram table. given a language pair x − y, we process both languages', 'with the same shared bpe vocabulary using their monolingual sentences together during pre - training.  #AUTHOR_TAG ;  #TAUTHOR_TAG, in our cmlm objective, we randomly sample 15 % of the bpe ngrams from the text streams, and replace them by [MASK] tokens 70 % of the time.', 'during pretraining, in each iteration, a batch is composed of sentences sampled from the same language, and we alternate between mlm', 'and cmlm objectives. different from the original mlm in bert, in the half of the mlm time, we randomly choose some source n - grams in the input text stream,', 'and replace them with their translation candidates to construct code - switching sentences. our final pre', '##training loss is defined']",4
"['than pre - training encoders  #TAUTHOR_TAG, one']","['than pre - training encoders  #TAUTHOR_TAG, one']","['the final performance than pre - training encoders  #TAUTHOR_TAG, one reason for which']","['two cross - lingual language models pretrained with the above method as the encoder and decoder, we build an initial unsupervised neural machine translation model.', 'then, we train the model with monolingual data until convergence via denoising auto - encoder and iterative backtranslation, as described in  #AUTHOR_TAG ;.', 'different from them, we step further and make another iteration with updated n - gram translation tables.', 'specifically, we translate the monolingual sentences with our latest translation model and run giza + +  #AUTHOR_TAG on the generated pseudo parallel data to extract updated n - gram translation pairs, which are used to tune the encoder as section 3. 3, together with the back - translation within a multi - task learning framework.', 'experimental results show that running another iteration can further improve the translation performance.', 'it is also interesting to explore the usage of pre - trained decoders in the translation model.', 'it seems that pre - training decoders has a smaller effect on the final performance than pre - training encoders  #TAUTHOR_TAG, one reason for which could be that the encoder - to - decoder attention is not pre - trained.', 'therefore, the parameters of the decoder need to be re - adjusted substantially in the following tuning process for mt task.', 'in our experiments, we explore some other usage of pre - trained decoders, i. e., we use the pretrained decoder as the feature extractor and feed the outputs into a new decoder consisting of several transformer layers with the attention to the encoder.', 'we find this method improves the performance of some language translation directions']",4
"[' #AUTHOR_TAG ;  #TAUTHOR_TAG, in our cmlm objective, we randomly sample']","['monolingual sentences together during pre - training.  #AUTHOR_TAG ;  #TAUTHOR_TAG, in our cmlm objective, we randomly sample']","[' #AUTHOR_TAG ;  #TAUTHOR_TAG, in our cmlm objective, we randomly sample 15 % of the bpe ngrams from the text streams, and replace them by [MASK] tokens 70 % of the time.', 'during pretraining, in each iteration, a batch is composed of sentences sampled from the same language, and we alternate between mlm', 'and cmlm objectives. different from the original mlm in bert, in the half of the mlm time,']","['', 'k translation candidates are used to calculate the cross entropy loss, which are weighted with their', 'translation probabilities in the n - gram table. given a language pair x − y, we process both languages', 'with the same shared bpe vocabulary using their monolingual sentences together during pre - training.  #AUTHOR_TAG ;  #TAUTHOR_TAG, in our cmlm objective, we randomly sample 15 % of the bpe ngrams from the text streams, and replace them by [MASK] tokens 70 % of the time.', 'during pretraining, in each iteration, a batch is composed of sentences sampled from the same language, and we alternate between mlm', 'and cmlm objectives. different from the original mlm in bert, in the half of the mlm time, we randomly choose some source n - grams in the input text stream,', 'and replace them with their translation candidates to construct code - switching sentences. our final pre', '##training loss is defined']",6
"['following unsupervised nmt iteration process.', 'our cmlm is optimized based on the pre - trained models released by  #TAUTHOR_TAG 1, which']","['following unsupervised nmt iteration process.', 'our cmlm is optimized based on the pre - trained models released by  #TAUTHOR_TAG 1, which']","['the following unsupervised nmt iteration process.', 'our cmlm is optimized based on the pre - trained models released by  #TAUTHOR_TAG 1, which are trained with wikipedia dumps.', 'for fair comparison, we use newstest 2014 as the test set']","['', 'for each language, we use all the available sentences in newscrawl till 2018, monolingual datasets from wmt.', 'the newscrawl data are used in both pretraining and the following unsupervised nmt iteration process.', 'our cmlm is optimized based on the pre - trained models released by  #TAUTHOR_TAG 1, which are trained with wikipedia dumps.', 'for fair comparison, we use newstest 2014 as the test set for en - fr, and newstest 2016 for en - de and en - ro.', '1 https : / / github. com / facebookresearch / xlm we use moses scripts for tokenization, and use fastbpe 2 to split words into subword units with their released bpe codes 1.', 'the number of shared bpe codes for each language pair is 60, 000']",3
"[' #AUTHOR_TAG a ) of source and target words ), xlm  #TAUTHOR_TAG and']","[' #AUTHOR_TAG a ) of source and target words ), xlm  #TAUTHOR_TAG and']","['unsupervised cross - lingual embeddings  #AUTHOR_TAG a ) of source and target words ), xlm  #TAUTHOR_TAG and']","['', 'we compare the context - unaware method ( i. e., directly calculating the similarity scores between unsupervised cross - lingual embeddings  #AUTHOR_TAG a ) of source and target words ), xlm  #TAUTHOR_TAG and our proposed cmlm pre - training method in the table 3.', 'in this experiment, we leave out all the oov words and those torn apart by the bpe operations.', 'table 3 : results of word alignment tasks using different cross - lingual word embeddings.', '']",3
"['following unsupervised nmt iteration process.', 'our cmlm is optimized based on the pre - trained models released by  #TAUTHOR_TAG 1, which']","['following unsupervised nmt iteration process.', 'our cmlm is optimized based on the pre - trained models released by  #TAUTHOR_TAG 1, which']","['the following unsupervised nmt iteration process.', 'our cmlm is optimized based on the pre - trained models released by  #TAUTHOR_TAG 1, which are trained with wikipedia dumps.', 'for fair comparison, we use newstest 2014 as the test set']","['', 'for each language, we use all the available sentences in newscrawl till 2018, monolingual datasets from wmt.', 'the newscrawl data are used in both pretraining and the following unsupervised nmt iteration process.', 'our cmlm is optimized based on the pre - trained models released by  #TAUTHOR_TAG 1, which are trained with wikipedia dumps.', 'for fair comparison, we use newstest 2014 as the test set for en - fr, and newstest 2016 for en - de and en - ro.', '1 https : / / github. com / facebookresearch / xlm we use moses scripts for tokenization, and use fastbpe 2 to split words into subword units with their released bpe codes 1.', 'the number of shared bpe codes for each language pair is 60, 000']",5
[' #TAUTHOR_TAG compared with'],[' #TAUTHOR_TAG compared with'],[' #TAUTHOR_TAG compared with'],[' #TAUTHOR_TAG'],2
[' #TAUTHOR_TAG compared with'],[' #TAUTHOR_TAG compared with'],[' #TAUTHOR_TAG compared with'],[' #TAUTHOR_TAG'],2
"['##d features  #TAUTHOR_TAG', ',']","['on various hand - crafted features  #TAUTHOR_TAG', ',']","['##d features  #TAUTHOR_TAG', ', we']","['', 'a group of seafish... "" ; ( 2 ) images of the close neighbors, e. g., shark and ray are usually', 'visually similar and images of the child, e. g. shark / ray are', 'similar to a subset of images of seafish. to effectively capture these', 'patterns, in contrast to previous works that rely on various hand - crafted features  #TAUTHOR_TAG', ', we extract features by leveraging the distributed representations that embed images  #AUTHOR_TAG and words as compact vectors, based on which the semantic closeness is directly measured in vector space. further, we develop a probabilistic framework that integrates the rich multi - modal features to induce "" is - a ""', 'relations between categories, encouraging local semantic consistency that each category should be visually and textually close to its parent and siblings. in summary, this paper has the following contributions : ( 1 ) we propose a novel', 'probabilistic bayesian model ( section 3 ) for taxonomy induction by jointly leveraging textual and visual', 'data. the model is discriminatively trained and can be directly', 'applied to build a taxonomy from scratch for a collection of', 'semantic labels. ( 2 ) we design novel features ( section 4 ) based on generalpurpose distributed representations of text and images to capture both textual and visual relations between labels. ( 3 ) we evaluate our model and features on the imagenet hierarchies with two different taxonomy induction tasks ( section 5 ). we achieve superior performance on both tasks and improve the f 1 score by 2x in the taxonomy construction task, compared to previous approaches. extensive comparisons demonstrate the effectiveness of integrating visual features with language features for taxonomy induction. we also provide qualitative analysis on our features, the learned model, and the taxonomies induced to provide further insights ( section 5. 3 )']",0
"['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend']","['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend']","['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend']","['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend it by inserting new terms.', ' #AUTHOR_TAG and  #AUTHOR_TAG first find leaf nodes and then use lexical patterns to find intermediate terms and all the attested hypernymy links between them.', 'in  #AUTHOR_TAG, syntactic contextual similarity is exploited to construct the taxonomy, while  #AUTHOR_TAG go one step further to consider trustiness and collective synonym / contrastive evidence.', 'different from them, our model is discriminatively trained with multi - modal data.', 'the works of  #AUTHOR_TAG and  #TAUTHOR_TAG use similar language - based features as ours.', 'specifically, in  #AUTHOR_TAG, linguistic regularities between pretrained word vectors are modeled as projection mappings.', '']",0
"['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend']","['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend']","['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend']","['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend it by inserting new terms.', ' #AUTHOR_TAG and  #AUTHOR_TAG first find leaf nodes and then use lexical patterns to find intermediate terms and all the attested hypernymy links between them.', 'in  #AUTHOR_TAG, syntactic contextual similarity is exploited to construct the taxonomy, while  #AUTHOR_TAG go one step further to consider trustiness and collective synonym / contrastive evidence.', 'different from them, our model is discriminatively trained with multi - modal data.', 'the works of  #AUTHOR_TAG and  #TAUTHOR_TAG use similar language - based features as ours.', 'specifically, in  #AUTHOR_TAG, linguistic regularities between pretrained word vectors are modeled as projection mappings.', '']",0
"['##d features  #TAUTHOR_TAG', ',']","['on various hand - crafted features  #TAUTHOR_TAG', ',']","['##d features  #TAUTHOR_TAG', ', we']","['', 'a group of seafish... "" ; ( 2 ) images of the close neighbors, e. g., shark and ray are usually', 'visually similar and images of the child, e. g. shark / ray are', 'similar to a subset of images of seafish. to effectively capture these', 'patterns, in contrast to previous works that rely on various hand - crafted features  #TAUTHOR_TAG', ', we extract features by leveraging the distributed representations that embed images  #AUTHOR_TAG and words as compact vectors, based on which the semantic closeness is directly measured in vector space. further, we develop a probabilistic framework that integrates the rich multi - modal features to induce "" is - a ""', 'relations between categories, encouraging local semantic consistency that each category should be visually and textually close to its parent and siblings. in summary, this paper has the following contributions : ( 1 ) we propose a novel', 'probabilistic bayesian model ( section 3 ) for taxonomy induction by jointly leveraging textual and visual', 'data. the model is discriminatively trained and can be directly', 'applied to build a taxonomy from scratch for a collection of', 'semantic labels. ( 2 ) we design novel features ( section 4 ) based on generalpurpose distributed representations of text and images to capture both textual and visual relations between labels. ( 3 ) we evaluate our model and features on the imagenet hierarchies with two different taxonomy induction tasks ( section 5 ). we achieve superior performance on both tasks and improve the f 1 score by 2x in the taxonomy construction task, compared to previous approaches. extensive comparisons demonstrate the effectiveness of integrating visual features with language features for taxonomy induction. we also provide qualitative analysis on our features, the learned model, and the taxonomies induced to provide further insights ( section 5. 3 )']",1
"['##d features  #TAUTHOR_TAG', ',']","['on various hand - crafted features  #TAUTHOR_TAG', ',']","['##d features  #TAUTHOR_TAG', ', we']","['', 'a group of seafish... "" ; ( 2 ) images of the close neighbors, e. g., shark and ray are usually', 'visually similar and images of the child, e. g. shark / ray are', 'similar to a subset of images of seafish. to effectively capture these', 'patterns, in contrast to previous works that rely on various hand - crafted features  #TAUTHOR_TAG', ', we extract features by leveraging the distributed representations that embed images  #AUTHOR_TAG and words as compact vectors, based on which the semantic closeness is directly measured in vector space. further, we develop a probabilistic framework that integrates the rich multi - modal features to induce "" is - a ""', 'relations between categories, encouraging local semantic consistency that each category should be visually and textually close to its parent and siblings. in summary, this paper has the following contributions : ( 1 ) we propose a novel', 'probabilistic bayesian model ( section 3 ) for taxonomy induction by jointly leveraging textual and visual', 'data. the model is discriminatively trained and can be directly', 'applied to build a taxonomy from scratch for a collection of', 'semantic labels. ( 2 ) we design novel features ( section 4 ) based on generalpurpose distributed representations of text and images to capture both textual and visual relations between labels. ( 3 ) we evaluate our model and features on the imagenet hierarchies with two different taxonomy induction tasks ( section 5 ). we achieve superior performance on both tasks and improve the f 1 score by 2x in the taxonomy construction task, compared to previous approaches. extensive comparisons demonstrate the effectiveness of integrating visual features with language features for taxonomy induction. we also provide qualitative analysis on our features, the learned model, and the taxonomies induced to provide further insights ( section 5. 3 )']",6
"['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend']","['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend']","['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend']","['approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora  #TAUTHOR_TAG.', 'the approaches in  #AUTHOR_TAG and  #AUTHOR_TAG assume a starting incomplete hierarchy and try to extend it by inserting new terms.', ' #AUTHOR_TAG and  #AUTHOR_TAG first find leaf nodes and then use lexical patterns to find intermediate terms and all the attested hypernymy links between them.', 'in  #AUTHOR_TAG, syntactic contextual similarity is exploited to construct the taxonomy, while  #AUTHOR_TAG go one step further to consider trustiness and collective synonym / contrastive evidence.', 'different from them, our model is discriminatively trained with multi - modal data.', 'the works of  #AUTHOR_TAG and  #TAUTHOR_TAG use similar language - based features as ours.', 'specifically, in  #AUTHOR_TAG, linguistic regularities between pretrained word vectors are modeled as projection mappings.', '']",3
"['##s algorithm  #TAUTHOR_TAG. training.', 'we need to learn the model parameters w l of']","['( mst ) using the chu - liu - edmonds algorithm  #TAUTHOR_TAG. training.', 'we need to learn the model parameters w l of']","['##s algorithm  #TAUTHOR_TAG. training.', 'we need to learn the model parameters w l of each layer l', ', which capture the relative importance of different features. the model is trained using the em algorithm']","['', 'the whole valid tree space. output taxonomy selection. to apply the model to discover the underlying taxonomy from a given set of categories', ', we first obtain the marginals of z by averaging over the samples generated through eq 3, then output the optimal taxonomy z * by finding the maximum spanning tree ( mst ) using the chu - liu - edmonds algorithm  #TAUTHOR_TAG. training.', 'we need to learn the model parameters w l of each layer l', ', which capture the relative importance of different features. the model is trained using the em algorithm. let ( x n ) be the depth ( layer ) of category x n ; andz ( siblings c n ) denote the gold structure in training data. our training algorithm updates w through maximum likelihood estimation, wherein the gradient of w l is ( see the supplementary materials for', 'details ) : which is the net difference between gold feature', 'vectors and', 'expected feature vectors as per the model. the expectation is approximated by collecting', 'samples using the sampler described above and averaging them']",5
"['employ the capitalization, ends with, contains, suffix match, lcs and length different features, which are commonly used in previous works in taxonomy induction  #TAUTHOR_TAG']","['employ the capitalization, ends with, contains, suffix match, lcs and length different features, which are commonly used in previous works in taxonomy induction  #TAUTHOR_TAG']","['parent category names.', 'specifically, we employ the capitalization, ends with, contains, suffix match, lcs and length different features, which are commonly used in previous works in taxonomy induction  #TAUTHOR_TAG']","['briefly introduce the text features employed.', 'more details about the text feature extraction could be found in the supplementary material.', 'word embedding features. d pc - v1, we induce features using word vectors to measure both sibling - sibling and parent - child closeness in text domain  #AUTHOR_TAG.', 'one exception is that, as each category has only one word, the sibling similarity is computed as the cosine distance between two word vectors ( instead of mean vectors ).', 'this will produce another two parts of features, parentchild word - word relation feature ( pc - t1 ) and siblings word - word relation feature ( s - t1 ).', 'word surface features.', 'in addition to the embedding - based features, we further leverage lexical features based on the surface forms of child / parent category names.', 'specifically, we employ the capitalization, ends with, contains, suffix match, lcs and length different features, which are commonly used in previous works in taxonomy induction  #TAUTHOR_TAG']",5
['methods  #TAUTHOR_TAG with two taxonomy induction tasks'],"['state - of - the - art methods  #TAUTHOR_TAG with two taxonomy induction tasks.', 'finally, we provide analysis on the weights and taxonomies induced']","[' #TAUTHOR_TAG with two taxonomy induction tasks.', 'finally, we provide analysis on the weights and taxonomi']","['first disclose our implementation details in section 5. 1 and the supplementary material for better reproducibility.', 'we then compare our model with previous state - of - the - art methods  #TAUTHOR_TAG with two taxonomy induction tasks.', 'finally, we provide analysis on the weights and taxonomies induced']",5
"['metric  #TAUTHOR_TAG.', 'specifically, we measure']","['metric  #TAUTHOR_TAG.', 'specifically, we measure']","['metric  #TAUTHOR_TAG.', 'specifically, we measure']","['', 'specifically, we select two trees as the training set to learn w. in the test phase, the model is required to build the full taxonomy from scratch for the third tree.', 'we use ancestor f 1 as our evaluation metric  #TAUTHOR_TAG.', 'specifically, we measure f 1 = 2p r / ( p + r ) values of predicted "" is - a "" relations where the precision ( p ) and recall ( r ) are :', 'we compare our method to two previously state - of - the - art models by  #AUTHOR_TAG and  #TAUTHOR_TAG, which are closest to ours.', 'table 2 : comparisons among different variants of our model,  #AUTHOR_TAG and  #TAUTHOR_TAG on two tasks.', 'the ancestor - f 1 scores are reported']",5
"['metric  #TAUTHOR_TAG.', 'specifically, we measure']","['metric  #TAUTHOR_TAG.', 'specifically, we measure']","['metric  #TAUTHOR_TAG.', 'specifically, we measure']","['', 'specifically, we select two trees as the training set to learn w. in the test phase, the model is required to build the full taxonomy from scratch for the third tree.', 'we use ancestor f 1 as our evaluation metric  #TAUTHOR_TAG.', 'specifically, we measure f 1 = 2p r / ( p + r ) values of predicted "" is - a "" relations where the precision ( p ) and recall ( r ) are :', 'we compare our method to two previously state - of - the - art models by  #AUTHOR_TAG and  #TAUTHOR_TAG, which are closest to ours.', 'table 2 : comparisons among different variants of our model,  #AUTHOR_TAG and  #TAUTHOR_TAG on two tasks.', 'the ancestor - f 1 scores are reported']",5
"['metric  #TAUTHOR_TAG.', 'specifically, we measure']","['metric  #TAUTHOR_TAG.', 'specifically, we measure']","['metric  #TAUTHOR_TAG.', 'specifically, we measure']","['', 'specifically, we select two trees as the training set to learn w. in the test phase, the model is required to build the full taxonomy from scratch for the third tree.', 'we use ancestor f 1 as our evaluation metric  #TAUTHOR_TAG.', 'specifically, we measure f 1 = 2p r / ( p + r ) values of predicted "" is - a "" relations where the precision ( p ) and recall ( r ) are :', 'we compare our method to two previously state - of - the - art models by  #AUTHOR_TAG and  #TAUTHOR_TAG, which are closest to ours.', 'table 2 : comparisons among different variants of our model,  #AUTHOR_TAG and  #TAUTHOR_TAG on two tasks.', 'the ancestor - f 1 scores are reported']",5
[': the model by  #TAUTHOR_TAG'],[': the model by  #TAUTHOR_TAG'],[': the model by  #TAUTHOR_TAG'],"['difficult taxonomy', 'to be accurately constructed. overall, our model outperforms fu2014 in terms of the f 1 score, even without visual features. in the most difficult case with h = 7, our model still holds an f 1 score of 0. 42 ( 2× of fu', '##2014 ), demonstrating the superiority of our model. hierarchy construction. the hierarchy construction task is much more difficult than hierarchy completion task because we need to build a taxonomy from scratch given only a hyper - root. for this task, we use a leave -', 'one - out strategy, i. e. we train our', 'model on every two trees and test on the third, and report the average performance in table 2. we compare the following methods : ( 1 ) fu2014, ( 2', ') ours ( l ), and ( 3 ) ours ( lv ), as described above ; ( 4', ') bansal2014 : the model by  #TAUTHOR_TAG ; ( 7 ) ours ( lvb - e ) : by excluding word embeddingbased language features from ours ( lvb ). as', 'shown, on', '']",5
"['. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85']","['( e. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85 %']","['. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85']","['the internal state of a robotic system is complex : this is performed from multiple heterogeneous sensor inputs and knowledge sources.', 'discretization of such inputs is done to capture saliences, represented as symbolic information, which often presents structure and recurrence.', 'as these sequences are used to reason over complex scenarios [ 1 ], a more compact representation would aid exactness of technical cognitive reasoning capabilities, which are today constrained by computational complexity issues and fallback to representational heuristics or human intervention [ 1 ], [ 2 ].', 'such problems need to be addressed to ensure timely and meaningful human - robot interaction.', 'our work is towards understanding the variability of learning informativeness when training on subsets of a given input dataset.', 'this is in view of reducing the training size while retaining the majority of the symbolic learning potential.', 'we prove the concept on human - written texts, and conjecture this work will reduce training data size of sequential instructions, while preserving semantic relations, when gathering information from large remote sources [ 3 ].', 'we computed multiple random subsets of sentences from the umbc webbase corpus ( ∼ 17. 13gb ) via a custom implementation using the spark distributed framework.', 'we evaluated the learning informativess of such sets in terms of semantic word - sense classification accuracy ( with word2vec [ 4 ] ), and of n - gram perplexity.', 'previous literature inform us that corpus size and posterior quality do not follow linear correlation for some learning tasks ( e. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85 % of the quality can be obtained by training on a random ∼ 4 % subset of the original corpus ( e. g. as in fig. 1, 5 random million lines yield 64. 14 % instead of 75. 14 % ).', 'our claims are that i ) such evaluation posteriors are normally distributed ( tab. i ), and that ii ) the variance is inversely proportional to the subset size ( tab. ii ).', 'it is therefore possible to select the best random subset for a given size, if an information criterion is known.', 'such metric is currently under investigation.', 'within the robotics domain, in order to reduce computational complexity of the training phase, cardinality reduction of human - written instructions is particularly important for non - recursive online training algorithms, such as current symbol - based probabilistic reasoning systems [ 1 ], [ 3 ], [ 6 ]']",0
"['. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85']","['learning tasks ( e. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85 %']","['. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85']","['computed multiple random subsets of sentences from the umbc webbase corpus ( ∼ 17. 13gb ) via a custom implementation using the spark distributed framework.', 'we evaluated the learning informativess of such sets in terms of semantic word - sense classification accuracy ( with word2vec [ 4 ] ), and of n - gram perplexity.', 'previous literature inform us that corpus size and posterior quality do not follow linear correlation for some learning tasks ( e. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85 % of the quality can be obtained by training on a random ∼ 4 % subset of the original corpus ( e. g. as in fig. 1, 5 random million lines yield 64. 14 % instead of 75. 14 % ).', '']",0
"['. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85']","['( e. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85 %']","['. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85']","['the internal state of a robotic system is complex : this is performed from multiple heterogeneous sensor inputs and knowledge sources.', 'discretization of such inputs is done to capture saliences, represented as symbolic information, which often presents structure and recurrence.', 'as these sequences are used to reason over complex scenarios [ 1 ], a more compact representation would aid exactness of technical cognitive reasoning capabilities, which are today constrained by computational complexity issues and fallback to representational heuristics or human intervention [ 1 ], [ 2 ].', 'such problems need to be addressed to ensure timely and meaningful human - robot interaction.', 'our work is towards understanding the variability of learning informativeness when training on subsets of a given input dataset.', 'this is in view of reducing the training size while retaining the majority of the symbolic learning potential.', 'we prove the concept on human - written texts, and conjecture this work will reduce training data size of sequential instructions, while preserving semantic relations, when gathering information from large remote sources [ 3 ].', 'we computed multiple random subsets of sentences from the umbc webbase corpus ( ∼ 17. 13gb ) via a custom implementation using the spark distributed framework.', 'we evaluated the learning informativess of such sets in terms of semantic word - sense classification accuracy ( with word2vec [ 4 ] ), and of n - gram perplexity.', 'previous literature inform us that corpus size and posterior quality do not follow linear correlation for some learning tasks ( e. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85 % of the quality can be obtained by training on a random ∼ 4 % subset of the original corpus ( e. g. as in fig. 1, 5 random million lines yield 64. 14 % instead of 75. 14 % ).', 'our claims are that i ) such evaluation posteriors are normally distributed ( tab. i ), and that ii ) the variance is inversely proportional to the subset size ( tab. ii ).', 'it is therefore possible to select the best random subset for a given size, if an information criterion is known.', 'such metric is currently under investigation.', 'within the robotics domain, in order to reduce computational complexity of the training phase, cardinality reduction of human - written instructions is particularly important for non - recursive online training algorithms, such as current symbol - based probabilistic reasoning systems [ 1 ], [ 3 ], [ 6 ]']",6
"['. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85']","['learning tasks ( e. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85 %']","['. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85']","['computed multiple random subsets of sentences from the umbc webbase corpus ( ∼ 17. 13gb ) via a custom implementation using the spark distributed framework.', 'we evaluated the learning informativess of such sets in terms of semantic word - sense classification accuracy ( with word2vec [ 4 ] ), and of n - gram perplexity.', 'previous literature inform us that corpus size and posterior quality do not follow linear correlation for some learning tasks ( e. g. semantic measures )  #TAUTHOR_TAG.', 'in our semantic tests, on average 85 % of the quality can be obtained by training on a random ∼ 4 % subset of the original corpus ( e. g. as in fig. 1, 5 random million lines yield 64. 14 % instead of 75. 14 % ).', '']",6
,,,,0
,,,,0
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['', 'we propose here to extend the lrp application to a linguistically motivated network architecture, known as  #TAUTHOR_TAG, which frames semantic information captured by linguistic tree kernel [ 2 ] methods within the neural - based learning paradigm.', '']",5
"['standard similarity calculations as proposed in  #TAUTHOR_TAG computationally infeasible.', 'these approaches first calculate an information measure between each word and the according context and then calculate the similarity between all words, based on the information measure for all shared contexts']","['standard similarity calculations as proposed in  #TAUTHOR_TAG computationally infeasible.', 'these approaches first calculate an information measure between each word and the according context and then calculate the similarity between all words, based on the information measure for all shared contexts']","['standard similarity calculations as proposed in  #TAUTHOR_TAG computationally infeasible.', 'these approaches first calculate an information measure between each word and the according context and then calculate the similarity between all words, based on the information measure for all shared contexts']","['larger data to estimate models for machine learning applications as well as for applications of natural language processing ( nlp ) has repeatedly shown to be advantageous, see e. g.  #AUTHOR_TAG.', 'in this work, we tackle the influence of corpus size for building a distributional thesaurus  #AUTHOR_TAG.', 'especially, we shed light on the interaction of similarity measures and corpus size, as well as aspects of scalability.', 'we shortly introduce the jobimtext framework for distributional semantics and show its scalability for large corpora.', 'for the computation of the data we follow the mapreduce  #AUTHOR_TAG paradigm.', 'the computation of similarities between terms becomes challenging on large corpora, as both the numbers of terms to be compared and the number of context features increases.', 'this makes standard similarity calculations as proposed in  #TAUTHOR_TAG computationally infeasible.', 'these approaches first calculate an information measure between each word and the according context and then calculate the similarity between all words, based on the information measure for all shared contexts']",0
"['stated in  #TAUTHOR_TAG 1.', 'an']","['stated in  #TAUTHOR_TAG 1.', 'an']","['stated in  #TAUTHOR_TAG 1.', 'an explanation']","["", we inspect the results of curran's measure using the wikipedia and newspaper corpus for the frequent nouns, shown in figure 1."", 'both graphs show the inverse ranking score against the size of the corpus.', 'our method scores consistently higher when using lmi instead of pmi for ranking the features per term.', 'the pmi measure declines when the corpus becomes larger.', 'this can be attributed to the fact that pmi favors term - context pairs involving rare contexts  #AUTHOR_TAG.', 'computing similarities between terms should not be performed on the basis of rare contexts, as these do not generalize well because of their sparseness.', 'all other measures improve with larger corpora.', 'it is surprising that recent works use pmi to calculate similarities between terms  #AUTHOR_TAG, who, however evaluate their approach only with respect to their own implementation or extrinsically, and do not prune on saliency.', ""apart from the pmi measure, curran's measure leads to the weakest results."", ""we could not confirm that his measure outperforms lin's measure as stated in  #TAUTHOR_TAG 1."", 'an explanation for this results might be the use of a different parser, very few test words and also a different gold standard thesaurus in his evaluation.', ""comparing our method using lmi to lin's method, we achieve lower scores with our method using small corpora, but surpass lin's measure from 10 million sentences onwards."", 'next, we show the results of the wordnet evaluation measure in figure 2.', '']",0
"['i 1, ( nsub ; gave 2 ; @ ) >. this representation scheme is more generic then the schemes introduced in  #TAUTHOR_TAG, as it allows to characterise pairs by several holes, which could be used to learn analog']","['( nsub ; gave 2 ; i 1 ) could be transferred to < gave 2, ( nsub ; @ ; i 1 ) > and < i 1, ( nsub ; gave 2 ; @ ) >. this representation scheme is more generic then the schemes introduced in  #TAUTHOR_TAG, as it allows to characterise pairs by several holes, which could be used to learn analogies, cf.', ' #AUTHOR_TAG']","['i 1, ( nsub ; gave 2 ; @ ) >. this representation scheme is more generic then the schemes introduced in  #TAUTHOR_TAG, as it allows to characterise pairs by several holes, which could be used to learn analog']","['holing operation splits an observation ( e. g. a dependency relation ) into a pair of two parts : a term and a context feature.', 'this captures their firstorder relationship.', 'these pairs are subsequently used for the computation of the similarities between terms, leading to a second - order relation.', 'the representation can be formalized by the pair < x, y > where x is the term and y represents the context feature.', ""the position of x in y is denoted by the hole symbol'@ '."", 'as an example the dependency relation ( nsub ; gave 2 ; i 1 ) could be transferred to < gave 2, ( nsub ; @ ; i 1 ) > and < i 1, ( nsub ; gave 2 ; @ ) >. this representation scheme is more generic then the schemes introduced in  #TAUTHOR_TAG, as it allows to characterise pairs by several holes, which could be used to learn analogies, cf.', ' #AUTHOR_TAG']",4
['by  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG we'],['by  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG we'],"['by  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG we do not calculate any information measure using frequencies of features and terms ( we use significance ranking instead ), as shown in table 1.', 'additionally, we avoid any similarity measurement using the information measure, as also']","[', we count the frequency for each first - order relation and remove all features that occur with more than w terms, as these context features tend to be too general to characterise the similarity between other words ( rychly and  #AUTHOR_TAG cmp. ).', 'from this. we calculate a significance score for all first - order relations.', ""for this work, we implemented two different significance measures : pointwise mutual information ( pmi ) :  #AUTHOR_TAG and lexicographer's mutual information ( lmi ) :"", 'we then prune all negatively correlated pairs ( s < 0 ).', 'the maximum number of context features per term are defined with p, as we argue that it is sufficient to keep only the p most salient ( ordered descending by their significance score ) context features per term.', 'features of low saliency generally should not contribute much to the similarity of terms and also could lead to spurious similarity scores.', 'afterwards, all terms are aggregated by their features, which allows us to compute similarity scores between all terms that share at least one such feature.', 'whereas the method introduced by  #AUTHOR_TAG is very similar to the one proposed in this paper ( the similarity between terms is calculated solely by the number of features two terms share ), they use pmi to rank features and do not use pruning to scale to large corpora, as they use a rather small corpus.', 'additionally, they do not evaluate the effect of such pruning.', 'in contrast to the best measures proposed by  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG we do not calculate any information measure using frequencies of features and terms ( we use significance ranking instead ), as shown in table 1.', 'additionally, we avoid any similarity measurement using the information measure, as also done in these approaches, to calculate the similarity over the feature counts of each term : we merely count how many salient features two terms share.', ""all these constraints makes this approach more scalable to larger corpora, as we do not need to know the full list of information measures lin's formula i ( term, f eature ) = lin ( term, f eature ) =""]",4
"['stated in  #TAUTHOR_TAG 1.', 'an']","['stated in  #TAUTHOR_TAG 1.', 'an']","['stated in  #TAUTHOR_TAG 1.', 'an explanation']","["", we inspect the results of curran's measure using the wikipedia and newspaper corpus for the frequent nouns, shown in figure 1."", 'both graphs show the inverse ranking score against the size of the corpus.', 'our method scores consistently higher when using lmi instead of pmi for ranking the features per term.', 'the pmi measure declines when the corpus becomes larger.', 'this can be attributed to the fact that pmi favors term - context pairs involving rare contexts  #AUTHOR_TAG.', 'computing similarities between terms should not be performed on the basis of rare contexts, as these do not generalize well because of their sparseness.', 'all other measures improve with larger corpora.', 'it is surprising that recent works use pmi to calculate similarities between terms  #AUTHOR_TAG, who, however evaluate their approach only with respect to their own implementation or extrinsically, and do not prune on saliency.', ""apart from the pmi measure, curran's measure leads to the weakest results."", ""we could not confirm that his measure outperforms lin's measure as stated in  #TAUTHOR_TAG 1."", 'an explanation for this results might be the use of a different parser, very few test words and also a different gold standard thesaurus in his evaluation.', ""comparing our method using lmi to lin's method, we achieve lower scores with our method using small corpora, but surpass lin's measure from 10 million sentences onwards."", 'next, we show the results of the wordnet evaluation measure in figure 2.', '']",4
['by  #TAUTHOR_TAG ( see'],['by  #TAUTHOR_TAG ( see'],"['by  #TAUTHOR_TAG ( see table 1 ).', 'our evaluation is performed using the same 1000 frequent and 1000 infrequent nouns as previously employed by  #AUTHOR_TAG.', 'we create a gold standard, by extracting reasonable entries of these 2000 nouns using ro']","['evaluation is performed using a recent dump of english wikipedia, containing 36 million sentences and a newspaper corpus, compiled from 120 million sentences ( about 2 gigawords ) from leipzig corpora collection  #AUTHOR_TAG and the gigaword corpus  #AUTHOR_TAG.', 'the dts are based on collapsed dependencies from the stanford parser  #AUTHOR_TAG in the holing operation.', 'for all dts we use the pruning parameters s = 0, p = 1000 and w = 1000.', 'in a final evaluation, we use the syntactic n - grams built from google books  #AUTHOR_TAG.', 'to show the impact of corpus size, we downsampled our corpora to 10 million, 1 million and 100, 000 sentences.', ""we compare our results against dts calculated using lin's  #AUTHOR_TAG measure and the best measure proposed by  #TAUTHOR_TAG ( see table 1 )."", 'our evaluation is performed using the same 1000 frequent and 1000 infrequent nouns as previously employed by  #AUTHOR_TAG.', ""we create a gold standard, by extracting reasonable entries of these 2000 nouns using roget's 1911 thesaurus, moby thesaurus, merriam webster's thesaurus, the big huge thesaurus and the openoffice thesaurus and employ the inverse ranking measure  #TAUTHOR_TAG to evaluate the dts."", 'furthermore, we introduce a wordnet - based method.', 'to calculate the similarity between two terms, we use the wordnet : : similarity path  #AUTHOR_TAG measure.', 'while its absolute scores are hard to interpret due to inhomogenity in the granularity of wordnet, they are well - suited for relative comparison.', 'the score between two terms is inversely proportional to the shortest path between all the synsets of both terms.', 'the highest possible score is one, if two terms share a synset.', 'we compare the average score of the top five ( or ten ) entries in the dt for each of the 2000 selected words for our comparison']",7
['by  #TAUTHOR_TAG ( see'],['by  #TAUTHOR_TAG ( see'],"['by  #TAUTHOR_TAG ( see table 1 ).', 'our evaluation is performed using the same 1000 frequent and 1000 infrequent nouns as previously employed by  #AUTHOR_TAG.', 'we create a gold standard, by extracting reasonable entries of these 2000 nouns using ro']","['evaluation is performed using a recent dump of english wikipedia, containing 36 million sentences and a newspaper corpus, compiled from 120 million sentences ( about 2 gigawords ) from leipzig corpora collection  #AUTHOR_TAG and the gigaword corpus  #AUTHOR_TAG.', 'the dts are based on collapsed dependencies from the stanford parser  #AUTHOR_TAG in the holing operation.', 'for all dts we use the pruning parameters s = 0, p = 1000 and w = 1000.', 'in a final evaluation, we use the syntactic n - grams built from google books  #AUTHOR_TAG.', 'to show the impact of corpus size, we downsampled our corpora to 10 million, 1 million and 100, 000 sentences.', ""we compare our results against dts calculated using lin's  #AUTHOR_TAG measure and the best measure proposed by  #TAUTHOR_TAG ( see table 1 )."", 'our evaluation is performed using the same 1000 frequent and 1000 infrequent nouns as previously employed by  #AUTHOR_TAG.', ""we create a gold standard, by extracting reasonable entries of these 2000 nouns using roget's 1911 thesaurus, moby thesaurus, merriam webster's thesaurus, the big huge thesaurus and the openoffice thesaurus and employ the inverse ranking measure  #TAUTHOR_TAG to evaluate the dts."", 'furthermore, we introduce a wordnet - based method.', 'to calculate the similarity between two terms, we use the wordnet : : similarity path  #AUTHOR_TAG measure.', 'while its absolute scores are hard to interpret due to inhomogenity in the granularity of wordnet, they are well - suited for relative comparison.', 'the score between two terms is inversely proportional to the shortest path between all the synsets of both terms.', 'the highest possible score is one, if two terms share a synset.', 'we compare the average score of the top five ( or ten ) entries in the dt for each of the 2000 selected words for our comparison']",5
"['( e. g.  #TAUTHOR_TAG.', '']","['( e. g.  #TAUTHOR_TAG.', 'sentence - level representations have shown promise in multiple different nlp tasks.', 'one prominent']","['building representations of natural language on multiple levels of abstraction.', 'perhaps the most widely used representations in natural language processing are word embeddings ( e. g.  #AUTHOR_TAG.', 'recently there has been a growing interest in models for sentence - level representations using neural networks.', 'sentence embeddings are distributed representations of natural language sentences with the intention to encode the meaning of the sentences in a neural network representation.', 'sentence embeddings have been generated using unsupervised learning approaches ( e. g.  #AUTHOR_TAG, and supervised learning ( e. g.  #TAUTHOR_TAG.', '']","['networks have been shown to provide a powerful tool for building representations of natural language on multiple levels of abstraction.', 'perhaps the most widely used representations in natural language processing are word embeddings ( e. g.  #AUTHOR_TAG.', 'recently there has been a growing interest in models for sentence - level representations using neural networks.', 'sentence embeddings are distributed representations of natural language sentences with the intention to encode the meaning of the sentences in a neural network representation.', 'sentence embeddings have been generated using unsupervised learning approaches ( e. g.  #AUTHOR_TAG, and supervised learning ( e. g.  #TAUTHOR_TAG.', 'sentence - level representations have shown promise in multiple different nlp tasks.', '']",0
"['( e. g.  #TAUTHOR_TAG.', '']","['( e. g.  #TAUTHOR_TAG.', 'sentence - level representations have shown promise in multiple different nlp tasks.', 'one prominent']","['building representations of natural language on multiple levels of abstraction.', 'perhaps the most widely used representations in natural language processing are word embeddings ( e. g.  #AUTHOR_TAG.', 'recently there has been a growing interest in models for sentence - level representations using neural networks.', 'sentence embeddings are distributed representations of natural language sentences with the intention to encode the meaning of the sentences in a neural network representation.', 'sentence embeddings have been generated using unsupervised learning approaches ( e. g.  #AUTHOR_TAG, and supervised learning ( e. g.  #TAUTHOR_TAG.', '']","['networks have been shown to provide a powerful tool for building representations of natural language on multiple levels of abstraction.', 'perhaps the most widely used representations in natural language processing are word embeddings ( e. g.  #AUTHOR_TAG.', 'recently there has been a growing interest in models for sentence - level representations using neural networks.', 'sentence embeddings are distributed representations of natural language sentences with the intention to encode the meaning of the sentences in a neural network representation.', 'sentence embeddings have been generated using unsupervised learning approaches ( e. g.  #AUTHOR_TAG, and supervised learning ( e. g.  #TAUTHOR_TAG.', 'sentence - level representations have shown promise in multiple different nlp tasks.', '']",0
"['classifier.', ' #TAUTHOR_TAG explore multiple different sentence embedding architectures ranging']","['classifier.', ' #TAUTHOR_TAG explore multiple different sentence embedding architectures ranging']","['then combine those using a neural network classifier.', ' #TAUTHOR_TAG explore multiple different sentence embedding architectures ranging']","['embeddings have been utilized in a wide variety of approaches to natural language inference.', ' #AUTHOR_TAG bowman et al. (, 2016 explore rnn and lstm architectures,  #AUTHOR_TAG convolutional neural networks and  #AUTHOR_TAG grus, to name a few.', 'the basic idea behind these approaches is to encode the premise and hypothesis sentences separately and then combine those using a neural network classifier.', ' #TAUTHOR_TAG explore multiple different sentence embedding architectures ranging from lstm, bilstm and intra - attention to convolution neural networks and the performance of these architectures on nli tasks.', 'they show that out of these models bilstm with max pooling achieves the strongest results in nli.', 'they also show that their model trained on nli data achieves strong performance on various transfer learning tasks.', 'although sentence embedding approaches have shown their effectiveness in nli, there are multiple studies showing that treating the hypothesis and premise sentences together and focusing on the relationship between those sentences yields better results ( e. g.  #AUTHOR_TAG a ).', 'however, as these methods are focused on the inference relations rather than the internal semantics of the sentences, they cannot as straightforwardly be used outside of the nli context and do not offer similar insights about the sentence level semantics, as sentence embeddings do.', 'by choosing a sentence embedding - based architecture we can more easily use the models in a wide variety of nlp tasks requiring sentence - level semantic information']",0
['sentence embedding evaluation library 5  #TAUTHOR_TAG'],['sentence embedding evaluation library 5  #TAUTHOR_TAG'],['evaluation library 5  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
"['( e. g.  #TAUTHOR_TAG.', '']","['( e. g.  #TAUTHOR_TAG.', 'sentence - level representations have shown promise in multiple different nlp tasks.', 'one prominent']","['building representations of natural language on multiple levels of abstraction.', 'perhaps the most widely used representations in natural language processing are word embeddings ( e. g.  #AUTHOR_TAG.', 'recently there has been a growing interest in models for sentence - level representations using neural networks.', 'sentence embeddings are distributed representations of natural language sentences with the intention to encode the meaning of the sentences in a neural network representation.', 'sentence embeddings have been generated using unsupervised learning approaches ( e. g.  #AUTHOR_TAG, and supervised learning ( e. g.  #TAUTHOR_TAG.', '']","['networks have been shown to provide a powerful tool for building representations of natural language on multiple levels of abstraction.', 'perhaps the most widely used representations in natural language processing are word embeddings ( e. g.  #AUTHOR_TAG.', 'recently there has been a growing interest in models for sentence - level representations using neural networks.', 'sentence embeddings are distributed representations of natural language sentences with the intention to encode the meaning of the sentences in a neural network representation.', 'sentence embeddings have been generated using unsupervised learning approaches ( e. g.  #AUTHOR_TAG, and supervised learning ( e. g.  #TAUTHOR_TAG.', 'sentence - level representations have shown promise in multiple different nlp tasks.', '']",1
"[', h t ).', 'motivated by the strong results of the bilstm max pooling network by  #TAUTHOR_TAG, we experimented with combining bilstm max pooling networks as a hierarchical']","[', h t ).', 'motivated by the strong results of the bilstm max pooling network by  #TAUTHOR_TAG, we experimented with combining bilstm max pooling networks as a hierarchical']","['h 1,..., h t ).', 'motivated by the strong results of the bilstm max pooling network by  #TAUTHOR_TAG, we experimented with combining bilstm max pooling networks as']","['', 'motivated by the strong results of the bilstm max pooling network by  #TAUTHOR_TAG, we experimented with combining bilstm max pooling networks as a hierarchical structure.', ""1 to improve the bilstm layers'ability to remember the input words, we let each layer of the stack re - read the input sentence."", 'in our baseline model we stack three bilstm max pooling networks as a hierarchical structure, where each bilstm reads the input sentence as the input.', 'at each bilstm layer except the first one, we initialize the initial hidden state and the cell state with the final state of the previous layer.', 'we take the max value over each dimension of the hidden units for each bilstm layer.', 'the final output of the sentence embedding is the concatenation of each of these max pooling layers.', 'our sentence embedding architecture is visualized in figure 2']",1
['datasets in order to compare to the results by  #TAUTHOR_TAG'],['the multinli datasets in order to compare to the results by  #TAUTHOR_TAG'],['the multinli datasets in order to compare to the results by  #TAUTHOR_TAG'],"['evaluated the sentence embedding architecture with three different natural language inference datasets, including the stanford natural language inference ( snli ) corpus, the multi - genre natural language inference ( multinli ) corpus and the scitail dataset.', 'in all our experiments with the three datasets we used only the training data provided in the respective corpus.', 'for the transfer learning tasks, described in section 7, we used training data from both the snli and the multinli datasets in order to compare to the results by  #TAUTHOR_TAG']",1
"['( e. g.  #TAUTHOR_TAG.', '']","['( e. g.  #TAUTHOR_TAG.', 'sentence - level representations have shown promise in multiple different nlp tasks.', 'one prominent']","['building representations of natural language on multiple levels of abstraction.', 'perhaps the most widely used representations in natural language processing are word embeddings ( e. g.  #AUTHOR_TAG.', 'recently there has been a growing interest in models for sentence - level representations using neural networks.', 'sentence embeddings are distributed representations of natural language sentences with the intention to encode the meaning of the sentences in a neural network representation.', 'sentence embeddings have been generated using unsupervised learning approaches ( e. g.  #AUTHOR_TAG, and supervised learning ( e. g.  #TAUTHOR_TAG.', '']","['networks have been shown to provide a powerful tool for building representations of natural language on multiple levels of abstraction.', 'perhaps the most widely used representations in natural language processing are word embeddings ( e. g.  #AUTHOR_TAG.', 'recently there has been a growing interest in models for sentence - level representations using neural networks.', 'sentence embeddings are distributed representations of natural language sentences with the intention to encode the meaning of the sentences in a neural network representation.', 'sentence embeddings have been generated using unsupervised learning approaches ( e. g.  #AUTHOR_TAG, and supervised learning ( e. g.  #TAUTHOR_TAG.', 'sentence - level representations have shown promise in multiple different nlp tasks.', '']",5
['bilstm max pooling model of  #TAUTHOR_TAG ( our implementation )'],"['bilstm max pooling model of  #TAUTHOR_TAG ( our implementation ).', '4 3 for more detailed error statistics, see the appendix.', '4 the scores for our implementation of infersent are on par or slightly higher than the scores reported by  #TAUTHOR_TAG using their training setup']","['with the infersent bilstm max pooling model of  #TAUTHOR_TAG ( our implementation ).', '4 3 for more detailed error statistics, see the appendix.', '4 the scores for our implementation of infersen']","['understand better what kind of inferential relationships our model is able to identify, we conducted an error analysis for the three datasets.', 'we report the results below.', '3 we also conducted a linguistic error analysis and compared our results to the results obtained with the infersent bilstm max pooling model of  #TAUTHOR_TAG ( our implementation ).', '4 3 for more detailed error statistics, see the appendix.', '4 the scores for our implementation of infersent are on par or slightly higher than the scores reported by  #TAUTHOR_TAG using their training setup']",5
['sentence embedding evaluation library 5  #TAUTHOR_TAG'],['sentence embedding evaluation library 5  #TAUTHOR_TAG'],['evaluation library 5  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],5
"['implementation using the architecture and training set - up described in  #TAUTHOR_TAG.', 'scores highlighted with bold are top scores when comparing the infer']","['implementation using the architecture and training set - up described in  #TAUTHOR_TAG.', 'scores highlighted with bold are top scores when comparing the infersent and our hbmp model']","['implementation using the architecture and training set - up described in  #TAUTHOR_TAG.', 'scores highlighted with bold are top scores when comparing the infersent and our hbmp model']","['', 'our model also compares well against the other models, outperforming decomposable attention model ( 51. 90 % )  #AUTHOR_TAG and residual encoders ( 62. 20 % )  #AUTHOR_TAG b ) in the overall score.', 'as these models are not based purely on sentence embeddings, the obtained result highlights that sentence embedding approaches can be competitive when handling inferences requiring lexical information.', 'our model is still outperformed by and esim  #AUTHOR_TAG a ) and kim, an esim model incorporating external knowledge  #AUTHOR_TAG.', 'the results of the comparison are summarized in  #AUTHOR_TAG.', 'infersent results obtained with our implementation using the architecture and training set - up described in  #TAUTHOR_TAG.', 'scores highlighted with bold are top scores when comparing the infersent and our hbmp model']",5
"['( e. g.  #TAUTHOR_TAG.', '']","['( e. g.  #TAUTHOR_TAG.', 'sentence - level representations have shown promise in multiple different nlp tasks.', 'one prominent']","['building representations of natural language on multiple levels of abstraction.', 'perhaps the most widely used representations in natural language processing are word embeddings ( e. g.  #AUTHOR_TAG.', 'recently there has been a growing interest in models for sentence - level representations using neural networks.', 'sentence embeddings are distributed representations of natural language sentences with the intention to encode the meaning of the sentences in a neural network representation.', 'sentence embeddings have been generated using unsupervised learning approaches ( e. g.  #AUTHOR_TAG, and supervised learning ( e. g.  #TAUTHOR_TAG.', '']","['networks have been shown to provide a powerful tool for building representations of natural language on multiple levels of abstraction.', 'perhaps the most widely used representations in natural language processing are word embeddings ( e. g.  #AUTHOR_TAG.', 'recently there has been a growing interest in models for sentence - level representations using neural networks.', 'sentence embeddings are distributed representations of natural language sentences with the intention to encode the meaning of the sentences in a neural network representation.', 'sentence embeddings have been generated using unsupervised learning approaches ( e. g.  #AUTHOR_TAG, and supervised learning ( e. g.  #TAUTHOR_TAG.', 'sentence - level representations have shown promise in multiple different nlp tasks.', '']",4
"[', h t ).', 'motivated by the strong results of the bilstm max pooling network by  #TAUTHOR_TAG, we experimented with combining bilstm max pooling networks as a hierarchical']","[', h t ).', 'motivated by the strong results of the bilstm max pooling network by  #TAUTHOR_TAG, we experimented with combining bilstm max pooling networks as a hierarchical']","['h 1,..., h t ).', 'motivated by the strong results of the bilstm max pooling network by  #TAUTHOR_TAG, we experimented with combining bilstm max pooling networks as']","['', 'motivated by the strong results of the bilstm max pooling network by  #TAUTHOR_TAG, we experimented with combining bilstm max pooling networks as a hierarchical structure.', ""1 to improve the bilstm layers'ability to remember the input words, we let each layer of the stack re - read the input sentence."", 'in our baseline model we stack three bilstm max pooling networks as a hierarchical structure, where each bilstm reads the input sentence as the input.', 'at each bilstm layer except the first one, we initialize the initial hidden state and the cell state with the final state of the previous layer.', 'we take the max value over each dimension of the hidden units for each bilstm layer.', 'the final output of the sentence embedding is the concatenation of each of these max pooling layers.', 'our sentence embedding architecture is visualized in figure 2']",6
['bilstm max pooling model of  #TAUTHOR_TAG ( our implementation )'],"['bilstm max pooling model of  #TAUTHOR_TAG ( our implementation ).', '4 3 for more detailed error statistics, see the appendix.', '4 the scores for our implementation of infersent are on par or slightly higher than the scores reported by  #TAUTHOR_TAG using their training setup']","['with the infersent bilstm max pooling model of  #TAUTHOR_TAG ( our implementation ).', '4 3 for more detailed error statistics, see the appendix.', '4 the scores for our implementation of infersen']","['understand better what kind of inferential relationships our model is able to identify, we conducted an error analysis for the three datasets.', 'we report the results below.', '3 we also conducted a linguistic error analysis and compared our results to the results obtained with the infersent bilstm max pooling model of  #TAUTHOR_TAG ( our implementation ).', '4 3 for more detailed error statistics, see the appendix.', '4 the scores for our implementation of infersent are on par or slightly higher than the scores reported by  #TAUTHOR_TAG using their training setup']",3
['sentence embedding evaluation library 5  #TAUTHOR_TAG'],['sentence embedding evaluation library 5  #TAUTHOR_TAG'],['evaluation library 5  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],3
['sentence embedding evaluation library 5  #TAUTHOR_TAG'],['sentence embedding evaluation library 5  #TAUTHOR_TAG'],['evaluation library 5  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],7
"['is capable of to infersent bil - stm max pooling model  #TAUTHOR_TAG, in order to see what benefits']","['is capable of to infersent bil - stm max pooling model  #TAUTHOR_TAG, in order to see what benefits']","['of linguistic reasoning it is capable of to infersent bil - stm max pooling model  #TAUTHOR_TAG, in order to see what benefits']","['also conducted a linguistic error analysis for the hbmp model using the multinli annotation set.', 'we compare our model and the type of linguistic reasoning it is capable of to infersent bil - stm max pooling model  #TAUTHOR_TAG, in order to see what benefits are achieved by adding a hierarchical bilstm max pooling structure on top of the basic bilstm max pooling architecture.', 'we provide a detailed comparison of the prediction accuracies of our hbmp model with infersent with respect to the type of linguistic properties present in the sentence pairs.', 'table 10 contains the comparison for multinli - m dataset and table 11 for multinli - mm dataset.', 'the analysis show that our hbmp model outperforms infersent in some of the categories, but the results are mostly at this point inconclusive']",7
"['of learning narrative chains from text corpora  #TAUTHOR_TAG.', 'these statistical']","['of learning narrative chains from text corpora  #TAUTHOR_TAG.', 'these statistical']","['of learning narrative chains from text corpora  #TAUTHOR_TAG.', 'these statistical approaches have focused on open - domain script acquisition, in which a large number of scripts may be learned, but the acquisition of any particular set of scripts is not guaranteed']","['well - known theory from the intersection of psychology and artificial intelligence posits that humans organize certain kinds of general knowledge in the form of scripts, or common sequences of events  #AUTHOR_TAG.', 'though many early ai systems employed hand - encoded scripts, more recent work has attempted to induce scripts with automatic and scalable techniques.', 'in particular, several related techniques approach the problem of script induction as one of learning narrative chains from text corpora  #TAUTHOR_TAG.', 'these statistical approaches have focused on open - domain script acquisition, in which a large number of scripts may be learned, but the acquisition of any particular set of scripts is not guaranteed.', 'for many specialized applications, however, knowledge of a few relevant scripts may be more useful than knowledge of many irrelevant scripts.', 'with this scenario in mind, we attempt to learn the famous "" restaurant script ""  #AUTHOR_TAG by applying the aforementioned narrative chain learning methods to a specialized corpus of dinner narratives we compile from the website "" dinners from hell. "" our results suggest that applying these techniques to a domain - specific dataset may be reasonable way to learn domain - specific scripts']",0
['narrative chains  #TAUTHOR_TAG. it is from this'],['narrative chains  #TAUTHOR_TAG. it is from this'],['narrative chains  #TAUTHOR_TAG. it is from this body'],"['exists, previous work demonstrates the feasibility of assembling such a corpus by automatically retrieving relevant documents from a', 'larger collection. for example,  #AUTHOR_TAG use information retrieval techniques to gather a small number of bombing - related documents from the gigaword corpus, which they successfully use to learn a mucstyle  #AUTHOR_TAG', 'information extraction tem - plate for bombing events. following the work of  #AUTHOR_TAG in learning word associations via mutual information, and the dirt system introduced by  #AUTHOR_TAG,  #AUTHOR_TAG propose a pmi - based system for learning script - like structures called narrative chains. several followup', 'papers introduce variations and improvements on this original model for learning narrative chains  #TAUTHOR_TAG. it is from this body of work that we borrow techniques to apply to the dinners from hell dataset. as defined by  #AUTHOR_TAG, a narrative chain is', '"" a partially ordered set of narrative events that share a common actor, "" where a narrative event is "" a tuple of an event ( most simply a verb ) and its participants, represented as typed dependencies. "" to learn narrative chains', '']",0
['narrative chains  #TAUTHOR_TAG. it is from this'],['narrative chains  #TAUTHOR_TAG. it is from this'],['narrative chains  #TAUTHOR_TAG. it is from this body'],"['exists, previous work demonstrates the feasibility of assembling such a corpus by automatically retrieving relevant documents from a', 'larger collection. for example,  #AUTHOR_TAG use information retrieval techniques to gather a small number of bombing - related documents from the gigaword corpus, which they successfully use to learn a mucstyle  #AUTHOR_TAG', 'information extraction tem - plate for bombing events. following the work of  #AUTHOR_TAG in learning word associations via mutual information, and the dirt system introduced by  #AUTHOR_TAG,  #AUTHOR_TAG propose a pmi - based system for learning script - like structures called narrative chains. several followup', 'papers introduce variations and improvements on this original model for learning narrative chains  #TAUTHOR_TAG. it is from this body of work that we borrow techniques to apply to the dinners from hell dataset. as defined by  #AUTHOR_TAG, a narrative chain is', '"" a partially ordered set of narrative events that share a common actor, "" where a narrative event is "" a tuple of an event ( most simply a verb ) and its participants, represented as typed dependencies. "" to learn narrative chains', '']",3
"['50', ' #TAUTHOR_TAG. baseline the baseline we use for the narrative cloze task is']","['at 50', ' #TAUTHOR_TAG. baseline the baseline we use for the narrative cloze task is']","['', ' #TAUTHOR_TAG. baseline the baseline we use for the narrative cloze task is']","['', ' #TAUTHOR_TAG. baseline the baseline we use for the narrative cloze task is to rank events by frequency. this is the "" unigram model "" employed by  #AUTHOR_TAG, a competitive baseline on this task.', 'for each model and scoring metric, we perform a complete grid search over all possible parameter settings to find the best -', 'scoring combination on a cloze tests from a set - aside development set of ten documents. the parameter space is defined as the cartesian product of each of the following possible parameter values : skip', '- n ( all, 0 - 5 )', ', coreference chain length ( all, long, longest ), count threshold (', '']",3
['narrative chains  #TAUTHOR_TAG. it is from this'],['narrative chains  #TAUTHOR_TAG. it is from this'],['narrative chains  #TAUTHOR_TAG. it is from this body'],"['exists, previous work demonstrates the feasibility of assembling such a corpus by automatically retrieving relevant documents from a', 'larger collection. for example,  #AUTHOR_TAG use information retrieval techniques to gather a small number of bombing - related documents from the gigaword corpus, which they successfully use to learn a mucstyle  #AUTHOR_TAG', 'information extraction tem - plate for bombing events. following the work of  #AUTHOR_TAG in learning word associations via mutual information, and the dirt system introduced by  #AUTHOR_TAG,  #AUTHOR_TAG propose a pmi - based system for learning script - like structures called narrative chains. several followup', 'papers introduce variations and improvements on this original model for learning narrative chains  #TAUTHOR_TAG. it is from this body of work that we borrow techniques to apply to the dinners from hell dataset. as defined by  #AUTHOR_TAG, a narrative chain is', '"" a partially ordered set of narrative events that share a common actor, "" where a narrative event is "" a tuple of an event ( most simply a verb ) and its participants, represented as typed dependencies. "" to learn narrative chains', '']",5
"['modifications of  #TAUTHOR_TAG.', 'as part of this']","['modifications of  #TAUTHOR_TAG.', 'as part of this work, we are releasing a program called nachos, our integrated python implementation of']","['to learn narrative chains from the dinners from hell corpus, starting with the original model  #AUTHOR_TAG and extending to the modifications of  #TAUTHOR_TAG.', 'as part of this work, we are releasing a program called nachos, our integrated python implementation of']","['section provides an overview of each of the different methods and parameter settings we employ to learn narrative chains from the dinners from hell corpus, starting with the original model  #AUTHOR_TAG and extending to the modifications of  #TAUTHOR_TAG.', 'as part of this work, we are releasing a program called nachos, our integrated python implementation of each of the methods for learning narrative chains described in this section.', '']",4
"[').', "" #TAUTHOR_TAG's option to count over only the longest chains in each document, or to count only over chains of length 5 or greater ( long )."", 'count threshold because pmi favors low - count events, we add an option to set']","['2 to 0 though 5 intervening events ( skip - 0 through skip - 5 ).', "" #TAUTHOR_TAG's option to count over only the longest chains in each document, or to count only over chains of length 5 or greater ( long )."", 'count threshold because pmi favors low - count events, we add an option to set']","[').', "" #TAUTHOR_TAG's option to count over only the longest chains in each document, or to count only over chains of length 5 or greater ( long )."", 'count threshold because pmi favors low - count events, we add an option to set']","[', a narrative event, e : = ( v, d ), is a verb, v, paired with a typed dependency  #AUTHOR_TAG, d, defining the role a "" protagonist "" ( coreference mention ) plays in an event ( verb ).', ""the main computational component of learning narrative chains in chambers and jurafsky's model is to learn the pointwise mutual information for any pair of narrative events :"", 'pmi ( e 1, e 2 ) : = log c ( e 1, e 2 ) c ( e 1, * ) c ( *, e 2 )', '( 1 ) where c ( e 1, e 2 ) is the number of times that narrative events e 1 and e 2 "" co - occur "" and', 'chambers and jurafsky define c ( e 1, e 2 ) as "" the number of times the two events e 1 and e 2 had a coreferring entity filling the values of the dependencies d 1 and d 2. "" this is a symmetric value with respect to e 1 and e 2.', 'we implement the following counting variants :', 'skip n - gram by default, c ( e 1, e 2 ) is incremented if e 1 and e 2 occur anywhere within the same chain of events derived from a single coreference chain ( skip - all ) ; we also implement an option to restrict the distance between e 1 and e 2 to 0 though 5 intervening events ( skip - 0 through skip - 5 ).', "" #TAUTHOR_TAG's option to count over only the longest chains in each document, or to count only over chains of length 5 or greater ( long )."", 'count threshold because pmi favors low - count events, we add an option to set c ( e 1, e 2 ) to zero for any e 1, e 2 for which c ( e 1, e 2 ) is below some threshold, t, up to 5']",4
"['50', ' #TAUTHOR_TAG. baseline the baseline we use for the narrative cloze task is']","['at 50', ' #TAUTHOR_TAG. baseline the baseline we use for the narrative cloze task is']","['', ' #TAUTHOR_TAG. baseline the baseline we use for the narrative cloze task is']","['', ' #TAUTHOR_TAG. baseline the baseline we use for the narrative cloze task is to rank events by frequency. this is the "" unigram model "" employed by  #AUTHOR_TAG, a competitive baseline on this task.', 'for each model and scoring metric, we perform a complete grid search over all possible parameter settings to find the best -', 'scoring combination on a cloze tests from a set - aside development set of ten documents. the parameter space is defined as the cartesian product of each of the following possible parameter values : skip', '- n ( all, 0 - 5 )', ', coreference chain length ( all, long, longest ), count threshold (', '']",4
"['modifications of  #TAUTHOR_TAG.', 'as part of this']","['modifications of  #TAUTHOR_TAG.', 'as part of this work, we are releasing a program called nachos, our integrated python implementation of']","['to learn narrative chains from the dinners from hell corpus, starting with the original model  #AUTHOR_TAG and extending to the modifications of  #TAUTHOR_TAG.', 'as part of this work, we are releasing a program called nachos, our integrated python implementation of']","['section provides an overview of each of the different methods and parameter settings we employ to learn narrative chains from the dinners from hell corpus, starting with the original model  #AUTHOR_TAG and extending to the modifications of  #TAUTHOR_TAG.', 'as part of this work, we are releasing a program called nachos, our integrated python implementation of each of the methods for learning narrative chains described in this section.', '']",6
"[').', "" #TAUTHOR_TAG's option to count over only the longest chains in each document, or to count only over chains of length 5 or greater ( long )."", 'count threshold because pmi favors low - count events, we add an option to set']","['2 to 0 though 5 intervening events ( skip - 0 through skip - 5 ).', "" #TAUTHOR_TAG's option to count over only the longest chains in each document, or to count only over chains of length 5 or greater ( long )."", 'count threshold because pmi favors low - count events, we add an option to set']","[').', "" #TAUTHOR_TAG's option to count over only the longest chains in each document, or to count only over chains of length 5 or greater ( long )."", 'count threshold because pmi favors low - count events, we add an option to set']","[', a narrative event, e : = ( v, d ), is a verb, v, paired with a typed dependency  #AUTHOR_TAG, d, defining the role a "" protagonist "" ( coreference mention ) plays in an event ( verb ).', ""the main computational component of learning narrative chains in chambers and jurafsky's model is to learn the pointwise mutual information for any pair of narrative events :"", 'pmi ( e 1, e 2 ) : = log c ( e 1, e 2 ) c ( e 1, * ) c ( *, e 2 )', '( 1 ) where c ( e 1, e 2 ) is the number of times that narrative events e 1 and e 2 "" co - occur "" and', 'chambers and jurafsky define c ( e 1, e 2 ) as "" the number of times the two events e 1 and e 2 had a coreferring entity filling the values of the dependencies d 1 and d 2. "" this is a symmetric value with respect to e 1 and e 2.', 'we implement the following counting variants :', 'skip n - gram by default, c ( e 1, e 2 ) is incremented if e 1 and e 2 occur anywhere within the same chain of events derived from a single coreference chain ( skip - all ) ; we also implement an option to restrict the distance between e 1 and e 2 to 0 though 5 intervening events ( skip - 0 through skip - 5 ).', "" #TAUTHOR_TAG's option to count over only the longest chains in each document, or to count only over chains of length 5 or greater ( long )."", 'count threshold because pmi favors low - count events, we add an option to set c ( e 1, e 2 ) to zero for any e 1, e 2 for which c ( e 1, e 2 ) is below some threshold, t, up to 5']",6
"['2 ) is symmetric.', 'two additional models are introduced by  #TAUTHOR_TAG and we use them here, as well.', 'first,']","['2 ) is symmetric.', 'two additional models are introduced by  #TAUTHOR_TAG and we use them here, as well.', 'first,']","['2 ) is symmetric.', 'two additional models are introduced by  #TAUTHOR_TAG and we use them here, as well.', 'first, the ordered pmi model,', 'pmi']","['order to perform the narrative cloze task, we need a model for predicting the missing narrative event, e, from a chain of observed narrative events, e 1...', 'e n, at insertion point k. the original model, proposed by  #AUTHOR_TAG, predicts the event that maximizes unordered pmi,', 'where v is the set of all observed events ( the vocabulary ) and c ( e 1, e 2 ) is symmetric.', 'two additional models are introduced by  #TAUTHOR_TAG and we use them here, as well.', 'first, the ordered pmi model,', 'pmi ( e, e i ) ( 4 ) where c ( e 1, e 2 ) is asymmetric, i. e., c ( e 1, e 2 ) counts only cases in which e 1 occurs before e 2.', 'second, the bigram probability model :', 'where p ( e 2 | e 1 ) = c ( e 1, e 2 )', 'c ( e 1, * ) and c ( e 1, e 2 ) is asymmetric.', 'discounting for each model, we add an option for discounting the computed scores.', 'in the case of the two pmi - based models, we use the discount score described in  #AUTHOR_TAG and used by  #AUTHOR_TAG.', 'for the bigram probability model, this pmi discount score would be inappropriate, so we instead use absolute discounting.', 'document threshold we include a document threshold parameter, d, that ensures that, in any narrative cloze test, any event e that was observed during training in fewer than d distinct documents will receive a worse score ( i. e. be ranked behind ) any event e whose count meets the document threshold']",2
"['now back online  #TAUTHOR_TAG. unfortunately, in']","['now back online  #TAUTHOR_TAG. unfortunately, in some cases', 'even when code has been published,']","['now back online  #TAUTHOR_TAG. unfortunately, in some cases', 'even when code has been published,']","['a creative commons attribution 4. 0 international licence. licence details : http : / / creativecommons', '. org / licenses / by / 4. 0 / 1 we follow the definitions in antske fokkens\'guest blog post "" replication ( obtaining the same results using the same experiment ) as well as reproduction ( reach the same conclusion through different means ) "" from http : / /', 'coling2018. org / slowly - growing - offspring - zigglebottom - anno - 2017 - guest - post / are evaluated on the semeval dataset  #AUTHOR_TAG but not all. datasets can vary by domain ( e.', 'g. product ), type ( social media, review ), or medium ( written or spoken ), and to date there has been no comparative evaluation of methods from these multiple classes.', 'our primary and secondary contributions therefore, are to carry out the first study that reports results across all three different dataset classes, and to release a open source code framework implementing three complementary groups of tdsa methods. in terms of reproducibility via code release, recent tdsa papers have generally been very good with regards to publishing code alongside their papers  #AUTHOR_TAG but other papers have not', 'released code  #AUTHOR_TAG. in some cases, the code was initially made available, then removed, and is now back online  #TAUTHOR_TAG. unfortunately, in some cases', 'even when code has been published, different results have been obtained relative to the original paper. this can be seen when  #AUTHOR_TAG used the code and embeddings in  #AUTHOR_TAG b ) they observe different results', '. similarly, when others  #AUTHOR_TAG attempt to replicate the experiments of  #TAUTHOR_TAG they also produce different results to the original authors. our observations within this one', '']",1
"['did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were']","['did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were unsure']","['as stated in the original paper, and we did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were']","['a standard lstm that runs over the length of the sentence and takes no target information into account, 2. tdlstm runs two lstm', '##s, one over the left and the other over the right context of the target word and concatenates the output of the', 'two, and 3. tclstm same as the tdlstm method but each input word vector', 'is concatenated with vector of the target word. all of the methods outputs are fed', 'into a softmax activation function. the experiments are performed on the  #AUTHOR_TAG dataset where we train and test on the specified splits.', 'for the lstms we initialised the weights using uniform distribution u ( 0', '. 003, 0. 003 ), used stochastic gradient descent ( sgd ) a learning rate of 0. 01, cross entropy loss, padded', 'and truncated sequence to the length of the maximum sequence in the training', 'dataset as stated in the original paper, and we did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were unsure what this meant.', 'with regards to the number of epochs trained, we used early stopping with a patience of 10 and allowed 300 epochs. within their experiments they used sswe and', 'glove twitter vectors 11  #AUTHOR_TAG. as the paper being reproduced does not define the number of epochs they trained for, we use early stopping. thus for early stopping we require to split', 'the training data into train and validation sets to know when to stop. as it has been shown by  #AUTHOR_TAG that the random', 'seed statistically significantly changes the results of experiments we ran each model over each', 'word embedding thirty times, using a different seed value but keeping the same stratified train and validation', 'split, and reported the results on the same test data as the original paper. as can be seen in figure 4, the initial seed value makes a large difference more so for the smaller embeddings. in table 5, we show the difference between our mean and maximum result and the original result for each model using the 200 dimension glove twitter vectors. even though the mean result is quite different from the original the maximum is much closer. our results generally agree with their results on the ranking', 'of the word vectors and the embeddings. overall, we were able to reproduce the results of all three papers. however for', 'the neural network / deep learning approach of  #TAUTHOR_TAG we agree with  #AUTHOR_TAG that reporting', 'multiple runs of the system over different seed values is required as the single performance scores can be misleading, which', 'could explain why previous papers obtained different results to the original for the tdlstm method  #AUTHOR_TAG']",6
"['did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were']","['did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were unsure']","['as stated in the original paper, and we did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were']","['a standard lstm that runs over the length of the sentence and takes no target information into account, 2. tdlstm runs two lstm', '##s, one over the left and the other over the right context of the target word and concatenates the output of the', 'two, and 3. tclstm same as the tdlstm method but each input word vector', 'is concatenated with vector of the target word. all of the methods outputs are fed', 'into a softmax activation function. the experiments are performed on the  #AUTHOR_TAG dataset where we train and test on the specified splits.', 'for the lstms we initialised the weights using uniform distribution u ( 0', '. 003, 0. 003 ), used stochastic gradient descent ( sgd ) a learning rate of 0. 01, cross entropy loss, padded', 'and truncated sequence to the length of the maximum sequence in the training', 'dataset as stated in the original paper, and we did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were unsure what this meant.', 'with regards to the number of epochs trained, we used early stopping with a patience of 10 and allowed 300 epochs. within their experiments they used sswe and', 'glove twitter vectors 11  #AUTHOR_TAG. as the paper being reproduced does not define the number of epochs they trained for, we use early stopping. thus for early stopping we require to split', 'the training data into train and validation sets to know when to stop. as it has been shown by  #AUTHOR_TAG that the random', 'seed statistically significantly changes the results of experiments we ran each model over each', 'word embedding thirty times, using a different seed value but keeping the same stratified train and validation', 'split, and reported the results on the same test data as the original paper. as can be seen in figure 4, the initial seed value makes a large difference more so for the smaller embeddings. in table 5, we show the difference between our mean and maximum result and the original result for each model using the 200 dimension glove twitter vectors. even though the mean result is quite different from the original the maximum is much closer. our results generally agree with their results on the ranking', 'of the word vectors and the embeddings. overall, we were able to reproduce the results of all three papers. however for', 'the neural network / deep learning approach of  #TAUTHOR_TAG we agree with  #AUTHOR_TAG that reporting', 'multiple runs of the system over different seed values is required as the single performance scores can be misleading, which', 'could explain why previous papers obtained different results to the original for the tdlstm method  #AUTHOR_TAG']",6
"['did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were']","['did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were unsure']","['as stated in the original paper, and we did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were']","['a standard lstm that runs over the length of the sentence and takes no target information into account, 2. tdlstm runs two lstm', '##s, one over the left and the other over the right context of the target word and concatenates the output of the', 'two, and 3. tclstm same as the tdlstm method but each input word vector', 'is concatenated with vector of the target word. all of the methods outputs are fed', 'into a softmax activation function. the experiments are performed on the  #AUTHOR_TAG dataset where we train and test on the specified splits.', 'for the lstms we initialised the weights using uniform distribution u ( 0', '. 003, 0. 003 ), used stochastic gradient descent ( sgd ) a learning rate of 0. 01, cross entropy loss, padded', 'and truncated sequence to the length of the maximum sequence in the training', 'dataset as stated in the original paper, and we did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were unsure what this meant.', 'with regards to the number of epochs trained, we used early stopping with a patience of 10 and allowed 300 epochs. within their experiments they used sswe and', 'glove twitter vectors 11  #AUTHOR_TAG. as the paper being reproduced does not define the number of epochs they trained for, we use early stopping. thus for early stopping we require to split', 'the training data into train and validation sets to know when to stop. as it has been shown by  #AUTHOR_TAG that the random', 'seed statistically significantly changes the results of experiments we ran each model over each', 'word embedding thirty times, using a different seed value but keeping the same stratified train and validation', 'split, and reported the results on the same test data as the original paper. as can be seen in figure 4, the initial seed value makes a large difference more so for the smaller embeddings. in table 5, we show the difference between our mean and maximum result and the original result for each model using the 200 dimension glove twitter vectors. even though the mean result is quite different from the original the maximum is much closer. our results generally agree with their results on the ranking', 'of the word vectors and the embeddings. overall, we were able to reproduce the results of all three papers. however for', 'the neural network / deep learning approach of  #TAUTHOR_TAG we agree with  #AUTHOR_TAG that reporting', 'multiple runs of the system over different seed values is required as the single performance scores can be misleading, which', 'could explain why previous papers obtained different results to the original for the tdlstm method  #AUTHOR_TAG']",4
"['did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were']","['did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were unsure']","['as stated in the original paper, and we did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were']","['a standard lstm that runs over the length of the sentence and takes no target information into account, 2. tdlstm runs two lstm', '##s, one over the left and the other over the right context of the target word and concatenates the output of the', 'two, and 3. tclstm same as the tdlstm method but each input word vector', 'is concatenated with vector of the target word. all of the methods outputs are fed', 'into a softmax activation function. the experiments are performed on the  #AUTHOR_TAG dataset where we train and test on the specified splits.', 'for the lstms we initialised the weights using uniform distribution u ( 0', '. 003, 0. 003 ), used stochastic gradient descent ( sgd ) a learning rate of 0. 01, cross entropy loss, padded', 'and truncated sequence to the length of the maximum sequence in the training', 'dataset as stated in the original paper, and we did not "" set the clipping threshold of', 'softmax layer as 200 ""  #TAUTHOR_TAG as we were unsure what this meant.', 'with regards to the number of epochs trained, we used early stopping with a patience of 10 and allowed 300 epochs. within their experiments they used sswe and', 'glove twitter vectors 11  #AUTHOR_TAG. as the paper being reproduced does not define the number of epochs they trained for, we use early stopping. thus for early stopping we require to split', 'the training data into train and validation sets to know when to stop. as it has been shown by  #AUTHOR_TAG that the random', 'seed statistically significantly changes the results of experiments we ran each model over each', 'word embedding thirty times, using a different seed value but keeping the same stratified train and validation', 'split, and reported the results on the same test data as the original paper. as can be seen in figure 4, the initial seed value makes a large difference more so for the smaller embeddings. in table 5, we show the difference between our mean and maximum result and the original result for each model using the 200 dimension glove twitter vectors. even though the mean result is quite different from the original the maximum is much closer. our results generally agree with their results on the ranking', 'of the word vectors and the embeddings. overall, we were able to reproduce the results of all three papers. however for', 'the neural network / deep learning approach of  #TAUTHOR_TAG we agree with  #AUTHOR_TAG that reporting', 'multiple runs of the system over different seed values is required as the single performance scores can be misleading, which', 'could explain why previous papers obtained different results to the original for the tdlstm method  #AUTHOR_TAG']",4
['in different text types ; sswe for social media  #TAUTHOR_TAG and glo'],['in different text types ; sswe for social media  #TAUTHOR_TAG and glove'],"['the lstm methods.', 'we chose these word vectors as they have very different sizes ( 50 and 300 ), also they have been shown to perform well in different text types ; sswe for social media  #TAUTHOR_TAG and glo']","['all of the methods we pre - processed the text by lower casing and tokenising using twokenizer  #AUTHOR_TAG, and we used all three sentiment lexicons where applicable.', 'we found the best word vectors from sswe and the common crawl 42b 300 dimension glove vectors by five fold stratified cross validation for the np methods and the highest accuracy on the validation set for the lstm methods.', 'we chose these word vectors as they have very different sizes ( 50 and 300 ), also they have been shown to perform well in different text types ; sswe for social media  #TAUTHOR_TAG and glove for reviews  #AUTHOR_TAG.', 'to make the experiments quicker and computationally less expensive, we filtered out all words from the word vectors that did not appear in the train and test datasets, and this is equivalent with respect to word coverage as using all words.', 'finally we only reported results for the lstm methods with one seed value and not multiple due to time constraints.', 'the results of the methods using the best found word vectors on the test sets can be seen in table 6.', 'we find that the tdparse methods generally perform best but only clearly outperforms the other nondependency parser methods on the youtubean dataset.', 'we hypothesise that this is due to the dataset containing, on average, a deeper constituency tree depth which could be seen as on average more complex sentences.', 'this could be due to it being from the spoken medium compared to the rest of the datasets which are written.', 'also that using a sentiment lexicon is almost always beneficial, but only by a small amount.', 'within the lstm based methods the tdlstm method generally performs the best indicating that the extra target information that the tclstm method contains is not needed, but we believe this needs further analysis.', 'we can conclude that the simpler np models perform well across domain, type and medium and that even without language specific tools and lexicons they are competitive to the more complex lstm based methods']",3
['in different text types ; sswe for social media  #TAUTHOR_TAG and glo'],['in different text types ; sswe for social media  #TAUTHOR_TAG and glove'],"['the lstm methods.', 'we chose these word vectors as they have very different sizes ( 50 and 300 ), also they have been shown to perform well in different text types ; sswe for social media  #TAUTHOR_TAG and glo']","['all of the methods we pre - processed the text by lower casing and tokenising using twokenizer  #AUTHOR_TAG, and we used all three sentiment lexicons where applicable.', 'we found the best word vectors from sswe and the common crawl 42b 300 dimension glove vectors by five fold stratified cross validation for the np methods and the highest accuracy on the validation set for the lstm methods.', 'we chose these word vectors as they have very different sizes ( 50 and 300 ), also they have been shown to perform well in different text types ; sswe for social media  #TAUTHOR_TAG and glove for reviews  #AUTHOR_TAG.', 'to make the experiments quicker and computationally less expensive, we filtered out all words from the word vectors that did not appear in the train and test datasets, and this is equivalent with respect to word coverage as using all words.', 'finally we only reported results for the lstm methods with one seed value and not multiple due to time constraints.', 'the results of the methods using the best found word vectors on the test sets can be seen in table 6.', 'we find that the tdparse methods generally perform best but only clearly outperforms the other nondependency parser methods on the youtubean dataset.', 'we hypothesise that this is due to the dataset containing, on average, a deeper constituency tree depth which could be seen as on average more complex sentences.', 'this could be due to it being from the spoken medium compared to the rest of the datasets which are written.', 'also that using a sentiment lexicon is almost always beneficial, but only by a small amount.', 'within the lstm based methods the tdlstm method generally performs the best indicating that the extra target information that the tclstm method contains is not needed, but we believe this needs further analysis.', 'we can conclude that the simpler np models perform well across domain, type and medium and that even without language specific tools and lexicons they are competitive to the more complex lstm based methods']",5
"['compared to an lstm baseline  #TAUTHOR_TAG', 'and 5 % to']","['incorporating syntactic information to the training data, we achieve better performance by 10 % compared to an lstm baseline  #TAUTHOR_TAG', 'and 5 % to']","['compared to an lstm baseline  #TAUTHOR_TAG', 'and 5 % to the equivalent constraint']","['society. from a sociolinguistic perspective, individuals', 'do code - switching in order to construct an optimal interaction by accomplishing the conceptual, relational -', 'interpersonal, and discourse - presentational meaning of conversation [ 1 ]. in its practice, the variation of code - switching will vary due to the traditions, beliefs, and normative values in the respective communities. a', 'number of studies [ 2, 3, 4, 5 ] found that code - switching is not produced indiscriminately, but follows', 'syntactic constraints. many linguists formulated various constraints to define a general rule for code - switching [ 2, 4, 5 ]. however, the constraints are', 'not enough to make a good generalization of real code - switching constraints, and they have not been tested in large -', 'scale corpora for many language pairs. one of the biggest problem in code - switching is collecting large scale corpora. speech data have to be collected from a spontaneous speech by bilingual speakers', 'and the codeswitching has to be triggered naturally during the conversation. in', 'order to solve the data scarcity issue, code - switching data generation is useful to increase the volume and variance. a linguistics constraint - driven', 'generation approach such as equivalent constraint [ 6, 7 ] is not restrictive to languages with distinctive grammar structure. in this', 'paper, we propose a novel language - agnostic method to learn how to generate code - switching sentences by using a pointer - generator', 'network [ 8 ]. the model is trained from concatenated sequences of parallel sentences to generate code - switching sentences, constrained by codeswitching texts. the pointer network copies', 'words from both languages and pastes them into the output, generating code switching sentences in matrix language to embedded language and vice', 'versa. the attention mechanism helps the decoder to generate meaningful and grammatical sentences without needing any sequence alignment. this idea is also in line with code -', 'mixing by borrowing words from the embedded language [ 9 ] and intuitively, the copying mechanism can be', 'seen as an end - to - end approach to translate, align, and reorder the given words into a grammatical code - switching sentence. this approach is the unification of all components in the work of [ 6 ] into a single computational model. a code - switching language model', 'learned in this way is able to capture the patterns and constraints of the switches and mitigate the out - of -', 'vocabulary ( oov ) issue during sequence generation. by adding the generated sentences and incorporating syntactic information to the training data, we achieve better performance by 10 % compared to an lstm baseline  #TAUTHOR_TAG', 'and 5 % to the equivalent constraint']",4
"['7 ].', 'a multi - task learning approach was introduced to train the syntax representation of languages by constraining the language generator  #TAUTHOR_TAG.', 'a copy mechanism was proposed to copy words directly from']","['networks.', '[ 15 ] adapted an effective curriculum learning by training a network with monolingual corpora of both languages, and subsequently train on codeswitched data.', 'a further investigation of equivalence constraint and curriculum learning showed an improvement in language modeling [ 7 ].', 'a multi - task learning approach was introduced to train the syntax representation of languages by constraining the language generator  #TAUTHOR_TAG.', 'a copy mechanism was proposed to copy words directly from']","['15 ] adapted an effective curriculum learning by training a network with monolingual corpora of both languages, and subsequently train on codeswitched data.', 'a further investigation of equivalence constraint and curriculum learning showed an improvement in language modeling [ 7 ].', 'a multi - task learning approach was introduced to train the syntax representation of languages by constraining the language generator  #TAUTHOR_TAG.', 'a copy mechanism was proposed to copy words directly from']","['synthetic code - switching generation approach was introduced by adapting equivalence constraint on monolingual sentence pairs during the decoding step on an automatic speech recognition ( asr ) model [ 6 ].', '[ 11 ] explored functional head constraint, which was found to be more restrictive than the equivalence constraint, but complex to be implemented, by using a lattice parser with a weighted finitestate transducer.', '[ 12 ] extended the rnn by adding pos information to the input layer and factorized output layer with a language identifier.', 'then, factorized rnn networks were combined with an n - gram backoff model using linear interpolation [ 13 ].', '[ 14 ] added syntactic and semantic features to the factorized rnn networks.', '[ 15 ] adapted an effective curriculum learning by training a network with monolingual corpora of both languages, and subsequently train on codeswitched data.', 'a further investigation of equivalence constraint and curriculum learning showed an improvement in language modeling [ 7 ].', 'a multi - task learning approach was introduced to train the syntax representation of languages by constraining the language generator  #TAUTHOR_TAG.', 'a copy mechanism was proposed to copy words directly from the input to the output using an attention mechanism [ 16 ].', 'this mechanism has proven to be effective in several nlp tasks including text summarization [ 8 ], and dialog systems [ 17 ].', 'the common characteristic of these tasks is parts of the output are exactly the same as the input source.', 'for example, in dialog systems the responses most of the time have appeared in the previous dialog steps']",0
"['x w | x p ] to an lstm layer similar to  #TAUTHOR_TAG. 4.', '']","['[ x w | x p ] to an lstm layer similar to  #TAUTHOR_TAG. 4.', '']","['as an input [ x w | x p ] to an lstm layer similar to  #TAUTHOR_TAG. 4.', '']","['quality of the generated code - switching sentences is evaluated using a language modeling task.', 'indeed, if the perplexity in this task drops consistently we can assume that the generated sentences are well - formed.', 'hence, we use an lstm language model with weight tying [ 20 ] that can capture an unbounded number of context words to approximate the probability of the next word.', 'syntactic information such as partof - speech ( pos ) [ p 1,..., p t ] is added to further improve the performance.', 'the pos tags are generated phrase - wise using pretrained english and chinese stanford pos tagger [ 21 ] by adding a word at a time in a unidirectional way to avoid any intervention from future information.', 'the word and syntax unit are represented as a vector x w and x p respectively.', 'next, we concatenate both vectors and use it as an input [ x w | x p ] to an lstm layer similar to  #TAUTHOR_TAG. 4.', '']",3
"['23 ] and all hesitations and punctuations were removed except apostrophe.', 'the split of the dataset is identical to  #TAUTHOR_TAG and it is showed in table 1']","['tokenized using stanford nlp toolkit [ 23 ] and all hesitations and punctuations were removed except apostrophe.', 'the split of the dataset is identical to  #TAUTHOR_TAG and it is showed in table 1']","['our experiment, we use a conversational mandarin - english code - switching speech corpus called seame phase ii ( south east asia mandarin - english ).', 'the data are collected from spontaneously spoken interviews and conversations in singapore and malaysia by bilinguals [ 22 ].', 'as the data preprocessing, words are tokenized using stanford nlp toolkit [ 23 ] and all hesitations and punctuations were removed except apostrophe.', 'the split of the dataset is identical to  #TAUTHOR_TAG and it is showed in table 1']","['our experiment, we use a conversational mandarin - english code - switching speech corpus called seame phase ii ( south east asia mandarin - english ).', 'the data are collected from spontaneously spoken interviews and conversations in singapore and malaysia by bilinguals [ 22 ].', 'as the data preprocessing, words are tokenized using stanford nlp toolkit [ 23 ] and all hesitations and punctuations were removed except apostrophe.', 'the split of the dataset is identical to  #TAUTHOR_TAG and it is showed in table 1']",3
"['compared to  #TAUTHOR_TAG. however, tienet']","['compared to  #TAUTHOR_TAG. however, tienet']","['performance compared to  #TAUTHOR_TAG. however, tienet']",[' #TAUTHOR_TAG'],0
"['compared to  #TAUTHOR_TAG. however, tienet']","['compared to  #TAUTHOR_TAG. however, tienet']","['performance compared to  #TAUTHOR_TAG. however, tienet']",[' #TAUTHOR_TAG'],0
"['compared to  #TAUTHOR_TAG. however, tienet']","['compared to  #TAUTHOR_TAG. however, tienet']","['performance compared to  #TAUTHOR_TAG. however, tienet']",[' #TAUTHOR_TAG'],1
"['compared to  #TAUTHOR_TAG. however, tienet']","['compared to  #TAUTHOR_TAG. however, tienet']","['performance compared to  #TAUTHOR_TAG. however, tienet']",[' #TAUTHOR_TAG'],5
"['k w mk a k ).', 'the localized semantic features to predict disease m are identified and visualized with the heatmap h m.', 'similar to  #TAUTHOR_TAG, we']","['k w mk a k ).', 'the localized semantic features to predict disease m are identified and visualized with the heatmap h m.', 'similar to  #TAUTHOR_TAG, we']","['( k w mk a k ).', 'the localized semantic features to predict disease m are identified and visualized with the heatmap h m.', 'similar to  #TAUTHOR_TAG, we apply a thresholding based bounding box ( b - box ) generation method.', 'the b - box bounds pixels whose heatmap intensity is above 90']","['', 'thus w mk are calculated by :', 'represents the coordinates of a pixel, and n is the total number of pixels.', 'we then generate a heatmap for disease m by applying weighted average of a k, followed by a relu activation : h m = relu ( k w mk a k ).', 'the localized semantic features to predict disease m are identified and visualized with the heatmap h m.', 'similar to  #TAUTHOR_TAG, we apply a thresholding based bounding box ( b - box ) generation method.', 'the b - box bounds pixels whose heatmap intensity is above 90 % of the maximum intensity.', 'the resulting region of interest is then cropped for next level modeling.', 'fig. 2b illustrates the process of report generation.', 'if there is no active thoracic disease found in an x - ray, a report will be directly generated by an attentive lstm based on the original x - ray']",5
['##8  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['', 'we convert all the words to lower - case, remove all non - alphanumeric tokens, replace single - occurrence tokens with a special token and use another special token to separate sentences.', 'we filter out images and reports that are non - relevant to the eight common thoracic diseases included in both chestx - ray8  #TAUTHOR_TAG and iu x - ray datasets [ 2 ], resulting in a dataset with 2225 pairs of x - ray image and report.', 'finally, we split all the image - report pairs into training, validation and testing dataset by ratio 7 : 1 : 2.', 'implementation details.', 'we implement our model on a geforce gtx 1080ti gpu platform using pytorch.', '']",5
['##8  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['', 'we convert all the words to lower - case, remove all non - alphanumeric tokens, replace single - occurrence tokens with a special token and use another special token to separate sentences.', 'we filter out images and reports that are non - relevant to the eight common thoracic diseases included in both chestx - ray8  #TAUTHOR_TAG and iu x - ray datasets [ 2 ], resulting in a dataset with 2225 pairs of x - ray image and report.', 'finally, we split all the image - report pairs into training, validation and testing dataset by ratio 7 : 1 : 2.', 'implementation details.', 'we implement our model on a geforce gtx 1080ti gpu platform using pytorch.', '']",7
"['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns']","['lexicon can be considered the most dynamic part of all linguistic knowledge sources over time.', 'there are two innovative change strategies typical for lexical systems : the creation of entirely new lexical items, commonly reflecting the emergence of novel ideas, technologies or artifacts, on the one hand, and, on the other hand, shifts in the meaning of already existing lexical items, a process which usually takes place over larger periods of time.', 'tracing semantic changes of the latter type is the main focus of our research.', 'meaning shift has recently been investigated with emphasis on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns can be reduced to the measurement of lexical similarity between lexical items.', 'neural language models, originating from the word2vec algorithm  #AUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG c ), are currently considered as state - of - the - art solutions for implementing this assumption  #AUTHOR_TAG.', 'within this approach, changes in similarity relations between lexical items at two different points of time are interpreted as a signal for meaning shift.', 'accordingly, lexical items which are very similar to the lexical item under scrutiny can be considered as approximating its meaning at a given point in time.', 'both techniques were already combined in prior work to show, e. g., the increasing association of the lexical item "" gay "" with the meaning dimension of "" homosexuality ""  #TAUTHOR_TAG.', 'we here investigate the accuracy and reliability of such similarity judgments derived from different training protocols dependent on word frequency, word ambiguity and the number of training epochs ( i. e., iterations over all training material ).', 'accuracy renders a judgment of the overall model quality, whereas reliability between repeated experiments ensures that qualitative judgments can indeed be transferred between experiments.', 'based on the identification of critical conditions in the experimental set - up of previously employed protocols, we recommend improved training strategies for more adequate neural language models dealing with diachronic lexical change patterns.', 'our results concerning reliability also cast doubt on the reproducibility of experiments where semantic similarity between lexical items is taken as a computationally valid indicator for properly capturing lexical meaning ( and, consequently, meaning shifts ) under a diachronic perspective']",0
"['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns']","['lexicon can be considered the most dynamic part of all linguistic knowledge sources over time.', 'there are two innovative change strategies typical for lexical systems : the creation of entirely new lexical items, commonly reflecting the emergence of novel ideas, technologies or artifacts, on the one hand, and, on the other hand, shifts in the meaning of already existing lexical items, a process which usually takes place over larger periods of time.', 'tracing semantic changes of the latter type is the main focus of our research.', 'meaning shift has recently been investigated with emphasis on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns can be reduced to the measurement of lexical similarity between lexical items.', 'neural language models, originating from the word2vec algorithm  #AUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG c ), are currently considered as state - of - the - art solutions for implementing this assumption  #AUTHOR_TAG.', 'within this approach, changes in similarity relations between lexical items at two different points of time are interpreted as a signal for meaning shift.', 'accordingly, lexical items which are very similar to the lexical item under scrutiny can be considered as approximating its meaning at a given point in time.', 'both techniques were already combined in prior work to show, e. g., the increasing association of the lexical item "" gay "" with the meaning dimension of "" homosexuality ""  #TAUTHOR_TAG.', 'we here investigate the accuracy and reliability of such similarity judgments derived from different training protocols dependent on word frequency, word ambiguity and the number of training epochs ( i. e., iterations over all training material ).', 'accuracy renders a judgment of the overall model quality, whereas reliability between repeated experiments ensures that qualitative judgments can indeed be transferred between experiments.', 'based on the identification of critical conditions in the experimental set - up of previously employed protocols, we recommend improved training strategies for more adequate neural language models dealing with diachronic lexical change patterns.', 'our results concerning reliability also cast doubt on the reproducibility of experiments where semantic similarity between lexical items is taken as a computationally valid indicator for properly capturing lexical meaning ( and, consequently, meaning shifts ) under a diachronic perspective']",0
"['predecessor, and, alternatively, independent training with a mapping between models for different points in time  #TAUTHOR_TAG.', 'a comparison between these two protocols,']","['predecessor, and, alternatively, independent training with a mapping between models for different points in time  #TAUTHOR_TAG.', 'a comparison between these two protocols,']","['predecessor, and, alternatively, independent training with a mapping between models for different points in time  #TAUTHOR_TAG.', 'a comparison between these two protocols,']","['language models for tracking semantic changes over time typically distinguish between two different training protocols - continuous training of models  #AUTHOR_TAG where the model for each time span is initialized with the embeddings of its predecessor, and, alternatively, independent training with a mapping between models for different points in time  #TAUTHOR_TAG.', 'a comparison between these two protocols, such as the one proposed in this paper, has not been carried out before.', 'also, the application of such protocols to non - english corpora is lacking, with the exception of our own work relating to german data  #AUTHOR_TAG b ;  #AUTHOR_TAG a ).', 'the word2vec algorithm is a heavily trimmed version of an artificial neural network used to generate low - dimensional vector space representations of a lexicon.', 'we focus on its skip - gram variant, trained to predict plausible contexts for a given word that was shown to be superior over other settings for modeling semantic information  #AUTHOR_TAG a ).', 'there are several parameters to choose for training - learning rate, downsampling factor for frequent words, number of training epochs and choice between two strategies for managing the huge number of potential contexts.', 'one strategy, hierarchical softmax, uses a binary tree to efficiently represent the vocabulary, while the other, negative sampling, works by updating only a limited number of word vectors during each training step.', 'furthermore, artificial neural networks, in general, are known for a large number of local optima encountered during optimization.', 'while these commonly lead to very similar performance ( le  #AUTHOR_TAG, they cause different representations in the course of repeated experiments.', 'approaches to modelling changes of lexical semantics not using neural language models, e. g.,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG or  #AUTHOR_TAG are, intentionally, out of the scope of this paper.', 'in the same way, we here refrain from comparison with computational studies dealing with literary discussions related to the romantic period ( e. g.,  #AUTHOR_TAG )']",0
"['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less affected by sampling irregularities than other parts  #AUTHOR_TAG.', ""due to the opaque nature of google's corpus acquisition strategy, the influence of ocr errors on our results cannot be reasonably estimated, yet we assume that they will affect all experiments in an equal manner."", ""the wide range of experimental parameters described in section 2 makes it virtually impossible to test all their possible combinations, especially as repeated experiments are necessary to probe a method's reliability."", 'we thus concentrate on two experimental protocols - the one described by  #AUTHOR_TAG ( referred to as kim protocol ) and the one from  #TAUTHOR_TAG ( referred to as kulkarni protocol ), including close variations thereof.', ""kulkarni's protocol operates on all 5 - grams occurring during five consecutive years ( e. g., [ 1900 ] [ 1901 ] [ 1902 ] [ 1903 ] [ 1904 ] and trains models independently of each other."", ""kim's protocol operates on uniformly sized samples of 10m 5 - grams for each year from 1850 onwards in a continuous fashion ( years before 1900 are used for initialization only )."", 'its constant sampling sizes result in both oversampling and undersampling as is evident from figure 1.', 'we use the python - based gensim 1 implementation of word2vec for our experiments ; the relevant code is made available via github.', '2 due to the 5 - gram nature of the corpus, a context window covering four neighboring words is used for all experiments.', 'only words with at least 10 occurrences in a sample are modeled.', 'training for each sample is repeated until convergence 3 is achieved or 10 epochs have passed.', 'following both protocols, we use word vectors with 200 table 1 : accuracy and reliability among top n words for threefold application of different training protocols.', 'reliability is given as fraction of the maximum for n. standard deviation for accuracy ±0, if not noted otherwise ; reliability is based on the evaluation of all lexical items, thus no standard deviation.', 'dimensions for all experiments, as well as an initial learning rate of 0. 01 for experiments based on 10m samples, and one of 0. 025 for systems trained on unsampled texts ; the threshold for downsampling frequent words was 10 −3 for sample - based experiments and 10 −5 for unsampled ones.', ""we tested both negative sampling and hierarchical softmax training strategies, the latter being canonical for kulkarni's protocol, whereas kim's""]",0
"['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns']","['lexicon can be considered the most dynamic part of all linguistic knowledge sources over time.', 'there are two innovative change strategies typical for lexical systems : the creation of entirely new lexical items, commonly reflecting the emergence of novel ideas, technologies or artifacts, on the one hand, and, on the other hand, shifts in the meaning of already existing lexical items, a process which usually takes place over larger periods of time.', 'tracing semantic changes of the latter type is the main focus of our research.', 'meaning shift has recently been investigated with emphasis on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns can be reduced to the measurement of lexical similarity between lexical items.', 'neural language models, originating from the word2vec algorithm  #AUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG c ), are currently considered as state - of - the - art solutions for implementing this assumption  #AUTHOR_TAG.', 'within this approach, changes in similarity relations between lexical items at two different points of time are interpreted as a signal for meaning shift.', 'accordingly, lexical items which are very similar to the lexical item under scrutiny can be considered as approximating its meaning at a given point in time.', 'both techniques were already combined in prior work to show, e. g., the increasing association of the lexical item "" gay "" with the meaning dimension of "" homosexuality ""  #TAUTHOR_TAG.', 'we here investigate the accuracy and reliability of such similarity judgments derived from different training protocols dependent on word frequency, word ambiguity and the number of training epochs ( i. e., iterations over all training material ).', 'accuracy renders a judgment of the overall model quality, whereas reliability between repeated experiments ensures that qualitative judgments can indeed be transferred between experiments.', 'based on the identification of critical conditions in the experimental set - up of previously employed protocols, we recommend improved training strategies for more adequate neural language models dealing with diachronic lexical change patterns.', 'our results concerning reliability also cast doubt on the reproducibility of experiments where semantic similarity between lexical items is taken as a computationally valid indicator for properly capturing lexical meaning ( and, consequently, meaning shifts ) under a diachronic perspective']",1
"['predecessor, and, alternatively, independent training with a mapping between models for different points in time  #TAUTHOR_TAG.', 'a comparison between these two protocols,']","['predecessor, and, alternatively, independent training with a mapping between models for different points in time  #TAUTHOR_TAG.', 'a comparison between these two protocols,']","['predecessor, and, alternatively, independent training with a mapping between models for different points in time  #TAUTHOR_TAG.', 'a comparison between these two protocols,']","['language models for tracking semantic changes over time typically distinguish between two different training protocols - continuous training of models  #AUTHOR_TAG where the model for each time span is initialized with the embeddings of its predecessor, and, alternatively, independent training with a mapping between models for different points in time  #TAUTHOR_TAG.', 'a comparison between these two protocols, such as the one proposed in this paper, has not been carried out before.', 'also, the application of such protocols to non - english corpora is lacking, with the exception of our own work relating to german data  #AUTHOR_TAG b ;  #AUTHOR_TAG a ).', 'the word2vec algorithm is a heavily trimmed version of an artificial neural network used to generate low - dimensional vector space representations of a lexicon.', 'we focus on its skip - gram variant, trained to predict plausible contexts for a given word that was shown to be superior over other settings for modeling semantic information  #AUTHOR_TAG a ).', 'there are several parameters to choose for training - learning rate, downsampling factor for frequent words, number of training epochs and choice between two strategies for managing the huge number of potential contexts.', 'one strategy, hierarchical softmax, uses a binary tree to efficiently represent the vocabulary, while the other, negative sampling, works by updating only a limited number of word vectors during each training step.', 'furthermore, artificial neural networks, in general, are known for a large number of local optima encountered during optimization.', 'while these commonly lead to very similar performance ( le  #AUTHOR_TAG, they cause different representations in the course of repeated experiments.', 'approaches to modelling changes of lexical semantics not using neural language models, e. g.,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG or  #AUTHOR_TAG are, intentionally, out of the scope of this paper.', 'in the same way, we here refrain from comparison with computational studies dealing with literary discussions related to the romantic period ( e. g.,  #AUTHOR_TAG )']",1
"['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less affected by sampling irregularities than other parts  #AUTHOR_TAG.', ""due to the opaque nature of google's corpus acquisition strategy, the influence of ocr errors on our results cannot be reasonably estimated, yet we assume that they will affect all experiments in an equal manner."", ""the wide range of experimental parameters described in section 2 makes it virtually impossible to test all their possible combinations, especially as repeated experiments are necessary to probe a method's reliability."", 'we thus concentrate on two experimental protocols - the one described by  #AUTHOR_TAG ( referred to as kim protocol ) and the one from  #TAUTHOR_TAG ( referred to as kulkarni protocol ), including close variations thereof.', ""kulkarni's protocol operates on all 5 - grams occurring during five consecutive years ( e. g., [ 1900 ] [ 1901 ] [ 1902 ] [ 1903 ] [ 1904 ] and trains models independently of each other."", ""kim's protocol operates on uniformly sized samples of 10m 5 - grams for each year from 1850 onwards in a continuous fashion ( years before 1900 are used for initialization only )."", 'its constant sampling sizes result in both oversampling and undersampling as is evident from figure 1.', 'we use the python - based gensim 1 implementation of word2vec for our experiments ; the relevant code is made available via github.', '2 due to the 5 - gram nature of the corpus, a context window covering four neighboring words is used for all experiments.', 'only words with at least 10 occurrences in a sample are modeled.', 'training for each sample is repeated until convergence 3 is achieved or 10 epochs have passed.', 'following both protocols, we use word vectors with 200 table 1 : accuracy and reliability among top n words for threefold application of different training protocols.', 'reliability is given as fraction of the maximum for n. standard deviation for accuracy ±0, if not noted otherwise ; reliability is based on the evaluation of all lexical items, thus no standard deviation.', 'dimensions for all experiments, as well as an initial learning rate of 0. 01 for experiments based on 10m samples, and one of 0. 025 for systems trained on unsampled texts ; the threshold for downsampling frequent words was 10 −3 for sample - based experiments and 10 −5 for unsampled ones.', ""we tested both negative sampling and hierarchical softmax training strategies, the latter being canonical for kulkarni's protocol, whereas kim's""]",5
"['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less affected by sampling irregularities than other parts  #AUTHOR_TAG.', ""due to the opaque nature of google's corpus acquisition strategy, the influence of ocr errors on our results cannot be reasonably estimated, yet we assume that they will affect all experiments in an equal manner."", ""the wide range of experimental parameters described in section 2 makes it virtually impossible to test all their possible combinations, especially as repeated experiments are necessary to probe a method's reliability."", 'we thus concentrate on two experimental protocols - the one described by  #AUTHOR_TAG ( referred to as kim protocol ) and the one from  #TAUTHOR_TAG ( referred to as kulkarni protocol ), including close variations thereof.', ""kulkarni's protocol operates on all 5 - grams occurring during five consecutive years ( e. g., [ 1900 ] [ 1901 ] [ 1902 ] [ 1903 ] [ 1904 ] and trains models independently of each other."", ""kim's protocol operates on uniformly sized samples of 10m 5 - grams for each year from 1850 onwards in a continuous fashion ( years before 1900 are used for initialization only )."", 'its constant sampling sizes result in both oversampling and undersampling as is evident from figure 1.', 'we use the python - based gensim 1 implementation of word2vec for our experiments ; the relevant code is made available via github.', '2 due to the 5 - gram nature of the corpus, a context window covering four neighboring words is used for all experiments.', 'only words with at least 10 occurrences in a sample are modeled.', 'training for each sample is repeated until convergence 3 is achieved or 10 epochs have passed.', 'following both protocols, we use word vectors with 200 table 1 : accuracy and reliability among top n words for threefold application of different training protocols.', 'reliability is given as fraction of the maximum for n. standard deviation for accuracy ±0, if not noted otherwise ; reliability is based on the evaluation of all lexical items, thus no standard deviation.', 'dimensions for all experiments, as well as an initial learning rate of 0. 01 for experiments based on 10m samples, and one of 0. 025 for systems trained on unsampled texts ; the threshold for downsampling frequent words was 10 −3 for sample - based experiments and 10 −5 for unsampled ones.', ""we tested both negative sampling and hierarchical softmax training strategies, the latter being canonical for kulkarni's protocol, whereas kim's""]",5
['4  #TAUTHOR_TAG compiled'],['4  #TAUTHOR_TAG compiled'],"['of accuracy and reliability, especially 4  #TAUTHOR_TAG compiled the following list based on prior work  #AUTHOR_TAG : card, sleep, parent, address, gay, mouse, king, checked, check, actually, supposed, guess, cell, headed, ass, mail, toilet, cock, bloody, nice and guy.', '5 we used']","['investigation in the performance of two common protocols for training neural language models on historical text data led to several hitherto unknown results.', 'we could show that negative sampling outperforms hierarchical softmax both in terms of accuracy and reliability, especially 4  #TAUTHOR_TAG compiled the following list based on prior work  #AUTHOR_TAG : card, sleep, parent, address, gay, mouse, king, checked, check, actually, supposed, guess, cell, headed, ass, mail, toilet, cock, bloody, nice and guy.', '5 we used wordnet 3. 0 and the api provided by the natural language toolkit ( nltk ) : www. nltk. org even the most reliable system often identifies widely different words as most similar.', 'this carries unwarranted potential for erroneous conclusions on a words\'semantic evolution, e. g., "" romantic "" happens to be identified as most similar to "" lazzaroni "" 7, "" fanciful "" and "" melancholies "" by three systems trained with negative sampling on 1900 - 1904 texts.', 'we are thus skeptical about using such similarity clouds to describe or visualize lexical semantics at a point in time.', 'in future work, we will explore the effects of continuous training based on complete corpora.', 'the selection of a convergence criterion remains another open issue due to the threefold trade - off between training time, reliability and accuracy.', 'it would also be interesting to replicate our experiments for other languages or points in time.', 'yet, the enormous corpus size for more recent years might require a reduced number of maximum epochs for these experiments.', 'in order to improve the semantic modeling itself one could lemmatize the training material or utilize the part of speech annotations provided in the latest version of the google corpus  #AUTHOR_TAG.', 'also, recently available neural language models with support for multiple word senses  #AUTHOR_TAG could be helpful, since semantic changes can often be described as changes in the usage frequency of different word senses  #AUTHOR_TAG pp. 58 - 59 ).', 'finally, it is clearly important to test the effect of our proposed changes, based on synchronic experiments, on a system for tracking diachronic changes in word semantics']",4
"['by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing']","['by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing']","['by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing']","[' #AUTHOR_TAG and parseval for constituency parsers  #AUTHOR_TAG suffer from being an average over a highly skewed distribution of different grammatical constructions. as a result, infrequent yet semantically important construction types could be parsed with accuracies far below what one might expect. this', 'shortcoming of aggregate parsing metrics was highlighted in a recent study by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing around 700 sentences annotated with unbounded dependencies in seven different grammatical constructions. this', 'corpus was used to evaluate five state - of - the - art parsers for english, focusing on grammar - based', 'and statistical phrase structure parsers. for example, in the sentence by monday, they hope to have a sheaf of documents both sides can trust., parsers should recognize', 'that there is a dependency between trust and documents, an instance of object extraction out of a ( reduced ) relative clause. in the evaluation, the recall of', '']",6
"['by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing']","['by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing']","['by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing']","[' #AUTHOR_TAG and parseval for constituency parsers  #AUTHOR_TAG suffer from being an average over a highly skewed distribution of different grammatical constructions. as a result, infrequent yet semantically important construction types could be parsed with accuracies far below what one might expect. this', 'shortcoming of aggregate parsing metrics was highlighted in a recent study by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing around 700 sentences annotated with unbounded dependencies in seven different grammatical constructions. this', 'corpus was used to evaluate five state - of - the - art parsers for english, focusing on grammar - based', 'and statistical phrase structure parsers. for example, in the sentence by monday, they hope to have a sheaf of documents both sides can trust., parsers should recognize', 'that there is a dependency between trust and documents, an instance of object extraction out of a ( reduced ) relative clause. in the evaluation, the recall of', '']",4
"['by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing']","['by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing']","['by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing']","[' #AUTHOR_TAG and parseval for constituency parsers  #AUTHOR_TAG suffer from being an average over a highly skewed distribution of different grammatical constructions. as a result, infrequent yet semantically important construction types could be parsed with accuracies far below what one might expect. this', 'shortcoming of aggregate parsing metrics was highlighted in a recent study by  #TAUTHOR_TAG, introducing a new parser evaluation corpus containing around 700 sentences annotated with unbounded dependencies in seven different grammatical constructions. this', 'corpus was used to evaluate five state - of - the - art parsers for english, focusing on grammar - based', 'and statistical phrase structure parsers. for example, in the sentence by monday, they hope to have a sheaf of documents both sides can trust., parsers should recognize', 'that there is a dependency between trust and documents, an instance of object extraction out of a ( reduced ) relative clause. in the evaluation, the recall of', '']",4
"['in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead,']","['in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead,']","['in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead,']","['important difference between mstparser and maltparser, on the one hand, and the best performing parsers evaluated in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead, they are best understood as data - driven parser generators, that is, tools for generating a parser given a training set of sentences annotated with dependency structures.', 'over the years, both systems have been applied to a wide range of languages ( see, e. ( 2007 ) ), but they come with no language - specific enhancements and are not equipped specifically to deal with unbounded dependencies.', 'since the dependency representation used in the evaluation corpus is based on the stanford typed dependency scheme ( de  #AUTHOR_TAG, we opted for using the wsj section of the ptb, converted to stanford dependencies, as our primary source of training data.', 'thus, both parsers were trained on section 2 - 21 of the wsj data, which we converted to stanford dependencies using the stanford parser  #AUTHOR_TAG.', 'the stanford scheme comes in several varieties, but because both parsers require the dependency structure for each sentence to be a tree, we had to use the so - called basic variety ( de  #AUTHOR_TAG.', 'it is well known that questions are very rare in the wsj data, and  #TAUTHOR_TAG found that parsers trained only on wsj data generally performed badly on the questions included in the evaluation corpus, while the c & c parser equipped with a model trained on a combination of wsj and question data had much better performance.', 'to investigate whether the performance of mstparser and maltparser on questions could also be improved by adding more questions to the training data, we trained one variant of each parser using data that was extended with 3924 questions taken from questionbank ( qb )  #AUTHOR_TAG.', '4 since the qb sentences are annotated in ptb style, it was possible to use the same conversion procedure as for the wsj data.', 'however, it is clear that the conversion did not always produce adequate dependency structures for the questions, an observation that we will return to in the error analysis below.', 'in comparison to the five parsers evaluated in  #TAUTHOR_TAG, it is worth noting that mstparser and maltparser were trained on the same basic data as four of the five, but with a different kind of syntactic representation - dependency trees instead of phrase structure trees or theoryspecific representations from ccg and hpsg.', 'it is especially interesting to compare mstparser and maltparser to the stanford parser, which essentially produces the same kind of dependency structures']",4
"['in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead,']","['in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead,']","['in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead,']","['important difference between mstparser and maltparser, on the one hand, and the best performing parsers evaluated in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead, they are best understood as data - driven parser generators, that is, tools for generating a parser given a training set of sentences annotated with dependency structures.', 'over the years, both systems have been applied to a wide range of languages ( see, e. ( 2007 ) ), but they come with no language - specific enhancements and are not equipped specifically to deal with unbounded dependencies.', 'since the dependency representation used in the evaluation corpus is based on the stanford typed dependency scheme ( de  #AUTHOR_TAG, we opted for using the wsj section of the ptb, converted to stanford dependencies, as our primary source of training data.', 'thus, both parsers were trained on section 2 - 21 of the wsj data, which we converted to stanford dependencies using the stanford parser  #AUTHOR_TAG.', 'the stanford scheme comes in several varieties, but because both parsers require the dependency structure for each sentence to be a tree, we had to use the so - called basic variety ( de  #AUTHOR_TAG.', 'it is well known that questions are very rare in the wsj data, and  #TAUTHOR_TAG found that parsers trained only on wsj data generally performed badly on the questions included in the evaluation corpus, while the c & c parser equipped with a model trained on a combination of wsj and question data had much better performance.', 'to investigate whether the performance of mstparser and maltparser on questions could also be improved by adding more questions to the training data, we trained one variant of each parser using data that was extended with 3924 questions taken from questionbank ( qb )  #AUTHOR_TAG.', '4 since the qb sentences are annotated in ptb style, it was possible to use the same conversion procedure as for the wsj data.', 'however, it is clear that the conversion did not always produce adequate dependency structures for the questions, an observation that we will return to in the error analysis below.', 'in comparison to the five parsers evaluated in  #TAUTHOR_TAG, it is worth noting that mstparser and maltparser were trained on the same basic data as four of the five, but with a different kind of syntactic representation - dependency trees instead of phrase structure trees or theoryspecific representations from ccg and hpsg.', 'it is especially interesting to compare mstparser and maltparser to the stanford parser, which essentially produces the same kind of dependency structures']",4
"['systems in  #TAUTHOR_TAG - c & c and enju.', 'this is true even though mstparser and maltparser have not been engineered specifically for english']","['systems in  #TAUTHOR_TAG - c & c and enju.', 'this is true even though mstparser and maltparser have not been engineered specifically for english']","['in  #TAUTHOR_TAG - c & c and enju.', 'this is true even though mstparser and maltparser have not been engineered specifically for english']","['conclusion, the capacity of mstparser and maltparser to recover unbounded dependencies is very similar on the macro and weighted macro level, but there is a clear distinction in their strengths - constructions involving more distant dependencies such as obq, rnr and sbem for mstparser and constructions with more locally defined configurations such as obrc, obred, sbrc and free for maltparser.', 'this is a pattern that has been observed in previous evaluations of the parsers and can be explained by the global learning and inference strategy of mstparser and the richer feature space of maltparser ( mc  #AUTHOR_TAG.', 'perhaps more interestingly, the accuracies of mstparser and maltparser are only slightly below the best performing systems in  #TAUTHOR_TAG - c & c and enju.', 'this is true even though mstparser and maltparser have not been engineered specifically for english and lack special mechanisms for handling unbounded dependencies, beyond the simple post - processing heuristic used to extract them from the output trees.', 'thus, it is reasonable to speculate that the addition of such mechanisms could lead to computationally lightweight parsers with the ability to extract unbounded dependencies with high accuracy']",4
"['of  #TAUTHOR_TAG for two dependency parsers, with the goal of evaluating']","['of  #TAUTHOR_TAG for two dependency parsers, with the goal of evaluating']","['this paper we repeat the study of  #TAUTHOR_TAG for two dependency parsers, with the goal of evaluating']","['this paper we repeat the study of  #TAUTHOR_TAG for two dependency parsers, with the goal of evaluating how parsers based on dependency grammars perform on unbounded dependencies.', 'mstparser 1 is a freely available implementation of the parsing models described in mc  #AUTHOR_TAG.', 'according to the categorization of parsers in kubler et al. ( 2008 ) it is a graph - based parsing system in that core parsing algorithms can be equated to finding directed maximum spanning trees ( either projective or non - projective ) from a dense graph representation of the sentence.', '']",5
"['in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead,']","['in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead,']","['in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead,']","['important difference between mstparser and maltparser, on the one hand, and the best performing parsers evaluated in  #TAUTHOR_TAG, on the other, is that the former were never developed specifically as parsers for english.', 'instead, they are best understood as data - driven parser generators, that is, tools for generating a parser given a training set of sentences annotated with dependency structures.', 'over the years, both systems have been applied to a wide range of languages ( see, e. ( 2007 ) ), but they come with no language - specific enhancements and are not equipped specifically to deal with unbounded dependencies.', 'since the dependency representation used in the evaluation corpus is based on the stanford typed dependency scheme ( de  #AUTHOR_TAG, we opted for using the wsj section of the ptb, converted to stanford dependencies, as our primary source of training data.', 'thus, both parsers were trained on section 2 - 21 of the wsj data, which we converted to stanford dependencies using the stanford parser  #AUTHOR_TAG.', 'the stanford scheme comes in several varieties, but because both parsers require the dependency structure for each sentence to be a tree, we had to use the so - called basic variety ( de  #AUTHOR_TAG.', 'it is well known that questions are very rare in the wsj data, and  #TAUTHOR_TAG found that parsers trained only on wsj data generally performed badly on the questions included in the evaluation corpus, while the c & c parser equipped with a model trained on a combination of wsj and question data had much better performance.', 'to investigate whether the performance of mstparser and maltparser on questions could also be improved by adding more questions to the training data, we trained one variant of each parser using data that was extended with 3924 questions taken from questionbank ( qb )  #AUTHOR_TAG.', '4 since the qb sentences are annotated in ptb style, it was possible to use the same conversion procedure as for the wsj data.', 'however, it is clear that the conversion did not always produce adequate dependency structures for the questions, an observation that we will return to in the error analysis below.', 'in comparison to the five parsers evaluated in  #TAUTHOR_TAG, it is worth noting that mstparser and maltparser were trained on the same basic data as four of the five, but with a different kind of syntactic representation - dependency trees instead of phrase structure trees or theoryspecific representations from ccg and hpsg.', 'it is especially interesting to compare mstparser and maltparser to the stanford parser, which essentially produces the same kind of dependency structures']",5
['the development and test sets in the corpus of  #TAUTHOR_TAG were'],['the development and test sets in the corpus of  #TAUTHOR_TAG were'],['the development and test sets in the corpus of  #TAUTHOR_TAG'],"['the development and test sets in the corpus of  #TAUTHOR_TAG were parsed using mstparser and maltparser after part - of - speech tagging the input using svmtool ( gimenez and marquez, 2004 ) trained on section 2 - 21 of the wsj data in stanford basic dependency format.', 'the stanford parser has an internal module that converts the basic dependency representation to the collapsed representation, which explicitly represents additional dependencies, including unbounded dependencies, that can be inferred from the basic representation ( de  #AUTHOR_TAG.', 'we performed a similar conversion using our own tool.', '']",5
"['criteria as in  #TAUTHOR_TAG.', 'a dependency was considered']","['criteria as in  #TAUTHOR_TAG.', 'a dependency was considered']","['evaluation was performed using the same criteria as in  #TAUTHOR_TAG.', 'a dependency was considered correctly recovered if the goldstandard head and dependent were']","['evaluation was performed using the same criteria as in  #TAUTHOR_TAG.', 'a dependency was considered correctly recovered if the goldstandard head and dependent were correct and the label was an "" acceptable match "" to the goldstandard label, indicating the grammatical function of the extracted element at least to the level of subject, passive subject, object, or adjunct.', 'the evaluation in  #TAUTHOR_TAG took into account a wide variety of parser output formats, some of which differed significantly from the gold - standard.', 'since mstparser and maltparser produced stanford dependencies for this experiment, evaluation required less manual examination than for some of the other parsers, as was also the case for the output of the stanford parser in the original evaluation.', 'however, a manual evaluation was still performed in order to resolve questionable cases']",5
"['sentences, since frequency statistics were not available for this construction in  #TAUTHOR_TAG']","['relative frequency in the ptb.', 'wavg excludes obq sentences, since frequency statistics were not available for this construction in  #TAUTHOR_TAG']","['relative frequency in the ptb.', 'wavg excludes obq sentences, since frequency statistics were not available for this construction in  #TAUTHOR_TAG.', 'our first observation is that the accuracies for both systems are considerably below']","['results are shown in table 2 : parser accuracy on the unbounded dependency corpus.', 'the obq score for c & c, mstparser, and maltparser is for a model trained with additional questions ( without this c & c scored 27. 5 ; mstparser and maltparser as in table 1 ).', 'a weighted macroaverage, where the constructions are weighted proportionally to their relative frequency in the ptb.', 'wavg excludes obq sentences, since frequency statistics were not available for this construction in  #TAUTHOR_TAG.', '']",5
"['telephone numbers.', 'one exception is  #TAUTHOR_TAG, who employed a char - based seq2seq model where the input mr is simply represented as a character sequence,']","['telephone numbers.', 'one exception is  #TAUTHOR_TAG, who employed a char - based seq2seq model where the input mr is simply represented as a character sequence,']","['telephone numbers.', 'one exception is  #TAUTHOR_TAG, who employed a char - based seq2seq model where the input mr is simply represented as a character sequence,']","['recently, researchers  #AUTHOR_TAG at heriot - watt university proposed the e2e nlg challenge 1 and released a dataset consisting of 50k ( mr, rf ) pairs, mr being a slot - value meaning representation of a restaurant, rf ( human reference ) being a natural language utterance rendering of that representation.', 'the utterances were crowd - sourced based on pictorial representations of the mrs, with the intention of producing more natural and diverse utterances compared to the ones directly based on the original mrs  #AUTHOR_TAG.', 'most of the rnn - based approaches to natural language generation ( nlg ) that we are aware of, starting with  #AUTHOR_TAG, generate the output word - by - word, and resort to special delexicalization or copy mechanisms  #AUTHOR_TAG to handle rare or unknown words, for instance restaurant names or telephone numbers.', 'one exception is  #TAUTHOR_TAG, who employed a char - based seq2seq model where the input mr is simply represented as a character sequence, and the output is also generated char - by - char ; this approach avoids the rare word problem, as the character vocabulary is very small.', 'while  #TAUTHOR_TAG used an additional finite - state mechanism to guide the production of well - formed ( and input - motivated ) character sequences, the performance of their basic char2char model was already quite good.', 'we further explore how a recent out - of - the box seq2seq model would perform on e2e nlg challenge, when used in a char - based mode.', 'we choose attention - based tfseq2seq framework provided by authors of  #AUTHOR_TAG ( which we detail in next section ).', 'using some standard options provided by this framework, and without any pre - or postprocessing ( not even tokenization or lowercasing ), we obtained results on which we conducted a small - scale human evaluation on one hundred mrs, involving two evaluators.', 'this evaluation, on the one hand, concentrated on the linguistic quality, and on the other hand, on the semantic adequacy of the produced utterances.', 'on the linguistic side, vast majority of the predictions were surprisingly grammatically perfect, while still being rather diverse and natural.', 'in particular, and contrary to the findings of  #TAUTHOR_TAG ( on a different dataset ), our char - based model never produced non - words.', 'on the adequacy side, we found that the only serious problem was the tendency ( in about half of the evaluated cases ) of the model to omit to render one ( rarely two ) slot ( s ) ; on the other end, it never hallucinated, and very rarely duplicated,']",4
"['to other grammatical categories has not been solved  #TAUTHOR_TAG.', 'if several other techniques have been proposed to determine affective valence from corpora, only a few of them have been designed to work with relatively small corpora ( ten million words or fewer ), a necessary property']","['to other grammatical categories has not been solved  #TAUTHOR_TAG.', 'if several other techniques have been proposed to determine affective valence from corpora, only a few of them have been designed to work with relatively small corpora ( ten million words or fewer ), a necessary property']","['to other grammatical categories has not been solved  #TAUTHOR_TAG.', 'if several other techniques have been proposed to determine affective valence from corpora, only a few of them have been designed to work with relatively small corpora ( ten million words or fewer ), a necessary property']","['my knowledge, the first researchers to propose an automatic procedure to determine the valence of words on the basis of corpora are hatzivassiloglou and mc  #AUTHOR_TAG.', 'their algorithm aims to infer the semantic orientation of adjectives on the basis of an analysis of their co - occurrences with conjunctions.', 'the main limitation of their algorithm is that it was developed specifically for adjectives and that the question of its application to other grammatical categories has not been solved  #TAUTHOR_TAG.', 'if several other techniques have been proposed to determine affective valence from corpora, only a few of them have been designed to work with relatively small corpora ( ten million words or fewer ), a necessary property for building specific affective lexicons.', 'two techniques that fulfil this condition are described below']",1
"[' #TAUTHOR_TAG tries to infer semantic orientation from semantic association in a corpus.', 'it is based on the semantic']","[' #TAUTHOR_TAG tries to infer semantic orientation from semantic association in a corpus.', 'it is based on the semantic']","[' #TAUTHOR_TAG tries to infer semantic orientation from semantic association in a corpus.', 'it is based on the semantic proximity between a target word and fourteen benchmarks : seven with positive valence and']","['technique proposed by  #TAUTHOR_TAG tries to infer semantic orientation from semantic association in a corpus.', 'it is based on the semantic proximity between a target word and fourteen benchmarks : seven with positive valence and seven with negative valence ( see table 1 ).', 'a word is considered as positive if it is closer to the positive benchmarks and further away from the negative benchmarks.', 'turney and littman proposed two techniques for estimating the strength of the semantic association between words on the basis of corpora.', 'the first technique estimates the semantic proximity between a word and a benchmark on the basis of the frequency with which they co - occur.', 'its main limitation is that it requires a very large corpus to be effective.', ' #AUTHOR_TAG  #AUTHOR_TAG.', ""for relatively small corpora ( i. e. ten million words ), they recommend the use of latent semantic analysis ( lsa ), a mathematical technique for extracting a very large'semantic space'from large text corpora on the basis of the statistical analysis of the set of co - occurrences in a text corpus  #AUTHOR_TAG."", 'the point of departure of the analysis is a lexical table  #AUTHOR_TAG containing the frequencies of every word in each of the documents included in the text material, a document being a text, a paragraph or a sentence.', '']",0
['- lsa benchmarks chosen by  #TAUTHOR_TAG were translated into 2'],"['two techniques described above were used in this experiment.', 'the fourteen so - lsa benchmarks chosen by  #TAUTHOR_TAG were translated into 2']","['two techniques described above were used in this experiment.', 'the fourteen so - lsa benchmarks chosen by  #TAUTHOR_TAG were translated into 2 each sentence was automatically modified so as to replace the name']","['two techniques described above were used in this experiment.', 'the fourteen so - lsa benchmarks chosen by  #TAUTHOR_TAG were translated into 2 each sentence was automatically modified so as to replace the name and the description of the function of every individual by a generic first name of adequate sex ( mary, john, etc. ) in order to prevent the judges being influenced by their prior positive or negative opinion about these people.', 'french ( bon, gentil, excellent, positif, heureux, correct et superieur : mauvais, mechant, mediocre, negatif, malheureux, faux et inferieur ).', 'for di - lsa, a french lexicon made up of 3000 words evaluated on the pleasant - unpleasant scale was used  #AUTHOR_TAG.', ""a minimum of thirty judges rated the words on a seven - point scale from'very unpleasant'( 1 ) table 3 : emotional valences of several sentences."", 'three corpora of five million words each, varying in similarity to the test materials, were used to estimate the proximity between the words and the benchmarks : - soir1995 corpus.', 'this includes newspaper articles published in le soir during the early months of 1995 : that is, the period from which the target sentences were extracted. - soir1997 corpus.', 'a comparable corpus was built from the articles published in le soir during the early months of 1997.', '- literary corpus.', 'a literary corpus of texts was built from novels and short stories available on the web ( mainly in the literary web databases abu and frantext ).', 'the soir1995 corpus is most similar to the test materials.', 'the soir1997 corpus includes texts from the same source as the test materials, but from a later period.', 'the literary corpus contains texts from a very different genre : it is the least similar to the test materials.', 'to be able to compare these three corpora in a fair way, the three semantic spaces were extracted, one from each corpus, according to an identical procedure adapted from  #AUTHOR_TAG.', 'these corpora were subdivided into segments of 125 words.', 'all the words of a segment had to come from the same text.', 'all the segments of fewer than 125 words ( articles of small size and the last incomplete segment of a text ) were removed.', 'these rules produced 40635 segments for the literary corpus and more than 50000 for the other two corpora.', 'in order to be able to compare corpora of different types, but of same sizes, only the first 40635 segments of the']",3
"['., using stacking  #TAUTHOR_TAG']",['using stacking  #TAUTHOR_TAG'],"['integrate base parsers at learning time, e. g., using stacking  #TAUTHOR_TAG.', 'in']","['ensemble models have been proposed for the parsing of syntactic dependencies.', 'these approaches can generally be classified in two categories : models that integrate base parsers at learning time, e. g., using stacking  #TAUTHOR_TAG.', 'in the latter case, the correctness of the final dependency tree is ensured by : ( a ) selecting entire trees proposed by the base parsers  #AUTHOR_TAG ; or ( b ) re - parsing the pool of dependencies proposed by the base models  #AUTHOR_TAG.', 'the latter approach was shown to perform better for constituent parsing  #AUTHOR_TAG.', 'while all these models achieved good performance, the previous work has left several questions table 2 : scores of unsupervised combination models using different voting strategies.', '']",0
"['by  #TAUTHOR_TAG.', 'the algorithm, which has a runtime']","['by  #TAUTHOR_TAG.', 'the algorithm, which has a runtime']","['have lower runtime complexity.', 'one such algorithm was proposed by  #TAUTHOR_TAG.', 'the algorithm, which has a runtime complexity']","['', 'this indicates that the focus on algorithms that guarantee well - formed trees is justified.', 'however, it is not clear how the eisner algorithm, which has runtime complexity of o ( n 3 ) ( n - number of tokens per sentence ), compares against approximate re - parsing algorithms that have lower runtime complexity.', 'one such algorithm was proposed by  #TAUTHOR_TAG.', '']",0
"['considerable benefits  #TAUTHOR_TAG.', 'however, it is unclear how these approaches compare']","['considerable benefits  #TAUTHOR_TAG.', 'however, it is unclear how these approaches compare']","['work has shown that the combination of base parsers at learning time, e. g., through stacking, yields considerable benefits  #TAUTHOR_TAG.', 'however, it is unclear how these approaches compare']","['work has shown that the combination of base parsers at learning time, e. g., through stacking, yields considerable benefits  #TAUTHOR_TAG.', 'however, it is unclear how these approaches compare against the simpler ensemble models, which combine parsers only at runtime.', 'to enable such a comparison, we reimplemented the best stacking model from ( nivre and mc  #AUTHOR_TAG - mst m alt - which trains a variant of the mstparser that uses additional features extracted from the output of a malt parser.', 'in table 6, we compare this stacking approach against four variants of our ensemble models.', 'the superscript in the ensemble name indicates the runtime complexity of the model ( o ( n 3 ) or o ( n ) ).', 'the cubic - time models use all base parsers from table 1 and the eisner algorithm for re - parsing.', 'the lineartime models use only malt - based parsers and the attardi algorithm for re - parsing.', 'the subscript in the model names indicates the percentage of available base parsers used, e. g., ensemble 3 50 % uses only the first three parsers from table 1.', 'these results show that mst m alt is statistically equivalent to an ensemble that uses mst and two malt variants, and both our ensemble 100 % models are significantly better than mst m alt.', 'while this comparison is somewhat unfair ( mst m alt uses two base models, whereas our ensemble models use at least three ) it does illustrate that the advantages gained from combining parsers at learning time can be easily surpassed by runtime combination models that have access to more base parsers.', 'considering that variants of shift - reduce parsers can be generated with minimal effort ( e. g., by varying the parsing direction, learning algorithms, etc. ) and combining models at runtime is simpler than combining them at learning time, we argue that runtime parser combination is a more attractive approach']",0
"['1, 2,  #TAUTHOR_TAG 4 ]']","['popular models for text - based response generation in dialog systems [ 1, 2,  #TAUTHOR_TAG 4 ]']","['1, 2,  #TAUTHOR_TAG 4 ].', 'historically, seq2seq - like models']","['- domain human - computer dialog systems are attracting increasing attention in the nlp community.', 'with the development of deep learning, sequence - to - sequence ( seq2seq ) neural networks or more generally encoder - decoder frameworks, are among the most popular models for text - based response generation in dialog systems [ 1, 2,  #TAUTHOR_TAG 4 ].', '']",0
"['1, 2,  #TAUTHOR_TAG 4 ]']","['popular models for text - based response generation in dialog systems [ 1, 2,  #TAUTHOR_TAG 4 ]']","['1, 2,  #TAUTHOR_TAG 4 ].', 'historically, seq2seq - like models']","['- domain human - computer dialog systems are attracting increasing attention in the nlp community.', 'with the development of deep learning, sequence - to - sequence ( seq2seq ) neural networks or more generally encoder - decoder frameworks, are among the most popular models for text - based response generation in dialog systems [ 1, 2,  #TAUTHOR_TAG 4 ].', '']",0
"['1, 2,  #TAUTHOR_TAG 4 ]']","['popular models for text - based response generation in dialog systems [ 1, 2,  #TAUTHOR_TAG 4 ]']","['1, 2,  #TAUTHOR_TAG 4 ].', 'historically, seq2seq - like models']","['- domain human - computer dialog systems are attracting increasing attention in the nlp community.', 'with the development of deep learning, sequence - to - sequence ( seq2seq ) neural networks or more generally encoder - decoder frameworks, are among the most popular models for text - based response generation in dialog systems [ 1, 2,  #TAUTHOR_TAG 4 ].', '']",0
"['1, 2,  #TAUTHOR_TAG 4 ]']","['popular models for text - based response generation in dialog systems [ 1, 2,  #TAUTHOR_TAG 4 ]']","['1, 2,  #TAUTHOR_TAG 4 ].', 'historically, seq2seq - like models']","['- domain human - computer dialog systems are attracting increasing attention in the nlp community.', 'with the development of deep learning, sequence - to - sequence ( seq2seq ) neural networks or more generally encoder - decoder frameworks, are among the most popular models for text - based response generation in dialog systems [ 1, 2,  #TAUTHOR_TAG 4 ].', '']",0
"['1, 2,  #TAUTHOR_TAG 4 ]']","['popular models for text - based response generation in dialog systems [ 1, 2,  #TAUTHOR_TAG 4 ]']","['1, 2,  #TAUTHOR_TAG 4 ].', 'historically, seq2seq - like models']","['- domain human - computer dialog systems are attracting increasing attention in the nlp community.', 'with the development of deep learning, sequence - to - sequence ( seq2seq ) neural networks or more generally encoder - decoder frameworks, are among the most popular models for text - based response generation in dialog systems [ 1, 2,  #TAUTHOR_TAG 4 ].', '']",0
"[""of seq2seq's performance in this way  #TAUTHOR_TAG, barely a practical approach exists to verify the conjecture in the dialog setting alone."", 'in the']","[""of seq2seq's performance in this way  #TAUTHOR_TAG, barely a practical approach exists to verify the conjecture in the dialog setting alone."", 'in the']","[""of seq2seq's performance in this way  #TAUTHOR_TAG, barely a practical approach exists to verify the conjecture in the dialog setting alone."", 'in the rest of this paper, we will verify it with a modification of machine translation tasks']","['hypothesize that given a source sequence, the conditional distribution of the target sequence having multiple plausible points is one cause of the deficiency of seq2seq models in dialog systems.', 'let us denote the source sequence by s = s 1, s 2, · · ·, s | s | and the target sequence by t = t 1, t 2, · · ·, t | t |.', 'both ( orthodox ) training and prediction objectives are to maximize p θ ( t | s ), where the conditional probability p θ ( · | · ) is modeled by a seq2seq neural network with parameters θ.', 'in a machine translation system, the source and target information generally aligns well, although some meanings could have different expressions.', 'figure 1a shows a continuous analog of p ( t | s ).', 'in an open - domain dialog system, however, an utterance may have a variety of replies that are ( nearly ) equally plausible.', 'for example, given a user - issued utterance "" what are you going to do? "" there could be multiple replies like "" having lunch, "" "" watching movies, "" and "" sleeping, "" shown in figure 1b with an analog using continuous variables.', 'there is no particular reason why one reply should be favored over another without further context ; even with context, this problem could not be fully solved because of the true randomness of dialog.', 'located near the "" mode "" could be viewed as replies of similar meanings but less fluent expressions.', 'other areas with low probabilities are nonsensical utterances that are either not fluent in spoken language or irrelevant to the previous utterance s.', 'the above is, perhaps, the most salient difference between dialog and translation datasets.', ""although it is tempting to think of seq2seq's performance in this way  #TAUTHOR_TAG, barely a practical approach exists to verify the conjecture in the dialog setting alone."", 'in the rest of this paper, we will verify it with a modification of machine translation tasks']",0
,,,,3
"['19 ], keywords  #TAUTHOR_TAG and knowledge bases']","['referring to additional information - including dialog context [ 19 ], keywords  #TAUTHOR_TAG and knowledge bases [ 20 ] - helps dialog systems :']","['referring to additional information - including dialog context [ 19 ], keywords  #TAUTHOR_TAG and knowledge bases']","['paper addressed the question why dialog systems generate short and meaningless replies.', 'we managed to reproduce this phenomenon in two translation datasets, artificially mimicking the scenario that a source sentence can have multiple equally plausible target sentences.', 'admittedly, it is impossible to construct identical scenario as dialog by using translation datasets ( otherwise the translation just becomes dialog ).', 'however, the unaligned property is a salient difference, and by controlling this, we observe the desired phenomenon, demonstrating our conjecture.', 'our findings also explain why referring to additional information - including dialog context [ 19 ], keywords  #TAUTHOR_TAG and knowledge bases [ 20 ] - helps dialog systems : the number of plausible target sentences decreases if the generation is conditioned on more information ; this intuition is helpful for future development of text - based response generation in seq2seq dialog systems.', 'besides, our experiments suggest that seq2seq models are more suitable to applications where the source and target information is aligned']",3
,,,,5
"['empirical results, most regard bilstm - cnn as a robust core module for sequence - labeling ner [ 1,  #TAUTHOR_TAG 3, 4, 5 ]']","['state - of - the - art empirical results, most regard bilstm - cnn as a robust core module for sequence - labeling ner [ 1,  #TAUTHOR_TAG 3, 4, 5 ]']","['- art empirical results, most regard bilstm - cnn as a robust core module for sequence - labeling ner [ 1,  #TAUTHOR_TAG 3, 4, 5 ].', 'however, each direction of bilstm only sees and encodes half of a sequence']","['state - of - the - art empirical results, most regard bilstm - cnn as a robust core module for sequence - labeling ner [ 1,  #TAUTHOR_TAG 3, 4, 5 ].', 'however, each direction of bilstm only sees and encodes half of a sequence at each time step.', 'for each token, the forward lstm only encodes past context ; the backward lstm only encodes future context.', 'both do not model the patterns that happen to cross past and future at this specific time step.', 'this paper explores two types of cross - structures to help cope with the problem : cross - bilstm - cnn and att - bilstm - cnn.', 'section 2 formulates the three models, with section 2. 2 gives a concrete proof that patterns forming an xor cannot be modeled by ( baseline - ) bilstm - cnn used in all previous work.', 'section 3 evaluates practical effectiveness of the approaches on two challenging ner datasets.', 'the cross - structures bring consistent improvements over baseline - bilstm - cnn without additional gazetteers, language - modeling, or multi - task supervision.', 'the improved core module surpasses comparable bare - bone models on ontonotes and wnut by 1. 4 % and 4. 6 % respectively.', 'ablation experiments reveal that emerging, complex, confusing, and multi - token entity mentions benefitted much from the cross - structures, up to 8. 7 % on some of the multi - token mentions']",0
"['empirical results, most regard bilstm - cnn as a robust core module for sequence - labeling ner [ 1,  #TAUTHOR_TAG 3, 4, 5 ]']","['state - of - the - art empirical results, most regard bilstm - cnn as a robust core module for sequence - labeling ner [ 1,  #TAUTHOR_TAG 3, 4, 5 ]']","['- art empirical results, most regard bilstm - cnn as a robust core module for sequence - labeling ner [ 1,  #TAUTHOR_TAG 3, 4, 5 ].', 'however, each direction of bilstm only sees and encodes half of a sequence']","['state - of - the - art empirical results, most regard bilstm - cnn as a robust core module for sequence - labeling ner [ 1,  #TAUTHOR_TAG 3, 4, 5 ].', 'however, each direction of bilstm only sees and encodes half of a sequence at each time step.', 'for each token, the forward lstm only encodes past context ; the backward lstm only encodes future context.', 'both do not model the patterns that happen to cross past and future at this specific time step.', 'this paper explores two types of cross - structures to help cope with the problem : cross - bilstm - cnn and att - bilstm - cnn.', 'section 2 formulates the three models, with section 2. 2 gives a concrete proof that patterns forming an xor cannot be modeled by ( baseline - ) bilstm - cnn used in all previous work.', 'section 3 evaluates practical effectiveness of the approaches on two challenging ner datasets.', 'the cross - structures bring consistent improvements over baseline - bilstm - cnn without additional gazetteers, language - modeling, or multi - task supervision.', 'the improved core module surpasses comparable bare - bone models on ontonotes and wnut by 1. 4 % and 4. 6 % respectively.', 'ablation experiments reveal that emerging, complex, confusing, and multi - token entity mentions benefitted much from the cross - structures, up to 8. 7 % on some of the multi - token mentions']",1
"['baseline  #TAUTHOR_TAG, a cnn is used']","['baseline  #TAUTHOR_TAG, a cnn is used']","['baseline  #TAUTHOR_TAG, a cnn is used']","['baseline  #TAUTHOR_TAG, a cnn is used to compute character - level word features alongside word embedding and multi - layer bilstm is used to capture the future and the past for each time step :', 'the probability of each token class is given by affine - softmax.', 'using osbie sequential labels  #TAUTHOR_TAG, when there are p entity types, the number of token classes d p = p × 4 + 1.', 'first, note that the score vector at each time step is the sum of contributions of two directions.', 'suppose the index of work - of - art : i and o are i, j respectively.', 'then, to predict each "" and "" correctly, it must hold that ( superscripts denote the phrase number )', ', phrase 1 and phrase 3 have the same past context for "" and "", and hence the same', 'finally, summing the first two inequalities and the last two inequalities gives two contradicting constraints that cannot be satisfied.', 'in other words, even if an oracle is given to training the model, baseline - bilstm - cnn can only tag at most 3 out of 4 "" and "" correctly.', 'no matter how many lstm cells are stacked for each direction, the formulation in previous studies simply does not have enough modeling capacity to capture cross - context patterns for sequence labeling ner']",5
"['baseline  #TAUTHOR_TAG, a cnn is used']","['baseline  #TAUTHOR_TAG, a cnn is used']","['baseline  #TAUTHOR_TAG, a cnn is used']","['baseline  #TAUTHOR_TAG, a cnn is used to compute character - level word features alongside word embedding and multi - layer bilstm is used to capture the future and the past for each time step :', 'the probability of each token class is given by affine - softmax.', 'using osbie sequential labels  #TAUTHOR_TAG, when there are p entity types, the number of token classes d p = p × 4 + 1.', 'first, note that the score vector at each time step is the sum of contributions of two directions.', 'suppose the index of work - of - art : i and o are i, j respectively.', 'then, to predict each "" and "" correctly, it must hold that ( superscripts denote the phrase number )', ', phrase 1 and phrase 3 have the same past context for "" and "", and hence the same', 'finally, summing the first two inequalities and the last two inequalities gives two contradicting constraints that cannot be satisfied.', 'in other words, even if an oracle is given to training the model, baseline - bilstm - cnn can only tag at most 3 out of 4 "" and "" correctly.', 'no matter how many lstm cells are stacked for each direction, the formulation in previous studies simply does not have enough modeling capacity to capture cross - context patterns for sequence labeling ner']",5
"['att - bilstm - cnn, results of bare - bone bilstm - cnn  #TAUTHOR_TAG, crf - bilstm ( - bilstm )']","['att - bilstm - cnn, results of bare - bone bilstm - cnn  #TAUTHOR_TAG, crf - bilstm ( - bilstm ) [ 11, 12 ], and crf - idcnn [ 11 ] from']","['att - bilstm - cnn, results of bare - bone bilstm - cnn  #TAUTHOR_TAG, crf - bilstm ( - bilstm ) [ 11, 12 ], and crf - idcnn [ 11 ] from']","['evaluated on tow datasets : ontonotes 5. 0 fine - grained ner - a million - token corpus with diverse sources and 18 fine - grained entity types, including hard ones such as law, event, work - of - art [ 7, 8 ] ; wnut 2017 emerging ner - a corpus consists of noisy social media text, with text in the testing set containing surface forms seen in the training set filtered out [ 9, 10 ].', 'overall results.', 'table 1 shows overall results.', 'besides baseline -, cross -, and att - bilstm - cnn, results of bare - bone bilstm - cnn  #TAUTHOR_TAG, crf - bilstm ( - bilstm ) [ 11, 12 ], and crf - idcnn [ 11 ] from the literature are also listed.', '']",5
"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the']","[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['the highest ranked parse trees are added to the training set of the parser and the parser is retrained. this self - training method gives improved performance, not only on section 23 of the wsj ( an absolute f - score improvement of 0. 8 % ), but also on test sentences', 'from the brown corpus ( francis and kucera, 1979 ) ( an absolute fscore improvement of', ""2. 6 % ). in the experiments of mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the same domain ( american newspaper text ) as the parser's original seed"", 'training material.  #AUTHOR_TAG find that self - training is effective when the parse trees used for self - training ( wsj parse trees ) come from a different domain to', 'the seed training data and from the same domain as the test data ( wsj sentences ). they report a performance boost of 4', '']",0
"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the']","[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['the highest ranked parse trees are added to the training set of the parser and the parser is retrained. this self - training method gives improved performance, not only on section 23 of the wsj ( an absolute f - score improvement of 0. 8 % ), but also on test sentences', 'from the brown corpus ( francis and kucera, 1979 ) ( an absolute fscore improvement of', ""2. 6 % ). in the experiments of mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the same domain ( american newspaper text ) as the parser's original seed"", 'training material.  #AUTHOR_TAG find that self - training is effective when the parse trees used for self - training ( wsj parse trees ) come from a different domain to', 'the seed training data and from the same domain as the test data ( wsj sentences ). they report a performance boost of 4', '']",0
"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the']","[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['the highest ranked parse trees are added to the training set of the parser and the parser is retrained. this self - training method gives improved performance, not only on section 23 of the wsj ( an absolute f - score improvement of 0. 8 % ), but also on test sentences', 'from the brown corpus ( francis and kucera, 1979 ) ( an absolute fscore improvement of', ""2. 6 % ). in the experiments of mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the same domain ( american newspaper text ) as the parser's original seed"", 'training material.  #AUTHOR_TAG find that self - training is effective when the parse trees used for self - training ( wsj parse trees ) come from a different domain to', 'the seed training data and from the same domain as the test data ( wsj sentences ). they report a performance boost of 4', '']",0
"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the']","[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['the highest ranked parse trees are added to the training set of the parser and the parser is retrained. this self - training method gives improved performance, not only on section 23 of the wsj ( an absolute f - score improvement of 0. 8 % ), but also on test sentences', 'from the brown corpus ( francis and kucera, 1979 ) ( an absolute fscore improvement of', ""2. 6 % ). in the experiments of mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the same domain ( american newspaper text ) as the parser's original seed"", 'training material.  #AUTHOR_TAG find that self - training is effective when the parse trees used for self - training ( wsj parse trees ) come from a different domain to', 'the seed training data and from the same domain as the test data ( wsj sentences ). they report a performance boost of 4', '']",0
"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the']","[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['the highest ranked parse trees are added to the training set of the parser and the parser is retrained. this self - training method gives improved performance, not only on section 23 of the wsj ( an absolute f - score improvement of 0. 8 % ), but also on test sentences', 'from the brown corpus ( francis and kucera, 1979 ) ( an absolute fscore improvement of', ""2. 6 % ). in the experiments of mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the same domain ( american newspaper text ) as the parser's original seed"", 'training material.  #AUTHOR_TAG find that self - training is effective when the parse trees used for self - training ( wsj parse trees ) come from a different domain to', 'the seed training data and from the same domain as the test data ( wsj sentences ). they report a performance boost of 4', '']",5
"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the']","[' #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used']","['the highest ranked parse trees are added to the training set of the parser and the parser is retrained. this self - training method gives improved performance, not only on section 23 of the wsj ( an absolute f - score improvement of 0. 8 % ), but also on test sentences', 'from the brown corpus ( francis and kucera, 1979 ) ( an absolute fscore improvement of', ""2. 6 % ). in the experiments of mc  #AUTHOR_TAG a ;  #TAUTHOR_TAG, the parse trees used for self - training come from the same domain ( american newspaper text ) as the parser's original seed"", 'training material.  #AUTHOR_TAG find that self - training is effective when the parse trees used for self - training ( wsj parse trees ) come from a different domain to', 'the seed training data and from the same domain as the test data ( wsj sentences ). they report a performance boost of 4', '']",4
['by  #TAUTHOR_TAG for'],['by  #TAUTHOR_TAG for'],['by  #TAUTHOR_TAG for'],[' #TAUTHOR_TAG'],4
[' #TAUTHOR_TAG has'],[' #TAUTHOR_TAG has'],"['', 'most recent work  #TAUTHOR_TAG has focused on the use of']","['- embeddings are a quick and useful prior step for improving word representations in natural language learning tasks.', 'this involves combining several learned embeddings in a way that improve the overall input representation.', 'this approach is a less computationally expensive compared to if a practitioner were to train a set of word embeddings from scratch, particularly when considering non - sliding window methods.', 'the most straightforward approaches to meta - embeddings are : concatenation ( conc ) and averaging ( av ).', 'the former is limited since the dimensionality grows large for multiple embeddings as more vectors are concatenated and the latter, while fast, does not preserve most of the information encoded in each embedding when taking the arithmetic mean.', 'although, it would seem surprising concatenating vectors from different embedding spaces is valid, it has been shown that  #AUTHOR_TAG av approximates conc even though the embedding spaces are different.', 'although, to address the loss of information when using av, singular value decomposition has been used as a dimensionality reduction technique to factorize the embeddings into a lower - rank approximation of the concatenated meta - embedding set.', 'linear methods include the use of a projection layer for meta - embedding ( known as 1ton ) yin and schutze ( 2015 ), which is simply trained using an 2 - based loss.', 'similarly, bollegala et al.  #AUTHOR_TAG has focused on finding a linear transformation between count - based and prediction - based embeddings, showing that linearly transformed count - based embeddings can be used for predictions in the localized neighborhoods in the target space.', 'most recent work  #TAUTHOR_TAG has focused on the use of an autoencoder ( ae ) to encode a set of n pretrained embeddings using 3 different variants : ( 1 ) decoupled autoencoded meta embeddings ( daeme ) that keep activations separated for each respective embedding input during encoding and uses a reconstruction loss for both predicted embeddings while minimizing the loss for each respective decoded output, ( 2 ) coupled autoencoded meta embeddings ( caeme ) which instead learn to predict from a shared encoding and ( 3 ) averaged autoencoded meta - embedding ( aame ) is simply an averaging of the embedding set as input instead of using a concatenation.', 'this is the most relevant work to our paper, hence, we include these 3 autoencoding schemes along with aforementioned methods for experiments, described in section 3.', 'we also include two subtle variations of the aforementioned arxiv : 1808. 04334v1 [ cs. cl ] 13 aug 2018', 'aes.', 'the first predicts a target embedding from an embedding set using the remaining embedding set, post - learning the single hidden layer is used as the word meta - embedding.', 'the second']",0
['##oder approaches  #TAUTHOR_TAG ('],"['2 shows a comparison of the previous autoencoder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction.']","['##oder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction. the concata']","['vectors we obtain a set of lowerdimensional target latent representation that represents different combinations of mappings from one vector space to another. after training, all h set of latent variables z s = { z 1,.., z h }', 'are concatenated with an autoencoded target vector. this means thats all vector spaces have been mapped to a target space and there hidden meta - word representations have been averaged, as illustrated in figure 1. figure 2 shows a comparison of the previous autoencoder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction. the concatautoencoder ( caeme ) simply concatenates the', '']",0
['##oder approaches  #TAUTHOR_TAG ('],"['2 shows a comparison of the previous autoencoder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction.']","['##oder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction. the concata']","['vectors we obtain a set of lowerdimensional target latent representation that represents different combinations of mappings from one vector space to another. after training, all h set of latent variables z s = { z 1,.., z h }', 'are concatenated with an autoencoded target vector. this means thats all vector spaces have been mapped to a target space and there hidden meta - word representations have been averaged, as illustrated in figure 1. figure 2 shows a comparison of the previous autoencoder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction. the concatautoencoder ( caeme ) simply concatenates the', '']",5
['##oder approaches  #TAUTHOR_TAG ('],"['2 shows a comparison of the previous autoencoder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction.']","['##oder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction. the concata']","['vectors we obtain a set of lowerdimensional target latent representation that represents different combinations of mappings from one vector space to another. after training, all h set of latent variables z s = { z 1,.., z h }', 'are concatenated with an autoencoded target vector. this means thats all vector spaces have been mapped to a target space and there hidden meta - word representations have been averaged, as illustrated in figure 1. figure 2 shows a comparison of the previous autoencoder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction. the concatautoencoder ( caeme ) simply concatenates the', '']",5
['##oder approaches  #TAUTHOR_TAG ('],"['2 shows a comparison of the previous autoencoder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction.']","['##oder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction. the concata']","['vectors we obtain a set of lowerdimensional target latent representation that represents different combinations of mappings from one vector space to another. after training, all h set of latent variables z s = { z 1,.., z h }', 'are concatenated with an autoencoded target vector. this means thats all vector spaces have been mapped to a target space and there hidden meta - word representations have been averaged, as illustrated in figure 1. figure 2 shows a comparison of the previous autoencoder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction. the concatautoencoder ( caeme ) simply concatenates the', '']",5
['schemes by  #TAUTHOR_TAG that'],['schemes by  #TAUTHOR_TAG that'],['##oder schemes by  #TAUTHOR_TAG that we have used'],"['following word association and word similarity datasets are used throughout experimentation : simlex  #AUTHOR_TAG, wordsim - 353  #AUTHOR_TAG, rg  #AUTHOR_TAG, mturk ( mechanicalturk - 771 )  #AUTHOR_TAG, rareword ( rw )  #AUTHOR_TAG and men  #AUTHOR_TAG.', 'the word vectors considered in the embeddings set are skipgram and cbow  #AUTHOR_TAG, fasttext  #AUTHOR_TAG, lexvec  #AUTHOR_TAG, hellinger pca ( hpca )  #AUTHOR_TAG and hierarchical document context ( hdc )  #AUTHOR_TAG.', 'we now report results on the performance of meta - embedding autoencodings with various loss functions, while also presenting target autoencoders for combinations of word embeddings and compare against existing current sota meta - embeddings.', 'table 1 shows the scaled spearman correlation test scores, where ( 1 ) shows the original single embeddings, ( 2 ) results for standard metaembedding approaches that either apply a single mathematical operation or employ a linear projection as an encoding, ( 3 ) presents the results using autoencoder schemes by  #TAUTHOR_TAG that we have used to test the various losses, ( 4 ) introduces tae without concatenating the target y embedding post - training with mse loss and ( 5 ) shows the results of concatenating y with the lower - dimensional ( 200 - dimensions ) vector that encodes all embeddings apart from the target vector.', 'therefore reported results from ( 4 ) are of a 200d vector, while ( 5 ) concatenates the vector leading to a vector between 300 - 500 dimensions dependent on the target vector.', 'all trained encodings from sections 3 - 5 are 200 - dimensional vectors.', 'results in red shading indicate the best performing meta - embedding for all presented approaches, while black shading indicates the best performing meta - embedding for the respective section.', 'best performing word meta - embeddings are held between concatenated autoencoders that use the proposed cosine - embedding loss, while a kl - divergence also performs well on simlex and rareword.', 'interestingly, both of these dataset are distinct in that simlex is the only dataset providing scores on true similarity instead of free association, which has shown to be more difficult for word embeddings to account for  #AUTHOR_TAG, while rareword provides morphologically complex words to find similarity between.', 'concretely, it would seem kl - divergence is well suited for encoding when the word relations exhibits of a more complex or rare nature.', 'similarly, we find scp loss to achieve best results on rg and men, both the smallest and largest datasets of the set.', 'furthermore, the tae variant has lead to competitive performance overall against other metaembedding approaches and even produces best results on ws353.', 'lastly']",5
['##oder approaches  #TAUTHOR_TAG ('],"['2 shows a comparison of the previous autoencoder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction.']","['##oder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction. the concata']","['vectors we obtain a set of lowerdimensional target latent representation that represents different combinations of mappings from one vector space to another. after training, all h set of latent variables z s = { z 1,.., z h }', 'are concatenated with an autoencoded target vector. this means thats all vector spaces have been mapped to a target space and there hidden meta - word representations have been averaged, as illustrated in figure 1. figure 2 shows a comparison of the previous autoencoder approaches  #TAUTHOR_TAG ( left ) and the alternative ae ( right ), where dashed lines indicate connections during training and bold lines indicate', 'prediction. the concatautoencoder ( caeme ) simply concatenates the', '']",4
"['', ' #TAUTHOR_TAG']","['', ' #TAUTHOR_TAG']","['', ' #TAUTHOR_TAG']","['', ' #TAUTHOR_TAG']",4
['2016 ;  #TAUTHOR_TAG on'],['2016 ;  #TAUTHOR_TAG on'],['2016 ;  #TAUTHOR_TAG on learning entity representation'],"['work focuses on improving entity linking by capturing latent entity type information with bert.', 'specifically, our work related to previous approaches in three aspects.', 'entity embedding the entity linking task is essentially a zero - shot task where the answer of test cases may not exist in the training data.', '3 so we need to build a shared entity embedding space for all entities which allows neural entity linking models to generalize to both seen and unseen entities during test time.', 'based on the distributional hypothesis ( harris 1954 ), an entity is characterized by its contexts.', ""different methods to characterize an entity's context result in different information its entity embedding can capture."", 'previous work ( yamada et al. 2016 ;  #TAUTHOR_TAG on learning entity representation are mostly extensions of the embedding methods proposed by ( mikolov et al. 2013 ).', ""an entity's context is a bag - ofwords representation which mainly captures topic level entity relatedness rather than entity type relatedness."", 'in contrast, we propose a simple method to build entity embeddings directly from pre - trained bert ( devlin et al. 2019 ) which can better capture entity type information.', '']",4
['type information than those from  #TAUTHOR_TAG'],['type information than those from  #TAUTHOR_TAG'],"[', the entity embeddings from bert better capture entity type information than those from  #TAUTHOR_TAG']","['', ""here, the mention's immediate context is a sequence of tokens where the mention m ij is replaced with a single [MASK] token."", 'then, we represent the immediate entity context by extracting the upper most layer representation of pre - trained bert ( devlin et al. 2019 ) corresponding to the [MASK] token.', 'entity representation for each entity e i ∈ e, we randomly sample at most n anchor contexts { c i1, c i2,..., c in } from wikipedia.', 'then the entity representation of e i is computed by aggregating all the context representation { c i1, c i2,..., c in } via average pooling.', 'as will be shown in the analysis section, the entity embeddings from bert better capture entity type information than those from  #TAUTHOR_TAG']",4
"['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG,']","['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG,']","['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG, all the entity embeddings are fixed during fine - tuning']","['not bert related parameters a larger initial learning rate to avoid the whole model biasing toward', 'the bert feature and disregarding other model components. in our experiments, pre - trained bert model is fine - tuned with initial learning rate 10 −5 whereas not bert related parameters are trained with 10 −3. similar learning rate usage can be found in the recent work by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG, all the entity embeddings are fixed during fine - tuning. we', 'randomly initialize the not bert related parameters using gaussian distribution n ( 0. 0, 0. 02 ) and the bias term is zeroed. note that all the hyper - parameters used in the local context and global model of  #TAUTHOR_TAG were', 'set to the same values as theirs for direct comparison purpose. detailed hyper - parameters', 'setting is described in the appendices. our model is trained with 4 nvidia tes', '##la p100 gpus. we run each of our model five times with different random seeds, and the performance is', 'reported in the form of average ± standard deviation. table 1 shows', 'the micro f1 scores on in - domain aida - b dataset of the sota methods and ours, which all use', 'wikipedia and yago mention - entity index. the models are divided into two groups : local models and local & global models. as we can see,', '']",4
"['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG,']","['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG,']","['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG, all the entity embeddings are fixed during fine - tuning']","['not bert related parameters a larger initial learning rate to avoid the whole model biasing toward', 'the bert feature and disregarding other model components. in our experiments, pre - trained bert model is fine - tuned with initial learning rate 10 −5 whereas not bert related parameters are trained with 10 −3. similar learning rate usage can be found in the recent work by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG, all the entity embeddings are fixed during fine - tuning. we', 'randomly initialize the not bert related parameters using gaussian distribution n ( 0. 0, 0. 02 ) and the bias term is zeroed. note that all the hyper - parameters used in the local context and global model of  #TAUTHOR_TAG were', 'set to the same values as theirs for direct comparison purpose. detailed hyper - parameters', 'setting is described in the appendices. our model is trained with 4 nvidia tes', '##la p100 gpus. we run each of our model five times with different random seeds, and the performance is', 'reported in the form of average ± standard deviation. table 1 shows', 'the micro f1 scores on in - domain aida - b dataset of the sota methods and ours, which all use', 'wikipedia and yago mention - entity index. the models are divided into two groups : local models and local & global models. as we can see,', '']",4
['global version of  #TAUTHOR_TAG ;  #AUTHOR_TAG ; by an average'],['global version of  #TAUTHOR_TAG ;  #AUTHOR_TAG ; by an average'],['global version of  #TAUTHOR_TAG ;  #AUTHOR_TAG ; by an average'],"['evaluate the robustness of our model, table 2 shows the performance of our method and sota methods on five out - domain test sets.', 'on average, our proposed model ( bert - entity - sim ) outperforms the local & global version of  #TAUTHOR_TAG ;  #AUTHOR_TAG ; by an average 0. 80 and 0. 51 on f1']",4
['cases. this indicates that  #TAUTHOR_TAG'],['( 322 ) error cases. this indicates that  #TAUTHOR_TAG'],['cases. this indicates that  #TAUTHOR_TAG produces many type'],[' #TAUTHOR_TAG'],4
['cases. this indicates that  #TAUTHOR_TAG'],['( 322 ) error cases. this indicates that  #TAUTHOR_TAG'],['cases. this indicates that  #TAUTHOR_TAG produces many type'],[' #TAUTHOR_TAG'],4
['cases. this indicates that  #TAUTHOR_TAG'],['( 322 ) error cases. this indicates that  #TAUTHOR_TAG'],['cases. this indicates that  #TAUTHOR_TAG produces many type'],[' #TAUTHOR_TAG'],4
"['linking', 'model featuring better efficiency and effectiveness than that of  #TAUTHOR_TAG by breaking the']","['2019 ). dca is a global entity linking', 'model featuring better efficiency and effectiveness than that of  #TAUTHOR_TAG by breaking the']","['linking', 'model featuring better efficiency and effectiveness than that of  #TAUTHOR_TAG by breaking the']","['', 'proposed dynamic context augmentation ( dca ) 15 ( yang et al. 2019 ). dca is a global entity linking', 'model featuring better efficiency and effectiveness than that of  #TAUTHOR_TAG by breaking the "" all - mention', 'coherence "" assumption. compared to bert - entity - sim equipped with  #TAUTHOR_TAG. we found that  #AUTHOR_TAG includes an explicit type similarity which is', 'based on a typing system 16 trained with aida - train ner annotation. this explicit type similarity feature is tailored', ""for aida - conll data set and doesn't achieve good generalization performance on out - domain test sets. in contrast, our bert - entity - sim model capturing latent type information has potential better generalization performance with an average 2. 10 f1 improvement over them""]",4
"['nearest entities in the embedding space of  #TAUTHOR_TAG and ours.', '']","['nearest entities in the embedding space of  #TAUTHOR_TAG and ours.', '']","['nearest entities in the embedding space of  #TAUTHOR_TAG and ours.', '']","['also retrieve nearest entities in the embedding space of  #TAUTHOR_TAG and ours.', 'as we can see, we query steve jobs, the nearest entity in  #TAUTHOR_TAG is apple inc.', 'which is a different type.', 'in contrast, all the entities retrieved by our approach share the same types like person, entrepreneur etc.', 'another example is when we query na - tional basketball association, the most similar entities in  #TAUTHOR_TAG are nba teams which are topically related, while the entities retrieved by our approach are all basketball leagues']",4
"['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG,']","['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG,']","['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG, all the entity embeddings are fixed during fine - tuning']","['not bert related parameters a larger initial learning rate to avoid the whole model biasing toward', 'the bert feature and disregarding other model components. in our experiments, pre - trained bert model is fine - tuned with initial learning rate 10 −5 whereas not bert related parameters are trained with 10 −3. similar learning rate usage can be found in the recent work by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG, all the entity embeddings are fixed during fine - tuning. we', 'randomly initialize the not bert related parameters using gaussian distribution n ( 0. 0, 0. 02 ) and the bias term is zeroed. note that all the hyper - parameters used in the local context and global model of  #TAUTHOR_TAG were', 'set to the same values as theirs for direct comparison purpose. detailed hyper - parameters', 'setting is described in the appendices. our model is trained with 4 nvidia tes', '##la p100 gpus. we run each of our model five times with different random seeds, and the performance is', 'reported in the form of average ± standard deviation. table 1 shows', 'the micro f1 scores on in - domain aida - b dataset of the sota methods and ours, which all use', 'wikipedia and yago mention - entity index. the models are divided into two groups : local models and local & global models. as we can see,', '']",3
"['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG,']","['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG,']","['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG, all the entity embeddings are fixed during fine - tuning']","['not bert related parameters a larger initial learning rate to avoid the whole model biasing toward', 'the bert feature and disregarding other model components. in our experiments, pre - trained bert model is fine - tuned with initial learning rate 10 −5 whereas not bert related parameters are trained with 10 −3. similar learning rate usage can be found in the recent work by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG, all the entity embeddings are fixed during fine - tuning. we', 'randomly initialize the not bert related parameters using gaussian distribution n ( 0. 0, 0. 02 ) and the bias term is zeroed. note that all the hyper - parameters used in the local context and global model of  #TAUTHOR_TAG were', 'set to the same values as theirs for direct comparison purpose. detailed hyper - parameters', 'setting is described in the appendices. our model is trained with 4 nvidia tes', '##la p100 gpus. we run each of our model five times with different random seeds, and the performance is', 'reported in the form of average ± standard deviation. table 1 shows', 'the micro f1 scores on in - domain aida - b dataset of the sota methods and ours, which all use', 'wikipedia and yago mention - entity index. the models are divided into two groups : local models and local & global models. as we can see,', '']",3
"['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG,']","['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG,']","['by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG, all the entity embeddings are fixed during fine - tuning']","['not bert related parameters a larger initial learning rate to avoid the whole model biasing toward', 'the bert feature and disregarding other model components. in our experiments, pre - trained bert model is fine - tuned with initial learning rate 10 −5 whereas not bert related parameters are trained with 10 −3. similar learning rate usage can be found in the recent work by ( hwang et al. 2019 ). similar to  #TAUTHOR_TAG, all the entity embeddings are fixed during fine - tuning. we', 'randomly initialize the not bert related parameters using gaussian distribution n ( 0. 0, 0. 02 ) and the bias term is zeroed. note that all the hyper - parameters used in the local context and global model of  #TAUTHOR_TAG were', 'set to the same values as theirs for direct comparison purpose. detailed hyper - parameters', 'setting is described in the appendices. our model is trained with 4 nvidia tes', '##la p100 gpus. we run each of our model five times with different random seeds, and the performance is', 'reported in the form of average ± standard deviation. table 1 shows', 'the micro f1 scores on in - domain aida - b dataset of the sota methods and ours, which all use', 'wikipedia and yago mention - entity index. the models are divided into two groups : local models and local & global models. as we can see,', '']",6
"['linking', 'model featuring better efficiency and effectiveness than that of  #TAUTHOR_TAG by breaking the']","['2019 ). dca is a global entity linking', 'model featuring better efficiency and effectiveness than that of  #TAUTHOR_TAG by breaking the']","['linking', 'model featuring better efficiency and effectiveness than that of  #TAUTHOR_TAG by breaking the']","['', 'proposed dynamic context augmentation ( dca ) 15 ( yang et al. 2019 ). dca is a global entity linking', 'model featuring better efficiency and effectiveness than that of  #TAUTHOR_TAG by breaking the "" all - mention', 'coherence "" assumption. compared to bert - entity - sim equipped with  #TAUTHOR_TAG. we found that  #AUTHOR_TAG includes an explicit type similarity which is', 'based on a typing system 16 trained with aida - train ner annotation. this explicit type similarity feature is tailored', ""for aida - conll data set and doesn't achieve good generalization performance on out - domain test sets. in contrast, our bert - entity - sim model capturing latent type information has potential better generalization performance with an average 2. 10 f1 improvement over them""]",6
"['by nrc canada 2013  #TAUTHOR_TAG, with some modifications']","['by nrc canada 2013  #TAUTHOR_TAG, with some modifications']","['by nrc canada 2013  #TAUTHOR_TAG, with some modifications']","['describe a classifier to predict the message - level sentiment of english microblog messages from twitter.', 'this paper describes the classifier submitted to the semeval - 2014 competition ( task 9b ).', ""our approach was to build up on the system of the last year's winning approach by nrc canada 2013  #TAUTHOR_TAG, with some modifications and additions of features, and additional sentiment lexicons."", 'furthermore, we used a sparse ( 1 - regularized ) svm, instead of the more commonly used 2 - regularization, resulting in a very sparse linear classifier']",6
"['canada 2013 approach  #TAUTHOR_TAG, our main changes']","['canada 2013 approach  #TAUTHOR_TAG, our main changes']","['canada 2013 approach  #TAUTHOR_TAG, our main changes']","['', '##c canada 2013 approach  #TAUTHOR_TAG, our main changes are the following three : first we use sparse linear classifiers instead of classical dense ones.', 'secondly, we drop n - gram features completely, in favor of what we call part - of - speech n - grams, which are n - grams where up to two tokens are the original ones, and the rest of the tokens is replaced by their corresponding pos tag', '( noun', ', verb, punctuation etc ). third, we added two new sentiment lexicons,', 'containing numerical scores associated for all 3 classes ( positive, neutral, negative ), instead of just 2 as in classical po - larity lexicons', '. all changes are described in more detail in sections 4 and 3 below. performance. we tried to reproduce the same classifier as in', ' #TAUTHOR_TAG as a baseline for comparison. trying to quantify our contributions, when adding all our additional features and tricks described below, the score of our method increases from the baseline of 63. 25 to 64. 81 ( on the twitter - 2013 test set ), which is a gain of 1. 56 points in f1. baseline approach by nrc canada 2013. unfortunately our replica system of  #TAUTHOR_TAG only achieved an f1 - score of 63. 25 on the twitter - 2013', 'test set, while their score in the 2013 competition on the same test set was 69. 02, nearly 6 points higher in f1. part of this', ""big difference might be explained by the fact that the exact same training sets are not available anymore. other possibly more important differences are the svm classifier variant used and class weighting ( described in section 4 ). furthermore, we didn't implement all features in the exactly same way, see the more detailed description in section"", '3. 1. 2 below. although we had the impression that these changes individually had only a relatively minor effect, it might be that the changes together with the different training set add up to the difference', 'in score']",6
"['( unsupervised ) as for example tweets with a positive or negative smiley.', 'we used the same set of lexicons as in  #TAUTHOR_TAG, with one addition']","['( unsupervised ) as for example tweets with a positive or negative smiley.', 'we used the same set of lexicons as in  #TAUTHOR_TAG, with one addition']","['( unsupervised ) as for example tweets with a positive or negative smiley.', 'we used the same set of lexicons as in  #TAUTHOR_TAG, with one addition']","['sentiment lexicon is a mapping from words ( or n - grams ) to an association score corresponding to positive or negative sentiment.', 'such lists can be constructed either from manually labeled data ( supervised ), or automatically labeled data ( unsupervised ) as for example tweets with a positive or negative smiley.', 'we used the same set of lexicons as in  #TAUTHOR_TAG, with one addition']",6
"['nrc canada  #TAUTHOR_TAG, with several modifications and extensions ( e. g. sparse linear classifiers']","['nrc canada  #TAUTHOR_TAG, with several modifications and extensions ( e. g. sparse linear classifiers']","['nrc canada  #TAUTHOR_TAG, with several modifications and extensions ( e. g. sparse linear classifiers']","['have described an svm classifier to detect the sentiment of short texts such as tweets.', 'our system is built up on the approach of nrc canada  #TAUTHOR_TAG, with several modifications and extensions ( e. g. sparse linear classifiers']",6
"['by nrc canada 2013  #TAUTHOR_TAG, with some modifications']","['by nrc canada 2013  #TAUTHOR_TAG, with some modifications']","['by nrc canada 2013  #TAUTHOR_TAG, with some modifications']","['describe a classifier to predict the message - level sentiment of english microblog messages from twitter.', 'this paper describes the classifier submitted to the semeval - 2014 competition ( task 9b ).', ""our approach was to build up on the system of the last year's winning approach by nrc canada 2013  #TAUTHOR_TAG, with some modifications and additions of features, and additional sentiment lexicons."", 'furthermore, we used a sparse ( 1 - regularized ) svm, instead of the more commonly used 2 - regularization, resulting in a very sparse linear classifier']",5
"['canada 2013 approach  #TAUTHOR_TAG, our main changes']","['canada 2013 approach  #TAUTHOR_TAG, our main changes']","['canada 2013 approach  #TAUTHOR_TAG, our main changes']","['', '##c canada 2013 approach  #TAUTHOR_TAG, our main changes are the following three : first we use sparse linear classifiers instead of classical dense ones.', 'secondly, we drop n - gram features completely, in favor of what we call part - of - speech n - grams, which are n - grams where up to two tokens are the original ones, and the rest of the tokens is replaced by their corresponding pos tag', '( noun', ', verb, punctuation etc ). third, we added two new sentiment lexicons,', 'containing numerical scores associated for all 3 classes ( positive, neutral, negative ), instead of just 2 as in classical po - larity lexicons', '. all changes are described in more detail in sections 4 and 3 below. performance. we tried to reproduce the same classifier as in', ' #TAUTHOR_TAG as a baseline for comparison. trying to quantify our contributions, when adding all our additional features and tricks described below, the score of our method increases from the baseline of 63. 25 to 64. 81 ( on the twitter - 2013 test set ), which is a gain of 1. 56 points in f1. baseline approach by nrc canada 2013. unfortunately our replica system of  #TAUTHOR_TAG only achieved an f1 - score of 63. 25 on the twitter - 2013', 'test set, while their score in the 2013 competition on the same test set was 69. 02, nearly 6 points higher in f1. part of this', ""big difference might be explained by the fact that the exact same training sets are not available anymore. other possibly more important differences are the svm classifier variant used and class weighting ( described in section 4 ). furthermore, we didn't implement all features in the exactly same way, see the more detailed description in section"", '3. 1. 2 below. although we had the impression that these changes individually had only a relatively minor effect, it might be that the changes together with the different training set add up to the difference', 'in score']",5
"['to lowercase ( except for those features in  #TAUTHOR_TAG which use case information ).', 'as usual, urls']","['to lowercase ( except for those features in  #TAUTHOR_TAG which use case information ).', 'as usual, urls']","['preprocessing.', 'a good tokenization seems very important for twitter data.', 'we used the popular tokenizer arktweetnlp  #AUTHOR_TAG which is suitable for tweets.', 'all text was transformed to lowercase ( except for those features in  #TAUTHOR_TAG which use case information ).', 'as usual, urls']","['preprocessing.', 'a good tokenization seems very important for twitter data.', 'we used the popular tokenizer arktweetnlp  #AUTHOR_TAG which is suitable for tweets.', 'all text was transformed to lowercase ( except for those features in  #TAUTHOR_TAG which use case information ).', 'as usual, urls were normalized to http : / / someurl and twitter user ids to @ someuser.', ""we also employed the usual marking of negated contexts of a sentence as in  #AUTHOR_TAG, using the list of negation words from christopher potts'sentiment tutorial 1""]",5
"['( unsupervised ) as for example tweets with a positive or negative smiley.', 'we used the same set of lexicons as in  #TAUTHOR_TAG, with one addition']","['( unsupervised ) as for example tweets with a positive or negative smiley.', 'we used the same set of lexicons as in  #TAUTHOR_TAG, with one addition']","['( unsupervised ) as for example tweets with a positive or negative smiley.', 'we used the same set of lexicons as in  #TAUTHOR_TAG, with one addition']","['sentiment lexicon is a mapping from words ( or n - grams ) to an association score corresponding to positive or negative sentiment.', 'such lists can be constructed either from manually labeled data ( supervised ), or automatically labeled data ( unsupervised ) as for example tweets with a positive or negative smiley.', 'we used the same set of lexicons as in  #TAUTHOR_TAG, with one addition']",5
"['3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion']","['3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion']","['##s from manually labeled data.', 'we used the same 3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion lexicon (']","['##s from manually labeled data.', 'we used the same 3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion lexicon ( about 14k words ), the mpqa lexicon ( about 8k words ), and the bing liu lexicon ( about 7k words ).', 'lexicons from automatically labeled data.', 'the nrc hashtag sentiment lexicon was generated automatically from a set of 775k tweets containing a hashtag of a small predefined list of positive and negative hashtags  #TAUTHOR_TAG.', 'lexicon scores were trained via pmi ( point - wise mutual information ).', 'scores are not only available for words, but also unigramunigram, unigram - bigram, and bigram - bigram pairs ( that can be non - contiguous in the text ).', 'the sentiment140 lexicon  #AUTHOR_TAG was generated automatically from a set of 1. 6 million tweets containing a positive or negative emoticon.', 'this uses the same features and scoring as above']",5
"['3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion']","['3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion']","['##s from manually labeled data.', 'we used the same 3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion lexicon (']","['##s from manually labeled data.', 'we used the same 3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion lexicon ( about 14k words ), the mpqa lexicon ( about 8k words ), and the bing liu lexicon ( about 7k words ).', 'lexicons from automatically labeled data.', 'the nrc hashtag sentiment lexicon was generated automatically from a set of 775k tweets containing a hashtag of a small predefined list of positive and negative hashtags  #TAUTHOR_TAG.', 'lexicon scores were trained via pmi ( point - wise mutual information ).', 'scores are not only available for words, but also unigramunigram, unigram - bigram, and bigram - bigram pairs ( that can be non - contiguous in the text ).', 'the sentiment140 lexicon  #AUTHOR_TAG was generated automatically from a set of 1. 6 million tweets containing a positive or negative emoticon.', 'this uses the same features and scoring as above']",5
"['nrc canada  #TAUTHOR_TAG, with several modifications and extensions ( e. g. sparse linear classifiers']","['nrc canada  #TAUTHOR_TAG, with several modifications and extensions ( e. g. sparse linear classifiers']","['nrc canada  #TAUTHOR_TAG, with several modifications and extensions ( e. g. sparse linear classifiers']","['have described an svm classifier to detect the sentiment of short texts such as tweets.', 'our system is built up on the approach of nrc canada  #TAUTHOR_TAG, with several modifications and extensions ( e. g. sparse linear classifiers']",5
"['canada 2013 approach  #TAUTHOR_TAG, our main changes']","['canada 2013 approach  #TAUTHOR_TAG, our main changes']","['canada 2013 approach  #TAUTHOR_TAG, our main changes']","['', '##c canada 2013 approach  #TAUTHOR_TAG, our main changes are the following three : first we use sparse linear classifiers instead of classical dense ones.', 'secondly, we drop n - gram features completely, in favor of what we call part - of - speech n - grams, which are n - grams where up to two tokens are the original ones, and the rest of the tokens is replaced by their corresponding pos tag', '( noun', ', verb, punctuation etc ). third, we added two new sentiment lexicons,', 'containing numerical scores associated for all 3 classes ( positive, neutral, negative ), instead of just 2 as in classical po - larity lexicons', '. all changes are described in more detail in sections 4 and 3 below. performance. we tried to reproduce the same classifier as in', ' #TAUTHOR_TAG as a baseline for comparison. trying to quantify our contributions, when adding all our additional features and tricks described below, the score of our method increases from the baseline of 63. 25 to 64. 81 ( on the twitter - 2013 test set ), which is a gain of 1. 56 points in f1. baseline approach by nrc canada 2013. unfortunately our replica system of  #TAUTHOR_TAG only achieved an f1 - score of 63. 25 on the twitter - 2013', 'test set, while their score in the 2013 competition on the same test set was 69. 02, nearly 6 points higher in f1. part of this', ""big difference might be explained by the fact that the exact same training sets are not available anymore. other possibly more important differences are the svm classifier variant used and class weighting ( described in section 4 ). furthermore, we didn't implement all features in the exactly same way, see the more detailed description in section"", '3. 1. 2 below. although we had the impression that these changes individually had only a relatively minor effect, it might be that the changes together with the different training set add up to the difference', 'in score']",4
"['1 above ) from all texts.', 'in comparison,  #TAUTHOR_TAG used noncont']","['3. 1. 1 above ) from all texts.', 'in comparison,  #TAUTHOR_TAG used noncontiguous n - grams ( unigram - unigram, unigrambigram,']","['the pos n - grams ( as we described in section 3. 1. 1 above ) from all texts.', 'in comparison,  #TAUTHOR_TAG used noncont']","['main new addition was another type of lexicon, which not only provides one score per word, but 3 of them, ( being the association to positive, negative and neutral ).', 'the idea here is to improve on the discrimination quality, especially for neutral text, and treat all 3 labels in this multi - class task the same way, instead of just 2 as in the previous approaches.', 'data.', 'we found it challenging to find good datasets to build such a lexicon.', 'we again used the sentiment140 corpus  #AUTHOR_TAG ( containing tweets with positive or negative emoticons ).', 'using a subset of 100k positive and 100k negative ones, we added a set of 100k arbitrary ( hopefully neutral ) tweets.', 'the neutral set was chosen randomly from the thinknook. com dataset 3 of 1. 5mio tweets ( from which we ignored the provided labels, and counted the tweets as neutral ).', 'we did the same with the movie reviews from the recent kaggle competition on annotated reviews from the rotten - tomatoes website 4.', 'we automatically built a lexicon from 100k texts in this dataset, with the data balanced equally for the three classes.', 'features used in the lexicon.', 'to construct the lexicon, we extracted the pos n - grams ( as we described in section 3. 1. 1 above ) from all texts.', 'in comparison,  #TAUTHOR_TAG used noncontiguous n - grams ( unigram - unigram, unigrambigram, and bigram - bigram pairs ).', 'we only used pos n - grams with 2 tokens kept original, and the remaining ones replaced by their pos tag, with n ranging from 3 to 6.', 'building the lexicon.', 'while in  #TAUTHOR_TAG, the score for each n - gram was computed using point - wise mutual information ( pmi ) with the labels, we trained a linear classifier on the same labels instead.', 'the lexicon weights are set as the resulting classifier weights for our ( pos ) n - grams.', 'we used the same type of sparse svm trained with liblinear, for 3 classes, as in the final classifier.', 'download of the lexicons.', 'we built 4 lexicons as described above.', 'thanks to the sparsity of the linear weights from the svm, they are again relatively small, analogous to the final classifier.', 'we also provide the lexicons for download as text files 5']",4
"['1 above ) from all texts.', 'in comparison,  #TAUTHOR_TAG used noncont']","['3. 1. 1 above ) from all texts.', 'in comparison,  #TAUTHOR_TAG used noncontiguous n - grams ( unigram - unigram, unigrambigram,']","['the pos n - grams ( as we described in section 3. 1. 1 above ) from all texts.', 'in comparison,  #TAUTHOR_TAG used noncont']","['main new addition was another type of lexicon, which not only provides one score per word, but 3 of them, ( being the association to positive, negative and neutral ).', 'the idea here is to improve on the discrimination quality, especially for neutral text, and treat all 3 labels in this multi - class task the same way, instead of just 2 as in the previous approaches.', 'data.', 'we found it challenging to find good datasets to build such a lexicon.', 'we again used the sentiment140 corpus  #AUTHOR_TAG ( containing tweets with positive or negative emoticons ).', 'using a subset of 100k positive and 100k negative ones, we added a set of 100k arbitrary ( hopefully neutral ) tweets.', 'the neutral set was chosen randomly from the thinknook. com dataset 3 of 1. 5mio tweets ( from which we ignored the provided labels, and counted the tweets as neutral ).', 'we did the same with the movie reviews from the recent kaggle competition on annotated reviews from the rotten - tomatoes website 4.', 'we automatically built a lexicon from 100k texts in this dataset, with the data balanced equally for the three classes.', 'features used in the lexicon.', 'to construct the lexicon, we extracted the pos n - grams ( as we described in section 3. 1. 1 above ) from all texts.', 'in comparison,  #TAUTHOR_TAG used noncontiguous n - grams ( unigram - unigram, unigrambigram, and bigram - bigram pairs ).', 'we only used pos n - grams with 2 tokens kept original, and the remaining ones replaced by their pos tag, with n ranging from 3 to 6.', 'building the lexicon.', 'while in  #TAUTHOR_TAG, the score for each n - gram was computed using point - wise mutual information ( pmi ) with the labels, we trained a linear classifier on the same labels instead.', 'the lexicon weights are set as the resulting classifier weights for our ( pos ) n - grams.', 'we used the same type of sparse svm trained with liblinear, for 3 classes, as in the final classifier.', 'download of the lexicons.', 'we built 4 lexicons as described above.', 'thanks to the sparsity of the linear weights from the svm, they are again relatively small, analogous to the final classifier.', 'we also provide the lexicons for download as text files 5']",4
"['as in  #TAUTHOR_TAG,']","['as in  #TAUTHOR_TAG, i. e. per tweet,']","['as in  #TAUTHOR_TAG,']","['', '• instead of the score itself, we used the sigmoid value s ( t ) = 1 / ( 1 + e −t ) ) of each lexicon score.', 'for each lexicon, the 4 scores were the same as in  #TAUTHOR_TAG, i. e. per tweet, we use the number of tokens appearing in the lexicon, the sum and the max of the scores, and the last non - zero score.', 'we skipped some features from the baseline approach ( because their effect was not significant in our setting ) : elongated words ( number of words with one character repeated more than two times ), and word clustering.', 'also, we had a slightly simplified variant of how to use the lexicon scores.', ""we didn't count the lexicon scores separately per emotion ( pos and neg ), but only altogether""]",3
"['3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion']","['3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion']","['##s from manually labeled data.', 'we used the same 3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion lexicon (']","['##s from manually labeled data.', 'we used the same 3 existing sentiment lexicons as in  #TAUTHOR_TAG.', 'all lexicons give a single score for each word ( if present in the lexicon ).', 'those existing lexicons are : nrc emotion lexicon ( about 14k words ), the mpqa lexicon ( about 8k words ), and the bing liu lexicon ( about 7k words ).', 'lexicons from automatically labeled data.', 'the nrc hashtag sentiment lexicon was generated automatically from a set of 775k tweets containing a hashtag of a small predefined list of positive and negative hashtags  #TAUTHOR_TAG.', 'lexicon scores were trained via pmi ( point - wise mutual information ).', 'scores are not only available for words, but also unigramunigram, unigram - bigram, and bigram - bigram pairs ( that can be non - contiguous in the text ).', 'the sentiment140 lexicon  #AUTHOR_TAG was generated automatically from a set of 1. 6 million tweets containing a positive or negative emoticon.', 'this uses the same features and scoring as above']",3
"['15,  #TAUTHOR_TAG.', 'although']","['by the recent successes of the attention mechanism in other domains [ 15,  #TAUTHOR_TAG.', 'although']","['15,  #TAUTHOR_TAG.', 'although some works focused on understanding the influence of image parts on its popularity [ 6, 1 ], our method addresses videos, not images, and exploits the temporal characteristics of video clips through the attention mechanism.', 'by extending the baseline popularity prediction method with the attention mechanism,']","['', 'we use those weights to scale the magnitudes of grad - cam [ 9 ] heatmaps when visualizing the importance of video elements on the popularity score.', 'the bottom row shows the frame with the highest attention weight ( left ) with its popularity importance visualization ( right ).', 'for the headline text darker color corresponds to higher importance.', 'in this paper, we outline a fundamentally different approach to online video popularity analysis that allows social media creators both to predict video popularity as well as to understand the impact of its headline or video frames on the future popularity.', 'to that end, we propose to use an attention - based model and gradient - weighted class activation maps [ 9 ], inspired by the recent successes of the attention mechanism in other domains [ 15,  #TAUTHOR_TAG.', 'although some works focused on understanding the influence of image parts on its popularity [ 6, 1 ], our method addresses videos, not images, and exploits the temporal characteristics of video clips through the attention mechanism.', 'by extending the baseline popularity prediction method with the attention mechanism, we enable more intuitive visualization of the impact visual and textual features of the video have on its final popularity, while achieving state - of - the - art results on the popularity prediction task']",5
[' #TAUTHOR_TAG :'],['with attention mechanism implemented as a two - layer neural network  #TAUTHOR_TAG :'],"['video embedding is a weighted average of', 'these embed - weights α i are computed with attention mechanism implemented as a two - layer neural network  #TAUTHOR_TAG : the first']","['. for each frame feature vector we apply a learnable linear transformation followed by relu, obtaining a sequence of frame', 'embeddings ( q j ) n j = 1. the final video embedding is a weighted average of', 'these embed - weights α i are computed with attention mechanism implemented as a two - layer neural network  #TAUTHOR_TAG : the first layer produces a hidden representation', 'u i = tanh ( w u q i + b u ) and the second layer outputs unnormalized importance a i = w a u i + b a. w a', 'can be interpreted', 'as a trainable high level representation of the most informative vector in u i space. final', 'weights are normalized with softmax : headline. we represent a headline as a sequence of pre - trained glove [ 7 ] word vectors ( w t ) n t = 1. we handle sequences of variable length', 'using a bidirectional lstm. similarly to video frames, we use a two - layer attention mechanism on hidden state vectors h t to let the network learn the importance', '']",5
[' #TAUTHOR_TAG :'],['with attention mechanism implemented as a two - layer neural network  #TAUTHOR_TAG :'],"['video embedding is a weighted average of', 'these embed - weights α i are computed with attention mechanism implemented as a two - layer neural network  #TAUTHOR_TAG : the first']","['. for each frame feature vector we apply a learnable linear transformation followed by relu, obtaining a sequence of frame', 'embeddings ( q j ) n j = 1. the final video embedding is a weighted average of', 'these embed - weights α i are computed with attention mechanism implemented as a two - layer neural network  #TAUTHOR_TAG : the first layer produces a hidden representation', 'u i = tanh ( w u q i + b u ) and the second layer outputs unnormalized importance a i = w a u i + b a. w a', 'can be interpreted', 'as a trainable high level representation of the most informative vector in u i space. final', 'weights are normalized with softmax : headline. we represent a headline as a sequence of pre - trained glove [ 7 ] word vectors ( w t ) n t = 1. we handle sequences of variable length', 'using a bidirectional lstm. similarly to video frames, we use a two - layer attention mechanism on hidden state vectors h t to let the network learn the importance', '']",5
[' #TAUTHOR_TAG :'],['with attention mechanism implemented as a two - layer neural network  #TAUTHOR_TAG :'],"['video embedding is a weighted average of', 'these embed - weights α i are computed with attention mechanism implemented as a two - layer neural network  #TAUTHOR_TAG : the first']","['. for each frame feature vector we apply a learnable linear transformation followed by relu, obtaining a sequence of frame', 'embeddings ( q j ) n j = 1. the final video embedding is a weighted average of', 'these embed - weights α i are computed with attention mechanism implemented as a two - layer neural network  #TAUTHOR_TAG : the first layer produces a hidden representation', 'u i = tanh ( w u q i + b u ) and the second layer outputs unnormalized importance a i = w a u i + b a. w a', 'can be interpreted', 'as a trainable high level representation of the most informative vector in u i space. final', 'weights are normalized with softmax : headline. we represent a headline as a sequence of pre - trained glove [ 7 ] word vectors ( w t ) n t = 1. we handle sequences of variable length', 'using a bidirectional lstm. similarly to video frames, we use a two - layer attention mechanism on hidden state vectors h t to let the network learn the importance', '']",0
"[' #TAUTHOR_TAG, which includes models for both orthography and pronunciation.', 'the pronunciation variation modeling is shown to improve performance for misspellings produced by japanese writers of english']","[' #TAUTHOR_TAG, which includes models for both orthography and pronunciation.', 'the pronunciation variation modeling is shown to improve performance for misspellings produced by japanese writers of english']","[' #TAUTHOR_TAG, which includes models for both orthography and pronunciation.', 'the pronunciation variation modeling is shown to improve performance for misspellings produced by japanese writers of english']","['propose a method for modeling pronunciation variation in the context of spell checking for non - native writers of english.', 'spell checkers, typically developed for native speakers, fail to address many of the types of spelling errors peculiar to non - native speakers, especially those errors influenced by differences in phonology.', 'our model of pronunciation variation is used to extend a pronouncing dictionary for use in the spelling correction algorithm developed by  #TAUTHOR_TAG, which includes models for both orthography and pronunciation.', 'the pronunciation variation modeling is shown to improve performance for misspellings produced by japanese writers of english']",6
"[' #TAUTHOR_TAG, which includes models for both orthography and pronunciation.', 'the pronunciation variation modeling is shown to improve performance for misspellings produced by japanese writers of english']","[' #TAUTHOR_TAG, which includes models for both orthography and pronunciation.', 'the pronunciation variation modeling is shown to improve performance for misspellings produced by japanese writers of english']","[' #TAUTHOR_TAG, which includes models for both orthography and pronunciation.', 'the pronunciation variation modeling is shown to improve performance for misspellings produced by japanese writers of english']","['propose a method for modeling pronunciation variation in the context of spell checking for non - native writers of english.', 'spell checkers, typically developed for native speakers, fail to address many of the types of spelling errors peculiar to non - native speakers, especially those errors influenced by differences in phonology.', 'our model of pronunciation variation is used to extend a pronouncing dictionary for use in the spelling correction algorithm developed by  #TAUTHOR_TAG, which includes models for both orthography and pronunciation.', 'the pronunciation variation modeling is shown to improve performance for misspellings produced by japanese writers of english']",1
"['by  #TAUTHOR_TAG, which uses statistical models of spe']","['by  #TAUTHOR_TAG, which uses statistical models of spelling errors that consider both orthography and pronunciation.', 'several conventions are used throughout this paper : a word is a sequence of characters from the given alphabet found in']","['by  #TAUTHOR_TAG, which uses statistical models of spe']","['', ' #AUTHOR_TAG identifies two main sources of errors for jwefl : differences between english and japanese phonology and differences between the english alphabet and the japanese romazi writing system, which uses a subset of english letters.', 'phonological differences result in number of distinctions in english that are not present in japanese and romazi causes difficulties for jwefl because the latin letters correspond to very different sounds in japanese.', 'we propose a method for creating a model of pronunciation variation from a phonetically untranscribed corpus of read speech recorded by nonnative speakers.', 'the pronunciation variation model is used to generate multiple pronunciations for each canonical pronunciation in a pronouncing dictionary and these variations are used in the spelling correction approach developed by  #TAUTHOR_TAG, which uses statistical models of spelling errors that consider both orthography and pronunciation.', 'several conventions are used throughout this paper : a word is a sequence of characters from the given alphabet found in the word list.', 'a word list is a list of words.', 'a misspelling, marked with *, is a sequence of characters not found in the word list.', 'a candidate correction is a word from the word list proposed as a potential correction']",1
"['by  #TAUTHOR_TAG, which uses statistical models of spe']","['by  #TAUTHOR_TAG, which uses statistical models of spelling errors that consider both orthography and pronunciation.', 'several conventions are used throughout this paper : a word is a sequence of characters from the given alphabet found in']","['by  #TAUTHOR_TAG, which uses statistical models of spe']","['', ' #AUTHOR_TAG identifies two main sources of errors for jwefl : differences between english and japanese phonology and differences between the english alphabet and the japanese romazi writing system, which uses a subset of english letters.', 'phonological differences result in number of distinctions in english that are not present in japanese and romazi causes difficulties for jwefl because the latin letters correspond to very different sounds in japanese.', 'we propose a method for creating a model of pronunciation variation from a phonetically untranscribed corpus of read speech recorded by nonnative speakers.', 'the pronunciation variation model is used to generate multiple pronunciations for each canonical pronunciation in a pronouncing dictionary and these variations are used in the spelling correction approach developed by  #TAUTHOR_TAG, which uses statistical models of spelling errors that consider both orthography and pronunciation.', 'several conventions are used throughout this paper : a word is a sequence of characters from the given alphabet found in the word list.', 'a word list is a list of words.', 'a misspelling, marked with *, is a sequence of characters not found in the word list.', 'a candidate correction is a word from the word list proposed as a potential correction']",0
"['##ing errors.', ' #TAUTHOR_TAG extend  #AUTHOR_TAG to consider edits over both letter sequences and sequences of phones in']","['edit from a corpus of spelling errors.', ' #TAUTHOR_TAG extend  #AUTHOR_TAG to consider edits over both letter sequences and sequences of phones in']","['##ing errors.', ' #TAUTHOR_TAG extend  #AUTHOR_TAG to consider edits over both letter sequences and sequences of phones in the pronunciations of the word and misspelling.', 'they show that including pronunciation information improves']","['recent spelling correction approaches, edit operations have been extended beyond single character edits and the methods for calculating edit operation weights have become more sophisticated.', 'the spelling error model proposed by  #AUTHOR_TAG allows generic string edit operations up to a certain length.', 'each edit operation also has an associated probability that improves the ranking of candidate corrections by modeling how likely particular edits are.', ' #AUTHOR_TAG estimate the probability of each edit from a corpus of spelling errors.', ' #TAUTHOR_TAG extend  #AUTHOR_TAG to consider edits over both letter sequences and sequences of phones in the pronunciations of the word and misspelling.', 'they show that including pronunciation information improves performance as compared to  #AUTHOR_TAG']",0
['##ing correction models from  #AUTHOR_TAG and  #TAUTHOR_TAG use the noisy channel model approach to determine the types'],['spelling correction models from  #AUTHOR_TAG and  #TAUTHOR_TAG use the noisy channel model approach to determine the types'],['spelling correction models from  #AUTHOR_TAG and  #TAUTHOR_TAG use the noisy channel model approach to determine the types'],"['spelling correction models from  #AUTHOR_TAG and  #TAUTHOR_TAG use the noisy channel model approach to determine the types and weights of edit operations.', 'the idea behind this approach is that a writer starts out with the intended word w in mind, but as it is being written the word passes through a noisy channel resulting in the observed non - word r. in order to determine how likely a candidate correction is, the spelling correction model determines the probability that the word w was the intended word given the misspelling r : p ( w | r ).', '']",0
['describe an extension to  #AUTHOR_TAG where'],['describe an extension to  #AUTHOR_TAG where'],['describe an extension to  #AUTHOR_TAG where the same noisy channel error model is used'],"['describe an extension to  #AUTHOR_TAG where the same noisy channel error model is used to model phone sequences instead of letter sequences.', 'instead of the word w and the non - word r, the error model considers the pronunciation of the non - word r, pron r, and the pronunciation of the word w, pron w.', 'the error model over phone sequences, called p p h, is just like p l shown in figure 1 except that r and w are replaced with their pronunciations.', 'the model is trained like p l using alignments between phones.', 'since a spelling correction model needs to rank candidate words rather than candidate pronunciations,  #TAUTHOR_TAG derive an error model that determines the probability that a word w was spelled as the non - word r based on their pronunciations.', 'their approximation of this model, called p p hl, is also shown in figure 1.', 'p p h ( pron w | pron r ) is the phone error model described above and p ( pron r | r ) is provided by the letter - to - phone model described below']",0
['describe an extension to  #AUTHOR_TAG where'],['describe an extension to  #AUTHOR_TAG where'],['describe an extension to  #AUTHOR_TAG where the same noisy channel error model is used'],"['describe an extension to  #AUTHOR_TAG where the same noisy channel error model is used to model phone sequences instead of letter sequences.', 'instead of the word w and the non - word r, the error model considers the pronunciation of the non - word r, pron r, and the pronunciation of the word w, pron w.', 'the error model over phone sequences, called p p h, is just like p l shown in figure 1 except that r and w are replaced with their pronunciations.', 'the model is trained like p l using alignments between phones.', 'since a spelling correction model needs to rank candidate words rather than candidate pronunciations,  #TAUTHOR_TAG derive an error model that determines the probability that a word w was spelled as the non - word r based on their pronunciations.', 'their approximation of this model, called p p hl, is also shown in figure 1.', 'p p h ( pron w | pron r ) is the phone error model described above and p ( pron r | r ) is provided by the letter - to - phone model described below']",0
"['section presents our method for modeling pronunciation variation from a phonetically untranscribed corpus of read speech.', 'the pronunciationbased spelling correction approach developed in  #TAUTHOR_TAG requires a list of possible pronunciations in']","['section presents our method for modeling pronunciation variation from a phonetically untranscribed corpus of read speech.', 'the pronunciationbased spelling correction approach developed in  #TAUTHOR_TAG requires a list of possible pronunciations in']","['section presents our method for modeling pronunciation variation from a phonetically untranscribed corpus of read speech.', 'the pronunciationbased spelling correction approach developed in  #TAUTHOR_TAG requires a list of possible pronunciations in']","['section presents our method for modeling pronunciation variation from a phonetically untranscribed corpus of read speech.', 'the pronunciationbased spelling correction approach developed in  #TAUTHOR_TAG requires a list of possible pronunciations in order to compare the pronunciation of the misspelling to the pronunciation of correct words.', 'to account for target pronunciations specific to japanese speakers, we observe the pronunciation variation in the erj and generate additional pronunciations for each word in the word list.', 'since the erj is not transcribed, we begin by adapting a recognizer trained on native english speech.', 'first, the erj is recognized using a monophone recognizer trained on timit.', 'next, the most frequent variations between the canonical and recognized pronunciations are used to adapt the recognizer.', 'the adapted recognizer is then used to recognize the erj in forced alignment with the canonical pronunciations.', 'finally, the variations from the previous step are used to create models of pronunciation variation for each phone, which are used to generate multiple pronunciations for each word']",0
"['by  #AUTHOR_TAG and  #TAUTHOR_TAG appears well - suited for writers of english as a foreign language.', 'the letter and combined models']","['by  #AUTHOR_TAG and  #TAUTHOR_TAG appears well - suited for writers of english as a foreign language.', 'the letter and combined models']","['by  #AUTHOR_TAG and  #TAUTHOR_TAG appears well - suited for writers of english as a foreign language.', 'the letter and combined models']","['noisy channel spelling correction approach developed by  #AUTHOR_TAG and  #TAUTHOR_TAG appears well - suited for writers of english as a foreign language.', 'the letter and combined models outperform the traditional spell checker aspell by a wide margin.', 'although including pronunciation variation does not improve the combined model, it leads to significant improvements in the pronunciation - based model p p hl']",0
"['', 'like  #TAUTHOR_TAG, we use the n - gram ltp model from  #AUTHOR_TAG to predict these pronunciations']","['letter - to - phone ( ltp ) model is needed to predict the pronunciation of misspellings for p p hl, since they are not found in a pronouncing dictionary.', 'like  #TAUTHOR_TAG, we use the n - gram ltp model from  #AUTHOR_TAG to predict these pronunciations.', 'the n - gram']","['letter - to - phone ( ltp ) model is needed to predict the pronunciation of misspellings for p p hl, since they are not found in a pronouncing dictionary.', 'like  #TAUTHOR_TAG, we use the n - gram ltp model from  #AUTHOR_TAG to predict these pronunciations.', 'the n - gram ltp model predicts the pronunciation of each letter in']","['letter - to - phone ( ltp ) model is needed to predict the pronunciation of misspellings for p p hl, since they are not found in a pronouncing dictionary.', 'like  #TAUTHOR_TAG, we use the n - gram ltp model from  #AUTHOR_TAG to predict these pronunciations.', 'the n - gram ltp model predicts the pronunciation of each letter in a word considering up to four letters of context to the left and right.', 'the most specific context found for each letter and its context in the training data is used to predict the pronunciation of a word.', '']",5
"['section presents our method for modeling pronunciation variation from a phonetically untranscribed corpus of read speech.', 'the pronunciationbased spelling correction approach developed in  #TAUTHOR_TAG requires a list of possible pronunciations in']","['section presents our method for modeling pronunciation variation from a phonetically untranscribed corpus of read speech.', 'the pronunciationbased spelling correction approach developed in  #TAUTHOR_TAG requires a list of possible pronunciations in']","['section presents our method for modeling pronunciation variation from a phonetically untranscribed corpus of read speech.', 'the pronunciationbased spelling correction approach developed in  #TAUTHOR_TAG requires a list of possible pronunciations in']","['section presents our method for modeling pronunciation variation from a phonetically untranscribed corpus of read speech.', 'the pronunciationbased spelling correction approach developed in  #TAUTHOR_TAG requires a list of possible pronunciations in order to compare the pronunciation of the misspelling to the pronunciation of correct words.', 'to account for target pronunciations specific to japanese speakers, we observe the pronunciation variation in the erj and generate additional pronunciations for each word in the word list.', 'since the erj is not transcribed, we begin by adapting a recognizer trained on native english speech.', 'first, the erj is recognized using a monophone recognizer trained on timit.', 'next, the most frequent variations between the canonical and recognized pronunciations are used to adapt the recognizer.', 'the adapted recognizer is then used to recognize the erj in forced alignment with the canonical pronunciations.', 'finally, the variations from the previous step are used to create models of pronunciation variation for each phone, which are used to generate multiple pronunciations for each word']",5
"[""order to evaluate the effect of pronunciation variation in  #TAUTHOR_TAG's spelling correction approach, we compare the""]","[""order to evaluate the effect of pronunciation variation in  #TAUTHOR_TAG's spelling correction approach, we compare the""]","[""order to evaluate the effect of pronunciation variation in  #TAUTHOR_TAG's spelling correction approach, we compare the performance of the pronunciation model and the combined model with and without pronunciation variation."", 'we implemented the letter and pronunciation spelling correction models as described in section 2. 2.', 'the letter error model p l']","[""order to evaluate the effect of pronunciation variation in  #TAUTHOR_TAG's spelling correction approach, we compare the performance of the pronunciation model and the combined model with and without pronunciation variation."", 'we implemented the letter and pronunciation spelling correction models as described in section 2. 2.', 'the letter error model p l and the phone error model p p h are trained on the training set.', 'the development set is used to tune the parameters introduced in previous sections.', '7 in order to rank the words as candidate corrections for a misspelling r, p l ( r | w ) and p p hl ( r | w ) are calculated for each word in the word list using the algorithm described in  #AUTHOR_TAG.', 'finally, p l and p p hl are combined using s cm b to rank each word']",5
"[' #TAUTHOR_TAG, which combines orthography - based and pronunciation - based models.', 'although the extended pron']","[' #TAUTHOR_TAG, which combines orthography - based and pronunciation - based models.', 'although the extended pronunciation dictionary']","[' #TAUTHOR_TAG, which combines orthography - based and pronunciation - based models.', 'although the extended pronunciation dictionary does not lead to improvement in the combined model,']","['have presented a method for modeling pronunciation variation from a phonetically untranscribed corpus of read non - native speech by adapting a monophone recognizer initially trained on native speech.', 'this model allows a native pronouncing dictionary to be extended to include non - native pronunciation variations.', 'we incorporated a pronouncing dictionary extended for japanese writers of english into the spelling correction model developed by  #TAUTHOR_TAG, which combines orthography - based and pronunciation - based models.', 'although the extended pronunciation dictionary does not lead to improvement in the combined model, it does leads to significant improvement in the pronunciation - based model']",5
['project languages into the same shared semantics vectorspace and compute document semantic similarity  #TAUTHOR_TAG irrespective of the'],['project languages into the same shared semantics vectorspace and compute document semantic similarity  #TAUTHOR_TAG irrespective of the'],"['##ented streams of text have a number of novel applications.', 'the most straightforward novel application is the possibility to embed the documents of all project languages into the same shared semantics vectorspace and compute document semantic similarity  #TAUTHOR_TAG irrespective of']","['a shared vectorspace multilingual translation system ( fig. 2 and fig. 3 ) able to operate on unsegmented streams of text have a number of novel applications.', 'the most straightforward novel application is the possibility to embed the documents of all project languages into the same shared semantics vectorspace and compute document semantic similarity  #TAUTHOR_TAG irrespective of the document language.', 'the sliding - window translation approach allows to view the document as a sequence ( trace ) of vectors corresponding to every slidingwindow step while translating the document.', 'these vectors are similar to word embedding vectors, but are likely to be semantically richer, as they would mostly distinguish word - senses in the context of the window.', 'such vectortraces corresponding to the documents can be compared in the bag - of - words fashion by measuring cosine - distance between the sums of document trace - vectors ( as part of kmeans clustering or nearest - neighbor search ).', 'this can be used as a building block for multilingual semantic clustering of stories into storylines, or for the semantic search of the documents in any language which are similar to the given document.', 'another novel application of the character - level neural translation is stream segmentation into the individual stories - a difficult task for news ingested from audio or video sources and transcribed with asr and thus lacking any explicit sentence or story segmentation information.', 'for stream segmentation into the stories it is possible to utilize the exceptional generalization and memorization capacity of the neural networks, which is already applied in the neural dialogue systems such as gmail smart replies  #AUTHOR_TAG vinyals &  #AUTHOR_TAG.', 'table 3 illustrates how mere 400 lstm cells of our single - layer 90 - character neural translator have been able to generalize and memorize rather correct translations for the first 100 characters of the entire europarl v7 en - lv training corpus containing 600, 000 sentence pairs.', 'for story segmentation a sliding - window neural translation system can be incrementally trained to monolingually "" translate "" the current 5 words of the stream into the next 5 words of the stream ( predicting next 5 words from previous 5 words ), based on the actual news streams encountered.', 'such system should be able to predict reasonably well the next 5 words within the news story, but will fail to do so when there is a transition from one story to the next.', 'along with additional auxiliary information such as time - code ( when exactly the phrase was spoken and pauses in the speech ) and speaker identification for each phrase this should provide a rather reliable segmentation signal.', '']",0
['the semantically best clusters  #TAUTHOR_TAG and further experiments'],['the semantically best clusters  #TAUTHOR_TAG and further experiments'],['the semantically best clusters  #TAUTHOR_TAG and further experiments'],"['is still an open issue which vectorspace projections yield the semantically best clusters  #TAUTHOR_TAG and further experiments are needed.', 'particularly for storyline  #AUTHOR_TAG clustering the signals for the stories belonging to the same storyline might be not so much the semantic similarity of the articles ( they might report various developments of the storyline from differing viewpoints ), but rather the matching time and location as well as same organizations and people being involved - the information typically supplied by named entity linking ( nel ) tools.', 'the tradeoffs between semantic clustering quality and computational complexity are likely to be crucial.', 'once trained, the run - time use of the multilingual translation modules for translation and news story clustering is around 1 sec on titanx gpu per average news story.', 'this is an order of magnitude slower than regular nel or if idf bagof - words based clustering methods.', 'establishing reliable storyline clustering benchmarking data sets and metrics is one of the goals of the summa project, as good storyline clusters are the prerequisite for downstream storyline summarization, visualization, and predictive anticipation of upcoming developments']",2
"['attention  #TAUTHOR_TAG, to the best of our knowledge this is the first']","['attention  #TAUTHOR_TAG, to the best of our knowledge this is the first']","['-  #AUTHOR_TAG.', 'although the prediction of evocation ratings has attracted some attention  #TAUTHOR_TAG, to the best of our knowledge this is the first work to focus on the prediction of us']","['', 'this is backed up by  #AUTHOR_TAG b ) which found word associations performed better than word embeddings across a variety of semantic relatedness tasks.', 'furthermore, word associations, unlike cosine similarities, are asymmetric ; when presented with the word "" beer "", many people think of the word "" glass "" but when presented with the word "" glass "", few people think of the word "" beer ""  #AUTHOR_TAG.', 'this directionality allows for more fine - grained exploration of semantic links, with applications in word similarity  #AUTHOR_TAG and computational humour  #AUTHOR_TAG.', 'although several word association datasets exist, such as the edinburgh associative thesaurus ( eat,  #AUTHOR_TAG, the university of south florida free association norms ( usf,  #AUTHOR_TAG, or wordnet evocation ( evocation, boyd -  #AUTHOR_TAG their reliance on human annotations mean they all suffer from coverage issues relating to limited vocabularies or sparse connectivity  #AUTHOR_TAG b ).', 'although these issues would be somewhat alleviated by the creation of larger datasets, collecting human judgments for all possible word pairs is impractical.', 'therefore, the ability to predict association strengths between arbitrary word pairs represents the best solution to these coverage issues ( boyd -  #AUTHOR_TAG.', 'although the prediction of evocation ratings has attracted some attention  #TAUTHOR_TAG, to the best of our knowledge this is the first work to focus on the prediction of usf or eat strengths.', 'as described in sec - tion 2, usf and eat have several advantages over evocation, such as the ability to work with ambiguous words instead of wordnet synsets.', 'following  #TAUTHOR_TAG on evocation prediction, we frame word']",0
"['those useful for computational humour', ' #AUTHOR_TAG. to this end,  #TAUTHOR_TAG']","['those useful for computational humour', ' #AUTHOR_TAG. to this end,  #TAUTHOR_TAG']","['as those useful for computational humour', ' #AUTHOR_TAG. to this end,  #TAUTHOR_TAG framed ev']","['have the disadvantage that 67 % of pairs were unanimously rated as having no connection ( boyd', '-  #AUTHOR_TAG. despite attempts to address this spareness issue by expanding evocation with data gathered from amazon mechanical turk 1  #AUTHOR_TAG or word - sense disambiguated usf cue / response pairs  #AUTHOR_TAG, obtaining human judgments for all possible syn', '##set pairs is impractical. as such, the prediction of evocation ratings presents the most promising solution to this coverage issue. boyd -  #AUTHOR_TAG detailed a simple evocation estimator which used', 'a combination of wordnet structure - based features', ', wordnet definition - based features, and corpus - based word co - occurrence features', '. however, this approach is somewhat limited in that it frames evocation prediction as a classification task, considering only five evocation levels. the', 'main drawback of evocation prediction as a classification task is that it is too coarse - grained to deal with very weak associations, such as those in remote triads  #AUTHOR_TAG', 'a ), or very slight variations in association strength, such as those useful for computational humour', ' #AUTHOR_TAG. to this end,  #TAUTHOR_TAG framed evocation prediction as a supervised regression task.  #TAUTHOR_TAG employed', 'a combination of wordnet structure - based features, word embedding - based features,', ""and lexical features and found that vector offsets, i. e. the mathematical difference between vectors, were a strong indicator of evocation ratings. while evocation's use of unambiguous"", '']",0
"['those useful for computational humour', ' #AUTHOR_TAG. to this end,  #TAUTHOR_TAG']","['those useful for computational humour', ' #AUTHOR_TAG. to this end,  #TAUTHOR_TAG']","['as those useful for computational humour', ' #AUTHOR_TAG. to this end,  #TAUTHOR_TAG framed ev']","['have the disadvantage that 67 % of pairs were unanimously rated as having no connection ( boyd', '-  #AUTHOR_TAG. despite attempts to address this spareness issue by expanding evocation with data gathered from amazon mechanical turk 1  #AUTHOR_TAG or word - sense disambiguated usf cue / response pairs  #AUTHOR_TAG, obtaining human judgments for all possible syn', '##set pairs is impractical. as such, the prediction of evocation ratings presents the most promising solution to this coverage issue. boyd -  #AUTHOR_TAG detailed a simple evocation estimator which used', 'a combination of wordnet structure - based features', ', wordnet definition - based features, and corpus - based word co - occurrence features', '. however, this approach is somewhat limited in that it frames evocation prediction as a classification task, considering only five evocation levels. the', 'main drawback of evocation prediction as a classification task is that it is too coarse - grained to deal with very weak associations, such as those in remote triads  #AUTHOR_TAG', 'a ), or very slight variations in association strength, such as those useful for computational humour', ' #AUTHOR_TAG. to this end,  #TAUTHOR_TAG framed evocation prediction as a supervised regression task.  #TAUTHOR_TAG employed', 'a combination of wordnet structure - based features, word embedding - based features,', ""and lexical features and found that vector offsets, i. e. the mathematical difference between vectors, were a strong indicator of evocation ratings. while evocation's use of unambiguous"", '']",0
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",0
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",0
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",0
"['attention  #TAUTHOR_TAG, to the best of our knowledge this is the first']","['attention  #TAUTHOR_TAG, to the best of our knowledge this is the first']","['-  #AUTHOR_TAG.', 'although the prediction of evocation ratings has attracted some attention  #TAUTHOR_TAG, to the best of our knowledge this is the first work to focus on the prediction of us']","['', 'this is backed up by  #AUTHOR_TAG b ) which found word associations performed better than word embeddings across a variety of semantic relatedness tasks.', 'furthermore, word associations, unlike cosine similarities, are asymmetric ; when presented with the word "" beer "", many people think of the word "" glass "" but when presented with the word "" glass "", few people think of the word "" beer ""  #AUTHOR_TAG.', 'this directionality allows for more fine - grained exploration of semantic links, with applications in word similarity  #AUTHOR_TAG and computational humour  #AUTHOR_TAG.', 'although several word association datasets exist, such as the edinburgh associative thesaurus ( eat,  #AUTHOR_TAG, the university of south florida free association norms ( usf,  #AUTHOR_TAG, or wordnet evocation ( evocation, boyd -  #AUTHOR_TAG their reliance on human annotations mean they all suffer from coverage issues relating to limited vocabularies or sparse connectivity  #AUTHOR_TAG b ).', 'although these issues would be somewhat alleviated by the creation of larger datasets, collecting human judgments for all possible word pairs is impractical.', 'therefore, the ability to predict association strengths between arbitrary word pairs represents the best solution to these coverage issues ( boyd -  #AUTHOR_TAG.', 'although the prediction of evocation ratings has attracted some attention  #TAUTHOR_TAG, to the best of our knowledge this is the first work to focus on the prediction of usf or eat strengths.', 'as described in sec - tion 2, usf and eat have several advantages over evocation, such as the ability to work with ambiguous words instead of wordnet synsets.', 'following  #TAUTHOR_TAG on evocation prediction, we frame word']",6
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",6
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",6
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",6
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",4
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",4
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",4
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",4
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",4
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",4
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",4
['of our  #TAUTHOR_TAG ('],['of our  #TAUTHOR_TAG ( r ='],"['in the eat ablation tests.', 'the results of our  #TAUTHOR_TAG (']",[' #TAUTHOR_TAG'],4
"['in  #TAUTHOR_TAG, potentially indicating that predicting association strengths in']","['in  #TAUTHOR_TAG, potentially indicating that predicting association strengths in word - sense ambiguous contexts is a harder task,']","['in  #TAUTHOR_TAG, potentially indicating that predicting association strengths in']","['this paper we explored the effectiveness of various features for predicting evocation, usf, and eat association strengths, finding glove and word2vec cosine similarities as well as vector offsets to be the most useful features.', 'we also examined the effectiveness of gaussian embeddings for capturing the asymmetric nature of word embeddings but found it to be less effective than traditional word embeddings.', 'although we report a lower performance than that in  #TAUTHOR_TAG, potentially indicating that predicting association strengths in word - sense ambiguous contexts is a harder task, we believe our results are a promising start.', 'training gaussian embeddings on a larger corpus may lead to improved effectiveness.', 'future works should also consider incorporating word - sense frequencies or developing word - sense agnostic features, with a particular focus on asymmetric features']",4
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",5
"['##nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', '']","['nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre -""]","[', as shown in equation 1. this may increase the probability that | nb ( s, k ) ∩nb ( t,', 'k ) | > 0, a  #TAUTHOR_TAG', "". fourth, in addition to the word2vec ( w2v ) cosine similarity between cue / response pairs calculated using google's pre - trained 300 dimension"", ""word2vec embeddings 2. we also examine the effectiveness of stanford's pre - trained 300 dimension glove embeddings 3. fifth, in order to better"", 'capture asymmetric word associations, we propose using gaussian embeddings. gaussian embeddings ( vilnis and mc  #AUTHOR_TAG represent words', 'not as a fixed point in vector space but as "" potential functions "", continuous densities in latent space ; therefore, they are more suitable for capturing asymmetric relationships. more specifically, for each cue / response pair, we calculate both the kl - divergence and cosine', 'similarities of their gaussian embeddings. the embeddings have a dimensionality of 300 and are trained on english wikipedia using the word2gauss 4 ( w2g ) and the hyperparameters reported', 'by the developer 5 sixth, since cue and response words are not associated with a single synset, the autoex embeddings employed in  #TAUTHOR_TAG to compute vector offsets are not well suited for our task', '.  #TAUTHOR_TAG experiment with offsets calculated using w2v, glove, and w2g embeddings. finally, our 300 topic lda model  #AUTHOR_TAG was trained using gensim 6 on', 'full english wikipedia instead of the subset of english wikipedia used in  #TAUTHOR_TAG. using the above features, we trained a multilayer', ""perceptron for each of our three datasets ; evocation, usf, and eat. in the case of evocation, we discarded any synset information and table 1 : individual feature performance after 50 epochs simply use each synset's headword ( e. g. given the sysnet entity. n. 01, we only considered the word entity )"", '. following the setup used in  #TAUTHOR_TAG, all neural networks are trained using the chainer 7 python library with rectified linear units, dropout, and two hidden layers, each with', '50 % of the number of units in the input layer. all were trained on 80 % of their respective dataset, with 20 % held', 'out for testing. mean squared error was used as a loss function and optimization was performed using adam algorithm  #AUTHOR_TAG. to act as a baseline, we also reimplemented the system described in', ' #TAUTHOR_TAG on the same 80 / 20 split of evocation as our system. in addition to the', 'reported results, we also performed feature selection experiments using 20 % of the training sets as', 'validation']",5
['of our  #TAUTHOR_TAG ('],['of our  #TAUTHOR_TAG ( r ='],"['in the eat ablation tests.', 'the results of our  #TAUTHOR_TAG (']",[' #TAUTHOR_TAG'],3
['style of  #TAUTHOR_TAG'],['style of  #TAUTHOR_TAG'],"['specific dependencies like obj ( in the style of  #TAUTHOR_TAG.', 'the second - maximum spanning']",[' #TAUTHOR_TAG'],0
['style of  #TAUTHOR_TAG'],['style of  #TAUTHOR_TAG'],"['specific dependencies like obj ( in the style of  #TAUTHOR_TAG.', 'the second - maximum spanning']",[' #TAUTHOR_TAG'],0
"['bert  #TAUTHOR_TAG.', ' #AUTHOR_TAG']","['bert  #TAUTHOR_TAG.', ' #AUTHOR_TAG']","['bert  #TAUTHOR_TAG.', ' #AUTHOR_TAG']","['works have proposed methods for extracting dependency relations and trees from the attention heads of the transformer - based neural machine translation ( nmt ) models.', 'in their preliminary work, marecek and  #AUTHOR_TAG aggregate the attention weights across the self - attention layers and heads to form a single attention weight matrix.', 'using this matrix, they propose a method to extract constituency and ( undirected ) dependency trees by recursively splitting and constructing the maximum spanning trees respectively.', 'in contrast,  #AUTHOR_TAG train a transformer - based machine translation model on different language pairs and extract the maximum spanning tree algorithm from the attention weights of the encoder for each layer and head individually.', 'they find that the best dependency score is not significantly higher than a right - branching tree baseline.', ' #AUTHOR_TAG find the most confident attention heads of the transformer nmt encoder based on a heuristic of the concentration of attention weights on a single token, and find that these heads mostly attend to relative positions, syntactic relations, and rare words.', 'additionally, researchers have investigated the syntactic knowledge that bert learns by analyzing the contextualized embeddings  #AUTHOR_TAG a ) and attention heads of bert  #TAUTHOR_TAG.', ' #AUTHOR_TAG analyzes the contextualized embeddings of bert by computing language model surprisal on subject - verb agreement and shows that bert learns significant knowledge of syntax.', ' #AUTHOR_TAG b ) introduce a probing classifier for evaluating syntactic knowledge in bert and show that bert encodes syntax more than semantics.', ' #AUTHOR_TAG train a structural probing model that maps the hidden representations of each token to an inner - product space that corresponds to syntax tree distance.', 'they show that the learned spaces of strong models such as bert and elmo  #AUTHOR_TAG are better for reconstructing dependency trees compared to baselines.', "" #AUTHOR_TAG train a probing classifier on the attentionheads of bert and show that bert's attention heads capture substantial syntactic information."", 'while there has been prior work on analysis of the attention heads of bert, we believe we are the first to analyze the dependency relations learned by the attention heads of fine - tuned bert models and roberta']",0
['style of  #TAUTHOR_TAG'],['style of  #TAUTHOR_TAG'],"['specific dependencies like obj ( in the style of  #TAUTHOR_TAG.', 'the second - maximum spanning']",[' #TAUTHOR_TAG'],5
['style of  #TAUTHOR_TAG'],['style of  #TAUTHOR_TAG'],"['specific dependencies like obj ( in the style of  #TAUTHOR_TAG.', 'the second - maximum spanning']",[' #TAUTHOR_TAG'],1
['style of  #TAUTHOR_TAG'],['style of  #TAUTHOR_TAG'],"['specific dependencies like obj ( in the style of  #TAUTHOR_TAG.', 'the second - maximum spanning']",[' #TAUTHOR_TAG'],6
"['', 'this method is similar to  #TAUTHOR_TAG, and attempts to']","['sentences in our evaluation datasets.', 'this method is similar to  #TAUTHOR_TAG, and attempts to']","['all sentences in our evaluation datasets.', 'this method is similar to  #TAUTHOR_TAG, and attempts to']","['', 'based on this simple strategy, we extract relations for all sentences in our evaluation datasets.', 'this method is similar to  #TAUTHOR_TAG, and attempts to recover individual arcs between words ; the relations extracted using this method need not form a valid tree, or even be fully connected, and the resulting edge directions may or may not match the canonical directions.', 'hence, we evaluate the resulting arcs individually and ignore their direction.', 'after extracting dependency relations from all heads at all layers, we take the maximum uuas over all relations types']",6
"['', 'this method is similar to  #TAUTHOR_TAG, and attempts to']","['sentences in our evaluation datasets.', 'this method is similar to  #TAUTHOR_TAG, and attempts to']","['all sentences in our evaluation datasets.', 'this method is similar to  #TAUTHOR_TAG, and attempts to']","['', 'based on this simple strategy, we extract relations for all sentences in our evaluation datasets.', 'this method is similar to  #TAUTHOR_TAG, and attempts to recover individual arcs between words ; the relations extracted using this method need not form a valid tree, or even be fully connected, and the resulting edge directions may or may not match the canonical directions.', 'hence, we evaluate the resulting arcs individually and ignore their direction.', 'after extracting dependency relations from all heads at all layers, we take the maximum uuas over all relations types']",3
['of  #TAUTHOR_TAG'],['of  #TAUTHOR_TAG'],"['of  #TAUTHOR_TAG. moreover,', 'we']",[' #TAUTHOR_TAG'],3
['##j )  #TAUTHOR_TAG and bref'],"['using the bigram lm [ 6 ].', 'experimental results are reported on the arpa wall street journal ( wsj )  #TAUTHOR_TAG and bref [ 14 ] corpora, using for both corpora over 37k utterances for acoustic training and more']","['##j )  #TAUTHOR_TAG and bref [ 14 ] corpora, using for both corpora over']","['material.', 'to deal with phonological variability alternate pronunciations are included in the lexicon, and optional phonological rules are applied during training and recognition.', 'the recognizer uses a time - synchronous graph - search strategy [ 16 ] for a first pass with a bigram back - off language model ( lm ) [ 10 ].', 'a trigram lm is used in a second acoustic decoding pass which makes use of the word graph generated using the bigram lm [ 6 ].', 'experimental results are reported on the arpa wall street journal ( wsj )  #TAUTHOR_TAG and bref [ 14 ] corpora, using for both corpora over 37k utterances for acoustic training and more than 37 million words of newspaper text for language model training.', 'while the number of speakers is larger for wsj, the total amount of acoustic training material is about the same ( see table 1 ).', 'it is shown that for both corpora increasing the amount of training utterances by an order of magnitude reduces the word error by about 30 %.', 'the use of a trigram lm in a second pass also gives an error reduction of 20 % to 30 %.', 'the combined error reduction is on the order of 50 %']",0
['corpus  #TAUTHOR_TAG was'],['arpa wsj corpus  #TAUTHOR_TAG was'],"['arpa wsj corpus  #TAUTHOR_TAG was designed to provide general - purpose speech data with large vocabularies.', 'text materials were selected to provide training and test data for 5']","['arpa wsj corpus  #TAUTHOR_TAG was designed to provide general - purpose speech data with large vocabularies.', 'text materials were selected to provide training and test data for 5k and 20k word, closed and open vocabularies, and with both verbalized ( vp ) and non - verbalized ( nvp ) punctuation.', '41n our implementation, a word lattice differs from a word graph only because it includes word endpoint information.', 'the 20k open test is also referred to as a 64k test since all of the words in these sentences occur in the 63, 495 most frequent words in the normalized wsj text material  #TAUTHOR_TAG.', 'two sets of standard training material have been used for these experiments : the standard wsj0 si84 training data which include 7240 sentences from 84 speakers, and the standard set of 37, 518 wsj0 / wsj1 si284 sentences from 284 speakers.', 'only the primary microphone data were used for training.', 'the wsj corpus provides a wealth of material that can be used for system development.', 'we have worked primarily with the wsj0 - dev ( 410 sentences, 10 speakers ), and the wsj1 - dev from spokes s5 and s6 ( 394 sentences, 10 speakers ).', '']",0
['lincoln labs  #TAUTHOR_TAG as required'],['lincoln labs  #TAUTHOR_TAG as required'],['lincoln labs  #TAUTHOR_TAG as required'],"['modeling entails incorporating constraints on the allowable sequences of words which form a sentence.', 'statistical n - gram models attempt to capture the syntactic and semantic constraints by estimating the frequencies of sequences of n words.', 'in this work bigram and trigram language models are estimated on the training text material for each corpus.', 'this data consists of 37m words of the wsj 1 and 38m words of le monde.', 'a backoff mechanism [ 10 ] is used to smooth the estimates of the probabilities of rare n - grams by relying on a lower order n - gram when there is insufficient training data, and to provide a means of modeling unobserved n - grams.', 'another advantage of the backoff mechanism is that lm size can be arbitrarily reduced by relying more on the backoff, by increasing the minimum number of required n - gram observations needed to include the n - gram.', 'this property can be used in the first bigram decod1while we have built n - gram - backoff lms directly from the 37m - word standardized wsj training text material, in these experiments all results are reported using the 5k or 20k, bigram and tfigram backoff lms provided by lincoln labs  #TAUTHOR_TAG as required by arpa so as to be compatible with the other sites participating in the tests.', 'ing pass to reduce computational requirements.', 'the trigram langage model is used in the second pass of the decoding process :.', 'in order to be able to constnact lms for bref, it was necessary to normalize the text material of le monde newpaper, which entailed a pre - treatment rather different from that used to normalize the wsj texts  #TAUTHOR_TAG.', 'the main differences are in the treatment of compound words, abbreviations, and case.', 'in bref the distinction between the cases is kept if it designates a distinctive graphemic feature, but not when the upper case is simply due to the fact that the word occurs at the beginning of the sentence.', 'thus, the first word of each sentence was semi - automatically verified to determine if a transformation to lower case was needed.', ""special treatment is also needed for the symbols hyphen ( - ), quote ('), and period (. ) which can lead to ambiguous separations."", 'for example, the hyphen in compound words like beaux - arts and au - dessus is considered word - internal.', 'alternatively the hyphen may be associated with the first word as in ex -, or anti -, or with the second word as in - id or - nl finally, it may appear in']",5
['lincoln labs  #TAUTHOR_TAG as required'],['lincoln labs  #TAUTHOR_TAG as required'],['lincoln labs  #TAUTHOR_TAG as required'],"['modeling entails incorporating constraints on the allowable sequences of words which form a sentence.', 'statistical n - gram models attempt to capture the syntactic and semantic constraints by estimating the frequencies of sequences of n words.', 'in this work bigram and trigram language models are estimated on the training text material for each corpus.', 'this data consists of 37m words of the wsj 1 and 38m words of le monde.', 'a backoff mechanism [ 10 ] is used to smooth the estimates of the probabilities of rare n - grams by relying on a lower order n - gram when there is insufficient training data, and to provide a means of modeling unobserved n - grams.', 'another advantage of the backoff mechanism is that lm size can be arbitrarily reduced by relying more on the backoff, by increasing the minimum number of required n - gram observations needed to include the n - gram.', 'this property can be used in the first bigram decod1while we have built n - gram - backoff lms directly from the 37m - word standardized wsj training text material, in these experiments all results are reported using the 5k or 20k, bigram and tfigram backoff lms provided by lincoln labs  #TAUTHOR_TAG as required by arpa so as to be compatible with the other sites participating in the tests.', 'ing pass to reduce computational requirements.', 'the trigram langage model is used in the second pass of the decoding process :.', 'in order to be able to constnact lms for bref, it was necessary to normalize the text material of le monde newpaper, which entailed a pre - treatment rather different from that used to normalize the wsj texts  #TAUTHOR_TAG.', 'the main differences are in the treatment of compound words, abbreviations, and case.', 'in bref the distinction between the cases is kept if it designates a distinctive graphemic feature, but not when the upper case is simply due to the fact that the word occurs at the beginning of the sentence.', 'thus, the first word of each sentence was semi - automatically verified to determine if a transformation to lower case was needed.', ""special treatment is also needed for the symbols hyphen ( - ), quote ('), and period (. ) which can lead to ambiguous separations."", 'for example, the hyphen in compound words like beaux - arts and au - dessus is considered word - internal.', 'alternatively the hyphen may be associated with the first word as in ex -, or anti -, or with the second word as in - id or - nl finally, it may appear in']",5
['corpus  #TAUTHOR_TAG was'],['arpa wsj corpus  #TAUTHOR_TAG was'],"['arpa wsj corpus  #TAUTHOR_TAG was designed to provide general - purpose speech data with large vocabularies.', 'text materials were selected to provide training and test data for 5']","['arpa wsj corpus  #TAUTHOR_TAG was designed to provide general - purpose speech data with large vocabularies.', 'text materials were selected to provide training and test data for 5k and 20k word, closed and open vocabularies, and with both verbalized ( vp ) and non - verbalized ( nvp ) punctuation.', '41n our implementation, a word lattice differs from a word graph only because it includes word endpoint information.', 'the 20k open test is also referred to as a 64k test since all of the words in these sentences occur in the 63, 495 most frequent words in the normalized wsj text material  #TAUTHOR_TAG.', 'two sets of standard training material have been used for these experiments : the standard wsj0 si84 training data which include 7240 sentences from 84 speakers, and the standard set of 37, 518 wsj0 / wsj1 si284 sentences from 284 speakers.', 'only the primary microphone data were used for training.', 'the wsj corpus provides a wealth of material that can be used for system development.', 'we have worked primarily with the wsj0 - dev ( 410 sentences, 10 speakers ), and the wsj1 - dev from spokes s5 and s6 ( 394 sentences, 10 speakers ).', '']",5
['corpus  #TAUTHOR_TAG was'],['arpa wsj corpus  #TAUTHOR_TAG was'],"['arpa wsj corpus  #TAUTHOR_TAG was designed to provide general - purpose speech data with large vocabularies.', 'text materials were selected to provide training and test data for 5']","['arpa wsj corpus  #TAUTHOR_TAG was designed to provide general - purpose speech data with large vocabularies.', 'text materials were selected to provide training and test data for 5k and 20k word, closed and open vocabularies, and with both verbalized ( vp ) and non - verbalized ( nvp ) punctuation.', '41n our implementation, a word lattice differs from a word graph only because it includes word endpoint information.', 'the 20k open test is also referred to as a 64k test since all of the words in these sentences occur in the 63, 495 most frequent words in the normalized wsj text material  #TAUTHOR_TAG.', 'two sets of standard training material have been used for these experiments : the standard wsj0 si84 training data which include 7240 sentences from 84 speakers, and the standard set of 37, 518 wsj0 / wsj1 si284 sentences from 284 speakers.', 'only the primary microphone data were used for training.', 'the wsj corpus provides a wealth of material that can be used for system development.', 'we have worked primarily with the wsj0 - dev ( 410 sentences, 10 speakers ), and the wsj1 - dev from spokes s5 and s6 ( 394 sentences, 10 speakers ).', '']",5
"['most frequent words  #TAUTHOR_TAG, and these additional words were then included as part of the vocabulary.', 'for bre']","['most frequent words  #TAUTHOR_TAG, and these additional words were then included as part of the vocabulary.', 'for bref, a lexicon was first constructed containing the']","[', paragraphs were selected ensuring not more than one word was out of the 5. 6k most frequent words  #TAUTHOR_TAG, and these additional words were then included as part of the vocabulary.', 'for bre']","['recognizer has been evaluated on 5k and 20k test data for the english and french languages using similar style corpora.', 'it should be pointed out however, that although the nov92 5k wsj test data and the bref 5k test data were closed - vocabulary, the conditions are not quite the same.', 'for wsj, paragraphs were selected ensuring not more than one word was out of the 5. 6k most frequent words  #TAUTHOR_TAG, and these additional words were then included as part of the vocabulary.', 'for bref, a lexicon was first constructed containing the 5k / 20k most frequent words, and sentences covered by this vocabulary were selected from the development test material.', 'the situation was slightly different for the nov93 5k test in that the prompt texts were not normalized, and therefore several oov words ( 0. 3 % ) occurred in the test data despite it being a closed - vocabulary test.', 'however, looking at the recognition results for individual speakers, it appears that interspeaker differences are much more important than differences in perplexity, and perhaps more than language differences.', 'just considering the relationship between speaking rate and word accurracy, in general, speakers that are faster or slower than the average have a higher word error.', '']",5
['lincoln labs  #TAUTHOR_TAG as required'],['lincoln labs  #TAUTHOR_TAG as required'],['lincoln labs  #TAUTHOR_TAG as required'],"['modeling entails incorporating constraints on the allowable sequences of words which form a sentence.', 'statistical n - gram models attempt to capture the syntactic and semantic constraints by estimating the frequencies of sequences of n words.', 'in this work bigram and trigram language models are estimated on the training text material for each corpus.', 'this data consists of 37m words of the wsj 1 and 38m words of le monde.', 'a backoff mechanism [ 10 ] is used to smooth the estimates of the probabilities of rare n - grams by relying on a lower order n - gram when there is insufficient training data, and to provide a means of modeling unobserved n - grams.', 'another advantage of the backoff mechanism is that lm size can be arbitrarily reduced by relying more on the backoff, by increasing the minimum number of required n - gram observations needed to include the n - gram.', 'this property can be used in the first bigram decod1while we have built n - gram - backoff lms directly from the 37m - word standardized wsj training text material, in these experiments all results are reported using the 5k or 20k, bigram and tfigram backoff lms provided by lincoln labs  #TAUTHOR_TAG as required by arpa so as to be compatible with the other sites participating in the tests.', 'ing pass to reduce computational requirements.', 'the trigram langage model is used in the second pass of the decoding process :.', 'in order to be able to constnact lms for bref, it was necessary to normalize the text material of le monde newpaper, which entailed a pre - treatment rather different from that used to normalize the wsj texts  #TAUTHOR_TAG.', 'the main differences are in the treatment of compound words, abbreviations, and case.', 'in bref the distinction between the cases is kept if it designates a distinctive graphemic feature, but not when the upper case is simply due to the fact that the word occurs at the beginning of the sentence.', 'thus, the first word of each sentence was semi - automatically verified to determine if a transformation to lower case was needed.', ""special treatment is also needed for the symbols hyphen ( - ), quote ('), and period (. ) which can lead to ambiguous separations."", 'for example, the hyphen in compound words like beaux - arts and au - dessus is considered word - internal.', 'alternatively the hyphen may be associated with the first word as in ex -, or anti -, or with the second word as in - id or - nl finally, it may appear in']",4
"['( 2 )  #TAUTHOR_TAG subject - verb agreement stimuli, in which content words in natural sentences']","['the recently introduced bert model captures english syntactic phenomena, using ( 1 ) naturally - occurring subject - verb agreement stimuli ; ( 2 )  #TAUTHOR_TAG subject - verb agreement stimuli, in which content words in natural sentences']","['the recently introduced bert model captures english syntactic phenomena, using ( 1 ) naturally - occurring subject - verb agreement stimuli ; ( 2 )  #TAUTHOR_TAG subject - verb agreement stimuli, in which content words in natural sentences are randomly replaced with words sharing the same part - of - speech and inflection ; and ( 3 ) manually cra']","['assess the extent to which the recently introduced bert model captures english syntactic phenomena, using ( 1 ) naturally - occurring subject - verb agreement stimuli ; ( 2 )  #TAUTHOR_TAG subject - verb agreement stimuli, in which content words in natural sentences are randomly replaced with words sharing the same part - of - speech and inflection ; and ( 3 ) manually crafted stimuli for subject - verb agreement and reflexive anaphora phenomena.', 'the bert model performs remarkably well on all cases']",1
"['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers']","['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia']","['sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences']","['single word in the bert wordpiece - based vocabulary ( and hence cannot be predicted by the model ). this include discarding  #AUTHOR_TAG stimuli involving the words swims or adm', '##ires, resulting in 23, 368 discarded pairs ( out of 152, 300 ). i similarly discard', '680 sentences from  #AUTHOR_TAG where the focus verb or its inflection were one of 108 out - ofvocabulary tokens, 6 and 28 sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia and books ). 4 https :', '/ / github. com / huggingface / pytorch - pretrained - bert 5 results are generally a bit higher when not discarding the is / are cases. 6 blames, dislike, inhabit, exclude, revolves, governs, delete, composes, overlap, edit', '##s, embrace, compose, undertakes, disagrees, redirect', ', persist, recognise, rotates, accompanies', ', attach, undertake, earn, communicates,', 'imagine, contradicts, specialize, accuses, obtain', ', caters, welcomes, interprets,', 'await, communicate, templates, qualify, reverts, achieve, achieves, govern, restricts, violate, behave, emit, contend, adopt, overlaps, reproduces, rotate,', 'defends, submit, revolve, lend, pertain, disagree, concentrate, detects, endors', '##es, detect, predate, persists, consume, locates, earns, predict, interact', ', merge, consumes, behaves, locate, predates, enhances, predicts, integrates, inhabits, satisfy, contradict, swear, activate, restrict, satisfies, redirect', '##s, excludes, violates, interacts, admires, speculate, blame, drag, qualifies, activates, criticize, assures, welcome, depart, characterizes, defend, obtains, lends', ', strives, accuse, recognises, characterize, contends, perceive, compl', '##ain, awaits 7 toss, spills, tosses, affirms, spill, melt, approves, affirm table 2 : results on the en nonce  #AUTHOR_TAG stimuli. while not strictly comparable,', 'the numbers reported by  #TAUTHOR_TAG for the lstm in this condition ( on all ) is 74. 1 ± 1. 6']",1
"['occurring wikipedia sentences.', ' #TAUTHOR_TAG setting in which content words in naturally occurring sentences']","['occurring wikipedia sentences.', ' #TAUTHOR_TAG setting in which content words in naturally occurring sentences']","['on naturally occurring wikipedia sentences.', ' #TAUTHOR_TAG setting in which content words in naturally occurring sentences are replaced with random words with the same partof - speech and inflection, thus ensuring a focus on syntax rather than on selectional - preferences based cues.', ' #AUTHOR_TAG consider a wider range']","['', 'recent work examines the extent to which rnn - based models capture syntax - sensitive phenomena that are traditionally taken as evidence for the existence in hierarchical structure.', 'in particular, in  #AUTHOR_TAG we assess the ability of lstms to learn subject - verb agreement patterns in english, and evaluate on naturally occurring wikipedia sentences.', ' #TAUTHOR_TAG setting in which content words in naturally occurring sentences are replaced with random words with the same partof - speech and inflection, thus ensuring a focus on syntax rather than on selectional - preferences based cues.', ' #AUTHOR_TAG consider a wider range of syntactic phenomena ( subjectverb agreement, reflexive anaphora, negative polarity items ) using manually constructed stimuli, allowing for greater coverage and control than in the naturally occurring setting.', 'the bert model is based on the "" transformer "" architecture  #AUTHOR_TAG, which - in contrast to rnns - relies purely on attention mechanisms, and does not have an explicit notion of word order beyond marking each word with its absolute - position embedding.', 'this reliance on attention may lead one 1 to expect decreased performance on syntax - sensitive tasks compared to rnn ( lstm ) models that do model word order directly, and explicitly track states across the sentence.', ' #AUTHOR_TAG finds that transformerbased models perform worse than lstm models on the  #AUTHOR_TAG agreement prediction dataset.', 'in contrast,  #AUTHOR_TAG find that self - attention performs on par with lstm for syntax sensitive dependencies in the context of machine - translation, and performance on syntactic tasks is correlated with the number of attention heads in multi - head attention.', 'i adapt the evaluation protocol and stimuli of  #AUTHOR_TAG,  #TAUTHOR_TAG and  #AUTHOR_TAG to the bidirectional setting required by bert, and evaluate the pretrained bert models ( both the large and the base models ).', 'surprisingly ( at least to me ), the out - of - the - box models ( without any task - specific fine - tuning ) perform very well on all the syntactic tasks']",4
"['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers']","['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia']","['sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences']","['single word in the bert wordpiece - based vocabulary ( and hence cannot be predicted by the model ). this include discarding  #AUTHOR_TAG stimuli involving the words swims or adm', '##ires, resulting in 23, 368 discarded pairs ( out of 152, 300 ). i similarly discard', '680 sentences from  #AUTHOR_TAG where the focus verb or its inflection were one of 108 out - ofvocabulary tokens, 6 and 28 sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia and books ). 4 https :', '/ / github. com / huggingface / pytorch - pretrained - bert 5 results are generally a bit higher when not discarding the is / are cases. 6 blames, dislike, inhabit, exclude, revolves, governs, delete, composes, overlap, edit', '##s, embrace, compose, undertakes, disagrees, redirect', ', persist, recognise, rotates, accompanies', ', attach, undertake, earn, communicates,', 'imagine, contradicts, specialize, accuses, obtain', ', caters, welcomes, interprets,', 'await, communicate, templates, qualify, reverts, achieve, achieves, govern, restricts, violate, behave, emit, contend, adopt, overlaps, reproduces, rotate,', 'defends, submit, revolve, lend, pertain, disagree, concentrate, detects, endors', '##es, detect, predate, persists, consume, locates, earns, predict, interact', ', merge, consumes, behaves, locate, predates, enhances, predicts, integrates, inhabits, satisfy, contradict, swear, activate, restrict, satisfies, redirect', '##s, excludes, violates, interacts, admires, speculate, blame, drag, qualifies, activates, criticize, assures, welcome, depart, characterizes, defend, obtains, lends', ', strives, accuse, recognises, characterize, contends, perceive, compl', '##ain, awaits 7 toss, spills, tosses, affirms, spill, melt, approves, affirm table 2 : results on the en nonce  #AUTHOR_TAG stimuli. while not strictly comparable,', 'the numbers reported by  #TAUTHOR_TAG for the lstm in this condition ( on all ) is 74. 1 ± 1. 6']",4
"['occurring wikipedia sentences.', ' #TAUTHOR_TAG setting in which content words in naturally occurring sentences']","['occurring wikipedia sentences.', ' #TAUTHOR_TAG setting in which content words in naturally occurring sentences']","['on naturally occurring wikipedia sentences.', ' #TAUTHOR_TAG setting in which content words in naturally occurring sentences are replaced with random words with the same partof - speech and inflection, thus ensuring a focus on syntax rather than on selectional - preferences based cues.', ' #AUTHOR_TAG consider a wider range']","['', 'recent work examines the extent to which rnn - based models capture syntax - sensitive phenomena that are traditionally taken as evidence for the existence in hierarchical structure.', 'in particular, in  #AUTHOR_TAG we assess the ability of lstms to learn subject - verb agreement patterns in english, and evaluate on naturally occurring wikipedia sentences.', ' #TAUTHOR_TAG setting in which content words in naturally occurring sentences are replaced with random words with the same partof - speech and inflection, thus ensuring a focus on syntax rather than on selectional - preferences based cues.', ' #AUTHOR_TAG consider a wider range of syntactic phenomena ( subjectverb agreement, reflexive anaphora, negative polarity items ) using manually constructed stimuli, allowing for greater coverage and control than in the naturally occurring setting.', 'the bert model is based on the "" transformer "" architecture  #AUTHOR_TAG, which - in contrast to rnns - relies purely on attention mechanisms, and does not have an explicit notion of word order beyond marking each word with its absolute - position embedding.', 'this reliance on attention may lead one 1 to expect decreased performance on syntax - sensitive tasks compared to rnn ( lstm ) models that do model word order directly, and explicitly track states across the sentence.', ' #AUTHOR_TAG finds that transformerbased models perform worse than lstm models on the  #AUTHOR_TAG agreement prediction dataset.', 'in contrast,  #AUTHOR_TAG find that self - attention performs on par with lstm for syntax sensitive dependencies in the context of machine - translation, and performance on syntactic tasks is correlated with the number of attention heads in multi - head attention.', 'i adapt the evaluation protocol and stimuli of  #AUTHOR_TAG,  #TAUTHOR_TAG and  #AUTHOR_TAG to the bidirectional setting required by bert, and evaluate the pretrained bert models ( both the large and the base models ).', 'surprisingly ( at least to me ), the out - of - the - box models ( without any task - specific fine - tuning ) perform very well on all the syntactic tasks']",6
"['use the stimuli provided by  #TAUTHOR_TAG, but change the experimental protocol to']","['use the stimuli provided by  #TAUTHOR_TAG, but change the experimental protocol to']","['use the stimuli provided by  #TAUTHOR_TAG, but change the experimental protocol to']","['use the stimuli provided by  #TAUTHOR_TAG, but change the experimental protocol to adapt it to the bidirectional nature of the bert model.', 'this requires discarding some of the stimuli, as described below.', 'thus, the numbers are not strictly comparable to those reported in previous work']",6
"['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers']","['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia']","['sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences']","['single word in the bert wordpiece - based vocabulary ( and hence cannot be predicted by the model ). this include discarding  #AUTHOR_TAG stimuli involving the words swims or adm', '##ires, resulting in 23, 368 discarded pairs ( out of 152, 300 ). i similarly discard', '680 sentences from  #AUTHOR_TAG where the focus verb or its inflection were one of 108 out - ofvocabulary tokens, 6 and 28 sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia and books ). 4 https :', '/ / github. com / huggingface / pytorch - pretrained - bert 5 results are generally a bit higher when not discarding the is / are cases. 6 blames, dislike, inhabit, exclude, revolves, governs, delete, composes, overlap, edit', '##s, embrace, compose, undertakes, disagrees, redirect', ', persist, recognise, rotates, accompanies', ', attach, undertake, earn, communicates,', 'imagine, contradicts, specialize, accuses, obtain', ', caters, welcomes, interprets,', 'await, communicate, templates, qualify, reverts, achieve, achieves, govern, restricts, violate, behave, emit, contend, adopt, overlaps, reproduces, rotate,', 'defends, submit, revolve, lend, pertain, disagree, concentrate, detects, endors', '##es, detect, predate, persists, consume, locates, earns, predict, interact', ', merge, consumes, behaves, locate, predates, enhances, predicts, integrates, inhabits, satisfy, contradict, swear, activate, restrict, satisfies, redirect', '##s, excludes, violates, interacts, admires, speculate, blame, drag, qualifies, activates, criticize, assures, welcome, depart, characterizes, defend, obtains, lends', ', strives, accuse, recognises, characterize, contends, perceive, compl', '##ain, awaits 7 toss, spills, tosses, affirms, spill, melt, approves, affirm table 2 : results on the en nonce  #AUTHOR_TAG stimuli. while not strictly comparable,', 'the numbers reported by  #TAUTHOR_TAG for the lstm in this condition ( on all ) is 74. 1 ± 1. 6']",6
"['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers']","['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia']","['sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences']","['single word in the bert wordpiece - based vocabulary ( and hence cannot be predicted by the model ). this include discarding  #AUTHOR_TAG stimuli involving the words swims or adm', '##ires, resulting in 23, 368 discarded pairs ( out of 152, 300 ). i similarly discard', '680 sentences from  #AUTHOR_TAG where the focus verb or its inflection were one of 108 out - ofvocabulary tokens, 6 and 28 sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia and books ). 4 https :', '/ / github. com / huggingface / pytorch - pretrained - bert 5 results are generally a bit higher when not discarding the is / are cases. 6 blames, dislike, inhabit, exclude, revolves, governs, delete, composes, overlap, edit', '##s, embrace, compose, undertakes, disagrees, redirect', ', persist, recognise, rotates, accompanies', ', attach, undertake, earn, communicates,', 'imagine, contradicts, specialize, accuses, obtain', ', caters, welcomes, interprets,', 'await, communicate, templates, qualify, reverts, achieve, achieves, govern, restricts, violate, behave, emit, contend, adopt, overlaps, reproduces, rotate,', 'defends, submit, revolve, lend, pertain, disagree, concentrate, detects, endors', '##es, detect, predate, persists, consume, locates, earns, predict, interact', ', merge, consumes, behaves, locate, predates, enhances, predicts, integrates, inhabits, satisfy, contradict, swear, activate, restrict, satisfies, redirect', '##s, excludes, violates, interacts, admires, speculate, blame, drag, qualifies, activates, criticize, assures, welcome, depart, characterizes, defend, obtains, lends', ', strives, accuse, recognises, characterize, contends, perceive, compl', '##ain, awaits 7 toss, spills, tosses, affirms, spill, melt, approves, affirm table 2 : results on the en nonce  #AUTHOR_TAG stimuli. while not strictly comparable,', 'the numbers reported by  #TAUTHOR_TAG for the lstm in this condition ( on all ) is 74. 1 ± 1. 6']",6
"['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers']","['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia']","['sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences']","['single word in the bert wordpiece - based vocabulary ( and hence cannot be predicted by the model ). this include discarding  #AUTHOR_TAG stimuli involving the words swims or adm', '##ires, resulting in 23, 368 discarded pairs ( out of 152, 300 ). i similarly discard', '680 sentences from  #AUTHOR_TAG where the focus verb or its inflection were one of 108 out - ofvocabulary tokens, 6 and 28 sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia and books ). 4 https :', '/ / github. com / huggingface / pytorch - pretrained - bert 5 results are generally a bit higher when not discarding the is / are cases. 6 blames, dislike, inhabit, exclude, revolves, governs, delete, composes, overlap, edit', '##s, embrace, compose, undertakes, disagrees, redirect', ', persist, recognise, rotates, accompanies', ', attach, undertake, earn, communicates,', 'imagine, contradicts, specialize, accuses, obtain', ', caters, welcomes, interprets,', 'await, communicate, templates, qualify, reverts, achieve, achieves, govern, restricts, violate, behave, emit, contend, adopt, overlaps, reproduces, rotate,', 'defends, submit, revolve, lend, pertain, disagree, concentrate, detects, endors', '##es, detect, predate, persists, consume, locates, earns, predict, interact', ', merge, consumes, behaves, locate, predates, enhances, predicts, integrates, inhabits, satisfy, contradict, swear, activate, restrict, satisfies, redirect', '##s, excludes, violates, interacts, admires, speculate, blame, drag, qualifies, activates, criticize, assures, welcome, depart, characterizes, defend, obtains, lends', ', strives, accuse, recognises, characterize, contends, perceive, compl', '##ain, awaits 7 toss, spills, tosses, affirms, spill, melt, approves, affirm table 2 : results on the en nonce  #AUTHOR_TAG stimuli. while not strictly comparable,', 'the numbers reported by  #TAUTHOR_TAG for the lstm in this condition ( on all ) is 74. 1 ± 1. 6']",6
"['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers']","['- pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia']","['sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences']","['single word in the bert wordpiece - based vocabulary ( and hence cannot be predicted by the model ). this include discarding  #AUTHOR_TAG stimuli involving the words swims or adm', '##ires, resulting in 23, 368 discarded pairs ( out of 152, 300 ). i similarly discard', '680 sentences from  #AUTHOR_TAG where the focus verb or its inflection were one of 108 out - ofvocabulary tokens, 6 and 28 sentence - pairs (', '8 tokens 7 ) from  #TAUTHOR_TAG.', 'limitations the bert results are not directly comparable to the numbers reported in previous work. beyond the differences due to bidirectionality and the discarded stimuli, the bert models are also trained on a different and larger corpus ( covering', 'both wikipedia and books ). 4 https :', '/ / github. com / huggingface / pytorch - pretrained - bert 5 results are generally a bit higher when not discarding the is / are cases. 6 blames, dislike, inhabit, exclude, revolves, governs, delete, composes, overlap, edit', '##s, embrace, compose, undertakes, disagrees, redirect', ', persist, recognise, rotates, accompanies', ', attach, undertake, earn, communicates,', 'imagine, contradicts, specialize, accuses, obtain', ', caters, welcomes, interprets,', 'await, communicate, templates, qualify, reverts, achieve, achieves, govern, restricts, violate, behave, emit, contend, adopt, overlaps, reproduces, rotate,', 'defends, submit, revolve, lend, pertain, disagree, concentrate, detects, endors', '##es, detect, predate, persists, consume, locates, earns, predict, interact', ', merge, consumes, behaves, locate, predates, enhances, predicts, integrates, inhabits, satisfy, contradict, swear, activate, restrict, satisfies, redirect', '##s, excludes, violates, interacts, admires, speculate, blame, drag, qualifies, activates, criticize, assures, welcome, depart, characterizes, defend, obtains, lends', ', strives, accuse, recognises, characterize, contends, perceive, compl', '##ain, awaits 7 toss, spills, tosses, affirms, spill, melt, approves, affirm table 2 : results on the en nonce  #AUTHOR_TAG stimuli. while not strictly comparable,', 'the numbers reported by  #TAUTHOR_TAG for the lstm in this condition ( on all ) is 74. 1 ± 1. 6']",5
"['by these results.', 'the  #TAUTHOR_TAG and  #AUTHOR_TAG conditions']","['by these results.', 'the  #TAUTHOR_TAG and  #AUTHOR_TAG conditions']","['by these results.', 'the  #TAUTHOR_TAG and  #AUTHOR_TAG conditions']","['bert models perform remarkably well on all the syntactic test cases.', 'i expected the attentionbased mechanism to fail on these ( compared to the lstm - based models ), and am surprised by these results.', 'the  #TAUTHOR_TAG and  #AUTHOR_TAG conditions rule out the possibility of overly relying on selectional preference cues or memorizing the wikipedia training data, and suggest real syntactic generalization is taking place.', 'exploring the extent to which deep purely - attention - based architectures such as bert are capable of capturing hierarchy - sensitive and syntactic dependencies - as well as the mechanisms by which this is achieved - is a fascinating area for future research']",5
"[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement']","[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement']","['', 'to address the model design issue, we discuss several recent solutions  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement learning']","['', 'we further discuss we further discuss several critical issues in drl solutions for nlp tasks, including ( 1 ) the efficient and practical design of the action space, state space, and reward functions ; ( 2 ) the trade - off between exploration and exploitation ; and ( 3 ) the goal of incorporating linguistic structures in drl.', 'to address the model design issue, we discuss several recent solutions  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement learning for video captioning  #AUTHOR_TAG b ), discussing the techniques of leveraging hierarchies in drl for nlp generation problems.', 'this tutorial aims at introducing deep reinforcement learning methods to researchers in the nlp community.', 'we do not assume any particular prior knowledge in reinforcement learning.', 'the intended length of the tutorial is 3 hours, including a coffee break.', 'representation learning, reasoning ( learning to search ), and scalability are']",0
"[' #TAUTHOR_TAG, text games']","[' #TAUTHOR_TAG, text games']","[' #TAUTHOR_TAG, text games']","['', 'we outline the applications of deep reinforcement learning in nlp, including dialog  #AUTHOR_TAG, semi - supervised text classification  #AUTHOR_TAG, coreference  #AUTHOR_TAG, knowledge graph reasoning  #TAUTHOR_TAG, text games  #AUTHOR_TAG a ), social media  #AUTHOR_TAG b ;  #AUTHOR_TAG, information extraction  #AUTHOR_TAG, language and vision  #AUTHOR_TAG a, b, c ;  #AUTHOR_TAG, etc.', 'we further discuss several critical issues in drl solutions for nlp tasks, including ( 1 ) the efficient and practical design of the action space, state space, and reward functions ; ( 2 ) the trade - off between exploration and exploitation ; and ( 3 ) the goal of incorporating linguistic structures in drl.', 'to address the model design issue, we discuss several recent solutions  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement learning for video captioning  #AUTHOR_TAG b ), discussing the techniques of leveraging hierarchies in drl for nlp generation problems.', 'this tutorial aims at introducing deep reinforcement learning methods to researchers in the nlp community.', 'we do not assume any particular prior knowledge in reinforcement learning.', 'the intended length of the tutorial is 3 hours, including a coffee break']",0
"[' #TAUTHOR_TAG, text games']","[' #TAUTHOR_TAG, text games']","[' #TAUTHOR_TAG, text games']","['', 'we outline the applications of deep reinforcement learning in nlp, including dialog  #AUTHOR_TAG, semi - supervised text classification  #AUTHOR_TAG, coreference  #AUTHOR_TAG, knowledge graph reasoning  #TAUTHOR_TAG, text games  #AUTHOR_TAG a ), social media  #AUTHOR_TAG b ;  #AUTHOR_TAG, information extraction  #AUTHOR_TAG, language and vision  #AUTHOR_TAG a, b, c ;  #AUTHOR_TAG, etc.', 'we further discuss several critical issues in drl solutions for nlp tasks, including ( 1 ) the efficient and practical design of the action space, state space, and reward functions ; ( 2 ) the trade - off between exploration and exploitation ; and ( 3 ) the goal of incorporating linguistic structures in drl.', 'to address the model design issue, we discuss several recent solutions  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement learning for video captioning  #AUTHOR_TAG b ), discussing the techniques of leveraging hierarchies in drl for nlp generation problems.', 'this tutorial aims at introducing deep reinforcement learning methods to researchers in the nlp community.', 'we do not assume any particular prior knowledge in reinforcement learning.', 'the intended length of the tutorial is 3 hours, including a coffee break']",0
"[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement']","[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement']","['', 'to address the model design issue, we discuss several recent solutions  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement learning']","['', 'we further discuss we further discuss several critical issues in drl solutions for nlp tasks, including ( 1 ) the efficient and practical design of the action space, state space, and reward functions ; ( 2 ) the trade - off between exploration and exploitation ; and ( 3 ) the goal of incorporating linguistic structures in drl.', 'to address the model design issue, we discuss several recent solutions  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement learning for video captioning  #AUTHOR_TAG b ), discussing the techniques of leveraging hierarchies in drl for nlp generation problems.', 'this tutorial aims at introducing deep reinforcement learning methods to researchers in the nlp community.', 'we do not assume any particular prior knowledge in reinforcement learning.', 'the intended length of the tutorial is 3 hours, including a coffee break.', 'representation learning, reasoning ( learning to search ), and scalability are']",4
"[' #TAUTHOR_TAG, text games']","[' #TAUTHOR_TAG, text games']","[' #TAUTHOR_TAG, text games']","['', 'we outline the applications of deep reinforcement learning in nlp, including dialog  #AUTHOR_TAG, semi - supervised text classification  #AUTHOR_TAG, coreference  #AUTHOR_TAG, knowledge graph reasoning  #TAUTHOR_TAG, text games  #AUTHOR_TAG a ), social media  #AUTHOR_TAG b ;  #AUTHOR_TAG, information extraction  #AUTHOR_TAG, language and vision  #AUTHOR_TAG a, b, c ;  #AUTHOR_TAG, etc.', 'we further discuss several critical issues in drl solutions for nlp tasks, including ( 1 ) the efficient and practical design of the action space, state space, and reward functions ; ( 2 ) the trade - off between exploration and exploitation ; and ( 3 ) the goal of incorporating linguistic structures in drl.', 'to address the model design issue, we discuss several recent solutions  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'we then focus on a new case study of hierarchical deep reinforcement learning for video captioning  #AUTHOR_TAG b ), discussing the techniques of leveraging hierarchies in drl for nlp generation problems.', 'this tutorial aims at introducing deep reinforcement learning methods to researchers in the nlp community.', 'we do not assume any particular prior knowledge in reinforcement learning.', 'the intended length of the tutorial is 3 hours, including a coffee break']",4
[' #TAUTHOR_TAG included entity'],[' #TAUTHOR_TAG included entity'],['and this task  #TAUTHOR_TAG included entity linking ('],"['', 'while these earlier tasks also experienced improvement, f - scores remained lower overall.', 'table 1 depicted above are distributions for each domain and language, detailing the probability ( y - axis ) of specific parts of speech at increasing degrees of polysemy ( x - axis ).', 'these distributions were produced from the gold keys ( or synsets ) of the test documents by querying babelnet for the polysemy of each word.', 'each distribution was normalised with one sense per discourse assumed, therefore duplicate synsets were ignored.', 'lastly the difference in f - score between the conventional run1 and the iterative run2 and run3 is listed beside each distribution.', 'firstly wsd tasks before 2013 generally relied on only a lexicon, such as wordnet  #AUTHOR_TAG or an alternative equivalent, whereas semeval 2013 task 12 wsd and this task  #TAUTHOR_TAG included entity linking ( el ) using the encyclopaedia wikipedia via babelnet  #AUTHOR_TAG.', 'secondly, as shown by  #AUTHOR_TAG with a simple linear regression, the iterative approach increases wsd performance for documents that have a higher degree of document monosemy - the percentage']",0
"['noting the results of the task paper  #TAUTHOR_TAG report', 'that sudok']","['iterative run2 and run3. yet it is worth noting the results of the task paper  #TAUTHOR_TAG report', 'that sudok']","['run3. yet it is worth noting the results of the task paper  #TAUTHOR_TAG report', 'that sudok']","['. the italian biomedical domain had the highest document monosemy, observable in figure 1 ( g ), yet this did not help the iterative run2 and run3. yet it is worth noting the results of the task paper  #TAUTHOR_TAG report', 'that sudoku run2 and run3 achieved very low f - scores for named entity disambiguation ( < 28. 6 ) in spanish and italian. given that more than half of the', 'named entities were monosemous in figure 1 ( d ) and ( g ), the wsd system either did not capture them in text or filtered them out during subgraph construction ( see babelnet', 'api ). this underscores the importance of named entities being included in disambiguation tasks. to further support this', 'evidence, while the iterative approach is suited to domain based wsd, recall that the 2010 domain based wsd task in table 1 also had no tagged named entities (', 'and thus scores were lower than for successive named entity inclusive wsd tasks ). as seen in table 2, the iterative approach has a varied effect on different parts of speech. always improved is the disambiguation of named entities', '']",0
"['noting the results of the task paper  #TAUTHOR_TAG report', 'that sudok']","['iterative run2 and run3. yet it is worth noting the results of the task paper  #TAUTHOR_TAG report', 'that sudok']","['run3. yet it is worth noting the results of the task paper  #TAUTHOR_TAG report', 'that sudok']","['. the italian biomedical domain had the highest document monosemy, observable in figure 1 ( g ), yet this did not help the iterative run2 and run3. yet it is worth noting the results of the task paper  #TAUTHOR_TAG report', 'that sudoku run2 and run3 achieved very low f - scores for named entity disambiguation ( < 28. 6 ) in spanish and italian. given that more than half of the', 'named entities were monosemous in figure 1 ( d ) and ( g ), the wsd system either did not capture them in text or filtered them out during subgraph construction ( see babelnet', 'api ). this underscores the importance of named entities being included in disambiguation tasks. to further support this', 'evidence, while the iterative approach is suited to domain based wsd, recall that the 2010 domain based wsd task in table 1 also had no tagged named entities (', 'and thus scores were lower than for successive named entity inclusive wsd tasks ). as seen in table 2, the iterative approach has a varied effect on different parts of speech. always improved is the disambiguation of named entities', '']",0
"['sets  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'in this study, we present our experiments of using named entities']","['sets  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'in this study, we present our experiments of using named entities']","['present publicly - available stance - annotated data sets  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'in this study, we present our experiments of using named entities']","['the emergence of social media applications like twitter and facebook, a considerable body of social media texts has accumulated.', 'the need for the utilization of this user - generated content, for several purposes like trend analysis, has accelerated research on social media analysis.', 'as acknowledged in the related literature, the language used in social media texts is usually different from well - formed texts such as news articles, where the latter has been one of the most common text genre targeted by natural language processing ( nlp ) research so far.', 'as a result, approaches proposed for well - formed texts have suffered from the porting problem, revealed with poor performance on social media texts.', 'one of these nlp problems is named entity recognition ( ner ) which targets at the extraction and classification of named entities like person, location, and organization names in texts  #AUTHOR_TAG.', 'several recent studies on ner report performance results on social media texts and propose customized systems for this text genre  #AUTHOR_TAG.', 'another important research topic regarding social media analysis is sentiment analysis  #AUTHOR_TAG where the opinion or sentiment of the text owner is explored.', 'stance detection is a considerably recent research field usually considered as a subproblem of sentiment analysis  #AUTHOR_TAG b ).', 'in stance detection, the aim is to determine the stance of the text owner ( as favor, against, or neither ) for a particular target either explicitly or implicitly mentioned in the text  #AUTHOR_TAG b ).', 'the most common text genres used by stance detection studies are on - line debates and social media texts like tweets.', 'some of the recent studies on this topic report performance evaluation results of different classifiers using different feature sets  #AUTHOR_TAG b ) while others present publicly - available stance - annotated data sets  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'in this study, we present our experiments of using named entities for the purposes of improved stance detection in tweets.', 'we have used the publicly - available tweet data set in turkish annotated with stance information, together with the results of the corresponding svm classifiers using unigrams as features in  #TAUTHOR_TAG as the baselines.', 'we first perform ner on this data set and next use the named entities as additional features during our svm - based stance detection experiments.', '']",0
['set in turkish  #TAUTHOR_TAG which includes 700 random tweets'],['set in turkish  #TAUTHOR_TAG which includes 700 random tweets'],"['during the training of supervised systems ) for this new text genre.', 'in this study, we have used the stance - annotated tweet data set in turkish  #TAUTHOR_TAG which includes 700 random tweets']","['is an information extraction task that has been studied for decades, especially on well - formed texts like news articles.', 'more recently, considerable number of studies on ner target at social media texts, like tweets.', 'yet, as emphasized in the related literature  #AUTHOR_TAG, porting existing ner systems to social media texts results in poor performance.', 'therefore, related studies usually propose customized systems and / or annotated data sets ( to be used during the training of supervised systems ) for this new text genre.', 'in this study, we have used the stance - annotated tweet data set in turkish  #TAUTHOR_TAG which includes 700 random tweets related to two sports clubs and these clubs constitute the stance targets.', 'the data set is a balanced one in the sense that 175 tweets are in favor of target - 1 and 175 tweets are against target - 1, while 175 tweets are in favor of and 175 are against target - 2.', 'there are no tweet instances annotated with the class neither in the data set  #TAUTHOR_TAG.', 'the names of the two target clubs are explicitly mentioned in all of the tweets although some of these mentions are neologisms or contracted forms while some others have writing errors, as expected due to the peculiarities of language use in twitter ( kucuk and  #AUTHOR_TAG.', 'in order to create the ner answer key for this data set, we have annotated it with person, location, and organization names.', 'the resulting named entity statistics are provided in table 1.', 'as the ner tool, we have used the extended version of the rule - based tool ( kucuk and yazıcı, 2009 ) proposed for news articles in order to perform better on tweets, as presented in ( kucuk and  #AUTHOR_TAG.', 'these extensions include relaxing the capitalization constraint to extract entities all in lowercase as well and diacriticsbased extension of the lexical resources of the tool since characters with diacritics such as c, ı, o, s are commonly replaced with the corresponding characters such as c, i, o, s in tweets.', 'the evaluation results of the ner tool on the tweet data set are presented in table 2, in terms of the corresponding metrics of precision ( p ), recall ( r ), and f - measure ( f ), without giving credit to partial extractions.', 'that is, a named entity extraction is considered as correct if both its type and all of its tokens are correctly identified by the system.', 'the ner results obtained are not favorable compared to the ner results on news articles in turkish ( usually over 85 % in f']",0
"['settings in  #TAUTHOR_TAG,']","['settings in  #TAUTHOR_TAG,']","['and the annotations consistent. similar to the settings in  #TAUTHOR_TAG,']","['##tive language and the particular ner tool that we have employed extracts named entities in their bare forms by', 'excluding the sequence of suffixes attached to named entities, making the corresponding single -', 'token named entities different from unigrams. we', 'should note that during the named entity annotation procedure to', 'create the answer key ( as explained in section 2 ), bare forms of the entities are', 'annotated, making the system results and the annotations consistent. similar to the settings in  #TAUTHOR_TAG, we have used the svm classifier based on the smo algorithm  #AUTHOR_TAG, available in the weka tool  #AUTHOR_TAG, during our stance detection experiments. 10 -', '']",0
"['settings in  #TAUTHOR_TAG,']","['settings in  #TAUTHOR_TAG,']","['and the annotations consistent. similar to the settings in  #TAUTHOR_TAG,']","['##tive language and the particular ner tool that we have employed extracts named entities in their bare forms by', 'excluding the sequence of suffixes attached to named entities, making the corresponding single -', 'token named entities different from unigrams. we', 'should note that during the named entity annotation procedure to', 'create the answer key ( as explained in section 2 ), bare forms of the entities are', 'annotated, making the system results and the annotations consistent. similar to the settings in  #TAUTHOR_TAG, we have used the svm classifier based on the smo algorithm  #AUTHOR_TAG, available in the weka tool  #AUTHOR_TAG, during our stance detection experiments. 10 -', '']",0
"['sets  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'in this study, we present our experiments of using named entities']","['sets  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'in this study, we present our experiments of using named entities']","['present publicly - available stance - annotated data sets  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'in this study, we present our experiments of using named entities']","['the emergence of social media applications like twitter and facebook, a considerable body of social media texts has accumulated.', 'the need for the utilization of this user - generated content, for several purposes like trend analysis, has accelerated research on social media analysis.', 'as acknowledged in the related literature, the language used in social media texts is usually different from well - formed texts such as news articles, where the latter has been one of the most common text genre targeted by natural language processing ( nlp ) research so far.', 'as a result, approaches proposed for well - formed texts have suffered from the porting problem, revealed with poor performance on social media texts.', 'one of these nlp problems is named entity recognition ( ner ) which targets at the extraction and classification of named entities like person, location, and organization names in texts  #AUTHOR_TAG.', 'several recent studies on ner report performance results on social media texts and propose customized systems for this text genre  #AUTHOR_TAG.', 'another important research topic regarding social media analysis is sentiment analysis  #AUTHOR_TAG where the opinion or sentiment of the text owner is explored.', 'stance detection is a considerably recent research field usually considered as a subproblem of sentiment analysis  #AUTHOR_TAG b ).', 'in stance detection, the aim is to determine the stance of the text owner ( as favor, against, or neither ) for a particular target either explicitly or implicitly mentioned in the text  #AUTHOR_TAG b ).', 'the most common text genres used by stance detection studies are on - line debates and social media texts like tweets.', 'some of the recent studies on this topic report performance evaluation results of different classifiers using different feature sets  #AUTHOR_TAG b ) while others present publicly - available stance - annotated data sets  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'in this study, we present our experiments of using named entities for the purposes of improved stance detection in tweets.', 'we have used the publicly - available tweet data set in turkish annotated with stance information, together with the results of the corresponding svm classifiers using unigrams as features in  #TAUTHOR_TAG as the baselines.', 'we first perform ner on this data set and next use the named entities as additional features during our svm - based stance detection experiments.', '']",5
['set in turkish  #TAUTHOR_TAG which includes 700 random tweets'],['set in turkish  #TAUTHOR_TAG which includes 700 random tweets'],"['during the training of supervised systems ) for this new text genre.', 'in this study, we have used the stance - annotated tweet data set in turkish  #TAUTHOR_TAG which includes 700 random tweets']","['is an information extraction task that has been studied for decades, especially on well - formed texts like news articles.', 'more recently, considerable number of studies on ner target at social media texts, like tweets.', 'yet, as emphasized in the related literature  #AUTHOR_TAG, porting existing ner systems to social media texts results in poor performance.', 'therefore, related studies usually propose customized systems and / or annotated data sets ( to be used during the training of supervised systems ) for this new text genre.', 'in this study, we have used the stance - annotated tweet data set in turkish  #TAUTHOR_TAG which includes 700 random tweets related to two sports clubs and these clubs constitute the stance targets.', 'the data set is a balanced one in the sense that 175 tweets are in favor of target - 1 and 175 tweets are against target - 1, while 175 tweets are in favor of and 175 are against target - 2.', 'there are no tweet instances annotated with the class neither in the data set  #TAUTHOR_TAG.', 'the names of the two target clubs are explicitly mentioned in all of the tweets although some of these mentions are neologisms or contracted forms while some others have writing errors, as expected due to the peculiarities of language use in twitter ( kucuk and  #AUTHOR_TAG.', 'in order to create the ner answer key for this data set, we have annotated it with person, location, and organization names.', 'the resulting named entity statistics are provided in table 1.', 'as the ner tool, we have used the extended version of the rule - based tool ( kucuk and yazıcı, 2009 ) proposed for news articles in order to perform better on tweets, as presented in ( kucuk and  #AUTHOR_TAG.', 'these extensions include relaxing the capitalization constraint to extract entities all in lowercase as well and diacriticsbased extension of the lexical resources of the tool since characters with diacritics such as c, ı, o, s are commonly replaced with the corresponding characters such as c, i, o, s in tweets.', 'the evaluation results of the ner tool on the tweet data set are presented in table 2, in terms of the corresponding metrics of precision ( p ), recall ( r ), and f - measure ( f ), without giving credit to partial extractions.', 'that is, a named entity extraction is considered as correct if both its type and all of its tokens are correctly identified by the system.', 'the ner results obtained are not favorable compared to the ner results on news articles in turkish ( usually over 85 % in f']",5
"['settings in  #TAUTHOR_TAG,']","['settings in  #TAUTHOR_TAG,']","['and the annotations consistent. similar to the settings in  #TAUTHOR_TAG,']","['##tive language and the particular ner tool that we have employed extracts named entities in their bare forms by', 'excluding the sequence of suffixes attached to named entities, making the corresponding single -', 'token named entities different from unigrams. we', 'should note that during the named entity annotation procedure to', 'create the answer key ( as explained in section 2 ), bare forms of the entities are', 'annotated, making the system results and the annotations consistent. similar to the settings in  #TAUTHOR_TAG, we have used the svm classifier based on the smo algorithm  #AUTHOR_TAG, available in the weka tool  #AUTHOR_TAG, during our stance detection experiments. 10 -', '']",5
"['settings in  #TAUTHOR_TAG,']","['settings in  #TAUTHOR_TAG,']","['and the annotations consistent. similar to the settings in  #TAUTHOR_TAG,']","['##tive language and the particular ner tool that we have employed extracts named entities in their bare forms by', 'excluding the sequence of suffixes attached to named entities, making the corresponding single -', 'token named entities different from unigrams. we', 'should note that during the named entity annotation procedure to', 'create the answer key ( as explained in section 2 ), bare forms of the entities are', 'annotated, making the system results and the annotations consistent. similar to the settings in  #TAUTHOR_TAG, we have used the svm classifier based on the smo algorithm  #AUTHOR_TAG, available in the weka tool  #AUTHOR_TAG, during our stance detection experiments. 10 -', '']",5
"['settings in  #TAUTHOR_TAG,']","['settings in  #TAUTHOR_TAG,']","['and the annotations consistent. similar to the settings in  #TAUTHOR_TAG,']","['##tive language and the particular ner tool that we have employed extracts named entities in their bare forms by', 'excluding the sequence of suffixes attached to named entities, making the corresponding single -', 'token named entities different from unigrams. we', 'should note that during the named entity annotation procedure to', 'create the answer key ( as explained in section 2 ), bare forms of the entities are', 'annotated, making the system results and the annotations consistent. similar to the settings in  #TAUTHOR_TAG, we have used the svm classifier based on the smo algorithm  #AUTHOR_TAG, available in the weka tool  #AUTHOR_TAG, during our stance detection experiments. 10 -', '']",5
"['settings in  #TAUTHOR_TAG,']","['settings in  #TAUTHOR_TAG,']","['and the annotations consistent. similar to the settings in  #TAUTHOR_TAG,']","['##tive language and the particular ner tool that we have employed extracts named entities in their bare forms by', 'excluding the sequence of suffixes attached to named entities, making the corresponding single -', 'token named entities different from unigrams. we', 'should note that during the named entity annotation procedure to', 'create the answer key ( as explained in section 2 ), bare forms of the entities are', 'annotated, making the system results and the annotations consistent. similar to the settings in  #TAUTHOR_TAG, we have used the svm classifier based on the smo algorithm  #AUTHOR_TAG, available in the weka tool  #AUTHOR_TAG, during our stance detection experiments. 10 -', '']",3
"['settings in  #TAUTHOR_TAG,']","['settings in  #TAUTHOR_TAG,']","['and the annotations consistent. similar to the settings in  #TAUTHOR_TAG,']","['##tive language and the particular ner tool that we have employed extracts named entities in their bare forms by', 'excluding the sequence of suffixes attached to named entities, making the corresponding single -', 'token named entities different from unigrams. we', 'should note that during the named entity annotation procedure to', 'create the answer key ( as explained in section 2 ), bare forms of the entities are', 'annotated, making the system results and the annotations consistent. similar to the settings in  #TAUTHOR_TAG, we have used the svm classifier based on the smo algorithm  #AUTHOR_TAG, available in the weka tool  #AUTHOR_TAG, during our stance detection experiments. 10 -', '']",3
['the strong transformer model  #TAUTHOR_TAG across language pairs'],['the strong transformer model  #TAUTHOR_TAG across language pairs. comparing'],['the strong transformer model  #TAUTHOR_TAG across language pairs. comparing'],"['', '##14 english - to - german, wmt17', 'chineseto - english, and wat17 japanese - to - english. experimental results demonstrate that our approach consistently improves', 'performance over the strong transformer model  #TAUTHOR_TAG across language pairs. comparing with previous work on modeling locality', 'for sans ( e. g.  #AUTHOR_TAG, our model boosts performance on both translation quality and training efficiency. 2 multi - head', 'self - attention networks sans produce representations by applying attention to each pair of tokens from the input sequence, regardless of their distance.  #AUTHOR_TAG found it is', 'beneficial to capture different contextual features with multiple individual attention functions. given an input sequence x = { x 1,', '']",0
['the strong transformer model  #TAUTHOR_TAG across language pairs'],['the strong transformer model  #TAUTHOR_TAG across language pairs. comparing'],['the strong transformer model  #TAUTHOR_TAG across language pairs. comparing'],"['', '##14 english - to - german, wmt17', 'chineseto - english, and wat17 japanese - to - english. experimental results demonstrate that our approach consistently improves', 'performance over the strong transformer model  #TAUTHOR_TAG across language pairs. comparing with previous work on modeling locality', 'for sans ( e. g.  #AUTHOR_TAG, our model boosts performance on both translation quality and training efficiency. 2 multi - head', 'self - attention networks sans produce representations by applying attention to each pair of tokens from the input sequence, regardless of their distance.  #AUTHOR_TAG found it is', 'beneficial to capture different contextual features with multiple individual attention functions. given an input sequence x = { x 1,', '']",0
['the strong transformer model  #TAUTHOR_TAG across language pairs'],['the strong transformer model  #TAUTHOR_TAG across language pairs. comparing'],['the strong transformer model  #TAUTHOR_TAG across language pairs. comparing'],"['', '##14 english - to - german, wmt17', 'chineseto - english, and wat17 japanese - to - english. experimental results demonstrate that our approach consistently improves', 'performance over the strong transformer model  #TAUTHOR_TAG across language pairs. comparing with previous work on modeling locality', 'for sans ( e. g.  #AUTHOR_TAG, our model boosts performance on both translation quality and training efficiency. 2 multi - head', 'self - attention networks sans produce representations by applying attention to each pair of tokens from the input sequence, regardless of their distance.  #AUTHOR_TAG found it is', 'beneficial to capture different contextual features with multiple individual attention functions. given an input sequence x = { x 1,', '']",0
"['head attention multi - head attention mechanism  #TAUTHOR_TAG employs different attention heads to capture distinct features  #AUTHOR_TAG.', 'along this']","['in both translation quality and training efficiency.', 'multi - head attention multi - head attention mechanism  #TAUTHOR_TAG employs different attention heads to capture distinct features  #AUTHOR_TAG.', 'along this direction,  #AUTHOR_TAG a ) explicitly used multiple attention heads']","['head attention multi - head attention mechanism  #TAUTHOR_TAG employs different attention heads to capture distinct features  #AUTHOR_TAG.', 'along this direction,  #AUTHOR_TAG a ) explicitly used multiple attention heads']","['', 'several researches proposed to revise the attention distribution with a parametric localness bias, and succeed on machine translation and natural language inference  #AUTHOR_TAG.', 'while both models introduce additional parameters, our approach is a more lightweight solution without introducing any new parameters.', 'closely related to this work,  #AUTHOR_TAG a ) applied a positional mask to encode temporal order, which only allows sans to attend to the previous or following tokens in the sequence.', 'in contrast, we employ a positional mask ( i. e. the tokens outside the local window is masked as 0 ) to encode the distance - aware local information.', 'in the context of distance - aware sa  #AUTHOR_TAG introduced relative position encoding to consider the relative distances between sequence elements.', 'while they modeled locality from position embedding, we improve locality modeling from revising attention scope.', 'to make a fair comparison, we re - implemented the above approaches under a same framework.', 'empirical results on machine translation tasks show the superiority of our approach in both translation quality and training efficiency.', 'multi - head attention multi - head attention mechanism  #TAUTHOR_TAG employs different attention heads to capture distinct features  #AUTHOR_TAG.', 'along this direction,  #AUTHOR_TAG a ) explicitly used multiple attention heads to model different dependencies of the same word pair, and  #AUTHOR_TAG employed different attention heads to capture different linguistic features.', ' #AUTHOR_TAG introduced disagreement regularizations to encourage the diversity among attention heads.', 'inspired by recent successes']",0
['the strong transformer model  #TAUTHOR_TAG across language pairs'],['the strong transformer model  #TAUTHOR_TAG across language pairs. comparing'],['the strong transformer model  #TAUTHOR_TAG across language pairs. comparing'],"['', '##14 english - to - german, wmt17', 'chineseto - english, and wat17 japanese - to - english. experimental results demonstrate that our approach consistently improves', 'performance over the strong transformer model  #TAUTHOR_TAG across language pairs. comparing with previous work on modeling locality', 'for sans ( e. g.  #AUTHOR_TAG, our model boosts performance on both translation quality and training efficiency. 2 multi - head', 'self - attention networks sans produce representations by applying attention to each pair of tokens from the input sequence, regardless of their distance.  #AUTHOR_TAG found it is', 'beneficial to capture different contextual features with multiple individual attention functions. given an input sequence x = { x 1,', '']",4
['conducted experiments with the transformer model  #TAUTHOR_TAG on'],"['conducted experiments with the transformer model  #TAUTHOR_TAG on english⇒german ( en⇒de ),']",['conducted experiments with the transformer model  #TAUTHOR_TAG on'],"['conducted experiments with the transformer model  #TAUTHOR_TAG on english⇒german ( en⇒de ), chinese⇒english ( zh⇒en ) and japanese⇒english ( ja⇒en ) translation tasks.', 'for the en⇒de and zh⇒en tasks, the models were trained on widely - used wmt14 and wmt17 corpora, consisting of around 4. 5 and 20. 62 million sentence pairs, respectively.', 'concerning ja⇒en, we used the first two sections of wat17 corpus as the training data, which consists of 2m sentence pairs.', 'to reduce the vocabulary size, all the data were tokenized and segmented into subword symbols using byte - pair encoding  #AUTHOR_TAG with 32k merge operations.', ' #AUTHOR_TAG, we incorporated the proposed model into the encoder, which is a stack of 6 san layers.', 'prior studies revealed that modeling locality in lower layers can achieve better performance  #AUTHOR_TAG b ;  #AUTHOR_TAG we applied our approach to the lowest three layers of the encoder.', 'about configurations of nmt models, we used the base and big settings same as  #TAUTHOR_TAG, and all models were trained on 8 nvidia p40 gpus with a batch of 4096 tokens']",5
['conducted experiments with the transformer model  #TAUTHOR_TAG on'],"['conducted experiments with the transformer model  #TAUTHOR_TAG on english⇒german ( en⇒de ),']",['conducted experiments with the transformer model  #TAUTHOR_TAG on'],"['conducted experiments with the transformer model  #TAUTHOR_TAG on english⇒german ( en⇒de ), chinese⇒english ( zh⇒en ) and japanese⇒english ( ja⇒en ) translation tasks.', 'for the en⇒de and zh⇒en tasks, the models were trained on widely - used wmt14 and wmt17 corpora, consisting of around 4. 5 and 20. 62 million sentence pairs, respectively.', 'concerning ja⇒en, we used the first two sections of wat17 corpus as the training data, which consists of 2m sentence pairs.', 'to reduce the vocabulary size, all the data were tokenized and segmented into subword symbols using byte - pair encoding  #AUTHOR_TAG with 32k merge operations.', ' #AUTHOR_TAG, we incorporated the proposed model into the encoder, which is a stack of 6 san layers.', 'prior studies revealed that modeling locality in lower layers can achieve better performance  #AUTHOR_TAG b ;  #AUTHOR_TAG we applied our approach to the lowest three layers of the encoder.', 'about configurations of nmt models, we used the base and big settings same as  #TAUTHOR_TAG, and all models were trained on 8 nvidia p40 gpus with a batch of 4096 tokens']",3
"['examination of word co - occurrences has proven to be a fruitful research paradigm.', 'for example,  #TAUTHOR_TAG utilize skipgram negativesampling ( sgns ) to train']","['examination of word co - occurrences has proven to be a fruitful research paradigm.', 'for example,  #TAUTHOR_TAG utilize skipgram negativesampling ( sgns ) to train']","[', traditional topic models over text do not take advantage of recent advances in distributed word representations which can capture semantically meaningful regularities between tokens.', 'the examination of word co - occurrences has proven to be a fruitful research paradigm.', 'for example,  #TAUTHOR_TAG utilize skipgram negativesampling ( sgns ) to train word embeddings using']","['models are popular for their ability to organize document collections into a smaller set of prominent themes.', 'in contrast to dense distributed representations, these document and topic representations are generally accessible to humans and more easily lend themselves to being interpreted.', 'this interpretability provides additional options to highlight the patterns and structures within our systems of documents.', 'for example, using latent dirichlet allocation ( lda ) topic models can reveal cluster of words within documents  #AUTHOR_TAG, highlight temporal trends  #AUTHOR_TAG, and infer networks of complementary products ( mc  #AUTHOR_TAG.', ' #AUTHOR_TAG for an overview of topic modelling in domains as diverse as computer vision, genetic markers, survey data, and social network data.', 'dense vector approaches to building document representations also exist :  #AUTHOR_TAG propose paragraph vectors that are predictive of bags of words within paragraphs,  #AUTHOR_TAG build vectors that reconstruct the sentence sequences before and after a given sentence, and  #AUTHOR_TAG construct contextual lstms that predict proceeding sentence features.', 'probabilistic topic models tend to form documents as a sparse mixed - membership of topics while neural network models tend to model documents as dense vectors.', 'by virtue of both their sparsity and low - dimensionality, representations from the former are simpler to inspect and more immediately yield high level intuitions about the underlying system ( although not without hazards, see  #AUTHOR_TAG ).', 'this paper explores hybrid approaches mixing sparse document representations with dense word and topic vectors.', 'unfortunately, crafting a new probabilistic topic model requires deriving a new approximation, a procedure which takes substantial expertise and must be customized to every model.', 'as a result, prototypes are time - consuming to develop and changes to model architectures must be carefully considered.', 'however, with modern automatic differentiation frameworks the practitioner can focus development time on the model design rather than the model approximations.', 'this expedites the process of evaluating which model features are relevant.', 'this work takes advantage of the chainer  #AUTHOR_TAG framework to quickly develop models while also enabling us to utilize gpus to dramatically improve computational speed.', 'finally, traditional topic models over text do not take advantage of recent advances in distributed word representations which can capture semantically meaningful regularities between tokens.', 'the examination of word co - occurrences has proven to be a fruitful research paradigm.', 'for example,  #TAUTHOR_TAG utilize skipgram negativesampling ( sgns ) to train word embeddings using word - context pairs formed from windows moving across a text corpus.', 'these vector representations ultimately encode remarkable linearities such as king − man + woman = queen.', 'in fact,  #AUTHOR_TAG c ) demonstrate that this is implicitly factorizing a variant of the pointwise mutual information ( pmi ) matrix that emphasizes predicting frequent co - occurrences over rare ones.', 'closely related']",0
"['.', ' #TAUTHOR_TAG provide the intuition that word vectors']","['vectors together, both spaces are effectively joined.', ' #TAUTHOR_TAG provide the intuition that word vectors']","['.', ' #TAUTHOR_TAG provide the intuition that word vectors']","['##2vec embeds both words and document vectors into the same space and trains both representations simultaneously.', 'by adding the pivot and document vectors together, both spaces are effectively joined.', ' #TAUTHOR_TAG provide the intuition that word vectors can be summed together to form a semantically meaningful combination of both words.', 'for example, the vector representation for germany + airline is similar to the vector for luf thansa.', 'we would like to exploit the additive property of word vectors to construct a meaningful sum of word and document vectors.', 'for example, if as lda2vec is scanning a document the jth word is germany, then neighboring words are predicted to be similar such as f rance, spain, and austria. but if the document is specifically about airlines, then we would like to construct a document vector similar to the word vector for airline.', 'then instead of predicting tokens similar to germany alone, predictions similar to both the document and the pivot word can be made such as : luf thansa, condor f lugdienst, and aero lloyd.', 'motivated by the meaningful sums of words vectors, in lda2vec the context vector is explicitly designed to be the sum of a document vector and a word vector as in ( 3 ) :', 'this models document - wide relationships by preserving d j for all word - context pairs in a document, while still leveraging local inter - word relationships stemming from the interaction between the pivot word vector w j and target word w i.', 'the document and word vectors are summed together to form a context vector that intuitively captures long - and short - term themes, respectively.', 'in order to prevent co - adaptation, we also perform dropout on both the unnormalized document vector d j and the pivot word vector w j  #AUTHOR_TAG']",0
"['model for lda2vec.', 'we are interested in modifying the skipgram negative - sampling ( sgns ) objective in  #TAUTHOR_TAG to utilize']","['model for lda2vec.', 'we are interested in modifying the skipgram negative - sampling ( sgns ) objective in  #TAUTHOR_TAG to utilize document - wide feature vectors while simultaneously learning continuous document weights loading onto topic vectors.', 'the network']","['section describes the model for lda2vec.', 'we are interested in modifying the skipgram negative - sampling ( sgns ) objective in  #TAUTHOR_TAG to utilize']","['section describes the model for lda2vec.', 'we are interested in modifying the skipgram negative - sampling ( sgns ) objective in  #TAUTHOR_TAG to utilize document - wide feature vectors while simultaneously learning continuous document weights loading onto topic vectors.', 'the network architecture is shown in figure 1.', 'the total loss term l in ( 1 ) is the sum of the skipgram negative sampling loss ( sgns ) l neg ij with the addition of a dirichlet - likelihood term over document weights, l d that will be discussed later.', 'the loss is conducted using a context vector, c j, pivot word vector w j, target word vector w i, and negatively - sampled word vector w l']",6
"['work demonstrates a simple model, lda2vec, that extends sgns  #TAUTHOR_TAG to build unsupervised']","['work demonstrates a simple model, lda2vec, that extends sgns  #TAUTHOR_TAG to build unsupervised']","['work demonstrates a simple model, lda2vec, that extends sgns  #TAUTHOR_TAG to build unsupervised document representations']","['work demonstrates a simple model, lda2vec, that extends sgns  #TAUTHOR_TAG to build unsupervised document representations that yield coherent topics.', 'word, topic, and document vectors are jointly trained and embedded in a common representation space that preserves semantic regularities between the learned word vectors while still yielding sparse and interpretable documentto - topic proportions in the style of lda  #AUTHOR_TAG.', 'topics formed in the twenty newsgroups corpus yield high mean topic coherences which have been shown to correlate with human evaluations of topics ( roder et al., 2015 ).', 'when applied to a hacker news comments corpus, lda2vec discovers the salient topics within this community and learns linear relationships between words that allow it solve word analogies in the specialized vocabulary of this corpus.', 'finally, we note that our method is simple to implement in automatic differentiation frameworks and can lead to more readily interpretable unsupervised representations']",6
"['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', '']","['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', '']","['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', '']","['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', 'for every pivot - target pair of words the pivot word is used to predict the nearby target word.', 'each word is represented with a fixedlength dense distributed - representation vector, but unlike  #TAUTHOR_TAG the same word vectors are used in both the pivot and target representations.', ""the sgns loss shown in ( 2 ) attempts to discriminate context - word pairs that appear in the corpus from those randomly sampled from a'negative'pool of words."", 'this loss is minimized when the observed words are completely separated from the marginal distribution.', 'the distribution from which tokens are drawn is u β, where u denotes the overall word frequency normalized by the total corpus size.', 'unless stated otherwise, the negative sampling power beta is set to 3 / 4 and the number of negative samples is fixed to n = 15 as in  #TAUTHOR_TAG.', 'note that a distribution of u 0. 0 would draw negative tokens from the vocabulary with no notion of popularity while a distribution proportional with u 1. 0 draws from the empirical unigram distribution.', 'compared to the unigram distribution, the choice of u 3 / 4 slightly emphasizes choosing infrequent words for negative samples.', ""in contrast to optimizing the softmax cross entropy, which requires modelling the overall popularity of each token, negative sampling focuses on learning word vectors conditional on a context by drawing negative samples from each token's marginal popularity in the corpus""]",5
"['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', '']","['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', '']","['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', '']","['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', 'for every pivot - target pair of words the pivot word is used to predict the nearby target word.', 'each word is represented with a fixedlength dense distributed - representation vector, but unlike  #TAUTHOR_TAG the same word vectors are used in both the pivot and target representations.', ""the sgns loss shown in ( 2 ) attempts to discriminate context - word pairs that appear in the corpus from those randomly sampled from a'negative'pool of words."", 'this loss is minimized when the observed words are completely separated from the marginal distribution.', 'the distribution from which tokens are drawn is u β, where u denotes the overall word frequency normalized by the total corpus size.', 'unless stated otherwise, the negative sampling power beta is set to 3 / 4 and the number of negative samples is fixed to n = 15 as in  #TAUTHOR_TAG.', 'note that a distribution of u 0. 0 would draw negative tokens from the vocabulary with no notion of popularity while a distribution proportional with u 1. 0 draws from the empirical unigram distribution.', 'compared to the unigram distribution, the choice of u 3 / 4 slightly emphasizes choosing infrequent words for negative samples.', ""in contrast to optimizing the softmax cross entropy, which requires modelling the overall popularity of each token, negative sampling focuses on learning word vectors conditional on a context by drawing negative samples from each token's marginal popularity in the corpus""]",5
"['values found in  #TAUTHOR_TAG but otherwise updates are allowed to these vectors at training time.', 'a']","['pretrained values found in  #TAUTHOR_TAG but otherwise updates are allowed to these vectors at training time.', 'a']","['values found in  #TAUTHOR_TAG but otherwise updates are allowed to these vectors at training time.', 'a range of lda2vec parameters are evaluated by varying the number of topics n ∈ 20,']","['section details experiments in discovering the salient topics in the twenty newsgroups dataset, a popular corpus for machine learning on text.', 'each document in the corpus was posted to one of twenty possible newsgroups.', 'while the text of each post is available to lda2vec, each of the newsgroup partitions is not revealed to the algorithm but is nevertheless useful for post - hoc qualitative evaluations of the discovered topics.', 'the corpus is preprocessed using the data loader available in scikit - learn  #AUTHOR_TAG and tokens are identified using the spacy parser  #AUTHOR_TAG.', 'words are lemmatized to group multiple inflections into single tokens.', 'tokens that occur fewer than ten times in the corpus are removed, as are tokens that appear to be urls, numbers or contain special symbols within their orthographic forms.', 'after preprocessing, the dataset contains 1. 8 million observations of 8, 946 unique tokens in 11, 313 documents.', 'word vectors are initialized to the pretrained values found in  #TAUTHOR_TAG but otherwise updates are allowed to these vectors at training time.', 'a range of lda2vec parameters are evaluated by varying the number of topics n ∈ 20, 30, 40, 50 and the negative sampling exponent β ∈ 0. 75, 1. 0.', 'the best topic coherences were achieved with n = 20 topics and with negative sampling power β = 0. 75 as summarized in figure 2.', 'we briefly experimented with variations on dropout ratios but we did not observe any substantial differences.', 'figure 3 lists four example topics discovered in the twenty newsgroups dataset.', 'each topic is associated with a topic vector that lives in the same space as the trained word vectors and listed are the most similar words to each topic vector.', ""the first topic shown has high similarity to the tokens astronomical, astronomy, satellite, planetary, and telescope and is thus likely a'space'- related topic similar to the'sci. space'newsgroup."", ""the second example topic is similar to words semantically related to'encryption ', such as clipper and encrypt, and is likely related to the'sci. crypt'newsgroup."", ""the third and four example topics are'x windows'and'middle east'which likely belong to the'comp. windows. x'and'talk. politics. mideast'newsgroups""]",5
"['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', '']","['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', '']","['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', '']","['in  #TAUTHOR_TAG, pairs of pivot and target words ( j, i ) are extracted when they cooccur in a moving window scanning across the corpus.', 'in our experiments, the window contains five tokens before and after the pivot token.', 'for every pivot - target pair of words the pivot word is used to predict the nearby target word.', 'each word is represented with a fixedlength dense distributed - representation vector, but unlike  #TAUTHOR_TAG the same word vectors are used in both the pivot and target representations.', ""the sgns loss shown in ( 2 ) attempts to discriminate context - word pairs that appear in the corpus from those randomly sampled from a'negative'pool of words."", 'this loss is minimized when the observed words are completely separated from the marginal distribution.', 'the distribution from which tokens are drawn is u β, where u denotes the overall word frequency normalized by the total corpus size.', 'unless stated otherwise, the negative sampling power beta is set to 3 / 4 and the number of negative samples is fixed to n = 15 as in  #TAUTHOR_TAG.', 'note that a distribution of u 0. 0 would draw negative tokens from the vocabulary with no notion of popularity while a distribution proportional with u 1. 0 draws from the empirical unigram distribution.', 'compared to the unigram distribution, the choice of u 3 / 4 slightly emphasizes choosing infrequent words for negative samples.', ""in contrast to optimizing the softmax cross entropy, which requires modelling the overall popularity of each token, negative sampling focuses on learning word vectors conditional on a context by drawing negative samples from each token's marginal popularity in the corpus""]",4
['as in sgns  #TAUTHOR_TAG but specialized to the'],"['as in sgns  #TAUTHOR_TAG but specialized to the hacker news corpus.', 'tokens similar to the token artificial sweeteners include other sugar - related tokens like fructose and food - related tokens']","['as in sgns  #TAUTHOR_TAG but specialized to the hacker news corpus.', 'tokens similar to the token artificial sweeteners include other sugar - related tokens like fructose and food - related tokens']","['', 'the first, which we figure 5 demonstrates that token similarities are learned in a similar fashion as in sgns  #TAUTHOR_TAG but specialized to the hacker news corpus.', 'tokens similar to the token artificial sweeteners include other sugar - related tokens like fructose and food - related tokens such as paleo diet.', 'tokens similar to black holes include physics - related concepts such as galaxies and dark matter.', 'the hacker news corpus devotes a substantial quantity of text to fonts and design, and the words most similar to comic sans are other popular fonts ( e. g. times new roman and helvetica ) as well as font - related concepts such as typeface and serif font.', 'tokens similar to functional programming demonstrate similarity to other computer science - related tokens while tokens similar to san francisco include other large american cities as well smaller cities located in the san francisco bay area.', 'figure 6 demonstrates that in addition to learning topics over documents and similarities to word tokens, linear regularities between tokens are also learned.', ""the'query'column lists a selection of tokens that when combined yield a token vector closest to the token shown in""]",3
"['same data  #TAUTHOR_TAG.', 'the paper is structured as follows : in the following']","['same data  #TAUTHOR_TAG.', 'the paper is structured as follows : in the following']","['on reference resolution applied to the same data  #TAUTHOR_TAG.', 'the paper is structured as follows : in the following section we discuss related work on incremental resolution of referring expressions.', 'we explain the model that we use in section 3 and the data we apply']","['', 'the model can also incorporate other modalities, such as gaze or pointing cues ( deixis ) incrementally.', 'we also model the saliency of the context, and show that the model can easily take such contextual information into account.', 'the model improves over previous work on reference resolution applied to the same data  #TAUTHOR_TAG.', 'the paper is structured as follows : in the following section we discuss related work on incremental resolution of referring expressions.', 'we explain the model that we use in section 3 and the data we apply it to in section 4.', 'we then describe the experiments and the results and provide a discussion']",4
['ling model presented in  #TAUTHOR_TAG'],"['the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG']",['ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had'],"['see figure 2 ). an object with a', 'centroid in the left - most section of the horizontal range received a left property, similarly middle and right properties were calculated for corresponding objects. for vertical placement, top, center and bottom properties were given to objects in the respective vertical segments. figure 2 shows an example', 'segmentation. each object had a vertical and a horizontal property at all times, however, moving an object could result in a change of one of these spatial properties as', 'the dialogue progressed. as an', 'example, compare figure 1, which is a snapshot of the interaction towards the beginning, and figure 2, which shows a later stage of the game board ;', 'spatial layout changes throughout the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had to do with reference recency : the most recently referred object received the referred x properties, if an object was referred to in the past', '5, 10, or 20 seconds. tasksp  #TAUTHOR_TAG used 14 task - specific features, three of which they found to be the most informative in their model. here, we will only use the two most informative features as properties ( the', '']",4
['ling model presented in  #TAUTHOR_TAG'],"['the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG']",['ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had'],"['see figure 2 ). an object with a', 'centroid in the left - most section of the horizontal range received a left property, similarly middle and right properties were calculated for corresponding objects. for vertical placement, top, center and bottom properties were given to objects in the respective vertical segments. figure 2 shows an example', 'segmentation. each object had a vertical and a horizontal property at all times, however, moving an object could result in a change of one of these spatial properties as', 'the dialogue progressed. as an', 'example, compare figure 1, which is a snapshot of the interaction towards the beginning, and figure 2, which shows a later stage of the game board ;', 'spatial layout changes throughout the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had to do with reference recency : the most recently referred object received the referred x properties, if an object was referred to in the past', '5, 10, or 20 seconds. tasksp  #TAUTHOR_TAG used 14 task - specific features, three of which they found to be the most informative in their model. here, we will only use the two most informative features as properties ( the', '']",4
['ling model presented in  #TAUTHOR_TAG'],"['the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG']",['ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had'],"['see figure 2 ). an object with a', 'centroid in the left - most section of the horizontal range received a left property, similarly middle and right properties were calculated for corresponding objects. for vertical placement, top, center and bottom properties were given to objects in the respective vertical segments. figure 2 shows an example', 'segmentation. each object had a vertical and a horizontal property at all times, however, moving an object could result in a change of one of these spatial properties as', 'the dialogue progressed. as an', 'example, compare figure 1, which is a snapshot of the interaction towards the beginning, and figure 2, which shows a later stage of the game board ;', 'spatial layout changes throughout the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had to do with reference recency : the most recently referred object received the referred x properties, if an object was referred to in the past', '5, 10, or 20 seconds. tasksp  #TAUTHOR_TAG used 14 task - specific features, three of which they found to be the most informative in their model. here, we will only use the two most informative features as properties ( the', '']",4
"['of  #TAUTHOR_TAG, and performs better than']","['of  #TAUTHOR_TAG, and performs better than']","['of  #TAUTHOR_TAG, and performs better than']","['of our evaluation are shown in figure 4.', 'the sium model performs better than the combined approach of  #TAUTHOR_TAG, and performs better than their separated model - when not including gaze ( there is a significant difference between sium and the separated models for ling + tasksp, though ( 2011 ) sium only got one more correct than the separated model ).', 'this is a welcome result, as it shows that our very simple incremental model that uses a basic classifier is comparable to a non - incremental approach that uses a more complicated classifier.', 'it further shows that the sium model is robust to using tasksp and gaze features as properties, as long as those features are available immediately before the re begins, or during the re.', 'the best - performing approach is the iida2011 - separated model with gaze.', 'this is the case for several reasons : first, their models use features that are not available to our incremental model ( e. g., their model uses 14 gaze features, some of which were based on the entire re, ours only uses 4 properties ).', 'second, and more importantly, separated models means less feature confusion : in  #TAUTHOR_TAG ( section 5. 2 ), the authors give a comparison of the most informative features for each model ; task and gaze features were prominent for the pronoun model, whereas gaze and language features were prominent for the non - pronoun model.', 'we also tested sium under separated conditions to better compare with the approaches presented here.', 'the separated models, however, did not improve.', 'this, we assume, is because the model grounds language with properties ( see discussion below ).', 'an interactive dialogue system might not have the luxury of choosing between two models at runtime.', ""we assume that a model that can sufficiently handle both 1 - 5 6 - 8 9 - 14 first correct ( % into re ) 35. 47 22. 34 14. 8 first final ( % into re ) 69. 0 49. 85 48. 0 edit overhead ( all lengths ) 0. 88 % never correct ( all lengths ) 5. 5 % types of utterances is to be preferred to one that doesn't."", 'table 6 shows how our model fares using the incremental metrics described earlier.', '( as this has not been done in  #TAUTHOR_TAG, direct comparison is not possible. ) for the evaluation, res are binned into short, normal, and long ( 1 - 5, 6 - 8, 9 - 14 characters, respectively, based on what the average numbers of words in res in this corpus is ), to make relative statements ( ""']",4
"['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', '']","['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', '']","['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', 'the re']","['. this represents a type of grounding  #AUTHOR_TAG. 4 in terms of the sium formalism,', 'the link between object and words is mediated by the properties the object has and by a stochastic process of associating words with properties. figure 6 visualises this : each word has a stochastic connection between each', 'property and objects have a set of properties.', 'the property names are arbitrary as long as they are consistent. in contrast, previous work in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', 'the re match that of a particular object. if so, a binary compatibility feature was set. figure 5 shows this', '; words can only link to objects via hand - crafte', '##d rules ( e. g., the word or fol predicate and property string must match ). by the way sium uses properties, it can also perform', '( exophoric ) pronoun resolution, deix', '##is ( the mouse pointer ) and definite descriptions, in a single framework. this is a nice feature of the model : adding additional modalities does not require model reformulation. incorporating saliency', 'information via a context model is also a nice feature of the model. in this paper, we computed the initial p ( i ) using a context model instantiated by sium. by', '']",4
"['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', '']","['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', '']","['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', 'the re']","['. this represents a type of grounding  #AUTHOR_TAG. 4 in terms of the sium formalism,', 'the link between object and words is mediated by the properties the object has and by a stochastic process of associating words with properties. figure 6 visualises this : each word has a stochastic connection between each', 'property and objects have a set of properties.', 'the property names are arbitrary as long as they are consistent. in contrast, previous work in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', 'the re match that of a particular object. if so, a binary compatibility feature was set. figure 5 shows this', '; words can only link to objects via hand - crafte', '##d rules ( e. g., the word or fol predicate and property string must match ). by the way sium uses properties, it can also perform', '( exophoric ) pronoun resolution, deix', '##is ( the mouse pointer ) and definite descriptions, in a single framework. this is a nice feature of the model : adding additional modalities does not require model reformulation. incorporating saliency', 'information via a context model is also a nice feature of the model. in this paper, we computed the initial p ( i ) using a context model instantiated by sium. by', '']",4
"['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', '']","['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', '']","['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', 'the re']","['. this represents a type of grounding  #AUTHOR_TAG. 4 in terms of the sium formalism,', 'the link between object and words is mediated by the properties the object has and by a stochastic process of associating words with properties. figure 6 visualises this : each word has a stochastic connection between each', 'property and objects have a set of properties.', 'the property names are arbitrary as long as they are consistent. in contrast, previous work in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', 'the re match that of a particular object. if so, a binary compatibility feature was set. figure 5 shows this', '; words can only link to objects via hand - crafte', '##d rules ( e. g., the word or fol predicate and property string must match ). by the way sium uses properties, it can also perform', '( exophoric ) pronoun resolution, deix', '##is ( the mouse pointer ) and definite descriptions, in a single framework. this is a nice feature of the model : adding additional modalities does not require model reformulation. incorporating saliency', 'information via a context model is also a nice feature of the model. in this paper, we computed the initial p ( i ) using a context model instantiated by sium. by', '']",4
"[', in human - human interactive puzzle tasks  #TAUTHOR_TAG, in']","[', in human - human interactive puzzle tasks  #TAUTHOR_TAG, in']","[', in human - human interactive puzzle tasks  #TAUTHOR_TAG, in web browsing ( hakkani - tur et al., 2014 ), and in a moving car where speakers']","['resolution ( rr ), which is the task of resolving referring expressions ( res ) to what they are intended to refer to, has been well - studied in various fields such as psychology  #AUTHOR_TAG tanenhaus and spivey -  #AUTHOR_TAG, linguistics  #AUTHOR_TAG, as well as human / human  #AUTHOR_TAG and human / machine interaction  #AUTHOR_TAG.', 'in recent years, multi - modal corpora have emerged which provide rr with important contextual information : collecting dialogue between two humans  #AUTHOR_TAG, between a human and a ( simulated ) dialogue system  #AUTHOR_TAG, with gaze, information about the shared environment, and in some cases deixis.', 'it has been shown that incorporating gaze improves rr in a situated setting because speakers need to look at and distinguish from distractors the objects they are describing : this has been shown in a static scene on a computer screen  #AUTHOR_TAG, in human - human interactive puzzle tasks  #TAUTHOR_TAG, in web browsing ( hakkani - tur et al., 2014 ), and in a moving car where speakers look at objects in their vicinity  #AUTHOR_TAG.', 'incorporating pointing ( deictic ) gestures is also potentially useful in situated rr ; as for example  #AUTHOR_TAG have shown in work on resolving objects processed by computer vision techniques.', ' #AUTHOR_TAG looked into reference in multi - modal settings, with focus on co - referential pronouns and pointing gestures.', 'however, these approaches were applied in settings in which communication between the two interlocutors was constrained, or the developed systems did not process incrementally.', ' #AUTHOR_TAG presented approach that focused more on interaction in a map task, though the model was not incremental, nor did grounding occur between language and world, as we do here.', 'incremental rr has also been studied in a number of papers, including a framework for fast incremental interpretation  #AUTHOR_TAG, a bayesian filtering model approach that was sensitive to disfluencies, a model that used markov logic networks to resolve objects on a screen, a model of rr and incremental feedback  #AUTHOR_TAG, and an approach that used a semantic representation to refer to objects  #AUTHOR_TAG.', 'however, the approaches reported there did not incorporate multi - modal information, were too slow to work in real - time, were evaluated on constrained data, or only focused on a specific type of rr, ignoring pronouns or deixis.', 'in this paper, we opted to use the model presented in, the simple incremental update model ( sium ).', 'it has been tested extensively against data from a puzzle - playing human / computer interaction domain ( the pento data, ) ; it can incorporate multi - modal information, works in real - time, and can resolve definite']",0
"['was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '']","['was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '']","['was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '. in']","['aimed to distinguish puzzle pieces ( and piece groups ) from each other. the following are some example res from the rex corpus :', ""( 1 ) a. chicchai sankakkei b. small triangle ( 2 ) a. sono ichiban migi ni shippo ni natte iru sankakkei b. that most right tail becoming triangle'that right - most triangle that is the tail'example ( 1 ) is a typical example of an re as found in the corpus. note that this at the same time constitutes the whole utterance, which hence"", 'can be classi - fied as a non - sentential utterance  #AUTHOR_TAG. its transliteration consists of 8 japanese characters, which could be tokenized into two words. the more difficult', 're shown in example ( 2 ) requires the model to learn how spatial placements map to certain descriptions. moreover, japanese is a head', '- final language where comparative landmark pieces are uttered before the referent. also, because this was a highly interactive setting, many exophoric pronouns were used, e.', 'g., sore and sono,', 'both meaning that. 2 pronoun references like this made up around 32 % of the utterances. corpus annotations included ( for both participants ) transcriptions of utterances, the object being looked at any given time, the object being pointed at or manipulated by the mouse, segmentation of the res and the corresponding referred object or objects. the spatial layout', 'of the board was recorded each time an object was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '. in order to directly compare our work with previous work,', 'in our evaluations below we consider the same annotated res.  #TAUTHOR_TAG applied a support vector machine - based ranking algorithm  #AUTHOR_TAG to the task of resolving res in this corpus. they used a total of 36 binary features in the svm classifier, which predicted the referred object. they further used a separate model for pronoun', 'utterances and non - pronoun utterances, allowing the classifier to learn patterns without confusing utterance', 'types. more details on the results of these models are given below. the siu - model has previously been applied to two datasets from the pent', ""##omino domain, where the speaker's goal was to identify one out of a set of"", 'tetris - like ( but consisting of five instead of four blocks ) puzzle pieces. however, in these datasets, the', 'references were "" one - shot "" and not embedded in longer dialogues, as is the case in the', 'rex corpus. a summary of differences between the two tasks is summarised']",0
"['was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '']","['was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '']","['was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '. in']","['aimed to distinguish puzzle pieces ( and piece groups ) from each other. the following are some example res from the rex corpus :', ""( 1 ) a. chicchai sankakkei b. small triangle ( 2 ) a. sono ichiban migi ni shippo ni natte iru sankakkei b. that most right tail becoming triangle'that right - most triangle that is the tail'example ( 1 ) is a typical example of an re as found in the corpus. note that this at the same time constitutes the whole utterance, which hence"", 'can be classi - fied as a non - sentential utterance  #AUTHOR_TAG. its transliteration consists of 8 japanese characters, which could be tokenized into two words. the more difficult', 're shown in example ( 2 ) requires the model to learn how spatial placements map to certain descriptions. moreover, japanese is a head', '- final language where comparative landmark pieces are uttered before the referent. also, because this was a highly interactive setting, many exophoric pronouns were used, e.', 'g., sore and sono,', 'both meaning that. 2 pronoun references like this made up around 32 % of the utterances. corpus annotations included ( for both participants ) transcriptions of utterances, the object being looked at any given time, the object being pointed at or manipulated by the mouse, segmentation of the res and the corresponding referred object or objects. the spatial layout', 'of the board was recorded each time an object was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '. in order to directly compare our work with previous work,', 'in our evaluations below we consider the same annotated res.  #TAUTHOR_TAG applied a support vector machine - based ranking algorithm  #AUTHOR_TAG to the task of resolving res in this corpus. they used a total of 36 binary features in the svm classifier, which predicted the referred object. they further used a separate model for pronoun', 'utterances and non - pronoun utterances, allowing the classifier to learn patterns without confusing utterance', 'types. more details on the results of these models are given below. the siu - model has previously been applied to two datasets from the pent', ""##omino domain, where the speaker's goal was to identify one out of a set of"", 'tetris - like ( but consisting of five instead of four blocks ) puzzle pieces. however, in these datasets, the', 'references were "" one - shot "" and not embedded in longer dialogues, as is the case in the', 'rex corpus. a summary of differences between the two tasks is summarised']",0
['ling model presented in  #TAUTHOR_TAG'],"['the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG']",['ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had'],"['see figure 2 ). an object with a', 'centroid in the left - most section of the horizontal range received a left property, similarly middle and right properties were calculated for corresponding objects. for vertical placement, top, center and bottom properties were given to objects in the respective vertical segments. figure 2 shows an example', 'segmentation. each object had a vertical and a horizontal property at all times, however, moving an object could result in a change of one of these spatial properties as', 'the dialogue progressed. as an', 'example, compare figure 1, which is a snapshot of the interaction towards the beginning, and figure 2, which shows a later stage of the game board ;', 'spatial layout changes throughout the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had to do with reference recency : the most recently referred object received the referred x properties, if an object was referred to in the past', '5, 10, or 20 seconds. tasksp  #TAUTHOR_TAG used 14 task - specific features, three of which they found to be the most informative in their model. here, we will only use the two most informative features as properties ( the', '']",0
"['of  #TAUTHOR_TAG, and performs better than']","['of  #TAUTHOR_TAG, and performs better than']","['of  #TAUTHOR_TAG, and performs better than']","['of our evaluation are shown in figure 4.', 'the sium model performs better than the combined approach of  #TAUTHOR_TAG, and performs better than their separated model - when not including gaze ( there is a significant difference between sium and the separated models for ling + tasksp, though ( 2011 ) sium only got one more correct than the separated model ).', 'this is a welcome result, as it shows that our very simple incremental model that uses a basic classifier is comparable to a non - incremental approach that uses a more complicated classifier.', 'it further shows that the sium model is robust to using tasksp and gaze features as properties, as long as those features are available immediately before the re begins, or during the re.', 'the best - performing approach is the iida2011 - separated model with gaze.', 'this is the case for several reasons : first, their models use features that are not available to our incremental model ( e. g., their model uses 14 gaze features, some of which were based on the entire re, ours only uses 4 properties ).', 'second, and more importantly, separated models means less feature confusion : in  #TAUTHOR_TAG ( section 5. 2 ), the authors give a comparison of the most informative features for each model ; task and gaze features were prominent for the pronoun model, whereas gaze and language features were prominent for the non - pronoun model.', 'we also tested sium under separated conditions to better compare with the approaches presented here.', 'the separated models, however, did not improve.', 'this, we assume, is because the model grounds language with properties ( see discussion below ).', 'an interactive dialogue system might not have the luxury of choosing between two models at runtime.', ""we assume that a model that can sufficiently handle both 1 - 5 6 - 8 9 - 14 first correct ( % into re ) 35. 47 22. 34 14. 8 first final ( % into re ) 69. 0 49. 85 48. 0 edit overhead ( all lengths ) 0. 88 % never correct ( all lengths ) 5. 5 % types of utterances is to be preferred to one that doesn't."", 'table 6 shows how our model fares using the incremental metrics described earlier.', '( as this has not been done in  #TAUTHOR_TAG, direct comparison is not possible. ) for the evaluation, res are binned into short, normal, and long ( 1 - 5, 6 - 8, 9 - 14 characters, respectively, based on what the average numbers of words in res in this corpus is ), to make relative statements ( ""']",0
"['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', '']","['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', '']","['in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', 'the re']","['. this represents a type of grounding  #AUTHOR_TAG. 4 in terms of the sium formalism,', 'the link between object and words is mediated by the properties the object has and by a stochastic process of associating words with properties. figure 6 visualises this : each word has a stochastic connection between each', 'property and objects have a set of properties.', 'the property names are arbitrary as long as they are consistent. in contrast, previous work in rr  #TAUTHOR_TAG used a hand - coded concept - labeled semantic representation and checked if aspects of', 'the re match that of a particular object. if so, a binary compatibility feature was set. figure 5 shows this', '; words can only link to objects via hand - crafte', '##d rules ( e. g., the word or fol predicate and property string must match ). by the way sium uses properties, it can also perform', '( exophoric ) pronoun resolution, deix', '##is ( the mouse pointer ) and definite descriptions, in a single framework. this is a nice feature of the model : adding additional modalities does not require model reformulation. incorporating saliency', 'information via a context model is also a nice feature of the model. in this paper, we computed the initial p ( i ) using a context model instantiated by sium. by', '']",0
"['was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '']","['was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '']","['was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '. in']","['aimed to distinguish puzzle pieces ( and piece groups ) from each other. the following are some example res from the rex corpus :', ""( 1 ) a. chicchai sankakkei b. small triangle ( 2 ) a. sono ichiban migi ni shippo ni natte iru sankakkei b. that most right tail becoming triangle'that right - most triangle that is the tail'example ( 1 ) is a typical example of an re as found in the corpus. note that this at the same time constitutes the whole utterance, which hence"", 'can be classi - fied as a non - sentential utterance  #AUTHOR_TAG. its transliteration consists of 8 japanese characters, which could be tokenized into two words. the more difficult', 're shown in example ( 2 ) requires the model to learn how spatial placements map to certain descriptions. moreover, japanese is a head', '- final language where comparative landmark pieces are uttered before the referent. also, because this was a highly interactive setting, many exophoric pronouns were used, e.', 'g., sore and sono,', 'both meaning that. 2 pronoun references like this made up around 32 % of the utterances. corpus annotations included ( for both participants ) transcriptions of utterances, the object being looked at any given time, the object being pointed at or manipulated by the mouse, segmentation of the res and the corresponding referred object or objects. the spatial layout', 'of the board was recorded each time an object was manipulated. further details of the corpus can be found in  #TAUTHOR_TAG', '. in order to directly compare our work with previous work,', 'in our evaluations below we consider the same annotated res.  #TAUTHOR_TAG applied a support vector machine - based ranking algorithm  #AUTHOR_TAG to the task of resolving res in this corpus. they used a total of 36 binary features in the svm classifier, which predicted the referred object. they further used a separate model for pronoun', 'utterances and non - pronoun utterances, allowing the classifier to learn patterns without confusing utterance', 'types. more details on the results of these models are given below. the siu - model has previously been applied to two datasets from the pent', ""##omino domain, where the speaker's goal was to identify one out of a set of"", 'tetris - like ( but consisting of five instead of four blocks ) puzzle pieces. however, in these datasets, the', 'references were "" one - shot "" and not embedded in longer dialogues, as is the case in the', 'rex corpus. a summary of differences between the two tasks is summarised']",5
['ling model presented in  #TAUTHOR_TAG'],"['the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG']",['ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had'],"['see figure 2 ). an object with a', 'centroid in the left - most section of the horizontal range received a left property, similarly middle and right properties were calculated for corresponding objects. for vertical placement, top, center and bottom properties were given to objects in the respective vertical segments. figure 2 shows an example', 'segmentation. each object had a vertical and a horizontal property at all times, however, moving an object could result in a change of one of these spatial properties as', 'the dialogue progressed. as an', 'example, compare figure 1, which is a snapshot of the interaction towards the beginning, and figure 2, which shows a later stage of the game board ;', 'spatial layout changes throughout the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had to do with reference recency : the most recently referred object received the referred x properties, if an object was referred to in the past', '5, 10, or 20 seconds. tasksp  #TAUTHOR_TAG used 14 task - specific features, three of which they found to be the most informative in their model. here, we will only use the two most informative features as properties ( the', '']",5
"['going', 'beyond  #TAUTHOR_TAG, our']","['). going', 'beyond  #TAUTHOR_TAG, our']","['going', 'beyond  #TAUTHOR_TAG, our']","['', 'moved object and the mouse pointer was still over it. however, initial prior information alone is not enough to resolve the intended object ; for that the re is needed. after the word small is uttered, 1 is the most likely referred object. after triangle, 1 remains the highest in the distribution. with the', 're alone, in this case there would have been enough information to infer that 1 was', 'the referred object, but adding the prior information provided additional evidence.. 162 table 5 : application of re small triangle, where 1 is the referred object evaluation metrics we report results of our evaluation in referential accuracy on utterances', 'that were annotated as referring to a single object ( references to group objects is left for future work ). going', 'beyond  #TAUTHOR_TAG, our model computes a resolution hypothesis incrementally ; for the performance of', '']",5
['ling model presented in  #TAUTHOR_TAG'],"['the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG']",['ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had'],"['see figure 2 ). an object with a', 'centroid in the left - most section of the horizontal range received a left property, similarly middle and right properties were calculated for corresponding objects. for vertical placement, top, center and bottom properties were given to objects in the respective vertical segments. figure 2 shows an example', 'segmentation. each object had a vertical and a horizontal property at all times, however, moving an object could result in a change of one of these spatial properties as', 'the dialogue progressed. as an', 'example, compare figure 1, which is a snapshot of the interaction towards the beginning, and figure 2, which shows a later stage of the game board ;', 'spatial layout changes throughout the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had to do with reference recency : the most recently referred object received the referred x properties, if an object was referred to in the past', '5, 10, or 20 seconds. tasksp  #TAUTHOR_TAG used 14 task - specific features, three of which they found to be the most informative in their model. here, we will only use the two most informative features as properties ( the', '']",3
['ling model presented in  #TAUTHOR_TAG'],"['the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG']",['ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had'],"['see figure 2 ). an object with a', 'centroid in the left - most section of the horizontal range received a left property, similarly middle and right properties were calculated for corresponding objects. for vertical placement, top, center and bottom properties were given to objects in the respective vertical segments. figure 2 shows an example', 'segmentation. each object had a vertical and a horizontal property at all times, however, moving an object could result in a change of one of these spatial properties as', 'the dialogue progressed. as an', 'example, compare figure 1, which is a snapshot of the interaction towards the beginning, and figure 2, which shows a later stage of the game board ;', 'spatial layout changes throughout the dialogue. these properties differ somewhat from the features for', 'the ling model presented in  #TAUTHOR_TAG. three features that we did use as properties had to do with reference recency : the most recently referred object received the referred x properties, if an object was referred to in the past', '5, 10, or 20 seconds. tasksp  #TAUTHOR_TAG used 14 task - specific features, three of which they found to be the most informative in their model. here, we will only use the two most informative features as properties ( the', '']",3
"['going', 'beyond  #TAUTHOR_TAG, our']","['). going', 'beyond  #TAUTHOR_TAG, our']","['going', 'beyond  #TAUTHOR_TAG, our']","['', 'moved object and the mouse pointer was still over it. however, initial prior information alone is not enough to resolve the intended object ; for that the re is needed. after the word small is uttered, 1 is the most likely referred object. after triangle, 1 remains the highest in the distribution. with the', 're alone, in this case there would have been enough information to infer that 1 was', 'the referred object, but adding the prior information provided additional evidence.. 162 table 5 : application of re small triangle, where 1 is the referred object evaluation metrics we report results of our evaluation in referential accuracy on utterances', 'that were annotated as referring to a single object ( references to group objects is left for future work ). going', 'beyond  #TAUTHOR_TAG, our model computes a resolution hypothesis incrementally ; for the performance of', '']",6
"['of  #TAUTHOR_TAG, and performs better than']","['of  #TAUTHOR_TAG, and performs better than']","['of  #TAUTHOR_TAG, and performs better than']","['of our evaluation are shown in figure 4.', 'the sium model performs better than the combined approach of  #TAUTHOR_TAG, and performs better than their separated model - when not including gaze ( there is a significant difference between sium and the separated models for ling + tasksp, though ( 2011 ) sium only got one more correct than the separated model ).', 'this is a welcome result, as it shows that our very simple incremental model that uses a basic classifier is comparable to a non - incremental approach that uses a more complicated classifier.', 'it further shows that the sium model is robust to using tasksp and gaze features as properties, as long as those features are available immediately before the re begins, or during the re.', 'the best - performing approach is the iida2011 - separated model with gaze.', 'this is the case for several reasons : first, their models use features that are not available to our incremental model ( e. g., their model uses 14 gaze features, some of which were based on the entire re, ours only uses 4 properties ).', 'second, and more importantly, separated models means less feature confusion : in  #TAUTHOR_TAG ( section 5. 2 ), the authors give a comparison of the most informative features for each model ; task and gaze features were prominent for the pronoun model, whereas gaze and language features were prominent for the non - pronoun model.', 'we also tested sium under separated conditions to better compare with the approaches presented here.', 'the separated models, however, did not improve.', 'this, we assume, is because the model grounds language with properties ( see discussion below ).', 'an interactive dialogue system might not have the luxury of choosing between two models at runtime.', ""we assume that a model that can sufficiently handle both 1 - 5 6 - 8 9 - 14 first correct ( % into re ) 35. 47 22. 34 14. 8 first final ( % into re ) 69. 0 49. 85 48. 0 edit overhead ( all lengths ) 0. 88 % never correct ( all lengths ) 5. 5 % types of utterances is to be preferred to one that doesn't."", 'table 6 shows how our model fares using the incremental metrics described earlier.', '( as this has not been done in  #TAUTHOR_TAG, direct comparison is not possible. ) for the evaluation, res are binned into short, normal, and long ( 1 - 5, 6 - 8, 9 - 14 characters, respectively, based on what the average numbers of words in res in this corpus is ), to make relative statements ( ""']",7
"['from heterogeneous collections.', 'following  #TAUTHOR_TAG documents differ systematically']","['from heterogeneous collections.', 'following  #TAUTHOR_TAG documents differ systematically']","['from heterogeneous collections.', 'following  #TAUTHOR_TAG documents differ systematically']","['present a simple and efficient unsupervised method for pairwise matching of documents from heterogeneous collections.', 'following  #TAUTHOR_TAG documents differ systematically with respect to vocabulary and / or level of abstraction.', 'with these defining differences, there often also comes a difference in length, which, however, by itself does not make document collections heterogeneous.', 'examples include collections in which expert answers are mapped to non - expert questions ( e. g. insuranceqa by  #AUTHOR_TAG ), but also so - called community qa collections (  #AUTHOR_TAG ), where the lexical mismatch between q and a documents is often less pronounced than the length difference.', 'like many other approaches, the proposed method is based on word embeddings as universal meaning representations, and on vector cosine as the similarity metric.', 'however, instead of computing pairs of document representations and measuring their similarity, our method assesses the document - pair similarity on the basis of selected pairwise word similarities.', 'this has the following advantages, which make our method a viable candidate for practical, real - world applications : efficiency, because pairwise word similarities can be efficiently ( pre - ) computed and cached, and transparency, because the selected words from each document are available as evidence for what the similarity computation was based on.', 'we demonstrate our method with the concept - project matching task  #TAUTHOR_TAG, which is described in the next section']",1
"['). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches""]","['). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches""]","['##apeake bay. the publicly available data set 3 contains 510 labelled pairs 4 involving c =', '75 unique concepts and p = 230 unique projects. a pair is annotated as 1 if the project matches the', 'concept ( 57 % ), and as 0 otherwise ( 43 % ). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches""]","['', 'forming in your area? for an experiment that studies the relationship between water quality and algal bloom events, see the science buddie', '##s project harmful algal blooms in the chesapeake bay. the publicly available data set 3 contains 510 labelled pairs 4 involving c =', '75 unique concepts and p = 230 unique projects. a pair is annotated as 1 if the project matches the', 'concept ( 57 % ), and as 0 otherwise ( 43 % ). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches'relation to be annotated. instead,  #TAUTHOR_TAG create gold standard annotations based on a majority vote of three manual annotations. figure 1"", 'provides an example of a matching c - p pair. the concept labels can be very specific, potentially introducing vocabulary that', 'is not present in the actual concept descriptions. the extent to which this information is used by  #TAUTHOR_TAG is not entirely clear, so we', 'experiment with several setups ( cf. section 4 )']",1
['semantic matching of documents from heterogeneous collections as a solution to the concept - project matching task by  #TAUTHOR_TAG'],['semantic matching of documents from heterogeneous collections as a solution to the concept - project matching task by  #TAUTHOR_TAG'],"['semantic matching of documents from heterogeneous collections as a solution to the concept - project matching task by  #TAUTHOR_TAG.', 'although much simpler, our method clearly outperform']","['presented a simple method for semantic matching of documents from heterogeneous collections as a solution to the concept - project matching task by  #TAUTHOR_TAG.', 'although much simpler, our method clearly outperformed the original system in most input settings.', '']",1
"['from heterogeneous collections.', 'following  #TAUTHOR_TAG documents differ systematically']","['from heterogeneous collections.', 'following  #TAUTHOR_TAG documents differ systematically']","['from heterogeneous collections.', 'following  #TAUTHOR_TAG documents differ systematically']","['present a simple and efficient unsupervised method for pairwise matching of documents from heterogeneous collections.', 'following  #TAUTHOR_TAG documents differ systematically with respect to vocabulary and / or level of abstraction.', 'with these defining differences, there often also comes a difference in length, which, however, by itself does not make document collections heterogeneous.', 'examples include collections in which expert answers are mapped to non - expert questions ( e. g. insuranceqa by  #AUTHOR_TAG ), but also so - called community qa collections (  #AUTHOR_TAG ), where the lexical mismatch between q and a documents is often less pronounced than the length difference.', 'like many other approaches, the proposed method is based on word embeddings as universal meaning representations, and on vector cosine as the similarity metric.', 'however, instead of computing pairs of document representations and measuring their similarity, our method assesses the document - pair similarity on the basis of selected pairwise word similarities.', 'this has the following advantages, which make our method a viable candidate for practical, real - world applications : efficiency, because pairwise word similarities can be efficiently ( pre - ) computed and cached, and transparency, because the selected words from each document are available as evidence for what the similarity computation was based on.', 'we demonstrate our method with the concept - project matching task  #TAUTHOR_TAG, which is described in the next section']",5
"['). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches""]","['). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches""]","['##apeake bay. the publicly available data set 3 contains 510 labelled pairs 4 involving c =', '75 unique concepts and p = 230 unique projects. a pair is annotated as 1 if the project matches the', 'concept ( 57 % ), and as 0 otherwise ( 43 % ). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches""]","['', 'forming in your area? for an experiment that studies the relationship between water quality and algal bloom events, see the science buddie', '##s project harmful algal blooms in the chesapeake bay. the publicly available data set 3 contains 510 labelled pairs 4 involving c =', '75 unique concepts and p = 230 unique projects. a pair is annotated as 1 if the project matches the', 'concept ( 57 % ), and as 0 otherwise ( 43 % ). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches'relation to be annotated. instead,  #TAUTHOR_TAG create gold standard annotations based on a majority vote of three manual annotations. figure 1"", 'provides an example of a matching c - p pair. the concept labels can be very specific, potentially introducing vocabulary that', 'is not present in the actual concept descriptions. the extent to which this information is used by  #TAUTHOR_TAG is not entirely clear, so we', 'experiment with several setups ( cf. section 4 )']",7
"['). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches""]","['). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches""]","['##apeake bay. the publicly available data set 3 contains 510 labelled pairs 4 involving c =', '75 unique concepts and p = 230 unique projects. a pair is annotated as 1 if the project matches the', 'concept ( 57 % ), and as 0 otherwise ( 43 % ). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches""]","['', 'forming in your area? for an experiment that studies the relationship between water quality and algal bloom events, see the science buddie', '##s project harmful algal blooms in the chesapeake bay. the publicly available data set 3 contains 510 labelled pairs 4 involving c =', '75 unique concepts and p = 230 unique projects. a pair is annotated as 1 if the project matches the', 'concept ( 57 % ), and as 0 otherwise ( 43 % ). the annotation was done by undergrad engineering', 'students.  #TAUTHOR_TAG do not provide any specification, or annotation guidelines', "", of the semantics of the'matches'relation to be annotated. instead,  #TAUTHOR_TAG create gold standard annotations based on a majority vote of three manual annotations. figure 1"", 'provides an example of a matching c - p pair. the concept labels can be very specific, potentially introducing vocabulary that', 'is not present in the actual concept descriptions. the extent to which this information is used by  #TAUTHOR_TAG is not entirely clear, so we', 'experiment with several setups ( cf. section 4 )']",6
['approach by  #TAUTHOR_TAG is based on the idea that the longer'],['approach by  #TAUTHOR_TAG is based on the idea that the longer'],"['approach by  #TAUTHOR_TAG is based on the idea that the longer document in the pair is reduced to a set of topics which capture the essence of the document in a way that eliminates the effect of a potential length difference.', 'in order to overcome the vocabulary mismatch, these topics are not']","['approach by  #TAUTHOR_TAG is based on the idea that the longer document in the pair is reduced to a set of topics which capture the essence of the document in a way that eliminates the effect of a potential length difference.', 'in order to overcome the vocabulary mismatch, these topics are not based on words and their distributions ( as in lsi (  #AUTHOR_TAG ) or lda (  #AUTHOR_TAG ) ), but on word embedding vectors.', 'then, basically, matching is done by measuring the cosine similarity between the topic vectors and the short document words.', ' #TAUTHOR_TAG claim makes approaches relying on document representations ( incl. vector averaging ) unsuitable.', 'accordingly,  #TAUTHOR_TAG method.', ' #TAUTHOR_TAG do not, however, provide a much simpler averaging - based baseline.', 'as a second baseline,  #TAUTHOR_TAG topic - based method.', ' #TAUTHOR_TAG use two different sets of word embeddings : one ( topic wiki ) was trained on a full english wikipedia dump, the other ( wiki science ) on a smaller subset of the former dump which only contained science articles.', 'the similarity of two documents ( i. e. word sequences ) c and p is to average over the word embeddings for each sequence first, and to compute the cosine similarity between the two averages afterwards.', 'in the first step, weighting can be applied by multiplying a vector with the tf, idf, or tf * idf score of its pertaining word.', 'we implement this standard measure ( avg cos sim ) as a baseline for both our method and for the method by  #TAUTHOR_TAG.', 'it yields a single scalar similarity score.', 'the core idea of our alternative method is to turn the above process upside down, by computing the cosine similarity of selected pairs of words from c and p first, and to average over the similarity scores afterwards ( cf. also section 6 ).', 'more precisely, we implement a measure top n cos sim avg as the average of the n highest pairwise cosine similarities of the n top - ranking words in c and p. ranking, again, is done by tf, idf, and tf * idf.', 'for each ranking, we take the top - ranking n words from c and p, compute n × n similarities, rank by decreasing similarity, and average over the top n similarities.', 'this measure yields both a scalar similarity score and a list of < c x, p y, sim > tuples, which represent the qualitative aspects of c and p on which the similarity score is based']",6
"['split used by  #TAUTHOR_TAG settings, but we also']","['', 'since the original data split used by  #TAUTHOR_TAG settings, but we also']","['split used by  #TAUTHOR_TAG settings, but we also perform ten runs using randomly selected']","['', 'idf weighting and the most informative input. we', 'then selected the best performing parameter settings for every concept input and ran experiments on the held - out test data.', 'since the original data split used by  #TAUTHOR_TAG settings, but we also perform ten runs using randomly selected 10 % of our 408 instances test data set,', '']",3
"['split used by  #TAUTHOR_TAG settings, but we also']","['', 'since the original data split used by  #TAUTHOR_TAG settings, but we also']","['split used by  #TAUTHOR_TAG settings, but we also perform ten runs using randomly selected']","['', 'idf weighting and the most informative input. we', 'then selected the best performing parameter settings for every concept input and ran experiments on the held - out test data.', 'since the original data split used by  #TAUTHOR_TAG settings, but we also perform ten runs using randomly selected 10 % of our 408 instances test data set,', '']",3
"['in twitter sentiment classification  #TAUTHOR_TAG.', 'in this']","['in twitter sentiment classification  #TAUTHOR_TAG.', 'in this work, the word2vec technique on']","['as concept features for classification.', 'an important advance in this area is the development of the word2vec technique [ 4 ], which has proved to be an effective approach in twitter sentiment classification  #TAUTHOR_TAG.', 'in this work, the word2vec technique on']","['', 'citation sentence examples 1 with different sentiment polarity are shown in table 1.', 'sentiment analysis of citations plays an important role in plotting scientific idea flow.', 'i can see from paper a0 is hidden markov model ( hmm ) based part - of - speech ( pos ) tagging, which has been referenced positively in paper a1.', 'in paper a2, however, a better approach was brought up making the idea ( hmm based pos ) in paper a0 negative.', 'this citation sentiment analysis could lead to future - works in such a way that new approaches ( mentioned in paper a2 ) are recommended to other papers which cited a0 positively 2.', 'analyzing citation sentences during literature review is time consuming.', 'recently, researchers developed algorithms to automatically analyze citation sentiment.', 'for example, [ 1 ] extracted several features for citation purpose and polarity classification, such as reference count, contrary expression and dependency relations.', 'jochim et al. tried to improve the result by using unigram and bigram features [ 2 ].', '[ 3 ] used word level features, contextual polarity features, and sentence structure based features to detect sentiment citations.', 'although they generated good results using the combination of features, it required a lot of engineering work and big amount of annotated data to obtain the features.', 'further more, capturing accurate features relies on other nlp techniques, such as part - of - speech tagging ( pos ) and sentence parsing.', 'therefore, it is necessary to explore other techniques that are free from hand - crafted features.', 'with the development of neural networks and deep learning, it is possible to learn the representations of concepts from unlabeled text corpus automatically.', 'these representations can be treated as concept features for classification.', 'an important advance in this area is the development of the word2vec technique [ 4 ], which has proved to be an effective approach in twitter sentiment classification  #TAUTHOR_TAG.', 'in this work, the word2vec technique on sentiment analysis of citations was explored.', 'word embeddings trained from different corpora were compared']",0
"[' #TAUTHOR_TAG 8, 9 ] and text']","[' #TAUTHOR_TAG 8, 9 ] and text']","['of sentiment analysis  #TAUTHOR_TAG 8, 9 ] and text classification [ 10 ].', 'sadeghian and sharafat [ 11 ] extended word embeddings to sentence embeddings by averaging the word vectors in a sentiment review statement.', '']","['##olov et al. introduced word2vec technique [ 4 ] that can obtain word vectors by training text corpus.', 'the idea of word2vec ( word embeddings ) originated from the concept of distributed representation of words [ 6 ].', 'the common method to derive the vectors is using neural probabilistic language model [ 7 ].', 'word embeddings proved to be effective representations in the tasks of sentiment analysis  #TAUTHOR_TAG 8, 9 ] and text classification [ 10 ].', 'sadeghian and sharafat [ 11 ] extended word embeddings to sentence embeddings by averaging the word vectors in a sentiment review statement.', '']",0
"[' #TAUTHOR_TAG 8, 9 ] and text']","[' #TAUTHOR_TAG 8, 9 ] and text']","['of sentiment analysis  #TAUTHOR_TAG 8, 9 ] and text classification [ 10 ].', 'sadeghian and sharafat [ 11 ] extended word embeddings to sentence embeddings by averaging the word vectors in a sentiment review statement.', '']","['##olov et al. introduced word2vec technique [ 4 ] that can obtain word vectors by training text corpus.', 'the idea of word2vec ( word embeddings ) originated from the concept of distributed representation of words [ 6 ].', 'the common method to derive the vectors is using neural probabilistic language model [ 7 ].', 'word embeddings proved to be effective representations in the tasks of sentiment analysis  #TAUTHOR_TAG 8, 9 ] and text classification [ 10 ].', 'sadeghian and sharafat [ 11 ] extended word embeddings to sentence embeddings by averaging the word vectors in a sentiment review statement.', '']",5
"['improve sentiment citation classification results, i trained polarity specific word embeddings ( ps - embeddings ), which were inspired by the sentiment - specific word embedding  #TAUTHOR_TAG.', 'after obtaining the ps - embeddings, i used the same scheme']","['improve sentiment citation classification results, i trained polarity specific word embeddings ( ps - embeddings ), which were inspired by the sentiment - specific word embedding  #TAUTHOR_TAG.', 'after obtaining the ps - embeddings, i used the same scheme']","['improve sentiment citation classification results, i trained polarity specific word embeddings ( ps - embeddings ), which were inspired by the sentiment - specific word embedding  #TAUTHOR_TAG.', 'after obtaining the ps - embeddings, i used the same scheme']","['improve sentiment citation classification results, i trained polarity specific word embeddings ( ps - embeddings ), which were inspired by the sentiment - specific word embedding  #TAUTHOR_TAG.', 'after obtaining the ps - embeddings, i used the same scheme to average the vectors in one sentence according to the sent2vec model']",5
"['in the paper of  #TAUTHOR_TAG, where they concluded that sentiment specific word embeddings performed best, integrating polarity information did not']","['in the paper of  #TAUTHOR_TAG, where they concluded that sentiment specific word embeddings performed best, integrating polarity information did not']","['positive and negative citations.', 'however, unlike the outcomes in the paper of  #TAUTHOR_TAG, where they concluded that sentiment specific word embeddings performed best, integrating polarity information did not']","['', 'however, the higher micro - f score ( the highest micro - f in this work is 0. 88, theirs is 0. 78 ) and the weighted - f scores indicated that this method may achieve better performances if the evaluations are conducted on a balanced dataset.', 'among the embeddings, acl - embeddings performed better than brown corpus in terms of macro - f and weighted - f measurements 12.', 'to compare the dimensionality of word embeddings, acl300 gave a higher micro - f score than acl100, but there is no difference between 300 and 100 dimensional acl - embeddings when look at the macro - f and weighted - f scores.', 'table 3 showed the sent2vec performance on classifying implicit citations with four categories : objective, negative, positive and excluded.', 'the method in this experiment had a poor performance on detecting positive citations, but it was comparable with both the baseline and sentence structure method [ 13 ] for the category of objective citations.', 'with respect to classifying negative citations, this method was not as good as sentence structure features but it outperformed the baseline.', 'the results of classifying category x from the rest showed that the performances of this method and the sentence structure method are fairly equal.', 'table 4 showed the results of classifying positive and negative citations using different word embeddings.', 'the macro - f score 0. 85 and the weighted - f score 0. 86 proved that word2vec is effective on classifying positive and negative citations.', 'however, unlike the outcomes in the paper of  #TAUTHOR_TAG, where they concluded that sentiment specific word embeddings performed best, integrating polarity information did not improve the result in this experiment.', '']",4
"['proposed word embedding association test ( weat ) to computationally measure biases in any text repository  #TAUTHOR_TAG.', 'their test quantifies biases by computing similarity scores between various sets of words.', 'to compute similarity, the we']","['proposed word embedding association test ( weat ) to computationally measure biases in any text repository  #TAUTHOR_TAG.', 'their test quantifies biases by computing similarity scores between various sets of words.', 'to compute similarity, the weat test represents words using a distributed word representation method such as fasttext or word2vec [ 4, 16 ].', 'we']","['proposed word embedding association test ( weat ) to computationally measure biases in any text repository  #TAUTHOR_TAG.', 'their test quantifies biases by computing similarity scores between various sets of words.', 'to compute similarity, the weat test represents words using a distributed word representation method such as fasttext or word2vec [ 4, 16 ].', 'we apply the weat test on song lyrics and discuss its implications']","['lyrics have been used for many tasks related to music mining such as genre identification and popularity prediction.', 'earlier works considered lyrics as a weak source of song characteristics as compared to auditory or social features.', 'however, recent works have shown the strength of lyrics for music mining.', 'barman et al. have shown that knowledge encoded in lyrics can be utilized to improve the distributed representation of words [ 2 ].', 'mayer et al. have introduced various features for lyrics processing [ 15 ].', 'fell and sporleder presented a lyrics - based analysis of songs based on vocabulary and song structure [ 8 ].', 'our work complements these works by characterizing lyrics style using multiple attributes extracted from lyrics.', 'many studies have analyzed gender and racial biases in song lyrics [ 14, 18 ].', 'however, such an approach of manual analysis cannot scale to millions of songs.', 'caliskan et al. proposed word embedding association test ( weat ) to computationally measure biases in any text repository  #TAUTHOR_TAG.', 'their test quantifies biases by computing similarity scores between various sets of words.', 'to compute similarity, the weat test represents words using a distributed word representation method such as fasttext or word2vec [ 4, 16 ].', 'we apply the weat test on song lyrics and discuss its implications']",0
['. designed the word embedding association test ( weat ) by tweaking the iat test  #TAUTHOR_TAG.'],"['. designed the word embedding association test ( weat ) by tweaking the iat test  #TAUTHOR_TAG. similar to', 'the iat test,']","['zero, then it indicates slight or no bias. calisk', '##an et al. designed the word embedding association test ( weat ) by tweaking the iat test  #TAUTHOR_TAG. similar to', 'the iat test, this test can measure bias given the sets of attribute and', 'target words. however, the iat test requires human subjects to compute the bias value. on the other hand, the we']","['the other direction, that is flowers are', 'unpleasant, and insects are pleasant. larger magnitude of effect size indicates a stronger bias.', 'if the value of effect size is closer to zero, then it indicates slight or no bias. calisk', '##an et al. designed the word embedding association test ( weat ) by tweaking the iat test  #TAUTHOR_TAG. similar to', 'the iat test, this test can measure bias given the sets of attribute and', 'target words. however, the iat test requires human subjects to compute the bias value. on the other hand, the weat test can compute the bias value', 'using a large text repository, and it does not require human subjects. the weat test represents attribute and target words as vectors using distributed representation methods', 'such as word2vec and fasttext [ 4, 16 ]. the weat test computes the similarity between words using the cosine similarity. calisk', '##an et al. have performed the bias measurement on a large internet crawl text corpus using', 'the weat test. they have shown that their results correlate with the iat tests conducted with human subjects. we applied the weat test on our song lyrics dataset. due to the small size of popular songs dataset, we cannot apply the we', '##at test separately on popular songs lyrics. please refer to table 1. corresponding to eight rows of the table, we have measured', 'eight biases. we borrowed these attribute and target', 'word sets from caliskan et al.  #TAUTHOR_TAG. first two columns ( w2v and', 'ft ) correspond to measurements on the song lyrics dataset with word2vec and out of all tests, we can', '']",0
"['proposed word embedding association test ( weat ) to computationally measure biases in any text repository  #TAUTHOR_TAG.', 'their test quantifies biases by computing similarity scores between various sets of words.', 'to compute similarity, the we']","['proposed word embedding association test ( weat ) to computationally measure biases in any text repository  #TAUTHOR_TAG.', 'their test quantifies biases by computing similarity scores between various sets of words.', 'to compute similarity, the weat test represents words using a distributed word representation method such as fasttext or word2vec [ 4, 16 ].', 'we']","['proposed word embedding association test ( weat ) to computationally measure biases in any text repository  #TAUTHOR_TAG.', 'their test quantifies biases by computing similarity scores between various sets of words.', 'to compute similarity, the weat test represents words using a distributed word representation method such as fasttext or word2vec [ 4, 16 ].', 'we apply the weat test on song lyrics and discuss its implications']","['lyrics have been used for many tasks related to music mining such as genre identification and popularity prediction.', 'earlier works considered lyrics as a weak source of song characteristics as compared to auditory or social features.', 'however, recent works have shown the strength of lyrics for music mining.', 'barman et al. have shown that knowledge encoded in lyrics can be utilized to improve the distributed representation of words [ 2 ].', 'mayer et al. have introduced various features for lyrics processing [ 15 ].', 'fell and sporleder presented a lyrics - based analysis of songs based on vocabulary and song structure [ 8 ].', 'our work complements these works by characterizing lyrics style using multiple attributes extracted from lyrics.', 'many studies have analyzed gender and racial biases in song lyrics [ 14, 18 ].', 'however, such an approach of manual analysis cannot scale to millions of songs.', 'caliskan et al. proposed word embedding association test ( weat ) to computationally measure biases in any text repository  #TAUTHOR_TAG.', 'their test quantifies biases by computing similarity scores between various sets of words.', 'to compute similarity, the weat test represents words using a distributed word representation method such as fasttext or word2vec [ 4, 16 ].', 'we apply the weat test on song lyrics and discuss its implications']",5
['. designed the word embedding association test ( weat ) by tweaking the iat test  #TAUTHOR_TAG.'],"['. designed the word embedding association test ( weat ) by tweaking the iat test  #TAUTHOR_TAG. similar to', 'the iat test,']","['zero, then it indicates slight or no bias. calisk', '##an et al. designed the word embedding association test ( weat ) by tweaking the iat test  #TAUTHOR_TAG. similar to', 'the iat test, this test can measure bias given the sets of attribute and', 'target words. however, the iat test requires human subjects to compute the bias value. on the other hand, the we']","['the other direction, that is flowers are', 'unpleasant, and insects are pleasant. larger magnitude of effect size indicates a stronger bias.', 'if the value of effect size is closer to zero, then it indicates slight or no bias. calisk', '##an et al. designed the word embedding association test ( weat ) by tweaking the iat test  #TAUTHOR_TAG. similar to', 'the iat test, this test can measure bias given the sets of attribute and', 'target words. however, the iat test requires human subjects to compute the bias value. on the other hand, the weat test can compute the bias value', 'using a large text repository, and it does not require human subjects. the weat test represents attribute and target words as vectors using distributed representation methods', 'such as word2vec and fasttext [ 4, 16 ]. the weat test computes the similarity between words using the cosine similarity. calisk', '##an et al. have performed the bias measurement on a large internet crawl text corpus using', 'the weat test. they have shown that their results correlate with the iat tests conducted with human subjects. we applied the weat test on our song lyrics dataset. due to the small size of popular songs dataset, we cannot apply the we', '##at test separately on popular songs lyrics. please refer to table 1. corresponding to eight rows of the table, we have measured', 'eight biases. we borrowed these attribute and target', 'word sets from caliskan et al.  #TAUTHOR_TAG. first two columns ( w2v and', 'ft ) correspond to measurements on the song lyrics dataset with word2vec and out of all tests, we can', '']",5
"[':  #TAUTHOR_TAG treat it as classification problem, while  #AUTHOR_TAG pursue several approaches for']","['to  #AUTHOR_TAG.', 'recently, empty - element recovery for chinese has begun to receive attention :  #TAUTHOR_TAG treat it as classification problem, while  #AUTHOR_TAG pursue several approaches for']","[':  #TAUTHOR_TAG treat it as classification problem, while  #AUTHOR_TAG pursue several approaches for both korean']","['', ' #AUTHOR_TAG studied emptyelement recovery in english, followed by several others  #AUTHOR_TAG ; the best results we are aware of are due to  #AUTHOR_TAG.', 'recently, empty - element recovery for chinese has begun to receive attention :  #TAUTHOR_TAG treat it as classification problem, while  #AUTHOR_TAG pursue several approaches for both korean and chinese, and explore applications to machine translation.', 'our intuition motivating this work is that empty elements are an integral part of syntactic structure, and should be constructed jointly with it, not added in afterwards.', 'moreover, we expect empty - element recovery to improve as the parsing quality improves.', 'our method makes use of a strong syntactic model, the pcfgs with latent annotation of  #AUTHOR_TAG, which we extend to predict empty cate - gories by the use of lattice parsing.', 'the method is language - independent and performs very well on both languages we tested it on : for english, it outperforms the best published method we are aware of  #AUTHOR_TAG, and for chinese, it outperforms the method of  #TAUTHOR_TAG.', '']",0
"['span.', ' #TAUTHOR_TAG simply count unlabeled empty']","['span.', ' #TAUTHOR_TAG simply count unlabeled empty elements : items are ( i, i ) for']","['span.', ' #TAUTHOR_TAG simply count unlabeled empty elements : items are ( i, i ) for']","['metrics for empty - element recovery are not well established, and previous studies use a variety of metrics.', 'we review several of these here and additionally propose a unified evaluation of parsing and empty - element recovery.', '3 if a and b are multisets, let a ( x ) be the number of occurrences of x in a, let | a | = ∑ x a ( x ), and let a ∩ b be the multiset such that ( a ∩ b ) ( x ) = min ( a ( x ), b ( x ) ).', 'if t is the multiset of "" items "" in the trees being tested and g is the multiset of "" items "" in the gold - standard trees, then', 'the modified parser is available at http : / / www. cs. bgu.', 'where "" items "" are defined differently for each metric, as follows.', 'define a nonterminal node, for present purposes, to be a node which is neither a terminal nor preterminal node.', 'the standard parseval metric  #AUTHOR_TAG counts labeled nonempty brackets : items are ( x, i, j ) for each nonempty nonterminal node, where x is its label and i, j are the start and end positions of its span.', ' #TAUTHOR_TAG simply count unlabeled empty elements : items are ( i, i ) for each empty element, where i is its position.', '']",0
"[':  #TAUTHOR_TAG treat it as classification problem, while  #AUTHOR_TAG pursue several approaches for']","['to  #AUTHOR_TAG.', 'recently, empty - element recovery for chinese has begun to receive attention :  #TAUTHOR_TAG treat it as classification problem, while  #AUTHOR_TAG pursue several approaches for']","[':  #TAUTHOR_TAG treat it as classification problem, while  #AUTHOR_TAG pursue several approaches for both korean']","['', ' #AUTHOR_TAG studied emptyelement recovery in english, followed by several others  #AUTHOR_TAG ; the best results we are aware of are due to  #AUTHOR_TAG.', 'recently, empty - element recovery for chinese has begun to receive attention :  #TAUTHOR_TAG treat it as classification problem, while  #AUTHOR_TAG pursue several approaches for both korean and chinese, and explore applications to machine translation.', 'our intuition motivating this work is that empty elements are an integral part of syntactic structure, and should be constructed jointly with it, not added in afterwards.', 'moreover, we expect empty - element recovery to improve as the parsing quality improves.', 'our method makes use of a strong syntactic model, the pcfgs with latent annotation of  #AUTHOR_TAG, which we extend to predict empty cate - gories by the use of lattice parsing.', 'the method is language - independent and performs very well on both languages we tested it on : for english, it outperforms the best published method we are aware of  #AUTHOR_TAG, and for chinese, it outperforms the method of  #TAUTHOR_TAG.', '']",4
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[""difference is not small ; scores using schmid's metric are lower by roughly 1 %."", ""there are other minor differences in schmid's metric which we do not detail here."", 'chinese we also experimented on a subset of the penn chinese treebank 6. 0.', 'for comparability with previous work  #TAUTHOR_TAG, we trained the parser on sections 0081 - 0900, used sections 0041 - 0080 for development, and sections 0001 - 0040 and 0901 - 0931 for testing.', 'the results are shown in table 2.', 'we selected the 6th split - merge cycle based on the labeled empty elements f 1 measure.', '']",4
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[""difference is not small ; scores using schmid's metric are lower by roughly 1 %."", ""there are other minor differences in schmid's metric which we do not detail here."", 'chinese we also experimented on a subset of the penn chinese treebank 6. 0.', 'for comparability with previous work  #TAUTHOR_TAG, we trained the parser on sections 0081 - 0900, used sections 0041 - 0080 for development, and sections 0001 - 0040 and 0901 - 0931 for testing.', 'the results are shown in table 2.', 'we selected the 6th split - merge cycle based on the labeled empty elements f 1 measure.', '']",4
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[""difference is not small ; scores using schmid's metric are lower by roughly 1 %."", ""there are other minor differences in schmid's metric which we do not detail here."", 'chinese we also experimented on a subset of the penn chinese treebank 6. 0.', 'for comparability with previous work  #TAUTHOR_TAG, we trained the parser on sections 0081 - 0900, used sections 0041 - 0080 for development, and sections 0001 - 0040 and 0901 - 0931 for testing.', 'the results are shown in table 2.', 'we selected the 6th split - merge cycle based on the labeled empty elements f 1 measure.', '']",7
"['as presented by  #TAUTHOR_TAG.', 'this is']","['representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is']","['exploring various knowledge representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is the problem of']","['', 'in contrast, gorilla - ride - camel is uncommon, likely unattested, and yet still semantically plausible.', 'modeling semantic plausibility then requires distinguishing these plausible events from the semantically nonsensical, e. g. lake - ridecamel.', 'semantic plausibility is a necessary part of many natural language understanding ( nlu ) tasks including narrative interpolation  #AUTHOR_TAG, story understanding  #AUTHOR_TAG, paragraph reconstruction  #AUTHOR_TAG, and hard coreference resolution ( peng event plausible?', 'bird - construct - nest et al., 2015 ).', 'furthermore, the problem of modeling semantic plausibility has itself been used as a testbed for exploring various knowledge representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is the problem of determining if a given event, represented as an s - v - o triple, is physically plausible ( table 1 ).', 'we show that in the original supervised setting a distributional model, namely a novel application of bert  #AUTHOR_TAG, significantly outperforms the best existing method which has access to manually labeled physical features  #TAUTHOR_TAG.', 'still, the generalization ability of supervised models is limited by the coverage of the training set.', 'we therefore present the more difficult problem of learning physical plausibility directly from text.', ""we create a training set by parsing and extracting attested s - v - o triples from english wikipedia, and we provide a baseline for training on this dataset and evaluating on  #TAUTHOR_TAG's physical plausibility task."", '']",7
['as  #TAUTHOR_TAG : we perform 10 - fold'],['as  #TAUTHOR_TAG : we perform 10 - fold'],['as  #TAUTHOR_TAG : we perform 10 -'],"['the supervised setting, we follow the same evaluation procedure as  #TAUTHOR_TAG : we perform 10 - fold cross validation on the dataset of 3, 062 s - v - o triples, and report the mean accuracy of running this procedure 20 times all with the same model initialization ( table 3 ).', 'bert outperforms existing methods by a large margin, including those with access to manually labeled physical features.', 'we conclude from model accuracy random 0. 50 nn ( van de  #AUTHOR_TAG 0. 68 nn + wk  #TAUTHOR_TAG.', 'examples of positive and negative results for bert are presented in table 4.', '']",7
"['which has previously been used in the supervised setting  #TAUTHOR_TAG.', 'interestingly, bert is']","['which has previously been used in the supervised setting  #TAUTHOR_TAG.', 'interestingly, bert is']","['.', 'performance may benefit from injecting explicit commonsense knowledge into the model, an approach which has previously been used in the supervised setting  #TAUTHOR_TAG.', 'interestingly, bert is biased towards labelling events as plausible.', 'for the best performing model, for example, 78']","['learning from text ( subsection 3. 2 ), we report both the validation and test accuracies of classifying physically plausible events ( table 5 ).', 'bert fine - tuned on wikipedia performs the best, although only partially captures semantic plausibility with a test set accuracy of 63 %.', 'performance may benefit from injecting explicit commonsense knowledge into the model, an approach which has previously been used in the supervised setting  #TAUTHOR_TAG.', 'interestingly, bert is biased towards labelling events as plausible.', 'for the best performing model, for example, 78 % of errors are false positives.', 'models trained on wikipedia events consistently outperform those trained on nell which is consistent with our subjective assessment of the cleanliness of these datasets.', 'the baseline nn method in particular seems to learn very little from training on the nell dataset']",7
"['as presented by  #TAUTHOR_TAG.', 'this is']","['representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is']","['exploring various knowledge representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is the problem of']","['', 'in contrast, gorilla - ride - camel is uncommon, likely unattested, and yet still semantically plausible.', 'modeling semantic plausibility then requires distinguishing these plausible events from the semantically nonsensical, e. g. lake - ridecamel.', 'semantic plausibility is a necessary part of many natural language understanding ( nlu ) tasks including narrative interpolation  #AUTHOR_TAG, story understanding  #AUTHOR_TAG, paragraph reconstruction  #AUTHOR_TAG, and hard coreference resolution ( peng event plausible?', 'bird - construct - nest et al., 2015 ).', 'furthermore, the problem of modeling semantic plausibility has itself been used as a testbed for exploring various knowledge representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is the problem of determining if a given event, represented as an s - v - o triple, is physically plausible ( table 1 ).', 'we show that in the original supervised setting a distributional model, namely a novel application of bert  #AUTHOR_TAG, significantly outperforms the best existing method which has access to manually labeled physical features  #TAUTHOR_TAG.', 'still, the generalization ability of supervised models is limited by the coverage of the training set.', 'we therefore present the more difficult problem of learning physical plausibility directly from text.', ""we create a training set by parsing and extracting attested s - v - o triples from english wikipedia, and we provide a baseline for training on this dataset and evaluating on  #TAUTHOR_TAG's physical plausibility task."", '']",4
"['as presented by  #TAUTHOR_TAG.', 'this is']","['representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is']","['exploring various knowledge representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is the problem of']","['', 'in contrast, gorilla - ride - camel is uncommon, likely unattested, and yet still semantically plausible.', 'modeling semantic plausibility then requires distinguishing these plausible events from the semantically nonsensical, e. g. lake - ridecamel.', 'semantic plausibility is a necessary part of many natural language understanding ( nlu ) tasks including narrative interpolation  #AUTHOR_TAG, story understanding  #AUTHOR_TAG, paragraph reconstruction  #AUTHOR_TAG, and hard coreference resolution ( peng event plausible?', 'bird - construct - nest et al., 2015 ).', 'furthermore, the problem of modeling semantic plausibility has itself been used as a testbed for exploring various knowledge representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is the problem of determining if a given event, represented as an s - v - o triple, is physically plausible ( table 1 ).', 'we show that in the original supervised setting a distributional model, namely a novel application of bert  #AUTHOR_TAG, significantly outperforms the best existing method which has access to manually labeled physical features  #TAUTHOR_TAG.', 'still, the generalization ability of supervised models is limited by the coverage of the training set.', 'we therefore present the more difficult problem of learning physical plausibility directly from text.', ""we create a training set by parsing and extracting attested s - v - o triples from english wikipedia, and we provide a baseline for training on this dataset and evaluating on  #TAUTHOR_TAG's physical plausibility task."", '']",5
"['as presented by  #TAUTHOR_TAG.', 'this is']","['representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is']","['exploring various knowledge representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is the problem of']","['', 'in contrast, gorilla - ride - camel is uncommon, likely unattested, and yet still semantically plausible.', 'modeling semantic plausibility then requires distinguishing these plausible events from the semantically nonsensical, e. g. lake - ridecamel.', 'semantic plausibility is a necessary part of many natural language understanding ( nlu ) tasks including narrative interpolation  #AUTHOR_TAG, story understanding  #AUTHOR_TAG, paragraph reconstruction  #AUTHOR_TAG, and hard coreference resolution ( peng event plausible?', 'bird - construct - nest et al., 2015 ).', 'furthermore, the problem of modeling semantic plausibility has itself been used as a testbed for exploring various knowledge representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is the problem of determining if a given event, represented as an s - v - o triple, is physically plausible ( table 1 ).', 'we show that in the original supervised setting a distributional model, namely a novel application of bert  #AUTHOR_TAG, significantly outperforms the best existing method which has access to manually labeled physical features  #TAUTHOR_TAG.', 'still, the generalization ability of supervised models is limited by the coverage of the training set.', 'we therefore present the more difficult problem of learning physical plausibility directly from text.', ""we create a training set by parsing and extracting attested s - v - o triples from english wikipedia, and we provide a baseline for training on this dataset and evaluating on  #TAUTHOR_TAG's physical plausibility task."", '']",5
"['o triple, is physically plausible.', ""we use  #TAUTHOR_TAG's physical plausibility dataset for evaluation."", 'this dataset consists of 3, 062 s']","['triple, is physically plausible.', ""we use  #TAUTHOR_TAG's physical plausibility dataset for evaluation."", 'this dataset consists of 3, 062']","[', we focus on the task of single - event, physical plausibility.', 'this is the problem of determining if a given event, represented as an s - v - o triple, is physically plausible.', ""we use  #TAUTHOR_TAG's physical plausibility dataset for evaluation."", 'this dataset consists of 3, 06']","['existing work, we focus on the task of single - event, physical plausibility.', 'this is the problem of determining if a given event, represented as an s - v - o triple, is physically plausible.', ""we use  #TAUTHOR_TAG's physical plausibility dataset for evaluation."", 'this dataset consists of 3, 062 s - v - o triples, built from a vocabulary of 150 verbs and 450 nouns, and containing a diverse combination of both typical and atypical events balanced between the plausible and implausible categories.', 'the set of events and ground truth labels were manually curated']",5
"['evaluation procedure as previous work and perform cross validation on the 3, 062 labeled triples  #TAUTHOR_TAG']","['evaluation procedure as previous work and perform cross validation on the 3, 062 labeled triples  #TAUTHOR_TAG']","['tested on labelled events from the same distribution.', 'therefore, both the training and test set capture typical and atypical plausibility.', 'we follow the same evaluation procedure as previous work and perform cross validation on the 3, 062 labeled triples  #TAUTHOR_TAG']","['the supervised setting, a model is trained and tested on labelled events from the same distribution.', 'therefore, both the training and test set capture typical and atypical plausibility.', 'we follow the same evaluation procedure as previous work and perform cross validation on the 3, 062 labeled triples  #TAUTHOR_TAG']",5
['as  #TAUTHOR_TAG : we perform 10 - fold'],['as  #TAUTHOR_TAG : we perform 10 - fold'],['as  #TAUTHOR_TAG : we perform 10 -'],"['the supervised setting, we follow the same evaluation procedure as  #TAUTHOR_TAG : we perform 10 - fold cross validation on the dataset of 3, 062 s - v - o triples, and report the mean accuracy of running this procedure 20 times all with the same model initialization ( table 3 ).', 'bert outperforms existing methods by a large margin, including those with access to manually labeled physical features.', 'we conclude from model accuracy random 0. 50 nn ( van de  #AUTHOR_TAG 0. 68 nn + wk  #TAUTHOR_TAG.', 'examples of positive and negative results for bert are presented in table 4.', '']",5
"['as presented by  #TAUTHOR_TAG.', 'this is']","['representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is']","['exploring various knowledge representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is the problem of']","['', 'in contrast, gorilla - ride - camel is uncommon, likely unattested, and yet still semantically plausible.', 'modeling semantic plausibility then requires distinguishing these plausible events from the semantically nonsensical, e. g. lake - ridecamel.', 'semantic plausibility is a necessary part of many natural language understanding ( nlu ) tasks including narrative interpolation  #AUTHOR_TAG, story understanding  #AUTHOR_TAG, paragraph reconstruction  #AUTHOR_TAG, and hard coreference resolution ( peng event plausible?', 'bird - construct - nest et al., 2015 ).', 'furthermore, the problem of modeling semantic plausibility has itself been used as a testbed for exploring various knowledge representations.', 'in this work, we focus specifically on modeling physical plausibility as presented by  #TAUTHOR_TAG.', 'this is the problem of determining if a given event, represented as an s - v - o triple, is physically plausible ( table 1 ).', 'we show that in the original supervised setting a distributional model, namely a novel application of bert  #AUTHOR_TAG, significantly outperforms the best existing method which has access to manually labeled physical features  #TAUTHOR_TAG.', 'still, the generalization ability of supervised models is limited by the coverage of the training set.', 'we therefore present the more difficult problem of learning physical plausibility directly from text.', ""we create a training set by parsing and extracting attested s - v - o triples from english wikipedia, and we provide a baseline for training on this dataset and evaluating on  #TAUTHOR_TAG's physical plausibility task."", '']",0
"['capturing semantic plausibility  #TAUTHOR_TAG.', 'o seaghdha and  #AUTHOR_TAG have investigated combining a lexical hierarchy with a distributional']","['capturing semantic plausibility  #TAUTHOR_TAG.', 'o seaghdha and  #AUTHOR_TAG have investigated combining a lexical hierarchy with a distributional approach, and there have been related attempts at grounding selectional preference in visual perception  #AUTHOR_TAG.', 'models of selectional preference are']","['capturing semantic plausibility  #TAUTHOR_TAG.', 'o seaghdha and  #AUTHOR_TAG have investigated combining a lexical hierarchy with a distributional approach, and there have been related attempts at grounding selectional preference in visual perception  #AUTHOR_TAG.', 'models of selectional preference are either']","['related to semantic plausibility is selectional preference  #AUTHOR_TAG which concerns the semantic preference of a predicate for its arguments.', 'here, preference refers to the typicality of arguments : while it is plausible that a gorilla rides a camel, it is not preferred.', 'current approaches to selectional preference are distributional  #AUTHOR_TAG van de  #AUTHOR_TAG and have shown limited performance in capturing semantic plausibility  #TAUTHOR_TAG.', 'o seaghdha and  #AUTHOR_TAG have investigated combining a lexical hierarchy with a distributional approach, and there have been related attempts at grounding selectional preference in visual perception  #AUTHOR_TAG.', 'models of selectional preference are either evaluated on a pseudo - disambiguation task, where attested predicate - argument tuples must be disambiguated from pseudo - negative random tuples, or evaluated on their correlation with human plausibility judgments.', 'selectional preference is one factor in plausibility and thus the two should correlate']",0
"['evaluation procedure as previous work and perform cross validation on the 3, 062 labeled triples  #TAUTHOR_TAG']","['evaluation procedure as previous work and perform cross validation on the 3, 062 labeled triples  #TAUTHOR_TAG']","['tested on labelled events from the same distribution.', 'therefore, both the training and test set capture typical and atypical plausibility.', 'we follow the same evaluation procedure as previous work and perform cross validation on the 3, 062 labeled triples  #TAUTHOR_TAG']","['the supervised setting, a model is trained and tested on labelled events from the same distribution.', 'therefore, both the training and test set capture typical and atypical plausibility.', 'we follow the same evaluation procedure as previous work and perform cross validation on the 3, 062 labeled triples  #TAUTHOR_TAG']",3
"['( nn ) over static embeddings.', 'supervised.', 'we reproduce the results of  #TAUTHOR_TAG using glove embeddings and the']","['( nn ) over static embeddings.', 'supervised.', 'we reproduce the results of  #TAUTHOR_TAG using glove embeddings and the']","[' #AUTHOR_TAG.', 'this method is a two - layer artificial neural network ( nn ) over static embeddings.', 'supervised.', 'we reproduce the results of  #TAUTHOR_TAG using glove embeddings and the same hyperparameter settings.', 'self - supervised.', 'we use this same method for learning from text ( subsection 3. 2 ).', 'to do so, we turn the training data into a self - supervised train - ing set : attested events are considered to be plausible, and pseudo - implausible events are created by sampling each word in']","['a baseline, we consider the performance of a neural method for selectional preference ( van de  #AUTHOR_TAG.', 'this method is a two - layer artificial neural network ( nn ) over static embeddings.', 'supervised.', 'we reproduce the results of  #TAUTHOR_TAG using glove embeddings and the same hyperparameter settings.', 'self - supervised.', 'we use this same method for learning from text ( subsection 3. 2 ).', 'to do so, we turn the training data into a self - supervised train - ing set : attested events are considered to be plausible, and pseudo - implausible events are created by sampling each word in an s - v - o triple independently by occurrence frequency.', 'we do hyperparameter search on the validation set over learning rates in { 1e −3, 1e −4, 1e − 5, 2e − 5 }, batch sizes in { 16, 32, 64, 128 }, and epochs in { 0. 5, 1, 2 }']",3
['as  #TAUTHOR_TAG : we perform 10 - fold'],['as  #TAUTHOR_TAG : we perform 10 - fold'],['as  #TAUTHOR_TAG : we perform 10 -'],"['the supervised setting, we follow the same evaluation procedure as  #TAUTHOR_TAG : we perform 10 - fold cross validation on the dataset of 3, 062 s - v - o triples, and report the mean accuracy of running this procedure 20 times all with the same model initialization ( table 3 ).', 'bert outperforms existing methods by a large margin, including those with access to manually labeled physical features.', 'we conclude from model accuracy random 0. 50 nn ( van de  #AUTHOR_TAG 0. 68 nn + wk  #TAUTHOR_TAG.', 'examples of positive and negative results for bert are presented in table 4.', '']",3
"['unique triples with a cumulative 112 million occurrences.', ""for evaluation, we split  #TAUTHOR_TAG's 3, 062 triples into equal sized validation and test sets."", 'each set thus consists of 1,']","['unique triples with a cumulative 112 million occurrences.', ""for evaluation, we split  #TAUTHOR_TAG's 3, 062 triples into equal sized validation and test sets."", 'each set thus consists of 1, 531 triples']","['with a cumulative 112 million occurrences.', ""for evaluation, we split  #TAUTHOR_TAG's 3, 062 triples into equal sized validation and test sets."", 'each set thus consists of 1,']","['also present the problem of learning to model physical plausibility directly from text.', 'in this new setting, a model is trained on events extracted from a large corpus and evaluated on a physical plausibility task.', 'therefore, only the test set covers both typical and atypical plausibility.', 'we create two training sets based on separate corpora : first, we parse english wikipedia using the stanfordnlp neural pipeline  #AUTHOR_TAG and extract attested s - v - o triples.', 'wikipedia has led to relatively good results for selectional preference  #AUTHOR_TAG, and in total we extract 6 million unique triples with a cumulative 10 million occurrences.', 'second, we use the nell  #AUTHOR_TAG dataset of 604 million s - v - o triples extracted from the dependency parsed clueweb09 dataset.', 'for nell, we filter out triples with nonalphabetic characters or less than 5 occurrences, resulting in a total 2. 5 million unique triples with a cumulative 112 million occurrences.', ""for evaluation, we split  #TAUTHOR_TAG's 3, 062 triples into equal sized validation and test sets."", 'each set thus consists of 1, 531 triples']",6
"['such patterns include bootstrapping techniques  #TAUTHOR_TAG, weakly supervised']","['such patterns include bootstrapping techniques  #TAUTHOR_TAG, weakly supervised']","['learning such patterns include bootstrapping techniques  #TAUTHOR_TAG, weakly supervised learning algorithms  #AUTHOR_TAG, fully supervised']","['', 'the problem we address here is the detection of role - filler candidates and their association with specific roles in event templates.', 'for this task, ie systems adopt various ways of extracting patterns or generating rules based on the surrounding context, local context and global context  #AUTHOR_TAG.', 'current approaches for learning such patterns include bootstrapping techniques  #TAUTHOR_TAG, weakly supervised learning algorithms  #AUTHOR_TAG, fully supervised learning approaches  #AUTHOR_TAG and other variations.', 'all these methods rely on substantial amounts of manually annotated corpora and use a large body of linguistic knowledge.', 'the performance of these approaches is related to the amount of knowledge engineering deployed and a good choice of features and classifiers.', '']",0
"['such patterns include bootstrapping techniques  #TAUTHOR_TAG, weakly supervised']","['such patterns include bootstrapping techniques  #TAUTHOR_TAG, weakly supervised']","['learning such patterns include bootstrapping techniques  #TAUTHOR_TAG, weakly supervised learning algorithms  #AUTHOR_TAG, fully supervised']","['', 'the problem we address here is the detection of role - filler candidates and their association with specific roles in event templates.', 'for this task, ie systems adopt various ways of extracting patterns or generating rules based on the surrounding context, local context and global context  #AUTHOR_TAG.', 'current approaches for learning such patterns include bootstrapping techniques  #TAUTHOR_TAG, weakly supervised learning algorithms  #AUTHOR_TAG, fully supervised learning approaches  #AUTHOR_TAG and other variations.', 'all these methods rely on substantial amounts of manually annotated corpora and use a large body of linguistic knowledge.', 'the performance of these approaches is related to the amount of knowledge engineering deployed and a good choice of features and classifiers.', '']",0
"['works  #TAUTHOR_TAG b ), the role fillers']","['works  #TAUTHOR_TAG b ), the role fillers']","['the event roles whereas, in most works  #TAUTHOR_TAG b ), the role fillers are represented by a set of different features ( raw words,']","['this work, we approach the event extraction task by learning word representations from a domainspecific data set and by using these representations to identify the event roles.', 'this idea relies on the assumption that the different words used for a given event role in the text share some semantic properties, related to their context of use and that these similarities can be captured by specific representations that can be automatically induced from the text, in an unsupervised way.', 'we then propose to rely only on these word representations to detect the event roles whereas, in most works  #TAUTHOR_TAG b ), the role fillers are represented by a set of different features ( raw words, their parts - ofspeech, syntactic or semantic roles in the sentence ).', 'furthermore, we propose two additional contributions to the construction of the word representations.', 'the first one is to exploit limited knowledge about the event types ( seed words ) to improve the learning procedure by better selecting the dictionary.', 'the second one is to use a max operation 1 on the word vector representations in order to build noun phrase representations ( since slot fillers are generally noun phrases ), which represents a better way of aggregating the semantic information born by the word representations']",4
"['##4 with different parameters, compared to the learning curve of tier  #TAUTHOR_TAG']","['size of training data, of "" string slots "" on the tst3 + tst4 with different parameters, compared to the learning curve of tier  #TAUTHOR_TAG']","['string slots "" on the tst3 + tst4 with different parameters, compared to the learning curve of tier  #TAUTHOR_TAG.', 'the grey points represent the performances of other ie systems.', 'figure 1 presents the average f1 - score results, computed over the slots perpind, perporg, target, victim and weapon']","['all the experiments involving our model, we established the following stable choices of parameters : 50 - dimensional vectors obtained by training on sequences of 5 words, which is consistent with previous studies  #AUTHOR_TAG.', 'all the hyper - parameters of our model ( e. g. learning rate, size of the hidden layer, size of the word vectors ) have been chosen by finetuning our event extraction system on the tst1 + tst2 data set.', 'for drvr - 50 and w2v - 50, the embeddings were built from the whole training corpus ( 1, 300 documents ) and the dictionary was made of all the words of this corpus under their inflected form.', 'we used the extra - trees ensemble classifier implemented in  #AUTHOR_TAG, with hyperparameters optimized on the validation data : forest of 500 trees and the maximum number of features to consider when looking for the best split is √ number f eatures.', 'we present a 3 - fold evaluation : first, we compare our system with state - of - the - art systems on the same task, then we compare our domain - relevant vector representations ( drvr - 50 ) to more generic word embeddings ( c & w50, hlbl - 50 ) 3 and finally to another state - of - the - art systems perpind perporg target victim weapon average  #AUTHOR_TAG 33 word representation construction on the domainspecific data ( w2v - 50 ) 4.', 'figure 1 : f1 - score results for event role labeling on muc - 4 data, for different size of training data, of "" string slots "" on the tst3 + tst4 with different parameters, compared to the learning curve of tier  #TAUTHOR_TAG.', 'the grey points represent the performances of other ie systems.', 'figure 1 presents the average f1 - score results, computed over the slots perpind, perporg, target, victim and weapon.', 'we observe that models relying on word embeddings globally outperform the state - of - the - art results, which demonstrates that the word embeddings capture enough semantic information to perform the task of event newswire corpus 4 w2v - 50 are the embeddings induced from the muc4 data set using the negative sampling training algorithm  #AUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG c ), available at https : / / code. google. com / p / word2vec / role labeling on "" string slots "" without using any additional hand - engineered features.', 'moreover, our representations ( drvr - 50 ) clearly surpass the models based on generic embeddings ( c & w - 50 and hlbl -']",4
"['( perpetrators, human targets, physical targets, etc ).', 'following previous works  #TAUTHOR_TAG, we']","['( perpetrators, human targets, physical targets, etc ).', 'following previous works  #TAUTHOR_TAG, we']","['from the document ( perpetrators, human targets, physical targets, etc ).', 'following previous works  #TAUTHOR_TAG, we']","['', 'these are represented by templates containing various slots for each piece of information that should be extracted from the document ( perpetrators, human targets, physical targets, etc ).', 'following previous works  #TAUTHOR_TAG, we only consider the "" string slots "" in this work ( other slots need different treatments ) and we group certain slots to finally consider the five slot types perpind ( individual perpetrator ), perporg ( organizational perpetrator ), target ( physical target ), victim ( human target name or description ) and weapon ( instrument id or type ).', 'we used 1, 300 documents ( dev ) for training, 200 documents ( tst1 + tst2 ) for tuning, and 200 documents ( tst3 + tst4 ) as the blind test set.', 'to compare with similar works, we do not evaluate the template construction and only focus on the identification of the slot fillers : for each answer key in a reference template, we check if we find it correctly with our extraction method, using head noun matching ( e. g., the victim her mother martha lopez orozco de lopez is considered to match matha lopez ), and merging duplicate extractions ( so that different extracted slot fillers sharing the same head noun are counted only once ).', 'we also took into account the answer keys with multiple values in the reference, dealing with conjunctions ( when several victims are named, we need to find all of them ) and disjunctions ( when several names for the same organization are possible, we need to find any of them ).', 'our results are reported as precision / recall / f1 - score for each event role separately and averaged on all roles']",5
"['( perpetrators, human targets, physical targets, etc ).', 'following previous works  #TAUTHOR_TAG, we']","['( perpetrators, human targets, physical targets, etc ).', 'following previous works  #TAUTHOR_TAG, we']","['from the document ( perpetrators, human targets, physical targets, etc ).', 'following previous works  #TAUTHOR_TAG, we']","['', 'these are represented by templates containing various slots for each piece of information that should be extracted from the document ( perpetrators, human targets, physical targets, etc ).', 'following previous works  #TAUTHOR_TAG, we only consider the "" string slots "" in this work ( other slots need different treatments ) and we group certain slots to finally consider the five slot types perpind ( individual perpetrator ), perporg ( organizational perpetrator ), target ( physical target ), victim ( human target name or description ) and weapon ( instrument id or type ).', 'we used 1, 300 documents ( dev ) for training, 200 documents ( tst1 + tst2 ) for tuning, and 200 documents ( tst3 + tst4 ) as the blind test set.', 'to compare with similar works, we do not evaluate the template construction and only focus on the identification of the slot fillers : for each answer key in a reference template, we check if we find it correctly with our extraction method, using head noun matching ( e. g., the victim her mother martha lopez orozco de lopez is considered to match matha lopez ), and merging duplicate extractions ( so that different extracted slot fillers sharing the same head noun are counted only once ).', 'we also took into account the answer keys with multiple values in the reference, dealing with conjunctions ( when several victims are named, we need to find all of them ) and disjunctions ( when several names for the same organization are possible, we need to find any of them ).', 'our results are reported as precision / recall / f1 - score for each event role separately and averaged on all roles']",3
"['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG']","['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the']","['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the same data are used to train the models and']","['', 'is evaluated using the uncontrolled keywords as the gold standard. in the paper, three minor improvements to the keyword extraction algorithm are presented. these concern how', 'one of the term selection approaches extract candidate terms ; how the collection frequency is calculated ; and how the weights are set to the positive examples', '. the major focus of the paper is how the learning task is defined. for these experiments, the', 'same machine learning system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the same data are used to train the models and to tune the parameters. the results', 'of the experiments are presented in tables 1 - 5, which show : the average number of keywords assigned per document ( assign. ) ; the average number', '']",5
"['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG']","['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the']","['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the same data are used to train the models and']","['', 'is evaluated using the uncontrolled keywords as the gold standard. in the paper, three minor improvements to the keyword extraction algorithm are presented. these concern how', 'one of the term selection approaches extract candidate terms ; how the collection frequency is calculated ; and how the weights are set to the positive examples', '. the major focus of the paper is how the learning task is defined. for these experiments, the', 'same machine learning system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the same data are used to train the models and to tune the parameters. the results', 'of the experiments are presented in tables 1 - 5, which show : the average number of keywords assigned per document ( assign. ) ; the average number', '']",5
"['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG']","['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the']","['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the same data are used to train the models and']","['', 'is evaluated using the uncontrolled keywords as the gold standard. in the paper, three minor improvements to the keyword extraction algorithm are presented. these concern how', 'one of the term selection approaches extract candidate terms ; how the collection frequency is calculated ; and how the weights are set to the positive examples', '. the major focus of the paper is how the learning task is defined. for these experiments, the', 'same machine learning system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the same data are used to train the models and to tune the parameters. the results', 'of the experiments are presented in tables 1 - 5, which show : the average number of keywords assigned per document ( assign. ) ; the average number', '']",0
"['the experiments presented in  #TAUTHOR_TAG, only the documents present in the training, validation, and test set respectively are used']","['the experiments presented in  #TAUTHOR_TAG, only the documents present in the training, validation, and test set respectively are used']","['the experiments presented in  #TAUTHOR_TAG, only the documents present in the training, validation, and test set respectively are used']","['the experiments presented in  #TAUTHOR_TAG, only the documents present in the training, validation, and test set respectively are used for calculating the collection frequency.', 'this means that the collection is rather homogenous.', 'for this reason, the collection frequency is instead calculated on a set of 200 arbitrarily chosen documents from the british national corpus ( bnc ).', 'in table 2, the performance of two runs when taking the majority vote of the three classifiers removing the subsumed terms is presented.', ""the first run ('abstracts') is when the collection frequency is calculated from the abstracts."", ""the second run ('gen. corp.') is when the bnc documents are used for this calculation."", 'if comparing these two runs, the fmeasure increases.', 'in other words, using a more general corpus for this calculation leads to a better performance of the automatic keyword extraction']",0
"['the experiments presented in  #TAUTHOR_TAG, the automatic keyword indexing task is treated as a binary classification task, where each candidate term is classified either as a keyword or a non - keyword.', 'rds allows for the prediction to be treated as a regression task  #AUTHOR_TAG.', 'this means that the prediction is given as a numerical']","['the experiments presented in  #TAUTHOR_TAG, the automatic keyword indexing task is treated as a binary classification task, where each candidate term is classified either as a keyword or a non - keyword.', 'rds allows for the prediction to be treated as a regression task  #AUTHOR_TAG.', 'this means that the prediction is given as a numerical value, instead of a category.', '']","['the experiments presented in  #TAUTHOR_TAG, the automatic keyword indexing task is treated as a binary classification task, where each candidate term is classified either as a keyword or a non - keyword.', 'rds allows for the prediction to be treated as a regression task  #AUTHOR_TAG.', 'this means that the prediction is given as a numerical value, instead of a category.', '']","['the experiments presented in  #TAUTHOR_TAG, the automatic keyword indexing task is treated as a binary classification task, where each candidate term is classified either as a keyword or a non - keyword.', 'rds allows for the prediction to be treated as a regression task  #AUTHOR_TAG.', 'this means that the prediction is given as a numerical value, instead of a category.', 'when training the regression models, the candidate terms being manually assigned keywords are given the value one, and all other candidate terms are assigned the value zero.', 'in this fashion, the prediction is a value between zero and one, and the higher the value, the more likely a candidate term is to be a keyword ( according to the model ).', 'to combine the results from the three models, there are two alternatives.', '']",0
"['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG']","['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the']","['system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the same data are used to train the models and']","['', 'is evaluated using the uncontrolled keywords as the gold standard. in the paper, three minor improvements to the keyword extraction algorithm are presented. these concern how', 'one of the term selection approaches extract candidate terms ; how the collection frequency is calculated ; and how the weights are set to the positive examples', '. the major focus of the paper is how the learning task is defined. for these experiments, the', 'same machine learning system - rds - is', 'used as for the experiments presented by  #TAUTHOR_TAG. also the same data are used to train the models and to tune the parameters. the results', 'of the experiments are presented in tables 1 - 5, which show : the average number of keywords assigned per document ( assign. ) ; the average number', '']",3
"['classifier ( as described in  #TAUTHOR_TAG.', '']","['classifier ( as described in  #TAUTHOR_TAG.', '']","['classifier ( as described in  #TAUTHOR_TAG.', '']","['the data set is unbalanced - there is a larger number of negative than positive examples - the positive examples are given a higher weight when training the prediction models.', 'in the experiments discussed so far, the weights given to the positive examples are those resulting in the best performance for each individual classifier ( as described in  #TAUTHOR_TAG.', 'for the results presented further, the weights are instead set according to which individual weight that maximises the f - measure for the combined model on the validation set.', 'the weight given to the positive examples for each term selection approach has in a ( rather large ) number of runs been altered systematically for each classifier, and the combination that results in the best performance is selected.', 'the results on the test set are presented in table 3.', 'as can be seen in this table, the recall decreases, while the precision and the f - measure increase']",7
[' #AUTHOR_TAG b ;  #TAUTHOR_TAG utilize a deterministic shift - reduce process'],[' #AUTHOR_TAG b ;  #TAUTHOR_TAG utilize a deterministic shift - reduce process'],[' #AUTHOR_TAG b ;  #TAUTHOR_TAG utilize a deterministic shift - reduce process'],"['- based dependency parsing  #AUTHOR_TAG b ;  #TAUTHOR_TAG utilize a deterministic shift - reduce process for making structural predictions.', 'compared to graph - based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non - local features, as exemplified by the comparison between maltparser and mstparser  #AUTHOR_TAG b ; mc  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'recent research has addressed two potential disadvantages of systems like maltparser.', 'in the aspect of decoding, beam - search  #AUTHOR_TAG and partial dynamic - programming  #TAUTHOR_TAG have been applied to improve upon greedy one - best search, and positive results were reported.', 'in the aspect of training, global structural learning has been used to replace local learning on each decision  #AUTHOR_TAG, although the effect of global learning has not been separated out and studied alone.', 'in this short paper, we study a third aspect in a statistical system : feature definition.', 'representing the type of information a statistical system uses to make predictions, feature templates can be one of the most important factors determining parsing accuracy.', 'various recent attempts have been made to include non - local features into graph - based dependency parsing  #AUTHOR_TAG.', 'transitionbased parsing, by contrast, can easily accommodate arbitrarily complex representations involving nonlocal features.', 'complex non - local features, such as bracket matching and rhythmic patterns, are used in transition - based constituency parsing  #AUTHOR_TAG, and most transitionbased dependency parsers incorporate some nonlocal features, but current practice is nevertheless to use a rather restricted set of features, as exemplified by the default feature models in maltparser  #AUTHOR_TAG a ).', 'we explore considerably richer feature representations and show that they improve parsing accuracy significantly.', 'in standard experiments using the penn treebank, our parser gets an unlabeled attachment score of 92. 9 %, which is the best result achieved with a transition - based parser and comparable to the state of the art.', 'for the chinese treebank, our parser gets a score of 86. 0 %, the best reported result so far.', '']",0
[' #AUTHOR_TAG b ;  #TAUTHOR_TAG utilize a deterministic shift - reduce process'],[' #AUTHOR_TAG b ;  #TAUTHOR_TAG utilize a deterministic shift - reduce process'],[' #AUTHOR_TAG b ;  #TAUTHOR_TAG utilize a deterministic shift - reduce process'],"['- based dependency parsing  #AUTHOR_TAG b ;  #TAUTHOR_TAG utilize a deterministic shift - reduce process for making structural predictions.', 'compared to graph - based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non - local features, as exemplified by the comparison between maltparser and mstparser  #AUTHOR_TAG b ; mc  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'recent research has addressed two potential disadvantages of systems like maltparser.', 'in the aspect of decoding, beam - search  #AUTHOR_TAG and partial dynamic - programming  #TAUTHOR_TAG have been applied to improve upon greedy one - best search, and positive results were reported.', 'in the aspect of training, global structural learning has been used to replace local learning on each decision  #AUTHOR_TAG, although the effect of global learning has not been separated out and studied alone.', 'in this short paper, we study a third aspect in a statistical system : feature definition.', 'representing the type of information a statistical system uses to make predictions, feature templates can be one of the most important factors determining parsing accuracy.', 'various recent attempts have been made to include non - local features into graph - based dependency parsing  #AUTHOR_TAG.', 'transitionbased parsing, by contrast, can easily accommodate arbitrarily complex representations involving nonlocal features.', 'complex non - local features, such as bracket matching and rhythmic patterns, are used in transition - based constituency parsing  #AUTHOR_TAG, and most transitionbased dependency parsers incorporate some nonlocal features, but current practice is nevertheless to use a rather restricted set of features, as exemplified by the default feature models in maltparser  #AUTHOR_TAG a ).', 'we explore considerably richer feature representations and show that they improve parsing accuracy significantly.', 'in standard experiments using the penn treebank, our parser gets an unlabeled attachment score of 92. 9 %, which is the best result achieved with a transition - based parser and comparable to the state of the art.', 'for the chinese treebank, our parser gets a score of 86. 0 %, the best reported result so far.', '']",0
['- standard  #TAUTHOR_TAG process'],"['in an arc - eager  #AUTHOR_TAG b ;  #AUTHOR_TAG or arc - standard  #TAUTHOR_TAG process.', 'we adopt']","['- standard  #TAUTHOR_TAG process.', 'we adopt']","['a typical transition - based parsing process, the input words are put into a queue and partially built structures are organized by a stack.', 'a set of shiftreduce actions are defined, which consume words from the queue and build the output parse.', 'recent research have focused on action sets that build projective dependency trees in an arc - eager  #AUTHOR_TAG b ;  #AUTHOR_TAG or arc - standard  #TAUTHOR_TAG process.', '']",0
['- standard  #TAUTHOR_TAG process'],"['in an arc - eager  #AUTHOR_TAG b ;  #AUTHOR_TAG or arc - standard  #TAUTHOR_TAG process.', 'we adopt']","['- standard  #TAUTHOR_TAG process.', 'we adopt']","['a typical transition - based parsing process, the input words are put into a queue and partially built structures are organized by a stack.', 'a set of shiftreduce actions are defined, which consume words from the queue and build the output parse.', 'recent research have focused on action sets that build projective dependency trees in an arc - eager  #AUTHOR_TAG b ;  #AUTHOR_TAG or arc - standard  #TAUTHOR_TAG process.', '']",5
"['from  #AUTHOR_TAG and  #TAUTHOR_TAG, and our']","['mostly taken from  #AUTHOR_TAG and  #TAUTHOR_TAG, and our parser reproduces']","['1. these features are mostly taken from  #AUTHOR_TAG and  #TAUTHOR_TAG, and our']","['##r2 w ; s 0r2 p ; s 0r2 l ; n 0l2 w ; n 0l2 p ; n 0l2 l ; s 0 ps 0l ps 0l2 p ; s 0 ps 0', '##r ps 0r2 p ; s 0 ps 0h ps 0h2 p ; n 0 pn 0l pn 0l2 p ; label set s 0 ws r ; s 0 ps r ; s 0 ws l ; s 0', 'ps l ; n 0 ws l ; n 0', 'ps l ; w - word ; p - pos - tag ; v l, v r - valency ; ldependency label, s l, s r - labelset. with s 0, the front items from the queue with n 0, n 1, and n 2, the head of s 0 ( if any ) with s 0h, the leftmost and rightmost modifiers of s 0 ( if any ) with s 0l and s 0r, respectively, and the leftmost modifier of n 0 ( if any ) with n 0l, the baseline features are shown in table 1. these features are mostly taken from  #AUTHOR_TAG and  #TAUTHOR_TAG, and our parser reproduces the same accuracies as reported by both papers. in this table, w and p represents the word and pos - tag, respectively. for example, s 0 pn 0 wp represents the feature template that takes the word and pos - tag of n 0, and combines it with the word of s 0. 189 in this short paper, we extend the baseline feature templates with the following : distance between s 0 and n 0 direction and distance between a pair of head and modifier have been used in the standard feature templates for maximum spanning tree parsing ( mc  #AUTHOR_TAG. distance information has also been used in the easy - first parser of  #AUTHOR_TAG. for a transition - based parser, direction information is indirectly included in the leftarc and rightarc actions. we add the distance between s 0 and n 0 to the feature set by combining it with the', 'word and pos - tag of s 0 and n 0, as shown in table 2. it is worth noticing that the use of distance information in our transition - based model is different from that in a typical graph - based parser such as mstparser. the distance between s 0 and n 0 will correspond to the distance between a pair of head and modifier when an leftarc action is taken, for example, but not when a shift', 'action is taken']",5
"['.', '2 following  #TAUTHOR_TAG,']","['penn2malt tool.', '2 following  #TAUTHOR_TAG,']","['into dependency formats using the penn2malt tool.', '2 following  #TAUTHOR_TAG, we assign pos - tags to the training data using ten - way jackknifing.', 'we used our implementation of the  #AUTHOR_TAG tagger ( with 97']","['experiments were performed using the penn treebank ( ptb ) and chinese treebank ( ctb ) data.', 'we follow the standard approach to split ptb3, using sections 2 - 21 for training, section 22 for development and 23 for final testing.', 'bracketed sentences from ptb were transformed into dependency formats using the penn2malt tool.', '2 following  #TAUTHOR_TAG, we assign pos - tags to the training data using ten - way jackknifing.', 'we used our implementation of the  #AUTHOR_TAG tagger ( with 97. 3 % accuracy on a standard penn treebank test ) to perform pos - tagging.', 'for all experiments, we set the beam size to 64 for the parser, and report unlabeled and labeled attachment scores ( uas, las ) and unlabeled exact match ( uem ) for evaluation.', '']",5
"['.', '2 following  #TAUTHOR_TAG,']","['penn2malt tool.', '2 following  #TAUTHOR_TAG,']","['into dependency formats using the penn2malt tool.', '2 following  #TAUTHOR_TAG, we assign pos - tags to the training data using ten - way jackknifing.', 'we used our implementation of the  #AUTHOR_TAG tagger ( with 97']","['experiments were performed using the penn treebank ( ptb ) and chinese treebank ( ctb ) data.', 'we follow the standard approach to split ptb3, using sections 2 - 21 for training, section 22 for development and 23 for final testing.', 'bracketed sentences from ptb were transformed into dependency formats using the penn2malt tool.', '2 following  #TAUTHOR_TAG, we assign pos - tags to the training data using ten - way jackknifing.', 'we used our implementation of the  #AUTHOR_TAG tagger ( with 97. 3 % accuracy on a standard penn treebank test ) to perform pos - tagging.', 'for all experiments, we set the beam size to 64 for the parser, and report unlabeled and labeled attachment scores ( uas, las ) and unlabeled exact match ( uem ) for evaluation.', '']",5
"[' #TAUTHOR_TAG on chinese.', 'we take the standard split of ctb and use gold segmentation and pos - tags for the input.', 'our scores for this test set are the']","[' #TAUTHOR_TAG on chinese.', 'we take the standard split of ctb and use gold segmentation and pos - tags for the input.', 'our scores for this test set are the']","[' #TAUTHOR_TAG on chinese.', 'we take the standard split of ctb and use gold segmentation and pos - tags for the input.', 'our scores for this test set are the']","['experiments were performed on a linux platform with a 2ghz cpu.', 'the speed of our baseline parser was 50 sentences per second.', 'with all new features added, the speed dropped to 29 sentences per second.', 'as an alternative to penn2malt, bracketed sentences can also be transformed into stanford dependencies  #AUTHOR_TAG.', 'our parser gave 93. 5 % uas, 91. 9 % las and 52. 1 % uem when trained and evaluated on stanford basic dependencies, which are projective dependency trees.', ' #AUTHOR_TAG report results on stanford collapsed dependencies, which allow a word to have multiple heads and therefore cannot be produced by a regular dependency parser.', 'their results are relevant although not directly comparable with ours.', 'table 5 shows the results of our final parser, the pure transition - based parser of  #AUTHOR_TAG, and the parser of  #TAUTHOR_TAG on chinese.', 'we take the standard split of ctb and use gold segmentation and pos - tags for the input.', 'our scores for this test set are the best reported so far and significantly better than the previous systems']",5
"['from  #AUTHOR_TAG and  #TAUTHOR_TAG, and our']","['mostly taken from  #AUTHOR_TAG and  #TAUTHOR_TAG, and our parser reproduces']","['1. these features are mostly taken from  #AUTHOR_TAG and  #TAUTHOR_TAG, and our']","['##r2 w ; s 0r2 p ; s 0r2 l ; n 0l2 w ; n 0l2 p ; n 0l2 l ; s 0 ps 0l ps 0l2 p ; s 0 ps 0', '##r ps 0r2 p ; s 0 ps 0h ps 0h2 p ; n 0 pn 0l pn 0l2 p ; label set s 0 ws r ; s 0 ps r ; s 0 ws l ; s 0', 'ps l ; n 0 ws l ; n 0', 'ps l ; w - word ; p - pos - tag ; v l, v r - valency ; ldependency label, s l, s r - labelset. with s 0, the front items from the queue with n 0, n 1, and n 2, the head of s 0 ( if any ) with s 0h, the leftmost and rightmost modifiers of s 0 ( if any ) with s 0l and s 0r, respectively, and the leftmost modifier of n 0 ( if any ) with n 0l, the baseline features are shown in table 1. these features are mostly taken from  #AUTHOR_TAG and  #TAUTHOR_TAG, and our parser reproduces the same accuracies as reported by both papers. in this table, w and p represents the word and pos - tag, respectively. for example, s 0 pn 0 wp represents the feature template that takes the word and pos - tag of n 0, and combines it with the word of s 0. 189 in this short paper, we extend the baseline feature templates with the following : distance between s 0 and n 0 direction and distance between a pair of head and modifier have been used in the standard feature templates for maximum spanning tree parsing ( mc  #AUTHOR_TAG. distance information has also been used in the easy - first parser of  #AUTHOR_TAG. for a transition - based parser, direction information is indirectly included in the leftarc and rightarc actions. we add the distance between s 0 and n 0 to the feature set by combining it with the', 'word and pos - tag of s 0 and n 0, as shown in table 2. it is worth noticing that the use of distance information in our transition - based model is different from that in a typical graph - based parser such as mstparser. the distance between s 0 and n 0 will correspond to the distance between a pair of head and modifier when an leftarc action is taken, for example, but not when a shift', 'action is taken']",3
"[' #TAUTHOR_TAG on chinese.', 'we take the standard split of ctb and use gold segmentation and pos - tags for the input.', 'our scores for this test set are the']","[' #TAUTHOR_TAG on chinese.', 'we take the standard split of ctb and use gold segmentation and pos - tags for the input.', 'our scores for this test set are the']","[' #TAUTHOR_TAG on chinese.', 'we take the standard split of ctb and use gold segmentation and pos - tags for the input.', 'our scores for this test set are the']","['experiments were performed on a linux platform with a 2ghz cpu.', 'the speed of our baseline parser was 50 sentences per second.', 'with all new features added, the speed dropped to 29 sentences per second.', 'as an alternative to penn2malt, bracketed sentences can also be transformed into stanford dependencies  #AUTHOR_TAG.', 'our parser gave 93. 5 % uas, 91. 9 % las and 52. 1 % uem when trained and evaluated on stanford basic dependencies, which are projective dependency trees.', ' #AUTHOR_TAG report results on stanford collapsed dependencies, which allow a word to have multiple heads and therefore cannot be produced by a regular dependency parser.', 'their results are relevant although not directly comparable with ours.', 'table 5 shows the results of our final parser, the pure transition - based parser of  #AUTHOR_TAG, and the parser of  #TAUTHOR_TAG on chinese.', 'we take the standard split of ctb and use gold segmentation and pos - tags for the input.', 'our scores for this test set are the best reported so far and significantly better than the previous systems']",4
"['well as the effect of using dynamic programming, as in -  #TAUTHOR_TAG.', 'this shows that feature definition is']","['well as the effect of using dynamic programming, as in -  #TAUTHOR_TAG.', 'this shows that feature definition is']","['well as the effect of using dynamic programming, as in -  #TAUTHOR_TAG.', 'this shows that feature definition is']","['', 'the effect of the new features appears to outweigh the effect of combining transition - based and graph - based models, reported by  #AUTHOR_TAG, as well as the effect of using dynamic programming, as in -  #TAUTHOR_TAG.', 'this shows that feature definition is a crucial aspect of transition - based pars - 191 ing.', 'in fact, some of the new feature templates in this paper, such as distance and valency, are among those which are in the graph - based submodel of  #AUTHOR_TAG, but not the transition - based submodel.', 'therefore our new features to some extent achieved the same effect as their model combination.', 'the new features are also hard to use in dynamic programming because they add considerable complexity to the parse items.', 'enriched feature representations have been studied as an important factor for improving the accuracies of graph - based dependency parsing also.', 'recent research including the use of loopy belief network  #AUTHOR_TAG, integer linear programming  #AUTHOR_TAG and an improved dynamic programming algorithm  #AUTHOR_TAG can be seen as methods to incorporate nonlocal features into a graph - based model.', 'an open source release of our parser, together with trained models for english and chinese, are freely available.', '']",4
"['sequence generation  #TAUTHOR_TAG.', 'these']","['sequence generation  #TAUTHOR_TAG.', 'these']","['sequence generation  #TAUTHOR_TAG.', 'these frameworks license a diverse set of generation']","['', 'they found that generating function words first followed by content words second yielded the best results.', ' #AUTHOR_TAG and  #AUTHOR_TAG developed non - autoregressive approaches to machine translation where the entire output can be generated in parallel in constant time.', 'these models do away with order selection altogether but typically lag behind their autoregressive counterparts in translation quality.', 'more recently, a number of novel insertionbased architectures have been developed for sequence generation  #TAUTHOR_TAG.', 'these frameworks license a diverse set of generation orders, including uniform  #AUTHOR_TAG, random  #AUTHOR_TAG, or balanced binary trees  #AUTHOR_TAG.', '']",0
"['sequence generation  #TAUTHOR_TAG.', 'these']","['sequence generation  #TAUTHOR_TAG.', 'these']","['sequence generation  #TAUTHOR_TAG.', 'these frameworks license a diverse set of generation']","['', 'they found that generating function words first followed by content words second yielded the best results.', ' #AUTHOR_TAG and  #AUTHOR_TAG developed non - autoregressive approaches to machine translation where the entire output can be generated in parallel in constant time.', 'these models do away with order selection altogether but typically lag behind their autoregressive counterparts in translation quality.', 'more recently, a number of novel insertionbased architectures have been developed for sequence generation  #TAUTHOR_TAG.', 'these frameworks license a diverse set of generation orders, including uniform  #AUTHOR_TAG, random  #AUTHOR_TAG, or balanced binary trees  #AUTHOR_TAG.', '']",3
"['insertion transformer  #TAUTHOR_TAG, for our empirical study']","['insertion transformer  #TAUTHOR_TAG, for our empirical study.', 'we give a brief overview of the model in this section before moving on to the details of our investigation']","['', 'we use one such insertion - based model, the insertion transformer  #TAUTHOR_TAG, for our empirical study.', 'we give a brief overview of the model in this section before moving on to the details of our investigation']","['sequence models have traditionally been designed with left - to - right prediction in mind.', 'in the classical setting, output sequences are produced by repeatedly appending tokens to the rightmost end of the hypothesis until an endof - sequence token is generated.', 'though highperforming across a wide range of application areas, this approach lacks the flexibility to accommodate other types of inference such as parallel generation, constrained decoding, infilling, etc.', 'moreover, it also leaves open the possibility that a non - left - to - right factorization of the joint distribution over output sequences could outperform the usual monotonic ordering.', 'to address these concerns, several recent approaches have been proposed for insertion - based sequence modeling, in which sequences are con - structed by repeatedly inserting tokens at arbitrary locations in the output rather than only at the right - most position.', 'we use one such insertion - based model, the insertion transformer  #TAUTHOR_TAG, for our empirical study.', 'we give a brief overview of the model in this section before moving on to the details of our investigation']",5
"['1 for reference.', 'we note that  #TAUTHOR_TAG also experimented with a number of other architectural variants, but we use']","['1 for reference.', 'we note that  #TAUTHOR_TAG also experimented with a number of other architectural variants, but we use']","['is given in figure 1 for reference.', 'we note that  #TAUTHOR_TAG also experimented with a number of other architectural variants, but we use the baseline version of the model described above in our experiments for simplicity']","['', 'a schematic of the architecture is given in figure 1 for reference.', 'we note that  #TAUTHOR_TAG also experimented with a number of other architectural variants, but we use the baseline version of the model described above in our experiments for simplicity']",5
"['. substituting l in for the slot loss within the training framework of  #TAUTHOR_TAG then gives the full sequence generation loss,']","['oracle and the model distribution p. substituting l in for the slot loss within the training framework of  #TAUTHOR_TAG then gives the full sequence generation loss,']","['. substituting l in for the slot loss within the training framework of  #TAUTHOR_TAG then gives the full sequence generation loss,']","['presented our model of interest, we now describe a general soft order - reward framework that can be used to train the model to follow any oracle ordering for sequence generation.', 'let o ( a ) be an order function mapping insertion actions to real numbers, where lower values correspond to better actions, and let p ( a ) be the probability assigned by the model to action a. from these, we construct a reward function r ( a ), an oracle policy q oracle, and a per - slot loss l :', 'here, a * is the set of all valid actions.', 'the temperature τ ∈ ( 0, ∞ ) controls the sharpness of the distribution, where τ → 0 results in a one - hot distribution with all mass on the best - scoring action under the order function o ( a ), and τ → ∞ results in a uniform distribution over all valid actions.', 'intermediate values of τ result in distributions which are biased towards better - scoring actions but allow for other valid actions to be taken some of the time.', 'having defined the target distribution, we take the slot loss l for insertions within a particular slot to be the kl - divergence between the oracle distribution q oracle and the model distribution p. substituting l in for the slot loss within the training framework of  #TAUTHOR_TAG then gives the full sequence generation loss, which we can use to train an insertion transformer under any oracle policy rather than just the specific one they propose.', 'we describe a wide variety of generation orders which can be characterized by different order functions o ( a ) in the subsections that follow.', 'a summary is given in table 1']",5
['follow  #TAUTHOR_TAG and use a uniform roll - in policy'],['follow  #TAUTHOR_TAG and use a uniform roll - in policy'],['follow  #TAUTHOR_TAG and use a uniform roll - in policy'],"['follow  #TAUTHOR_TAG and use a uniform roll - in policy when sampling partial outputs at training time in which we first select a subset size uniformly at random, then select a random subset of the output of that size.', 'repeated tokens are handled via greedy left or right alignment to the true output.', 'input : it would of course be a little simpler for the germans if there were a coherent and standardised european policy, which is currently not the case.', 'output : es ware fur die deutschen naturlich ein wenig einfacher, wenn es eine koharente und einheitliche europaische politik gabe, was derzeit nicht der fall ist']",5
"[',..., 8 }']","['transformer  #AUTHOR_TAG.', 'we perform a sweep over temperatures τ ∈ { 0. 5, 1, 2 } and eos penalties ∈ { 0, 0. 5, 1, 1. 5,..., 8 }']","[', 1, 1. 5,..., 8 }']","['decode ( common - first ) : out using sacrebleu 2  #AUTHOR_TAG.', 'in both cases, we train all models for 1m steps using sequencelevel knowledge distillation  #AUTHOR_TAG from a base transformer  #AUTHOR_TAG.', 'we perform a sweep over temperatures τ ∈ { 0. 5, 1, 2 } and eos penalties ∈ { 0, 0. 5, 1, 1. 5,..., 8 }']",5
['by  #TAUTHOR_TAG serves as a strong baseline for'],['by  #TAUTHOR_TAG serves as a strong baseline for'],"['by  #TAUTHOR_TAG serves as a strong baseline for both language pairs, coming within']","[', we measure the quality of our models by evaluating their performance on their respective test sets.', 'the bleu scores are reported in table 3.', 'the uniform loss proposed by  #TAUTHOR_TAG serves as a strong baseline for both language pairs, coming within 0. 6 points of the original transformer for en - de at 26. 72 bleu, and attaining a respectable score of 33. 1 bleu on en - zh.', '']",5
['by  #TAUTHOR_TAG serves as a strong baseline for'],['by  #TAUTHOR_TAG serves as a strong baseline for'],"['by  #TAUTHOR_TAG serves as a strong baseline for both language pairs, coming within']","[', we measure the quality of our models by evaluating their performance on their respective test sets.', 'the bleu scores are reported in table 3.', 'the uniform loss proposed by  #TAUTHOR_TAG serves as a strong baseline for both language pairs, coming within 0. 6 points of the original transformer for en - de at 26. 72 bleu, and attaining a respectable score of 33. 1 bleu on en - zh.', '']",4
"['on requirements ; introducing elements of sarcasm, or aspects of factual and emotional argumentation styles  #TAUTHOR_TAG 14 ].', 'changes in the perceived speaker personality can also']","['on requirements ; introducing elements of sarcasm, or aspects of factual and emotional argumentation styles  #TAUTHOR_TAG 14 ].', 'changes in the perceived speaker personality can also']","['[ 12, 13 ].', 'the style of an utterance can be altered based on requirements ; introducing elements of sarcasm, or aspects of factual and emotional argumentation styles  #TAUTHOR_TAG 14 ].', 'changes in the perceived speaker personality can also make more personable conversations [ 11 ].', 'even utterances from monologic texts']","['', 'the style of an utterance can be altered based on requirements ; introducing elements of sarcasm, or aspects of factual and emotional argumentation styles  #TAUTHOR_TAG 14 ].', 'changes in the perceived speaker personality can also make more personable conversations [ 11 ].', 'even utterances from monologic texts can be leveraged by converting the content to dialogic flow, and performing stylistic transformations [ 3 ].', 'of course, while many data sources may be of interest for indexing knowledge for a dialogue system, annotations are not always available or easy to obtain.', 'by using machine learning models designed to classify different classes of interest, such as sentiment, sarcasm, and topic, data can be bootstrapped to greatly increase the amount of data available for indexing and utterance selection  #TAUTHOR_TAG.', 'there is no shortage of human generated dialogues, but the challenge is to analyze and harness them appropriately for social - dialogue generation.', 'we']",0
"['on requirements ; introducing elements of sarcasm, or aspects of factual and emotional argumentation styles  #TAUTHOR_TAG 14 ].', 'changes in the perceived speaker personality can also']","['on requirements ; introducing elements of sarcasm, or aspects of factual and emotional argumentation styles  #TAUTHOR_TAG 14 ].', 'changes in the perceived speaker personality can also']","['[ 12, 13 ].', 'the style of an utterance can be altered based on requirements ; introducing elements of sarcasm, or aspects of factual and emotional argumentation styles  #TAUTHOR_TAG 14 ].', 'changes in the perceived speaker personality can also make more personable conversations [ 11 ].', 'even utterances from monologic texts']","['', 'the style of an utterance can be altered based on requirements ; introducing elements of sarcasm, or aspects of factual and emotional argumentation styles  #TAUTHOR_TAG 14 ].', 'changes in the perceived speaker personality can also make more personable conversations [ 11 ].', 'even utterances from monologic texts can be leveraged by converting the content to dialogic flow, and performing stylistic transformations [ 3 ].', 'of course, while many data sources may be of interest for indexing knowledge for a dialogue system, annotations are not always available or easy to obtain.', 'by using machine learning models designed to classify different classes of interest, such as sentiment, sarcasm, and topic, data can be bootstrapped to greatly increase the amount of data available for indexing and utterance selection  #TAUTHOR_TAG.', 'there is no shortage of human generated dialogues, but the challenge is to analyze and harness them appropriately for social - dialogue generation.', 'we']",0
"['[ 7, 8,  #TAUTHOR_TAG.', 'the word2']","['[ 7, 8,  #TAUTHOR_TAG.', 'the word2vec [ 10 ] is among the']","['nlp tasks [ 7, 8,  #TAUTHOR_TAG.', 'the word2vec [ 10 ] is among the']","['from analyzing large - scaled unlabeled data is compulsory and proved useful in the previous works [ 4, 5, 6 ].', 'how to extract useful information from unannotated large scale corpus has been a research issue.', 'word embeddings have become increasingly popular lately, proving to be valuable as a source of features in a broad range of nlp tasks [ 7, 8,  #TAUTHOR_TAG.', 'the word2vec [ 10 ] is among the most widely used word embedding models today.', 'their success is largely due to an efficient and user - friendly implementation that learns high quality word embeddings from very large corpora.', 'the word2vec learns low dimensional continuous vector representations for words by considering window - based contexts, i. e., context words within some fixed distance of each side of the target words.', 'another different context type is dependency - based word embedding [ 11, 12, 13 ], which considers syntactic contexts rather', 'the 2016 conference on computational linguistics and speech processing rocling 2016, pp.', '100 - 102 the association for computational linguistics and chinese language processing 100 than window contexts in word2vec.', '']",0
"['5 ],  #TAUTHOR_TAG and maximum entropy']","['( [ 5 ],  #TAUTHOR_TAG and maximum entropy [ 10 ].', 'among these leaning methods, the']","['5 ],  #TAUTHOR_TAG and maximum entropy [ 10 ].', 'among these leaning methods, the']","['##ating word sense disambiguation tasks based on annotated corpora have been proposed.', 'examples of supervised learning methods for wsd appear in [ 2 ] [ 3 ] [ 4 ], [ 7 ] [ 8 ].', 'the learning algorithms applied including : decision tree, decisionlist [ 15 ], neural networks [ 7 ], naive bayesian learning ( [ 5 ],  #TAUTHOR_TAG and maximum entropy [ 10 ].', 'among these leaning methods, the most important issue is what features will be used to construct the classifier.', 'it is common in wsd to use contextual information that can be found in the neighborhood of the ambiguous word in training data ( [ 6 ], [ 16 ] [ 17 ] [ 18 ] ).', 'it is generally true that when words are used in the same sense, they have similar context and co - occurrence information [ 13 ].', 'it is also generally true that the nearby context words of an ambiguous word give more effective patterns and features values than those far from it [ 12 ].', 'the existing methods consider features selection for context representation including both local and topic features where local features refer to the information pertained only to the given context and topical features are statistically obtained from a training corpus.', '']",5
['##u  #TAUTHOR_TAG proved in his experiments that naive'],['##u  #TAUTHOR_TAG proved in his experiments that naive'],['##u  #TAUTHOR_TAG proved in his experiments that naive bayes classifier'],"['##u  #TAUTHOR_TAG proved in his experiments that naive bayes classifier achieved best disambiguation accuracy with small topical context window size ( < 10 words ).', 'we follow their method and set the contextual window size as 10 in our system.', 'each of the chinese words except the stop words inside the window range will be considered as one topical feature.', 'their frequencies are calculated over the entire corpus with respect to each sense of an ambiguous word w. the sense definitions are obtained from hownet']",5
"['5 ],  #TAUTHOR_TAG and maximum entropy']","['( [ 5 ],  #TAUTHOR_TAG and maximum entropy [ 10 ].', 'among these leaning methods, the']","['5 ],  #TAUTHOR_TAG and maximum entropy [ 10 ].', 'among these leaning methods, the']","['##ating word sense disambiguation tasks based on annotated corpora have been proposed.', 'examples of supervised learning methods for wsd appear in [ 2 ] [ 3 ] [ 4 ], [ 7 ] [ 8 ].', 'the learning algorithms applied including : decision tree, decisionlist [ 15 ], neural networks [ 7 ], naive bayesian learning ( [ 5 ],  #TAUTHOR_TAG and maximum entropy [ 10 ].', 'among these leaning methods, the most important issue is what features will be used to construct the classifier.', 'it is common in wsd to use contextual information that can be found in the neighborhood of the ambiguous word in training data ( [ 6 ], [ 16 ] [ 17 ] [ 18 ] ).', 'it is generally true that when words are used in the same sense, they have similar context and co - occurrence information [ 13 ].', 'it is also generally true that the nearby context words of an ambiguous word give more effective patterns and features values than those far from it [ 12 ].', 'the existing methods consider features selection for context representation including both local and topic features where local features refer to the information pertained only to the given context and topical features are statistically obtained from a training corpus.', '']",0
['##u  #TAUTHOR_TAG proved in his experiments that naive'],['##u  #TAUTHOR_TAG proved in his experiments that naive'],['##u  #TAUTHOR_TAG proved in his experiments that naive bayes classifier'],"['##u  #TAUTHOR_TAG proved in his experiments that naive bayes classifier achieved best disambiguation accuracy with small topical context window size ( < 10 words ).', 'we follow their method and set the contextual window size as 10 in our system.', 'each of the chinese words except the stop words inside the window range will be considered as one topical feature.', 'their frequencies are calculated over the entire corpus with respect to each sense of an ambiguous word w. the sense definitions are obtained from hownet']",0
"['will be explained in section 4. 1.', 'in both niu  #TAUTHOR_TAG and dan']","['collocations applied in our system.', 'the sources of the collocations will be explained in section 4. 1.', ""in both niu  #TAUTHOR_TAG and dang's [ 10 ] work, topical features""]","['.', 'the sources of the collocations will be explained in section 4. 1.', 'in both niu  #TAUTHOR_TAG and dan']","['chose collocations as the local features.', 'a collocation is a recurrent and conventional fixed expression of words which holds syntactic and semantic relations [ 21 ].', 'collocations can be classified as fully fixed collocations, fixed collocations, strong collocations and loose collocations.', 'fixed collocations means the appearance of one word implies the co - occurrence of another one such as "" "" ( "" burden of history "" ), while strong collocations allows very limited substitution of the components, for example, ""', '"" ( "" local college "" ), or "" "" ( "" local university "" ).', 'the sense of ambiguous words can be uniquely determined in these two types of collocations, therefore are the collocations applied in our system.', 'the sources of the collocations will be explained in section 4. 1.', ""in both niu  #TAUTHOR_TAG and dang's [ 10 ] work, topical features as well as the so called collocational features were used."", 'however, as discussed in section 2, they both used bi - gram cooccurrences as the additional local features.', 'however, bi - gram co - occurrences only indicate statistical significance which may not actually satisfy the conceptual definition of collocations.', 'thus instead of using co - occurrences of bigrams, we take the true bi - gram collocations extracted from our system and use this data to compare with bi - gram co - occurrences to test the usefulness of collocation for wsd.', 'the local features in our system make use of the collocations using the template ( w i, w ) within a window size of ten ( where i = ± 5 ).', 'for example, "" "" ( "" government departments and local government commanded that "" ) fits the bi - gram collocation template ( w, w 1 ) with the value of ( ).', 'during the training and the testing processes, the counting of frequency value of the collocation feature will be increased by 1 if a collocation containing the ambiguous word occurs in a sentence.', 'to have a good analysis on collocation features, we have also developed an algorithm using lonely adjacent bi - gram as locals features ( named sys - adjacent bi - gram as locals features ( named system a ) and another using collocation as local features ( named system b )']",0
"['5 ],  #TAUTHOR_TAG and maximum entropy']","['( [ 5 ],  #TAUTHOR_TAG and maximum entropy [ 10 ].', 'among these leaning methods, the']","['5 ],  #TAUTHOR_TAG and maximum entropy [ 10 ].', 'among these leaning methods, the']","['##ating word sense disambiguation tasks based on annotated corpora have been proposed.', 'examples of supervised learning methods for wsd appear in [ 2 ] [ 3 ] [ 4 ], [ 7 ] [ 8 ].', 'the learning algorithms applied including : decision tree, decisionlist [ 15 ], neural networks [ 7 ], naive bayesian learning ( [ 5 ],  #TAUTHOR_TAG and maximum entropy [ 10 ].', 'among these leaning methods, the most important issue is what features will be used to construct the classifier.', 'it is common in wsd to use contextual information that can be found in the neighborhood of the ambiguous word in training data ( [ 6 ], [ 16 ] [ 17 ] [ 18 ] ).', 'it is generally true that when words are used in the same sense, they have similar context and co - occurrence information [ 13 ].', 'it is also generally true that the nearby context words of an ambiguous word give more effective patterns and features values than those far from it [ 12 ].', 'the existing methods consider features selection for context representation including both local and topic features where local features refer to the information pertained only to the given context and topical features are statistically obtained from a training corpus.', '']",4
"['will be explained in section 4. 1.', 'in both niu  #TAUTHOR_TAG and dan']","['collocations applied in our system.', 'the sources of the collocations will be explained in section 4. 1.', ""in both niu  #TAUTHOR_TAG and dang's [ 10 ] work, topical features""]","['.', 'the sources of the collocations will be explained in section 4. 1.', 'in both niu  #TAUTHOR_TAG and dan']","['chose collocations as the local features.', 'a collocation is a recurrent and conventional fixed expression of words which holds syntactic and semantic relations [ 21 ].', 'collocations can be classified as fully fixed collocations, fixed collocations, strong collocations and loose collocations.', 'fixed collocations means the appearance of one word implies the co - occurrence of another one such as "" "" ( "" burden of history "" ), while strong collocations allows very limited substitution of the components, for example, ""', '"" ( "" local college "" ), or "" "" ( "" local university "" ).', 'the sense of ambiguous words can be uniquely determined in these two types of collocations, therefore are the collocations applied in our system.', 'the sources of the collocations will be explained in section 4. 1.', ""in both niu  #TAUTHOR_TAG and dang's [ 10 ] work, topical features as well as the so called collocational features were used."", 'however, as discussed in section 2, they both used bi - gram cooccurrences as the additional local features.', 'however, bi - gram co - occurrences only indicate statistical significance which may not actually satisfy the conceptual definition of collocations.', 'thus instead of using co - occurrences of bigrams, we take the true bi - gram collocations extracted from our system and use this data to compare with bi - gram co - occurrences to test the usefulness of collocation for wsd.', 'the local features in our system make use of the collocations using the template ( w i, w ) within a window size of ten ( where i = ± 5 ).', 'for example, "" "" ( "" government departments and local government commanded that "" ) fits the bi - gram collocation template ( w, w 1 ) with the value of ( ).', 'during the training and the testing processes, the counting of frequency value of the collocation feature will be increased by 1 if a collocation containing the ambiguous word occurs in a sentence.', 'to have a good analysis on collocation features, we have also developed an algorithm using lonely adjacent bi - gram as locals features ( named sys - adjacent bi - gram as locals features ( named system a ) and another using collocation as local features ( named system b )']",4
"['retrieval toolkit ( sert ) that provides implementations of  #TAUTHOR_TAG.', 'e toolkit provides a uni ed interface to di erent representation learning algorithms, ne - grained parsing con guration and']","['retrieval toolkit ( sert ) that provides implementations of  #TAUTHOR_TAG.', 'e toolkit provides a uni ed interface to di erent representation learning algorithms, ne - grained parsing con guration and']","['learning of low - dimensional, semantic representations of words and entities has recently gained a ention.', 'in this paper we describe the semantic entity retrieval toolkit ( sert ) that provides implementations of  #TAUTHOR_TAG.', 'e toolkit provides a uni ed interface to di erent representation learning algorithms, ne - grained parsing con guration and can be used transparently with gpus.', 'in addition, users can easily modify existing models or implement']","['learning of low - dimensional, semantic representations of words and entities has recently gained a ention.', 'in this paper we describe the semantic entity retrieval toolkit ( sert ) that provides implementations of  #TAUTHOR_TAG.', 'e toolkit provides a uni ed interface to di erent representation learning algorithms, ne - grained parsing con guration and can be used transparently with gpus.', 'in addition, users can easily modify existing models or implement their own models in the framework.', 'a er model training, sert can be used to rank entities according to a textual query and extract the learned entity / word representation for use in downstream algorithms, such as clustering or recommendation']",1
['[  #TAUTHOR_TAG ]'],['[  #TAUTHOR_TAG ]'],"['product search [  #TAUTHOR_TAG ].', 'representations are learned from a document collection and domain - speci c associations between']","['unsupervised learning of low - dimensional, semantic representations of words and entities has recently gained a ention for the entity - oriented tasks of expert nding [ 9 ] and product search [  #TAUTHOR_TAG ].', 'representations are learned from a document collection and domain - speci c associations between documents and entities.', 'expert nding is the task of nding the right person with the appropriate skills or knowledge [ 1 ] and an association indicates document authorship ( e. g., academic papers ) or involvement in a project ( e. g., annual progress reports ).', '']",1
"['retrieval toolkit ( sert ) that provides implementations of  #TAUTHOR_TAG.', 'e toolkit provides a uni ed interface to di erent representation learning algorithms, ne - grained parsing con guration and']","['retrieval toolkit ( sert ) that provides implementations of  #TAUTHOR_TAG.', 'e toolkit provides a uni ed interface to di erent representation learning algorithms, ne - grained parsing con guration and']","['learning of low - dimensional, semantic representations of words and entities has recently gained a ention.', 'in this paper we describe the semantic entity retrieval toolkit ( sert ) that provides implementations of  #TAUTHOR_TAG.', 'e toolkit provides a uni ed interface to di erent representation learning algorithms, ne - grained parsing con guration and can be used transparently with gpus.', 'in addition, users can easily modify existing models or implement']","['learning of low - dimensional, semantic representations of words and entities has recently gained a ention.', 'in this paper we describe the semantic entity retrieval toolkit ( sert ) that provides implementations of  #TAUTHOR_TAG.', 'e toolkit provides a uni ed interface to di erent representation learning algorithms, ne - grained parsing con guration and can be used transparently with gpus.', 'in addition, users can easily modify existing models or implement their own models in the framework.', 'a er model training, sert can be used to rank entities according to a textual query and extract the learned entity / word representation for use in downstream algorithms, such as clustering or recommendation']",6
['[  #TAUTHOR_TAG ]'],['[  #TAUTHOR_TAG ]'],"['product search [  #TAUTHOR_TAG ].', 'representations are learned from a document collection and domain - speci c associations between']","['unsupervised learning of low - dimensional, semantic representations of words and entities has recently gained a ention for the entity - oriented tasks of expert nding [ 9 ] and product search [  #TAUTHOR_TAG ].', 'representations are learned from a document collection and domain - speci c associations between documents and entities.', 'expert nding is the task of nding the right person with the appropriate skills or knowledge [ 1 ] and an association indicates document authorship ( e. g., academic papers ) or involvement in a project ( e. g., annual progress reports ).', '']",6
"['product search [  #TAUTHOR_TAG ].', 'code snippet 1 : illustrative example of the sert model interface.', 'e full interface supports more functionality omitted here for brevity.', 'users can de ne a symbolic graph of computation using the eano library']","['product search [  #TAUTHOR_TAG ].', 'code snippet 1 : illustrative example of the sert model interface.', 'e full interface supports more functionality omitted here for brevity.', 'users can de ne a symbolic graph of computation using the eano library [ 6 ] in combination with lasagne [ 3 ]']","['product search [  #TAUTHOR_TAG ].', 'code snippet 1 : illustrative example of the sert model interface.', 'e full interface supports more functionality omitted here for brevity.', 'users can de ne a symbolic graph of computation using the eano library [ 6 ] in combination with lasagne [ 3 ]']","['begin, sert constructs a vocabulary that will be used to tokenize the document collection.', 'non - signi cant words that are too frequent ( e. g., stopwords ), noisy ( e. g., single characters ) and rare words are ltered out.', 'words that do not occur in the dictionary are ignored.', 'a erwards, word sequences are extracted from the documents and stored together with the associated entities in the numerical format provided by numpy [ 7 ].', 'word sequences can be extracted consecutively or a stride can be speci ed to extract nonconsecutive windows.', 'in addition, a hierarchy of word sequence extractors can be applied to extract skip - grams, i. e., word sequences where a number of tokens are skipped a er selecting a token [ 4 ].', 'to support short documents, a special - purpose padding token can be used to ll up word sequences that are longer than a particular document.', 'a er word sequence extraction, a weight can be assigned to each word sequence / entity pair that can be used to re - weight the training objective.', 'for example, in the case of expert nding [ 9 ], this weight is the reciprocal of the document length of the document where the sequence was extracted from. is avoids a bias in the objective towards long documents.', 'an alternative option that exists within the toolkit is to resample word sequence / entity pairs such that every entity is associated with the same number of word sequences, as used for product search [  #TAUTHOR_TAG ].', 'code snippet 1 : illustrative example of the sert model interface.', 'e full interface supports more functionality omitted here for brevity.', 'users can de ne a symbolic graph of computation using the eano library [ 6 ] in combination with lasagne [ 3 ]']",6
"['[ 9 ] and product search [  #TAUTHOR_TAG ].', 'users of the']","['[ 9 ] and product search [  #TAUTHOR_TAG ].', 'users of the']","['##ing [ 9 ] and product search [  #TAUTHOR_TAG ].', 'users of the toolkit can use these implementations to']","['er the collection has been processed and packaged in a machinefriendly format, representations of words and entities can be learned.', 'e toolkit includes implementations of state - of - the - art representation learning models that were applied to expert nding [ 9 ] and product search [  #TAUTHOR_TAG ].', 'users of the toolkit can use these implementations to learn representations out - of - the - box or adapt the algorithms to their needs.', 'in addition, users can implement their own models by extending an interface provided by the framework.', 'code snippet 1 shows an example of a model implemented in the sert toolkit where users can de ne a symbolic cost function that will be optimized using eano [ 6 ].', 'due to the component - wise organization of the toolkit ( fig. 1 ), modeling and text processing are separated from each other.', 'consequently, researchers can focus on modeling and representation learning only.', 'in addition, any improvements to the collection processing ( § 2. 1 ) collectively bene ts all models implemented in sert']",6
['[  #TAUTHOR_TAG ]'],['[  #TAUTHOR_TAG ]'],"['product search [  #TAUTHOR_TAG ].', 'representations are learned from a document collection and domain - speci c associations between']","['unsupervised learning of low - dimensional, semantic representations of words and entities has recently gained a ention for the entity - oriented tasks of expert nding [ 9 ] and product search [  #TAUTHOR_TAG ].', 'representations are learned from a document collection and domain - speci c associations between documents and entities.', 'expert nding is the task of nding the right person with the appropriate skills or knowledge [ 1 ] and an association indicates document authorship ( e. g., academic papers ) or involvement in a project ( e. g., annual progress reports ).', '']",0
['[  #TAUTHOR_TAG ]'],['[  #TAUTHOR_TAG ]'],"['product search [  #TAUTHOR_TAG ].', 'representations are learned from a document collection and domain - speci c associations between']","['unsupervised learning of low - dimensional, semantic representations of words and entities has recently gained a ention for the entity - oriented tasks of expert nding [ 9 ] and product search [  #TAUTHOR_TAG ].', 'representations are learned from a document collection and domain - speci c associations between documents and entities.', 'expert nding is the task of nding the right person with the appropriate skills or knowledge [ 1 ] and an association indicates document authorship ( e. g., academic papers ) or involvement in a project ( e. g., annual progress reports ).', '']",0
"['[ 9 ] and product search [  #TAUTHOR_TAG ].', 'users of the']","['[ 9 ] and product search [  #TAUTHOR_TAG ].', 'users of the']","['##ing [ 9 ] and product search [  #TAUTHOR_TAG ].', 'users of the toolkit can use these implementations to']","['er the collection has been processed and packaged in a machinefriendly format, representations of words and entities can be learned.', 'e toolkit includes implementations of state - of - the - art representation learning models that were applied to expert nding [ 9 ] and product search [  #TAUTHOR_TAG ].', 'users of the toolkit can use these implementations to learn representations out - of - the - box or adapt the algorithms to their needs.', 'in addition, users can implement their own models by extending an interface provided by the framework.', 'code snippet 1 shows an example of a model implemented in the sert toolkit where users can de ne a symbolic cost function that will be optimized using eano [ 6 ].', 'due to the component - wise organization of the toolkit ( fig. 1 ), modeling and text processing are separated from each other.', 'consequently, researchers can focus on modeling and representation learning only.', 'in addition, any improvements to the collection processing ( § 2. 1 ) collectively bene ts all models implemented in sert']",0
"['product search [  #TAUTHOR_TAG ].', 'code snippet 1 : illustrative example of the sert model interface.', 'e full interface supports more functionality omitted here for brevity.', 'users can de ne a symbolic graph of computation using the eano library']","['product search [  #TAUTHOR_TAG ].', 'code snippet 1 : illustrative example of the sert model interface.', 'e full interface supports more functionality omitted here for brevity.', 'users can de ne a symbolic graph of computation using the eano library [ 6 ] in combination with lasagne [ 3 ]']","['product search [  #TAUTHOR_TAG ].', 'code snippet 1 : illustrative example of the sert model interface.', 'e full interface supports more functionality omitted here for brevity.', 'users can de ne a symbolic graph of computation using the eano library [ 6 ] in combination with lasagne [ 3 ]']","['begin, sert constructs a vocabulary that will be used to tokenize the document collection.', 'non - signi cant words that are too frequent ( e. g., stopwords ), noisy ( e. g., single characters ) and rare words are ltered out.', 'words that do not occur in the dictionary are ignored.', 'a erwards, word sequences are extracted from the documents and stored together with the associated entities in the numerical format provided by numpy [ 7 ].', 'word sequences can be extracted consecutively or a stride can be speci ed to extract nonconsecutive windows.', 'in addition, a hierarchy of word sequence extractors can be applied to extract skip - grams, i. e., word sequences where a number of tokens are skipped a er selecting a token [ 4 ].', 'to support short documents, a special - purpose padding token can be used to ll up word sequences that are longer than a particular document.', 'a er word sequence extraction, a weight can be assigned to each word sequence / entity pair that can be used to re - weight the training objective.', 'for example, in the case of expert nding [ 9 ], this weight is the reciprocal of the document length of the document where the sequence was extracted from. is avoids a bias in the objective towards long documents.', 'an alternative option that exists within the toolkit is to resample word sequence / entity pairs such that every entity is associated with the same number of word sequences, as used for product search [  #TAUTHOR_TAG ].', 'code snippet 1 : illustrative example of the sert model interface.', 'e full interface supports more functionality omitted here for brevity.', 'users can de ne a symbolic graph of computation using the eano library [ 6 ] in combination with lasagne [ 3 ]']",3
"['2,  #TAUTHOR_TAG ], sert casts']","['model is interpreted as a metric vector space [ 2,  #TAUTHOR_TAG ], sert casts']","['when the model is interpreted as a metric vector space [ 2,  #TAUTHOR_TAG ], sert casts entity ranking as a k - nearest neighbor problem and uses specialized data structures']","['', 'e concrete implementation used to rank entities depends on the model that was trained.', 'in the most generic case, a matching score is computed for every entity and entities are ranked in decreasing order of his score.', 'however, in the special case when the model is interpreted as a metric vector space [ 2,  #TAUTHOR_TAG ], sert casts entity ranking as a k - nearest neighbor problem and uses specialized data structures for retrieval [ 5 ].', 'a er ranking, sert outputs the entity rankings as a trec - compatible le that can be used as input to the trec eval 1 evaluation utility.', 'in this paper we described the semantic entity retrieval toolkit, a toolkit that learns latent representations of words and entities.', 'e toolkit contains implementations of state - of - the - art entity representations algorithms [  #TAUTHOR_TAG, 9 ] and consists of three components : text processing, representation learning and inference.', 'users of the toolkit can easily make changes to existing model implementations or contribute their own models by extending an interface provided by the sert framework.', 'future work includes integration with pyndri [ 11 ] such that document collections indexed with indri can transparently be used to train entity representations.', 'in addition, integration with machine learning frameworks besides eano, such as tensorflow and pytorch, will make it easier to integrate existing models into sert']",7
"['2,  #TAUTHOR_TAG ], sert casts']","['model is interpreted as a metric vector space [ 2,  #TAUTHOR_TAG ], sert casts']","['when the model is interpreted as a metric vector space [ 2,  #TAUTHOR_TAG ], sert casts entity ranking as a k - nearest neighbor problem and uses specialized data structures']","['', 'e concrete implementation used to rank entities depends on the model that was trained.', 'in the most generic case, a matching score is computed for every entity and entities are ranked in decreasing order of his score.', 'however, in the special case when the model is interpreted as a metric vector space [ 2,  #TAUTHOR_TAG ], sert casts entity ranking as a k - nearest neighbor problem and uses specialized data structures for retrieval [ 5 ].', 'a er ranking, sert outputs the entity rankings as a trec - compatible le that can be used as input to the trec eval 1 evaluation utility.', 'in this paper we described the semantic entity retrieval toolkit, a toolkit that learns latent representations of words and entities.', 'e toolkit contains implementations of state - of - the - art entity representations algorithms [  #TAUTHOR_TAG, 9 ] and consists of three components : text processing, representation learning and inference.', 'users of the toolkit can easily make changes to existing model implementations or contribute their own models by extending an interface provided by the sert framework.', 'future work includes integration with pyndri [ 11 ] such that document collections indexed with indri can transparently be used to train entity representations.', 'in addition, integration with machine learning frameworks besides eano, such as tensorflow and pytorch, will make it easier to integrate existing models into sert']",5
[' #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG'],[' #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG'],"[' #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'the basic motivation behind syntax - based model is']","['', 'to overcome these limitations, many syntaxbased smt models have been proposed  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'the basic motivation behind syntax - based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability.', '']",0
[' #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG'],[' #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG'],"[' #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'the basic motivation behind syntax - based model is']","['', 'to overcome these limitations, many syntaxbased smt models have been proposed  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'the basic motivation behind syntax - based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability.', '']",0
"[' #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', ' #TAUTHOR_TAG differentiated the']","['into different subcategories  #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', ' #TAUTHOR_TAG differentiated the']","['the effects of different rules by classifying the translation rules into different subcategories  #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', ' #TAUTHOR_TAG differentiated the rules in']","['few researches have made some exploratory investigations towards the effects of different rules by classifying the translation rules into different subcategories  #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', '']",0
"[' #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', ' #TAUTHOR_TAG differentiated the']","['into different subcategories  #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', ' #TAUTHOR_TAG differentiated the']","['the effects of different rules by classifying the translation rules into different subcategories  #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', ' #TAUTHOR_TAG differentiated the rules in']","['few researches have made some exploratory investigations towards the effects of different rules by classifying the translation rules into different subcategories  #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', '']",0
['levels  #TAUTHOR_TAG'],['lexicalization levels  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG'],[' #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG'],"[' #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'the basic motivation behind syntax - based model is']","['', 'to overcome these limitations, many syntaxbased smt models have been proposed  #TAUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'the basic motivation behind syntax - based model is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability.', '']",1
"[' #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', ' #TAUTHOR_TAG differentiated the']","['into different subcategories  #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', ' #TAUTHOR_TAG differentiated the']","['the effects of different rules by classifying the translation rules into different subcategories  #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', ' #TAUTHOR_TAG differentiated the rules in']","['few researches have made some exploratory investigations towards the effects of different rules by classifying the translation rules into different subcategories  #TAUTHOR_TAG a ; de  #AUTHOR_TAG.', '']",1
"['presented in  #TAUTHOR_TAG or in  #AUTHOR_TAG a ).', 'taking such']","['presented in  #TAUTHOR_TAG or in  #AUTHOR_TAG a ).', 'taking such']","['presented in  #TAUTHOR_TAG or in  #AUTHOR_TAG a ).', 'taking such a system as the experimental platform,']","['this paper, we present a refined rule classification system.', 'based on this classification system, the rules are classified according to different standards, such as lexicalization level and generalization.', 'especially, we refresh the concepts of the structure reordering rules and the discontiguous phrase rules.', 'this novel classification system may supports the smt research community with some helpful references.', 'in the future works, aiming to analyze the rule contributions and the redundances issues using the presented rule classification based on some real translation systems, we plan to implement some synchronous grammar based syntax translation models such as the one presented in  #TAUTHOR_TAG or in  #AUTHOR_TAG a ).', 'taking such a system as the experimental platform, we can perform comprehensive statistics about distributions of different rule categories.', 'what is more important, the contribution of each rule category can be evaluated seriatim.', 'furthermore, which kinds of rules are preferentially applied in the 1 - best decoding can be studied.', 'all these investigations could reveal very useful information for the optimization of rule extraction and the improvement of the computational models for synchronous grammar based machine translation']",2
"['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming']","['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming']","['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming and can only']","['', ""##lmann and sima'an show that the resulting estimator is consistent. but equally important is the fact that this new dop * model does"", ""not suffer from a decrease in parse accuracy if larger subtrees are included, whereas the original dop model needs to be redressed by a correction factor to maintain this property ( bod 2003 ). moreover, dop *'s estimation procedure is very"", 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming and can only operate by randomly sampling trees. given the advantages of dop *, we will generalize this model in the current paper to unsupervised parsing. we will use the same allsubtrees methodology as in  #TAUTHOR_TAG, but now', 'by applying the efficient and consistent dop * - based estimator. the resulting model, which we will call u - dop *, roughly operates as follows : ( 1', '']",0
"['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming']","['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming']","['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming and can only']","['', ""##lmann and sima'an show that the resulting estimator is consistent. but equally important is the fact that this new dop * model does"", ""not suffer from a decrease in parse accuracy if larger subtrees are included, whereas the original dop model needs to be redressed by a correction factor to maintain this property ( bod 2003 ). moreover, dop *'s estimation procedure is very"", 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming and can only operate by randomly sampling trees. given the advantages of dop *, we will generalize this model in the current paper to unsupervised parsing. we will use the same allsubtrees methodology as in  #TAUTHOR_TAG, but now', 'by applying the efficient and consistent dop * - based estimator. the resulting model, which we will call u - dop *, roughly operates as follows : ( 1', '']",0
"['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming']","['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming']","['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming and can only']","['', ""##lmann and sima'an show that the resulting estimator is consistent. but equally important is the fact that this new dop * model does"", ""not suffer from a decrease in parse accuracy if larger subtrees are included, whereas the original dop model needs to be redressed by a correction factor to maintain this property ( bod 2003 ). moreover, dop *'s estimation procedure is very"", 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming and can only operate by randomly sampling trees. given the advantages of dop *, we will generalize this model in the current paper to unsupervised parsing. we will use the same allsubtrees methodology as in  #TAUTHOR_TAG, but now', 'by applying the efficient and consistent dop * - based estimator. the resulting model, which we will call u - dop *, roughly operates as follows : ( 1', '']",4
"['reduction is applied. this is a huge reduction compared to  #TAUTHOR_TAG where the number of subtrees of', 'all trees increases with']","['reduction is applied. this is a huge reduction compared to  #TAUTHOR_TAG where the number of subtrees of', 'all trees increases with']","['next our pcfg reduction is applied. this is a huge reduction compared to  #TAUTHOR_TAG where the number of subtrees of', 'all trees increases with']","['that there are o ( n 3 ) many nodes that receive a unique address as described above, to which next our pcfg reduction is applied. this is a huge reduction compared to  #TAUTHOR_TAG where the number of subtrees of', 'all trees increases with the catalan number, and only ad hoc sampling could make the method work. since u - dop * computes the shortest derivations ( in the training', 'phase ) by combining subtrees from unlabeled binary trees, the pcfg reduction in figure 1 can be represented as in figure 2, where', 'x refers to the generalized category while b and c either refer to part - of - speech categories or are', 'equivalent to x. the equal weights follow from the fact that the shortest', '']",4
['in  #TAUTHOR_TAG : 1'],['in  #TAUTHOR_TAG : 1'],"['in  #TAUTHOR_TAG : 1. 8 %, while the difference in table']","['', 'a pcfg treebank grammar and the supervised dop * parser using the same test set. for these supervised parsers, we employed the standard training set, i. e', "". penn's wsj sections 2 - 21, but only by taking the p - o - s strings as we did for"", ""our unsupervised u - dop * model. table 5. comparison between the ( best version of ) u - dop *, the supervised treebank pcfg and the supervised dop * for section 23 of penn's wsj as seen in table 5, u -"", 'dop * outperforms the binarized treebank pcfg on the wsj test set. while a similar result was obtained in  #TAUTHOR_TAG : 1. 8 %, while the difference in table 5 is 7. 2 %, corresponding to 19', '. 7 % error reduction. our f - score remains behind the supervised version of dop * but the gap gets narrower as more training data is being', 'added to u - dop *']",4
"['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming']","['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming']","['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming and can only']","['', ""##lmann and sima'an show that the resulting estimator is consistent. but equally important is the fact that this new dop * model does"", ""not suffer from a decrease in parse accuracy if larger subtrees are included, whereas the original dop model needs to be redressed by a correction factor to maintain this property ( bod 2003 ). moreover, dop *'s estimation procedure is very"", 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming and can only operate by randomly sampling trees. given the advantages of dop *, we will generalize this model in the current paper to unsupervised parsing. we will use the same allsubtrees methodology as in  #TAUTHOR_TAG, but now', 'by applying the efficient and consistent dop * - based estimator. the resulting model, which we will call u - dop *, roughly operates as follows : ( 1', '']",5
"['reduction is applied. this is a huge reduction compared to  #TAUTHOR_TAG where the number of subtrees of', 'all trees increases with']","['reduction is applied. this is a huge reduction compared to  #TAUTHOR_TAG where the number of subtrees of', 'all trees increases with']","['next our pcfg reduction is applied. this is a huge reduction compared to  #TAUTHOR_TAG where the number of subtrees of', 'all trees increases with']","['that there are o ( n 3 ) many nodes that receive a unique address as described above, to which next our pcfg reduction is applied. this is a huge reduction compared to  #TAUTHOR_TAG where the number of subtrees of', 'all trees increases with the catalan number, and only ad hoc sampling could make the method work. since u - dop * computes the shortest derivations ( in the training', 'phase ) by combining subtrees from unlabeled binary trees, the pcfg reduction in figure 1 can be represented as in figure 2, where', 'x refers to the generalized category while b and c either refer to part - of - speech categories or are', 'equivalent to x. the equal weights follow from the fact that the shortest', '']",5
"['in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn']","[""in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn's wsj10 which contains 7422 sentences ≤ 10 words after removing empty elements and punctuation,""]","['in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn']","[""evaluate u - dop * against uml - dop and other unsupervised parsing models, we started out with three corpora that are also used in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn's wsj10 which contains 7422 sentences ≤ 10 words after removing empty elements and punctuation, the german negra10 corpus and the chinese treebank ctb10 both containing 2200 + sentences ≤ 10 words after removing punctuation."", 'as with most other unsupervised parsing models, we train and test on p - o - s strings rather than on word strings.', 'the extension to word strings is straightforward as there exist highly accurate unsupervised part - of - speech taggers ( e. g. schutze 1995 ) which can be directly combined with unsupervised parsers, but for the moment we will stick to p - o - s strings ( we will come back to word strings in section 5 ).', 'each corpus was divided into 10 training / test set splits of 90 % / 10 % ( n - fold testing ), and each training set was randomly divided into two equal parts, that serve as ec and hc and vice versa.', 'we used the same evaluation metrics for unlabeled precision ( up ) and unlabeled recall ( ur ) as in  #AUTHOR_TAG, 2004 ).', '']",5
"['in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn']","[""in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn's wsj10 which contains 7422 sentences ≤ 10 words after removing empty elements and punctuation,""]","['in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn']","[""evaluate u - dop * against uml - dop and other unsupervised parsing models, we started out with three corpora that are also used in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn's wsj10 which contains 7422 sentences ≤ 10 words after removing empty elements and punctuation, the german negra10 corpus and the chinese treebank ctb10 both containing 2200 + sentences ≤ 10 words after removing punctuation."", 'as with most other unsupervised parsing models, we train and test on p - o - s strings rather than on word strings.', 'the extension to word strings is straightforward as there exist highly accurate unsupervised part - of - speech taggers ( e. g. schutze 1995 ) which can be directly combined with unsupervised parsers, but for the moment we will stick to p - o - s strings ( we will come back to word strings in section 5 ).', 'each corpus was divided into 10 training / test set splits of 90 % / 10 % ( n - fold testing ), and each training set was randomly divided into two equal parts, that serve as ec and hc and vice versa.', 'we used the same evaluation metrics for unlabeled precision ( up ) and unlabeled recall ( ur ) as in  #AUTHOR_TAG, 2004 ).', '']",5
"['in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn']","[""in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn's wsj10 which contains 7422 sentences ≤ 10 words after removing empty elements and punctuation,""]","['in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn']","[""evaluate u - dop * against uml - dop and other unsupervised parsing models, we started out with three corpora that are also used in  #AUTHOR_TAG, 2004 ) and  #TAUTHOR_TAG : penn's wsj10 which contains 7422 sentences ≤ 10 words after removing empty elements and punctuation, the german negra10 corpus and the chinese treebank ctb10 both containing 2200 + sentences ≤ 10 words after removing punctuation."", 'as with most other unsupervised parsing models, we train and test on p - o - s strings rather than on word strings.', 'the extension to word strings is straightforward as there exist highly accurate unsupervised part - of - speech taggers ( e. g. schutze 1995 ) which can be directly combined with unsupervised parsers, but for the moment we will stick to p - o - s strings ( we will come back to word strings in section 5 ).', 'each corpus was divided into 10 training / test set splits of 90 % / 10 % ( n - fold testing ), and each training set was randomly divided into two equal parts, that serve as ec and hc and vice versa.', 'we used the same evaluation metrics for unlabeled precision ( up ) and unlabeled recall ( ur ) as in  #AUTHOR_TAG, 2004 ).', '']",5
"['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming']","['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming']","['s estimation procedure is very', 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming and can only']","['', ""##lmann and sima'an show that the resulting estimator is consistent. but equally important is the fact that this new dop * model does"", ""not suffer from a decrease in parse accuracy if larger subtrees are included, whereas the original dop model needs to be redressed by a correction factor to maintain this property ( bod 2003 ). moreover, dop *'s estimation procedure is very"", 'efficient, while the em training procedure for uml - dop proposed in  #TAUTHOR_TAG is particularly time consuming and can only operate by randomly sampling trees. given the advantages of dop *, we will generalize this model in the current paper to unsupervised parsing. we will use the same allsubtrees methodology as in  #TAUTHOR_TAG, but now', 'by applying the efficient and consistent dop * - based estimator. the resulting model, which we will call u - dop *, roughly operates as follows : ( 1', '']",6
"['and report results for several models on it.', ' #TAUTHOR_TAG improve webspl']","['and report results for several models on it.', ' #TAUTHOR_TAG improve websplit by reducing overlap in the']","['rather than expensive expert annotation  #AUTHOR_TAG.', 'introduce the websplit corpus for the split - and - rephrase task and report results for several models on it.', ' #TAUTHOR_TAG improve webspl']","['', 'performing this split - and - rephrase task is one of the main operations in text simplification, alongside paraphrasing and dropping less salient content  #AUTHOR_TAG i. a. ).', 'the area of automatic text simplification has received a lot of attention  #AUTHOR_TAG, yet still holds many open challenges  #AUTHOR_TAG.', 'splitting sentences in this way could also benefit systems where predictive quality degrades with sentence length, as observed in, e. g., relation extraction  #AUTHOR_TAG and translation  #AUTHOR_TAG. and the schema - free nature of the task may allow for future supervision in the form of crowd - sourced rather than expensive expert annotation  #AUTHOR_TAG.', 'introduce the websplit corpus for the split - and - rephrase task and report results for several models on it.', ' #TAUTHOR_TAG improve websplit by reducing overlap in the data splits, and * both authors contributed equally.', 'a classic leaf symptom is water - soaked lesions between the veins which appear as angular leaf - spots where the lesion edge and vein meet.', 'a classic leaf symptom is the appearance of angular, water - soaked lesions between the veins.', 'the angular appearance results where the lesion edge and vein meet.', 'demonstrate that neural encoder - decoder models  #AUTHOR_TAG perform poorly, even when enhanced with a copy mechanism  #AUTHOR_TAG.', 'one limitation of the websplit examples themselves is that they contain fairly unnatural linguistic expression using a small vocabulary.', 'we introduce new training data mined from wikipedia edit histories that have some noise, but which have a rich and varied vocabulary over naturally expressed sentences and their extracted splits.', 'figure 1 gives an example of how a wikipedia editor rewrote a single sentence into two simpler ones.', 'we create wikisplit, a set of one million such examples mined from english wikipedia, and show that models trained with this resource produce dramatically better output for split and rephrase.', 'our primary contributions are :', '• a scalable, language agnostic method for extracting split - and - rephrase rewrites from wikipedia edits.', '• public release of the english wikisplit dataset, containing one million rewrites :', 'http : / / goo. gl / language / wiki - split', '• by incorporating wikisplit into training, we more than double ( 30. 5 to 62. 4 ) the bleu score obtained on websplit by  #TAUTHOR_TAG.', 'figure 1']",0
"['and report results for several models on it.', ' #TAUTHOR_TAG improve webspl']","['and report results for several models on it.', ' #TAUTHOR_TAG improve websplit by reducing overlap in the']","['rather than expensive expert annotation  #AUTHOR_TAG.', 'introduce the websplit corpus for the split - and - rephrase task and report results for several models on it.', ' #TAUTHOR_TAG improve webspl']","['', 'performing this split - and - rephrase task is one of the main operations in text simplification, alongside paraphrasing and dropping less salient content  #AUTHOR_TAG i. a. ).', 'the area of automatic text simplification has received a lot of attention  #AUTHOR_TAG, yet still holds many open challenges  #AUTHOR_TAG.', 'splitting sentences in this way could also benefit systems where predictive quality degrades with sentence length, as observed in, e. g., relation extraction  #AUTHOR_TAG and translation  #AUTHOR_TAG. and the schema - free nature of the task may allow for future supervision in the form of crowd - sourced rather than expensive expert annotation  #AUTHOR_TAG.', 'introduce the websplit corpus for the split - and - rephrase task and report results for several models on it.', ' #TAUTHOR_TAG improve websplit by reducing overlap in the data splits, and * both authors contributed equally.', 'a classic leaf symptom is water - soaked lesions between the veins which appear as angular leaf - spots where the lesion edge and vein meet.', 'a classic leaf symptom is the appearance of angular, water - soaked lesions between the veins.', 'the angular appearance results where the lesion edge and vein meet.', 'demonstrate that neural encoder - decoder models  #AUTHOR_TAG perform poorly, even when enhanced with a copy mechanism  #AUTHOR_TAG.', 'one limitation of the websplit examples themselves is that they contain fairly unnatural linguistic expression using a small vocabulary.', 'we introduce new training data mined from wikipedia edit histories that have some noise, but which have a rich and varied vocabulary over naturally expressed sentences and their extracted splits.', 'figure 1 gives an example of how a wikipedia editor rewrote a single sentence into two simpler ones.', 'we create wikisplit, a set of one million such examples mined from english wikipedia, and show that models trained with this resource produce dramatically better output for split and rephrase.', 'our primary contributions are :', '• a scalable, language agnostic method for extracting split - and - rephrase rewrites from wikipedia edits.', '• public release of the english wikisplit dataset, containing one million rewrites :', 'http : / / goo. gl / language / wiki - split', '• by incorporating wikisplit into training, we more than double ( 30. 5 to 62. 4 ) the bleu score obtained on websplit by  #TAUTHOR_TAG.', 'figure 1']",3
"['categorization schema proposed by  #TAUTHOR_TAG ; see table 1 for examples of correct,']","['categorization schema proposed by  #TAUTHOR_TAG ; see table 1 for examples of correct,']","['extraction heuristic is imperfect, so we manually assess corpus quality using the same categorization schema proposed by  #TAUTHOR_TAG ; see table 1 for examples of correct,']","['extraction heuristic is imperfect, so we manually assess corpus quality using the same categorization schema proposed by  #TAUTHOR_TAG ; see table 1 for examples of correct, unsupported and missing sentences in splits extracted from wikipedia.', 'we do this for 100 randomly selected examples using three different thresholds of δ.', 'as shown in table 2, δ = 0. 2 provides the best trade - off between quality and size.', 'out of the 100 complex sentences in the sample, only 4 contained information that was not completely covered by the simple sentences.', 'in our corpus, every complex sentence is split into two simpler sentences, so the sample contains 200 simple sentences.', '']",3
"['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['order to understand how wikisplit can inform the split - and - rephrase task, we vary the composition of the training set when training a fixed model architecture.', 'we compare three training configurations : websplit only, wikisplit only, and both, which is simply their concatenation.', 'text - to - text training instances are defined as all the unique pairs of ( c, s ), where c is a complex sentence and s is its simplification into multiple simple sentences  #TAUTHOR_TAG.', 'for training, we delimit the simple sentences with a special symbol.', 'we depart from the prior work by only using a subset of the websplit training set : we take a fixed sub - sample such that each distinct c is paired with a single s, randomly selected from the multiple possibilities in the dataset.', 'this scheme produced superior performance in preliminary experiments.', 'as a quality measure, we report multi - reference corpus - level bleu 4  #AUTHOR_TAG, but include sentence - level bleu ( sbleu ) for direct comparison to past work.', '5 we also report lengthbased statistics to quantify splitting.', 'we use the same sequence - to - sequence architecture that produced the top result for  #TAUTHOR_TAG, "" copy512 "", which is a one - layer, bi - directional lstm ( cell size 512 ) with attention  #AUTHOR_TAG and a copying mechanism  #AUTHOR_TAG that dynamically interpolates the standard word distribution with a distribution over the words in the input sentence.', 'training details are as described in the appendix of  #TAUTHOR_TAG using the opennmt - py framework  #AUTHOR_TAG.', '']",3
"['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['order to understand how wikisplit can inform the split - and - rephrase task, we vary the composition of the training set when training a fixed model architecture.', 'we compare three training configurations : websplit only, wikisplit only, and both, which is simply their concatenation.', 'text - to - text training instances are defined as all the unique pairs of ( c, s ), where c is a complex sentence and s is its simplification into multiple simple sentences  #TAUTHOR_TAG.', 'for training, we delimit the simple sentences with a special symbol.', 'we depart from the prior work by only using a subset of the websplit training set : we take a fixed sub - sample such that each distinct c is paired with a single s, randomly selected from the multiple possibilities in the dataset.', 'this scheme produced superior performance in preliminary experiments.', 'as a quality measure, we report multi - reference corpus - level bleu 4  #AUTHOR_TAG, but include sentence - level bleu ( sbleu ) for direct comparison to past work.', '5 we also report lengthbased statistics to quantify splitting.', 'we use the same sequence - to - sequence architecture that produced the top result for  #TAUTHOR_TAG, "" copy512 "", which is a one - layer, bi - directional lstm ( cell size 512 ) with attention  #AUTHOR_TAG and a copying mechanism  #AUTHOR_TAG that dynamically interpolates the standard word distribution with a distribution over the words in the input sentence.', 'training details are as described in the appendix of  #TAUTHOR_TAG using the opennmt - py framework  #AUTHOR_TAG.', '']",3
"['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['order to understand how wikisplit can inform the split - and - rephrase task, we vary the composition of the training set when training a fixed model architecture.', 'we compare three training configurations : websplit only, wikisplit only, and both, which is simply their concatenation.', 'text - to - text training instances are defined as all the unique pairs of ( c, s ), where c is a complex sentence and s is its simplification into multiple simple sentences  #TAUTHOR_TAG.', 'for training, we delimit the simple sentences with a special symbol.', 'we depart from the prior work by only using a subset of the websplit training set : we take a fixed sub - sample such that each distinct c is paired with a single s, randomly selected from the multiple possibilities in the dataset.', 'this scheme produced superior performance in preliminary experiments.', 'as a quality measure, we report multi - reference corpus - level bleu 4  #AUTHOR_TAG, but include sentence - level bleu ( sbleu ) for direct comparison to past work.', '5 we also report lengthbased statistics to quantify splitting.', 'we use the same sequence - to - sequence architecture that produced the top result for  #TAUTHOR_TAG, "" copy512 "", which is a one - layer, bi - directional lstm ( cell size 512 ) with attention  #AUTHOR_TAG and a copying mechanism  #AUTHOR_TAG that dynamically interpolates the standard word distribution with a distribution over the words in the input sentence.', 'training details are as described in the appendix of  #TAUTHOR_TAG using the opennmt - py framework  #AUTHOR_TAG.', '']",3
"['and report results for several models on it.', ' #TAUTHOR_TAG improve webspl']","['and report results for several models on it.', ' #TAUTHOR_TAG improve websplit by reducing overlap in the']","['rather than expensive expert annotation  #AUTHOR_TAG.', 'introduce the websplit corpus for the split - and - rephrase task and report results for several models on it.', ' #TAUTHOR_TAG improve webspl']","['', 'performing this split - and - rephrase task is one of the main operations in text simplification, alongside paraphrasing and dropping less salient content  #AUTHOR_TAG i. a. ).', 'the area of automatic text simplification has received a lot of attention  #AUTHOR_TAG, yet still holds many open challenges  #AUTHOR_TAG.', 'splitting sentences in this way could also benefit systems where predictive quality degrades with sentence length, as observed in, e. g., relation extraction  #AUTHOR_TAG and translation  #AUTHOR_TAG. and the schema - free nature of the task may allow for future supervision in the form of crowd - sourced rather than expensive expert annotation  #AUTHOR_TAG.', 'introduce the websplit corpus for the split - and - rephrase task and report results for several models on it.', ' #TAUTHOR_TAG improve websplit by reducing overlap in the data splits, and * both authors contributed equally.', 'a classic leaf symptom is water - soaked lesions between the veins which appear as angular leaf - spots where the lesion edge and vein meet.', 'a classic leaf symptom is the appearance of angular, water - soaked lesions between the veins.', 'the angular appearance results where the lesion edge and vein meet.', 'demonstrate that neural encoder - decoder models  #AUTHOR_TAG perform poorly, even when enhanced with a copy mechanism  #AUTHOR_TAG.', 'one limitation of the websplit examples themselves is that they contain fairly unnatural linguistic expression using a small vocabulary.', 'we introduce new training data mined from wikipedia edit histories that have some noise, but which have a rich and varied vocabulary over naturally expressed sentences and their extracted splits.', 'figure 1 gives an example of how a wikipedia editor rewrote a single sentence into two simpler ones.', 'we create wikisplit, a set of one million such examples mined from english wikipedia, and show that models trained with this resource produce dramatically better output for split and rephrase.', 'our primary contributions are :', '• a scalable, language agnostic method for extracting split - and - rephrase rewrites from wikipedia edits.', '• public release of the english wikisplit dataset, containing one million rewrites :', 'http : / / goo. gl / language / wiki - split', '• by incorporating wikisplit into training, we more than double ( 30. 5 to 62. 4 ) the bleu score obtained on websplit by  #TAUTHOR_TAG.', 'figure 1']",5
"['categorization schema proposed by  #TAUTHOR_TAG ; see table 1 for examples of correct,']","['categorization schema proposed by  #TAUTHOR_TAG ; see table 1 for examples of correct,']","['extraction heuristic is imperfect, so we manually assess corpus quality using the same categorization schema proposed by  #TAUTHOR_TAG ; see table 1 for examples of correct,']","['extraction heuristic is imperfect, so we manually assess corpus quality using the same categorization schema proposed by  #TAUTHOR_TAG ; see table 1 for examples of correct, unsupported and missing sentences in splits extracted from wikipedia.', 'we do this for 100 randomly selected examples using three different thresholds of δ.', 'as shown in table 2, δ = 0. 2 provides the best trade - off between quality and size.', 'out of the 100 complex sentences in the sample, only 4 contained information that was not completely covered by the simple sentences.', 'in our corpus, every complex sentence is split into two simpler sentences, so the sample contains 200 simple sentences.', '']",5
"['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['order to understand how wikisplit can inform the split - and - rephrase task, we vary the composition of the training set when training a fixed model architecture.', 'we compare three training configurations : websplit only, wikisplit only, and both, which is simply their concatenation.', 'text - to - text training instances are defined as all the unique pairs of ( c, s ), where c is a complex sentence and s is its simplification into multiple simple sentences  #TAUTHOR_TAG.', 'for training, we delimit the simple sentences with a special symbol.', 'we depart from the prior work by only using a subset of the websplit training set : we take a fixed sub - sample such that each distinct c is paired with a single s, randomly selected from the multiple possibilities in the dataset.', 'this scheme produced superior performance in preliminary experiments.', 'as a quality measure, we report multi - reference corpus - level bleu 4  #AUTHOR_TAG, but include sentence - level bleu ( sbleu ) for direct comparison to past work.', '5 we also report lengthbased statistics to quantify splitting.', 'we use the same sequence - to - sequence architecture that produced the top result for  #TAUTHOR_TAG, "" copy512 "", which is a one - layer, bi - directional lstm ( cell size 512 ) with attention  #AUTHOR_TAG and a copying mechanism  #AUTHOR_TAG that dynamically interpolates the standard word distribution with a distribution over the words in the input sentence.', 'training details are as described in the appendix of  #TAUTHOR_TAG using the opennmt - py framework  #AUTHOR_TAG.', '']",5
"['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['is its simplification into multiple simple sentences  #TAUTHOR_TAG.', '']","['order to understand how wikisplit can inform the split - and - rephrase task, we vary the composition of the training set when training a fixed model architecture.', 'we compare three training configurations : websplit only, wikisplit only, and both, which is simply their concatenation.', 'text - to - text training instances are defined as all the unique pairs of ( c, s ), where c is a complex sentence and s is its simplification into multiple simple sentences  #TAUTHOR_TAG.', 'for training, we delimit the simple sentences with a special symbol.', 'we depart from the prior work by only using a subset of the websplit training set : we take a fixed sub - sample such that each distinct c is paired with a single s, randomly selected from the multiple possibilities in the dataset.', 'this scheme produced superior performance in preliminary experiments.', 'as a quality measure, we report multi - reference corpus - level bleu 4  #AUTHOR_TAG, but include sentence - level bleu ( sbleu ) for direct comparison to past work.', '5 we also report lengthbased statistics to quantify splitting.', 'we use the same sequence - to - sequence architecture that produced the top result for  #TAUTHOR_TAG, "" copy512 "", which is a one - layer, bi - directional lstm ( cell size 512 ) with attention  #AUTHOR_TAG and a copying mechanism  #AUTHOR_TAG that dynamically interpolates the standard word distribution with a distribution over the words in the input sentence.', 'training details are as described in the appendix of  #TAUTHOR_TAG using the opennmt - py framework  #AUTHOR_TAG.', '']",5
[' #TAUTHOR_TAG reported'],[' #TAUTHOR_TAG reported macro - averaged sentence'],['on websplit  #TAUTHOR_TAG reported'],"['4 using nltk v3. 2. 2, with case sensitive scoring. 5 past work on websplit  #TAUTHOR_TAG reported macro - averaged sentence - level bleu, calculated without smoothing precision values of zero. we found this ill - defined case occurred often for low', '- quality output. 6 github. com / opennmt / opennmt - py, 0ece', '##c8b table 5 : results on the websplit v1. 0 test set when varying the training data while holding model architecture fixed : corpus - level bleu, sentence - level bleu ( to match past work', '), simple sentences per complex sentence, and tokens per simple sentence ( micro - average ). ag18 is the previous best model by  #TAUTHOR_TAG, which used the full websplit training set, whereas we downsampled it. dient "", "" publisher "" ) and generally fails to produce coherent sentences. in contrast', ', the wikisplit model achieves 59. 4 bleu on the websplit validation set, without observing any in - domain', '']",5
[' #TAUTHOR_TAG reported'],[' #TAUTHOR_TAG reported macro - averaged sentence'],['on websplit  #TAUTHOR_TAG reported'],"['4 using nltk v3. 2. 2, with case sensitive scoring. 5 past work on websplit  #TAUTHOR_TAG reported macro - averaged sentence - level bleu, calculated without smoothing precision values of zero. we found this ill - defined case occurred often for low', '- quality output. 6 github. com / opennmt / opennmt - py, 0ece', '##c8b table 5 : results on the websplit v1. 0 test set when varying the training data while holding model architecture fixed : corpus - level bleu, sentence - level bleu ( to match past work', '), simple sentences per complex sentence, and tokens per simple sentence ( micro - average ). ag18 is the previous best model by  #TAUTHOR_TAG, which used the full websplit training set, whereas we downsampled it. dient "", "" publisher "" ) and generally fails to produce coherent sentences. in contrast', ', the wikisplit model achieves 59. 4 bleu on the websplit validation set, without observing any in - domain', '']",4
[' #TAUTHOR_TAG reported'],[' #TAUTHOR_TAG reported macro - averaged sentence'],['on websplit  #TAUTHOR_TAG reported'],"['4 using nltk v3. 2. 2, with case sensitive scoring. 5 past work on websplit  #TAUTHOR_TAG reported macro - averaged sentence - level bleu, calculated without smoothing precision values of zero. we found this ill - defined case occurred often for low', '- quality output. 6 github. com / opennmt / opennmt - py, 0ece', '##c8b table 5 : results on the websplit v1. 0 test set when varying the training data while holding model architecture fixed : corpus - level bleu, sentence - level bleu ( to match past work', '), simple sentences per complex sentence, and tokens per simple sentence ( micro - average ). ag18 is the previous best model by  #TAUTHOR_TAG, which used the full websplit training set, whereas we downsampled it. dient "", "" publisher "" ) and generally fails to produce coherent sentences. in contrast', ', the wikisplit model achieves 59. 4 bleu on the websplit validation set, without observing any in - domain', '']",4
[' #TAUTHOR_TAG reported'],[' #TAUTHOR_TAG reported macro - averaged sentence'],['on websplit  #TAUTHOR_TAG reported'],"['4 using nltk v3. 2. 2, with case sensitive scoring. 5 past work on websplit  #TAUTHOR_TAG reported macro - averaged sentence - level bleu, calculated without smoothing precision values of zero. we found this ill - defined case occurred often for low', '- quality output. 6 github. com / opennmt / opennmt - py, 0ece', '##c8b table 5 : results on the websplit v1. 0 test set when varying the training data while holding model architecture fixed : corpus - level bleu, sentence - level bleu ( to match past work', '), simple sentences per complex sentence, and tokens per simple sentence ( micro - average ). ag18 is the previous best model by  #TAUTHOR_TAG, which used the full websplit training set, whereas we downsampled it. dient "", "" publisher "" ) and generally fails to produce coherent sentences. in contrast', ', the wikisplit model achieves 59. 4 bleu on the websplit validation set, without observing any in - domain', '']",4
[' #TAUTHOR_TAG reported'],[' #TAUTHOR_TAG reported macro - averaged sentence'],['on websplit  #TAUTHOR_TAG reported'],"['4 using nltk v3. 2. 2, with case sensitive scoring. 5 past work on websplit  #TAUTHOR_TAG reported macro - averaged sentence - level bleu, calculated without smoothing precision values of zero. we found this ill - defined case occurred often for low', '- quality output. 6 github. com / opennmt / opennmt - py, 0ece', '##c8b table 5 : results on the websplit v1. 0 test set when varying the training data while holding model architecture fixed : corpus - level bleu, sentence - level bleu ( to match past work', '), simple sentences per complex sentence, and tokens per simple sentence ( micro - average ). ag18 is the previous best model by  #TAUTHOR_TAG, which used the full websplit training set, whereas we downsampled it. dient "", "" publisher "" ) and generally fails to produce coherent sentences. in contrast', ', the wikisplit model achieves 59. 4 bleu on the websplit validation set, without observing any in - domain', '']",6
[' #TAUTHOR_TAG reported'],[' #TAUTHOR_TAG reported macro - averaged sentence'],['on websplit  #TAUTHOR_TAG reported'],"['4 using nltk v3. 2. 2, with case sensitive scoring. 5 past work on websplit  #TAUTHOR_TAG reported macro - averaged sentence - level bleu, calculated without smoothing precision values of zero. we found this ill - defined case occurred often for low', '- quality output. 6 github. com / opennmt / opennmt - py, 0ece', '##c8b table 5 : results on the websplit v1. 0 test set when varying the training data while holding model architecture fixed : corpus - level bleu, sentence - level bleu ( to match past work', '), simple sentences per complex sentence, and tokens per simple sentence ( micro - average ). ag18 is the previous best model by  #TAUTHOR_TAG, which used the full websplit training set, whereas we downsampled it. dient "", "" publisher "" ) and generally fails to produce coherent sentences. in contrast', ', the wikisplit model achieves 59. 4 bleu on the websplit validation set, without observing any in - domain', '']",6
"['quality estimation c. de  #TAUTHOR_TAG, and the task for which transcrater, the tool described in this paper, has been designed.', 'the']","['on asr quality estimation c. de  #TAUTHOR_TAG, and the task for which transcrater, the tool described in this paper, has been designed.', 'the']","['on asr quality estimation c. de  #TAUTHOR_TAG, and the task for which transcrater, the tool described in this paper, has been designed.', 'the work on as']","['to determine the quality of an automatic transcription without reference transcripts and without confidence information?', 'this is the key problem addressed by research on asr quality estimation c. de  #TAUTHOR_TAG, and the task for which transcrater, the tool described in this paper, has been designed.', '']",0
"['as a qe - based ranking problem  #TAUTHOR_TAG, in which each utterance is captured by multiple microphones or transcribed by multiple as']","['as a qe - based ranking problem  #TAUTHOR_TAG, in which each utterance is captured by multiple microphones or transcribed by multiple asr systems.', 'in this case, the capability to rank transcriptions from the best to the worst']","['as a qe - based ranking problem  #TAUTHOR_TAG, in which each utterance is captured by multiple microphones or transcribed by multiple asr systems.', 'in this case, the capability to rank transcriptions from the best to the worst']","['', 'a variant of the basic asr qe task is to consider it as a qe - based ranking problem  #TAUTHOR_TAG, in which each utterance is captured by multiple microphones or transcribed by multiple asr systems.', 'in this case, the capability to rank transcriptions from the best to the worst can be evaluated in terms of normalized discounted cumulative gain ( ndcg ) or similar metrics']",0
"['contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that']","['contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that']","['contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that']","['regression - based tasks ( wer prediction ), transcrater includes an interface to the scikitlearn package  #AUTHOR_TAG, a python machine learning library that contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that extremely randomized trees ( xrt  #AUTHOR_TAG ) is a very competitive algorithm in several wer prediction tasks, the current version of the tool exploits xrt.', 'however, adapting the interface to apply other algorithms is an easy task and one of the future extension directions.', 'the main hyper - parameters of the model, such as the number of tree bags, the number of trees per bag, the number of features per tree and the number of instances in the leaves, are tuned using grid search with k - fold cross - validation on the training set to minimize the mean absolute error ( mae ) between the true wers and the predicted ones.', 'as mentioned before, transcrater provides the possibility to evaluate multiple transcriptions ( e. g. obtained from different microphones or asr systems ) and rank them based on their quality.', 'this can be done either indirectly, by exploiting the predicted wer labels in a "" ranking by regression "" approach ( rr ) or directly, by exploiting machinelearned ranking methods ( mlr ).', 'to train and test mlr models, transcrater exploits ranklib 8, a library of learning - to - rank algorithms.', 'the current version of the tool includes an interface to the random forest algorithm ( rf  #AUTHOR_TAG ), the same used in  #TAUTHOR_TAG.', 'mlr predicts ranks through pairwise comparison between the transcriptions.', 'the main parameters such as the number of bags, the number of trees per bag and the number of leaves per tree are tuned on training set using k - fold cross - validation to maximize the ndcg measure']",0
"['works c. de  #TAUTHOR_TAG a ).', 'to further investigate']","['works c. de  #TAUTHOR_TAG a ).', 'to further investigate']","['features and algorithms contained in transcrater have been successfully used in previous works c. de  #TAUTHOR_TAG a ).', 'to further investigate']","['features and algorithms contained in transcrater have been successfully used in previous works c. de  #TAUTHOR_TAG a ).', 'to further investigate their effectiveness, in this section we provide new results, both in wer prediction ( mae ) and transcription ranking ( ndcg ), together with some efficiency analysis ( time in seconds 9 ).', 'to this aim, we use data from the 3 rd chime challenge, 10 which were collected for multiple distant microphone speech recognition in noisy environments  #AUTHOR_TAG.', 'chime - 3 data consists of sentences of the wall street journal corpus, uttered by four speakers in four noisy environments, and recorded by five microphones placed on the frame of a tablet pc ( a sixth one, placed on the back, mainly records background noise ).', 'training and test respectively contain 1, 640 and 1, 320 sentences.', 'transcriptions are produced by a baseline asr system, provided by the task organizers, which uses the deep neural network recipe of kaldi  #AUTHOR_TAG.', 'in wer prediction, different models built with transcrater are compared with a baseline commonly used for regression tasks, which labels all the test instances with the average wer value computed on the training set.', 'in ranking mode, baseline results are computed by averaging the ndcg scores obtained in one hundred iterations in which test instances are randomly ranked.', 'table 1 shows the results of models trained with different feature groups for wer prediction with a single microphone.', 'in terms of time, in this as in the following experiments, the total time ( feature extraction + training + test ) is mostly determined by feature extraction and the bottleneck is clearly represented by the extraction of signal ( sig ) features.', 'in terms of mae, sig features are also those achieving the worst result.', 'although they significantly improve over the baseline, they are outperformed by lex + lm + pos and, even in combination with them, they do not help.', 'however, as suggested by previous works like ( in which some of the sig features are among the most predictive ones, the usefulness of signal features highly depends on data and, in specific conditions, they definitely improve results.', 'their ineffectiveness in the experiments of this paper likely depends on the lack of wordlevel time boundaries, which prevented us to compute more discriminative features like word logenergies, noise log - energies and signal - to - noise ratio ( the best indicator of the acoustic quality of an input utterance ).', 'table 2 shows the results achieved by the same feature groups when ranking by regression ( rr ) the transcriptions from five microphones.', 'in terms of computation time, the higher']",0
"['contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that']","['contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that']","['contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that']","['regression - based tasks ( wer prediction ), transcrater includes an interface to the scikitlearn package  #AUTHOR_TAG, a python machine learning library that contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that extremely randomized trees ( xrt  #AUTHOR_TAG ) is a very competitive algorithm in several wer prediction tasks, the current version of the tool exploits xrt.', 'however, adapting the interface to apply other algorithms is an easy task and one of the future extension directions.', 'the main hyper - parameters of the model, such as the number of tree bags, the number of trees per bag, the number of features per tree and the number of instances in the leaves, are tuned using grid search with k - fold cross - validation on the training set to minimize the mean absolute error ( mae ) between the true wers and the predicted ones.', 'as mentioned before, transcrater provides the possibility to evaluate multiple transcriptions ( e. g. obtained from different microphones or asr systems ) and rank them based on their quality.', 'this can be done either indirectly, by exploiting the predicted wer labels in a "" ranking by regression "" approach ( rr ) or directly, by exploiting machinelearned ranking methods ( mlr ).', 'to train and test mlr models, transcrater exploits ranklib 8, a library of learning - to - rank algorithms.', 'the current version of the tool includes an interface to the random forest algorithm ( rf  #AUTHOR_TAG ), the same used in  #TAUTHOR_TAG.', 'mlr predicts ranks through pairwise comparison between the transcriptions.', 'the main parameters such as the number of bags, the number of trees per bag and the number of leaves per tree are tuned on training set using k - fold cross - validation to maximize the ndcg measure']",3
"['contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that']","['contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that']","['contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that']","['regression - based tasks ( wer prediction ), transcrater includes an interface to the scikitlearn package  #AUTHOR_TAG, a python machine learning library that contains a large set of classification and regression algorithms.', 'based on the empirical results reported in c. de  #TAUTHOR_TAG, which indicate that extremely randomized trees ( xrt  #AUTHOR_TAG ) is a very competitive algorithm in several wer prediction tasks, the current version of the tool exploits xrt.', 'however, adapting the interface to apply other algorithms is an easy task and one of the future extension directions.', 'the main hyper - parameters of the model, such as the number of tree bags, the number of trees per bag, the number of features per tree and the number of instances in the leaves, are tuned using grid search with k - fold cross - validation on the training set to minimize the mean absolute error ( mae ) between the true wers and the predicted ones.', 'as mentioned before, transcrater provides the possibility to evaluate multiple transcriptions ( e. g. obtained from different microphones or asr systems ) and rank them based on their quality.', 'this can be done either indirectly, by exploiting the predicted wer labels in a "" ranking by regression "" approach ( rr ) or directly, by exploiting machinelearned ranking methods ( mlr ).', 'to train and test mlr models, transcrater exploits ranklib 8, a library of learning - to - rank algorithms.', 'the current version of the tool includes an interface to the random forest algorithm ( rf  #AUTHOR_TAG ), the same used in  #TAUTHOR_TAG.', 'mlr predicts ranks through pairwise comparison between the transcriptions.', 'the main parameters such as the number of bags, the number of trees per bag and the number of leaves per tree are tuned on training set using k - fold cross - validation to maximize the ndcg measure']",5
['machine translation ( nmt )  #TAUTHOR_TAG trains an encoder'],['machine translation ( nmt )  #TAUTHOR_TAG trains an'],['machine translation ( nmt )  #TAUTHOR_TAG trains'],"['machine translation ( nmt )  #TAUTHOR_TAG trains an encoder - decoder network on sentence pairs to maximize the likelihood of predicting a target - language sentence given the corresponding source - language sentence, without considering the document context.', 'by ignoring discourse connections between sentences and other valuable contextual information, this simplification potentially degrades the coherence and cohesion of a translated document  #AUTHOR_TAG.', 'recent studies  #AUTHOR_TAG have demonstrated that adding contextual information to the nmt model improves the general translation performance, and more importantly, improves the coherence and cohesion of the translated text  #AUTHOR_TAG lapshinova -  #AUTHOR_TAG.', '']",0
[' #TAUTHOR_TAG to capture different types of'],[' #TAUTHOR_TAG to capture different types of'],[' #TAUTHOR_TAG to capture different types of'],"['', 'the function f w is a linear transformation to obtain the query q w.', 'we used the multihead attention function proposed by  #TAUTHOR_TAG to capture different types of relations among words.', 'it matches the query against each of the hidden representations h j i ( used as value and key for the attention ).', '']",0
['machine translation ( nmt )  #TAUTHOR_TAG trains an encoder'],['machine translation ( nmt )  #TAUTHOR_TAG trains an'],['machine translation ( nmt )  #TAUTHOR_TAG trains'],"['machine translation ( nmt )  #TAUTHOR_TAG trains an encoder - decoder network on sentence pairs to maximize the likelihood of predicting a target - language sentence given the corresponding source - language sentence, without considering the document context.', 'by ignoring discourse connections between sentences and other valuable contextual information, this simplification potentially degrades the coherence and cohesion of a translated document  #AUTHOR_TAG.', 'recent studies  #AUTHOR_TAG have demonstrated that adding contextual information to the nmt model improves the general translation performance, and more importantly, improves the coherence and cohesion of the translated text  #AUTHOR_TAG lapshinova -  #AUTHOR_TAG.', '']",5
['machine translation ( nmt )  #TAUTHOR_TAG trains an encoder'],['machine translation ( nmt )  #TAUTHOR_TAG trains an'],['machine translation ( nmt )  #TAUTHOR_TAG trains'],"['machine translation ( nmt )  #TAUTHOR_TAG trains an encoder - decoder network on sentence pairs to maximize the likelihood of predicting a target - language sentence given the corresponding source - language sentence, without considering the document context.', 'by ignoring discourse connections between sentences and other valuable contextual information, this simplification potentially degrades the coherence and cohesion of a translated document  #AUTHOR_TAG.', 'recent studies  #AUTHOR_TAG have demonstrated that adding contextual information to the nmt model improves the general translation performance, and more importantly, improves the coherence and cohesion of the translated text  #AUTHOR_TAG lapshinova -  #AUTHOR_TAG.', '']",5
[' #TAUTHOR_TAG to capture different types of'],[' #TAUTHOR_TAG to capture different types of'],[' #TAUTHOR_TAG to capture different types of'],"['', 'the function f w is a linear transformation to obtain the query q w.', 'we used the multihead attention function proposed by  #TAUTHOR_TAG to capture different types of relations among words.', 'it matches the query against each of the hidden representations h j i ( used as value and key for the attention ).', '']",5
"['in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are']","['"" base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are']","['base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are composed of 6 hidden layers each.', 'all hidden states have dimension']","['baselines, we use a nmt transformer, and a context - aware nmt transformer with cache memory which we implemented for comparison following the best model described by, with memory size of 25 words.', 'we used the opennmt  #AUTHOR_TAG implementation of the transformer network.', 'the configuration is the same as the model called "" base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are composed of 6 hidden layers each.', 'all hidden states have dimension of 512, dropout of 0. 1, and 8 heads for the multi - head attention.', 'the target and source vocabulary size is 30k.', 'the optimization and regularization methods were the same as proposed by  #TAUTHOR_TAG.', 'inspired by we trained the models in two stages.', 'first we optimize the parameters for the nmt without the han, then we proceed to optimize the parameters of the whole network.', 'we use k = 3 previous sentences, which gave the best performance on the development set.', 'table 1 shows the bleu scores for different models.', 'the baseline nmt transformer already has better performance than previously published results on these datasets, and we replicate previous previous improvements from the cache method over the this stronger baseline.', 'all of our proposed han models perform at least as well as the cache method.', 'the best scores are obtained by the combined encoder and decoder han model, which is significantly better than the cache method on all datasets without compromising training speed ( 2. 3k vs 2. 6k tok / sec ).', 'an important portion of the improvement comes from the han encoder, which can be attributed to the fact that the sourceside always contains correct information, while the target - side may contain erroneous predictions at testing time. but combining han decoder with han encoder further improves translation performance, showing that they contribute complementary information.', 'the three ways of incorporating information into the decoder all perform similarly.', 'table 3 shows the performance of our best han model with a varying number k of previous sentences in the test - set.', 'we can see that the best performance for ted talks and news is archived with 3, while for subtitles it is similar between 3 and 7']",5
"['in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are']","['"" base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are']","['base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are composed of 6 hidden layers each.', 'all hidden states have dimension']","['baselines, we use a nmt transformer, and a context - aware nmt transformer with cache memory which we implemented for comparison following the best model described by, with memory size of 25 words.', 'we used the opennmt  #AUTHOR_TAG implementation of the transformer network.', 'the configuration is the same as the model called "" base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are composed of 6 hidden layers each.', 'all hidden states have dimension of 512, dropout of 0. 1, and 8 heads for the multi - head attention.', 'the target and source vocabulary size is 30k.', 'the optimization and regularization methods were the same as proposed by  #TAUTHOR_TAG.', 'inspired by we trained the models in two stages.', 'first we optimize the parameters for the nmt without the han, then we proceed to optimize the parameters of the whole network.', 'we use k = 3 previous sentences, which gave the best performance on the development set.', 'table 1 shows the bleu scores for different models.', 'the baseline nmt transformer already has better performance than previously published results on these datasets, and we replicate previous previous improvements from the cache method over the this stronger baseline.', 'all of our proposed han models perform at least as well as the cache method.', 'the best scores are obtained by the combined encoder and decoder han model, which is significantly better than the cache method on all datasets without compromising training speed ( 2. 3k vs 2. 6k tok / sec ).', 'an important portion of the improvement comes from the han encoder, which can be attributed to the fact that the sourceside always contains correct information, while the target - side may contain erroneous predictions at testing time. but combining han decoder with han encoder further improves translation performance, showing that they contribute complementary information.', 'the three ways of incorporating information into the decoder all perform similarly.', 'table 3 shows the performance of our best han model with a varying number k of previous sentences in the test - set.', 'we can see that the best performance for ted talks and news is archived with 3, while for subtitles it is similar between 3 and 7']",5
"['in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are']","['"" base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are']","['base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are composed of 6 hidden layers each.', 'all hidden states have dimension']","['baselines, we use a nmt transformer, and a context - aware nmt transformer with cache memory which we implemented for comparison following the best model described by, with memory size of 25 words.', 'we used the opennmt  #AUTHOR_TAG implementation of the transformer network.', 'the configuration is the same as the model called "" base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are composed of 6 hidden layers each.', 'all hidden states have dimension of 512, dropout of 0. 1, and 8 heads for the multi - head attention.', 'the target and source vocabulary size is 30k.', 'the optimization and regularization methods were the same as proposed by  #TAUTHOR_TAG.', 'inspired by we trained the models in two stages.', 'first we optimize the parameters for the nmt without the han, then we proceed to optimize the parameters of the whole network.', 'we use k = 3 previous sentences, which gave the best performance on the development set.', 'table 1 shows the bleu scores for different models.', 'the baseline nmt transformer already has better performance than previously published results on these datasets, and we replicate previous previous improvements from the cache method over the this stronger baseline.', 'all of our proposed han models perform at least as well as the cache method.', 'the best scores are obtained by the combined encoder and decoder han model, which is significantly better than the cache method on all datasets without compromising training speed ( 2. 3k vs 2. 6k tok / sec ).', 'an important portion of the improvement comes from the han encoder, which can be attributed to the fact that the sourceside always contains correct information, while the target - side may contain erroneous predictions at testing time. but combining han decoder with han encoder further improves translation performance, showing that they contribute complementary information.', 'the three ways of incorporating information into the decoder all perform similarly.', 'table 3 shows the performance of our best han model with a varying number k of previous sentences in the test - set.', 'we can see that the best performance for ted talks and news is archived with 3, while for subtitles it is similar between 3 and 7']",3
"['in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are']","['"" base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are']","['base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are composed of 6 hidden layers each.', 'all hidden states have dimension']","['baselines, we use a nmt transformer, and a context - aware nmt transformer with cache memory which we implemented for comparison following the best model described by, with memory size of 25 words.', 'we used the opennmt  #AUTHOR_TAG implementation of the transformer network.', 'the configuration is the same as the model called "" base model "" in the original paper  #TAUTHOR_TAG.', 'the encoder and decoder are composed of 6 hidden layers each.', 'all hidden states have dimension of 512, dropout of 0. 1, and 8 heads for the multi - head attention.', 'the target and source vocabulary size is 30k.', 'the optimization and regularization methods were the same as proposed by  #TAUTHOR_TAG.', 'inspired by we trained the models in two stages.', 'first we optimize the parameters for the nmt without the han, then we proceed to optimize the parameters of the whole network.', 'we use k = 3 previous sentences, which gave the best performance on the development set.', 'table 1 shows the bleu scores for different models.', 'the baseline nmt transformer already has better performance than previously published results on these datasets, and we replicate previous previous improvements from the cache method over the this stronger baseline.', 'all of our proposed han models perform at least as well as the cache method.', 'the best scores are obtained by the combined encoder and decoder han model, which is significantly better than the cache method on all datasets without compromising training speed ( 2. 3k vs 2. 6k tok / sec ).', 'an important portion of the improvement comes from the han encoder, which can be attributed to the fact that the sourceside always contains correct information, while the target - side may contain erroneous predictions at testing time. but combining han decoder with han encoder further improves translation performance, showing that they contribute complementary information.', 'the three ways of incorporating information into the decoder all perform similarly.', 'table 3 shows the performance of our best han model with a varying number k of previous sentences in the test - set.', 'we can see that the best performance for ted talks and news is archived with 3, while for subtitles it is similar between 3 and 7']",3
"['embedding model that implicitly does matrix factorization, debiasing vectors post hoc using subspace projection  #TAUTHOR_TAG is, under']","['embedding model that implicitly does matrix factorization, debiasing vectors post hoc using subspace projection  #TAUTHOR_TAG is, under']","['gender stereotypes.', 'however, methods for measuring and removing such biases remain poorly understood.', 'we show that for any embedding model that implicitly does matrix factorization, debiasing vectors post hoc using subspace projection  #TAUTHOR_TAG is, under certain conditions, equivalent to training on an unbiased corpus.', 'we also prove that weat, the']","['embeddings are often criticized for capturing undesirable word associations such as gender stereotypes.', 'however, methods for measuring and removing such biases remain poorly understood.', 'we show that for any embedding model that implicitly does matrix factorization, debiasing vectors post hoc using subspace projection  #TAUTHOR_TAG is, under certain conditions, equivalent to training on an unbiased corpus.', 'we also prove that weat, the most common association test for word embeddings, systematically overestimates bias.', 'given that the subspace projection method is provably effective, we use it to derive a new measure of association called the relational inner product association ( ripa ).', 'experiments with ripa reveal that, on average, skipgram with negative sampling ( sgns ) does not make most words any more gendered than they are in the training corpus.', 'however, for gender - stereotyped words, sgns actually amplifies the gender association in the corpus']",5
['words using the  #TAUTHOR_TAG lists of gender - biased and gender - appropriate analog'],"['words using the  #TAUTHOR_TAG lists of gender - biased and gender - appropriate analogies.', 'for example, doctor : nurse : : man : woman is biased, so we classify the first']","['to gender : biased, appropriate, and neutral.', 'we create lists of biased and appropriate words using the  #TAUTHOR_TAG lists of gender - biased and gender - appropriate analogies.', 'for']","['our experiments, we use sgns embeddings trained on wikipedia, since ripa is highly interpretable for sgns ( see section 5. 1 ).', 'this means that for any given word in the vocabulary, we can compare its gender association in the training corpus to its gender association in the embedding space, which should be equal under perfect reconstruction.', 'words are grouped into three categories with respect to gender : biased, appropriate, and neutral.', 'we create lists of biased and appropriate words using the  #TAUTHOR_TAG lists of gender - biased and gender - appropriate analogies.', 'for example, doctor : nurse : : man : woman is biased, so we classify the first two words as biased.', 'the last category, neutral, contains uniformly randomly sampled words that appear at least 10k times in the corpus and that are not in either of the other categories, and which we therefore expect to be gender - agnostic']",5
"['pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['∆ g denote the change in absolute gender association from corpus to embedding space.', 'where s is a set of gender - defining word pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['any given word, the gender association in the training corpus is what the gender association in the embedding space would be if there were no reconstruction error.', 'by comparing these two quantities, we can infer the change induced by the embedding model.', 'let g ( w ; x, y ) denote the ripa of a word w with respect to the gender relation vector defined by word pair ( x, y ), letg ( w ; x, y ) denote what g ( w ; x, y ) would be under perfect reconstruction for an sgns embedding model, and let ∆ g denote the change in absolute gender association from corpus to embedding space.', 'where s is a set of gender - defining word pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take the absolute value of each term because the embedding model may make a word more gendered, but in the direction opposite of what is implied in the corpus.', 'λ ← 1 because we expect figure 1 : before debiasing words using subspace projection, one needs to identify which words are genderappropriate - to avoid debiasing them.', 'the  #TAUTHOR_TAG method of identifying these words is ineffective : it ends up precluding most gender - appropriate analogies ( dotted line, left ) while preserving most gender - biased analogies ( dotted line, right ).', 'our unsupervised method ( dashed line ) does much better in both respects.', 'λ ≈ 1 in practice  #AUTHOR_TAG.', 'similarly, α ← −1 because it minimizes the difference between x − y and its information theoretic interpretation over the gender - defining word pairs in s, though this is an estimate and may differ from the true value of α.', 'in table 2, we list the gender association in the training corpus ( g ( w ) ), the gender association in embedding space ( g ( w ) ), and the absolute change ( ∆ g ( w ) ) for each group of words.', 'on average, the sgns embedding model does not make gender - neutral words any more gendered than they are in the training corpus.', 'given that much of the vocabulary falls into this category, this means that the embedding model does not systematically change the genderedness of most words.', 'however, because of reconstruction error, individual words may be more or less gendered in the embedding space, simply due to chance.', 'in contrast, for words that are either gender - biased or genderappropriate, on average, the embedding model actually amplifies the gender association in the corpus.', ""for example, for the word'king ', which""]",5
"['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github.']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['', '. 7 % of gender - biased analogies are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b / debiaswe preserves only 16. 5 % of appropriate analogies with a strength of at least 0. 5 while preserving 80. 0', '% of biased ones. recall that we use the same debiasing method as  #TAUTHOR_TAG ; the difference in performance can only be ascribed to how we', 'choose the gender - appropriate words. combining our heuristic with other methods may yield even better results, which we leave as future work']",5
['in contrast to the supervised method proposed by  #TAUTHOR_TAG'],"['as king : queen : : man : woman from holding in the embedding space. in contrast to the supervised method proposed by  #TAUTHOR_TAG for identifying these gender', '- specific words, we introduce an unsupervised method. ours is much more effective at preserving gender - appropriate analogies and precluding gender - biased ones. to allow a fair comparison with prior']","['. debiasing', 'all vectors can preclude gender - appropriate analogies such as king : queen : : man : woman from holding in the embedding space. in contrast to the supervised method proposed by  #TAUTHOR_TAG']","['', 'the training corpus. making such comparisons yields several novel insights : 1. sgns does not, on average, make the vast majority of words any more gendered in the vector space than they are in the training corpus ; individual words may be slightly more or less gender', ""##ed due to reconstruction error. however, for words that are genderstereotyped ( e. g.,'nurse') or gender -"", ""specific by definition ( e. g.,'queen'), sgns amplifies the gender association in the training corpus. 2."", 'to use the subspace projection method, one must have prior knowledge of which words are gender - specific by definition, so that they are not also debiased. debiasing', 'all vectors can preclude gender - appropriate analogies such as king : queen : : man : woman from holding in the embedding space. in contrast to the supervised method proposed by  #TAUTHOR_TAG for identifying these gender', '- specific words, we introduce an unsupervised method. ours is much more effective at preserving gender - appropriate analogies and precluding gender - biased ones. to allow a fair comparison with prior work, our experiments in this paper focus on gender association. however, our claims extend to other types of word associations as well, which', 'we leave as future work']",0
"['from', 'holding in the embedding space,  #TAUTHOR_TAG did not provide any theoretical guarantee that the vectors were unbiased (']","['orthogonal to the', 'gender bias subspace and its projection on the subspace was zero. while this subspace projection method precluded gender - biased analogies from', 'holding in the embedding space,  #TAUTHOR_TAG did not provide any theoretical guarantee that the vectors were unbiased (']","['gender - biased analogies from', 'holding in the embedding space,  #TAUTHOR_TAG did not provide any theoretical guarantee that the vectors were unbiased (']","['', 'that this was statistically significant. however, aside from some intuitive results ( e', '. g., that female names are associated with female attributes ), there is little evidence that weat is a good measure of association.  #AUTHOR_TAG claimed that the existence of stereotypical analogies such as doctor : nurse : : man', ': woman constituted gender bias. to prevent such analogies from holding in the vector space, they subtracted from each biased word vector its projection on a "" gender bias subspace "".', 'this subspace was defined by the first m principal components for ten gender relation vectors ( e. g., man − woman ). each debiased word vector was thus orthogonal to the', 'gender bias subspace and its projection on the subspace was zero. while this subspace projection method precluded gender - biased analogies from', 'holding in the embedding space,  #TAUTHOR_TAG did not provide any theoretical guarantee that the vectors were unbiased ( i. e., equivalent to vectors that would', 'be obtained from training on a gender - agnostic corpus with no reconstruction error ). other work has tried to learn gender - neutral', 'embeddings from scratch  #AUTHOR_TAG, despite this approach requiring custom changes to the objective of each embedding model']",0
['by  #TAUTHOR_TAG found that debiasing word embeddings using the subspace projection method preclude'],"['by  #TAUTHOR_TAG found that debiasing word embeddings using the subspace projection method precludes gender - biased analogies from holding.', 'however,']",['by  #TAUTHOR_TAG found that debiasing word embeddings using the subspace projection method preclude'],"['by  #TAUTHOR_TAG found that debiasing word embeddings using the subspace projection method precludes gender - biased analogies from holding.', 'however, as we noted earlier, despite this method being intuitive, there is no theoretical guarantee that the debiased vectors are perfectly unbiased or that the debiasing method works for embedding models other than sgns.', 'in this section, we prove that for any embedding model that does implicit matrix factorization ( e. g., glove, sgns ), debiasing embeddings post hoc using the subspace projection method is, under certain conditions, equivalent to training on a perfectly unbiased corpus without reconstruction error.', '']",0
"['of the measurement  #TAUTHOR_TAG. for the same reason discussed in proposition 1, this measure']","['of the measurement  #TAUTHOR_TAG. for the same reason discussed in proposition 1, this measure can also overestim']","['of the measurement  #TAUTHOR_TAG. for the same reason discussed in proposition 1, this measure can also overestim']","['', '##biased or male - biased than another. conversely, we can also manipulate the attribute sets to claim that an association is not statistically significant ( p = 0. 5 ), despite a large effect size. broadly speaking, cosine similarity is a useful measure', 'of vector similarity and hypothesis tests are useful for testing sample differences. because of this, weat seems', 'to be an intuitive measure. however, as shown in propositions 1 and 2, there are two key theoretical flaws to weat that cause it to overestimate the degree of association and ultimately make it an inappropriate metric for', 'word embeddings. the only other metric of note quantifies association as | cos ( w, b ) | c, where b is the bias subspace and c ∈ r the "" strictness', '"" of the measurement  #TAUTHOR_TAG. for the same reason discussed in proposition 1, this measure can also overestimate the degree of association']",0
"['same embedding space.', 'to use the terminology in  #TAUTHOR_TAG defined b as the first principal']","['same embedding space.', 'to use the terminology in  #TAUTHOR_TAG defined b as the first principal']","['given word vector in the same embedding space.', 'to use the terminology in  #TAUTHOR_TAG defined b as the first principal component']","['relational inner product association β ( w ; b ) of a word vector w ∈ v with respect to a relation vector b ∈ v is w, b.', 'where s is a non - empty set of ordered word pairs ( x, y ) that define the association, b is the first principal component of { x − y | ( x, y ) ∈ s }.', 'our metric, the relational inner product association ( ripa ), is simply the inner product of a relation vector describing the association and a given word vector in the same embedding space.', 'to use the terminology in  #TAUTHOR_TAG defined b as the first principal component for a set of gender difference vectors ( e. g., man − woman ).', 'this would be the means of deriving b for ripa as well.', 'for the sake of interpretability, we do not define b as the span of difference vectors, as would be required if one were using b to provably debias words with respect to s ( see section 3 ).', 'when b is a vector, the sign of w, b indicates the direction of the association ( e. g., male or female, depending on the order of the word pairs ).', 'for higher dimensional bias subspaces, the sign of the projection cannot be interpreted in the same way.', 'also, as noted earlier, bias vectors are what are typically used to debias words in practice.', 'as we show in the rest of this section, the interpretability of ripa, its robustness to how the relation vector is defined, and its derivation from a method that provably debiases word embeddings are the key reasons why it is an ideal replacement for weat.', 'given that ripa can be used for any embedding model that does matrix factorization, it is applicable to common embedding models such as sgns and glove']",0
"['pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['∆ g denote the change in absolute gender association from corpus to embedding space.', 'where s is a set of gender - defining word pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['any given word, the gender association in the training corpus is what the gender association in the embedding space would be if there were no reconstruction error.', 'by comparing these two quantities, we can infer the change induced by the embedding model.', 'let g ( w ; x, y ) denote the ripa of a word w with respect to the gender relation vector defined by word pair ( x, y ), letg ( w ; x, y ) denote what g ( w ; x, y ) would be under perfect reconstruction for an sgns embedding model, and let ∆ g denote the change in absolute gender association from corpus to embedding space.', 'where s is a set of gender - defining word pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take the absolute value of each term because the embedding model may make a word more gendered, but in the direction opposite of what is implied in the corpus.', 'λ ← 1 because we expect figure 1 : before debiasing words using subspace projection, one needs to identify which words are genderappropriate - to avoid debiasing them.', 'the  #TAUTHOR_TAG method of identifying these words is ineffective : it ends up precluding most gender - appropriate analogies ( dotted line, left ) while preserving most gender - biased analogies ( dotted line, right ).', 'our unsupervised method ( dashed line ) does much better in both respects.', 'λ ≈ 1 in practice  #AUTHOR_TAG.', 'similarly, α ← −1 because it minimizes the difference between x − y and its information theoretic interpretation over the gender - defining word pairs in s, though this is an estimate and may differ from the true value of α.', 'in table 2, we list the gender association in the training corpus ( g ( w ) ), the gender association in embedding space ( g ( w ) ), and the absolute change ( ∆ g ( w ) ) for each group of words.', 'on average, the sgns embedding model does not make gender - neutral words any more gendered than they are in the training corpus.', 'given that much of the vocabulary falls into this category, this means that the embedding model does not systematically change the genderedness of most words.', 'however, because of reconstruction error, individual words may be more or less gendered in the embedding space, simply due to chance.', 'in contrast, for words that are either gender - biased or genderappropriate, on average, the embedding model actually amplifies the gender association in the corpus.', ""for example, for the word'king ', which""]",0
"['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github.']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['', '. 7 % of gender - biased analogies are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b / debiaswe preserves only 16. 5 % of appropriate analogies with a strength of at least 0. 5 while preserving 80. 0', '% of biased ones. recall that we use the same debiasing method as  #TAUTHOR_TAG ; the difference in performance can only be ascribed to how we', 'choose the gender - appropriate words. combining our heuristic with other methods may yield even better results, which we leave as future work']",0
"['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github.']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['', '. 7 % of gender - biased analogies are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b / debiaswe preserves only 16. 5 % of appropriate analogies with a strength of at least 0. 5 while preserving 80. 0', '% of biased ones. recall that we use the same debiasing method as  #TAUTHOR_TAG ; the difference in performance can only be ascribed to how we', 'choose the gender - appropriate words. combining our heuristic with other methods may yield even better results, which we leave as future work']",0
"['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github.']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['', '. 7 % of gender - biased analogies are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b / debiaswe preserves only 16. 5 % of appropriate analogies with a strength of at least 0. 5 while preserving 80. 0', '% of biased ones. recall that we use the same debiasing method as  #TAUTHOR_TAG ; the difference in performance can only be ascribed to how we', 'choose the gender - appropriate words. combining our heuristic with other methods may yield even better results, which we leave as future work']",0
['in contrast to the supervised method proposed by  #TAUTHOR_TAG'],"['as king : queen : : man : woman from holding in the embedding space. in contrast to the supervised method proposed by  #TAUTHOR_TAG for identifying these gender', '- specific words, we introduce an unsupervised method. ours is much more effective at preserving gender - appropriate analogies and precluding gender - biased ones. to allow a fair comparison with prior']","['. debiasing', 'all vectors can preclude gender - appropriate analogies such as king : queen : : man : woman from holding in the embedding space. in contrast to the supervised method proposed by  #TAUTHOR_TAG']","['', 'the training corpus. making such comparisons yields several novel insights : 1. sgns does not, on average, make the vast majority of words any more gendered in the vector space than they are in the training corpus ; individual words may be slightly more or less gender', ""##ed due to reconstruction error. however, for words that are genderstereotyped ( e. g.,'nurse') or gender -"", ""specific by definition ( e. g.,'queen'), sgns amplifies the gender association in the training corpus. 2."", 'to use the subspace projection method, one must have prior knowledge of which words are gender - specific by definition, so that they are not also debiased. debiasing', 'all vectors can preclude gender - appropriate analogies such as king : queen : : man : woman from holding in the embedding space. in contrast to the supervised method proposed by  #TAUTHOR_TAG for identifying these gender', '- specific words, we introduce an unsupervised method. ours is much more effective at preserving gender - appropriate analogies and precluding gender - biased ones. to allow a fair comparison with prior work, our experiments in this paper focus on gender association. however, our claims extend to other types of word associations as well, which', 'we leave as future work']",4
['in contrast to the supervised method proposed by  #TAUTHOR_TAG'],"['as king : queen : : man : woman from holding in the embedding space. in contrast to the supervised method proposed by  #TAUTHOR_TAG for identifying these gender', '- specific words, we introduce an unsupervised method. ours is much more effective at preserving gender - appropriate analogies and precluding gender - biased ones. to allow a fair comparison with prior']","['. debiasing', 'all vectors can preclude gender - appropriate analogies such as king : queen : : man : woman from holding in the embedding space. in contrast to the supervised method proposed by  #TAUTHOR_TAG']","['', 'the training corpus. making such comparisons yields several novel insights : 1. sgns does not, on average, make the vast majority of words any more gendered in the vector space than they are in the training corpus ; individual words may be slightly more or less gender', ""##ed due to reconstruction error. however, for words that are genderstereotyped ( e. g.,'nurse') or gender -"", ""specific by definition ( e. g.,'queen'), sgns amplifies the gender association in the training corpus. 2."", 'to use the subspace projection method, one must have prior knowledge of which words are gender - specific by definition, so that they are not also debiased. debiasing', 'all vectors can preclude gender - appropriate analogies such as king : queen : : man : woman from holding in the embedding space. in contrast to the supervised method proposed by  #TAUTHOR_TAG for identifying these gender', '- specific words, we introduce an unsupervised method. ours is much more effective at preserving gender - appropriate analogies and precluding gender - biased ones. to allow a fair comparison with prior work, our experiments in this paper focus on gender association. however, our claims extend to other types of word associations as well, which', 'we leave as future work']",4
['by  #TAUTHOR_TAG found that debiasing word embeddings using the subspace projection method preclude'],"['by  #TAUTHOR_TAG found that debiasing word embeddings using the subspace projection method precludes gender - biased analogies from holding.', 'however,']",['by  #TAUTHOR_TAG found that debiasing word embeddings using the subspace projection method preclude'],"['by  #TAUTHOR_TAG found that debiasing word embeddings using the subspace projection method precludes gender - biased analogies from holding.', 'however, as we noted earlier, despite this method being intuitive, there is no theoretical guarantee that the debiased vectors are perfectly unbiased or that the debiasing method works for embedding models other than sgns.', 'in this section, we prove that for any embedding model that does implicit matrix factorization ( e. g., glove, sgns ), debiasing embeddings post hoc using the subspace projection method is, under certain conditions, equivalent to training on a perfectly unbiased corpus without reconstruction error.', '']",4
['s. the subspace projection method is therefore far more powerful than initially stated in  #TAUTHOR_TAG : not only'],['s. the subspace projection method is therefore far more powerful than initially stated in  #TAUTHOR_TAG : not only'],['s. the subspace projection method is therefore far more powerful than initially stated in  #TAUTHOR_TAG : not only can it be applied to any embedding model that implicitly does matrix factorization ('],"['', 'this implies that the co - occurrence matrix m d that is reconstructed using the debiased word matrix w d is also unbiased with respect to s. the subspace projection method is therefore far more powerful than initially stated in  #TAUTHOR_TAG : not only can it be applied to any embedding model that implicitly does matrix factorization ( e. g., glove, sgns ), but debiasing word vectors in this way is equivalent to training on a perfectly unbiased corpus when there is no reconstruction error.', 'however, word vectors should not be normalized prior to debiasing, since the matrix that is factorized by the embedding model cannot necessarily be reconstructed with normalized embeddings.', 'unbiasedness with respect to word pairs s is also only guaranteed when the bias subspace', 'because we define unbiasedness with respect to a set of word pairs, we cannot make any claims about word pairs outside that set.', ""for example, consider the set s = { ('man ','woman') }. if we define a bias subspace using s and use it to debias w, we can only say definitively that w is unbiased with respect to s. we cannot claim, for example, that w is also unbiased with respect to { ('policeman ','policewoman') }, because it""]",4
"['pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['∆ g denote the change in absolute gender association from corpus to embedding space.', 'where s is a set of gender - defining word pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['any given word, the gender association in the training corpus is what the gender association in the embedding space would be if there were no reconstruction error.', 'by comparing these two quantities, we can infer the change induced by the embedding model.', 'let g ( w ; x, y ) denote the ripa of a word w with respect to the gender relation vector defined by word pair ( x, y ), letg ( w ; x, y ) denote what g ( w ; x, y ) would be under perfect reconstruction for an sgns embedding model, and let ∆ g denote the change in absolute gender association from corpus to embedding space.', 'where s is a set of gender - defining word pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take the absolute value of each term because the embedding model may make a word more gendered, but in the direction opposite of what is implied in the corpus.', 'λ ← 1 because we expect figure 1 : before debiasing words using subspace projection, one needs to identify which words are genderappropriate - to avoid debiasing them.', 'the  #TAUTHOR_TAG method of identifying these words is ineffective : it ends up precluding most gender - appropriate analogies ( dotted line, left ) while preserving most gender - biased analogies ( dotted line, right ).', 'our unsupervised method ( dashed line ) does much better in both respects.', 'λ ≈ 1 in practice  #AUTHOR_TAG.', 'similarly, α ← −1 because it minimizes the difference between x − y and its information theoretic interpretation over the gender - defining word pairs in s, though this is an estimate and may differ from the true value of α.', 'in table 2, we list the gender association in the training corpus ( g ( w ) ), the gender association in embedding space ( g ( w ) ), and the absolute change ( ∆ g ( w ) ) for each group of words.', 'on average, the sgns embedding model does not make gender - neutral words any more gendered than they are in the training corpus.', 'given that much of the vocabulary falls into this category, this means that the embedding model does not systematically change the genderedness of most words.', 'however, because of reconstruction error, individual words may be more or less gendered in the embedding space, simply due to chance.', 'in contrast, for words that are either gender - biased or genderappropriate, on average, the embedding model actually amplifies the gender association in the corpus.', ""for example, for the word'king ', which""]",4
"['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github.']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['', '. 7 % of gender - biased analogies are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b / debiaswe preserves only 16. 5 % of appropriate analogies with a strength of at least 0. 5 while preserving 80. 0', '% of biased ones. recall that we use the same debiasing method as  #TAUTHOR_TAG ; the difference in performance can only be ascribed to how we', 'choose the gender - appropriate words. combining our heuristic with other methods may yield even better results, which we leave as future work']",4
"['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github.']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b']","['', '. 7 % of gender - biased analogies are. in contrast, the  #TAUTHOR_TAG approach 2 available at https', ': / / github. com / tolga -', 'b / debiaswe preserves only 16. 5 % of appropriate analogies with a strength of at least 0. 5 while preserving 80. 0', '% of biased ones. recall that we use the same debiasing method as  #TAUTHOR_TAG ; the difference in performance can only be ascribed to how we', 'choose the gender - appropriate words. combining our heuristic with other methods may yield even better results, which we leave as future work']",4
"['pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['∆ g denote the change in absolute gender association from corpus to embedding space.', 'where s is a set of gender - defining word pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take']","['any given word, the gender association in the training corpus is what the gender association in the embedding space would be if there were no reconstruction error.', 'by comparing these two quantities, we can infer the change induced by the embedding model.', 'let g ( w ; x, y ) denote the ripa of a word w with respect to the gender relation vector defined by word pair ( x, y ), letg ( w ; x, y ) denote what g ( w ; x, y ) would be under perfect reconstruction for an sgns embedding model, and let ∆ g denote the change in absolute gender association from corpus to embedding space.', 'where s is a set of gender - defining word pairs 1 from  #TAUTHOR_TAG and λ, α are the model - specific constants defined in section 5. 1,', 'we take the absolute value of each term because the embedding model may make a word more gendered, but in the direction opposite of what is implied in the corpus.', 'λ ← 1 because we expect figure 1 : before debiasing words using subspace projection, one needs to identify which words are genderappropriate - to avoid debiasing them.', 'the  #TAUTHOR_TAG method of identifying these words is ineffective : it ends up precluding most gender - appropriate analogies ( dotted line, left ) while preserving most gender - biased analogies ( dotted line, right ).', 'our unsupervised method ( dashed line ) does much better in both respects.', 'λ ≈ 1 in practice  #AUTHOR_TAG.', 'similarly, α ← −1 because it minimizes the difference between x − y and its information theoretic interpretation over the gender - defining word pairs in s, though this is an estimate and may differ from the true value of α.', 'in table 2, we list the gender association in the training corpus ( g ( w ) ), the gender association in embedding space ( g ( w ) ), and the absolute change ( ∆ g ( w ) ) for each group of words.', 'on average, the sgns embedding model does not make gender - neutral words any more gendered than they are in the training corpus.', 'given that much of the vocabulary falls into this category, this means that the embedding model does not systematically change the genderedness of most words.', 'however, because of reconstruction error, individual words may be more or less gendered in the embedding space, simply due to chance.', 'in contrast, for words that are either gender - biased or genderappropriate, on average, the embedding model actually amplifies the gender association in the corpus.', ""for example, for the word'king ', which""]",7
"['using ass extracted', 'from a corpus of native texts enables a better prediction than that obtained by using the simple frequency of the unigrams and bigrams  #TAUTHOR_TAG', '. this study attempts to']","['using ass extracted', 'from a corpus of native texts enables a better prediction than that obtained by using the simple frequency of the unigrams and bigrams  #TAUTHOR_TAG', '. this study attempts to answer these questions by extracting from the bigrams in efl texts richer features from several association measures as described in']","['using ass extracted', 'from a corpus of native texts enables a better prediction than that obtained by using the simple frequency of the unigrams and bigrams  #TAUTHOR_TAG', '. this study attempts to answer these questions by extracting from the bigrams in efl texts richer features from several association measures as described in']","['', 'other associational measures for collocations. in this context, extracting richer features than the mean scores, as done by  #AUTHOR_TAG, seems particularly promising, because found that', 'the best learner texts contain more middlelevel t - score bigrams and fewer low and high - level t - score bigrams. this observation may be related to the fact that the low t - score bigrams are often erroneous combinations of words, while high scores indicate extremely common bigrams', 'in the language, which are easy to learn. it is therefore far from obvious that there is a simple linear or monotonic relationship between the', 'distribution of the association scores ( ass ) in a text and its quality. finally, it would be interesting to determine whether using ass extracted', 'from a corpus of native texts enables a better prediction than that obtained by using the simple frequency of the unigrams and bigrams  #TAUTHOR_TAG', '. this study attempts to answer these questions by extracting from the bigrams in efl texts richer features from several association measures as described in section 2, and by comparing the effectiveness of', 'these collocational features to that of lexical features ( section 3 ). the conclusion proposes several paths for further research']",2
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",3
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",3
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",3
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",3
"['scores reported by  #TAUTHOR_TAG, which give']","['scores reported by  #TAUTHOR_TAG, which give']","[""2 can be compared to the average correlation between the examiners'scores reported by  #TAUTHOR_TAG, which give an upper bound""]","['lexical features used alone allowed a 0. 68 correlation 4.', 'these features are thus more effective than the best combinations of collocational features reported in table 1, but, as shown in table 2, adding the collocational features to the lexical ones produces far better performances.', ""steiner's ttest  #AUTHOR_TAG - 271 ) for comparing two non - independent correlations showed that collocational features significantly improve the prediction when compared to the baseline ( all ps < 0. 005 )."", 'if mi is always one of the best performing ass, the differences between the ass are quite low.', 'for all numbers of bins, using all the ass allows the best performance.', ""to get an idea of how well the collocational and lexical features perform, the correlations in table 2 can be compared to the average correlation between the examiners'scores reported by  #TAUTHOR_TAG, which give an upper bound of 0. 80 while the all models with more than three bins obtain a correlation of at least 0. 75."", 'adding collocational features to lexical ones thus reduces by 58 % the difference between the lexical features alone and the upper bound.', 'however, the most difficult part of the work is still to be done']",3
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",5
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",5
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",5
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",4
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",4
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",6
[') esol examination scripts described in  #TAUTHOR_TAG'],"[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this']","[') esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #TAUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #TAUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #AUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #TAUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #TAUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #TAUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #TAUTHOR_TAG, as the measure of performance""]",6
"['cnn )  #TAUTHOR_TAG, recurrent']","['( cnn )  #TAUTHOR_TAG, recurrent']","['cnn )  #TAUTHOR_TAG,']","['natural language processing or text related community, effective representation of textual sequences is the fundamental topic for the up - stream tasks.', 'traditionally, bag - of - word models ( tfidf or language model ) with vocabulary - aware vector space tends to be the main - stream approach, especially in the task with long text ( e. g. ad hoc retrieval with long document, text classification for long sentence ).', 'however, it tends to get pool performance in the tasks with short - text sentence ( text classification for relatively short sentence, question answering, machine comprehension and dialogue system ), which there are little word - level overlaps in bag - of - word vector space.', 'distributed representation  #AUTHOR_TAG in a fixed low - dimensional space trained from large - scale * † means equal contribution.', 'need to be peer - reviewed corpus have been proposed to enhance the features of text, then break through the performance bottleneck of bag - of - words models in short - text tasks.', 'with combination of conventional neural network ( cnn )  #TAUTHOR_TAG, recurrent neural network ( rnn ), recursive neural network  #AUTHOR_TAG and attention, hundreds of models had been proposed to model text for further classification, matching  #AUTHOR_TAG or other tasks.', 'however, these models are tested in different settings with various datasets, preprocessing and even evaluation.', 'since subtle differences may lead to large divergence in final performance.', 'it is essential to get a robust comparison and tested in rigid significance test.', 'moreover, models with both effective and efficient performance is impossible due to the no - free - lunch principle.', 'thus each model should be considered in a trade off between its effectiveness and efficiency.', 'out contribution is 1.', 'a new open - source benchmark of text classification 1 with more than 20 models and 10 datasets.', '2.', 'systemic reconsideration of text classification in a trade off']",0
"['cnn )  #TAUTHOR_TAG, recurrent']","['( cnn )  #TAUTHOR_TAG, recurrent']","['cnn )  #TAUTHOR_TAG,']","['natural language processing or text related community, effective representation of textual sequences is the fundamental topic for the up - stream tasks.', 'traditionally, bag - of - word models ( tfidf or language model ) with vocabulary - aware vector space tends to be the main - stream approach, especially in the task with long text ( e. g. ad hoc retrieval with long document, text classification for long sentence ).', 'however, it tends to get pool performance in the tasks with short - text sentence ( text classification for relatively short sentence, question answering, machine comprehension and dialogue system ), which there are little word - level overlaps in bag - of - word vector space.', 'distributed representation  #AUTHOR_TAG in a fixed low - dimensional space trained from large - scale * † means equal contribution.', 'need to be peer - reviewed corpus have been proposed to enhance the features of text, then break through the performance bottleneck of bag - of - words models in short - text tasks.', 'with combination of conventional neural network ( cnn )  #TAUTHOR_TAG, recurrent neural network ( rnn ), recursive neural network  #AUTHOR_TAG and attention, hundreds of models had been proposed to model text for further classification, matching  #AUTHOR_TAG or other tasks.', 'however, these models are tested in different settings with various datasets, preprocessing and even evaluation.', 'since subtle differences may lead to large divergence in final performance.', 'it is essential to get a robust comparison and tested in rigid significance test.', 'moreover, models with both effective and efficient performance is impossible due to the no - free - lunch principle.', 'thus each model should be considered in a trade off between its effectiveness and efficiency.', 'out contribution is 1.', 'a new open - source benchmark of text classification 1 with more than 20 models and 10 datasets.', '2.', 'systemic reconsideration of text classification in a trade off']",1
"[', text classification  #TAUTHOR_TAG, text segmentation  #AUTHOR_TAG, information']","[', text classification  #TAUTHOR_TAG, text segmentation  #AUTHOR_TAG, information']","[', text classification  #TAUTHOR_TAG, text segmentation  #AUTHOR_TAG, information extraction']","['tutorial introduces the advances in deep bayesian learning with abundant applications for natural language understanding ranging from speech recognition  #AUTHOR_TAG to document summarization  #AUTHOR_TAG, text classification  #TAUTHOR_TAG, text segmentation  #AUTHOR_TAG, information extraction  #AUTHOR_TAG, image caption generation  #AUTHOR_TAG, sentence generation  #AUTHOR_TAG b ), dialogue control  #AUTHOR_TAG a ), sentiment classification, recommendation system, question answering  #AUTHOR_TAG and machine translation, to name a few.', 'traditionally, "" deep learning "" is taken to be a learning process where the inference or optimization is based on the real - valued deterministic model.', 'the "" semantic structure "" in words, sentences, entities, actions and documents drawn from a large vocabulary may not be well expressed or correctly optimized in mathematical logic or computer programs.', 'the "" distribution function "" in discrete or continuous latent variable model for natural language may not be properly decomposed or estimated in model inference.', 'this tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced bayesian models and deep models including hierarchical dirichlet process, chinese restaurant process  #AUTHOR_TAG, hierarchical pitman - yor process  #AUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural network  #AUTHOR_TAG, long short - term memory  #AUTHOR_TAG sequence - to - sequence model  #AUTHOR_TAG, variational auto - encoder  #AUTHOR_TAG, generative adversarial network  #AUTHOR_TAG, attention mechanism  #AUTHOR_TAG, memory - augmented neural network  #AUTHOR_TAG, stochastic neural network  #AUTHOR_TAG, predictive state neural network  #AUTHOR_TAG, policy gradient  #AUTHOR_TAG and reinforcement learning  #AUTHOR_TAG.', '']",0
"[', text classification  #TAUTHOR_TAG, text segmentation  #AUTHOR_TAG, information']","[', text classification  #TAUTHOR_TAG, text segmentation  #AUTHOR_TAG, information']","[', text classification  #TAUTHOR_TAG, text segmentation  #AUTHOR_TAG, information extraction']","['tutorial introduces the advances in deep bayesian learning with abundant applications for natural language understanding ranging from speech recognition  #AUTHOR_TAG to document summarization  #AUTHOR_TAG, text classification  #TAUTHOR_TAG, text segmentation  #AUTHOR_TAG, information extraction  #AUTHOR_TAG, image caption generation  #AUTHOR_TAG, sentence generation  #AUTHOR_TAG b ), dialogue control  #AUTHOR_TAG a ), sentiment classification, recommendation system, question answering  #AUTHOR_TAG and machine translation, to name a few.', 'traditionally, "" deep learning "" is taken to be a learning process where the inference or optimization is based on the real - valued deterministic model.', 'the "" semantic structure "" in words, sentences, entities, actions and documents drawn from a large vocabulary may not be well expressed or correctly optimized in mathematical logic or computer programs.', 'the "" distribution function "" in discrete or continuous latent variable model for natural language may not be properly decomposed or estimated in model inference.', 'this tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced bayesian models and deep models including hierarchical dirichlet process, chinese restaurant process  #AUTHOR_TAG, hierarchical pitman - yor process  #AUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural network  #AUTHOR_TAG, long short - term memory  #AUTHOR_TAG sequence - to - sequence model  #AUTHOR_TAG, variational auto - encoder  #AUTHOR_TAG, generative adversarial network  #AUTHOR_TAG, attention mechanism  #AUTHOR_TAG, memory - augmented neural network  #AUTHOR_TAG, stochastic neural network  #AUTHOR_TAG, predictive state neural network  #AUTHOR_TAG, policy gradient  #AUTHOR_TAG and reinforcement learning  #AUTHOR_TAG.', '']",5
,,,,0
,,,,0
,,,,0
,,,,5
"[' #TAUTHOR_TAG, we']","[' #TAUTHOR_TAG, we']","[' #TAUTHOR_TAG, we extend their text baseline to speech input']","['translation applications for speech can suffer due to conversational speech phenomena, particularly the presence of disfluencies.', 'previous work to remove disfluencies in speech translation did so as a separate step between speech recognition and machine translation, which is not possible using end - to - end models.', 'using clean references for disfluent data collected by  #TAUTHOR_TAG, we extend their text baseline to speech input and provide first results for direct generation of fluent text from noisy disfluent speech.', 'while fluent training data enables research on this task with end - to - end models, it is unlikely to have this resource for every corpus and domain and it is expensive to collect.', 'in future work, we hope to reduce the dependence on fluent target data during training through decoder pretraining on external non - conversational corpora or multitask learning.', 'further, standard metrics alone do not tell the full story for this task ; additional work on evaluation metrics may better demonstrate the differences between such systems']",6
[' #AUTHOR_TAG b ;  #TAUTHOR_TAG'],['mc  #AUTHOR_TAG a ; riedel and mc  #AUTHOR_TAG b ;  #TAUTHOR_TAG'],"[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'both approaches have coped with']",[' #TAUTHOR_TAG'],0
"['not  #TAUTHOR_TAG?', '']","['not  #TAUTHOR_TAG?', '']","['not  #TAUTHOR_TAG?', 'the current token along with']","['formalize the event detection problem as a multi - class classification problem.', 'given a sentence, for every token in that sentence, we want to predict if the current token is an event trigger : i. e, does it express some event in the pre - defined event set or not  #TAUTHOR_TAG?', 'the current token along with its context in the sentence constitute an event trigger candidate or an example in multiclass classification terms.', 'in order to prepare for the cnns, we limit the context to a fixed window size by trimming longer sentences and padding shorter sentences with a special token when necessary.', '']",0
"['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['state - of - the - art systems for event detection on the ace 2005 dataset have followed the traditional feature - based approach with rich hand - designed feature sets, and statistical classifiers such as maxent and perceptron for structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare the proposed cnns with these state - of - the - art systems on the blind test set.', 'table 2 presents the overall performance of the systems with gold - standard entity mention and type information 4.', 'as we can see from the table, considering the systems that only use sentence level information, cnn1 significantly outperforms the maxent classifier as well as the joint beam search with local features from  #TAUTHOR_TAG.', 'this is remarkable since cnn1 does not require any external features 5, in contrast to the other featurebased systems that extensively rely on such external features to perform well.', 'more interestingly, when the entity type information is incorporated into cnn1, we obtain cnn2 that still only needs sentence level information but achieves the stateof - the - art performance for this task ( an improvement of 1. 5 % over the best system with only sentence level information  #TAUTHOR_TAG.', 'except for cnn1, all the systems reported in table 2 employ the gold - standard ( perfect ) entities mentions and types from manual annotation which might not be available in reality.', 'table 3 compares the performance of cnn1 and the feature - based systems in a more realistic setting, where entity mentions and types are acquired from an automatic high - performing name tagger and information extraction system  #TAUTHOR_TAG.', 'note that cnn1 is eligible for this comparison as it does not utilize any external features, thus avoiding usage of the name tagger and the information extraction system to identify entity mentions and types']",0
[' #AUTHOR_TAG b ;  #TAUTHOR_TAG'],['mc  #AUTHOR_TAG a ; riedel and mc  #AUTHOR_TAG b ;  #TAUTHOR_TAG'],"[' #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'both approaches have coped with']",[' #TAUTHOR_TAG'],1
"['not  #TAUTHOR_TAG?', '']","['not  #TAUTHOR_TAG?', '']","['not  #TAUTHOR_TAG?', 'the current token along with']","['formalize the event detection problem as a multi - class classification problem.', 'given a sentence, for every token in that sentence, we want to predict if the current token is an event trigger : i. e, does it express some event in the pre - defined event set or not  #TAUTHOR_TAG?', 'the current token along with its context in the sentence constitute an event trigger candidate or an example in multiclass classification terms.', 'in order to prepare for the cnns, we limit the context to a fixed window size by trimming longer sentences and padding shorter sentences with a special token when necessary.', '']",5
"[' #TAUTHOR_TAG.', 'the']","[' #TAUTHOR_TAG.', 'the']","['set with 30 other documents ( 836 sentences ) and the same training set with the remaning 529 documents ( 14, 849 sentences ) as the previous studies on this dataset  #TAUTHOR_TAG.', '']","['the benefit of multiple window sizes in the convolution layer has been demonstrated in the previous work on sentence modeling  #AUTHOR_TAG, in the experiments below, we use window sizes in the set { 2, 3, 4, 5 } to generate feature maps.', 'we utilize 150 feature maps for each window size in this set.', 'the window size for triggers is set to 31 while the dimensionality of the position embeddings and entity type embeddings is 50 3. we inherit the values for the other parameters from  #AUTHOR_TAG, i. e, the dropout rate ρ = 0. 5, the mini - batch size = 50, the hyperparameter for the l 2 norms = 3.', 'finally, we employ the pre - trained word embeddings word2vec with 300 dimensions from  #AUTHOR_TAG for initialization.', 'we evaluate the presented cnn over the ace 2005 corpus.', 'for comparison purposes, we utilize the same test set with 40 newswire articles ( 672 sentences ), the same development set with 30 other documents ( 836 sentences ) and the same training set with the remaning 529 documents ( 14, 849 sentences ) as the previous studies on this dataset  #TAUTHOR_TAG.', '']",5
"['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['state - of - the - art systems for event detection on the ace 2005 dataset have followed the traditional feature - based approach with rich hand - designed feature sets, and statistical classifiers such as maxent and perceptron for structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare the proposed cnns with these state - of - the - art systems on the blind test set.', 'table 2 presents the overall performance of the systems with gold - standard entity mention and type information 4.', 'as we can see from the table, considering the systems that only use sentence level information, cnn1 significantly outperforms the maxent classifier as well as the joint beam search with local features from  #TAUTHOR_TAG.', 'this is remarkable since cnn1 does not require any external features 5, in contrast to the other featurebased systems that extensively rely on such external features to perform well.', 'more interestingly, when the entity type information is incorporated into cnn1, we obtain cnn2 that still only needs sentence level information but achieves the stateof - the - art performance for this task ( an improvement of 1. 5 % over the best system with only sentence level information  #TAUTHOR_TAG.', 'except for cnn1, all the systems reported in table 2 employ the gold - standard ( perfect ) entities mentions and types from manual annotation which might not be available in reality.', 'table 3 compares the performance of cnn1 and the feature - based systems in a more realistic setting, where entity mentions and types are acquired from an automatic high - performing name tagger and information extraction system  #TAUTHOR_TAG.', 'note that cnn1 is eligible for this comparison as it does not utilize any external features, thus avoiding usage of the name tagger and the information extraction system to identify entity mentions and types']",5
"['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['state - of - the - art systems for event detection on the ace 2005 dataset have followed the traditional feature - based approach with rich hand - designed feature sets, and statistical classifiers such as maxent and perceptron for structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare the proposed cnns with these state - of - the - art systems on the blind test set.', 'table 2 presents the overall performance of the systems with gold - standard entity mention and type information 4.', 'as we can see from the table, considering the systems that only use sentence level information, cnn1 significantly outperforms the maxent classifier as well as the joint beam search with local features from  #TAUTHOR_TAG.', 'this is remarkable since cnn1 does not require any external features 5, in contrast to the other featurebased systems that extensively rely on such external features to perform well.', 'more interestingly, when the entity type information is incorporated into cnn1, we obtain cnn2 that still only needs sentence level information but achieves the stateof - the - art performance for this task ( an improvement of 1. 5 % over the best system with only sentence level information  #TAUTHOR_TAG.', 'except for cnn1, all the systems reported in table 2 employ the gold - standard ( perfect ) entities mentions and types from manual annotation which might not be available in reality.', 'table 3 compares the performance of cnn1 and the feature - based systems in a more realistic setting, where entity mentions and types are acquired from an automatic high - performing name tagger and information extraction system  #TAUTHOR_TAG.', 'note that cnn1 is eligible for this comparison as it does not utilize any external features, thus avoiding usage of the name tagger and the information extraction system to identify entity mentions and types']",4
"['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare']","['state - of - the - art systems for event detection on the ace 2005 dataset have followed the traditional feature - based approach with rich hand - designed feature sets, and statistical classifiers such as maxent and perceptron for structured prediction in a joint architecture  #TAUTHOR_TAG.', 'in this section, we compare the proposed cnns with these state - of - the - art systems on the blind test set.', 'table 2 presents the overall performance of the systems with gold - standard entity mention and type information 4.', 'as we can see from the table, considering the systems that only use sentence level information, cnn1 significantly outperforms the maxent classifier as well as the joint beam search with local features from  #TAUTHOR_TAG.', 'this is remarkable since cnn1 does not require any external features 5, in contrast to the other featurebased systems that extensively rely on such external features to perform well.', 'more interestingly, when the entity type information is incorporated into cnn1, we obtain cnn2 that still only needs sentence level information but achieves the stateof - the - art performance for this task ( an improvement of 1. 5 % over the best system with only sentence level information  #TAUTHOR_TAG.', 'except for cnn1, all the systems reported in table 2 employ the gold - standard ( perfect ) entities mentions and types from manual annotation which might not be available in reality.', 'table 3 compares the performance of cnn1 and the feature - based systems in a more realistic setting, where entity mentions and types are acquired from an automatic high - performing name tagger and information extraction system  #TAUTHOR_TAG.', 'note that cnn1 is eligible for this comparison as it does not utilize any external features, thus avoiding usage of the name tagger and the information extraction system to identify entity mentions and types']",4
['traditional feature - based systems  #TAUTHOR_TAG'],"['traditional feature - based systems  #TAUTHOR_TAG do, cnns automatically induce their features from word embeddings, the general distributed representation of words that is shared across domains.', '']","['the traditional feature - based systems  #TAUTHOR_TAG do, cnns automatically induce their features from word embeddings, the general distributed representation of words that is shared across domains']","['', '( ii ) the propagated errors of the pre - processing toolkits for lower - level tasks ( pos tagging, name tagging, parsing etc ) to extract features : these pre - processing toolkits are also known to degrade when shifted to target domains  #AUTHOR_TAG daume iii, 2007 ; mc  #AUTHOR_TAG, introducing noisy features into the systems for higher - level tasks in the target domains and eventually impairing the performance of these higherlevel systems on the target domains.', 'for ed, we postulate that cnns are more useful than the feature - based approach for da for two reasons.', 'first, rather than relying on the symbolic and concrete forms ( i. e words, types etc ) to construct features as the traditional feature - based systems  #TAUTHOR_TAG do, cnns automatically induce their features from word embeddings, the general distributed representation of words that is shared across domains.', 'this helps cnns mitigate the lexical sparsity, learn more general and effective feature representation for trigger candidates, and thus bridge the gap between domains.', 'second, as cnns minimize the reliance on the supervised pre - processing toolkits for features, they can alleviate the error table 4 : in - domain ( first column ) and out -']",4
"['[ 13,  #TAUTHOR_TAG.', 'furthermore, the network learns to self - normalize']","['[ 13,  #TAUTHOR_TAG.', 'furthermore, the network learns to self - normalize']","['requires a fixed small number of noise samples ( e. g., 100 ) to achieve a good performance [ 13,  #TAUTHOR_TAG.', 'furthermore, the network learns to self - normalize']","['authors of [ 18 ] have shown that nce and importance sampling ( is ) are closely related, with the main difference is that nce is defined as a binary classifier between samples drawn from data or noise distributions with a logistic loss, whereas is is a multi - class classifier, which uses softmax and a crossentropy loss.', 'hence, the authors concluded that is is theoretically a better choice than nce.', 'the results reported, however, showed a minor difference in performance ( 2. 4 points in perplexity ).', 'moreover, training using is can be very difficult and requires a careful control of the samples variance, which can lead otherwise to unstable learning as was reported in [ 12 ].', 'hence, an adaptive is may use a large number of samples to solve this problem whereas nce is more stable and requires a fixed small number of noise samples ( e. g., 100 ) to achieve a good performance [ 13,  #TAUTHOR_TAG.', 'furthermore, the network learns to self - normalize during training using nce.', 'as a results, and on the contrary to is, the softmax is no longer required during evaluation, which makes nce an attractive choice to train large vocabulary nnlm.', 'the next section will show how nce can be efficiently implemented in batch mode training']",0
['batch  #TAUTHOR_TAG'],['batch  #TAUTHOR_TAG'],"['the batch  #TAUTHOR_TAG.', 'this paper proposes an extension']","['nce is a good alternative to train large vocabulary lms, it is not well - suited for batch mode training on gpus.', 'more particularly, each target word in the batch uses a different set of noise samples, which makes it difficult to formulate the learning using dense matrix operations.', 'as a result, the training time significantly increases.', 'to alleviate this problem, noise samples can be shared across the batch  #TAUTHOR_TAG.', 'this paper proposes an extension of nce to batch mode ( b - nce ) training.', 'this approach does not require any sampling and can be formulated using dense matrix operations.', 'furthermore, we can show that this solution optimally approximates the sampling from a unigram distribution, which has been shown to be a good noise distribution choice [ 13,  #TAUTHOR_TAG.', 'the main idea here is to restrict the vocabulary, at each forward - backward pass, to the target words in the batch ( words to predict ) and then replace the softmax function by nce.', 'in particular, these words play alternatively the role of targets and noise samples.', 'that is, for a target word wi, at batch index i, the rest of the target batch ( the remaining target words at the other batch indices j, j = i ) are considered to be the noise samples.', 'the rest of this section introduces the mathematical formulation of b - nce to efficiently calculate the error with respect to the output layer weights and biases, as well as the error at the previous layer in batch training, using the objective function ( 5 ) and its gradient ( 6 )']",0
['batch  #TAUTHOR_TAG'],['batch  #TAUTHOR_TAG'],"['the batch  #TAUTHOR_TAG.', 'this paper proposes an extension']","['nce is a good alternative to train large vocabulary lms, it is not well - suited for batch mode training on gpus.', 'more particularly, each target word in the batch uses a different set of noise samples, which makes it difficult to formulate the learning using dense matrix operations.', 'as a result, the training time significantly increases.', 'to alleviate this problem, noise samples can be shared across the batch  #TAUTHOR_TAG.', 'this paper proposes an extension of nce to batch mode ( b - nce ) training.', 'this approach does not require any sampling and can be formulated using dense matrix operations.', 'furthermore, we can show that this solution optimally approximates the sampling from a unigram distribution, which has been shown to be a good noise distribution choice [ 13,  #TAUTHOR_TAG.', 'the main idea here is to restrict the vocabulary, at each forward - backward pass, to the target words in the batch ( words to predict ) and then replace the softmax function by nce.', 'in particular, these words play alternatively the role of targets and noise samples.', 'that is, for a target word wi, at batch index i, the rest of the target batch ( the remaining target words at the other batch indices j, j = i ) are considered to be the noise samples.', 'the rest of this section introduces the mathematical formulation of b - nce to efficiently calculate the error with respect to the output layer weights and biases, as well as the error at the previous layer in batch training, using the objective function ( 5 ) and its gradient ( 6 )']",0
"['in  #TAUTHOR_TAG.', 'the adaptive b - nc']","['in  #TAUTHOR_TAG.', 'the adaptive b - nce follows']","['in  #TAUTHOR_TAG.', 'the adaptive b - nce follows']","['proposed b - nce approach as defined above uses a fixed number of noise samples ( b − 1 ), which is dependent on the batch size.', 'in cases where the latter is small ( e. g., b ≤ 100 ), b - nce can be extended to use an additional k noise samples.', 'this can be done by simply drawing an additional k samples form the noise distribution pn, and share them across the batch as it was done in  #TAUTHOR_TAG.', 'the adaptive b - nce follows the exact same steps described above using the extended output weight sub - matrix w t b + k ( h × ( b + k ) ), and the extended sub - vector bias c t b + k ( 1× ( b + k ) ) to evaluate ( 7 ), whereas ( 8 ) becomes', 'are the probabilities of the additional k noise samples using the noise distribution pn']",0
"['##tm is comparable to the lstm models proposed in  #TAUTHOR_TAG and [ 18 ] which use large hidden layers.', 'in particular, the first paper trains a large 4 - layers lstm model using s - nc']","['small relu - lstm is comparable to the lstm models proposed in  #TAUTHOR_TAG and [ 18 ] which use large hidden layers.', 'in particular, the first paper trains a large 4 - layers lstm model using s - nce on 4 gpus ( ppl = 43. 2']","['is comparable to the lstm models proposed in  #TAUTHOR_TAG and [ 18 ] which use large hidden layers.', 'in particular, the first paper trains a large 4 - layers lstm model using s - nc']","['', 'moreover, the performance of the small relu - lstm is comparable to the lstm models proposed in  #TAUTHOR_TAG and [ 18 ] which use large hidden layers.', 'in particular, the first paper trains a large 4 - layers lstm model using s - nce on 4 gpus ( ppl = 43. 2 and nop = 3. 4b ), whereas the second uses a recurrent bottleneck layer [ 23 ] and a total of k = 8192 noise samples with importance sampling on 32 tesla k40 gpus']",0
['s - nce )  #TAUTHOR_TAG'],['and the shared noise nce ( s - nce )  #TAUTHOR_TAG'],"['s - nce )  #TAUTHOR_TAG.', 'for the ltcb corpus, we also report']","['', 'our rnn implementation uses a projection weight matrix to decouple the word embedding and the hidden layer sizes.', 'we also report results after adding a bottleneck fully - connected relu layer right before the output layer in the recurrent models.', 'these models are marked with the prefix relu in the tables below.', 'each of the models is trained using the proposed b - nce approach and the shared noise nce ( s - nce )  #TAUTHOR_TAG.', 'for the ltcb corpus, we also report results of the models trained with the full softmax function.', 'this is the primary motive for using this corpus.', 'we would like also to highlight that the goal of this paper is not about improving lms performance but rather showing how a significant training speed - up can be achieved without compromising the models performance for large vocabulary lms.', 'hence, we solely focus our experiments on nce as a major approach to achieve this goal [ 17, 13,  #TAUTHOR_TAG in comparison to the reference full softmax function.', 'comparison to other training approaches such as importance sampling will be conducted in future work']",5
"['13,  #TAUTHOR_TAG, s']","['in [ 13,  #TAUTHOR_TAG,']","['13,  #TAUTHOR_TAG, s']","['', 'the latter is halved when no improvement on the validation data is observed for an additional 7 epochs.', 'we also use a norm - based gradient clipping with a threshold of 5 but we do not use dropout.', 'moreover, b - nce and s - nce use the unigram as noise distribution pn.', 'following the setup proposed in [ 13,  #TAUTHOR_TAG, s - nce uses k = 100 noise samples, whereas b - nce uses only the target words in the batch ( k = 0 ).', '']",5
['s - nce )  #TAUTHOR_TAG'],['and the shared noise nce ( s - nce )  #TAUTHOR_TAG'],"['s - nce )  #TAUTHOR_TAG.', 'for the ltcb corpus, we also report']","['', 'our rnn implementation uses a projection weight matrix to decouple the word embedding and the hidden layer sizes.', 'we also report results after adding a bottleneck fully - connected relu layer right before the output layer in the recurrent models.', 'these models are marked with the prefix relu in the tables below.', 'each of the models is trained using the proposed b - nce approach and the shared noise nce ( s - nce )  #TAUTHOR_TAG.', 'for the ltcb corpus, we also report results of the models trained with the full softmax function.', 'this is the primary motive for using this corpus.', 'we would like also to highlight that the goal of this paper is not about improving lms performance but rather showing how a significant training speed - up can be achieved without compromising the models performance for large vocabulary lms.', 'hence, we solely focus our experiments on nce as a major approach to achieve this goal [ 17, 13,  #TAUTHOR_TAG in comparison to the reference full softmax function.', 'comparison to other training approaches such as importance sampling will be conducted in future work']",7
['van  #TAUTHOR_TAG have explored using perceptual modalities like vision and sound'],['van  #TAUTHOR_TAG have explored using perceptual modalities like vision and sound'],['van  #TAUTHOR_TAG have explored using perceptual modalities like vision and sound'],"['and word embeddings.', 'multiple works in the recent past  #AUTHOR_TAG lopopolo and van  #TAUTHOR_TAG have explored using perceptual modalities like vision and sound to learn language embeddings.', 'while lopopolo and van  #AUTHOR_TAG show preliminary results on using sound to learn distributional representations,  #TAUTHOR_TAG build on ideas from  #AUTHOR_TAG to learn word embeddings that respect both linguistic and auditory relationships by optimizing a joint objective.', 'further, they propose various fusion strategies to combine knowledge from both the modalities.', 'instead, we "" specialize "" embeddings to exclusively respect relationships defined by sounds, while initializing with word2vec embeddings for smoothness.', 'similar to previous findings  #AUTHOR_TAG, we observe that our specialized embeddings outperform language - only as well as other multi - modal embeddings in the downstream tasks of interest.', 'in an orthogonal and interesting direction, other recent works  #AUTHOR_TAG learn word representations based on similarity in their pronunciation and not the sounds associated with them.', 'in other words, phonetically similar words that have near identical pronunciations are brought closer in the embedding space ( e. g., flower and flour ).', ' #AUTHOR_TAG study the applicability of onomatopoeia to obtain semantically meaningful representations of audio.', 'using a novel word - similarity metric and principal component analysis, they find representations for sounds and cluster them in this derived space to reason about similarities.', 'in contrast, we are interested in learning word representations that respect aural - similarity.', 'more importantly, our approach learns word representations for in a data - driven manner without having to first map the sound or its tags to corresponding onomatopoeic words.', 'multimodal learning with surrogate supervision.', ' #AUTHOR_TAG and  #AUTHOR_TAG use a surrogate modality to induce supervision to learn representations for a desired modality.', 'while the former learns word embeddings grounded in cartoon images, the latter learns visual features grounded in sound.', 'in contrast, we use sound as the surrogate modality to supervise representation learning for words']",0
['van  #TAUTHOR_TAG have explored using perceptual modalities like vision and sound'],['van  #TAUTHOR_TAG have explored using perceptual modalities like vision and sound'],['van  #TAUTHOR_TAG have explored using perceptual modalities like vision and sound'],"['and word embeddings.', 'multiple works in the recent past  #AUTHOR_TAG lopopolo and van  #TAUTHOR_TAG have explored using perceptual modalities like vision and sound to learn language embeddings.', 'while lopopolo and van  #AUTHOR_TAG show preliminary results on using sound to learn distributional representations,  #TAUTHOR_TAG build on ideas from  #AUTHOR_TAG to learn word embeddings that respect both linguistic and auditory relationships by optimizing a joint objective.', 'further, they propose various fusion strategies to combine knowledge from both the modalities.', 'instead, we "" specialize "" embeddings to exclusively respect relationships defined by sounds, while initializing with word2vec embeddings for smoothness.', 'similar to previous findings  #AUTHOR_TAG, we observe that our specialized embeddings outperform language - only as well as other multi - modal embeddings in the downstream tasks of interest.', 'in an orthogonal and interesting direction, other recent works  #AUTHOR_TAG learn word representations based on similarity in their pronunciation and not the sounds associated with them.', 'in other words, phonetically similar words that have near identical pronunciations are brought closer in the embedding space ( e. g., flower and flour ).', ' #AUTHOR_TAG study the applicability of onomatopoeia to obtain semantically meaningful representations of audio.', 'using a novel word - similarity metric and principal component analysis, they find representations for sounds and cluster them in this derived space to reason about similarities.', 'in contrast, we are interested in learning word representations that respect aural - similarity.', 'more importantly, our approach learns word representations for in a data - driven manner without having to first map the sound or its tags to corresponding onomatopoeic words.', 'multimodal learning with surrogate supervision.', ' #AUTHOR_TAG and  #AUTHOR_TAG use a surrogate modality to induce supervision to learn representations for a desired modality.', 'while the former learns word embeddings grounded in cartoon images, the latter learns visual features grounded in sound.', 'in contrast, we use sound as the surrogate modality to supervise representation learning for words']",0
[' #TAUTHOR_TAG ; lo'],"[' #TAUTHOR_TAG ; lopopolo and van  #AUTHOR_TAG to learn the proposed sound - word2vec embeddings.', 'freesound is a freely available, collaborative dataset consisting of user uploaded sounds permitting reuse.', '']",[' #TAUTHOR_TAG ; lo'],"['##sound.', 'we use the freesound database  #AUTHOR_TAG, also used in prior work  #TAUTHOR_TAG ; lopopolo and van  #AUTHOR_TAG to learn the proposed sound - word2vec embeddings.', 'freesound is a freely available, collaborative dataset consisting of user uploaded sounds permitting reuse.', 'all uploaded sounds have human descriptions in the form of tags and captions in natural language.', 'the tags contain a broad set of relevant topics for a sound ( e. g., ambience, electronic, birds, city, reverb ) and captions describing the content of the sound, in addition to details pertaining to audio quality.', 'for the text - based sound retrieval task, we use a subset of 234, 120 sounds from this database and divide it into training ( 80 % ), validation ( 10 % ) and testing splits ( 10 % ).', 'further, for foley sound discovery, we aggregate descriptions of foley sound production provided by sound engineers ( epicsound, accessed 23 - jan - 2017 ; singer, accessed 23 - jan - 2017 ) to create a list of 30 foley sound pairs, which forms our ground truth for the task.', 'for example, the description to produce a foley "" driving on gravel "" sound is to record the "" crunching sound of plastic or polyethene bags "".', 'amen and aslex.', 'amen and aslex  #TAUTHOR_TAG are subsets of the standard men  #AUTHOR_TAG and simlex  #AUTHOR_TAG word similarity datasets consisting of word - pairs that "" can be associated with a distinctive associated sound "".', 'we evaluate on this dataset for completeness to benchmark our approach against previous work.', 'however, we are primarily interested in the slightly different problem of relating words with similar auditory instantions that may or may not be semantically related as opposed to relating semantically similar words that can be associated with some common auditory signal']",0
['and aslex  #TAUTHOR_TAG are subsets of the men and simlex - 999 datasets'],['and aslex  #TAUTHOR_TAG are subsets of the men and simlex - 999 datasets'],['and aslex  #TAUTHOR_TAG are subsets of the men and simlex - 999 datasets'],"['and aslex  #TAUTHOR_TAG are subsets of the men and simlex - 999 datasets for word relatedness grounded in sound.', 'from table 2, we can see that our embeddings outperform  #TAUTHOR_TAG on both amen and aslex.', 'these datasets were curated by annotating concepts related by sound ; however we observe that relatedness is often confounded.', 'for example, ( river, water ), ( automobile, car ) are marked as aurally related however they do not stand out as aurally - related examples as they are already semantically related.', 'in contrast, we are interested in how onomatopoeic words relate to regular words ( table 3 ), which we study by explicit grounding in sound.', 'thus while we show competitive performance on this dataset, it might not be best suited for studying the benefits of our approach']",0
[' #TAUTHOR_TAG ; lo'],"[' #TAUTHOR_TAG ; lopopolo and van  #AUTHOR_TAG to learn the proposed sound - word2vec embeddings.', 'freesound is a freely available, collaborative dataset consisting of user uploaded sounds permitting reuse.', '']",[' #TAUTHOR_TAG ; lo'],"['##sound.', 'we use the freesound database  #AUTHOR_TAG, also used in prior work  #TAUTHOR_TAG ; lopopolo and van  #AUTHOR_TAG to learn the proposed sound - word2vec embeddings.', 'freesound is a freely available, collaborative dataset consisting of user uploaded sounds permitting reuse.', 'all uploaded sounds have human descriptions in the form of tags and captions in natural language.', 'the tags contain a broad set of relevant topics for a sound ( e. g., ambience, electronic, birds, city, reverb ) and captions describing the content of the sound, in addition to details pertaining to audio quality.', 'for the text - based sound retrieval task, we use a subset of 234, 120 sounds from this database and divide it into training ( 80 % ), validation ( 10 % ) and testing splits ( 10 % ).', 'further, for foley sound discovery, we aggregate descriptions of foley sound production provided by sound engineers ( epicsound, accessed 23 - jan - 2017 ; singer, accessed 23 - jan - 2017 ) to create a list of 30 foley sound pairs, which forms our ground truth for the task.', 'for example, the description to produce a foley "" driving on gravel "" sound is to record the "" crunching sound of plastic or polyethene bags "".', 'amen and aslex.', 'amen and aslex  #TAUTHOR_TAG are subsets of the standard men  #AUTHOR_TAG and simlex  #AUTHOR_TAG word similarity datasets consisting of word - pairs that "" can be associated with a distinctive associated sound "".', 'we evaluate on this dataset for completeness to benchmark our approach against previous work.', 'however, we are primarily interested in the slightly different problem of relating words with similar auditory instantions that may or may not be semantically related as opposed to relating semantically similar words that can be associated with some common auditory signal']",5
[' #TAUTHOR_TAG ; lo'],"[' #TAUTHOR_TAG ; lopopolo and van  #AUTHOR_TAG to learn the proposed sound - word2vec embeddings.', 'freesound is a freely available, collaborative dataset consisting of user uploaded sounds permitting reuse.', '']",[' #TAUTHOR_TAG ; lo'],"['##sound.', 'we use the freesound database  #AUTHOR_TAG, also used in prior work  #TAUTHOR_TAG ; lopopolo and van  #AUTHOR_TAG to learn the proposed sound - word2vec embeddings.', 'freesound is a freely available, collaborative dataset consisting of user uploaded sounds permitting reuse.', 'all uploaded sounds have human descriptions in the form of tags and captions in natural language.', 'the tags contain a broad set of relevant topics for a sound ( e. g., ambience, electronic, birds, city, reverb ) and captions describing the content of the sound, in addition to details pertaining to audio quality.', 'for the text - based sound retrieval task, we use a subset of 234, 120 sounds from this database and divide it into training ( 80 % ), validation ( 10 % ) and testing splits ( 10 % ).', 'further, for foley sound discovery, we aggregate descriptions of foley sound production provided by sound engineers ( epicsound, accessed 23 - jan - 2017 ; singer, accessed 23 - jan - 2017 ) to create a list of 30 foley sound pairs, which forms our ground truth for the task.', 'for example, the description to produce a foley "" driving on gravel "" sound is to record the "" crunching sound of plastic or polyethene bags "".', 'amen and aslex.', 'amen and aslex  #TAUTHOR_TAG are subsets of the standard men  #AUTHOR_TAG and simlex  #AUTHOR_TAG word similarity datasets consisting of word - pairs that "" can be associated with a distinctive associated sound "".', 'we evaluate on this dataset for completeness to benchmark our approach against previous work.', 'however, we are primarily interested in the slightly different problem of relating words with similar auditory instantions that may or may not be semantically related as opposed to relating semantically similar words that can be associated with some common auditory signal']",5
"[' #AUTHOR_TAG and  #TAUTHOR_TAG.', '']","[' #AUTHOR_TAG and  #TAUTHOR_TAG.', '']","[' #AUTHOR_TAG and  #TAUTHOR_TAG.', '']","['##s.', 'in addition to the language - only baseline word2vec  #AUTHOR_TAG, we compare against tag - word2vec - that predicts a tag using other tags of the sound as context, inspired by  #AUTHOR_TAG.', 'we also report results with a randomly initialized projection matrix ( soundword2vec ( r ) to evaluate the effectiveness of pretraining with word2vec.', 'prior work.', 'we compare against previous works lopopolo and van  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'while the former uses a standard bag of words and svd pipeline to arrive at distributional representations for words, the latter trains under a joint objective that respects both linguistic and auditory similarity.', 'we use the openly available implementation for lopopolo and van  #AUTHOR_TAG and re - implement  #TAUTHOR_TAG and train them on our dataset for a fair comparison of the methods.', 'in addition, we show a comparison to word - vectors released by  #TAUTHOR_TAG in the supplementary material.', 'all approaches use an embedding size of 300 for consistency']",5
"[') from, as opposed to formulating a joint objective with language and audio context  #TAUTHOR_TAG is driven by the fact that we are', 'interested in embeddings for words grounded in sounds, and not better generic word similarity']","['3 ). our use of language embeddings as an initialization to fine - tune', '( specialize ) from, as opposed to formulating a joint objective with language and audio context  #TAUTHOR_TAG is driven by the fact that we are', 'interested in embeddings for words grounded in sounds, and not better generic word similarity']","[') from, as opposed to formulating a joint objective with language and audio context  #TAUTHOR_TAG is driven by the fact that we are', 'interested in embeddings for words grounded in sounds, and not better generic word similarity']","['', 'assignment c ( s ) 2, optimizing for parameters w p and w o : we use sgd with momentum to optimize this objective which essentially is the cross - entropy between cluster assignments and p ( c | t )', '. we set d to 300 to be consistent with the publicly available word2vec embeddings. initialization. we initialize w p with word2vec embeddings  #AUTHOR_TAG', 'trained on the google news corpus dataset with ∼3m words. we fine - tune on a subset of 9578 tags which are present in both freesound as well as google news corpus datasets, which is 55', '. 68 % of the original tags in the freesound dataset. this helps us remove noisy tags unrelated to the content of the sound. in addition to enlarging the vocabulary, the pre', '##training helps induce smoothness in the soundword2vec embeddings - allowing us to transfer semantics learnt from sounds to words that were not present as tags in the freesound database. indeed, we find that word2vec', 'pre - training helps improve performance ( sec. 5. 3 ). our use of language embeddings as an initialization to fine - tune', '( specialize ) from, as opposed to formulating a joint objective with language and audio context  #TAUTHOR_TAG is driven by the fact that we are', 'interested in embeddings for words grounded in sounds, and not better generic word similarity']",4
['prior work  #TAUTHOR_TAG and lo'],"['prior work  #TAUTHOR_TAG and lopopolo and van  #AUTHOR_TAG ), which did not do specialization.', 'among our approaches, tag - word2vec performs second best - this is intuitive']","['', 'we see that specializing the embeddings for sound using our two - stage training outperforms prior work  #TAUTHOR_TAG and lo']","['', 'we embed the caption provided for the sound ( in the freesound database ) in a similar manner, and use it as the query.', 'we then rank sounds based on the cosine similarity between the tag and query representations for retrieval.', 'we evaluate using standard retrieval metrics - recall @ { 1, 10, 50, 100 }. note that the entire testing set ( ≈10k sounds ) is present in the retrieval pool.', 'so, recall @ 100 corresponds to obtaining the correct result in the top 1 % of the search results, which is a relatively stringent evaluation criterion.', 'results. table.', '1 shows that our sound - word2vec embeddings outperform the baselines.', 'we see that specializing the embeddings for sound using our two - stage training outperforms prior work  #TAUTHOR_TAG and lopopolo and van  #AUTHOR_TAG ), which did not do specialization.', 'among our approaches, tag - word2vec performs second best - this is intuitive since the tag distributions implicitly capture auditory relatedness ( a sound may have tags cat and meow ), while word2vec and sound - word2vec ( r ) have the lowest performance.', ' #AUTHOR_TAG ( higher is better ).', 'our approach performs better than  #TAUTHOR_TAG']",4
['prior work  #TAUTHOR_TAG and lo'],"['prior work  #TAUTHOR_TAG and lopopolo and van  #AUTHOR_TAG ), which did not do specialization.', 'among our approaches, tag - word2vec performs second best - this is intuitive']","['', 'we see that specializing the embeddings for sound using our two - stage training outperforms prior work  #TAUTHOR_TAG and lo']","['', 'we embed the caption provided for the sound ( in the freesound database ) in a similar manner, and use it as the query.', 'we then rank sounds based on the cosine similarity between the tag and query representations for retrieval.', 'we evaluate using standard retrieval metrics - recall @ { 1, 10, 50, 100 }. note that the entire testing set ( ≈10k sounds ) is present in the retrieval pool.', 'so, recall @ 100 corresponds to obtaining the correct result in the top 1 % of the search results, which is a relatively stringent evaluation criterion.', 'results. table.', '1 shows that our sound - word2vec embeddings outperform the baselines.', 'we see that specializing the embeddings for sound using our two - stage training outperforms prior work  #TAUTHOR_TAG and lopopolo and van  #AUTHOR_TAG ), which did not do specialization.', 'among our approaches, tag - word2vec performs second best - this is intuitive since the tag distributions implicitly capture auditory relatedness ( a sound may have tags cat and meow ), while word2vec and sound - word2vec ( r ) have the lowest performance.', ' #AUTHOR_TAG ( higher is better ).', 'our approach performs better than  #TAUTHOR_TAG']",4
"['performing approach is tag - word2vec.', 'lopopolo and van  #AUTHOR_TAG and  #TAUTHOR_TAG perform worse than tag - word2vec with a mean']","['performing approach is tag - word2vec.', 'lopopolo and van  #AUTHOR_TAG and  #TAUTHOR_TAG perform worse than tag - word2vec with a mean']","['performing approach is tag - word2vec.', 'lopopolo and van  #AUTHOR_TAG and  #TAUTHOR_TAG perform worse than tag - word2vec with a mean rank']","['find that sound - word2vec performs the best with a mean rank of 34. 6 compared to other baselines tag - word2vec ( 38. 9 ), soundword2vec ( r ) ( 114. 3 ) and word2vec ( 189. 45 ).', 'as observed previously, the second best performing approach is tag - word2vec.', 'lopopolo and van  #AUTHOR_TAG and  #TAUTHOR_TAG perform worse than tag - word2vec with a mean rank of 48. 4 and 42. 1 respectively.', 'note that random chance gets a rank of ( | v | + 1 ) / 2 = 4789. 5']",4
['and aslex  #TAUTHOR_TAG are subsets of the men and simlex - 999 datasets'],['and aslex  #TAUTHOR_TAG are subsets of the men and simlex - 999 datasets'],['and aslex  #TAUTHOR_TAG are subsets of the men and simlex - 999 datasets'],"['and aslex  #TAUTHOR_TAG are subsets of the men and simlex - 999 datasets for word relatedness grounded in sound.', 'from table 2, we can see that our embeddings outperform  #TAUTHOR_TAG on both amen and aslex.', 'these datasets were curated by annotating concepts related by sound ; however we observe that relatedness is often confounded.', 'for example, ( river, water ), ( automobile, car ) are marked as aurally related however they do not stand out as aurally - related examples as they are already semantically related.', 'in contrast, we are interested in how onomatopoeic words relate to regular words ( table 3 ), which we study by explicit grounding in sound.', 'thus while we show competitive performance on this dataset, it might not be best suited for studying the benefits of our approach']",4
"[' #AUTHOR_TAG and  #TAUTHOR_TAG.', '']","[' #AUTHOR_TAG and  #TAUTHOR_TAG.', '']","[' #AUTHOR_TAG and  #TAUTHOR_TAG.', '']","['##s.', 'in addition to the language - only baseline word2vec  #AUTHOR_TAG, we compare against tag - word2vec - that predicts a tag using other tags of the sound as context, inspired by  #AUTHOR_TAG.', 'we also report results with a randomly initialized projection matrix ( soundword2vec ( r ) to evaluate the effectiveness of pretraining with word2vec.', 'prior work.', 'we compare against previous works lopopolo and van  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'while the former uses a standard bag of words and svd pipeline to arrive at distributional representations for words, the latter trains under a joint objective that respects both linguistic and auditory similarity.', 'we use the openly available implementation for lopopolo and van  #AUTHOR_TAG and re - implement  #TAUTHOR_TAG and train them on our dataset for a fair comparison of the methods.', 'in addition, we show a comparison to word - vectors released by  #TAUTHOR_TAG in the supplementary material.', 'all approaches use an embedding size of 300 for consistency']",7
"[' #AUTHOR_TAG and  #TAUTHOR_TAG.', '']","[' #AUTHOR_TAG and  #TAUTHOR_TAG.', '']","[' #AUTHOR_TAG and  #TAUTHOR_TAG.', '']","['##s.', 'in addition to the language - only baseline word2vec  #AUTHOR_TAG, we compare against tag - word2vec - that predicts a tag using other tags of the sound as context, inspired by  #AUTHOR_TAG.', 'we also report results with a randomly initialized projection matrix ( soundword2vec ( r ) to evaluate the effectiveness of pretraining with word2vec.', 'prior work.', 'we compare against previous works lopopolo and van  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'while the former uses a standard bag of words and svd pipeline to arrive at distributional representations for words, the latter trains under a joint objective that respects both linguistic and auditory similarity.', 'we use the openly available implementation for lopopolo and van  #AUTHOR_TAG and re - implement  #TAUTHOR_TAG and train them on our dataset for a fair comparison of the methods.', 'in addition, we show a comparison to word - vectors released by  #TAUTHOR_TAG in the supplementary material.', 'all approaches use an embedding size of 300 for consistency']",7
"['', 'the word2vec  #TAUTHOR_TAG is among the']","['of nlp tasks [ 7, 8, 9 ].', 'the word2vec  #TAUTHOR_TAG is among the']","['7, 8, 9 ].', 'the word2vec  #TAUTHOR_TAG is among the']","['', 'learning knowledge from analyzing large - scaled unlabeled data is compulsory and proved useful in the previous works [ 4, 5, 6 ].', 'how to extract useful information from unannotated large scale corpus has been a research issue.', 'word embeddings have become increasingly popular lately, proving to be valuable as a source of features in a broad range of nlp tasks [ 7, 8, 9 ].', 'the word2vec  #TAUTHOR_TAG is among the most widely used word embedding models today.', 'their success is largely due to an efficient and user - friendly implementation that learns high quality word embeddings from very large corpora.', 'the word2vec learns low dimensional continuous vector representations for words by considering window - based contexts, i. e., context words within some fixed distance of each side of the target words.', 'another different context type is dependency - based word embedding [ 11, 12, 13 ], which considers syntactic contexts']",0
"['7, 8, 9 ].', 'the word2vec  #TAUTHOR_TAG is among the']","['[ 7, 8, 9 ].', 'the word2vec  #TAUTHOR_TAG is among the']","['7, 8, 9 ].', 'the word2vec  #TAUTHOR_TAG is among the']","['from analyzing large - scaled unlabeled data is compulsory and proved useful in the previous works [ 4, 5, 6 ].', 'how to extract useful information from unannotated large scale corpus has been a research issue.', 'word embeddings have become increasingly popular lately, proving to be valuable as a source of features in a broad range of nlp tasks [ 7, 8, 9 ].', 'the word2vec  #TAUTHOR_TAG is among the most widely used word embedding models today.', 'their success is largely due to an efficient and user - friendly implementation that learns high quality word embeddings from very large corpora.', 'the word2vec learns low dimensional continuous vector representations for words by considering window - based contexts, i. e., context words within some fixed distance of each side of the target words.', 'another different context type is dependency - based word embedding [ 11, 12, 13 ], which considers syntactic contexts rather', 'the 2016 conference on computational linguistics and speech processing rocling 2016, pp.', '100 - 102 the association for computational linguistics and chinese language processing 100 than window contexts in word2vec.', 'bansal et al. [ 8 ] and melamud et al. [ 11 ] show the benefits of such modified - context embeddings in dependency parsing task.', 'the dependency - based word embedding can relieve the problem of data sparseness, since even without occurrence of dependency word pairs in a corpus, dependency scores can be still calculated by word embeddings [ 12 ].', 'in this paper, we proposed a rescoring approach for parsing, based on a combination of original parsing scores and dependency word embedding scores to assist the determination of the best parse tree among the n - best parse trees.', 'there are three main steps in our rescoring approach.', 'the first step is to have the parser to produce n - best parse trees with their structural scores.', 'for each parsed tree including words, part - of - speech ( pos ) and semantic role labels.', 'second, we extract word - to - word associations ( or called word dependency, a dependency implies its close association with other words in either syntactic or semantic perspective ) from large amounts of auto - parsed data and adopt word2vecf [ 13 ] to train dependency - based word embeddings.', 'the last step is to build a structural rescoring method to find the best tree structure from the n - best candidates.', 'we conduct experiments on the standard data sets of the chinese treebank.', 'we also study how different types of embeddings influence on rescoring, including word, word with semantic role labels, and word senses ( concepts )']",0
"[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","['generation, or surface realisation, is the task of generating meaningful, grammatically correct and fluent text from some abstract semantic or syntactic representation of the sentence.', 'it is an important and growing field of natural language processing with applications in areas such as transferbased machine translation  #AUTHOR_TAG and sentence condensation  #AUTHOR_TAG.', 'while recent work on generation in restricted domains, such as  #AUTHOR_TAG, has shown promising results there remains much room for improvement particularly for broad coverage and robust generators, like those of  #AUTHOR_TAG and  #TAUTHOR_TAG, which do not rely on handcrafted grammars and thus can easily be ported to new languages.', 'this paper is concerned with sentence generation from lexical - functional grammar ( lfg ) fstructures  #AUTHOR_TAG.', 'we present improvements in previous lfg - based generation models firstly by breaking down pcfg independence assumptions so that more f - structure conditioning context is included when predicting grammar rule expansions.', 'this history - based approach has worked well in parsing  #AUTHOR_TAG and we show that it also improves pcfg - based generation.', 'we also present work on utilising named entities and other multi - word units to improve generation results for both accuracy and coverage.', 'there has been a limited amount of exploration into the use of multi - word units in probabilistic parsing, for example in  #AUTHOR_TAG ( lfg parsing ) and  #AUTHOR_TAG ( dependency parsing ).', 'we are not aware of any similar work on generation.', 'in the lfg - based generation algorithm presented by  #TAUTHOR_TAG complex named entities ( i. e. those consisting of more than one word token ) and other multi - word units can be fragmented in the surface realization.', ""we show that the identification of such units may be used as a simple measure to constrain the generation model's output."", 'we take the generator of  #TAUTHOR_TAG as our baseline generator.', 'when tested on f - structures for all sentences from section 23 of the penn wall street journal ( wsj ) treebank  #AUTHOR_TAG, the techniques described in this paper improve bleu score from 66. 52 to 68. 82.', 'in addition, coverage is increased from 98. 18 % to almost 100 % ( 99. 96 % ).', 'the remainder of the paper is structured as follows : in section 2 we review related work on statistical sentence generation.', 'section 3 describes the baseline generation model and in section 4 we show how the new history - based model improves over the baseline.', 'in section 5 we describe the source of the multi - word units ( mwu ) used in our experiments and the various techniques we employ to make use of these mwus in the generation process.', 'section 6 gives experimental details and results']",0
"[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","['generation, or surface realisation, is the task of generating meaningful, grammatically correct and fluent text from some abstract semantic or syntactic representation of the sentence.', 'it is an important and growing field of natural language processing with applications in areas such as transferbased machine translation  #AUTHOR_TAG and sentence condensation  #AUTHOR_TAG.', 'while recent work on generation in restricted domains, such as  #AUTHOR_TAG, has shown promising results there remains much room for improvement particularly for broad coverage and robust generators, like those of  #AUTHOR_TAG and  #TAUTHOR_TAG, which do not rely on handcrafted grammars and thus can easily be ported to new languages.', 'this paper is concerned with sentence generation from lexical - functional grammar ( lfg ) fstructures  #AUTHOR_TAG.', 'we present improvements in previous lfg - based generation models firstly by breaking down pcfg independence assumptions so that more f - structure conditioning context is included when predicting grammar rule expansions.', 'this history - based approach has worked well in parsing  #AUTHOR_TAG and we show that it also improves pcfg - based generation.', 'we also present work on utilising named entities and other multi - word units to improve generation results for both accuracy and coverage.', 'there has been a limited amount of exploration into the use of multi - word units in probabilistic parsing, for example in  #AUTHOR_TAG ( lfg parsing ) and  #AUTHOR_TAG ( dependency parsing ).', 'we are not aware of any similar work on generation.', 'in the lfg - based generation algorithm presented by  #TAUTHOR_TAG complex named entities ( i. e. those consisting of more than one word token ) and other multi - word units can be fragmented in the surface realization.', ""we show that the identification of such units may be used as a simple measure to constrain the generation model's output."", 'we take the generator of  #TAUTHOR_TAG as our baseline generator.', 'when tested on f - structures for all sentences from section 23 of the penn wall street journal ( wsj ) treebank  #AUTHOR_TAG, the techniques described in this paper improve bleu score from 66. 52 to 68. 82.', 'in addition, coverage is increased from 98. 18 % to almost 100 % ( 99. 96 % ).', 'the remainder of the paper is structured as follows : in section 2 we review related work on statistical sentence generation.', 'section 3 describes the baseline generation model and in section 4 we show how the new history - based model improves over the baseline.', 'in section 5 we describe the source of the multi - word units ( mwu ) used in our experiments and the various techniques we employ to make use of these mwus in the generation process.', 'section 6 gives experimental details and results']",0
"['##s  #TAUTHOR_TAG.', 'insof']","['( langkilde  #AUTHOR_TAG, created semi - automatically  #AUTHOR_TAG or, alternatively, extracted fully automatically from treebanks  #TAUTHOR_TAG.', 'insofar as it is a broad coverage generator,']","['##s  #TAUTHOR_TAG.', 'insof']","['( statistical ) generators, sentences are generated from an abstract linguistic encoding via the application of grammar rules.', 'these rules can be handcrafted grammar rules, such as those of ( langkilde  #AUTHOR_TAG, created semi - automatically  #AUTHOR_TAG or, alternatively, extracted fully automatically from treebanks  #TAUTHOR_TAG.', 'insofar as it is a broad coverage generator, which has been trained and tested on sections of the wsj corpus, our generator is closer to the generators of  #AUTHOR_TAG langkilde -  #AUTHOR_TAG than to those designed for more restricted domains such as weather forecast  #AUTHOR_TAG and air travel domains  #AUTHOR_TAG.', 'another feature which characterises statistical generators is the probability model used to select the most probable sentence from among the space of all possible sentences licensed by the grammar.', 'one generation technique is to first generate all possible sentences, storing them in a word lattice  #AUTHOR_TAG or, alternatively, a generation forest, a packed represention of alternate trees proposed by the generator  #AUTHOR_TAG, and then select the most probable sequence of words via an n - gram language model.', 'increasingly syntax - based information is being incorporated directly into the generation model.', 'for example,  #AUTHOR_TAG describe a sentence realisation process which uses a hand - crafted hpsg grammar to generate a generation forest.', 'a selective unpacking algorithm allows the extraction of an n - best list of realisations where realisation ranking is based on a maximum entropy model.', 'this unpacking algorithm is used in  #AUTHOR_TAG to rank realisations with features defined over hpsg derivation trees.', 'they achieved the best results when combining the tree - based model with an n - gram language model.', ' #AUTHOR_TAG describe a treebankextracted hpsg - based chart generator.', 'importing techniques developed for hpsg parsing, they apply a log linear model to a packed representation of all alternative derivation trees for a given input.', 'they found that a model which included syntactic information outperformed a bigram model as well as a combination of bigram and syntax model.', 'the probability model described in this paper also incorporates syntactic information, however, unlike the discriminative hpsg models just described, it is a generative history - and pcfg - based model.', ' #AUTHOR_TAG and  #AUTHOR_TAG mention the use of contextual features for the rules in their generation models, they do not provide details nor do they provide a formal probability model.', 'to the best of our knowledge this is the first paper providing a probabilistic generative, history - based generation model.', 'cahill and van  #AUTHOR_TAG present a probabilistic surface generation model for lfg  #AUTHOR_TAG.', 'lfg is a constraint - based theory of grammar, which analyses strings in']",0
"['- str ) ( 1 )', 'the generation model of  #TAUTHOR_TAG maximises the']","['p ( tree | f - str ) ( 1 )', 'the generation model of  #TAUTHOR_TAG maximises the']","['- str ) ( 1 )', 'the generation model of  #TAUTHOR_TAG maximises the probability of a tree given an f - structure ( eqn. 1 ), and the string generated is']","['', 'f - structures and the cstructure / f - structure correspondence are described in terms of functional annotations on c - structure nodes ( cfg grammar rules ).', 'an equation of the form ( ↑f ) = ↓ states that the f - structure associated with the mother of the current c - structure node ( ↑ ) has an attribute ( grammatical function ) ( f ), whose value is the f - structure of the current node ( ↓ ).', 'the up - arrows and down - arrows are shorthand for φ ( m ( n i ) ) = φ ( n i ) where n i is the c - structure node annotated with the equation.', '2', 't ree best : = argmax tree p ( tree | f - str ) ( 1 )', 'the generation model of  #TAUTHOR_TAG maximises the probability of a tree given an f - structure ( eqn. 1 ), and the string generated is the yield of the highest probability tree.', 'the generation process is guided by purely local information in the input f - structure : f - structure annotated cfg rules ( lhs → rhs ) are conditioned on their lhss and on the set of features / attributes feats = { a i | ∃v j φ ( lhs ) a i = v j } 3 φ - linked to the lhs ( eqn.', '2 ).', 'table 1 shows a generation grammar rule and conditioning features extracted from the example in figure 1.', 'the probability of a tree is decomposed into the product of the probabilities of the f - structure annotated rules ( conditioned on the lhs and local feats ) contributing to the tree.', 'conditional probabilities are estimated using maximum likelihood estimation.', 'figure 1 ).', '( 2006 ) note that conditioning f - structure annotated generation rules on local features ( eqn. 2 ) can sometimes cause the model to make inappropriate choices.', 'consider the following scenario where in addition to the c - / f - structure in figure 1, the training set contains the c - / f - structure displayed in figure 2']",0
"['.', 'to solve the problem,  #TAUTHOR_TAG']","['hired her.', 'to solve the problem,  #TAUTHOR_TAG']","['.', 'to solve the problem,  #TAUTHOR_TAG']","['rules prob given the input f - structure ( for she accepted ) in figure 3, ( and assuming suitable generation rules for intransitive vps and accepted ) the model would produce the inappropriate highest probability tree of figure 4 with an incorrect case for the pronoun in subject position.', 'figure 2 : c - and f - structures with φ links for the sentence she hired her.', 'to solve the problem,  #TAUTHOR_TAG apply an automatic generation grammar transformation to their training data : they automatically label cfg nodes with additional case information and the model now learns the new improved generation rules of tables 4 and 5. note how the additional case labelling subverts the problematic independence assumptions of the probability model and communicates the fact that a subject np has to be realised as nominative case from the s → np - nom vp production, via the intermediate np - nom → prp - nom, down to the lexical production prp - nom → she.', 'the labelling guarantees that, given the example f - structure in figure 3, the model generates the correct string she accepted']",0
"['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['', '##j = ↓ ) and its daughter nnp ( ↑ = ↓ ) ( via the ↑ = ↓ functional annotation ) is subj, as ( φ ( m ( n 2', ') ) subj ) = φ ( n 2 ), or equivalently ( f 1 subj ) = f 2. given figures 1 and 2 as training set, the improved model learns the generation rules ( the mother grammatical function of the outermost f - structure', 'is assumed to be a dummy top grammatical function ) of tables 6 and 7. f - struct feats grammar rules note, that for our example the effect of the uniform additional conditioning on mother', 'grammatical function has the same effect as the generation grammar transform of  #TAUTHOR_TAG, but without the need for the gram - mar transform. given the input f - structure in figure 3, the model will generate the correct string she accepted. in addition, uniform conditioning on mother grammatical function is more general than the case', '- phenomena specific generation grammar transform of  #TAUTHOR_TAG, in that it applies to each and every sub - part of a recursive input f - structure driving generation, making available relevant generation history ( context ) to guide local generation decisions. the new history', '- based probabilistic generation model is defined as : note that the new conditioning feature, the fstructure mother grammatical function, gf, is available from structure previously generated in the cstructure tree. as such, it is part of the history of the tree, i. e. it has already been generated in the topdown derivation of the tree. in this way', ', the generation model resembles history - based models for parsing  #AUTHOR_TAG', '. unlike, say,', 'the parent annotation for parsing of  #AUTHOR_TAG the parent gf feature for a particular node expansion is not merely extracted from the parent node in the c - structure tree, but is sometimes extracted from an ancestor node further up the c - structure tree via intervening ↑ = ↓ functional annotations. section 6 provides evaluation results for the new model on section 23 of the penn treebank']",0
"[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","['generation, or surface realisation, is the task of generating meaningful, grammatically correct and fluent text from some abstract semantic or syntactic representation of the sentence.', 'it is an important and growing field of natural language processing with applications in areas such as transferbased machine translation  #AUTHOR_TAG and sentence condensation  #AUTHOR_TAG.', 'while recent work on generation in restricted domains, such as  #AUTHOR_TAG, has shown promising results there remains much room for improvement particularly for broad coverage and robust generators, like those of  #AUTHOR_TAG and  #TAUTHOR_TAG, which do not rely on handcrafted grammars and thus can easily be ported to new languages.', 'this paper is concerned with sentence generation from lexical - functional grammar ( lfg ) fstructures  #AUTHOR_TAG.', 'we present improvements in previous lfg - based generation models firstly by breaking down pcfg independence assumptions so that more f - structure conditioning context is included when predicting grammar rule expansions.', 'this history - based approach has worked well in parsing  #AUTHOR_TAG and we show that it also improves pcfg - based generation.', 'we also present work on utilising named entities and other multi - word units to improve generation results for both accuracy and coverage.', 'there has been a limited amount of exploration into the use of multi - word units in probabilistic parsing, for example in  #AUTHOR_TAG ( lfg parsing ) and  #AUTHOR_TAG ( dependency parsing ).', 'we are not aware of any similar work on generation.', 'in the lfg - based generation algorithm presented by  #TAUTHOR_TAG complex named entities ( i. e. those consisting of more than one word token ) and other multi - word units can be fragmented in the surface realization.', ""we show that the identification of such units may be used as a simple measure to constrain the generation model's output."", 'we take the generator of  #TAUTHOR_TAG as our baseline generator.', 'when tested on f - structures for all sentences from section 23 of the penn wall street journal ( wsj ) treebank  #AUTHOR_TAG, the techniques described in this paper improve bleu score from 66. 52 to 68. 82.', 'in addition, coverage is increased from 98. 18 % to almost 100 % ( 99. 96 % ).', 'the remainder of the paper is structured as follows : in section 2 we review related work on statistical sentence generation.', 'section 3 describes the baseline generation model and in section 4 we show how the new history - based model improves over the baseline.', 'in section 5 we describe the source of the multi - word units ( mwu ) used in our experiments and the various techniques we employ to make use of these mwus in the generation process.', 'section 6 gives experimental details and results']",1
"[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","[' #TAUTHOR_TAG, which do not rely on handcrafted grammars']","['generation, or surface realisation, is the task of generating meaningful, grammatically correct and fluent text from some abstract semantic or syntactic representation of the sentence.', 'it is an important and growing field of natural language processing with applications in areas such as transferbased machine translation  #AUTHOR_TAG and sentence condensation  #AUTHOR_TAG.', 'while recent work on generation in restricted domains, such as  #AUTHOR_TAG, has shown promising results there remains much room for improvement particularly for broad coverage and robust generators, like those of  #AUTHOR_TAG and  #TAUTHOR_TAG, which do not rely on handcrafted grammars and thus can easily be ported to new languages.', 'this paper is concerned with sentence generation from lexical - functional grammar ( lfg ) fstructures  #AUTHOR_TAG.', 'we present improvements in previous lfg - based generation models firstly by breaking down pcfg independence assumptions so that more f - structure conditioning context is included when predicting grammar rule expansions.', 'this history - based approach has worked well in parsing  #AUTHOR_TAG and we show that it also improves pcfg - based generation.', 'we also present work on utilising named entities and other multi - word units to improve generation results for both accuracy and coverage.', 'there has been a limited amount of exploration into the use of multi - word units in probabilistic parsing, for example in  #AUTHOR_TAG ( lfg parsing ) and  #AUTHOR_TAG ( dependency parsing ).', 'we are not aware of any similar work on generation.', 'in the lfg - based generation algorithm presented by  #TAUTHOR_TAG complex named entities ( i. e. those consisting of more than one word token ) and other multi - word units can be fragmented in the surface realization.', ""we show that the identification of such units may be used as a simple measure to constrain the generation model's output."", 'we take the generator of  #TAUTHOR_TAG as our baseline generator.', 'when tested on f - structures for all sentences from section 23 of the penn wall street journal ( wsj ) treebank  #AUTHOR_TAG, the techniques described in this paper improve bleu score from 66. 52 to 68. 82.', 'in addition, coverage is increased from 98. 18 % to almost 100 % ( 99. 96 % ).', 'the remainder of the paper is structured as follows : in section 2 we review related work on statistical sentence generation.', 'section 3 describes the baseline generation model and in section 4 we show how the new history - based model improves over the baseline.', 'in section 5 we describe the source of the multi - word units ( mwu ) used in our experiments and the various techniques we employ to make use of these mwus in the generation process.', 'section 6 gives experimental details and results']",5
"[', new york becomes new york ).', 'as in  #TAUTHOR_TAG']","['concatenated into single words ( for example, new york becomes new york ).', 'as in  #TAUTHOR_TAG fstructures']","[', new york becomes new york ).', 'as in  #TAUTHOR_TAG fstructures']","['carried out three types of experiment which, in different ways, enabled the generation process to respect the restrictions on word - order provided by multi - word units.', 'for the first experiments ( type 1 ), the wsj treebank training and test data were altered so that multi - word units are concatenated into single words ( for example, new york becomes new york ).', 'as in  #TAUTHOR_TAG fstructures are generated from the ( now altered ) treebank and from this data, along with the treebank trees, the pcfg - based grammar, which is used for training the generation model, is extracted.', 'similarly, the f - structures for the test and development sets are created from penn treebank trees which have been modified so that multi - word units form single units.', '']",5
"['of the generation algorithm of  #TAUTHOR_TAG.', 'hb']","['of the generation algorithm of  #TAUTHOR_TAG.', 'hb']","['of the generation algorithm of  #TAUTHOR_TAG.', 'hb model refers to']","['', 'in table 10, baseline gives the results of the generation algorithm of  #TAUTHOR_TAG.', 'hb model refers to the improved model with the increased history context, as described in section 4.', '']",5
"['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['', '##j = ↓ ) and its daughter nnp ( ↑ = ↓ ) ( via the ↑ = ↓ functional annotation ) is subj, as ( φ ( m ( n 2', ') ) subj ) = φ ( n 2 ), or equivalently ( f 1 subj ) = f 2. given figures 1 and 2 as training set, the improved model learns the generation rules ( the mother grammatical function of the outermost f - structure', 'is assumed to be a dummy top grammatical function ) of tables 6 and 7. f - struct feats grammar rules note, that for our example the effect of the uniform additional conditioning on mother', 'grammatical function has the same effect as the generation grammar transform of  #TAUTHOR_TAG, but without the need for the gram - mar transform. given the input f - structure in figure 3, the model will generate the correct string she accepted. in addition, uniform conditioning on mother grammatical function is more general than the case', '- phenomena specific generation grammar transform of  #TAUTHOR_TAG, in that it applies to each and every sub - part of a recursive input f - structure driving generation, making available relevant generation history ( context ) to guide local generation decisions. the new history', '- based probabilistic generation model is defined as : note that the new conditioning feature, the fstructure mother grammatical function, gf, is available from structure previously generated in the cstructure tree. as such, it is part of the history of the tree, i. e. it has already been generated in the topdown derivation of the tree. in this way', ', the generation model resembles history - based models for parsing  #AUTHOR_TAG', '. unlike, say,', 'the parent annotation for parsing of  #AUTHOR_TAG the parent gf feature for a particular node expansion is not merely extracted from the parent node in the c - structure tree, but is sometimes extracted from an ancestor node further up the c - structure tree via intervening ↑ = ↓ functional annotations. section 6 provides evaluation results for the new model on section 23 of the penn treebank']",4
"['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['', '##j = ↓ ) and its daughter nnp ( ↑ = ↓ ) ( via the ↑ = ↓ functional annotation ) is subj, as ( φ ( m ( n 2', ') ) subj ) = φ ( n 2 ), or equivalently ( f 1 subj ) = f 2. given figures 1 and 2 as training set, the improved model learns the generation rules ( the mother grammatical function of the outermost f - structure', 'is assumed to be a dummy top grammatical function ) of tables 6 and 7. f - struct feats grammar rules note, that for our example the effect of the uniform additional conditioning on mother', 'grammatical function has the same effect as the generation grammar transform of  #TAUTHOR_TAG, but without the need for the gram - mar transform. given the input f - structure in figure 3, the model will generate the correct string she accepted. in addition, uniform conditioning on mother grammatical function is more general than the case', '- phenomena specific generation grammar transform of  #TAUTHOR_TAG, in that it applies to each and every sub - part of a recursive input f - structure driving generation, making available relevant generation history ( context ) to guide local generation decisions. the new history', '- based probabilistic generation model is defined as : note that the new conditioning feature, the fstructure mother grammatical function, gf, is available from structure previously generated in the cstructure tree. as such, it is part of the history of the tree, i. e. it has already been generated in the topdown derivation of the tree. in this way', ', the generation model resembles history - based models for parsing  #AUTHOR_TAG', '. unlike, say,', 'the parent annotation for parsing of  #AUTHOR_TAG the parent gf feature for a particular node expansion is not merely extracted from the parent node in the c - structure tree, but is sometimes extracted from an ancestor node further up the c - structure tree via intervening ↑ = ↓ functional annotations. section 6 provides evaluation results for the new model on section 23 of the penn treebank']",4
"['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['', '##j = ↓ ) and its daughter nnp ( ↑ = ↓ ) ( via the ↑ = ↓ functional annotation ) is subj, as ( φ ( m ( n 2', ') ) subj ) = φ ( n 2 ), or equivalently ( f 1 subj ) = f 2. given figures 1 and 2 as training set, the improved model learns the generation rules ( the mother grammatical function of the outermost f - structure', 'is assumed to be a dummy top grammatical function ) of tables 6 and 7. f - struct feats grammar rules note, that for our example the effect of the uniform additional conditioning on mother', 'grammatical function has the same effect as the generation grammar transform of  #TAUTHOR_TAG, but without the need for the gram - mar transform. given the input f - structure in figure 3, the model will generate the correct string she accepted. in addition, uniform conditioning on mother grammatical function is more general than the case', '- phenomena specific generation grammar transform of  #TAUTHOR_TAG, in that it applies to each and every sub - part of a recursive input f - structure driving generation, making available relevant generation history ( context ) to guide local generation decisions. the new history', '- based probabilistic generation model is defined as : note that the new conditioning feature, the fstructure mother grammatical function, gf, is available from structure previously generated in the cstructure tree. as such, it is part of the history of the tree, i. e. it has already been generated in the topdown derivation of the tree. in this way', ', the generation model resembles history - based models for parsing  #AUTHOR_TAG', '. unlike, say,', 'the parent annotation for parsing of  #AUTHOR_TAG the parent gf feature for a particular node expansion is not merely extracted from the parent node in the c - structure tree, but is sometimes extracted from an ancestor node further up the c - structure tree via intervening ↑ = ↓ functional annotations. section 6 provides evaluation results for the new model on section 23 of the penn treebank']",4
"['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['of  #TAUTHOR_TAG, but without the need for the gram - mar transform']","['', '##j = ↓ ) and its daughter nnp ( ↑ = ↓ ) ( via the ↑ = ↓ functional annotation ) is subj, as ( φ ( m ( n 2', ') ) subj ) = φ ( n 2 ), or equivalently ( f 1 subj ) = f 2. given figures 1 and 2 as training set, the improved model learns the generation rules ( the mother grammatical function of the outermost f - structure', 'is assumed to be a dummy top grammatical function ) of tables 6 and 7. f - struct feats grammar rules note, that for our example the effect of the uniform additional conditioning on mother', 'grammatical function has the same effect as the generation grammar transform of  #TAUTHOR_TAG, but without the need for the gram - mar transform. given the input f - structure in figure 3, the model will generate the correct string she accepted. in addition, uniform conditioning on mother grammatical function is more general than the case', '- phenomena specific generation grammar transform of  #TAUTHOR_TAG, in that it applies to each and every sub - part of a recursive input f - structure driving generation, making available relevant generation history ( context ) to guide local generation decisions. the new history', '- based probabilistic generation model is defined as : note that the new conditioning feature, the fstructure mother grammatical function, gf, is available from structure previously generated in the cstructure tree. as such, it is part of the history of the tree, i. e. it has already been generated in the topdown derivation of the tree. in this way', ', the generation model resembles history - based models for parsing  #AUTHOR_TAG', '. unlike, say,', 'the parent annotation for parsing of  #AUTHOR_TAG the parent gf feature for a particular node expansion is not merely extracted from the parent node in the c - structure tree, but is sometimes extracted from an ancestor node further up the c - structure tree via intervening ↑ = ↓ functional annotations. section 6 provides evaluation results for the new model on section 23 of the penn treebank']",3
"[', new york becomes new york ).', 'as in  #TAUTHOR_TAG']","['concatenated into single words ( for example, new york becomes new york ).', 'as in  #TAUTHOR_TAG fstructures']","[', new york becomes new york ).', 'as in  #TAUTHOR_TAG fstructures']","['carried out three types of experiment which, in different ways, enabled the generation process to respect the restrictions on word - order provided by multi - word units.', 'for the first experiments ( type 1 ), the wsj treebank training and test data were altered so that multi - word units are concatenated into single words ( for example, new york becomes new york ).', 'as in  #TAUTHOR_TAG fstructures are generated from the ( now altered ) treebank and from this data, along with the treebank trees, the pcfg - based grammar, which is used for training the generation model, is extracted.', 'similarly, the f - structures for the test and development sets are created from penn treebank trees which have been modified so that multi - word units form single units.', '']",3
['over twitter  #TAUTHOR_TAG'],['over twitter  #TAUTHOR_TAG'],"['8 ] are powerful techniques for semi - supervised learning where the domain can naturally be described using an undirected graph.', 'each node contains a probability distribution over labels, which may be empty for unlabelled nodes, and these labels are propagated over the graph in an iterative fashion.', 'modified adsorption ( mad ) [ 6 ], is an extension that allows more control of the random walk through the graph.', 'applications of lp and mad are varied, including video recommendation [ 1 ] and sentiment analysis over twitter  #TAUTHOR_TAG']","['language identification compares a document with a language fingerprint built from n - gram bag - of - words 1 http : / / komunitatea. elhuyar. org / tweetlid permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.', 'to copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and / or a fee.', 'copyright 20xx acm x - xxxxx - xx - x / xx / xx... $ 15. 00.', '( character or word level ).', 'tweets carry additional metadata useful for identifying language, such as geolocation [ 3 ], username [ 2, 3 ] and urls mentioned in the tweet [ 2 ].', 'other methods expand beyond the tweet itself to use a histogram of previously predicted languages, those of users @ - mentioned and lexical content of other tweets in a discussion [ 3 ].', 'discriminating between similar languages was the focus of the vardial workshop [ 7 ], and most submissions used content analysis.', 'these methods make limited use of the social context in which the authors are tweeting - our research question is "" can we identify the language of a tweet using the social graph of the tweeter? "".', 'label propagation approaches [ 8 ] are powerful techniques for semi - supervised learning where the domain can naturally be described using an undirected graph.', 'each node contains a probability distribution over labels, which may be empty for unlabelled nodes, and these labels are propagated over the graph in an iterative fashion.', 'modified adsorption ( mad ) [ 6 ], is an extension that allows more control of the random walk through the graph.', 'applications of lp and mad are varied, including video recommendation [ 1 ] and sentiment analysis over twitter  #TAUTHOR_TAG']",0
"['da recognition : it has also been noted that prosodic knowledge plays a major role in da identification for certain da types  #TAUTHOR_TAG.', 'the main reason is that the acoustic signal of the same']","['da recognition : it has also been noted that prosodic knowledge plays a major role in da identification for certain da types  #TAUTHOR_TAG.', 'the main reason is that the acoustic signal of the same']","['da recognition : it has also been noted that prosodic knowledge plays a major role in da identification for certain da types  #TAUTHOR_TAG.', 'the main reason is that the acoustic signal of the same utterance can be very different in a different da class.', 'this indicates that if one wants to classify']","['dialogue act is a context - based discourse concept that means the da class of a current utterance can be derived from its preceding utterance.', 'we will elaborate this argument with an example given in table 1.', ""speaker a utters'oh, yeah.'twice in the first portion, and each time it is labelled with two different da labels."", 'this is simply due to the context of the previously conversed utterances.', ""if we see the last four utterances of the example, when speaker a utters the'yes - no question'da, speaker b answers with'yeah'which is labelled as'yes - answer'da."", ""however, after the'statementopinion'from the same speaker, the same utterance'yeah'is labelled as'backchannel'and not'yes - answer '."", 'this gives evidence that when we process the text of a conversation, we can see the context of a current utterance in the preceding utterances.', 'prosodic cues for da recognition : it has also been noted that prosodic knowledge plays a major role in da identification for certain da types  #TAUTHOR_TAG.', 'the main reason is that the acoustic signal of the same utterance can be very different in a different da class.', 'this indicates that if one wants to classify da classes only from the text, the context must be an important aspect to consider : simply classifying single utterances might not be enough, but considering the preceding utterances as a context is important']",0
"['out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the sw']","['out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the swda corpus, the state - of - the - art baseline result was 71 %', 'for more than a decade using a standard hidden markov model ( hmm ) with language features']","[', prosodic, and syntactic cues : many studies have been carried out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the swda corpus, the state - of - the - art baseline result was 71']","[', prosodic, and syntactic cues : many studies have been carried out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the swda corpus, the state - of - the - art baseline result was 71 %', 'for more than a decade using a standard hidden markov model ( hmm ) with language features such as words and n - grams  #TAUTHOR_TAG.', 'the inter - annotator agreement accuracy for the same corpus is 84 %, and in this particular case, we are still far from achieving human accuracy.', ""however, words like'yeah'appear in many classes such as backchannel, yes - answer, agree / accept etc."", 'here, the prosodic cues play a very important role in identifying the da classes, as the same utterance can acoustically differ a lot which helps to distinguish the specific da class  #AUTHOR_TAG.', 'there are several approaches like traditional naive bayes and hmm models, which use minimal information and certainly ignore the dependency of the context within the communication  #AUTHOR_TAG.', 'they achieved 66 % and 74. 32 % respectively on the swda test set.', 'utterance - level classification : perhaps most research in modelling dialogue act identification is conducted at utterance - level  #AUTHOR_TAG ji et al., ;  #AUTHOR_TAG.', 'the emergence of deep learning also gave a big push to da classification.', 'in a natural language conversation, most utterances are very short ; hence it is also referred to as short text classification.', ' #AUTHOR_TAG achieved 73. 1 % accuracy on the swda corpus by using advanced deep learning frameworks such as rnns and convolutional neural networks ( cnn ) with word - level feature embeddings.', 'a novel approach : context - based learning : classifying the da classes at single utterance - level might fail when it comes to da classes where the utterances share similar lexical and syntactic cues ( words and phrases ) like the backchannel, yes - answer and accept / agree classes.', 'some researchers proposed an utterance - dependent learning approach  #AUTHOR_TAG ji et al., ;  #AUTHOR_TAG.', ' #AUTHOR_TAG and  #AUTHOR_TAG have proposed contextbased learning, where they represent the utterance as a compressed vector of the word embeddings using cnns and use these utterance representations to model discourse within a conversation using rnns.', 'in their architecture, i c a n i m a g i n e.', 'figure 1 : ( a ) multiplicative lstm ( mlstm ) characterlevel language model to produce the sentence representation s t.', 'the character - level language model is pre - trained and produces the feature ( hidden unit states of mlstm at the last character ) or average ( average of all hidden unit states of every character ) vector representation of the given utterance.', '']",0
"['out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the sw']","['out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the swda corpus, the state - of - the - art baseline result was 71 %', 'for more than a decade using a standard hidden markov model ( hmm ) with language features']","[', prosodic, and syntactic cues : many studies have been carried out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the swda corpus, the state - of - the - art baseline result was 71']","[', prosodic, and syntactic cues : many studies have been carried out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the swda corpus, the state - of - the - art baseline result was 71 %', 'for more than a decade using a standard hidden markov model ( hmm ) with language features such as words and n - grams  #TAUTHOR_TAG.', 'the inter - annotator agreement accuracy for the same corpus is 84 %, and in this particular case, we are still far from achieving human accuracy.', ""however, words like'yeah'appear in many classes such as backchannel, yes - answer, agree / accept etc."", 'here, the prosodic cues play a very important role in identifying the da classes, as the same utterance can acoustically differ a lot which helps to distinguish the specific da class  #AUTHOR_TAG.', 'there are several approaches like traditional naive bayes and hmm models, which use minimal information and certainly ignore the dependency of the context within the communication  #AUTHOR_TAG.', 'they achieved 66 % and 74. 32 % respectively on the swda test set.', 'utterance - level classification : perhaps most research in modelling dialogue act identification is conducted at utterance - level  #AUTHOR_TAG ji et al., ;  #AUTHOR_TAG.', 'the emergence of deep learning also gave a big push to da classification.', 'in a natural language conversation, most utterances are very short ; hence it is also referred to as short text classification.', ' #AUTHOR_TAG achieved 73. 1 % accuracy on the swda corpus by using advanced deep learning frameworks such as rnns and convolutional neural networks ( cnn ) with word - level feature embeddings.', 'a novel approach : context - based learning : classifying the da classes at single utterance - level might fail when it comes to da classes where the utterances share similar lexical and syntactic cues ( words and phrases ) like the backchannel, yes - answer and accept / agree classes.', 'some researchers proposed an utterance - dependent learning approach  #AUTHOR_TAG ji et al., ;  #AUTHOR_TAG.', ' #AUTHOR_TAG and  #AUTHOR_TAG have proposed contextbased learning, where they represent the utterance as a compressed vector of the word embeddings using cnns and use these utterance representations to model discourse within a conversation using rnns.', 'in their architecture, i c a n i m a g i n e.', 'figure 1 : ( a ) multiplicative lstm ( mlstm ) characterlevel language model to produce the sentence representation s t.', 'the character - level language model is pre - trained and produces the feature ( hidden unit states of mlstm at the last character ) or average ( average of all hidden unit states of every character ) vector representation of the given utterance.', '']",0
"['out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the sw']","['out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the swda corpus, the state - of - the - art baseline result was 71 %', 'for more than a decade using a standard hidden markov model ( hmm ) with language features']","[', prosodic, and syntactic cues : many studies have been carried out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the swda corpus, the state - of - the - art baseline result was 71']","[', prosodic, and syntactic cues : many studies have been carried out to find out the lexical, prosodic and syntactic cues  #TAUTHOR_TAG.', 'for the swda corpus, the state - of - the - art baseline result was 71 %', 'for more than a decade using a standard hidden markov model ( hmm ) with language features such as words and n - grams  #TAUTHOR_TAG.', 'the inter - annotator agreement accuracy for the same corpus is 84 %, and in this particular case, we are still far from achieving human accuracy.', ""however, words like'yeah'appear in many classes such as backchannel, yes - answer, agree / accept etc."", 'here, the prosodic cues play a very important role in identifying the da classes, as the same utterance can acoustically differ a lot which helps to distinguish the specific da class  #AUTHOR_TAG.', 'there are several approaches like traditional naive bayes and hmm models, which use minimal information and certainly ignore the dependency of the context within the communication  #AUTHOR_TAG.', 'they achieved 66 % and 74. 32 % respectively on the swda test set.', 'utterance - level classification : perhaps most research in modelling dialogue act identification is conducted at utterance - level  #AUTHOR_TAG ji et al., ;  #AUTHOR_TAG.', 'the emergence of deep learning also gave a big push to da classification.', 'in a natural language conversation, most utterances are very short ; hence it is also referred to as short text classification.', ' #AUTHOR_TAG achieved 73. 1 % accuracy on the swda corpus by using advanced deep learning frameworks such as rnns and convolutional neural networks ( cnn ) with word - level feature embeddings.', 'a novel approach : context - based learning : classifying the da classes at single utterance - level might fail when it comes to da classes where the utterances share similar lexical and syntactic cues ( words and phrases ) like the backchannel, yes - answer and accept / agree classes.', 'some researchers proposed an utterance - dependent learning approach  #AUTHOR_TAG ji et al., ;  #AUTHOR_TAG.', ' #AUTHOR_TAG and  #AUTHOR_TAG have proposed contextbased learning, where they represent the utterance as a compressed vector of the word embeddings using cnns and use these utterance representations to model discourse within a conversation using rnns.', 'in their architecture, i c a n i m a g i n e.', 'figure 1 : ( a ) multiplicative lstm ( mlstm ) characterlevel language model to produce the sentence representation s t.', 'the character - level language model is pre - trained and produces the feature ( hidden unit states of mlstm at the last character ) or average ( average of all hidden unit states of every character ) vector representation of the given utterance.', '']",1
"['data split of 1115 training and 19 test conversations as in the baseline approach  #TAUTHOR_TAG.', 'table 3 shows the results of the proposed model with several setups, first without the context,']","['data split of 1115 training and 19 test conversations as in the baseline approach  #TAUTHOR_TAG.', 'table 3 shows the results of the proposed model with several setups, first without the context,']","['follow the same data split of 1115 training and 19 test conversations as in the baseline approach  #TAUTHOR_TAG.', 'table 3 shows the results of the proposed model with several setups, first without the context,']","['follow the same data split of 1115 training and 19 test conversations as in the baseline approach  #TAUTHOR_TAG.', 'table 3 shows the results of the proposed model with several setups, first without the context, then with one, two, and so on preceding utterances in the context.', 'we examined different values for the number of the hidden units of the rnn, empirically 64 was identified as best and used throughout the experiments.', 'we also experimented with the various representations for the speaker id that is concatenated with the respective utterances but could find no differences.', 'as a result, our proposed model uses minimal information for the context.', 'the performance increases from 74 % to about 77 % with context.', 'we run each experiment for ten times and take the average.', 'the model shows robustness providing minimal variance, and using a minimum number of preceding utterances as a context can produce fair results']",5
['- art  #TAUTHOR_TAG'],['dialog interpretation and conversational analysis aiming to understand the intent of the speaker at every utterance of the conversation and ( 2 ) deep learning methods reached state - of - the - art  #TAUTHOR_TAG'],"['- art  #TAUTHOR_TAG.', 'the main contributions of the paper are :', '• novel self - governing neural networks ( sgnns ) for on -']","['', 'there are multiple strategies to build lightweight text classification models for ondevice.', 'one can create a small dictionary of common input → category mapping on the device and use a naive look - up at inference time.', 'however, such an approach does not scale to complex natural language tasks involving rich vocabularies and wide language variability.', 'another strategy is to employ fast sampling techniques  #AUTHOR_TAG or incorporate deep learning models with graph learning like  #AUTHOR_TAG ( bui et al.,, 2018, which result in large models but have proven to be extremely powerful for complex language understanding tasks like response completion  #AUTHOR_TAG and smart reply  #AUTHOR_TAG.', 'in this paper, we propose self - governing neural networks ( sgnns ) inspired by projection networks  #AUTHOR_TAG.', 'sgnns are on - device deep learning models learned via embedding - free projection operations.', 'we employ a modified version of the locality sensitive hashing ( lsh ) to reduce input dimension from millions of unique words / features to a short, fixed - length sequence of bits.', 'this allows us to compute a projection for an incoming text very fast, on - the - fly, with a small memory footprint on the device since we do not need to store the incoming text and word embeddings.', 'we evaluate the performance of our sgnns on dialogue act classification, because ( 1 ) it is an important step towards dialog interpretation and conversational analysis aiming to understand the intent of the speaker at every utterance of the conversation and ( 2 ) deep learning methods reached state - of - the - art  #TAUTHOR_TAG.', 'the main contributions of the paper are :', '• novel self - governing neural networks ( sgnns ) for on - device deep learning for short text classification.', '• compression technique that effectively captures low - dimensional semantic text representation and produces compact models that save on storage and computational cost']",1
"['dataset statistics.', 'we use the train, validation and test splits as defined in  #TAUTHOR_TAG']","['dataset statistics.', 'we use the train, validation and test splits as defined in  #TAUTHOR_TAG']","[': icsi meeting recorder dialog act corpus  #AUTHOR_TAG is a dialog corpus of multiparty meetings with 5 tags of dialog acts.', 'table 1 summarizes dataset statistics.', 'we use the train, validation and test splits as defined in  #TAUTHOR_TAG']","['conduct our experimental evaluation on two dialog act benchmark datasets.', '• swda : switchboard dialog act corpus  #AUTHOR_TAG is a popular open domain dialogs corpus between two speakers with 42 dialogs acts.', '• mrda : icsi meeting recorder dialog act corpus  #AUTHOR_TAG is a dialog corpus of multiparty meetings with 5 tags of dialog acts.', 'table 1 summarizes dataset statistics.', 'we use the train, validation and test splits as defined in  #TAUTHOR_TAG']",5
"['splits.', 'therefore, we compare our research against these works.', 'according to  #TAUTHOR_TAG, prior']","['splits.', 'therefore, we compare our research against these works.', 'according to  #TAUTHOR_TAG, prior']","['reported on the same data splits.', 'therefore, we compare our research against these works.', 'according to  #TAUTHOR_TAG, prior work by  #AUTHOR_TAG']","['also compare our performance against prior work using hmms  #AUTHOR_TAG and recent deep learning methods like cnn  #AUTHOR_TAG, rnn  #AUTHOR_TAG and rnn with gated attention  #AUTHOR_TAG.', 'to the best of our knowledge,  #AUTHOR_TAG are the latest approaches in dialog act classification, which also reported on the same data splits.', 'therefore, we compare our research against these works.', 'according to  #TAUTHOR_TAG, prior work by  #AUTHOR_TAG achieved promising results on the mrda dataset, but since the evaluation was conducted on a different data split, it is hard to compare them directly.', '']",0
"['splits.', 'therefore, we compare our research against these works.', 'according to  #TAUTHOR_TAG, prior']","['splits.', 'therefore, we compare our research against these works.', 'according to  #TAUTHOR_TAG, prior']","['reported on the same data splits.', 'therefore, we compare our research against these works.', 'according to  #TAUTHOR_TAG, prior work by  #AUTHOR_TAG']","['also compare our performance against prior work using hmms  #AUTHOR_TAG and recent deep learning methods like cnn  #AUTHOR_TAG, rnn  #AUTHOR_TAG and rnn with gated attention  #AUTHOR_TAG.', 'to the best of our knowledge,  #AUTHOR_TAG are the latest approaches in dialog act classification, which also reported on the same data splits.', 'therefore, we compare our research against these works.', 'according to  #TAUTHOR_TAG, prior work by  #AUTHOR_TAG achieved promising results on the mrda dataset, but since the evaluation was conducted on a different data split, it is hard to compare them directly.', '']",4
"['##ing methods  #TAUTHOR_TAG.', '']","['state - of - the - art deep leaning methods  #TAUTHOR_TAG.', '']","['- art deep leaning methods  #TAUTHOR_TAG.', 'we introduced a compression technique']","['proposed self - governing neural networks for on - device short text classification.', 'experiments on multiple dialog act datasets showed that our model outperforms state - of - the - art deep leaning methods  #TAUTHOR_TAG.', 'we introduced a compression technique that effectively captures low - dimensional semantic representation and produces compact models that significantly save on storage and computational cost.', 'our approach does not rely on pre - trained embeddings and efficiently computes the projection vectors on the fly.', 'in the future, we are interested in extending this approach to more natural language tasks.', 'for instance, we built a multilingual sgnn model for customer feedback classification  #AUTHOR_TAG and obtained 73 % on japanese, close to best performing system on the challenge  #AUTHOR_TAG.', 'unlike their method, we did not use any pre - processing, tagging, parsing, pre - trained embeddings or other resources']",4
"['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['', 'most empirical approaches currently employed in ner task make decision only on local context for extract inference, which is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold because non - local dependencies are prevalent in natural language ( including the ner task ).', '']",0
"['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['', 'most empirical approaches currently employed in ner task make decision only on local context for extract inference, which is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold because non - local dependencies are prevalent in natural language ( including the ner task ).', '']",0
"['- local features are applied in english ner in one - step approach  #TAUTHOR_TAG,']","['same time.', 'these non - local features are applied in english ner in one - step approach  #TAUTHOR_TAG,']","['semantic class information at the same time.', 'these non - local features are applied in english ner in one - step approach  #TAUTHOR_TAG, they employ these features to improve entity consistence among']","['', 'token - position & entity - majority features ( f4 ) : these features capture non - local information from f2 and f3 simultaneously. they take into account the entity boundary and semantic class information at the same time.', 'these non - local features are applied in english ner in one - step approach  #TAUTHOR_TAG, they employ these features to improve entity consistence among their different occurrences.', 'these features are assigned to token sequences that are matched exactly with the ( entity, majority - type ) list in forward maximum matching ( fmm ) way.', 'during training or testing, when the crfs tagger encounters a token sequence c 1... c n such that ( c k... c s ) ( k≥1, s ≤n ) is the longest token sequence existing in the entity list ; the correspondent features will be turned on to each token in c k.... c s.', 'for example, considering the']",0
"['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['', 'most empirical approaches currently employed in ner task make decision only on local context for extract inference, which is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold because non - local dependencies are prevalent in natural language ( including the ner task ).', '']",1
"['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['', 'most empirical approaches currently employed in ner task make decision only on local context for extract inference, which is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold because non - local dependencies are prevalent in natural language ( including the ner task ).', '']",1
"['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['', 'most empirical approaches currently employed in ner task make decision only on local context for extract inference, which is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold because non - local dependencies are prevalent in natural language ( including the ner task ).', '']",3
"['using local context alone.', 'similar to  #TAUTHOR_TAG, we employ']","['using local context alone.', 'similar to  #TAUTHOR_TAG, we employ two - stage']","['local context alone.', 'similar to  #TAUTHOR_TAG, we employ']","['validate the effectiveness of our approach of exploiting non - local features, we need to establish a baseline with state - of - the - art performance using local context alone.', 'similar to  #TAUTHOR_TAG, we employ two - stage architecture under conditional random fields ( crfs ) framework.', 'in the first stage, we build the baseline with local features only, and then we build the second ner system with non - local features.', 'we will introduce them step by step']",3
"['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold']","['', 'most empirical approaches currently employed in ner task make decision only on local context for extract inference, which is based on the data independent assumption  #TAUTHOR_TAG.', 'but often this assumption does not hold because non - local dependencies are prevalent in natural language ( including the ner task ).', '']",4
"['sequence is [UNK] [UNK].', 'different from  #TAUTHOR_TAG, they only assign the majority type information, like maj - loc, to']","['sequence is [UNK] [UNK].', 'different from  #TAUTHOR_TAG, they only assign the majority type information, like maj - loc, to']","['sequence is [UNK] [UNK].', 'different from  #TAUTHOR_TAG, they only assign the majority type information, like maj - loc, to each token in matched candidates, boundary information']","['sequence is [UNK] [UNK].', 'different from  #TAUTHOR_TAG, they only assign the majority type information, like maj - loc, to each token in matched candidates, boundary information like b, i and e is ignored, it is acceptable because they utilize these features only for english corpora, and the boundary information can be captured by the capitalization characteristics.', 'but in chinese ner, ned is more difficult than nec, so we assign the boundary information, representing with b, i and e, to each token in the matched candidates.', 'please note that not all matching token sequences are true candidates.', 'the false candidates come from two aspects : the first is the boundaries are correct, but the occurrences are common words 1 ; the second errors come from fmm, so the features are soft constraints.', 't ta ab bl le e 1 1..', 'e ex xa am mp pl le e f fo or r t to ok ke en n - - m ma aj jo or ri it ty y - - t ty yp pe e f fe ea at tu ur re es']",7
['- svd  #TAUTHOR_TAG and glo'],"['ppmi - svd  #TAUTHOR_TAG and glove  #AUTHOR_TAG, both achieving state - of - the - art']",['- svd  #TAUTHOR_TAG and glo'],"['word representations, or word embeddings, have been successfully used in many nlp applications  #AUTHOR_TAG.', 'traditionally, word representations have been obtained using countbased methods  #AUTHOR_TAG, where the cooccurrence matrix is derived directly from corpus counts  #AUTHOR_TAG or using association measures like point - wise mutual information ( pmi )  #AUTHOR_TAG and positive pmi ( ppmi )  #AUTHOR_TAG.', 'techniques for generating lower - rank representations have also been employed, such as ppmi - svd  #TAUTHOR_TAG and glove  #AUTHOR_TAG, both achieving state - of - the - art performance on a variety of tasks.', '']",0
['of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling'],['of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling'],"['.', 'the performance of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling the corpus  #AUTHOR_TAG b ).', 'as word embeddings with lower dimensionality may improve efficiency and generalization  #TAUTHOR_TAG, the improved ppmi * matrix']","['a word w and a symmetric window of win context words to the left and win to the right, the co - occurrence matrix of elements m wc is defined as the number of times a target word w and the context word c co - occurred in the corpus within the window.', 'the pmi matrix is defined as', ""where'*'represents the summation of the corresponding index."", 'as this matrix is unbounded in the inferior limit, in most applications it is replaced by its positive definite version, ppmi, where negative values are set to zero.', 'the performance of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling the corpus  #AUTHOR_TAG b ).', 'as word embeddings with lower dimensionality may improve efficiency and generalization  #TAUTHOR_TAG, the improved ppmi * matrix can be factorized as a product of two lower rank matrices.', 'where w w andw c are d - dimensional row vectors corresponding to vector embeddings for the target and context words.', 'using the truncated svd of size d yields the factorization u σt [UNK] with the lowest possible l 2 error  #AUTHOR_TAG.', ' #AUTHOR_TAG recommend using w = u σ p as the word representations, as suggested by  #AUTHOR_TAG, who borrowed the idea of weighting singular values from the work of  #AUTHOR_TAG on latent semantic analysis.', 'although the optimal value of p is highly task - dependent ( osterlund et al., 2015 ), we set p = 0. 5 as it has been shown to perform well on the word similarity and analogy tasks we use in our experiments  #TAUTHOR_TAG']",0
['of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling'],['of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling'],"['.', 'the performance of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling the corpus  #AUTHOR_TAG b ).', 'as word embeddings with lower dimensionality may improve efficiency and generalization  #TAUTHOR_TAG, the improved ppmi * matrix']","['a word w and a symmetric window of win context words to the left and win to the right, the co - occurrence matrix of elements m wc is defined as the number of times a target word w and the context word c co - occurred in the corpus within the window.', 'the pmi matrix is defined as', ""where'*'represents the summation of the corresponding index."", 'as this matrix is unbounded in the inferior limit, in most applications it is replaced by its positive definite version, ppmi, where negative values are set to zero.', 'the performance of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling the corpus  #AUTHOR_TAG b ).', 'as word embeddings with lower dimensionality may improve efficiency and generalization  #TAUTHOR_TAG, the improved ppmi * matrix can be factorized as a product of two lower rank matrices.', 'where w w andw c are d - dimensional row vectors corresponding to vector embeddings for the target and context words.', 'using the truncated svd of size d yields the factorization u σt [UNK] with the lowest possible l 2 error  #AUTHOR_TAG.', ' #AUTHOR_TAG recommend using w = u σ p as the word representations, as suggested by  #AUTHOR_TAG, who borrowed the idea of weighting singular values from the work of  #AUTHOR_TAG on latent semantic analysis.', 'although the optimal value of p is highly task - dependent ( osterlund et al., 2015 ), we set p = 0. 5 as it has been shown to perform well on the word similarity and analogy tasks we use in our experiments  #TAUTHOR_TAG']",0
['of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling'],['of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling'],"['.', 'the performance of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling the corpus  #AUTHOR_TAG b ).', 'as word embeddings with lower dimensionality may improve efficiency and generalization  #TAUTHOR_TAG, the improved ppmi * matrix']","['a word w and a symmetric window of win context words to the left and win to the right, the co - occurrence matrix of elements m wc is defined as the number of times a target word w and the context word c co - occurred in the corpus within the window.', 'the pmi matrix is defined as', ""where'*'represents the summation of the corresponding index."", 'as this matrix is unbounded in the inferior limit, in most applications it is replaced by its positive definite version, ppmi, where negative values are set to zero.', 'the performance of the ppmi matrix on word similarity tasks can be further improved by using context - distribution smoothing  #TAUTHOR_TAG and subsampling the corpus  #AUTHOR_TAG b ).', 'as word embeddings with lower dimensionality may improve efficiency and generalization  #TAUTHOR_TAG, the improved ppmi * matrix can be factorized as a product of two lower rank matrices.', 'where w w andw c are d - dimensional row vectors corresponding to vector embeddings for the target and context words.', 'using the truncated svd of size d yields the factorization u σt [UNK] with the lowest possible l 2 error  #AUTHOR_TAG.', ' #AUTHOR_TAG recommend using w = u σ p as the word representations, as suggested by  #AUTHOR_TAG, who borrowed the idea of weighting singular values from the work of  #AUTHOR_TAG on latent semantic analysis.', 'although the optimal value of p is highly task - dependent ( osterlund et al., 2015 ), we set p = 0. 5 as it has been shown to perform well on the word similarity and analogy tasks we use in our experiments  #TAUTHOR_TAG']",5
['4 suggested in  #TAUTHOR_TAG and an'],"['suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t =']","['was constructed using smoothing of α = 3 / 4 suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t = 10 −5  #AUTHOR_TAG b ).', '2 additionally, sgns uses 5 negative samples  #AUTHOR_TAG b ), a window of']","['models were trained on a dump of wikipedia from june 2015, split into sentences, with punctuation removed, numbers converted to words, and lower - cased.', 'words with less than 100 counts were removed, resulting in a vocabulary of 302, 203 words.', 'all models generate embeddings of 300 dimensions.', 'the ppmi * matrix used by both ppmi - svd and lexvec was constructed using smoothing of α = 3 / 4 suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t = 10 −5  #AUTHOR_TAG b ).', '2 additionally, sgns uses 5 negative samples  #AUTHOR_TAG b ), a window of size 10  #TAUTHOR_TAG, for 5 iterations with initial learning rate set to the default 0. 025.', 'glove is run with a window of size 10, x max = 100, β = 3 / 4, for 50 iterations and initial learning rate of 0. 05  #AUTHOR_TAG.', 'in lexvec two window sampling alternatives are compared : w s p p m i, which keeps the same fixed size win = 2 as used to create the p p m i * matrix ; or w s sgn s, which adopts identical sgns settings ( win = 10 with size randomization ).', 'we run lexvec for 5 iterations over the training corpus.', 'all methods generate both word and context matrices ( w andw ) : w is used for sgns, ppmi - svd and w + w for glove ( following  #TAUTHOR_TAG, and w and w + w for lexvec.', 'for evaluation, we use standard word similarity and analogy tasks  #AUTHOR_TAG b ;  #TAUTHOR_TAG factorization of logm ) and skip - gram ( implicit factorization of the shifted pmi matrix ), and compare the stochastic and mini - batch approaches.', 'word similarity tasks are : 3 ws - 353 similarity ( wsim ) and relatedness ( wrel )  #AUTHOR_TAG, men  #AUTHOR_TAG, mturk  #AUTHOR_TAG rw  #AUTHOR_TAG, simlex - 999  #AUTHOR_TAG, mc  #AUTHOR_TAG, rg  #AUTHOR_TAG, and scws  #AUTHOR_TAG, calculated using cosine.', 'word analogy tasks are : google semantic ( gsem ) and syntactic ( gsyn )  #AUTHOR_TAG a ) and msr syntactic analogy dataset  #AUTHOR_TAG c ), using 3cosadd and 3cosm ul']",5
['4 suggested in  #TAUTHOR_TAG and an'],"['suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t =']","['was constructed using smoothing of α = 3 / 4 suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t = 10 −5  #AUTHOR_TAG b ).', '2 additionally, sgns uses 5 negative samples  #AUTHOR_TAG b ), a window of']","['models were trained on a dump of wikipedia from june 2015, split into sentences, with punctuation removed, numbers converted to words, and lower - cased.', 'words with less than 100 counts were removed, resulting in a vocabulary of 302, 203 words.', 'all models generate embeddings of 300 dimensions.', 'the ppmi * matrix used by both ppmi - svd and lexvec was constructed using smoothing of α = 3 / 4 suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t = 10 −5  #AUTHOR_TAG b ).', '2 additionally, sgns uses 5 negative samples  #AUTHOR_TAG b ), a window of size 10  #TAUTHOR_TAG, for 5 iterations with initial learning rate set to the default 0. 025.', 'glove is run with a window of size 10, x max = 100, β = 3 / 4, for 50 iterations and initial learning rate of 0. 05  #AUTHOR_TAG.', 'in lexvec two window sampling alternatives are compared : w s p p m i, which keeps the same fixed size win = 2 as used to create the p p m i * matrix ; or w s sgn s, which adopts identical sgns settings ( win = 10 with size randomization ).', 'we run lexvec for 5 iterations over the training corpus.', 'all methods generate both word and context matrices ( w andw ) : w is used for sgns, ppmi - svd and w + w for glove ( following  #TAUTHOR_TAG, and w and w + w for lexvec.', 'for evaluation, we use standard word similarity and analogy tasks  #AUTHOR_TAG b ;  #TAUTHOR_TAG factorization of logm ) and skip - gram ( implicit factorization of the shifted pmi matrix ), and compare the stochastic and mini - batch approaches.', 'word similarity tasks are : 3 ws - 353 similarity ( wsim ) and relatedness ( wrel )  #AUTHOR_TAG, men  #AUTHOR_TAG, mturk  #AUTHOR_TAG rw  #AUTHOR_TAG, simlex - 999  #AUTHOR_TAG, mc  #AUTHOR_TAG, rg  #AUTHOR_TAG, and scws  #AUTHOR_TAG, calculated using cosine.', 'word analogy tasks are : google semantic ( gsem ) and syntactic ( gsyn )  #AUTHOR_TAG a ) and msr syntactic analogy dataset  #AUTHOR_TAG c ), using 3cosadd and 3cosm ul']",5
['4 suggested in  #TAUTHOR_TAG and an'],"['suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t =']","['was constructed using smoothing of α = 3 / 4 suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t = 10 −5  #AUTHOR_TAG b ).', '2 additionally, sgns uses 5 negative samples  #AUTHOR_TAG b ), a window of']","['models were trained on a dump of wikipedia from june 2015, split into sentences, with punctuation removed, numbers converted to words, and lower - cased.', 'words with less than 100 counts were removed, resulting in a vocabulary of 302, 203 words.', 'all models generate embeddings of 300 dimensions.', 'the ppmi * matrix used by both ppmi - svd and lexvec was constructed using smoothing of α = 3 / 4 suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t = 10 −5  #AUTHOR_TAG b ).', '2 additionally, sgns uses 5 negative samples  #AUTHOR_TAG b ), a window of size 10  #TAUTHOR_TAG, for 5 iterations with initial learning rate set to the default 0. 025.', 'glove is run with a window of size 10, x max = 100, β = 3 / 4, for 50 iterations and initial learning rate of 0. 05  #AUTHOR_TAG.', 'in lexvec two window sampling alternatives are compared : w s p p m i, which keeps the same fixed size win = 2 as used to create the p p m i * matrix ; or w s sgn s, which adopts identical sgns settings ( win = 10 with size randomization ).', 'we run lexvec for 5 iterations over the training corpus.', 'all methods generate both word and context matrices ( w andw ) : w is used for sgns, ppmi - svd and w + w for glove ( following  #TAUTHOR_TAG, and w and w + w for lexvec.', 'for evaluation, we use standard word similarity and analogy tasks  #AUTHOR_TAG b ;  #TAUTHOR_TAG factorization of logm ) and skip - gram ( implicit factorization of the shifted pmi matrix ), and compare the stochastic and mini - batch approaches.', 'word similarity tasks are : 3 ws - 353 similarity ( wsim ) and relatedness ( wrel )  #AUTHOR_TAG, men  #AUTHOR_TAG, mturk  #AUTHOR_TAG rw  #AUTHOR_TAG, simlex - 999  #AUTHOR_TAG, mc  #AUTHOR_TAG, rg  #AUTHOR_TAG, and scws  #AUTHOR_TAG, calculated using cosine.', 'word analogy tasks are : google semantic ( gsem ) and syntactic ( gsyn )  #AUTHOR_TAG a ) and msr syntactic analogy dataset  #AUTHOR_TAG c ), using 3cosadd and 3cosm ul']",5
['4 suggested in  #TAUTHOR_TAG and an'],"['suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t =']","['was constructed using smoothing of α = 3 / 4 suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t = 10 −5  #AUTHOR_TAG b ).', '2 additionally, sgns uses 5 negative samples  #AUTHOR_TAG b ), a window of']","['models were trained on a dump of wikipedia from june 2015, split into sentences, with punctuation removed, numbers converted to words, and lower - cased.', 'words with less than 100 counts were removed, resulting in a vocabulary of 302, 203 words.', 'all models generate embeddings of 300 dimensions.', 'the ppmi * matrix used by both ppmi - svd and lexvec was constructed using smoothing of α = 3 / 4 suggested in  #TAUTHOR_TAG and an unweighted window of size 2.', 'a dirty subsampling of the corpus is adopted for ppmi * and sgns with threshold of t = 10 −5  #AUTHOR_TAG b ).', '2 additionally, sgns uses 5 negative samples  #AUTHOR_TAG b ), a window of size 10  #TAUTHOR_TAG, for 5 iterations with initial learning rate set to the default 0. 025.', 'glove is run with a window of size 10, x max = 100, β = 3 / 4, for 50 iterations and initial learning rate of 0. 05  #AUTHOR_TAG.', 'in lexvec two window sampling alternatives are compared : w s p p m i, which keeps the same fixed size win = 2 as used to create the p p m i * matrix ; or w s sgn s, which adopts identical sgns settings ( win = 10 with size randomization ).', 'we run lexvec for 5 iterations over the training corpus.', 'all methods generate both word and context matrices ( w andw ) : w is used for sgns, ppmi - svd and w + w for glove ( following  #TAUTHOR_TAG, and w and w + w for lexvec.', 'for evaluation, we use standard word similarity and analogy tasks  #AUTHOR_TAG b ;  #TAUTHOR_TAG factorization of logm ) and skip - gram ( implicit factorization of the shifted pmi matrix ), and compare the stochastic and mini - batch approaches.', 'word similarity tasks are : 3 ws - 353 similarity ( wsim ) and relatedness ( wrel )  #AUTHOR_TAG, men  #AUTHOR_TAG, mturk  #AUTHOR_TAG rw  #AUTHOR_TAG, simlex - 999  #AUTHOR_TAG, mc  #AUTHOR_TAG, rg  #AUTHOR_TAG, and scws  #AUTHOR_TAG, calculated using cosine.', 'word analogy tasks are : google semantic ( gsem ) and syntactic ( gsyn )  #AUTHOR_TAG a ) and msr syntactic analogy dataset  #AUTHOR_TAG c ), using 3cosadd and 3cosm ul']",5
['constituency parsing  #TAUTHOR_TAG'],['constituency parsing  #TAUTHOR_TAG'],"['constituency parsing  #TAUTHOR_TAG.', 'despite the popularity of multi - task learning and sequence']","['- task learning ( mtl ) is an important machine learning paradigm that aims at improving the generalization performance of a task using other related tasks.', 'such framework has been widely studied by  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ; kumar & iii ( 2012 ), among many others.', 'in the context of deep neural networks, mtl has been applied successfully to various problems ranging from language  #AUTHOR_TAG, to vision  #AUTHOR_TAG, and speech  #AUTHOR_TAG.', 'recently, sequence to sequence ( seq2seq ) learning, proposed by  #AUTHOR_TAG,  #AUTHOR_TAG, and  #AUTHOR_TAG, emerges as an effective paradigm for dealing with variable - length inputs and outputs.', 'seq2seq learning, at its core, uses recurrent neural networks to map variable - length input sequences to variable - length output sequences.', 'while relatively new, the seq2seq approach has achieved state - of - the - art results in not only its original application - machine translation -  #AUTHOR_TAG b ;  #AUTHOR_TAG a ;  #AUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG, but also image caption generation, and constituency parsing  #TAUTHOR_TAG.', 'despite the popularity of multi - task learning and sequence to sequence learning, there has been little work in combining mtl with seq2seq learning.', '']",0
[' #AUTHOR_TAG a ;  #AUTHOR_TAG a ;  #TAUTHOR_TAG has found that it is crucial to empower seq2seq models with the attention mechanism'],[' #AUTHOR_TAG a ;  #AUTHOR_TAG a ;  #TAUTHOR_TAG has found that it is crucial to empower seq2seq models with the attention mechanism'],[' #AUTHOR_TAG a ;  #AUTHOR_TAG a ;  #TAUTHOR_TAG has found that it is crucial to empower seq2seq models with the attention mechanism'],"['to sequence learning ( seq2seq ) aims to directly model the conditional probability p ( y | x ) of mapping an input sequence, x 1,..., x n, into an output sequence, y 1,..', '., y m.', 'it accomplishes such goal through the encoder - decoder framework proposed by  #AUTHOR_TAG and  #AUTHOR_TAG.', 'as illustrated in figure 1, the encoder computes a representation s for each input sequence.', 'based on that input representation, the decoder generates an output sequence, one unit at a time, and hence, decomposes the conditional probability as :', 'a natural model for sequential data is the recurrent neural network ( rnn ), which is used by most of the recent seq2seq work.', 'these work, however, differ in terms of : ( a ) architecture - from unidirectional, to bidirectional, and deep multi - layer rnns ; and ( b ) rnn type - which are long - short term memory ( lstm )  #AUTHOR_TAG and the gated recurrent unit  #AUTHOR_TAG.', 'another important difference between seq2seq work lies in what constitutes the input representation s. the early seq2seq work  #AUTHOR_TAG b ;  #AUTHOR_TAG b ) uses only the last encoder state to initialize the decoder and sets s = [ ] in eq. ( 1 ).', ' #AUTHOR_TAG proposes an attention mechanism, a way to provide seq2seq models with a random access memory, to handle long input sequences.', 'this is accomplished by setting s in eq.', '( 1 ) to be the set of encoder hidden states already computed.', 'on the decoder side, at each time step, the attention mechanism will decide how much information to retrieve from that memory by learning where to focus, i. e., computing the alignment weights for all input positions.', 'recent work such as  #AUTHOR_TAG a ;  #AUTHOR_TAG a ;  #TAUTHOR_TAG has found that it is crucial to empower seq2seq models with the attention mechanism']",0
"['', 'since the parsing task maps from a sequence of english words to a sequence of parsing tags  #TAUTHOR_TAG, only the encoder can be shared with an']","['', 'since the parsing task maps from a sequence of english words to a sequence of parsing tags  #TAUTHOR_TAG, only the encoder can be shared with an english→german translation task.', 'as a result, this is a one - to - many mtl scenario ( § 3. 1 ).', 'to our surprise, the results in']","['', 'since the parsing task maps from a sequence of english words to a sequence of parsing tags  #TAUTHOR_TAG, only the encoder can be shared with an english→german translation task.', 'as a result, this is a one - to - many mtl scenario ( § 3. 1 )']","['this setting, we want to understand if a small task such as ptb parsing can help improve the performance of a large task such as translation.', 'since the parsing task maps from a sequence of english words to a sequence of parsing tags  #TAUTHOR_TAG, only the encoder can be shared with an english→german translation task.', 'as a result, this is a one - to - many mtl scenario ( § 3. 1 ).', 'to our surprise, the results in table 2 suggest that by adding a very small number of parsing minibatches ( with mixing ratio 0. 01, i. e., one parsing mini - batch per 100 translation mini - batches ), we can improve the translation quality substantially.', '']",0
['constituency parsing  #TAUTHOR_TAG'],['constituency parsing  #TAUTHOR_TAG'],"['constituency parsing  #TAUTHOR_TAG.', 'despite the popularity of multi - task learning and sequence']","['- task learning ( mtl ) is an important machine learning paradigm that aims at improving the generalization performance of a task using other related tasks.', 'such framework has been widely studied by  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ; kumar & iii ( 2012 ), among many others.', 'in the context of deep neural networks, mtl has been applied successfully to various problems ranging from language  #AUTHOR_TAG, to vision  #AUTHOR_TAG, and speech  #AUTHOR_TAG.', 'recently, sequence to sequence ( seq2seq ) learning, proposed by  #AUTHOR_TAG,  #AUTHOR_TAG, and  #AUTHOR_TAG, emerges as an effective paradigm for dealing with variable - length inputs and outputs.', 'seq2seq learning, at its core, uses recurrent neural networks to map variable - length input sequences to variable - length output sequences.', 'while relatively new, the seq2seq approach has achieved state - of - the - art results in not only its original application - machine translation -  #AUTHOR_TAG b ;  #AUTHOR_TAG a ;  #AUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG, but also image caption generation, and constituency parsing  #TAUTHOR_TAG.', 'despite the popularity of multi - task learning and sequence to sequence learning, there has been little work in combining mtl with seq2seq learning.', '']",1
['constituency parsing  #TAUTHOR_TAG'],['constituency parsing  #TAUTHOR_TAG'],"['constituency parsing  #TAUTHOR_TAG.', 'despite the popularity of multi - task learning and sequence']","['- task learning ( mtl ) is an important machine learning paradigm that aims at improving the generalization performance of a task using other related tasks.', 'such framework has been widely studied by  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ; kumar & iii ( 2012 ), among many others.', 'in the context of deep neural networks, mtl has been applied successfully to various problems ranging from language  #AUTHOR_TAG, to vision  #AUTHOR_TAG, and speech  #AUTHOR_TAG.', 'recently, sequence to sequence ( seq2seq ) learning, proposed by  #AUTHOR_TAG,  #AUTHOR_TAG, and  #AUTHOR_TAG, emerges as an effective paradigm for dealing with variable - length inputs and outputs.', 'seq2seq learning, at its core, uses recurrent neural networks to map variable - length input sequences to variable - length output sequences.', 'while relatively new, the seq2seq approach has achieved state - of - the - art results in not only its original application - machine translation -  #AUTHOR_TAG b ;  #AUTHOR_TAG a ;  #AUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG, but also image caption generation, and constituency parsing  #TAUTHOR_TAG.', 'despite the popularity of multi - task learning and sequence to sequence learning, there has been little work in combining mtl with seq2seq learning.', '']",4
"['attention - based systems in  #TAUTHOR_TAG, including the']","['attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art']","['', 'our models are compared against the best attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art result of 92']","['second set of experiments shifts the attention to parsing by having it as the reference task.', 'we show in table 5 results that combine parsing with either ( a ) the english autoencoder task or ( b ) the english→german translation task.', 'our models are compared against the best attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art result of 92. 8 f 1.', 'before discussing the multi - task results, we note a few interesting observations.', 'first, very small parsing perplexities, close to 1. 1, can be achieved with large training data.', ""7 second, our baseline system can obtain a very competitive f 1 score of 92. 2, rivaling  #TAUTHOR_TAG's systems."", 'this is rather surprising since our models do not use any attention mechanism.', 'a closer look into these models reveal that there seems to be an architectural difference :  #TAUTHOR_TAG use 3 - layer lstm with 256 cells and 512 - dimensional embeddings ; whereas our models use 4 - layer lstm with 1000 cells and 1000 - dimensional embeddings.', 'this further supports findings in  #AUTHOR_TAG that larger networks matter for sequence models.', 'for the multi - task results, while autoencoder does not seem to help parsing, translation does.', '']",4
"[' #TAUTHOR_TAG.', 'the two parsing tasks, however, are evaluated on the same validation (']","[' #TAUTHOR_TAG.', 'the two parsing tasks, however, are evaluated on the same validation ( section 22 ) and test ( section 23 ) sets from the ptb data.', 'note also that the parse']","[' #TAUTHOR_TAG.', 'the two parsing tasks, however, are evaluated on the same validation ( section 22 ) and test ( section 23 ) sets from the ptb data.', 'note also that the parse trees have been linearized following  #TAUTHOR_TAG.', 'lastly, for image caption generation, we use a dataset of image and caption pairs provided by  #AUTHOR_TAG b )']","['', ""we use the wmt'15 data  #AUTHOR_TAG for the [UNK] translation problem."", ' #AUTHOR_TAG a ), we use the 50k most frequent words for each language from the training corpus.', '1 these vocabularies are then shared with other tasks, except for parsing in which the target "" language "" has a vocabulary of 104 tags.', 'we use newstest2013 ( 3000 sentences ) as a validation set to select our hyperparameters, e. g., mixing coefficients.', ""for testing, to be comparable with existing results in  #AUTHOR_TAG a ) for the unsupervised tasks, we use the english and german monolingual corpora from wmt'15."", '4 since in our experiments, unsupervised tasks are always coupled with translation tasks, we use the same validation and test sets as the accompanied translation tasks.', 'for constituency parsing, we experiment with two types of corpora :', '1. a small corpus - the widely used penn tree bank ( ptb ) dataset  #AUTHOR_TAG and, 2. a large corpus - the high - confidence ( hc ) parse trees provided by  #TAUTHOR_TAG.', 'the two parsing tasks, however, are evaluated on the same validation ( section 22 ) and test ( section 23 ) sets from the ptb data.', 'note also that the parse trees have been linearized following  #TAUTHOR_TAG.', 'lastly, for image caption generation, we use a dataset of image and caption pairs provided by  #AUTHOR_TAG b )']",5
"[' #TAUTHOR_TAG.', 'the two parsing tasks, however, are evaluated on the same validation (']","[' #TAUTHOR_TAG.', 'the two parsing tasks, however, are evaluated on the same validation ( section 22 ) and test ( section 23 ) sets from the ptb data.', 'note also that the parse']","[' #TAUTHOR_TAG.', 'the two parsing tasks, however, are evaluated on the same validation ( section 22 ) and test ( section 23 ) sets from the ptb data.', 'note also that the parse trees have been linearized following  #TAUTHOR_TAG.', 'lastly, for image caption generation, we use a dataset of image and caption pairs provided by  #AUTHOR_TAG b )']","['', ""we use the wmt'15 data  #AUTHOR_TAG for the [UNK] translation problem."", ' #AUTHOR_TAG a ), we use the 50k most frequent words for each language from the training corpus.', '1 these vocabularies are then shared with other tasks, except for parsing in which the target "" language "" has a vocabulary of 104 tags.', 'we use newstest2013 ( 3000 sentences ) as a validation set to select our hyperparameters, e. g., mixing coefficients.', ""for testing, to be comparable with existing results in  #AUTHOR_TAG a ) for the unsupervised tasks, we use the english and german monolingual corpora from wmt'15."", '4 since in our experiments, unsupervised tasks are always coupled with translation tasks, we use the same validation and test sets as the accompanied translation tasks.', 'for constituency parsing, we experiment with two types of corpora :', '1. a small corpus - the widely used penn tree bank ( ptb ) dataset  #AUTHOR_TAG and, 2. a large corpus - the high - confidence ( hc ) parse trees provided by  #TAUTHOR_TAG.', 'the two parsing tasks, however, are evaluated on the same validation ( section 22 ) and test ( section 23 ) sets from the ptb data.', 'note also that the parse trees have been linearized following  #TAUTHOR_TAG.', 'lastly, for image caption generation, we use a dataset of image and caption pairs provided by  #AUTHOR_TAG b )']",5
"['by  #TAUTHOR_TAG.', 'as highlighted in']","['by  #TAUTHOR_TAG.', 'as highlighted in']","['hc ) corpus, which is provided by  #TAUTHOR_TAG.', 'as highlighted in']","['first set of experiments is almost the same as the one - to - many setting in section 4. 3. 1 which combines translation, as the reference task, with parsing.', 'the only difference is in terms of parsing table 2.', 'reference tasks are in italic with mixing ratios in parentheses.', 'the average results of 2 runs are in mean ( stddev ) format.', 'data.', 'instead of using the small penn tree bank corpus, we consider a large parsing resource, the high - confidence ( hc ) corpus, which is provided by  #TAUTHOR_TAG.', 'as highlighted in table 4, the trend is consistent ; mtl helps boost translation quality by up to + 0. 9 bleu points.', ""table 4 : english→german wmt'14 translation - shown are perplexities ( ppl ) and bleu scores of various translation models."", 'our multi - task systems combine translation and parsing on the highconfidence corpus together.', 'mixing ratios are in parentheses and the average results over 2 runs are in mean ( stddev ) format.', 'best results are bolded']",5
"['attention - based systems in  #TAUTHOR_TAG, including the']","['attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art']","['', 'our models are compared against the best attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art result of 92']","['second set of experiments shifts the attention to parsing by having it as the reference task.', 'we show in table 5 results that combine parsing with either ( a ) the english autoencoder task or ( b ) the english→german translation task.', 'our models are compared against the best attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art result of 92. 8 f 1.', 'before discussing the multi - task results, we note a few interesting observations.', 'first, very small parsing perplexities, close to 1. 1, can be achieved with large training data.', ""7 second, our baseline system can obtain a very competitive f 1 score of 92. 2, rivaling  #TAUTHOR_TAG's systems."", 'this is rather surprising since our models do not use any attention mechanism.', 'a closer look into these models reveal that there seems to be an architectural difference :  #TAUTHOR_TAG use 3 - layer lstm with 256 cells and 512 - dimensional embeddings ; whereas our models use 4 - layer lstm with 1000 cells and 1000 - dimensional embeddings.', 'this further supports findings in  #AUTHOR_TAG that larger networks matter for sequence models.', 'for the multi - task results, while autoencoder does not seem to help parsing, translation does.', '']",5
"['', 'since the parsing task maps from a sequence of english words to a sequence of parsing tags  #TAUTHOR_TAG, only the encoder can be shared with an']","['', 'since the parsing task maps from a sequence of english words to a sequence of parsing tags  #TAUTHOR_TAG, only the encoder can be shared with an english→german translation task.', 'as a result, this is a one - to - many mtl scenario ( § 3. 1 ).', 'to our surprise, the results in']","['', 'since the parsing task maps from a sequence of english words to a sequence of parsing tags  #TAUTHOR_TAG, only the encoder can be shared with an english→german translation task.', 'as a result, this is a one - to - many mtl scenario ( § 3. 1 )']","['this setting, we want to understand if a small task such as ptb parsing can help improve the performance of a large task such as translation.', 'since the parsing task maps from a sequence of english words to a sequence of parsing tags  #TAUTHOR_TAG, only the encoder can be shared with an english→german translation task.', 'as a result, this is a one - to - many mtl scenario ( § 3. 1 ).', 'to our surprise, the results in table 2 suggest that by adding a very small number of parsing minibatches ( with mixing ratio 0. 01, i. e., one parsing mini - batch per 100 translation mini - batches ), we can improve the translation quality substantially.', '']",3
"['attention - based systems in  #TAUTHOR_TAG, including the']","['attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art']","['', 'our models are compared against the best attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art result of 92']","['second set of experiments shifts the attention to parsing by having it as the reference task.', 'we show in table 5 results that combine parsing with either ( a ) the english autoencoder task or ( b ) the english→german translation task.', 'our models are compared against the best attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art result of 92. 8 f 1.', 'before discussing the multi - task results, we note a few interesting observations.', 'first, very small parsing perplexities, close to 1. 1, can be achieved with large training data.', ""7 second, our baseline system can obtain a very competitive f 1 score of 92. 2, rivaling  #TAUTHOR_TAG's systems."", 'this is rather surprising since our models do not use any attention mechanism.', 'a closer look into these models reveal that there seems to be an architectural difference :  #TAUTHOR_TAG use 3 - layer lstm with 256 cells and 512 - dimensional embeddings ; whereas our models use 4 - layer lstm with 1000 cells and 1000 - dimensional embeddings.', 'this further supports findings in  #AUTHOR_TAG that larger networks matter for sequence models.', 'for the multi - task results, while autoencoder does not seem to help parsing, translation does.', '']",3
"['attention - based systems in  #TAUTHOR_TAG, including the']","['attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art']","['', 'our models are compared against the best attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art result of 92']","['second set of experiments shifts the attention to parsing by having it as the reference task.', 'we show in table 5 results that combine parsing with either ( a ) the english autoencoder task or ( b ) the english→german translation task.', 'our models are compared against the best attention - based systems in  #TAUTHOR_TAG, including the state - of - the - art result of 92. 8 f 1.', 'before discussing the multi - task results, we note a few interesting observations.', 'first, very small parsing perplexities, close to 1. 1, can be achieved with large training data.', ""7 second, our baseline system can obtain a very competitive f 1 score of 92. 2, rivaling  #TAUTHOR_TAG's systems."", 'this is rather surprising since our models do not use any attention mechanism.', 'a closer look into these models reveal that there seems to be an architectural difference :  #TAUTHOR_TAG use 3 - layer lstm with 256 cells and 512 - dimensional embeddings ; whereas our models use 4 - layer lstm with 1000 cells and 1000 - dimensional embeddings.', 'this further supports findings in  #AUTHOR_TAG that larger networks matter for sequence models.', 'for the multi - task results, while autoencoder does not seem to help parsing, translation does.', '']",3
"[' #TAUTHOR_TAG.', 'it is my view that']","[' #TAUTHOR_TAG.', 'it is my view that']","['suggested in three papers in this volume  #TAUTHOR_TAG.', 'it is my view that']","['', 'standards can be built on.', 'for example, if one accepts the framework of the penn treebank, it is easy to move on to representations of "" deeper "" structure as suggested in three papers in this volume  #TAUTHOR_TAG.', 'it is my view that these advantages outweigh the disadvantages.', '']",0
"[' #TAUTHOR_TAG.', 'it is my view that']","[' #TAUTHOR_TAG.', 'it is my view that']","['suggested in three papers in this volume  #TAUTHOR_TAG.', 'it is my view that']","['', 'standards can be built on.', 'for example, if one accepts the framework of the penn treebank, it is easy to move on to representations of "" deeper "" structure as suggested in three papers in this volume  #TAUTHOR_TAG.', 'it is my view that these advantages outweigh the disadvantages.', '']",0
"[' #TAUTHOR_TAG.', 'it is my view that']","[' #TAUTHOR_TAG.', 'it is my view that']","['suggested in three papers in this volume  #TAUTHOR_TAG.', 'it is my view that']","['', 'standards can be built on.', 'for example, if one accepts the framework of the penn treebank, it is easy to move on to representations of "" deeper "" structure as suggested in three papers in this volume  #TAUTHOR_TAG.', 'it is my view that these advantages outweigh the disadvantages.', '']",0
"[' #TAUTHOR_TAG.', 'it is my view that']","[' #TAUTHOR_TAG.', 'it is my view that']","['suggested in three papers in this volume  #TAUTHOR_TAG.', 'it is my view that']","['', 'standards can be built on.', 'for example, if one accepts the framework of the penn treebank, it is easy to move on to representations of "" deeper "" structure as suggested in three papers in this volume  #TAUTHOR_TAG.', 'it is my view that these advantages outweigh the disadvantages.', '']",0
"['α and one for generic elements  #TAUTHOR_TAG.', 'an important but rather easy property holds : if the constants define']","['α and one for generic elements  #TAUTHOR_TAG.', 'an important but rather easy property holds : if the constants define']","['α → t ) → α and one for generic elements  #TAUTHOR_TAG.', 'an important but rather easy property holds : if the constants define an n - order q - sorted logic, any ( η - long ) normal λ - term of type t']","['.', 'our meta logic ( a. k. a. glue logic ) is system f with many base types t, e i ( instead of simply typed λ - calculus with t, and e ) our logic for semantic representations is many - sorted higher - order logic ( e i instead of a single sort e ).', ""for representing quantification, we actually prefer to use hilbert's o and τ - terms constructed with two constants o, τ : λα. ( α → t ) → α and one for generic elements  #TAUTHOR_TAG."", 'an important but rather easy property holds : if the constants define an n - order q - sorted logic, any ( η - long ) normal λ - term of type t does actually correspond to a formula of n - order q - sorted logic ( possibly n = ω ).', 'we preferred system f to modern type theories ( mtt ) used by luo [ 5 ] or to the categorical logic of asher [ 1 ] because of its formal simplicity and absence of variants - as the terms are issued from the lexicon by means of syntactic rules, f terms with a problematic complexity are avoided.', ""there are two properties of luo's approach [ 5 ] that would be welcome : a proper notion of subtyping, mathematically safe and linguistically relevant, and predefined inductive types with specific reduction rules."", '']",5
"['aes as a classification  #AUTHOR_TAG, regression  #TAUTHOR_TAG, or ranking classification problem  #AUTHOR_TAG, addressing aes by supervised learning.', 'features']","['aes as a classification  #AUTHOR_TAG, regression  #TAUTHOR_TAG, or ranking classification problem  #AUTHOR_TAG, addressing aes by supervised learning.', 'features']","['also on semantics, discourse and pragmatics.', 'traditional approaches treat aes as a classification  #AUTHOR_TAG, regression  #TAUTHOR_TAG, or ranking classification problem  #AUTHOR_TAG, addressing aes by supervised learning.', 'features']","['essay scoring ( aes ) is the task of building a computer - based grading system, with the aim of reducing the involvement of human raters as far as possible.', 'aes is challenging since it relies not only on grammars, but also on semantics, discourse and pragmatics.', 'traditional approaches treat aes as a classification  #AUTHOR_TAG, regression  #TAUTHOR_TAG, or ranking classification problem  #AUTHOR_TAG, addressing aes by supervised learning.', 'features are typically bag - of - words, spelling errors and lengths, such word length, sentence length and essay length, etc.', 'some grammatical features are considered to assess the quality of essays  #AUTHOR_TAG.', 'a drawback is feature engineering, which can be time - consuming, since features need to be carefully handcrafted and selected to fit the approriate model.', 'a further drawback of manual feature templates is that they are sparse, instantiated by discrete pattern - matching.', 'as a result, parsers and semantic analyzers are necessary as a preprocessing step to offer syntactic and semantic patterns for feature extraction.', 'given variable qualities of student essays, such analyzers can be highly unreliable.', 'neural network approaches have been shown to be capable of inducing dense syntactic and semantic features automatcially, giving competitive results to manually designed features for several tasks  #AUTHOR_TAG dos  #AUTHOR_TAG.', 'in this paper, we empirically investigate a neural network method to learn features automatically for aes, without the need of external pre - processing.', 'in particular, we build a hierarchical cnn model, with one lower layer representing sentence structures and one upper layer representing essay structure based on sentence representations.', 'we compare automatically - induced features by the model with state - of - art baseline handcrafted features.', 'empirical results show that neural features learned by cnn are very effective in essay scoring task, covering more high - level and abstract information compared to manual feature templates']",0
"['baselines.', 'feature templates follow  #TAUTHOR_TAG,']","['( blrr ) and support vector regression ( svr )  #AUTHOR_TAG are chosen as state - of - art baselines.', 'feature templates follow  #TAUTHOR_TAG,']","['- of - art baselines.', 'feature templates follow  #TAUTHOR_TAG,']","['linear ridge regression ( blrr ) and support vector regression ( svr )  #AUTHOR_TAG are chosen as state - of - art baselines.', 'feature templates follow  #TAUTHOR_TAG, extracted by ease 1, which are briefly listed in table 1. "" useful n - grams "" are determined using the fisher test to separate the good scoring essays and bad scoring essays.', 'good essays are essays with a score greater than or equal to the average score, and the remainder are considered as bad scoring essays.', 'the top 201 ngrams with the highest fisher values are chosen as the bag of features and these top 201 n - grams constitute useful n - grams.', 'correct pos tags are generated using grammatically correct texts, which is done by ease.', 'the pos tags that are not included in the correct pos tags are treated as bad pos tags, and these bad pos tags make up the "" bad pos n - grams "" features.', 'the features tend to be highly useful for the in - domain task since the discrete features of same prompt data share the similar statistics.', 'however, for different prompts, features statistics vary significantly.', 'this raises challenges for discrete feature patterns.', 'ml - ρ  #TAUTHOR_TAG was proposed to address this issue.', 'it is based on feature augmentation, incorporating explicit correlation into augmented feature spaces.', 'in particular, it expands baseline feature vector x to be φ s ( x ) = ( ρx, ( 1 − ρ 2 ) 1 / 2 x ) and φ t ( x ) = ( x, 0 p ) for source and target domain data 1 https : / / github. com / edx / ease in r 2p respectively, with ρ being the correlation between source and target domain data.', 'then blrr and maximum likelihood estimation are used to the optimize correlation.', 'all the baseline models require pos - tagging as a pre - processing step, extracting syntactic features based on pos - tags']",5
"['baselines.', 'feature templates follow  #TAUTHOR_TAG,']","['( blrr ) and support vector regression ( svr )  #AUTHOR_TAG are chosen as state - of - art baselines.', 'feature templates follow  #TAUTHOR_TAG,']","['- of - art baselines.', 'feature templates follow  #TAUTHOR_TAG,']","['linear ridge regression ( blrr ) and support vector regression ( svr )  #AUTHOR_TAG are chosen as state - of - art baselines.', 'feature templates follow  #TAUTHOR_TAG, extracted by ease 1, which are briefly listed in table 1. "" useful n - grams "" are determined using the fisher test to separate the good scoring essays and bad scoring essays.', 'good essays are essays with a score greater than or equal to the average score, and the remainder are considered as bad scoring essays.', 'the top 201 ngrams with the highest fisher values are chosen as the bag of features and these top 201 n - grams constitute useful n - grams.', 'correct pos tags are generated using grammatically correct texts, which is done by ease.', 'the pos tags that are not included in the correct pos tags are treated as bad pos tags, and these bad pos tags make up the "" bad pos n - grams "" features.', 'the features tend to be highly useful for the in - domain task since the discrete features of same prompt data share the similar statistics.', 'however, for different prompts, features statistics vary significantly.', 'this raises challenges for discrete feature patterns.', 'ml - ρ  #TAUTHOR_TAG was proposed to address this issue.', 'it is based on feature augmentation, incorporating explicit correlation into augmented feature spaces.', 'in particular, it expands baseline feature vector x to be φ s ( x ) = ( ρx, ( 1 − ρ 2 ) 1 / 2 x ) and φ t ( x ) = ( x, 0 p ) for source and target domain data 1 https : / / github. com / edx / ease in r 2p respectively, with ρ being the correlation between source and target domain data.', 'then blrr and maximum likelihood estimation are used to the optimize correlation.', 'all the baseline models require pos - tagging as a pre - processing step, extracting syntactic features based on pos - tags']",5
"['0 to 1.', 'the settings of data preparation follow  #TAUTHOR_TAG.', '']","['0 to 1.', 'the settings of data preparation follow  #TAUTHOR_TAG.', '']","['0 to 1.', 'the settings of data preparation follow  #TAUTHOR_TAG.', '']","['we use the automated student assessment prize ( asap ) 2 dataset as evaluation data for our task, which contains 8 prompts of different genres as listed in table 2.', 'the essay scores are scaled into the range from 0 to 1.', 'the settings of data preparation follow  #TAUTHOR_TAG.', 'we use quadratic weighted kappa ( qwk ) as the metric.', 'for domainadaptation ( cross - domain ) experiments, we follow  #TAUTHOR_TAG, picking four pairs of essay prompts, namely, 1→2, 3→4, 5→6 and 7→8, where 1→2 denotes prompt 1 as source domain and prompt hyper - parameters we use adagrad for optimization.', 'word embeddings are randomly initialized and the hyper - parameter settings are listed in table 3']",5
"['0 to 1.', 'the settings of data preparation follow  #TAUTHOR_TAG.', '']","['0 to 1.', 'the settings of data preparation follow  #TAUTHOR_TAG.', '']","['0 to 1.', 'the settings of data preparation follow  #TAUTHOR_TAG.', '']","['we use the automated student assessment prize ( asap ) 2 dataset as evaluation data for our task, which contains 8 prompts of different genres as listed in table 2.', 'the essay scores are scaled into the range from 0 to 1.', 'the settings of data preparation follow  #TAUTHOR_TAG.', 'we use quadratic weighted kappa ( qwk ) as the metric.', 'for domainadaptation ( cross - domain ) experiments, we follow  #TAUTHOR_TAG, picking four pairs of essay prompts, namely, 1→2, 3→4, 5→6 and 7→8, where 1→2 denotes prompt 1 as source domain and prompt hyper - parameters we use adagrad for optimization.', 'word embeddings are randomly initialized and the hyper - parameter settings are listed in table 3']",5
"['structure of social networks in literature  #TAUTHOR_TAG.', 'these current approaches']","['structure of social networks in literature  #TAUTHOR_TAG.', 'these current approaches']","['many computational analyses, from inferring prototypical character types  #AUTHOR_TAG to identifying the structure of social networks in literature  #TAUTHOR_TAG.', 'these current approaches']","['many literary characters appear in a novel?', 'despite the seeming simplicity of the question, precisely identifying which characters appear in a story remains an open question in literary and narrative analysis.', 'characters form the core of many computational analyses, from inferring prototypical character types  #AUTHOR_TAG to identifying the structure of social networks in literature  #TAUTHOR_TAG.', 'these current approaches have largely assumed that characters can be reliably identified in text using standard techniques such as named entity recognition ( ner ) and that the variations in how a character is named can be found through coreference resolution.', 'however, such treatment of character identity often overlooks minor characters that serve to enrich the social structure and serve as foils for the identities of major characters  #AUTHOR_TAG.', 'this work provides a comprehensive examination of literary character detection, with three key contributions.', 'first, we formalize the task with evaluation criteria and offer two datasets, including a complete, manually - annotated list of all characters in 58 literary works.', 'second, we propose a new technique for character detection based on inducing character prototypes, and in comparisons with three state - of - the - art methods, demonstrate superior performance, achieving significant improvements in f1 over the next - best method.', 'third, as practical applications, we analyze literary trends in character density over 20 decades and revisit the character - based literary hypothesis tested by  #TAUTHOR_TAG']",0
"['methods of  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG build social networks by recognizing characters from explicit markers (']","['methods of  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG build social networks by recognizing characters from explicit markers ( e. g., kinship ) and implicit markers ( e. g., physical collocation ).', ' #AUTHOR_TAG build character networks using tree kernels on parse']","['the need for automated methods.', 'two approaches mined social interaction net - works without relying on dialogue, unlike the methods of  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG build social networks by recognizing characters from explicit markers (']","['detection has primarily been performed in the context of mining literary social networks.', ' #AUTHOR_TAG extract character mentions from conversational segments, using the stanford corenlp ner system to discover character names  #AUTHOR_TAG.', 'to account for variability in character naming, alternate forms of a name are generated using the method of  #AUTHOR_TAG and merged together as a single character.', 'furthermore, the set of aliases for a character is expanded by creating coreference chains originating from these proper names and merging all coreferent expressions.', ' #AUTHOR_TAG also rely on the corenlp ner and coreference resolution systems for character detection ; however for literary analysis, they use gold character mentions that have been marked and resolved by a team of trained annotators, highlighting the difficulty of the task.', ' #AUTHOR_TAG propose an alternate approach for identifying speaker references in novels, using a probabilistic model to identify which character is speaking.', 'however, to account for the multiple aliases used to refer to a character, the authors first manually constructed a list of characters and their aliases, which is the task proposed in this work and underscores the need for automated methods.', 'two approaches mined social interaction net - works without relying on dialogue, unlike the methods of  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG build social networks by recognizing characters from explicit markers ( e. g., kinship ) and implicit markers ( e. g., physical collocation ).', ' #AUTHOR_TAG build character networks using tree kernels on parse trees to identify interacting agents.', 'in the two most - related works,  #AUTHOR_TAG and  #AUTHOR_TAG, character names are extracted and clustered under a set of constraints.', 'in the booknlp system developed by  #AUTHOR_TAG, ner - identified names are retained and merged based on animacy, determined through dependencies with "" sentient "" lemmas from a small dictionary ( including for example, say and smile ), and gender, assigned through pronomial resolution and a dictionary of genderspecific honorifics.', ' #AUTHOR_TAG similarly use ner to identify character name mentions.', 'these names are grouped through the application of a series of deterministic rules, beginning with recognizing gender constraints, where gender assignments are based off of gender - specific honorifics and names.', ""if a gender can't be assigned, then one is derived from the majority count of gender - specific pronouns ( e. g. he, herself ) appearing in the immediate context of the name mentions."", 'the extracted names are then clustered, while respecting the gender impositions, based on a sieve of name variant heuristics.', 'in the final step, any remaining ambiguous referents, i. e.,']",0
"['structure of social networks in literature  #TAUTHOR_TAG.', 'these current approaches']","['structure of social networks in literature  #TAUTHOR_TAG.', 'these current approaches']","['many computational analyses, from inferring prototypical character types  #AUTHOR_TAG to identifying the structure of social networks in literature  #TAUTHOR_TAG.', 'these current approaches']","['many literary characters appear in a novel?', 'despite the seeming simplicity of the question, precisely identifying which characters appear in a story remains an open question in literary and narrative analysis.', 'characters form the core of many computational analyses, from inferring prototypical character types  #AUTHOR_TAG to identifying the structure of social networks in literature  #TAUTHOR_TAG.', 'these current approaches have largely assumed that characters can be reliably identified in text using standard techniques such as named entity recognition ( ner ) and that the variations in how a character is named can be found through coreference resolution.', 'however, such treatment of character identity often overlooks minor characters that serve to enrich the social structure and serve as foils for the identities of major characters  #AUTHOR_TAG.', 'this work provides a comprehensive examination of literary character detection, with three key contributions.', 'first, we formalize the task with evaluation criteria and offer two datasets, including a complete, manually - annotated list of all characters in 58 literary works.', 'second, we propose a new technique for character detection based on inducing character prototypes, and in comparisons with three state - of - the - art methods, demonstrate superior performance, achieving significant improvements in f1 over the next - best method.', 'third, as practical applications, we analyze literary trends in character density over 20 decades and revisit the character - based literary hypothesis tested by  #TAUTHOR_TAG']",5
"['systems for social network extraction were selected : the method described in  #TAUTHOR_TAG, booknlp  #AUTHOR_TAG, and the method described in  #AUTHOR_TAG.', 'for']","['task of character recognition has largely been subsumed into the task of extracting the social network of novels.', 'therefore, three state - of - the - art systems for social network extraction were selected : the method described in  #TAUTHOR_TAG, booknlp  #AUTHOR_TAG, and the method described in  #AUTHOR_TAG.', 'for']","['- art systems for social network extraction were selected : the method described in  #TAUTHOR_TAG, booknlp  #AUTHOR_TAG, and the method described in  #AUTHOR_TAG.', 'for each method, we follow their procedures']","['task of character recognition has largely been subsumed into the task of extracting the social network of novels.', 'therefore, three state - of - the - art systems for social network extraction were selected : the method described in  #TAUTHOR_TAG, booknlp  #AUTHOR_TAG, and the method described in  #AUTHOR_TAG.', 'for each method, we follow their procedures for identifying the characters in the social network, which produces sets of one or more aliases associated with each identified character.', 'as a baseline, we use the output of stanford ner, where every name is considered a separate character ; this baseline represents the upper - bound in recall from any system using only ner to identify character names.', 'table 1 shows the results for the manually - annotated and sparknotes corpora.', 'the sherlock holmes corpus presents a notable challenge due to the presence of many minor characters, which are not detected by ner.', ""an error analysis for our approach revealed that while many characters were extracted, the coreference resolution did not link a characters'different referents together and hence, each name was reported as a separate character, which caused a drop in performance."", 'nevertheless, our system provided the highest performance for character recognition.', 'ferent set of challenges due to multiple characters sharing the same last name or the same first name.', 'here, coreference resolution frequently creates incorrect links between the similar names of different characters, creating a drop in precision for most systems.', 'our precision value particularly benefited from the heuristics for distinguishing characters by gender and stringent name - merging constraints.', 'booknlp and the approach of  #AUTHOR_TAG performed quite similarly in identifying characters, which is expected given the overlap in rules applied by both systems']",5
"['2 : literary theories  #TAUTHOR_TAG analyze 60 novels to computationally test literary theories for novels in urban and rural settings  #AUTHOR_TAG.', ' #AUTHOR_TAG challenged this']","['2 : literary theories  #TAUTHOR_TAG analyze 60 novels to computationally test literary theories for novels in urban and rural settings  #AUTHOR_TAG.', ' #AUTHOR_TAG challenged this analysis, showing their improved method']","[', on the sherlock holmes set. ) experiment 2 : literary theories  #TAUTHOR_TAG analyze 60 novels to computationally test literary theories for novels in urban and rural settings  #AUTHOR_TAG.', ' #AUTHOR_TAG challenged this analysis, showing their improved method']","['', 'finally, returning to the initially - posed question of how many characters are present, we find that despite the detection error in our method, the overall predicted number of characters is quite close to the actual : for sherlock holmes stories, the number of characters was estimated within 2. 4 on average, for pride and prejudice our method predicted 72 compared with 73 actual characters, and for the moonstone our method predicted 87 compared with 78.', 'thus, we argue that our procedure can provide a reasonable estimate for the total number of characters.', '( for comparison, booknlp, the next best system, extracted 69 and 72 characters for pride and prejudice and the moonstone, respectively, and within 1. 2, on average, on the sherlock holmes set. ) experiment 2 : literary theories  #TAUTHOR_TAG analyze 60 novels to computationally test literary theories for novels in urban and rural settings  #AUTHOR_TAG.', ' #AUTHOR_TAG challenged this analysis, showing their improved method for social network extraction did not support the same conclusions.', 'while our work focuses only on character detection, we are nevertheless able to test the related hypothesis of whether the number of characters in novels with urban settings is more than those in rural.', 'character detection was run on the same novels from  #TAUTHOR_TAG and we found no statistically - significant difference in the mean number']",5
"['2 : literary theories  #TAUTHOR_TAG analyze 60 novels to computationally test literary theories for novels in urban and rural settings  #AUTHOR_TAG.', ' #AUTHOR_TAG challenged this']","['2 : literary theories  #TAUTHOR_TAG analyze 60 novels to computationally test literary theories for novels in urban and rural settings  #AUTHOR_TAG.', ' #AUTHOR_TAG challenged this analysis, showing their improved method']","[', on the sherlock holmes set. ) experiment 2 : literary theories  #TAUTHOR_TAG analyze 60 novels to computationally test literary theories for novels in urban and rural settings  #AUTHOR_TAG.', ' #AUTHOR_TAG challenged this analysis, showing their improved method']","['', 'finally, returning to the initially - posed question of how many characters are present, we find that despite the detection error in our method, the overall predicted number of characters is quite close to the actual : for sherlock holmes stories, the number of characters was estimated within 2. 4 on average, for pride and prejudice our method predicted 72 compared with 73 actual characters, and for the moonstone our method predicted 87 compared with 78.', 'thus, we argue that our procedure can provide a reasonable estimate for the total number of characters.', '( for comparison, booknlp, the next best system, extracted 69 and 72 characters for pride and prejudice and the moonstone, respectively, and within 1. 2, on average, on the sherlock holmes set. ) experiment 2 : literary theories  #TAUTHOR_TAG analyze 60 novels to computationally test literary theories for novels in urban and rural settings  #AUTHOR_TAG.', ' #AUTHOR_TAG challenged this analysis, showing their improved method for social network extraction did not support the same conclusions.', 'while our work focuses only on character detection, we are nevertheless able to test the related hypothesis of whether the number of characters in novels with urban settings is more than those in rural.', 'character detection was run on the same novels from  #TAUTHOR_TAG and we found no statistically - significant difference in the mean number']",5
"['##casts  #TAUTHOR_TAG,']","['sample sportscasts  #TAUTHOR_TAG,']","['sample sportscasts  #TAUTHOR_TAG,']","['ultimate goal of "" grounded "" language learning is to develop computational systems that can acquire language more like a human child.', 'given only supervision in the form of sentences paired with relevant but ambiguous perceptual contexts, a system should learn to interpret and / or generate language describing situations and events in the world.', 'for example, systems have learned to commentate simulated robot soccer games by learning from sample sportscasts  #TAUTHOR_TAG, or understand navigation instructions by learning from action traces produced when following the directions  #AUTHOR_TAG.', 'borschinger et al. ( 2011 ) recently introduced an approach to grounded language learning using unsupervised induction of probabilistic context free grammars ( pcfgs ) to learn from ambiguous contextual supervision.', 'their approach first constructs a large set of production rules from sentences paired with descriptions of their ambiguous context, and then trains the parameters of this grammar using em.', 'parsing a novel sentence with this grammar gives a parse tree which contains the formal meaning representation ( mr ) for this sentence.', 'this approach works quite well on the sportscasting task originally introduced by  #AUTHOR_TAG.', 'in this task, each sentence in a natural - language commentary describing activity in a simulated robot soccer game is paired with the small set of actions observed within the past 5 seconds, one of which is usually described by the sentence.', '']",0
[' #TAUTHOR_TAG assume training data consisting of'],[' #TAUTHOR_TAG assume training data consisting of'],"['from perceptual context.', 'a number of approaches  #TAUTHOR_TAG assume training data consisting of a set of sentences each associated with a small set of mrs, one of which is usually']","['work on learning semantic parsers that map natural - language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of nl / mr pairs  #AUTHOR_TAG.', 'several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context.', 'a number of approaches  #TAUTHOR_TAG assume training data consisting of a set of sentences each associated with a small set of mrs, one of which is usually the correct meaning of the sentence.', 'many of these approaches  #AUTHOR_TAG disambiguate the data and match nl sentences to their correct mr by iteratively retraining a supervised semantic parser.', '']",0
[' #TAUTHOR_TAG assume training data consisting of'],[' #TAUTHOR_TAG assume training data consisting of'],"['from perceptual context.', 'a number of approaches  #TAUTHOR_TAG assume training data consisting of a set of sentences each associated with a small set of mrs, one of which is usually']","['work on learning semantic parsers that map natural - language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of nl / mr pairs  #AUTHOR_TAG.', 'several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context.', 'a number of approaches  #TAUTHOR_TAG assume training data consisting of a set of sentences each associated with a small set of mrs, one of which is usually the correct meaning of the sentence.', 'many of these approaches  #AUTHOR_TAG disambiguate the data and match nl sentences to their correct mr by iteratively retraining a supervised semantic parser.', '']",0
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['approach extends that of  #TAUTHOR_TAG, which in turn was inspired by a series of previous techniques  #AUTHOR_TAG following the idea of constructing correspondences between nl and mr in a single probabilistic generative framework.', 'particularly, their approach automatically constructs a pcfg that generates nl sentences from mrs, which indicates how atomic mr constituents are probabilistically related to nl words.', '']",6
"['scheme of  #TAUTHOR_TAG, but instead of generating nl words from']","['scheme of  #TAUTHOR_TAG, but instead of generating nl words from']","['follow the scheme of  #TAUTHOR_TAG, but instead of generating nl words from each atomic mr, words are generated from each lexeme mr, figure 6 : summary of']","['next step composes pcfg rules from the lhgs and is summarized in figure 6.', 'we basically follow the scheme of  #TAUTHOR_TAG, but instead of generating nl words from each atomic mr, words are generated from each lexeme mr, figure 6 : summary of the rule generation process.', 'nls refer to the set of nl words in the corpus.', 'lexeme rules come from the schemata of  #TAUTHOR_TAG, and allow every lexeme mr to generate one or more nl words.', 'note that pseudo - lexeme nodes do not produce nl words.', '']",6
['improves on  #TAUTHOR_TAG'],"[""improves on  #TAUTHOR_TAG's method in the following ways :"", '• the building blocks']",['improves on  #TAUTHOR_TAG'],"[""approach improves on  #TAUTHOR_TAG's method in the following ways :"", '• the building blocks for associating nl and mr are semantic lexemes instead of atomic mr constituents.', ""this prevents the number of constructed pcfg rules from becoming intractably large as happens with borschinger et al.'s approach."", 'as previously mentioned, lexeme mrs are intuitively analogous to syntactic categories in that complex lexeme mrs represent complicated semantic concepts whereas higher - level syntactic categories such as s, vp, or np represent complex syntactic structures.', '']",6
"['learning a semantic parser given only highly ambiguous supervision.', ""our model enhances  #TAUTHOR_TAG's approach to reducing the problem of grounded learning of semantic parsers to pcfg induction."", 'we use a']","['learning a semantic parser given only highly ambiguous supervision.', ""our model enhances  #TAUTHOR_TAG's approach to reducing the problem of grounded learning of semantic parsers to pcfg induction."", 'we use a']","['learning a semantic parser given only highly ambiguous supervision.', ""our model enhances  #TAUTHOR_TAG's approach to reducing the problem of grounded learning of semantic parsers to pcfg induction."", 'we use a learned semantic lexicon']","['have presented a novel method for learning a semantic parser given only highly ambiguous supervision.', ""our model enhances  #TAUTHOR_TAG's approach to reducing the problem of grounded learning of semantic parsers to pcfg induction."", 'we use a learned semantic lexicon to aid the construction of a smaller and more focused set of pcfg productions.', 'this allows the approach to scale to complex mr languages that define a large ( potentially infinite ) space of representations for capturing the meaning of sentences.', 'by contrast, the previous pcfg approach requires a finite mr language and its grammar grows intractably large for even moderately complex mr languages.', 'in addition, our algorithm for composing mrs from the final parse tree provides the flexibility to produce a wide range of novel mrs that were not seen during training.', 'evaluations on a previous corpus of navigational instructions for virtual environments has demonstrated the effectiveness of our method compared to a recent competing system']",6
"['2 like  #TAUTHOR_TAG,']","['2 like  #TAUTHOR_TAG,']","['. 2 like  #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],3
['which was also used by  #TAUTHOR_TAG'],"['marks all of the nodes in its mr.', 'after traversing all of its children, 5 we used the implementation available at http : / / web.', 'science. mq. edu. au / [UNK] / software. htm which was also used by  #TAUTHOR_TAG']",['which was also used by  #TAUTHOR_TAG'],"['', 'when a leaf - node is reached, it marks all of the nodes in its mr.', 'after traversing all of its children, 5 we used the implementation available at http : / / web.', 'science. mq. edu. au / [UNK] / software. htm which was also used by  #TAUTHOR_TAG']",3
"['2 like  #TAUTHOR_TAG,']","['2 like  #TAUTHOR_TAG,']","['. 2 like  #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],5
"['scheme of  #TAUTHOR_TAG, but instead of generating nl words from']","['scheme of  #TAUTHOR_TAG, but instead of generating nl words from']","['follow the scheme of  #TAUTHOR_TAG, but instead of generating nl words from each atomic mr, words are generated from each lexeme mr, figure 6 : summary of']","['next step composes pcfg rules from the lhgs and is summarized in figure 6.', 'we basically follow the scheme of  #TAUTHOR_TAG, but instead of generating nl words from each atomic mr, words are generated from each lexeme mr, figure 6 : summary of the rule generation process.', 'nls refer to the set of nl words in the corpus.', 'lexeme rules come from the schemata of  #TAUTHOR_TAG, and allow every lexeme mr to generate one or more nl words.', 'note that pseudo - lexeme nodes do not produce nl words.', '']",5
['which was also used by  #TAUTHOR_TAG'],"['marks all of the nodes in its mr.', 'after traversing all of its children, 5 we used the implementation available at http : / / web.', 'science. mq. edu. au / [UNK] / software. htm which was also used by  #TAUTHOR_TAG']",['which was also used by  #TAUTHOR_TAG'],"['', 'when a leaf - node is reached, it marks all of the nodes in its mr.', 'after traversing all of its children, 5 we used the implementation available at http : / / web.', 'science. mq. edu. au / [UNK] / software. htm which was also used by  #TAUTHOR_TAG']",5
"['scheme of  #TAUTHOR_TAG, but instead of generating nl words from']","['scheme of  #TAUTHOR_TAG, but instead of generating nl words from']","['follow the scheme of  #TAUTHOR_TAG, but instead of generating nl words from each atomic mr, words are generated from each lexeme mr, figure 6 : summary of']","['next step composes pcfg rules from the lhgs and is summarized in figure 6.', 'we basically follow the scheme of  #TAUTHOR_TAG, but instead of generating nl words from each atomic mr, words are generated from each lexeme mr, figure 6 : summary of the rule generation process.', 'nls refer to the set of nl words in the corpus.', 'lexeme rules come from the schemata of  #TAUTHOR_TAG, and allow every lexeme mr to generate one or more nl words.', 'note that pseudo - lexeme nodes do not produce nl words.', '']",4
"['3 shows the effect of the different feature sets on vuamc used', 'by  #TAUTHOR_TAG. we use the']","['3 shows the effect of the different feature sets on vuamc used', 'by  #TAUTHOR_TAG. we use the same 12 - fold data split as  #TAUTHOR_TAG, and also in this']","[', table 3 shows the effect of the different feature sets on vuamc used', 'by  #TAUTHOR_TAG. we use the']","['', 'domain : "" animals "" ) in "" you can take a horse to the water, but you can\'t', 'make him drink "". finally, table 3 shows the effect of the different feature sets on vuamc used', 'by  #TAUTHOR_TAG. we use the same 12 - fold data split as  #TAUTHOR_TAG, and also in this case we perform a grid - search to optimize the meta - parameter c of the logistic', 'regression classifier. the best value of c identified for each genre and feature set is shown in the column labeled c. on this data, n features alone are significantly outperformed by b ( p < 0. 01 )', '. on the other hand, for the genres "" academic "" and "" fiction "", combining n and b features improves classification performance over b, and the difference is always statistically significant. besides, the addition of n always leads to more', 'balanced models, by compensating for the relatively lower precision of b. due to the lack of a separate test set, as in the', ""original setup by  #TAUTHOR_TAG, and to the high dimensionality of b's lexicalized features, we cannot rule out over - fitting as an explanation for the relatively good performance of b on this"", 'benchmark. it should also be noted that the results reported in  #AUTHOR_TAG are not the same, due to the mentioned differences in the implementation of the features and possibly other differences', 'in the experimental setup ( e. g., data filtering, pre - processing and meta - parameter optimization ). in particular, our implementation of', 'the b features performs better than reported by  #TAUTHOR_TAG on all four genres, namely : 0. 52 vs. 0.', '']",0
[' #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG'],[' #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG'],"[' #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG. meanwhile, our implicit sr']","['', '. based on this model, we study the proposed implicit semanticaware word representations for orl. in addition, we', 'compare this method with two other representative methods of srl integration as well : one uses discrete srl outputs as', 'features directly for orl and the other one exploits a multi - tasklearning ( mtl )', 'framework to benefit orl by srl information. experiments are conducted on the mpqa 2. 0 dataset, which is a standard benchmark', 'for opinion mining. results show that srl is highly effective for or', '##l, which is consistent with previous findings  #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG. meanwhile, our implicit srl - sawr method can achieve the best orl performance, 2. 23 % higher f - scores', 'than the second best method. all the codes and datasets are released publicly available for research purpose', 'under apache licence 2. 0 at https : / / github. com / zhangmeishan / srl4orl']",0
[' #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG'],[' #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG'],"[' #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG. meanwhile, our implicit sr']","['', '. based on this model, we study the proposed implicit semanticaware word representations for orl. in addition, we', 'compare this method with two other representative methods of srl integration as well : one uses discrete srl outputs as', 'features directly for orl and the other one exploits a multi - tasklearning ( mtl )', 'framework to benefit orl by srl information. experiments are conducted on the mpqa 2. 0 dataset, which is a standard benchmark', 'for opinion mining. results show that srl is highly effective for or', '##l, which is consistent with previous findings  #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG. meanwhile, our implicit srl - sawr method can achieve the best orl performance, 2. 23 % higher f - scores', 'than the second best method. all the codes and datasets are released publicly available for research purpose', 'under apache licence 2. 0 at https : / / github. com / zhangmeishan / srl4orl']",0
"[' #TAUTHOR_TAG, treating']","[' #TAUTHOR_TAG, treating']","['##l  #TAUTHOR_TAG, treating opinion expressions as the major predicates.', 'these systems can achieve good performances, indicating that srl information']","['##l aims to find the core semantic arguments for a given predicate, which is highly correlative with the orl task.', 'the semantic roles agent ( arg0 ) and patient ( arg1 ) are often corresponding to the opinion holder and target, respectively.', 'several works even directly transfer semantic roles into opinion roles for orl  #TAUTHOR_TAG, treating opinion expressions as the major predicates.', 'these systems can achieve good performances, indicating that srl information can be greatly useful for orl.', '']",0
[' #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG'],[' #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG'],"[' #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG. meanwhile, our implicit sr']","['', '. based on this model, we study the proposed implicit semanticaware word representations for orl. in addition, we', 'compare this method with two other representative methods of srl integration as well : one uses discrete srl outputs as', 'features directly for orl and the other one exploits a multi - tasklearning ( mtl )', 'framework to benefit orl by srl information. experiments are conducted on the mpqa 2. 0 dataset, which is a standard benchmark', 'for opinion mining. results show that srl is highly effective for or', '##l, which is consistent with previous findings  #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG. meanwhile, our implicit srl - sawr method can achieve the best orl performance, 2. 23 % higher f - scores', 'than the second best method. all the codes and datasets are released publicly available for research purpose', 'under apache licence 2. 0 at https : / / github. com / zhangmeishan / srl4orl']",3
"[', which is consistent with previous studies  #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG.', 'the implicit sr']","['very helpful for orl, which is consistent with previous studies  #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG.', 'the implicit srl - sawr method is highly effective']","[', which is consistent with previous studies  #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG.', 'the implicit srl - sawr method is highly effective']","['', 'the tendencies are similar by exploiting the binary and proportional matching methods.', 'the results show that srl information is very helpful for orl, which is consistent with previous studies  #TAUTHOR_TAG ; marasovic and  #AUTHOR_TAG.', 'the implicit srl - sawr method is highly effective to integrate srl information into the orl model']",3
"[' #TAUTHOR_TAG, treating']","[' #TAUTHOR_TAG, treating']","['##l  #TAUTHOR_TAG, treating opinion expressions as the major predicates.', 'these systems can achieve good performances, indicating that srl information']","['##l aims to find the core semantic arguments for a given predicate, which is highly correlative with the orl task.', 'the semantic roles agent ( arg0 ) and patient ( arg1 ) are often corresponding to the opinion holder and target, respectively.', 'several works even directly transfer semantic roles into opinion roles for orl  #TAUTHOR_TAG, treating opinion expressions as the major predicates.', 'these systems can achieve good performances, indicating that srl information can be greatly useful for orl.', '']",1
"['directly  #TAUTHOR_TAG.', '']","['orl directly  #TAUTHOR_TAG.', '']","['directly  #TAUTHOR_TAG.', '']","['', 'considering the much larger scale of annotated srl corpora, srl can benefit orl potentially.', 'according to the above findings, we design a simple system by mapping srl outputs into orl directly  #TAUTHOR_TAG.', '']",5
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[', whereas good authorities correspond to the high - quality resources themselves ; thus, distinguishing between two differing but interdependent types of webpages is quite appropriate. our previous study  #TAUTHOR_TAG applied hits to non - web documents. we found that its performance was comparable to or better than that of algorithms that do not involve structural', 're - ranking ; however, hits was not as effective as pagerank  #TAUTHOR_TAG. do these results imply that pagerank is better than hits for structural re - ranking of non', '- web documents? not necessarily, because there may exist graph - construction methods that are more suitable for hits. note that the only entities considered in our previous study were documents. if we could introduce entities distinct from documents but enjoying a mutually reinforcing relationship with them, then we might better satisfy the spirit of the hubs - versus - authorities distinction, and thus derive stronger results utilizing hits. a crucial insight of the present paper is that document clusters appear extremely well - suited to play this complementary role. the intuition is', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[', whereas good authorities correspond to the high - quality resources themselves ; thus, distinguishing between two differing but interdependent types of webpages is quite appropriate. our previous study  #TAUTHOR_TAG applied hits to non - web documents. we found that its performance was comparable to or better than that of algorithms that do not involve structural', 're - ranking ; however, hits was not as effective as pagerank  #TAUTHOR_TAG. do these results imply that pagerank is better than hits for structural re - ranking of non', '- web documents? not necessarily, because there may exist graph - construction methods that are more suitable for hits. note that the only entities considered in our previous study were documents. if we could introduce entities distinct from documents but enjoying a mutually reinforcing relationship with them, then we might better satisfy the spirit of the hubs - versus - authorities distinction, and thus derive stronger results utilizing hits. a crucial insight of the present paper is that document clusters appear extremely well - suited to play this complementary role. the intuition is', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[', whereas good authorities correspond to the high - quality resources themselves ; thus, distinguishing between two differing but interdependent types of webpages is quite appropriate. our previous study  #TAUTHOR_TAG applied hits to non - web documents. we found that its performance was comparable to or better than that of algorithms that do not involve structural', 're - ranking ; however, hits was not as effective as pagerank  #TAUTHOR_TAG. do these results imply that pagerank is better than hits for structural re - ranking of non', '- web documents? not necessarily, because there may exist graph - construction methods that are more suitable for hits. note that the only entities considered in our previous study were documents. if we could introduce entities distinct from documents but enjoying a mutually reinforcing relationship with them, then we might better satisfy the spirit of the hubs - versus - authorities distinction, and thus derive stronger results utilizing hits. a crucial insight of the present paper is that document clusters appear extremely well - suited to play this complementary role. the intuition is', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[', whereas good authorities correspond to the high - quality resources themselves ; thus, distinguishing between two differing but interdependent types of webpages is quite appropriate. our previous study  #TAUTHOR_TAG applied hits to non - web documents. we found that its performance was comparable to or better than that of algorithms that do not involve structural', 're - ranking ; however, hits was not as effective as pagerank  #TAUTHOR_TAG. do these results imply that pagerank is better than hits for structural re - ranking of non', '- web documents? not necessarily, because there may exist graph - construction methods that are more suitable for hits. note that the only entities considered in our previous study were documents. if we could introduce entities distinct from documents but enjoying a mutually reinforcing relationship with them, then we might better satisfy the spirit of the hubs - versus - authorities distinction, and thus derive stronger results utilizing hits. a crucial insight of the present paper is that document clusters appear extremely well - suited to play this complementary role. the intuition is', '']",0
"['in earlier work  #TAUTHOR_TAG, pagerank performed quite well as a tool']","['in earlier work  #TAUTHOR_TAG, pagerank performed quite well as a tool']","['in earlier work  #TAUTHOR_TAG, pagerank performed quite well as a tool']","['will compare the results of using the hits algorithm against those derived using pagerank instead.', 'this is a natural comparison because pagerank is the most well - known centrality - induction algorithm utilized for ranking documents, and because in earlier work  #TAUTHOR_TAG, pagerank performed quite well as a tool for structural re - ranking of non - web documents, at least when applied to document - to - document graphs.', 'one can think of pagerank as a version of hits in which the hub / authority distinction has been collapsed.', 'thus, writing "" pr "" for both auth and hub, we conceptually have the ( single ) equation', ""however, in practice, we incorporate brin and page's smoothing scheme [ 3 ] together with a correction for nodes with no positive - weight edges emanating from them [ 27, 21 ] :"", 'where out ( u )', ', and λ ∈ ( 0, 1 ) is the damping factor']",0
"['', 'earlier work  #TAUTHOR_TAG also considered scoring a node']","['graphs this is not the case.', 'earlier work  #TAUTHOR_TAG also considered scoring a node']","['hub graphs this is not the case.', 'earlier work  #TAUTHOR_TAG also considered scoring a node v by its influx, p u∈v w t ( u → v ).', 'this can be viewed as either a non - recursive version of equation 3, or as an un - normalized analog of']","['', 'earlier work  #TAUTHOR_TAG also considered scoring a node v by its influx, p u∈v w t ( u → v ).', 'this can be viewed as either a non - recursive version of equation 3, or as an un - normalized analog of equation 5']",0
"['7, 24, 9,  #TAUTHOR_TAG 39 ]']","['[ 7, 24, 9,  #TAUTHOR_TAG 39 ], text']","['- ) ranking [ 7, 24, 9,  #TAUTHOR_TAG 39 ], text summarization']",[' #TAUTHOR_TAG'],0
"['- based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for']","['our previous experiments with noncluster - based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for']","['- based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for the "" out - degree "" parameter δ ( called the "" ancestry "" parameter α in  #TAUTHOR_TAG ; and, of']","['aspects of the evaluation framework described below are adopted from our previous experiments with noncluster - based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for the "" out - degree "" parameter δ ( called the "" ancestry "" parameter α in  #TAUTHOR_TAG ; and, of course, the incorporation of clusters']",0
['- based graphs  #TAUTHOR_TAG'],['on document - based graphs  #TAUTHOR_TAG'],['- based graphs  #TAUTHOR_TAG'],"['flow based on language models ( lms ).', 'to estimate the degree to which one item, if considered relevant, can vouch for the relevance of another, we follow our previous work on document - based graphs  #TAUTHOR_TAG and utilize p [ [UNK] ] d ( · ), the unigram dirichlet - smoothed language model induced from a given document d ( [UNK] is the smoothing parameter ) [ 38 ].', 'to adapt this estimation scheme to settings involving clusters, we derive the language model p c ( · ) for a cluster c by treating c as the ( large ) document formed by concatenating 7 its constituent ( or most strongly associated ) documents [ 17, 25, 19 ].', 'the relevance - flow measure we use is essentially a directed similarity in language - model space :', '']",0
['- based graphs  #TAUTHOR_TAG'],['on document - based graphs  #TAUTHOR_TAG'],['- based graphs  #TAUTHOR_TAG'],"['flow based on language models ( lms ).', 'to estimate the degree to which one item, if considered relevant, can vouch for the relevance of another, we follow our previous work on document - based graphs  #TAUTHOR_TAG and utilize p [ [UNK] ] d ( · ), the unigram dirichlet - smoothed language model induced from a given document d ( [UNK] is the smoothing parameter ) [ 38 ].', 'to adapt this estimation scheme to settings involving clusters, we derive the language model p c ( · ) for a cluster c by treating c as the ( large ) document formed by concatenating 7 its constituent ( or most strongly associated ) documents [ 17, 25, 19 ].', 'the relevance - flow measure we use is essentially a directed similarity in language - model space :', '']",0
['- based graphs  #TAUTHOR_TAG'],['on document - based graphs  #TAUTHOR_TAG'],['- based graphs  #TAUTHOR_TAG'],"['flow based on language models ( lms ).', 'to estimate the degree to which one item, if considered relevant, can vouch for the relevance of another, we follow our previous work on document - based graphs  #TAUTHOR_TAG and utilize p [ [UNK] ] d ( · ), the unigram dirichlet - smoothed language model induced from a given document d ( [UNK] is the smoothing parameter ) [ 38 ].', 'to adapt this estimation scheme to settings involving clusters, we derive the language model p c ( · ) for a cluster c by treating c as the ( large ) document formed by concatenating 7 its constituent ( or most strongly associated ) documents [ 17, 25, 19 ].', 'the relevance - flow measure we use is essentially a directed similarity in language - model space :', '']",0
['- based graphs  #TAUTHOR_TAG'],['on document - based graphs  #TAUTHOR_TAG'],['- based graphs  #TAUTHOR_TAG'],"['flow based on language models ( lms ).', 'to estimate the degree to which one item, if considered relevant, can vouch for the relevance of another, we follow our previous work on document - based graphs  #TAUTHOR_TAG and utilize p [ [UNK] ] d ( · ), the unigram dirichlet - smoothed language model induced from a given document d ( [UNK] is the smoothing parameter ) [ 38 ].', 'to adapt this estimation scheme to settings involving clusters, we derive the language model p c ( · ) for a cluster c by treating c as the ( large ) document formed by concatenating 7 its constituent ( or most strongly associated ) documents [ 17, 25, 19 ].', 'the relevance - flow measure we use is essentially a directed similarity in language - model space :', '']",0
['- based graphs  #TAUTHOR_TAG'],['on document - based graphs  #TAUTHOR_TAG'],['- based graphs  #TAUTHOR_TAG'],"['flow based on language models ( lms ).', 'to estimate the degree to which one item, if considered relevant, can vouch for the relevance of another, we follow our previous work on document - based graphs  #TAUTHOR_TAG and utilize p [ [UNK] ] d ( · ), the unigram dirichlet - smoothed language model induced from a given document d ( [UNK] is the smoothing parameter ) [ 38 ].', 'to adapt this estimation scheme to settings involving clusters, we derive the language model p c ( · ) for a cluster c by treating c as the ( large ) document formed by concatenating 7 its constituent ( or most strongly associated ) documents [ 17, 25, 19 ].', 'the relevance - flow measure we use is essentially a directed similarity in language - model space :', '']",0
['strongly correlated  #TAUTHOR_TAG.'],"['strongly correlated  #TAUTHOR_TAG. indeed, employing this']","['strongly correlated  #TAUTHOR_TAG. indeed, employing this']","['', 'thus, while we have already demonstrated in previous sections of this paper that information about document - cluster similarity relationships is very valuable, the results just', 'mentioned suggest that such information is more useful in "" raw "" form. re - anchoring to the query. in previous work, we showed that pagerank centrality scores induced over documentbased graphs can be used as a multiplicative weight on document query - likelihood terms, the intent being to cope with cases in which centrality in dinit and relevance are not strongly correlated  #TAUTHOR_TAG. indeed, employing this technique on the ap, tre', '']",0
['strongly correlated  #TAUTHOR_TAG.'],"['strongly correlated  #TAUTHOR_TAG. indeed, employing this']","['strongly correlated  #TAUTHOR_TAG. indeed, employing this']","['', 'thus, while we have already demonstrated in previous sections of this paper that information about document - cluster similarity relationships is very valuable, the results just', 'mentioned suggest that such information is more useful in "" raw "" form. re - anchoring to the query. in previous work, we showed that pagerank centrality scores induced over documentbased graphs can be used as a multiplicative weight on document query - likelihood terms, the intent being to cope with cases in which centrality in dinit and relevance are not strongly correlated  #TAUTHOR_TAG. indeed, employing this technique on the ap, tre', '']",0
['strongly correlated  #TAUTHOR_TAG.'],"['strongly correlated  #TAUTHOR_TAG. indeed, employing this']","['strongly correlated  #TAUTHOR_TAG. indeed, employing this']","['', 'thus, while we have already demonstrated in previous sections of this paper that information about document - cluster similarity relationships is very valuable, the results just', 'mentioned suggest that such information is more useful in "" raw "" form. re - anchoring to the query. in previous work, we showed that pagerank centrality scores induced over documentbased graphs can be used as a multiplicative weight on document query - likelihood terms, the intent being to cope with cases in which centrality in dinit and relevance are not strongly correlated  #TAUTHOR_TAG. indeed, employing this technique on the ap, tre', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[', whereas good authorities correspond to the high - quality resources themselves ; thus, distinguishing between two differing but interdependent types of webpages is quite appropriate. our previous study  #TAUTHOR_TAG applied hits to non - web documents. we found that its performance was comparable to or better than that of algorithms that do not involve structural', 're - ranking ; however, hits was not as effective as pagerank  #TAUTHOR_TAG. do these results imply that pagerank is better than hits for structural re - ranking of non', '- web documents? not necessarily, because there may exist graph - construction methods that are more suitable for hits. note that the only entities considered in our previous study were documents. if we could introduce entities distinct from documents but enjoying a mutually reinforcing relationship with them, then we might better satisfy the spirit of the hubs - versus - authorities distinction, and thus derive stronger results utilizing hits. a crucial insight of the present paper is that document clusters appear extremely well - suited to play this complementary role. the intuition is', '']",1
"[""algorithms'parameters  #TAUTHOR_TAG."", 'first, we hope to show that structural']","[""algorithms'parameters  #TAUTHOR_TAG."", 'first, we hope to show that structural re - ranking']","[""algorithms'parameters  #TAUTHOR_TAG."", 'first, we hope to show that structural re - ranking can provide better results than']","['', ""there are two motivations underlying our approach to choosing values for our algorithms'parameters  #TAUTHOR_TAG."", 'first, we hope to show that structural re - ranking can provide better results than the optimized baselines even when initialized with a sub - optimal ( yet reasonable ) ranking.', '']",1
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],1
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[', whereas good authorities correspond to the high - quality resources themselves ; thus, distinguishing between two differing but interdependent types of webpages is quite appropriate. our previous study  #TAUTHOR_TAG applied hits to non - web documents. we found that its performance was comparable to or better than that of algorithms that do not involve structural', 're - ranking ; however, hits was not as effective as pagerank  #TAUTHOR_TAG. do these results imply that pagerank is better than hits for structural re - ranking of non', '- web documents? not necessarily, because there may exist graph - construction methods that are more suitable for hits. note that the only entities considered in our previous study were documents. if we could introduce entities distinct from documents but enjoying a mutually reinforcing relationship with them, then we might better satisfy the spirit of the hubs - versus - authorities distinction, and thus derive stronger results utilizing hits. a crucial insight of the present paper is that document clusters appear extremely well - suited to play this complementary role. the intuition is', '']",6
"['in earlier work  #TAUTHOR_TAG, pagerank performed quite well as a tool']","['in earlier work  #TAUTHOR_TAG, pagerank performed quite well as a tool']","['in earlier work  #TAUTHOR_TAG, pagerank performed quite well as a tool']","['will compare the results of using the hits algorithm against those derived using pagerank instead.', 'this is a natural comparison because pagerank is the most well - known centrality - induction algorithm utilized for ranking documents, and because in earlier work  #TAUTHOR_TAG, pagerank performed quite well as a tool for structural re - ranking of non - web documents, at least when applied to document - to - document graphs.', 'one can think of pagerank as a version of hits in which the hub / authority distinction has been collapsed.', 'thus, writing "" pr "" for both auth and hub, we conceptually have the ( single ) equation', ""however, in practice, we incorporate brin and page's smoothing scheme [ 3 ] together with a correction for nodes with no positive - weight edges emanating from them [ 27, 21 ] :"", 'where out ( u )', ', and λ ∈ ( 0, 1 ) is the damping factor']",5
"['- based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for']","['our previous experiments with noncluster - based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for']","['- based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for the "" out - degree "" parameter δ ( called the "" ancestry "" parameter α in  #TAUTHOR_TAG ; and, of']","['aspects of the evaluation framework described below are adopted from our previous experiments with noncluster - based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for the "" out - degree "" parameter δ ( called the "" ancestry "" parameter α in  #TAUTHOR_TAG ; and, of course, the incorporation of clusters']",5
"['- based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for']","['our previous experiments with noncluster - based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for']","['- based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for the "" out - degree "" parameter δ ( called the "" ancestry "" parameter α in  #TAUTHOR_TAG ; and, of']","['aspects of the evaluation framework described below are adopted from our previous experiments with noncluster - based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for the "" out - degree "" parameter δ ( called the "" ancestry "" parameter α in  #TAUTHOR_TAG ; and, of course, the incorporation of clusters']",5
['- based graphs  #TAUTHOR_TAG'],['on document - based graphs  #TAUTHOR_TAG'],['- based graphs  #TAUTHOR_TAG'],"['flow based on language models ( lms ).', 'to estimate the degree to which one item, if considered relevant, can vouch for the relevance of another, we follow our previous work on document - based graphs  #TAUTHOR_TAG and utilize p [ [UNK] ] d ( · ), the unigram dirichlet - smoothed language model induced from a given document d ( [UNK] is the smoothing parameter ) [ 38 ].', 'to adapt this estimation scheme to settings involving clusters, we derive the language model p c ( · ) for a cluster c by treating c as the ( large ) document formed by concatenating 7 its constituent ( or most strongly associated ) documents [ 17, 25, 19 ].', 'the relevance - flow measure we use is essentially a directed similarity in language - model space :', '']",5
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],5
['strongly correlated  #TAUTHOR_TAG.'],"['strongly correlated  #TAUTHOR_TAG. indeed, employing this']","['strongly correlated  #TAUTHOR_TAG. indeed, employing this']","['', 'thus, while we have already demonstrated in previous sections of this paper that information about document - cluster similarity relationships is very valuable, the results just', 'mentioned suggest that such information is more useful in "" raw "" form. re - anchoring to the query. in previous work, we showed that pagerank centrality scores induced over documentbased graphs can be used as a multiplicative weight on document query - likelihood terms, the intent being to cope with cases in which centrality in dinit and relevance are not strongly correlated  #TAUTHOR_TAG. indeed, employing this technique on the ap, tre', '']",5
"['- based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for']","['our previous experiments with noncluster - based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for']","['- based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for the "" out - degree "" parameter δ ( called the "" ancestry "" parameter α in  #TAUTHOR_TAG ; and, of']","['aspects of the evaluation framework described below are adopted from our previous experiments with noncluster - based structural re - ranking  #TAUTHOR_TAG so as to facilitate direct comparison.', 'section 4. 1 of  #TAUTHOR_TAG provides a more detailed justification of the experimental design.', 'the main conceptual changes 6 here are : a slightly larger parameter search - space for the "" out - degree "" parameter δ ( called the "" ancestry "" parameter α in  #TAUTHOR_TAG ; and, of course, the incorporation of clusters']",4
['strongly correlated  #TAUTHOR_TAG.'],"['strongly correlated  #TAUTHOR_TAG. indeed, employing this']","['strongly correlated  #TAUTHOR_TAG. indeed, employing this']","['', 'thus, while we have already demonstrated in previous sections of this paper that information about document - cluster similarity relationships is very valuable, the results just', 'mentioned suggest that such information is more useful in "" raw "" form. re - anchoring to the query. in previous work, we showed that pagerank centrality scores induced over documentbased graphs can be used as a multiplicative weight on document query - likelihood terms, the intent being to cope with cases in which centrality in dinit and relevance are not strongly correlated  #TAUTHOR_TAG. indeed, employing this technique on the ap, tre', '']",4
['- based graphs  #TAUTHOR_TAG'],['on document - based graphs  #TAUTHOR_TAG'],['- based graphs  #TAUTHOR_TAG'],"['flow based on language models ( lms ).', 'to estimate the degree to which one item, if considered relevant, can vouch for the relevance of another, we follow our previous work on document - based graphs  #TAUTHOR_TAG and utilize p [ [UNK] ] d ( · ), the unigram dirichlet - smoothed language model induced from a given document d ( [UNK] is the smoothing parameter ) [ 38 ].', 'to adapt this estimation scheme to settings involving clusters, we derive the language model p c ( · ) for a cluster c by treating c as the ( large ) document formed by concatenating 7 its constituent ( or most strongly associated ) documents [ 17, 25, 19 ].', 'the relevance - flow measure we use is essentially a directed similarity in language - model space :', '']",3
"['', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms']","['( nlp ) tasks.', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms']","['better performance in natural language processing ( nlp ) tasks.', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms']","['words in a common vector space can enable machine learning algorithms to achieve better performance in natural language processing ( nlp ) tasks.', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms for training such vector representations from unstructured text data via shal - * work done while with yahoo, inc.', 'permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.', '']",0
"['', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms']","['( nlp ) tasks.', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms']","['better performance in natural language processing ( nlp ) tasks.', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms']","['words in a common vector space can enable machine learning algorithms to achieve better performance in natural language processing ( nlp ) tasks.', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms for training such vector representations from unstructured text data via shal - * work done while with yahoo, inc.', 'permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.', '']",0
"['', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms']","['( nlp ) tasks.', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms']","['better performance in natural language processing ( nlp ) tasks.', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms']","['words in a common vector space can enable machine learning algorithms to achieve better performance in natural language processing ( nlp ) tasks.', 'word2vec  #TAUTHOR_TAG is a recently proposed family of algorithms for training such vector representations from unstructured text data via shal - * work done while with yahoo, inc.', 'permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.', '']",0
"['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '.,']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '., wi, m i, the objective is to maximize the log likelihood :', 'over input and output word row vectors u ( w ) and v ( w ) with w ranging over the words in the vocabulary v, where :', '']",0
"['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '.,']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '., wi, m i, the objective is to maximize the log likelihood :', 'over input and output word row vectors u ( w ) and v ( w ) with w ranging over the words in the vocabulary v, where :', '']",0
"['original open source implementation of word2vec  #TAUTHOR_TAG, as well as']","['original open source implementation of word2vec  #TAUTHOR_TAG, as well as']","['', 'these include the original open source implementation of word2vec  #TAUTHOR_TAG, as well as']","['existing word2vec training systems are limited to running on a single machine, though with multiple parallel threads of execution operating on different segments of training data.', 'these include the original open source implementation of word2vec  #TAUTHOR_TAG, as well as those of medallia [ 22 ], and rehurek [ 28 ].', 'as mentioned in the introduction, these systems would require far larger memory configurations than available on typical commodity - scale servers']",0
"['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '.,']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '., wi, m i, the objective is to maximize the log likelihood :', 'over input and output word row vectors u ( w ) and v ( w ) with w ranging over the words in the vocabulary v, where :', '']",5
"['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '.,']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '., wi, m i, the objective is to maximize the log likelihood :', 'over input and output word row vectors u ( w ) and v ( w ) with w ranging over the words in the vocabulary v, where :', '']",5
"['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '.,']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '., wi, m i, the objective is to maximize the log likelihood :', 'over input and output word row vectors u ( w ) and v ( w ) with w ranging over the words in the vocabulary v, where :', '']",5
"['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '.,']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '., wi, m i, the objective is to maximize the log likelihood :', 'over input and output word row vectors u ( w ) and v ( w ) with w ranging over the words in the vocabulary v, where :', '']",5
"['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '.,']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '., wi, m i, the objective is to maximize the log likelihood :', 'over input and output word row vectors u ( w ) and v ( w ) with w ranging over the words in the vocabulary v, where :', '']",5
"['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '.,']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '., wi, m i, the objective is to maximize the log likelihood :', 'over input and output word row vectors u ( w ) and v ( w ) with w ranging over the words in the vocabulary v, where :', '']",5
"['recommended in  #TAUTHOR_TAG,']","[', n = 10, d = 500, values within the ranges recommended in  #TAUTHOR_TAG,']","['recommended in  #TAUTHOR_TAG, this works out']",[' #TAUTHOR_TAG'],5
"['similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of']","['similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of the word vector state within or across shards or across client threads', '']","['similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of']","['', ""multithreaded and each thread handles the stream of rpc's coming from all client threads running on a single node. in a typical at scale run of the algorithm, the above process is carried out by multiple client threads running on each of a few hundred nodes,"", 'all interacting with the ps shards in parallel. the data set is iterated over multiple', 'times and after each iteration, the learning rate α is reduced in a manner similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of the word vector state within or across shards or across client threads', 'during any part of the computation. the only synchronization in effect is', 'that the rpc broadcast ensures that all shards operate on the same set of word vector indices', '']",5
"['similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of']","['similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of the word vector state within or across shards or across client threads', '']","['similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of']","['', ""multithreaded and each thread handles the stream of rpc's coming from all client threads running on a single node. in a typical at scale run of the algorithm, the above process is carried out by multiple client threads running on each of a few hundred nodes,"", 'all interacting with the ps shards in parallel. the data set is iterated over multiple', 'times and after each iteration, the learning rate α is reduced in a manner similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of the word vector state within or across shards or across client threads', 'during any part of the computation. the only synchronization in effect is', 'that the rpc broadcast ensures that all shards operate on the same set of word vector indices', '']",5
['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],"['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', 'of words within each sentence']","['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', '']",5
['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],"['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', 'of words within each sentence']","['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', '']",5
['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],"['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', 'of words within each sentence']","['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', '']",5
['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],"['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', 'of words within each sentence']","['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', '']",5
"['vector pairs trained using the open - source implementation of  #TAUTHOR_TAG, again on a large search session data set.', 'the former was']","['vector pairs trained using the open - source implementation of  #TAUTHOR_TAG, again on a large search session data set.', 'the former was']","['distributed system and for corresponding vector pairs trained using the open - source implementation of  #TAUTHOR_TAG, again on a large search session data set.', 'the former was trained using a vocabulary of 200']","['', 'the figure shows the ten most and least similar among the 800 most similar queries, where we note that the ten least similar queries can still be considered to be fairly semantically similar.', ""this particular set of vectors was trained for a vocabulary of 200m generalized words using the 300 dimen - ad title : download piano sheet music ad description : world's largest selection of sheet music for piano."", 'shop now! piano sheet music silent night, 0. 963 letter notes for songs, 0. 960 piano sheet music with lyrics, 0. 955 easy songs for the piano, 0. 955 easy music to play on the piano, 0. 954 super easy piano music, 0. 954 easy piano fur elise sheet music, 0. 953 easy piano notes for songs, 0. 953 sheet music for easy piano songs, 0. 953 easy piano songs sheet music, 0. 953 free piano songs, 0. 924 free sheet music on line, 0. 924 a thousand years piano sheet music free, 0. 924 sheet music the lion sleeps tonight, 0. 924 music notes for free, 0. 924 hiawatha rag sheet music free, 0. 924 oceans piano sheet music, 0. 924 i have returned sheet music, 0. 924 free sheet music for vocal solos, 0. 924 piano chopsticks sheet music, 0. 924 figure 4 : the top 10 and bottom 10 among the 800 most similar queries to a given ad vector, with cosine similarities to the ad vector.', 'sional vector, 15 ps shard settings described in section 6. 2.', 'we found the vector quality demonstrated in figure 4 to be the norm based on inspections of similar matchings of query vectors to a number of ad vectors.', 'we also compared the cosine similarities for pairs of vectors trained using the proposed distributed system and for corresponding vector pairs trained using the open - source implementation of  #TAUTHOR_TAG, again on a large search session data set.', 'the former was trained using a vocabulary of 200 million generalized words while the latter was trained using about 90 million words which is the']",5
['using implementation from  #TAUTHOR_TAG and the other was trained using'],['using implementation from  #TAUTHOR_TAG and the other was trained using'],"['', 'one model was trained using implementation from  #TAUTHOR_TAG and the other was trained using']","['successful offline evaluation of the proposed distributed system, in the following set of experiments we conducted tests on live web search traffic.', 'we ran two bucket tests, each on 5 % of search traffic, where we compared queryad matches produced by training query and ad vectors using search session data set spanning 9 months of search data.', 'one model was trained using implementation from  #TAUTHOR_TAG and the other was trained using the proposed distributed system.', 'both buckets were compared against control bucket, which employed a collection of different broad match techniques used in production at the time of the test.', 'each of the online tests were run for 10 days, one after another, more than a month apart.', '']",5
"['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '.,']","['this paper we focus on the skipgram approach with random negative examples proposed in  #TAUTHOR_TAG.', 'this has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [ 19,  #TAUTHOR_TAG.', 'given a corpus consisting of a sequence of sentences s1, s2,..., sn each comprising a sequence of words si = wi, 1, wi, 2,..', '., wi, m i, the objective is to maximize the log likelihood :', 'over input and output word row vectors u ( w ) and v ( w ) with w ranging over the words in the vocabulary v, where :', '']",4
['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],"['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', 'of words within each sentence']","['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', '']",4
['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],['algorithm described in  #TAUTHOR_TAG to coalesce sufficiently'],"['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', 'of words within each sentence']","['publicly available text corpuses and processes them using the algorithm described in  #TAUTHOR_TAG to coalesce sufficiently co - occurring words into phrases. we then randomly shuffled the order of sentences ( delimited by new line ) in the data set, retaining order', '']",4
"['similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of']","['similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of the word vector state within or across shards or across client threads', '']","['similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of']","['', ""multithreaded and each thread handles the stream of rpc's coming from all client threads running on a single node. in a typical at scale run of the algorithm, the above process is carried out by multiple client threads running on each of a few hundred nodes,"", 'all interacting with the ps shards in parallel. the data set is iterated over multiple', 'times and after each iteration, the learning rate α is reduced in a manner similar to the open source', 'implementation of  #TAUTHOR_TAG. note that there is no locking or synchronization of the word vector state within or across shards or across client threads', 'during any part of the computation. the only synchronization in effect is', 'that the rpc broadcast ensures that all shards operate on the same set of word vector indices', '']",3
['be transformed between languages  #TAUTHOR_TAG'],['be transformed between languages  #TAUTHOR_TAG'],"['can be transformed between languages  #TAUTHOR_TAG.', 'in']","['vector representations ( embeddings ) of words and phrases, as opposed to discrete feature templates, have recently allowed for notable advances in the state of the art of natural language processing ( nlp )  #AUTHOR_TAG.', 'these representations are typically induced from large unannotated corpora by predicting a word given its context  #AUTHOR_TAG.', 'unlike discrete feature templates, these representations allow supervised methods to readily make use of unlabeled data, effectively making them semi - supervised  #AUTHOR_TAG.', 'a recent focus has been on crosslingual, rather than monolingual, representations.', 'crosslingual representations are induced to represent words, phrases, or documents for more than one language, where the representations are constrained to preserve representational similarity or can be transformed between languages  #TAUTHOR_TAG.', 'in particular, crosslingual representations can be helpful for tasks such as translation or to leverage training data in a source language when little or no training data is available for a target language.', 'examples of such transfer learning tasks are crosslingual sentiment analysis  #AUTHOR_TAG and crosslingual document classification  #TAUTHOR_TAG.', 'induced language - specific word representations, learned a linear mapping between the language - specific representations using bilingual word pairs and evaluated their approach for single word translation.', '']",0
['be transformed between languages  #TAUTHOR_TAG'],['be transformed between languages  #TAUTHOR_TAG'],"['can be transformed between languages  #TAUTHOR_TAG.', 'in']","['vector representations ( embeddings ) of words and phrases, as opposed to discrete feature templates, have recently allowed for notable advances in the state of the art of natural language processing ( nlp )  #AUTHOR_TAG.', 'these representations are typically induced from large unannotated corpora by predicting a word given its context  #AUTHOR_TAG.', 'unlike discrete feature templates, these representations allow supervised methods to readily make use of unlabeled data, effectively making them semi - supervised  #AUTHOR_TAG.', 'a recent focus has been on crosslingual, rather than monolingual, representations.', 'crosslingual representations are induced to represent words, phrases, or documents for more than one language, where the representations are constrained to preserve representational similarity or can be transformed between languages  #TAUTHOR_TAG.', 'in particular, crosslingual representations can be helpful for tasks such as translation or to leverage training data in a source language when little or no training data is available for a target language.', 'examples of such transfer learning tasks are crosslingual sentiment analysis  #AUTHOR_TAG and crosslingual document classification  #TAUTHOR_TAG.', 'induced language - specific word representations, learned a linear mapping between the language - specific representations using bilingual word pairs and evaluated their approach for single word translation.', '']",0
['be transformed between languages  #TAUTHOR_TAG'],['be transformed between languages  #TAUTHOR_TAG'],"['can be transformed between languages  #TAUTHOR_TAG.', 'in']","['vector representations ( embeddings ) of words and phrases, as opposed to discrete feature templates, have recently allowed for notable advances in the state of the art of natural language processing ( nlp )  #AUTHOR_TAG.', 'these representations are typically induced from large unannotated corpora by predicting a word given its context  #AUTHOR_TAG.', 'unlike discrete feature templates, these representations allow supervised methods to readily make use of unlabeled data, effectively making them semi - supervised  #AUTHOR_TAG.', 'a recent focus has been on crosslingual, rather than monolingual, representations.', 'crosslingual representations are induced to represent words, phrases, or documents for more than one language, where the representations are constrained to preserve representational similarity or can be transformed between languages  #TAUTHOR_TAG.', 'in particular, crosslingual representations can be helpful for tasks such as translation or to leverage training data in a source language when little or no training data is available for a target language.', 'examples of such transfer learning tasks are crosslingual sentiment analysis  #AUTHOR_TAG and crosslingual document classification  #TAUTHOR_TAG.', 'induced language - specific word representations, learned a linear mapping between the language - specific representations using bilingual word pairs and evaluated their approach for single word translation.', '']",0
"['word representations.', ' #TAUTHOR_TAG use a neural language model']","['word representations.', ' #TAUTHOR_TAG use a neural language model']","['##lingual word representations.', ' #TAUTHOR_TAG use a neural language model']","['choice of the monolingual objective greatly influences the generality of models for crosslingual word representations.', ' #TAUTHOR_TAG use a neural language model to leverage monolingual data.', 'however, this does not explicitly encourage compositionality of the word representations.', ' #AUTHOR_TAG achieve good results with a noise - contrastive objective, discriminating aligned translation pairs from randomly sampled pairs.', 'however, their approach can only be trained using sentence aligned data, which makes it difficult to extend to leverage unannotated monolingual data.', ' #AUTHOR_TAG introduced bilbowa combining a bilingual objective with the skip - gram model proposed by which predicts the context of a word given the word itself.', '']",0
"['word representations.', ' #TAUTHOR_TAG use a neural language model']","['word representations.', ' #TAUTHOR_TAG use a neural language model']","['##lingual word representations.', ' #TAUTHOR_TAG use a neural language model']","['choice of the monolingual objective greatly influences the generality of models for crosslingual word representations.', ' #TAUTHOR_TAG use a neural language model to leverage monolingual data.', 'however, this does not explicitly encourage compositionality of the word representations.', ' #AUTHOR_TAG achieve good results with a noise - contrastive objective, discriminating aligned translation pairs from randomly sampled pairs.', 'however, their approach can only be trained using sentence aligned data, which makes it difficult to extend to leverage unannotated monolingual data.', ' #AUTHOR_TAG introduced bilbowa combining a bilingual objective with the skip - gram model proposed by which predicts the context of a word given the word itself.', '']",0
"['task introduced by  #TAUTHOR_TAG.', 'the goal is to']","['task introduced by  #TAUTHOR_TAG.', 'the goal is to']","['we evaluate our method on the crosslingual document classification task introduced by  #TAUTHOR_TAG.', 'the goal is to']","['', 'this requires either transforming the classifier itself to fit the new language or transforming / sharing representations of the text for both languages.', 'the crosslingual word and document representations induced using the approach proposed in this work present an intuitive way to tackle crosslingual document classification.', 'like previous work, we evaluate our method on the crosslingual document classification task introduced by  #TAUTHOR_TAG.', 'the goal is to correctly classify news articles taken from the english and german sections of the rcv1 and rcv2 corpus  #AUTHOR_TAG into one of four  #AUTHOR_TAG for 10 iterations on representations of documents in one language ( english / german ) and evaluate its performance on representations of documents in the corresponding other language ( german / english ).', 'we use the original data and the original implementation of the averaged perceptron used by  #TAUTHOR_TAG to evaluate the document representations created by our method.', 'there are different versions of the training set of varying sizes, ranging from 100 to 10, 000 documents, and the test sets for both languages contain 5, 000 documents.', 'most related work only reports results using the 1, 000 documents sized training set.', 'following previous work, we tune the hyperparameters of our model on held out documents in the same language that the model was trained on']",0
['the majority class baselines from  #TAUTHOR_TAG'],['the majority class baselines from  #TAUTHOR_TAG'],"['the majority class baselines from  #TAUTHOR_TAG.', 'our method']","['', 'table 2 shows results for all these configurations.', 'the result table includes previous work as well as the glossed, the machine translation and the majority class baselines from  #TAUTHOR_TAG.', '']",0
['be transformed between languages  #TAUTHOR_TAG'],['be transformed between languages  #TAUTHOR_TAG'],"['can be transformed between languages  #TAUTHOR_TAG.', 'in']","['vector representations ( embeddings ) of words and phrases, as opposed to discrete feature templates, have recently allowed for notable advances in the state of the art of natural language processing ( nlp )  #AUTHOR_TAG.', 'these representations are typically induced from large unannotated corpora by predicting a word given its context  #AUTHOR_TAG.', 'unlike discrete feature templates, these representations allow supervised methods to readily make use of unlabeled data, effectively making them semi - supervised  #AUTHOR_TAG.', 'a recent focus has been on crosslingual, rather than monolingual, representations.', 'crosslingual representations are induced to represent words, phrases, or documents for more than one language, where the representations are constrained to preserve representational similarity or can be transformed between languages  #TAUTHOR_TAG.', 'in particular, crosslingual representations can be helpful for tasks such as translation or to leverage training data in a source language when little or no training data is available for a target language.', 'examples of such transfer learning tasks are crosslingual sentiment analysis  #AUTHOR_TAG and crosslingual document classification  #TAUTHOR_TAG.', 'induced language - specific word representations, learned a linear mapping between the language - specific representations using bilingual word pairs and evaluated their approach for single word translation.', '']",1
"['word representations.', ' #TAUTHOR_TAG use a neural language model']","['word representations.', ' #TAUTHOR_TAG use a neural language model']","['##lingual word representations.', ' #TAUTHOR_TAG use a neural language model']","['choice of the monolingual objective greatly influences the generality of models for crosslingual word representations.', ' #TAUTHOR_TAG use a neural language model to leverage monolingual data.', 'however, this does not explicitly encourage compositionality of the word representations.', ' #AUTHOR_TAG achieve good results with a noise - contrastive objective, discriminating aligned translation pairs from randomly sampled pairs.', 'however, their approach can only be trained using sentence aligned data, which makes it difficult to extend to leverage unannotated monolingual data.', ' #AUTHOR_TAG introduced bilbowa combining a bilingual objective with the skip - gram model proposed by which predicts the context of a word given the word itself.', '']",1
['of  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG'],['of  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG'],"['of  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG we represent each word as a vector and use separate word representations for each language.', ' #AUTHOR_TAG,']","['the work of  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG we represent each word as a vector and use separate word representations for each language.', '']",3
"['a bilingual corpus of aligned sentences.', 'in addition, our model allows the representations to draw upon monolingual data from either or both languages.', 'like  #TAUTHOR_TAG we choose']","['a bilingual corpus of aligned sentences.', 'in addition, our model allows the representations to draw upon monolingual data from either or both languages.', 'like  #TAUTHOR_TAG we choose']","['least a bilingual corpus of aligned sentences.', 'in addition, our model allows the representations to draw upon monolingual data from either or both languages.', 'like  #TAUTHOR_TAG we choose']",[' #TAUTHOR_TAG'],3
['the majority class baselines from  #TAUTHOR_TAG'],['the majority class baselines from  #TAUTHOR_TAG'],"['the majority class baselines from  #TAUTHOR_TAG.', 'our method']","['', 'table 2 shows results for all these configurations.', 'the result table includes previous work as well as the glossed, the machine translation and the majority class baselines from  #TAUTHOR_TAG.', '']",3
"['introduced by  #TAUTHOR_TAG.', 'to increase']","['introduced by  #TAUTHOR_TAG.', 'to increase']","['introduced by  #TAUTHOR_TAG.', 'to increase the expressiveness']","['this work we introduced a method that is capable of inducing compositional crosslingual word representations while scaling to large amounts of data.', 'our novel approach for learning monolingual word representations integrates naturally with our sentence based bilingual objective and allows us to make use of sentence - aligned bilingual corpora as well as monolingual data.', 'the method is agnostic to the choice of composition function, enabling more complex ( e. g. preserving word order information ) ways to compose phrase representations from word representations.', 'depending on the amount of training data available the accuracy achieved with our models is comparable or greatly improves upon previously reported results for the crosslingual document classification task introduced by  #TAUTHOR_TAG.', 'to increase the expressiveness of our method we plan to investigate more complex composition functions, possibly based on convolution or other ways to preserve word order information.', 'we consider the monolingual inclusion objective to be worthy of further research on its own and will evaluate its performance in comparison to related methods when learning word representations from monolingual data']",3
"[' #TAUTHOR_TAG we split our objective into two sub - objectives,']","[' #TAUTHOR_TAG we split our objective into two sub - objectives,']","[' #TAUTHOR_TAG we split our objective into two sub - objectives, a bilingual objective minimizing']","[' #TAUTHOR_TAG we split our objective into two sub - objectives, a bilingual objective minimizing the transfer errors and a monolingual objective minimizing the monolingual errors for l 1 and l 2.', 'we formalize the loss over the whole training set as', 'where l bi is the bilingual loss for two aligned sentences, v i is a sample from the set of n bi aligned sentences in language 1 and 2, l mono is the monolingual loss which we sum over n mono1 sentences x l1 i from corpora in language 1 and n mono2 sentences y l2 i from corpora in language 2.', 'we learn the parameters θ, which represent the whole set of word representations for both l 1 and l 2.', 'the parameters are used in a shared fashion to construct sentence representations for both the monolingual corpora and the parts of the bilingual corpus corresponding to each language.', 'we regularize θ using the squared euclidean norm and scale the contribution of the regularizer by λ.', 'both objectives operate on vectors that represent composed versions of phrases and are agnostic to how a phrase is transformed into a vector.', 'the objective can therefore be used with arbitrary composition functions.', 'an illustration of our proposed method can be found in figure 1']",5
"['task introduced by  #TAUTHOR_TAG.', 'the goal is to']","['task introduced by  #TAUTHOR_TAG.', 'the goal is to']","['we evaluate our method on the crosslingual document classification task introduced by  #TAUTHOR_TAG.', 'the goal is to']","['', 'this requires either transforming the classifier itself to fit the new language or transforming / sharing representations of the text for both languages.', 'the crosslingual word and document representations induced using the approach proposed in this work present an intuitive way to tackle crosslingual document classification.', 'like previous work, we evaluate our method on the crosslingual document classification task introduced by  #TAUTHOR_TAG.', 'the goal is to correctly classify news articles taken from the english and german sections of the rcv1 and rcv2 corpus  #AUTHOR_TAG into one of four  #AUTHOR_TAG for 10 iterations on representations of documents in one language ( english / german ) and evaluate its performance on representations of documents in the corresponding other language ( german / english ).', 'we use the original data and the original implementation of the averaged perceptron used by  #TAUTHOR_TAG to evaluate the document representations created by our method.', 'there are different versions of the training set of varying sizes, ranging from 100 to 10, 000 documents, and the test sets for both languages contain 5, 000 documents.', 'most related work only reports results using the 1, 000 documents sized training set.', 'following previous work, we tune the hyperparameters of our model on held out documents in the same language that the model was trained on']",5
"['task introduced by  #TAUTHOR_TAG.', 'the goal is to']","['task introduced by  #TAUTHOR_TAG.', 'the goal is to']","['we evaluate our method on the crosslingual document classification task introduced by  #TAUTHOR_TAG.', 'the goal is to']","['', 'this requires either transforming the classifier itself to fit the new language or transforming / sharing representations of the text for both languages.', 'the crosslingual word and document representations induced using the approach proposed in this work present an intuitive way to tackle crosslingual document classification.', 'like previous work, we evaluate our method on the crosslingual document classification task introduced by  #TAUTHOR_TAG.', 'the goal is to correctly classify news articles taken from the english and german sections of the rcv1 and rcv2 corpus  #AUTHOR_TAG into one of four  #AUTHOR_TAG for 10 iterations on representations of documents in one language ( english / german ) and evaluate its performance on representations of documents in the corresponding other language ( german / english ).', 'we use the original data and the original implementation of the averaged perceptron used by  #TAUTHOR_TAG to evaluate the document representations created by our method.', 'there are different versions of the training set of varying sizes, ranging from 100 to 10, 000 documents, and the test sets for both languages contain 5, 000 documents.', 'most related work only reports results using the 1, 000 documents sized training set.', 'following previous work, we tune the hyperparameters of our model on held out documents in the same language that the model was trained on']",5
"['a bilingual corpus of aligned sentences.', 'in addition, our model allows the representations to draw upon monolingual data from either or both languages.', 'like  #TAUTHOR_TAG we choose']","['a bilingual corpus of aligned sentences.', 'in addition, our model allows the representations to draw upon monolingual data from either or both languages.', 'like  #TAUTHOR_TAG we choose']","['least a bilingual corpus of aligned sentences.', 'in addition, our model allows the representations to draw upon monolingual data from either or both languages.', 'like  #TAUTHOR_TAG we choose']",[' #TAUTHOR_TAG'],5
"['candidates  #TAUTHOR_TAG.', 'in span']","['candidates  #TAUTHOR_TAG.', 'in']","['candidates  #TAUTHOR_TAG.', 'in span']",[' #TAUTHOR_TAG'],0
"['successful models in these paradigms  #TAUTHOR_TAG.', 'the']","['successful models in these paradigms  #TAUTHOR_TAG.', 'the']","['successful models in these paradigms  #TAUTHOR_TAG.', 'the answer types in these datasets']","['machine learning models, especially deep neural networks, often significantly benefit from transfer learning.', 'in computer vision, deep convolutional neural networks trained on a large image classification dataset such as imagenet  #AUTHOR_TAG have proved to be useful for initializing models on other vision tasks, such as object detection  #AUTHOR_TAG.', 'in natural language processing, domain adaptation has traditionally been an important topic for syntactic parsing ( mc  #AUTHOR_TAG and named entity recognition  #AUTHOR_TAG, among others.', 'with the popularity of distributed representation, pre - trained word embedding models such as word2vec  #AUTHOR_TAG are also widely used for natural language tasks ( karpathy and fei -  #AUTHOR_TAG.', 'instead of these, we initialize our models from a qa dataset and show how standard transfer learning can achieve state - of - the - art in target qa datasets.', 'there have been several qa paradigms in nlp, which can be categorized by the context and supervision used to answer questions.', 'this context can range from structured and confined knowledge bases  #AUTHOR_TAG to unstructured and unbounded natural language form ( e. g., documents on the web  #AUTHOR_TAG ) and unstructured, but restricted in size ( e. g., a paragraph or multiple sentences  #AUTHOR_TAG ).', 'the recent advances in neural question answering lead to numerous datasets and successful models in these paradigms  #TAUTHOR_TAG.', '']",0
"['successful models in these paradigms  #TAUTHOR_TAG.', 'the']","['successful models in these paradigms  #TAUTHOR_TAG.', 'the']","['successful models in these paradigms  #TAUTHOR_TAG.', 'the answer types in these datasets']","['machine learning models, especially deep neural networks, often significantly benefit from transfer learning.', 'in computer vision, deep convolutional neural networks trained on a large image classification dataset such as imagenet  #AUTHOR_TAG have proved to be useful for initializing models on other vision tasks, such as object detection  #AUTHOR_TAG.', 'in natural language processing, domain adaptation has traditionally been an important topic for syntactic parsing ( mc  #AUTHOR_TAG and named entity recognition  #AUTHOR_TAG, among others.', 'with the popularity of distributed representation, pre - trained word embedding models such as word2vec  #AUTHOR_TAG are also widely used for natural language tasks ( karpathy and fei -  #AUTHOR_TAG.', 'instead of these, we initialize our models from a qa dataset and show how standard transfer learning can achieve state - of - the - art in target qa datasets.', 'there have been several qa paradigms in nlp, which can be categorized by the context and supervision used to answer questions.', 'this context can range from structured and confined knowledge bases  #AUTHOR_TAG to unstructured and unbounded natural language form ( e. g., documents on the web  #AUTHOR_TAG ) and unstructured, but restricted in size ( e. g., a paragraph or multiple sentences  #AUTHOR_TAG ).', 'the recent advances in neural question answering lead to numerous datasets and successful models in these paradigms  #TAUTHOR_TAG.', '']",0
"['candidates  #TAUTHOR_TAG.', 'in span']","['candidates  #TAUTHOR_TAG.', 'in']","['candidates  #TAUTHOR_TAG.', 'in span']",[' #TAUTHOR_TAG'],5
[' #TAUTHOR_TAG incorporates embeddings for authors ('],"[' #TAUTHOR_TAG incorporates embeddings for authors ( i. e., users who have composed tweets ) that encode the']","['.', 'to model homophily, recent research in abusive language detection on twitter  #TAUTHOR_TAG incorporates embeddings for authors (']","[""carried out an interesting study showing that the racist tweets posted in response to president obama's re - election were not distributed uniformly across the united states but instead formed clusters."", 'this phenomenon is known as homophily : i. e., people, both in real life and online, tend to cluster with those who appear similar to themselves.', 'to model homophily, recent research in abusive language detection on twitter  #TAUTHOR_TAG incorporates embeddings for authors ( i. e., users who have composed tweets ) that encode the structure of their surrounding communities.', 'the embeddings ( called author profiles ) are generated by applying a node embedding framework to an undirected unlabeled community graph where nodes denote the authors and edges the follower - following relationships amongst them on twitter.', 'however, these profiles do not capture the linguistic behavior of the authors and their communities and do not convey whether their tweets tend to be abusive or not.', 'in contrast, we represent the community of authors as a heterogeneous graph consisting of two types of nodes, authors and their tweets, rather than a homogeneous community graph of authors only.', 'the primary advantage of such heterogeneous representations is that they enable us to model both community structure as well as the linguistic behavior of authors in these communities.', 'to generate richer author profiles, we then propose a semi - supervised learning approach based on graph convolutional networks ( gcns ) applied to the heterogeneous graph representation.', 'to the best of our knowledge, our work is the first to use gcns to model online communities in social media.', 'we demonstrate that our methods provide significant improvements over existing techniques']",0
"['approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to']","['approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to']","['first describe the approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to']","['first describe the approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to our semi - supervised approach based on graph convolutional networks  #AUTHOR_TAG.', 'node2vec.', 'node2vec extends the word2vec skipgram model  #AUTHOR_TAG to graphs in order to create low - dimensional embeddings for nodes based on their position and neighborhood.', 'specifically, for a given graph with nodes v = { v 1, v 2,..., v n }, node2vec aims to maximize the following log probability :', '']",0
['method  #TAUTHOR_TAG for'],['method  #TAUTHOR_TAG for'],"[' #TAUTHOR_TAG for the dataset we are using.', 'for each tweet, the profile']","['experiment with five different supervised classification methods for tweets in the dataset.', 'the first three ( lr, lr + auth, lr + extd ) serve as our baselines, 3 and the last two with gcns 4 are the methods we propose.', 'lr.', 'this method is adopted from  #AUTHOR_TAG wherein they train a logistic regression classifier on character n - grams ( up to 4 - grams ) of the tweets.', 'character n - grams have been shown to be highly effective for abuse detection due to their robustness to spelling variations.', 'lr + auth.', 'this is the state of the art method  #TAUTHOR_TAG for the dataset we are using.', ""for each tweet, the profile of its author ( generated by node2vec from the community graph ) is appended onto the tweet's character n - gram representation for training the lr classifier as above."", 'lr + extd.', 'this method is identical to lr + auth, except that we now run node2vec on the extended graph to generate author profiles.', 'intuitively, since node2vec treats both author and tweet nodes as the same and does not take into account the labels of tweets, the author profiles generated should exhibit the same properties as those generated from the community graph.', 'gcn.', 'here, we simply assign a label to each tweet based on the highest score from the softmax distribution provided by our gcn model for the ( tweet ) nodes of the extended graph.', 'lr + gcn.', 'identical to lr + extd, except that we replace the author profiles from node2vec with those extracted by our gcn approach']",0
"[' #TAUTHOR_TAG, we experiment with a subset']","[' #TAUTHOR_TAG, we experiment with a subset']","[' #TAUTHOR_TAG, we experiment with a subset']","['learning for abusive language detection was first explored by  #AUTHOR_TAG who extracted rule - based features to train their classifier.', 'subsequently, manually - engineered lexicalsyntactic features formed the crux of most approaches to the task  #AUTHOR_TAG.', ' #AUTHOR_TAG showed that dense comment representations generated using paragraph2vec outperform bag - of - words features.', 'several works have since utilized ( deep ) neural architectures to achieve impressive results on a variety of abuse - annotated datasets  #AUTHOR_TAG a ).', 'recently, the research focus has shifted towards extraction of features that capture behavioral and social traits of users.', ' #AUTHOR_TAG b ) showed that including randomly - initialized user embeddings improved the performance of their rnn methods.', ' #AUTHOR_TAG following previous work  #TAUTHOR_TAG, we experiment with a subset of the twitter dataset compiled by']",5
['of  #TAUTHOR_TAG ( referred to as the community'],"['of  #TAUTHOR_TAG ( referred to as the community graph ).', 'it contains 1, 875 nodes representing each of the authors in the dataset.', 'two authors / nodes are connected by']","['of  #TAUTHOR_TAG ( referred to as the community graph ).', 'it contains 1, 875 nodes representing each of the authors in the dataset.', 'two authors / nodes are connected by a single undirected edge if either one follows the other on twitter.', 'there are']","['create two different graphs : the first one is identical to the community graph of  #TAUTHOR_TAG ( referred to as the community graph ).', 'it contains 1, 875 nodes representing each of the authors in the dataset.', 'two authors / nodes are connected by a single undirected edge if either one follows the other on twitter.', 'there are 453 solitary authors in the graph who are neither followed by nor follow any other author in the dataset.', 'this graph is homogeneous, i. e., it has nodes ( and hence edges ) of a single type only.', 'our second graph is an extended version of the first ( referred to as the extended graph ) that additionally contains nodes representing the tweets of the authors.', 'specifically, in addition to the 1, 875 author nodes, the graph contains 16, 202 tweet nodes.', 'each tweet node is connected to a single author node, denoting that the tweet is elicited from that particular author.', 'this graph is no longer homogeneous since it contains nodes and edges of two different types']",5
"['approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to']","['approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to']","['first describe the approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to']","['first describe the approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to our semi - supervised approach based on graph convolutional networks  #AUTHOR_TAG.', 'node2vec.', 'node2vec extends the word2vec skipgram model  #AUTHOR_TAG to graphs in order to create low - dimensional embeddings for nodes based on their position and neighborhood.', 'specifically, for a given graph with nodes v = { v 1, v 2,..., v n }, node2vec aims to maximize the following log probability :', '']",5
"['approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to']","['approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to']","['first describe the approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to']","['first describe the approach of  #TAUTHOR_TAG that learns author embeddings using node2vec  #AUTHOR_TAG ; this serves as our baseline.', 'we then move on to our semi - supervised approach based on graph convolutional networks  #AUTHOR_TAG.', 'node2vec.', 'node2vec extends the word2vec skipgram model  #AUTHOR_TAG to graphs in order to create low - dimensional embeddings for nodes based on their position and neighborhood.', 'specifically, for a given graph with nodes v = { v 1, v 2,..., v n }, node2vec aims to maximize the following log probability :', '']",5
['of  #TAUTHOR_TAG ( referred to as the community'],"['of  #TAUTHOR_TAG ( referred to as the community graph ).', 'it contains 1, 875 nodes representing each of the authors in the dataset.', 'two authors / nodes are connected by']","['of  #TAUTHOR_TAG ( referred to as the community graph ).', 'it contains 1, 875 nodes representing each of the authors in the dataset.', 'two authors / nodes are connected by a single undirected edge if either one follows the other on twitter.', 'there are']","['create two different graphs : the first one is identical to the community graph of  #TAUTHOR_TAG ( referred to as the community graph ).', 'it contains 1, 875 nodes representing each of the authors in the dataset.', 'two authors / nodes are connected by a single undirected edge if either one follows the other on twitter.', 'there are 453 solitary authors in the graph who are neither followed by nor follow any other author in the dataset.', 'this graph is homogeneous, i. e., it has nodes ( and hence edges ) of a single type only.', 'our second graph is an extended version of the first ( referred to as the extended graph ) that additionally contains nodes representing the tweets of the authors.', 'specifically, in addition to the 1, 875 author nodes, the graph contains 16, 202 tweet nodes.', 'each tweet node is connected to a single author node, denoting that the tweet is elicited from that particular author.', 'this graph is no longer homogeneous since it contains nodes and edges of two different types']",3
[' #TAUTHOR_TAG highlighted for'],[' #TAUTHOR_TAG highlighted for'],[' #TAUTHOR_TAG highlighted for'],"['', 'however, on the racism class, its recall is hindered by the same factor that  #TAUTHOR_TAG highlighted for their node2vec - only method, i. e., that racist tweets come from 5 unique authors only who have also contributed sexist or clean tweets.', 'the racist activity of these authors is therefore eclipsed, leading to misclassifications of their tweets.', 'lr + gcn alleviates this problem by incorporating character n - gram representations of the tweets, hence not relying solely on the linguistic behavior of their authors.', 'figure 1 shows the t - sne ( van der  #AUTHOR_TAG visualizations of node2vec author profiles from the community and extended graphs.', 'both visualizations show that some authors belong to densely - connected communities while others are part of more sparse ones.', 'the results from lr + auth and lr + extd have insignificant differences, further confirming that their author profiles have similar properties.', 'in essence, node2vec is unable to gain anything more from the extended graph than what it does from the community graph.', 'figure 2 shows a t - sne visualization of the author profiles generated using our gcn approach.', 'red dots denote the authors who are abusive ( sexist or racist ) according to our model ( i. e., as per the softmax outputs for the author nodes ).', '5 the red dots are mostly clustered in a small portion of the visualization, which corroborates the notion of']",3
['of  #TAUTHOR_TAG that introduces community -'],['of  #TAUTHOR_TAG that introduces community - based profiling of authors'],"['this paper, we built on the work of  #TAUTHOR_TAG that introduces community - based profiling of authors']","['this paper, we built on the work of  #TAUTHOR_TAG that introduces community - based profiling of authors for abusive language detection.', 'we proposed an approach based on graph convolutional networks to show that author profiles that directly capture the linguistic behavior of authors along with the structural traits of their community significantly advance the current state of the art']",6
"['data selection  #TAUTHOR_TAG.', '']","['data selection  #TAUTHOR_TAG.', '']","['data selection  #TAUTHOR_TAG.', '']","['parallel training data provided for german - english is quite large ( 38m sentence pairs ).', 'most of the parallel data is crawled from the internet and is not in news domain.', 'out - ofdomain training data can hurt the translation performance on news test sets  #AUTHOR_TAG and also significantly increase training time.', 'therefore, we trained neural language models on a large monolingual news corpus to perform data selection  #TAUTHOR_TAG.', 'back - translation large monolingual data in the news domain is provided for both german and 1 https : / / github. com / awslabs / sockeye english, which can be back - translated as additional parallel training data for our system  #AUTHOR_TAG a ;  #AUTHOR_TAG.', 'the back - translated parallel data is in the news domain, which is a big advantage compared to outof - domain parallel training data provided for the news task.', 'in - domain fine - tuning the transformer models were finally fine - tuned using the small in - domain parallel data provided for the news task  #TAUTHOR_TAG.', 'note that the large back - translated parallel data is also in - domain, but it has relatively low quality due to translation errors']",1
"['data selection  #TAUTHOR_TAG.', '']","['data selection  #TAUTHOR_TAG.', '']","['data selection  #TAUTHOR_TAG.', '']","['parallel training data provided for german - english is quite large ( 38m sentence pairs ).', 'most of the parallel data is crawled from the internet and is not in news domain.', 'out - ofdomain training data can hurt the translation performance on news test sets  #AUTHOR_TAG and also significantly increase training time.', 'therefore, we trained neural language models on a large monolingual news corpus to perform data selection  #TAUTHOR_TAG.', 'back - translation large monolingual data in the news domain is provided for both german and 1 https : / / github. com / awslabs / sockeye english, which can be back - translated as additional parallel training data for our system  #AUTHOR_TAG a ;  #AUTHOR_TAG.', 'the back - translated parallel data is in the news domain, which is a big advantage compared to outof - domain parallel training data provided for the news task.', 'in - domain fine - tuning the transformer models were finally fine - tuned using the small in - domain parallel data provided for the news task  #TAUTHOR_TAG.', 'note that the large back - translated parallel data is also in - domain, but it has relatively low quality due to translation errors']",5
"['of both models  #TAUTHOR_TAG.', 'the ensemble of both models outperform']","['of both models  #TAUTHOR_TAG.', 'the ensemble of both models outperformed']","['transformer - big.', 'our final submission is an ensemble of both models  #TAUTHOR_TAG.', 'the ensemble of both models outperform']","['trained two transformer models with different sizes, transformer - base and transformer - big.', 'our final submission is an ensemble of both models  #TAUTHOR_TAG.', 'the ensemble of both models outperformed a single base or big model most likely because the two models can capture somewhat different features for the translation task']",6
"['.', ""inspired by  #TAUTHOR_TAG's work which used kenlm  #AUTHOR_TAG""]","['selection on out - of - domain data.', ""inspired by  #TAUTHOR_TAG's work which used kenlm  #AUTHOR_TAG""]","['to domain dismatch.', 'therefore, we performed data selection on out - of - domain data.', ""inspired by  #TAUTHOR_TAG's work which used kenlm  #AUTHOR_TAG""]","['', 'therefore, we performed data selection on out - of - domain data.', ""inspired by  #TAUTHOR_TAG's work which used kenlm  #AUTHOR_TAG for data selection, we trained two neural language models based on self - attention networks using the 2018 part of the large monolingual news crawl corpus for english and german, respectively."", 'because these neural language models are trained on the news domain, we can use them to score out - ofdomain data.', '']",7
"['. 1998 ], and  #TAUTHOR_TAG which does not use the stack information of the']","['al. 1998 ], and  #TAUTHOR_TAG which does not use the stack information of the glr parser effectively,']","['. 1998 ], and  #TAUTHOR_TAG which does not use the stack information of the glr parser effectively,']","['the first approach [ wright and wrigley 1991 ] of combining a probabilistic method into the glr technique was published, some probabilistic glr parsers also have been implemented in which probabilities are assigned to actions of lr parsing tables by using lookaheads or lr states as simple context information of [ briscoe and carroll 1993 ], [ kentaro et al. 1998 ], and  #TAUTHOR_TAG which does not use the stack information of the glr parser effectively, because of highly complex internal glr stack.', 'as a result, they have used relatively limited contextual information for disambiguation.', '[  #AUTHOR_TAG ] have proposed a conditional action model that uses the partially constructed parse represented by the graph - structured stack as the additional context.', 'however, this method inappropriately defined sub - tree structure.', 'our proposed model uses surface phrasal types representing the structural characteristics of the sub - trees for its additional contextual information']",0
"['. 1998 ], and  #TAUTHOR_TAG which does not use the stack information of the']","['al. 1998 ], and  #TAUTHOR_TAG which does not use the stack information of the glr parser effectively,']","['. 1998 ], and  #TAUTHOR_TAG which does not use the stack information of the glr parser effectively,']","['the first approach [ wright and wrigley 1991 ] of combining a probabilistic method into the glr technique was published, some probabilistic glr parsers also have been implemented in which probabilities are assigned to actions of lr parsing tables by using lookaheads or lr states as simple context information of [ briscoe and carroll 1993 ], [ kentaro et al. 1998 ], and  #TAUTHOR_TAG which does not use the stack information of the glr parser effectively, because of highly complex internal glr stack.', 'as a result, they have used relatively limited contextual information for disambiguation.', '[  #AUTHOR_TAG ] have proposed a conditional action model that uses the partially constructed parse represented by the graph - structured stack as the additional context.', 'however, this method inappropriately defined sub - tree structure.', 'our proposed model uses surface phrasal types representing the structural characteristics of the sub - trees for its additional contextual information']",1
"['requires the users to specify the number of senses : current systems  #TAUTHOR_TAG ; chang, pei, and chen 2014 ) required to set the number of senses to a small number ( set to 3 or 5 in the literature ) to get a good']","['requires the users to specify the number of senses : current systems  #TAUTHOR_TAG ; chang, pei, and chen 2014 ) required to set the number of senses to a small number ( set to 3 or 5 in the literature ) to get a good accuracy, however many words']","['it requires the users to specify the number of senses : current systems  #TAUTHOR_TAG ; chang, pei, and chen 2014 ) required to set the number of senses to a small number ( set to 3 or 5 in the literature ) to get a good accuracy, however many words may have a large number of senses, e. g. play in figure 1']","['sense induction ( wsi ) is the task where given an ambiguous target word ( e. g. cold ) and texts where the word is used, we automatically discover its multiple senses or meanings ( e. g. ( 1 ) nose infection, ( 2 ) absence of heat, etc. ).', 'we show examples of words with multiple senses and example usage in a text 1 in figure 1.', 'it is distinct from its similar supervised counterpart, word sense disambiguation ( wsd ) ( stevenson and wilks 2003 ), because wsi models should consider the following challenges due to its unsupervised nature : ( c1 ) adaptability to new domains, ( c2 ) ability to detect novel senses, and ( c3 ) flexibility to different word sense granularities ( jurgens and klapaftis 2013 ).', 'another task similar to the wsi is the unsupervised author name disambiguation ( uand ) task ( song et al. 2007 ), where it aims to automatically find different authors, instead of words, with the same name.', 'in this paper, we consider a latent variable modeling approach to wsi problem as it is proven to be more effective than other approaches ( chang, pei, and chen 2014 ; komninos and manandhar 2016 ).', 'specifically, we look into methods based on latent dirichlet allocation ( lda ) ( blei, ng, and jordan 2003 ), a topic modeling method that automatically discovers the topics underlying a set of documents using dirichlet priors to infer the multinomial distribution over words and topics.', 'lda naturally answers two of the three main problems mentioned above, i. e. ( c1 ) and ( c2 ), of the wsi task ( brody and lapata 2009 ).', 'however, it is not flexible with regards to ( c3 ), or the sense granularity problem, as it requires the users to specify the number of senses : current systems  #TAUTHOR_TAG ; chang, pei, and chen 2014 ) required to set the number of senses to a small number ( set to 3 or 5 in the literature ) to get a good accuracy, however many words may have a large number of senses, e. g. play in figure 1']",1
"['is 3.', 'lda extensions  #TAUTHOR_TAG ; chang, pei, and chen 2014 )']","['is 3.', 'lda extensions  #TAUTHOR_TAG ; chang, pei, and chen 2014 )']","['is 3.', 'lda extensions  #TAUTHOR_TAG ; chang, pei, and chen 2014 )']","['are two reasons why latent dirichlet allocation ( lda ) ( blei, ng, and jordan 2003 ) is not effective for wsi.', 'first, lda tries to give instance assignments to all senses even when it is unnecessary.', 'for example, when the number of senses s is set to 10, the model tries to assign all the senses to all instances even when the original number of senses of a target word is 3.', 'lda extensions  #TAUTHOR_TAG ; chang, pei, and chen 2014 ) mitigated this problem by setting s to a small number ( e. g. 3 or 5 ).', 'however, this is not a good solution because there are many words with more than five senses.', 'second, lda and its extensions do not consider the existence of fine - grained senses.', 'for example, the cold : absence of heat and the cold : sensation from low temperature senses are fine - grained senses because they are similarly related to temperature yet have different usage']",1
['chen 2014 ) and stm  #TAUTHOR_TAG mitigate'],['chen 2014 ) and stm  #TAUTHOR_TAG mitigated this problem by tuning'],['chen 2014 ) and stm  #TAUTHOR_TAG mitigate'],"['main weakness of lda when used on wsi task is the sense granularity problem.', 'recent models such as hc ( chang, pei, and chen 2014 ) and stm  #TAUTHOR_TAG mitigated this problem by tuning the number of senses hyperparameter s to minimize the error.', 'however, such tuning, often empirically set to a small number such as s = 3  #TAUTHOR_TAG, fails to infer varying number of senses of words, especially for words with a higher number of senses.', 'nonparametric models such as hdp and bnp - hc chang, pei, and chen 2014 ) claim to automatically induce different s for each word.', 'however, as shown in the results in table 2, the estimated s is far from the actual number of senses and both models are ineffective.', 'on the other hand, table 2 also shows that autosense is effective even when s is overestimated.', 'we explain why through an example result shown in table 3, where the target word is the verb book, the actual number of senses is three, and s is set to 15.', '']",1
"['jointly ( stm )  #TAUTHOR_TAG.', 'in this paper, we also use a separate sense latent variable, however we show boost in']","['jointly ( stm )  #TAUTHOR_TAG.', 'in this paper, we also use a separate sense latent variable, however we show boost in']","['( stm )  #TAUTHOR_TAG.', 'in this paper, we also use a separate sense latent variable, however we show boost in']","['works on wsi used context vectors and attributes ( almuhareb, poesio, and others 2006 ), pretrained classification systems ( tsvetkov et al. 2014 ), and alignment of parallel corpus ( yao, van durme, and callison - burch 2012 ).', 'in the most recent shared task on wsi ( jurgens and klapaftis 2013 ), top models used lexical substitution method ( ai - ku ) ( baskaya et al. 2013 ) and hierarchical dirichlet process trained with additional instances ( unimelb ).', 'latent variable models such as lda ( blei, ng, and jordan 2003 ) are used to induce the word sense of a target word after rigorous preprocessing and feature extraction ( lda, spectral ) ( goyal and hovy 2014 ).', 'more recent models introduced a latent variable for the sense of a word, with the assumption that a sense has multiple concepts ( hc, hc + zipf ) ( chang, pei, and chen 2014 ) and that topics and senses should be inferred jointly ( stm )  #TAUTHOR_TAG.', 'in this paper, we also use a separate sense latent variable, however we show boost in performance by representing it with more versatility and by incorporating the use of targetneighbor pairs.', 'hc was also extended to a nonparametric model ( bnp - hc ) ( teh et al. 2004 ) in order to automatically set the number of senses of a word, providing flexibility to the sense granularity ( yao and van durme 2011 ; lau et al. 2012 ;.', 'in our experiments, we show that the sense granularity induced from nonparametric models are incorrect making the models less effective.', 'recent inclusions to the wsi models are neural - based dense distributional representation models.', 'stm also used word embeddings ( mikolov et al. 2013 ) to assign similarity weights during inference ( stm + w2v )  #TAUTHOR_TAG.', 'existing sense embeddings are also used to perform word sense induction ( crp - ppmi, se - wsi - fix, wg, dive ) ( song 2016 ; pelevina et al. 2016 ; chang et al. 2018 ).', 'these models, on their own, do not perform well on the wsi task until recently when embeddings of words and their dependencies are used to construct a probabilistic model ( mcc ) ( komninos and manandhar 2016 ).', 'we show that neuralbased embeddings are still ineffective for this task and that our model performs better than these models as well.', 'in the unsupervised author name disambiguation ( uand ) domain, lda - based models have']",0
"['jointly ( stm )  #TAUTHOR_TAG.', 'in this paper, we also use a separate sense latent variable, however we show boost in']","['jointly ( stm )  #TAUTHOR_TAG.', 'in this paper, we also use a separate sense latent variable, however we show boost in']","['( stm )  #TAUTHOR_TAG.', 'in this paper, we also use a separate sense latent variable, however we show boost in']","['works on wsi used context vectors and attributes ( almuhareb, poesio, and others 2006 ), pretrained classification systems ( tsvetkov et al. 2014 ), and alignment of parallel corpus ( yao, van durme, and callison - burch 2012 ).', 'in the most recent shared task on wsi ( jurgens and klapaftis 2013 ), top models used lexical substitution method ( ai - ku ) ( baskaya et al. 2013 ) and hierarchical dirichlet process trained with additional instances ( unimelb ).', 'latent variable models such as lda ( blei, ng, and jordan 2003 ) are used to induce the word sense of a target word after rigorous preprocessing and feature extraction ( lda, spectral ) ( goyal and hovy 2014 ).', 'more recent models introduced a latent variable for the sense of a word, with the assumption that a sense has multiple concepts ( hc, hc + zipf ) ( chang, pei, and chen 2014 ) and that topics and senses should be inferred jointly ( stm )  #TAUTHOR_TAG.', 'in this paper, we also use a separate sense latent variable, however we show boost in performance by representing it with more versatility and by incorporating the use of targetneighbor pairs.', 'hc was also extended to a nonparametric model ( bnp - hc ) ( teh et al. 2004 ) in order to automatically set the number of senses of a word, providing flexibility to the sense granularity ( yao and van durme 2011 ; lau et al. 2012 ;.', 'in our experiments, we show that the sense granularity induced from nonparametric models are incorrect making the models less effective.', 'recent inclusions to the wsi models are neural - based dense distributional representation models.', 'stm also used word embeddings ( mikolov et al. 2013 ) to assign similarity weights during inference ( stm + w2v )  #TAUTHOR_TAG.', 'existing sense embeddings are also used to perform word sense induction ( crp - ppmi, se - wsi - fix, wg, dive ) ( song 2016 ; pelevina et al. 2016 ; chang et al. 2018 ).', 'these models, on their own, do not perform well on the wsi task until recently when embeddings of words and their dependencies are used to construct a probabilistic model ( mcc ) ( komninos and manandhar 2016 ).', 'we show that neuralbased embeddings are still ineffective for this task and that our model performs better than these models as well.', 'in the unsupervised author name disambiguation ( uand ) domain, lda - based models have']",0
"['is 3.', 'lda extensions  #TAUTHOR_TAG ; chang, pei, and chen 2014 )']","['is 3.', 'lda extensions  #TAUTHOR_TAG ; chang, pei, and chen 2014 )']","['is 3.', 'lda extensions  #TAUTHOR_TAG ; chang, pei, and chen 2014 )']","['are two reasons why latent dirichlet allocation ( lda ) ( blei, ng, and jordan 2003 ) is not effective for wsi.', 'first, lda tries to give instance assignments to all senses even when it is unnecessary.', 'for example, when the number of senses s is set to 10, the model tries to assign all the senses to all instances even when the original number of senses of a target word is 3.', 'lda extensions  #TAUTHOR_TAG ; chang, pei, and chen 2014 ) mitigated this problem by setting s to a small number ( e. g. 3 or 5 ).', 'however, this is not a good solution because there are many words with more than five senses.', 'second, lda and its extensions do not consider the existence of fine - grained senses.', 'for example, the cold : absence of heat and the cold : sensation from low temperature senses are fine - grained senses because they are similarly related to temperature yet have different usage']",0
"['local context, decided by a strict user - specified window  #TAUTHOR_TAG.', 'we improve by softening the strict local context assumption by introducing']","['local context, decided by a strict user - specified window  #TAUTHOR_TAG.', 'we improve by softening the strict local context assumption by introducing']","['within a local context, decided by a strict user - specified window  #TAUTHOR_TAG.', 'we improve by softening the strict local context assumption by introducing a switch variable which decides whether a word not in a local context']","['solve the problems above, we propose to extend lda in two parts.', 'first, we introduce a new latent variable, apart from the topic latent variable, to represent word senses.', 'previous works also attempted to introduce a separate sense latent variable to generate all the words ( chang, pei, and chen 2014 ), or to generate only the neighboring words within a local context, decided by a strict user - specified window  #TAUTHOR_TAG.', 'we improve by softening the strict local context assumption by introducing a switch variable which decides whether a word not in a local context should be generated by conditioning also on the sense latent variable.', 'our experiments show that our sense representation provides superior improvements from previous models.', '']",0
['chen 2014 ) and stm  #TAUTHOR_TAG mitigate'],['chen 2014 ) and stm  #TAUTHOR_TAG mitigated this problem by tuning'],['chen 2014 ) and stm  #TAUTHOR_TAG mitigate'],"['main weakness of lda when used on wsi task is the sense granularity problem.', 'recent models such as hc ( chang, pei, and chen 2014 ) and stm  #TAUTHOR_TAG mitigated this problem by tuning the number of senses hyperparameter s to minimize the error.', 'however, such tuning, often empirically set to a small number such as s = 3  #TAUTHOR_TAG, fails to infer varying number of senses of words, especially for words with a higher number of senses.', 'nonparametric models such as hdp and bnp - hc chang, pei, and chen 2014 ) claim to automatically induce different s for each word.', 'however, as shown in the results in table 2, the estimated s is far from the actual number of senses and both models are ineffective.', 'on the other hand, table 2 also shows that autosense is effective even when s is overestimated.', 'we explain why through an example result shown in table 3, where the target word is the verb book, the actual number of senses is three, and s is set to 15.', '']",0
"['global context.', 'following  #TAUTHOR_TAG,']","['global context.', 'following  #TAUTHOR_TAG,']","['global context.', 'following  #TAUTHOR_TAG,']","['', 'following  #TAUTHOR_TAG, we set the local context window to 10, with a maximum number of words of 21 ( i. e. 10 words before and 10 words after ).', 'other words are put into the global context.', 'note however that autosense has a less strict global / local context assumption as it treats some words in the global context as local depending on the switch variable.', 'parameter setting we set the hyperparameters to α = 0. 1, β = 0. 01, γ = 0. 3, following the conventional setup ( griffiths and steyvers 2004 ; chemudugunta, smyth, and steyvers 2006 ).', '']",5
"['global context.', 'following  #TAUTHOR_TAG,']","['global context.', 'following  #TAUTHOR_TAG,']","['global context.', 'following  #TAUTHOR_TAG,']","['', 'following  #TAUTHOR_TAG, we set the local context window to 10, with a maximum number of words of 21 ( i. e. 10 words before and 10 words after ).', 'other words are put into the global context.', 'note however that autosense has a less strict global / local context assumption as it treats some words in the global context as local depending on the switch variable.', 'parameter setting we set the hyperparameters to α = 0. 1, β = 0. 01, γ = 0. 3, following the conventional setup ( griffiths and steyvers 2004 ; chemudugunta, smyth, and steyvers 2006 ).', '']",5
"['global context.', 'following  #TAUTHOR_TAG,']","['global context.', 'following  #TAUTHOR_TAG,']","['global context.', 'following  #TAUTHOR_TAG,']","['', 'following  #TAUTHOR_TAG, we set the local context window to 10, with a maximum number of words of 21 ( i. e. 10 words before and 10 words after ).', 'other words are put into the global context.', 'note however that autosense has a less strict global / local context assumption as it treats some words in the global context as local depending on the switch variable.', 'parameter setting we set the hyperparameters to α = 0. 1, β = 0. 01, γ = 0. 3, following the conventional setup ( griffiths and steyvers 2004 ; chemudugunta, smyth, and steyvers 2006 ).', '']",5
"[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG,']","[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG, e ) word graph embeddings ( wg ), f )']","[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG,']","['model ( unimelb ) as reported in ( jurgens and klapaftis 2013 ), c ) sense - topic model stm, d ) stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG, e ) word graph embeddings ( wg ), f ) distributional inclusion vector embedding ( dive ) as reported in ( chang et al. 2018 ), and g ) multi context continuous model mcc as reported in ( kom', '##ninos and manandhar 2016 ). results are shown in table 2b. among the models, all versions', '']",5
"[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG,']","[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG, e ) word graph embeddings ( wg ), f )']","[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG,']","['model ( unimelb ) as reported in ( jurgens and klapaftis 2013 ), c ) sense - topic model stm, d ) stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG, e ) word graph embeddings ( wg ), f ) distributional inclusion vector embedding ( dive ) as reported in ( chang et al. 2018 ), and g ) multi context continuous model mcc as reported in ( kom', '##ninos and manandhar 2016 ). results are shown in table 2b. among the models, all versions', '']",5
"[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG,']","[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG, e ) word graph embeddings ( wg ), f )']","[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG,']","['model ( unimelb ) as reported in ( jurgens and klapaftis 2013 ), c ) sense - topic model stm, d ) stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG, e ) word graph embeddings ( wg ), f ) distributional inclusion vector embedding ( dive ) as reported in ( chang et al. 2018 ), and g ) multi context continuous model mcc as reported in ( kom', '##ninos and manandhar 2016 ). results are shown in table 2b. among the models, all versions', '']",5
"[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG,']","[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG, e ) word graph embeddings ( wg ), f )']","[') stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG,']","['model ( unimelb ) as reported in ( jurgens and klapaftis 2013 ), c ) sense - topic model stm, d ) stm with word2vec weights ( stm', '+ w2v ) as reported in  #TAUTHOR_TAG, e ) word graph embeddings ( wg ), f ) distributional inclusion vector embedding ( dive ) as reported in ( chang et al. 2018 ), and g ) multi context continuous model mcc as reported in ( kom', '##ninos and manandhar 2016 ). results are shown in table 2b. among the models, all versions', '']",5
['chen 2014 ) and stm  #TAUTHOR_TAG mitigate'],['chen 2014 ) and stm  #TAUTHOR_TAG mitigated this problem by tuning'],['chen 2014 ) and stm  #TAUTHOR_TAG mitigate'],"['main weakness of lda when used on wsi task is the sense granularity problem.', 'recent models such as hc ( chang, pei, and chen 2014 ) and stm  #TAUTHOR_TAG mitigated this problem by tuning the number of senses hyperparameter s to minimize the error.', 'however, such tuning, often empirically set to a small number such as s = 3  #TAUTHOR_TAG, fails to infer varying number of senses of words, especially for words with a higher number of senses.', 'nonparametric models such as hdp and bnp - hc chang, pei, and chen 2014 ) claim to automatically induce different s for each word.', 'however, as shown in the results in table 2, the estimated s is far from the actual number of senses and both models are ineffective.', 'on the other hand, table 2 also shows that autosense is effective even when s is overestimated.', 'we explain why through an example result shown in table 3, where the target word is the verb book, the actual number of senses is three, and s is set to 15.', '']",5
"['chen 2014 ) and stm  #TAUTHOR_TAG as baselines.', 'we']","['chen 2014 ) and stm  #TAUTHOR_TAG as baselines.', 'we']","['chen 2014 ) and stm  #TAUTHOR_TAG as baselines.', 'we do not compare with non - text feature - based models ( tang et al. 2012 ; cen']","['', 'the pubmed dataset contains 37 author names with a total of 2875 research papers as instances.', 'it includes the pubmed id of the papers authored by the given author name.', 'we extract the title, author list, publication venue, and abstract of each pubmed id from the pubmed website.', 'we use lda ( blei, ng, and jordan 2003 ), hc ( chang, pei, and chen 2014 ) and stm  #TAUTHOR_TAG as baselines.', 'we do not compare with non - text feature - based models ( tang et al. 2012 ; cen et al. 2013 ) because our goal is to compare sense topic models on a task where the sense granularities are more varied.', 'for stm and autosense, the title, publication venue and the author names are used as local']",5
"['.  #TAUTHOR_TAG found', 'significant group - level differences in pitch, jitter and shimmer']","['.  #TAUTHOR_TAG found', 'significant group - level differences in pitch, jitter and shimmer']","['advancement of artificial intelligence ( www. aaai. org )', '. all rights reserved. frequency words and topic words. litman et al.  #TAUTHOR_TAG found', 'significant group - level differences in pitch, jitter and shimmer']","['on high copyright c 2019, association for the advancement of artificial intelligence ( www. aaai. org )', '. all rights reserved. frequency words and topic words. litman et al.  #TAUTHOR_TAG found', 'significant group - level differences in pitch, jitter and shimmer between first and second halves of conversation. multiparty', '']",0
"['.  #TAUTHOR_TAG found', 'significant group - level differences in pitch, jitter and shimmer']","['.  #TAUTHOR_TAG found', 'significant group - level differences in pitch, jitter and shimmer']","['advancement of artificial intelligence ( www. aaai. org )', '. all rights reserved. frequency words and topic words. litman et al.  #TAUTHOR_TAG found', 'significant group - level differences in pitch, jitter and shimmer']","['on high copyright c 2019, association for the advancement of artificial intelligence ( www. aaai. org )', '. all rights reserved. frequency words and topic words. litman et al.  #TAUTHOR_TAG found', 'significant group - level differences in pitch, jitter and shimmer between first and second halves of conversation. multiparty', '']",6
"['freely available teams corpus  #TAUTHOR_TAG the corpus also includes survey data.', 'a pre - game survey collected personal information']","['freely available teams corpus  #TAUTHOR_TAG the corpus also includes survey data.', 'a pre - game survey collected personal information']","['freely available teams corpus  #TAUTHOR_TAG the corpus also includes survey data.', 'a pre - game survey collected personal information']","['freely available teams corpus  #TAUTHOR_TAG the corpus also includes survey data.', 'a pre - game survey collected personal information such as age, gender, and eight options for ethnicity.', 'while each participant could choose multiple options, in this paper we categorize each speaker into nine exclusive categories : caucasian ( 150 ), east asian ( 12 ), south asian ( 11 ), pacific islander ( 0 ), black ( 15 ), native american ( 0 ), hispanic ( 3 ), middle eastern ( 2 ), and multiple ethnicity ( 20 ) for participants who chose more than one of the other categories.', '']",5
['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within'],"['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first']","['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first and last three minutes, we used this finding to define our n. we evenly divided']","['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first and last three minutes, we used this finding to define our n. we evenly divided each game, which was limited to 30 minutes, into ten intervals, so each interval is less than three minutes. since our focus is on measure', 'development in this paper, methods for optimally tuning this temporal parameter are left for future work. we will', ""use figure 1's excerpt to illustrate our calculations. assuming"", 'n is set to two, we first divide the excer', '']",5
['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within'],"['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first']","['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first and last three minutes, we used this finding to define our n. we evenly divided']","['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first and last three minutes, we used this finding to define our n. we evenly divided each game, which was limited to 30 minutes, into ten intervals, so each interval is less than three minutes. since our focus is on measure', 'development in this paper, methods for optimally tuning this temporal parameter are left for future work. we will', ""use figure 1's excerpt to illustrate our calculations. assuming"", 'n is set to two, we first divide the excer', '']",5
['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within'],"['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first']","['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first and last three minutes, we used this finding to define our n. we evenly divided']","['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first and last three minutes, we used this finding to define our n. we evenly divided each game, which was limited to 30 minutes, into ten intervals, so each interval is less than three minutes. since our focus is on measure', 'development in this paper, methods for optimally tuning this temporal parameter are left for future work. we will', ""use figure 1's excerpt to illustrate our calculations. assuming"", 'n is set to two, we first divide the excer', '']",3
['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within'],"['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first']","['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first and last three minutes, we used this finding to define our n. we evenly divided']","['previously found that in the teams corpus the highest acoustic - prosodic convergence occurred within the', 'first and last three minutes, we used this finding to define our n. we evenly divided each game, which was limited to 30 minutes, into ten intervals, so each interval is less than three minutes. since our focus is on measure', 'development in this paper, methods for optimally tuning this temporal parameter are left for future work. we will', ""use figure 1's excerpt to illustrate our calculations. assuming"", 'n is set to two, we first divide the excer', '']",3
"["") account of  #TAUTHOR_TAG's process""]","[""paper gives an abstract categorial grammar ( acg ) account of  #TAUTHOR_TAG's process""]","["") account of  #TAUTHOR_TAG's process""]","[""paper gives an abstract categorial grammar ( acg ) account of  #TAUTHOR_TAG's process of transformation of the derivation trees of tree adjoining grammar ( tag ) into dependency trees."", 'we make explicit how the requirement of keeping a direct interpretation of dependency trees into strings results into lexical ambiguity.', 'since the acg framework has already been used to provide a logical semantics from tag derivation trees, we have a unified picture where derivation trees and dependency trees are related but independent equivalent ways to account for the same surface - meaning relation']",0
"['( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a']","['( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a']","[' #AUTHOR_TAG or using an encoding  #AUTHOR_TAG of tag into the acg framework ( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a transformation from standard derivation trees']","['adjoining grammars ( tag )  #AUTHOR_TAG is a tree grammar formalism relying on two operations between trees : substitution and adjunction.', 'in addition to the tree generated by a sequence of such operations, there is a derivation tree which records this sequence.', 'derivation trees soon appeared as good candidates to encode semantic - like relations between the elementary trees they glue together.', 'however, some mismatch between these trees and the relative scoping of logical connectives and relational symbols, or between these trees and the dependency relations, have been observed.', 'solving these problems often leads to modifications of derivation tree structures  #AUTHOR_TAG chen - main and joshi, to appear ).', 'while alternative proposals have succeeded in linking derivation trees to semantic representations using unification  #AUTHOR_TAG or using an encoding  #AUTHOR_TAG of tag into the acg framework ( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a transformation from standard derivation trees to dependency trees.', 'this paper provides an acg perspective on this transformation.', 'the goal is twofold.', 'first, it exhibits the underlying lexical blow up of the yield functions associated with the elementary trees in  #TAUTHOR_TAG.', 'second, using the same framework as  #AUTHOR_TAG allows us to have a shared perspective on a phrase - structure architecture and a dependency one and an equivalence on the surface - meaning relation they define']",0
"['( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a']","['( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a']","[' #AUTHOR_TAG or using an encoding  #AUTHOR_TAG of tag into the acg framework ( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a transformation from standard derivation trees']","['adjoining grammars ( tag )  #AUTHOR_TAG is a tree grammar formalism relying on two operations between trees : substitution and adjunction.', 'in addition to the tree generated by a sequence of such operations, there is a derivation tree which records this sequence.', 'derivation trees soon appeared as good candidates to encode semantic - like relations between the elementary trees they glue together.', 'however, some mismatch between these trees and the relative scoping of logical connectives and relational symbols, or between these trees and the dependency relations, have been observed.', 'solving these problems often leads to modifications of derivation tree structures  #AUTHOR_TAG chen - main and joshi, to appear ).', 'while alternative proposals have succeeded in linking derivation trees to semantic representations using unification  #AUTHOR_TAG or using an encoding  #AUTHOR_TAG of tag into the acg framework ( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a transformation from standard derivation trees to dependency trees.', 'this paper provides an acg perspective on this transformation.', 'the goal is twofold.', 'first, it exhibits the underlying lexical blow up of the yield functions associated with the elementary trees in  #TAUTHOR_TAG.', 'second, using the same framework as  #AUTHOR_TAG allows us to have a shared perspective on a phrase - structure architecture and a dependency one and an equivalence on the surface - meaning relation they define']",0
"['the details.', '3 the tag literature typically uses this example, and  #TAUTHOR_TAG as well, to show the mismatch between']","['the details.', '3 the tag literature typically uses this example, and  #TAUTHOR_TAG as well, to show the mismatch between']","['the details.', '3 the tag literature typically uses this example, and  #TAUTHOR_TAG as well, to show the mismatch between']","['fig. 1 shows, the encoding of tag into acg uses two acgs', 'we exemplify the encoding 2 of a tag analyzing ( 1 ) 3 1 in addition to defining l on the atomic types and on the constants of σ, we have :', ') with the proviso that for any constant c :', '2 we refer the reader to  #AUTHOR_TAG for the details.', '3 the tag literature typically uses this example, and  #TAUTHOR_TAG as well, to show the mismatch between the derivation trees and the expected se - this sentence is usually analyzed in tag with a derivation tree where the to love component scopes over all the other arguments, and where claims and seems are unrelated, as fig. 2 ( a ) shows.', 'the three higher - order signatures are : σ derθ : its atomic types include s, vp, np, s a, vp a... where the x types stand for the categories x of the nodes where a substitution can occur while the x a types stand for the categories x of the nodes where an adjunction can occur.', '']",0
"['the details.', '3 the tag literature typically uses this example, and  #TAUTHOR_TAG as well, to show the mismatch between']","['the details.', '3 the tag literature typically uses this example, and  #TAUTHOR_TAG as well, to show the mismatch between']","['the details.', '3 the tag literature typically uses this example, and  #TAUTHOR_TAG as well, to show the mismatch between']","['fig. 1 shows, the encoding of tag into acg uses two acgs', 'we exemplify the encoding 2 of a tag analyzing ( 1 ) 3 1 in addition to defining l on the atomic types and on the constants of σ, we have :', ') with the proviso that for any constant c :', '2 we refer the reader to  #AUTHOR_TAG for the details.', '3 the tag literature typically uses this example, and  #TAUTHOR_TAG as well, to show the mismatch between the derivation trees and the expected se - this sentence is usually analyzed in tag with a derivation tree where the to love component scopes over all the other arguments, and where claims and seems are unrelated, as fig. 2 ( a ) shows.', 'the three higher - order signatures are : σ derθ : its atomic types include s, vp, np, s a, vp a... where the x types stand for the categories x of the nodes where a substitution can occur while the x a types stand for the categories x of the nodes where an adjunction can occur.', '']",0
"['', 'according to  #TAUTHOR_TAG, such edge reversal']","['', 'according to  #TAUTHOR_TAG, such edge reversal']","['', 'according to  #TAUTHOR_TAG, such edge reversal']","['', 'according to  #TAUTHOR_TAG, such edge reversal is due to the fact that an edge between a complement taking adjunction ( cta ) and an initial tree has to be reversed, while the other edges remain unchanged.', '']",0
"['', 'according to  #TAUTHOR_TAG, such edge reversal']","['', 'according to  #TAUTHOR_TAG, such edge reversal']","['', 'according to  #TAUTHOR_TAG, such edge reversal']","['', 'according to  #TAUTHOR_TAG, such edge reversal is due to the fact that an edge between a complement taking adjunction ( cta ) and an initial tree has to be reversed, while the other edges remain unchanged.', '']",0
"['', 'according to  #TAUTHOR_TAG, such edge reversal']","['', 'according to  #TAUTHOR_TAG, such edge reversal']","['', 'according to  #TAUTHOR_TAG, such edge reversal']","['', 'according to  #TAUTHOR_TAG, such edge reversal is due to the fact that an edge between a complement taking adjunction ( cta ) and an initial tree has to be reversed, while the other edges remain unchanged.', '']",0
"[""##n '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified']","[""only in the dependency structures, we wouldn '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified']","[""##n '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified framework for the two - step process they propose, this lexical blow up will result in a multiplicity of types as section 5 shows']","['', '3 - tuple to a 3 - tuple. and yield dep', '( d', 'claims ) maps a 3 - tuple to a 1 - tuple of strings. we will mimic this behavior by introducing as many different non - terminal symbols for', ""the dependency structures in our acg setting. ( 2 ) a. john bill claims mary seems to love b. john mary seems to love ( 3 ) john bill seems to claim mary seems to love remark. were we not interested in the yields but only in the dependency structures, we wouldn '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified framework for the two - step process they propose, this lexical blow up will result in a multiplicity of types as section 5 shows']",0
"[""##n '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified']","[""only in the dependency structures, we wouldn '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified']","[""##n '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified framework for the two - step process they propose, this lexical blow up will result in a multiplicity of types as section 5 shows']","['', '3 - tuple to a 3 - tuple. and yield dep', '( d', 'claims ) maps a 3 - tuple to a 1 - tuple of strings. we will mimic this behavior by introducing as many different non - terminal symbols for', ""the dependency structures in our acg setting. ( 2 ) a. john bill claims mary seems to love b. john mary seems to love ( 3 ) john bill seems to claim mary seems to love remark. were we not interested in the yields but only in the dependency structures, we wouldn '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified framework for the two - step process they propose, this lexical blow up will result in a multiplicity of types as section 5 shows']",0
"['.', ""6 this really mimics  #AUTHOR_TAG's encoding of  #TAUTHOR_TAG mtt rules :... are designed in""]","['no adjunction occurs.', ""6 this really mimics  #AUTHOR_TAG's encoding of  #TAUTHOR_TAG mtt rules :... are designed in""]","['no adjunction occurs.', ""6 this really mimics  #AUTHOR_TAG's encoding of  #TAUTHOR_TAG mtt rules :... are designed in""]","['order to encode the mtt acting on derivation trees, we introduce a new abstract vocabulary σ derθ for disambiguated derivation trees as in  #AUTHOR_TAG to love is used to model sentences where both adjunctions are performed into γ to love.', 'c 10 to love and c 01 to love are used for sentences where only one adjunction at the s or at the vp node occurs respectively.', 'c 00 to love : np np s is used when no adjunction occurs.', ""6 this really mimics  #AUTHOR_TAG's encoding of  #TAUTHOR_TAG mtt rules :... are designed in order to indicate that a given adjunction has n adjunctions above it ( i. e. which scope over it )."", 'the superscripts ( 2 ( n + 1 ) ) ( 2 ( n − 1 ) ) express that an adjunction that has n adjunctions above it is translated as a function that takes a 2 ( n + 1 ) - tuple as argument and returns a 2 ( n − 1 ) - tuple.', 'to model auxiliary trees which are ctas we need a different strategy.', '']",0
['proposed in  #TAUTHOR_TAG'],['proposed in  #TAUTHOR_TAG'],"['proposed in  #TAUTHOR_TAG.', '']","['this paper, we have given an acg perspective on the transformation of the derivation trees of tag to the dependency trees proposed in  #TAUTHOR_TAG.', '']",0
['proposed in  #TAUTHOR_TAG'],['proposed in  #TAUTHOR_TAG'],"['proposed in  #TAUTHOR_TAG.', '']","['this paper, we have given an acg perspective on the transformation of the derivation trees of tag to the dependency trees proposed in  #TAUTHOR_TAG.', '']",0
['proposed in  #TAUTHOR_TAG'],['proposed in  #TAUTHOR_TAG'],"['proposed in  #TAUTHOR_TAG.', '']","['this paper, we have given an acg perspective on the transformation of the derivation trees of tag to the dependency trees proposed in  #TAUTHOR_TAG.', '']",0
"['( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a']","['( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a']","[' #AUTHOR_TAG or using an encoding  #AUTHOR_TAG of tag into the acg framework ( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a transformation from standard derivation trees']","['adjoining grammars ( tag )  #AUTHOR_TAG is a tree grammar formalism relying on two operations between trees : substitution and adjunction.', 'in addition to the tree generated by a sequence of such operations, there is a derivation tree which records this sequence.', 'derivation trees soon appeared as good candidates to encode semantic - like relations between the elementary trees they glue together.', 'however, some mismatch between these trees and the relative scoping of logical connectives and relational symbols, or between these trees and the dependency relations, have been observed.', 'solving these problems often leads to modifications of derivation tree structures  #AUTHOR_TAG chen - main and joshi, to appear ).', 'while alternative proposals have succeeded in linking derivation trees to semantic representations using unification  #AUTHOR_TAG or using an encoding  #AUTHOR_TAG of tag into the acg framework ( de  #AUTHOR_TAG, only recently  #TAUTHOR_TAG has proposed a transformation from standard derivation trees to dependency trees.', 'this paper provides an acg perspective on this transformation.', 'the goal is twofold.', 'first, it exhibits the underlying lexical blow up of the yield functions associated with the elementary trees in  #TAUTHOR_TAG.', 'second, using the same framework as  #AUTHOR_TAG allows us to have a shared perspective on a phrase - structure architecture and a dependency one and an equivalence on the surface - meaning relation they define']",1
"[""##n '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified']","[""only in the dependency structures, we wouldn '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified']","[""##n '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified framework for the two - step process they propose, this lexical blow up will result in a multiplicity of types as section 5 shows']","['', '3 - tuple to a 3 - tuple. and yield dep', '( d', 'claims ) maps a 3 - tuple to a 1 - tuple of strings. we will mimic this behavior by introducing as many different non - terminal symbols for', ""the dependency structures in our acg setting. ( 2 ) a. john bill claims mary seems to love b. john mary seems to love ( 3 ) john bill seems to claim mary seems to love remark. were we not interested in the yields but only in the dependency structures, we wouldn '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified framework for the two - step process they propose, this lexical blow up will result in a multiplicity of types as section 5 shows']",1
"[""##n '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified']","[""only in the dependency structures, we wouldn '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified']","[""##n '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified framework for the two - step process they propose, this lexical blow up will result in a multiplicity of types as section 5 shows']","['', '3 - tuple to a 3 - tuple. and yield dep', '( d', 'claims ) maps a 3 - tuple to a 1 - tuple of strings. we will mimic this behavior by introducing as many different non - terminal symbols for', ""the dependency structures in our acg setting. ( 2 ) a. john bill claims mary seems to love b. john mary seems to love ( 3 ) john bill seems to claim mary seems to love remark. were we not interested in the yields but only in the dependency structures, we wouldn '"", ""t have to manage this ambiguity. this is true both for  #TAUTHOR_TAG's approach and ours"", '. but as we have here a unified framework for the two - step process they propose, this lexical blow up will result in a multiplicity of types as section 5 shows']",3
"[', and some understanding of the impact of flattening trees can be had in', ' #TAUTHOR_TAG, where the beneficial']","[', and some understanding of the impact of flattening trees can be had in', ' #TAUTHOR_TAG, where the beneficial']","['based language models that are chosen to represent robust approaches in the comparison. beyond language modeling,', 'methods for pcfg induction from treebanks have been a popular topic in the field over the past decade, and some understanding of the impact of flattening trees can be had in', ' #TAUTHOR_TAG, where the beneficial impact of various tree transformations for probabilistic grammars is presented']","['', 'methods for pcfg induction from treebanks have been a popular topic in the field over the past decade, and some understanding of the impact of flattening trees can be had in', ' #TAUTHOR_TAG, where the beneficial impact of various tree transformations for probabilistic grammars is presented. none of this work is discussed or cited, and the naive reader might be left with the impression that data - driven approaches have been demonstrated to under', '##perform relative to knowledge - based approaches, when in fact the authors simply demonstrate that their hybrid grammar - based / data - driven approach outperforms class - based language models. perhaps this is worth demonstrating', "", but the chapter couches the results within the context of a clash between paradigms, which simply does not ring true. this one misstep, however, does not detract from the quality of the authors'system, nor from the interesting presentation of too - often - ignored aspects of spoken language systems engineering. the book and the toolkit it describes can serve a very useful pedagogical purpose by providing a foundation upon which students and""]",0
"[', and some understanding of the impact of flattening trees can be had in', ' #TAUTHOR_TAG, where the beneficial']","[', and some understanding of the impact of flattening trees can be had in', ' #TAUTHOR_TAG, where the beneficial']","['based language models that are chosen to represent robust approaches in the comparison. beyond language modeling,', 'methods for pcfg induction from treebanks have been a popular topic in the field over the past decade, and some understanding of the impact of flattening trees can be had in', ' #TAUTHOR_TAG, where the beneficial impact of various tree transformations for probabilistic grammars is presented']","['', 'methods for pcfg induction from treebanks have been a popular topic in the field over the past decade, and some understanding of the impact of flattening trees can be had in', ' #TAUTHOR_TAG, where the beneficial impact of various tree transformations for probabilistic grammars is presented. none of this work is discussed or cited, and the naive reader might be left with the impression that data - driven approaches have been demonstrated to under', '##perform relative to knowledge - based approaches, when in fact the authors simply demonstrate that their hybrid grammar - based / data - driven approach outperforms class - based language models. perhaps this is worth demonstrating', "", but the chapter couches the results within the context of a clash between paradigms, which simply does not ring true. this one misstep, however, does not detract from the quality of the authors'system, nor from the interesting presentation of too - often - ignored aspects of spoken language systems engineering. the book and the toolkit it describes can serve a very useful pedagogical purpose by providing a foundation upon which students and""]",1
"[' #AUTHOR_TAG, cnn  #TAUTHOR_TAG gan  #AUTHOR_TAG and vae are introduced', '']","[' #AUTHOR_TAG, cnn  #TAUTHOR_TAG gan  #AUTHOR_TAG and vae are introduced', '']","['- sequence learning  #AUTHOR_TAG, cnn  #TAUTHOR_TAG gan  #AUTHOR_TAG and vae are introduced', '. the coffee break is']","['', 'natural language understanding, statistical modeling and deep neural network and explain the key issues in deep bayesian learning for discrete - valued observation data and', 'latent semantics. a new paradigm called the symbolic neural learning is introduced to extend how data analysis is performed from language processing to semantic learning and memory networking. secondly, we address a number of bayesian models ranging from latent variable model to vb inference  #AUTHOR_TAG b ), mcmc sampling  #AUTHOR_TAG and bnp learning  #AUTHOR_TAG a ;  #AUTHOR_TAG for hierarchical, thematic and sparse topics from natural language. in the third part, a series of deep models including deep unfolding  #AUTHOR_TAG, bayesian rnn  #AUTHOR_TAG, sequence - to - sequence learning  #AUTHOR_TAG, cnn  #TAUTHOR_TAG gan  #AUTHOR_TAG and vae are introduced', '']",0
"['of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large']","['of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large']","['- aligned parallel corpora of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large corpora']","['simplification is the task of automatically rewriting a text by substituting words or phrases with simpler variants, while retaining its meaning and grammaticality.', 'the goal is to make the text easier to understand for children, language learners, people with cognitive disabilities and even machines.', 'approaches to lexical simplification generally follow a standard pipeline consisting of two main steps : generation and ranking.', 'in the generation step, a set of possible substitutions for the target word is commonly created by querying semantic databases such as wordnet  #AUTHOR_TAG, learning substitution rules from sentence - aligned parallel corpora of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large corpora to obtain similar words of the complex word ( glavas andstajner, 2015 ;  #AUTHOR_TAG a, 2017 ).', 'in the ranking step, features that discriminate a substitution candidate from other substitution candidates are leveraged and the candidates are ranked with respect to their simplicity and contextual fitness.', '* this research was conducted while the first author was a post doctoral fellow at the city university of hong kong.', 'the ranking step is challenging because the substitution candidates usually have similar meaning to the target word, and thus share similar context features.', 'state - of - the - art approaches to ranking in lexical simplification exploit supervised machine learning - based methods that rely mostly on surface features, such as word frequency, word length and n - gram probability, for training the model  #TAUTHOR_TAG ; bingel and søgaard, 2016 ;  #AUTHOR_TAG a, 2017 ).', 'moreover, deep architectures are not explored in these models.', 'surface features and shallow architectures might not be able to explore the features at different levels of abstractions that capture nuances that discriminate the candidates.', 'in this paper, we propose to use a deep structured similarity model ( dssm )  #AUTHOR_TAG to rank substitution candidates.', 'the dssm exploits a deep architecture by using a deep neural network ( dnn ), that can effectively capture contextual features to perform semantic matching between two sentences.', 'it has been successfully applied to several natural language processing ( nlp ) tasks, such as machine translation, web search ranking  #AUTHOR_TAG, question answering, and image captioning  #AUTHOR_TAG.', 'to the best of our knowledge, this is the first time this model is applied to lexical simplification.', 'we adapt the original dssm architecture and objective function to our specific task.', 'our evaluation on two standard datasets for lexical simplification shows that this method outperforms state - of - the - art approaches that use supervised machine learning - based methods']",0
"['of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large']","['of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large']","['- aligned parallel corpora of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large corpora']","['simplification is the task of automatically rewriting a text by substituting words or phrases with simpler variants, while retaining its meaning and grammaticality.', 'the goal is to make the text easier to understand for children, language learners, people with cognitive disabilities and even machines.', 'approaches to lexical simplification generally follow a standard pipeline consisting of two main steps : generation and ranking.', 'in the generation step, a set of possible substitutions for the target word is commonly created by querying semantic databases such as wordnet  #AUTHOR_TAG, learning substitution rules from sentence - aligned parallel corpora of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large corpora to obtain similar words of the complex word ( glavas andstajner, 2015 ;  #AUTHOR_TAG a, 2017 ).', 'in the ranking step, features that discriminate a substitution candidate from other substitution candidates are leveraged and the candidates are ranked with respect to their simplicity and contextual fitness.', '* this research was conducted while the first author was a post doctoral fellow at the city university of hong kong.', 'the ranking step is challenging because the substitution candidates usually have similar meaning to the target word, and thus share similar context features.', 'state - of - the - art approaches to ranking in lexical simplification exploit supervised machine learning - based methods that rely mostly on surface features, such as word frequency, word length and n - gram probability, for training the model  #TAUTHOR_TAG ; bingel and søgaard, 2016 ;  #AUTHOR_TAG a, 2017 ).', 'moreover, deep architectures are not explored in these models.', 'surface features and shallow architectures might not be able to explore the features at different levels of abstractions that capture nuances that discriminate the candidates.', 'in this paper, we propose to use a deep structured similarity model ( dssm )  #AUTHOR_TAG to rank substitution candidates.', 'the dssm exploits a deep architecture by using a deep neural network ( dnn ), that can effectively capture contextual features to perform semantic matching between two sentences.', 'it has been successfully applied to several natural language processing ( nlp ) tasks, such as machine translation, web search ranking  #AUTHOR_TAG, question answering, and image captioning  #AUTHOR_TAG.', 'to the best of our knowledge, this is the first time this model is applied to lexical simplification.', 'we adapt the original dssm architecture and objective function to our specific task.', 'our evaluation on two standard datasets for lexical simplification shows that this method outperforms state - of - the - art approaches that use supervised machine learning - based methods']",0
"['of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large']","['of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large']","['- aligned parallel corpora of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large corpora']","['simplification is the task of automatically rewriting a text by substituting words or phrases with simpler variants, while retaining its meaning and grammaticality.', 'the goal is to make the text easier to understand for children, language learners, people with cognitive disabilities and even machines.', 'approaches to lexical simplification generally follow a standard pipeline consisting of two main steps : generation and ranking.', 'in the generation step, a set of possible substitutions for the target word is commonly created by querying semantic databases such as wordnet  #AUTHOR_TAG, learning substitution rules from sentence - aligned parallel corpora of complex - simple texts  #TAUTHOR_TAG, and learning word embeddings from a large corpora to obtain similar words of the complex word ( glavas andstajner, 2015 ;  #AUTHOR_TAG a, 2017 ).', 'in the ranking step, features that discriminate a substitution candidate from other substitution candidates are leveraged and the candidates are ranked with respect to their simplicity and contextual fitness.', '* this research was conducted while the first author was a post doctoral fellow at the city university of hong kong.', 'the ranking step is challenging because the substitution candidates usually have similar meaning to the target word, and thus share similar context features.', 'state - of - the - art approaches to ranking in lexical simplification exploit supervised machine learning - based methods that rely mostly on surface features, such as word frequency, word length and n - gram probability, for training the model  #TAUTHOR_TAG ; bingel and søgaard, 2016 ;  #AUTHOR_TAG a, 2017 ).', 'moreover, deep architectures are not explored in these models.', 'surface features and shallow architectures might not be able to explore the features at different levels of abstractions that capture nuances that discriminate the candidates.', 'in this paper, we propose to use a deep structured similarity model ( dssm )  #AUTHOR_TAG to rank substitution candidates.', 'the dssm exploits a deep architecture by using a deep neural network ( dnn ), that can effectively capture contextual features to perform semantic matching between two sentences.', 'it has been successfully applied to several natural language processing ( nlp ) tasks, such as machine translation, web search ranking  #AUTHOR_TAG, question answering, and image captioning  #AUTHOR_TAG.', 'to the best of our knowledge, this is the first time this model is applied to lexical simplification.', 'we adapt the original dssm architecture and objective function to our specific task.', 'our evaluation on two standard datasets for lexical simplification shows that this method outperforms state - of - the - art approaches that use supervised machine learning - based methods']",1
"['ranking in lexical simplification  #TAUTHOR_TAG, which contains 500 instances composed of a']","['ranking in lexical simplification  #TAUTHOR_TAG, which contains 500 instances composed of a sentence,']","['ranking in lexical simplification  #TAUTHOR_TAG, which contains 500 instances composed of a sentence,']","['previous works that used supervised machine learning for ranking in lexical simplification  #TAUTHOR_TAG, which contains 500 instances composed of a sentence, a target word and substitution candidates ranked by simplicity  #AUTHOR_TAG.', 'in order to learn the parameters w t and w s ( figure 1 ) of the dssm, we use the standard backpropagation algorithm  #AUTHOR_TAG.', 'the objective used in this paper follows the pair - wise learning - to - rank paradigm outlined in  #AUTHOR_TAG.', 'given a target word and its sentential context t, we obtain a list of candidates l. we set different positive values to the candidates based on their simplicity rankings.', 'e. g., if the list of the candidates is ordered by simplificity as, l = { a + > b + > c + }, the labels are first constructed as l = { y a + = 3, y b + = 2, y c + = 1 }. the values are then normalized by dividing by the maximum value in the list : l = { y a + = 1, y b + = 0. 667, y c + = 0. 333 }. if the target word was not originally in l, we add it with label 0.', 'this enables the model to reflect the label information in the similarity scores.', 'we minimize the bayesian expected loss as :', 'note that p ( s l | t ) is computed as :', 'here, γ is a tuning factor.', 'we used 5 - cross validation approach to select hyper - parameters, such as number of hidden nodes.', 'we set the gamma factor as 10 as per  #AUTHOR_TAG.', 'the selected hyperparameters were used to train the model in the whole lexmturk dataset.', 'we employ earlystopping and select the model whose change of the average loss in each epoch was smaller than 1. 0e - 3.', 'since the training data is small ( only 500 samples ) we use a smaller number of hidden nodes, d = 32, in the nonlinear projection layer and adopt a higher dropout rate ( 0. 4 ).', 'the model is optimized using adam  #AUTHOR_TAG with the learning rate fixed at 0. 001, and is trained for 30 epochs.', 'the mini - batch is set to 16 during training']",5
"[' #TAUTHOR_TAG, which we use']","[' #TAUTHOR_TAG, which we use']","['contain instances from the lexmturk dataset  #TAUTHOR_TAG, which we use']","['evaluate the proposed model, we conduct experiments on two common datasets for lexical simplification : benchls  #AUTHOR_TAG b ), which contains 929 instances, and nnseval  #AUTHOR_TAG a ), which contains 239 instances.', 'each instance is composed of a sentence, a target word, and a set of gold candidates ranked by simplicity  #AUTHOR_TAG.', 'since both datasets contain instances from the lexmturk dataset  #TAUTHOR_TAG, which we use for training the dnn, we remove the overlap instances between training and test datasets 1.', 'we finally obtain 429 remaining instances in the benchls dataset, and 78 instances in the nneval dataset, which are used in our evaluation.', 'we adopt the same evaluation metrics featured in glavas andstajner ( 2015 ) and  #TAUTHOR_TAG : 1 ) precision : ratio of correct simplifications out of all the simplifications made by the system ; 2 ) accuracy : ratio of correct simplifications out of all words that should have been simplified ; and 3 ) changed : ratio of target words changed by the system']",5
"[' #TAUTHOR_TAG, which we use']","[' #TAUTHOR_TAG, which we use']","['contain instances from the lexmturk dataset  #TAUTHOR_TAG, which we use']","['evaluate the proposed model, we conduct experiments on two common datasets for lexical simplification : benchls  #AUTHOR_TAG b ), which contains 929 instances, and nnseval  #AUTHOR_TAG a ), which contains 239 instances.', 'each instance is composed of a sentence, a target word, and a set of gold candidates ranked by simplicity  #AUTHOR_TAG.', 'since both datasets contain instances from the lexmturk dataset  #TAUTHOR_TAG, which we use for training the dnn, we remove the overlap instances between training and test datasets 1.', 'we finally obtain 429 remaining instances in the benchls dataset, and 78 instances in the nneval dataset, which are used in our evaluation.', 'we adopt the same evaluation metrics featured in glavas andstajner ( 2015 ) and  #TAUTHOR_TAG : 1 ) precision : ratio of correct simplifications out of all the simplifications made by the system ; 2 ) accuracy : ratio of correct simplifications out of all words that should have been simplified ; and 3 ) changed : ratio of target words changed by the system']",5
"['described in  #TAUTHOR_TAG.', 'all the']","['described in  #TAUTHOR_TAG.', 'all the']","['described in  #TAUTHOR_TAG.', 'all the three models employ the n - gram probability features']","['', 'we reimplement their model as part of the lexenstein toolkit  #AUTHOR_TAG.', 'the network has 3 hidden layers with 8 nodes each.', 'unlike the proposed model, they treat ranking in lexical simplification as a standard classification problem.', 'the second baseline is svm rank  #AUTHOR_TAG table 1 : substitution candidates ranking results.', 'n - gram probs.', 'denotes the n - gram probability features described in  #AUTHOR_TAG, and all denotes all features described in section 2. 3.', 'all values marked in bold are significantly higher compared to the best baseline, svm rank, measured by t - test at p - value of 0. 05.', 'with default parameters ) for ranking substitution candidates, similar to the method described in  #TAUTHOR_TAG.', 'all the three models employ the n - gram probability features extracted from the subimdb corpus  #AUTHOR_TAG, as described in  #AUTHOR_TAG, and are trained using the lexmturk dataset']",3
['from existing literature  #TAUTHOR_TAG which suggest that if'],['from existing literature  #TAUTHOR_TAG which suggest that if'],"['the source and target collections.', 'this is based on the observations from existing literature  #TAUTHOR_TAG which suggest that if the source']","['social media analytics, especially for sentiment categorization, there exist numerous collections about different products or services where labeled data is available and thus can be used to adapt to a new unlabeled collection.', 'given a target collection, the key question is to identify the best possible source collection to adapt from.', 'the similarity module in soda identifies the best adaptable source collection based on the similarity between the source and target collections.', 'this is based on the observations from existing literature  #TAUTHOR_TAG which suggest that if the source and target collections are similar, the adaptation performance tends to be better than if the two collections are dissimilar.', 'the similarity module in soda is capable of computing different kinds of lexical, syntactic, and semantic similarities between unlabeled target and labeled source collections.', 'for this demonstration on sentiment categorization from social media data, it measures cosine similarity between the comments in each collection and computes sim as the similarity score']",5
"['learns shared common representation  #TAUTHOR_TAG which minimizes the divergence between two collections.', 'we leverage one of the widely used structural correspondence']","['learns shared common representation  #TAUTHOR_TAG which minimizes the divergence between two collections.', 'we leverage one of the widely used structural correspondence']","['works on two principles, generalization and adaptation.', 'during generalization, it learns shared common representation  #TAUTHOR_TAG which minimizes the divergence between two collections.', 'we leverage one of the widely used structural correspondence learning ( scl ) approach  #TAUTHOR_TAG to compute shared representations.', 'the idea adhered here is that a model']","['heart of soda is the adaptation module that works on two principles, generalization and adaptation.', 'during generalization, it learns shared common representation  #TAUTHOR_TAG which minimizes the divergence between two collections.', 'we leverage one of the widely used structural correspondence learning ( scl ) approach  #TAUTHOR_TAG to compute shared representations.', '']",5
"['learns shared common representation  #TAUTHOR_TAG which minimizes the divergence between two collections.', 'we leverage one of the widely used structural correspondence']","['learns shared common representation  #TAUTHOR_TAG which minimizes the divergence between two collections.', 'we leverage one of the widely used structural correspondence']","['works on two principles, generalization and adaptation.', 'during generalization, it learns shared common representation  #TAUTHOR_TAG which minimizes the divergence between two collections.', 'we leverage one of the widely used structural correspondence learning ( scl ) approach  #TAUTHOR_TAG to compute shared representations.', 'the idea adhered here is that a model']","['heart of soda is the adaptation module that works on two principles, generalization and adaptation.', 'during generalization, it learns shared common representation  #TAUTHOR_TAG which minimizes the divergence between two collections.', 'we leverage one of the widely used structural correspondence learning ( scl ) approach  #TAUTHOR_TAG to compute shared representations.', '']",5
[' #TAUTHOR_TAG which is a benchmark'],[' #TAUTHOR_TAG which is a benchmark'],['on the amazon review dataset  #TAUTHOR_TAG which is a benchmark dataset'],"['', 'we also evaluated the performance of domain adaptation ( da ) module of soda on the amazon review dataset  #TAUTHOR_TAG which is a benchmark dataset for sentiment categorization.', 'it has 4 domains, namely, books ( b ), dvds ( d ), electronics ( e ), and kitchen ( k ) each with 2000 reviews divided equally into positive and negative reviews.', 'table 2 shows that da module of soda outperforms 1 ) a widely used domain adaptation technique, namely, structural correspondence learning ( scl )  #TAUTHOR_TAG, 2 ) the baseline ( bl ) where a classifier trained on one domain is applied on another domain, and 3 ) the in - domain classifier.', 'note that in table 2, the performance of da module of soda is reported when it does not use any labeled instances from the target domain']",5
[' #TAUTHOR_TAG which is a benchmark'],[' #TAUTHOR_TAG which is a benchmark'],['on the amazon review dataset  #TAUTHOR_TAG which is a benchmark dataset'],"['', 'we also evaluated the performance of domain adaptation ( da ) module of soda on the amazon review dataset  #TAUTHOR_TAG which is a benchmark dataset for sentiment categorization.', 'it has 4 domains, namely, books ( b ), dvds ( d ), electronics ( e ), and kitchen ( k ) each with 2000 reviews divided equally into positive and negative reviews.', 'table 2 shows that da module of soda outperforms 1 ) a widely used domain adaptation technique, namely, structural correspondence learning ( scl )  #TAUTHOR_TAG, 2 ) the baseline ( bl ) where a classifier trained on one domain is applied on another domain, and 3 ) the in - domain classifier.', 'note that in table 2, the performance of da module of soda is reported when it does not use any labeled instances from the target domain']",4
['- art models  #TAUTHOR_TAG have demonstrated large'],"['specified by the instruction ( e. g. the mirror ).', 'recent state - of - the - art models  #TAUTHOR_TAG have demonstrated large']","['g. the mirror ).', 'recent state - of - the - art models  #TAUTHOR_TAG have demonstrated large gains in accuracy on the vln task.', 'however, it is unclear']","['vision - and - language navigation ( vln ) task  #AUTHOR_TAG requires an agent to navigate to a particular location in a real - world environment, following complex, context - dependent instructions written by humans ( e. g. go down the second hallway on the left, enter the bedroom and stop by the mirror ).', 'the agent must navigate through the environment, conditioning on the instruction as well as the visual imagery that it observes along the route, to stop at the location specified by the instruction ( e. g. the mirror ).', 'recent state - of - the - art models  #TAUTHOR_TAG have demonstrated large gains in accuracy on the vln task.', 'however, it is unclear which modality these go past the couch [UNK] figure 1 : we factor the grounding of language instructions into visual appearance, route structure, and object detections using a mixture - of - experts approach.', 'substantial increases in task metrics can be attributed to, and, in particular, whether the gains in performance are due to stronger grounding into visual context or e. g. simply into the discrete, geometric structure of possible routes, such as turning left or moving forward ( see fig.']",0
"['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['', 'different model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes. unseen split of novel environments. since we aim', 'to evaluate how well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split', '. 2 the results are shown in table 1. in each block, the two rows show the', 'agent\'s performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn ""', ': resnet - 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and', '3 ) outperforms the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent', '( lines 6 and 8 ). this indicates that these models do not learn general', '##izable visual perception, so that the visual features may actually hurt them in unse', '##en environments']",1
"['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['', 'different model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes. unseen split of novel environments. since we aim', 'to evaluate how well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split', '. 2 the results are shown in table 1. in each block, the two rows show the', 'agent\'s performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn ""', ': resnet - 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and', '3 ) outperforms the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent', '( lines 6 and 8 ). this indicates that these models do not learn general', '##izable visual perception, so that the visual features may actually hurt them in unse', '##en environments']",3
"['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['', 'different model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes. unseen split of novel environments. since we aim', 'to evaluate how well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split', '. 2 the results are shown in table 1. in each block, the two rows show the', 'agent\'s performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn ""', ': resnet - 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and', '3 ) outperforms the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent', '( lines 6 and 8 ). this indicates that these models do not learn general', '##izable visual perception, so that the visual features may actually hurt them in unse', '##en environments']",3
['visual attention mechanism as in  #TAUTHOR_TAG'],['visual attention mechanism as in  #TAUTHOR_TAG'],['use the same visual attention mechanism as in  #TAUTHOR_TAG'],"['', ""each vector x obj, j ( j - th detected object in the scene ) is a concatenation of summed glove vectors  #AUTHOR_TAG for the detected object label ( e. g. door ) and attribute labels ( e. g. white ) and a location vector from the object's bounding box coordinates."", 'we then use the same visual attention mechanism as in  #TAUTHOR_TAG and  #AUTHOR_TAG to obtain an attended object representation x obj, att over these { x obj, j } vectors.', 'we either substitute the resnet cnn features x img, att ( "" rn "" ) with our object representation x obj, att ( "" obj "" ), or concatenate x img, att and x obj, att ( "" rn + obj "" ).', 'then we train the sf model or the sm model using this object representation, with results shown in table 2. 3 for sf ( lines 1 - 4 ), object representations substantially improve generalization ability : using either the object representation ( "" obj "" ) or the combined representation ( "" rn + obj "" ) obtains higher success rate on unseen environments than using only the']",3
[') model  #TAUTHOR_TAG and'],['( sf ) model  #TAUTHOR_TAG and'],[') model  #TAUTHOR_TAG and the self - monitoring ( sm ) model  #AUTHOR_TAG which we analyze both use sequence'],"['speaker - follower ( sf ) model  #TAUTHOR_TAG and the self - monitoring ( sm ) model  #AUTHOR_TAG which we analyze both use sequenceto - sequence model  #AUTHOR_TAG with attention  #AUTHOR_TAG as their base instruction - following agent.', 'both use an encoder lstm  #AUTHOR_TAG to represent the instruction text, and a decoder lstm to predict actions sequentially.', '']",3
"['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['', 'different model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes. unseen split of novel environments. since we aim', 'to evaluate how well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split', '. 2 the results are shown in table 1. in each block, the two rows show the', 'agent\'s performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn ""', ': resnet - 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and', '3 ) outperforms the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent', '( lines 6 and 8 ). this indicates that these models do not learn general', '##izable visual perception, so that the visual features may actually hurt them in unse', '##en environments']",5
['visual attention mechanism as in  #TAUTHOR_TAG'],['visual attention mechanism as in  #TAUTHOR_TAG'],['use the same visual attention mechanism as in  #TAUTHOR_TAG'],"['', ""each vector x obj, j ( j - th detected object in the scene ) is a concatenation of summed glove vectors  #AUTHOR_TAG for the detected object label ( e. g. door ) and attribute labels ( e. g. white ) and a location vector from the object's bounding box coordinates."", 'we then use the same visual attention mechanism as in  #TAUTHOR_TAG and  #AUTHOR_TAG to obtain an attended object representation x obj, att over these { x obj, j } vectors.', 'we either substitute the resnet cnn features x img, att ( "" rn "" ) with our object representation x obj, att ( "" obj "" ), or concatenate x img, att and x obj, att ( "" rn + obj "" ).', 'then we train the sf model or the sm model using this object representation, with results shown in table 2. 3 for sf ( lines 1 - 4 ), object representations substantially improve generalization ability : using either the object representation ( "" obj "" ) or the combined representation ( "" rn + obj "" ) obtains higher success rate on unseen environments than using only the']",5
"['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['', 'different model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes. unseen split of novel environments. since we aim', 'to evaluate how well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split', '. 2 the results are shown in table 1. in each block, the two rows show the', 'agent\'s performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn ""', ': resnet - 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and', '3 ) outperforms the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent', '( lines 6 and 8 ). this indicates that these models do not learn general', '##izable visual perception, so that the visual features may actually hurt them in unse', '##en environments']",4
"['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes']","['', 'different model architectures ( speakerfollower ( sf )  #TAUTHOR_TAG and', 'self - monitoring ( sm )  #AUTHOR_TAG ) and training schemes. unseen split of novel environments. since we aim', 'to evaluate how well the agents generalize to the unseen environments, we focus on the val - unseen split. for both the sf and sm models, we train two versions of the agents, using either the studentforcing or teacher - forcing approaches of  #AUTHOR_TAG 1, and select the best training snapshot on the val - seen split', '. 2 the results are shown in table 1. in each block, the two rows show the', 'agent\'s performance ( under the specific model architecture and training approach ) with or without access to the visual features ( "" rn ""', ': resnet - 152 network  #AUTHOR_TAG, "" no vis. "" : non - visual ). while visual features improve performance on environments seen during training, we see that for the sf architecture the non - visual agent ( lines 1 and', '3 ) outperforms the visual agent ( lines 2 and 4 ) on unseen environments under both studentforcing and teacher - forcing training. for sm, the non - visual agent ( lines 5 and 7 ) has a success rate very close to the visual agent', '( lines 6 and 8 ). this indicates that these models do not learn general', '##izable visual perception, so that the visual features may actually hurt them in unse', '##en environments']",6
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[', has started to receive scholarly attention  #TAUTHOR_TAG.', 'we assume']","['', 'however, recently the reverse process, i. e. the generation of texts from amrs, has started to receive scholarly attention  #TAUTHOR_TAG.', 'we assume that in practical applications, conceptualisation models or dialogue managers ( models which decide "" what to say "" ) output amrs.', 'in this paper we study different ways in which these amrs can be converted into natural language ( deciding "" how to say it "" ).', 'we approach this as a translation problem - automatically translating from amrs into natural language - and the keycontribution of this paper is that we systematically compare different preprocessing strategies for two different mt systems : phrase - based mt ( pbmt ) and neural mt ( nmt ).', 'we look at potential benefits of three preprocessing steps on amrs before feeding them into an mt system : delexicalisation, compression, and linearisation.', ""delexicalisation decreases the sparsity of an amr by removing constant values, compression removes nodes and edges which are less likely to be aligned to any word on the textual side and linearisation'flattens'the amr in a specific order."", 'com - figure 1 : example of an amr bining all possibilities gives rise to 2 3 = 8 amr preprocessing strategies, which we evaluate for two different']",1
"['', 'following the aligner of  #AUTHOR_TAG,  #TAUTHOR_TAG clean']","['representation.', 'following the aligner of  #AUTHOR_TAG,  #TAUTHOR_TAG clean']","['', 'following the aligner of  #AUTHOR_TAG,  #TAUTHOR_TAG clean']","['', 'following the aligner of  #AUTHOR_TAG,  #TAUTHOR_TAG clean an amr by removing some nodes and edges independent of the context.', '']",4
"['##rto - text systems described in the literature  #TAUTHOR_TAG.', 'since the models of  #AUTHOR_TAG and  #AUTHOR_TAG are publicly available, we also use them with the same training data as our models.', ' #AUTHOR_TAG, we specifically use the version available on github 2.', ' #AUTHOR_TAG, we use the version']","['some of the amrto - text systems described in the literature  #TAUTHOR_TAG.', 'since the models of  #AUTHOR_TAG and  #AUTHOR_TAG are publicly available, we also use them with the same training data as our models.', ' #AUTHOR_TAG, we specifically use the version available on github 2.', ' #AUTHOR_TAG, we use the version']","['some of the amrto - text systems described in the literature  #TAUTHOR_TAG.', 'since the models of  #AUTHOR_TAG and  #AUTHOR_TAG are publicly available, we also use them with the same training data as our models.', ' #AUTHOR_TAG, we specifically use the version available on github 2.', ' #AUTHOR_TAG, we use the version']","['compare bleu scores for some of the amrto - text systems described in the literature  #TAUTHOR_TAG.', 'since the models of  #AUTHOR_TAG and  #AUTHOR_TAG are publicly available, we also use them with the same training data as our models.', ' #AUTHOR_TAG, we specifically use the version available on github 2.', "" #AUTHOR_TAG, we use the version available at the first author's website 3."", 'the rules used for the preordering model and the feature functions from the pbmt system are trained using alignments over amr - sentence pairs from the training set obtained with the aligner described by  #AUTHOR_TAG.', 'we do not use lexicalised reordering models as  #TAUTHOR_TAG.', 'moreover, we tune the weights of the feature functions with mert  #AUTHOR_TAG.', 'both models make use of a 5 - gram language model trained on gigaword third edition corpus with kenlm']",4
[' #AUTHOR_TAG and  #TAUTHOR_TAG were officially'],[' #AUTHOR_TAG and  #TAUTHOR_TAG were officially'],[' #AUTHOR_TAG and  #TAUTHOR_TAG were officially'],"['1 depicts the scores of the different models by the size of the data they were trained on.', 'for illustration, we depicted the bleu scores of all the amr - to - text systems described in the literature.', 'the models of  #AUTHOR_TAG and  #TAUTHOR_TAG were officially trained with 10, 313 amr - sentence pairs from the ldc2014t12 corpus, and with 36, 521 amr - sentence pairs from the ldc2016e25 in our study ( as our models ).', 'the ones of  #AUTHOR_TAG and  #AUTHOR_TAG were trained with 16, 833 pairs from the ldc2015e86 corpus.', ' #AUTHOR_TAG, which presents the highest quantitative result in the task so far, also used the ldc2015e86 corpus plus 20 million english sentences from the gigaword corpus with a semi - supervised approach.', 'we report the results when their model were trained only with amrsentence pairs from the corpus, and when improved with more 20 million sentences.', 'among the pbmt models, the delexicalisation step ( + delex ) does not seem to play a role in obtaining better sentences from amrs.', 'all the models with the preordering method in  #AUTHOR_TAG and introduce competitive results with  #TAUTHOR_TAG.', 'in our nmt models, apparently the compression step is harmful to the task, whereas delexicalisation and preordering in linearisation lead to better results.', 'however, none of the nmt models outperform neither the pbmt models nor the baselines']",4
"['proposed in  #TAUTHOR_TAG.', 'we']","['proposed in  #TAUTHOR_TAG.', 'we']","['proposed in  #TAUTHOR_TAG.', 'we perform a depthfirst search through the amr, printing the elements according to']","['compression, we flatten the amr to serve as input to the translation step, similarly as proposed in  #TAUTHOR_TAG.', 'we perform a depthfirst search through the amr, printing the elements according to their visiting order.', 'in a second step, also following  #TAUTHOR_TAG, we implemented a version of the 2 - step classifier from  #AUTHOR_TAG to preorder the elements from an amr according to the target side']",3
[' #AUTHOR_TAG and  #TAUTHOR_TAG were officially'],[' #AUTHOR_TAG and  #TAUTHOR_TAG were officially'],[' #AUTHOR_TAG and  #TAUTHOR_TAG were officially'],"['1 depicts the scores of the different models by the size of the data they were trained on.', 'for illustration, we depicted the bleu scores of all the amr - to - text systems described in the literature.', 'the models of  #AUTHOR_TAG and  #TAUTHOR_TAG were officially trained with 10, 313 amr - sentence pairs from the ldc2014t12 corpus, and with 36, 521 amr - sentence pairs from the ldc2016e25 in our study ( as our models ).', 'the ones of  #AUTHOR_TAG and  #AUTHOR_TAG were trained with 16, 833 pairs from the ldc2015e86 corpus.', ' #AUTHOR_TAG, which presents the highest quantitative result in the task so far, also used the ldc2015e86 corpus plus 20 million english sentences from the gigaword corpus with a semi - supervised approach.', 'we report the results when their model were trained only with amrsentence pairs from the corpus, and when improved with more 20 million sentences.', 'among the pbmt models, the delexicalisation step ( + delex ) does not seem to play a role in obtaining better sentences from amrs.', 'all the models with the preordering method in  #AUTHOR_TAG and introduce competitive results with  #TAUTHOR_TAG.', 'in our nmt models, apparently the compression step is harmful to the task, whereas delexicalisation and preordering in linearisation lead to better results.', 'however, none of the nmt models outperform neither the pbmt models nor the baselines']",3
"['- delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['our best model ( pbmt - delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['- delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['amrs using pbmt. our best model ( pbmt - delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity. compressing an amr', 'graph with a classifier shows improvements over a comparable model without compression, but not as strong as preordering the elements in', 'the linearisation step. in fact, preordering seems to be the most important preprocessing step across all three mt preprocessing metrics. we note that', 'the preordering success was expected, based on previous results  #TAUTHOR_TAG. neural mt the first impression from our nmt experiments', '']",3
"['- delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['our best model ( pbmt - delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['- delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['amrs using pbmt. our best model ( pbmt - delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity. compressing an amr', 'graph with a classifier shows improvements over a comparable model without compression, but not as strong as preordering the elements in', 'the linearisation step. in fact, preordering seems to be the most important preprocessing step across all three mt preprocessing metrics. we note that', 'the preordering success was expected, based on previous results  #TAUTHOR_TAG. neural mt the first impression from our nmt experiments', '']",3
"['- delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['our best model ( pbmt - delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['- delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['amrs using pbmt. our best model ( pbmt - delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity. compressing an amr', 'graph with a classifier shows improvements over a comparable model without compression, but not as strong as preordering the elements in', 'the linearisation step. in fact, preordering seems to be the most important preprocessing step across all three mt preprocessing metrics. we note that', 'the preordering success was expected, based on previous results  #TAUTHOR_TAG. neural mt the first impression from our nmt experiments', '']",3
"['proposed in  #TAUTHOR_TAG.', 'we']","['proposed in  #TAUTHOR_TAG.', 'we']","['proposed in  #TAUTHOR_TAG.', 'we perform a depthfirst search through the amr, printing the elements according to']","['compression, we flatten the amr to serve as input to the translation step, similarly as proposed in  #TAUTHOR_TAG.', 'we perform a depthfirst search through the amr, printing the elements according to their visiting order.', 'in a second step, also following  #TAUTHOR_TAG, we implemented a version of the 2 - step classifier from  #AUTHOR_TAG to preorder the elements from an amr according to the target side']",5
"['##rto - text systems described in the literature  #TAUTHOR_TAG.', 'since the models of  #AUTHOR_TAG and  #AUTHOR_TAG are publicly available, we also use them with the same training data as our models.', ' #AUTHOR_TAG, we specifically use the version available on github 2.', ' #AUTHOR_TAG, we use the version']","['some of the amrto - text systems described in the literature  #TAUTHOR_TAG.', 'since the models of  #AUTHOR_TAG and  #AUTHOR_TAG are publicly available, we also use them with the same training data as our models.', ' #AUTHOR_TAG, we specifically use the version available on github 2.', ' #AUTHOR_TAG, we use the version']","['some of the amrto - text systems described in the literature  #TAUTHOR_TAG.', 'since the models of  #AUTHOR_TAG and  #AUTHOR_TAG are publicly available, we also use them with the same training data as our models.', ' #AUTHOR_TAG, we specifically use the version available on github 2.', ' #AUTHOR_TAG, we use the version']","['compare bleu scores for some of the amrto - text systems described in the literature  #TAUTHOR_TAG.', 'since the models of  #AUTHOR_TAG and  #AUTHOR_TAG are publicly available, we also use them with the same training data as our models.', ' #AUTHOR_TAG, we specifically use the version available on github 2.', "" #AUTHOR_TAG, we use the version available at the first author's website 3."", 'the rules used for the preordering model and the feature functions from the pbmt system are trained using alignments over amr - sentence pairs from the training set obtained with the aligner described by  #AUTHOR_TAG.', 'we do not use lexicalised reordering models as  #TAUTHOR_TAG.', 'moreover, we tune the weights of the feature functions with mert  #AUTHOR_TAG.', 'both models make use of a 5 - gram language model trained on gigaword third edition corpus with kenlm']",5
"['- delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['our best model ( pbmt - delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['- delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity']","['amrs using pbmt. our best model ( pbmt - delex + compress +', 'preorder ) presents competitive results to  #TAUTHOR_TAG with the advantage that no technique is necessary to overcome data sparsity. compressing an amr', 'graph with a classifier shows improvements over a comparable model without compression, but not as strong as preordering the elements in', 'the linearisation step. in fact, preordering seems to be the most important preprocessing step across all three mt preprocessing metrics. we note that', 'the preordering success was expected, based on previous results  #TAUTHOR_TAG. neural mt the first impression from our nmt experiments', '']",5
"['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with each word assigned a set of lexical categories.', 'a packed chart is used to efficiently represent all of the possible analyses for a sentence, and the cky chart parsing algorithm described in  #AUTHOR_TAG is used to build the chart.', ' #TAUTHOR_TAG evaluate a number of log - linear parsing models for ccg.', 'in this paper we use the normal - form model, which defines probabilities with the conditional log - linear form in ( 1 ), where y is a derivation and x is a sentence.', 'features are defined in terms of the local trees in the derivation, including lexical head information and wordword dependencies.', 'the normal - form derivations in ccgbank provide the gold standard training data.', 'the feature set we use is from the best performing normal - form model in  #TAUTHOR_TAG.', 'for a given sentence the output of the parser is a dependency structure corresponding to the most probable derivation, which can be found using the viterbi algorithm.', 'the dependency relations are defined in terms of the argument slots of ccg lexical categories.', 'and  #TAUTHOR_TAG give a detailed description of the dependency structures']",7
"['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with each word assigned a set of lexical categories.', 'a packed chart is used to efficiently represent all of the possible analyses for a sentence, and the cky chart parsing algorithm described in  #AUTHOR_TAG is used to build the chart.', ' #TAUTHOR_TAG evaluate a number of log - linear parsing models for ccg.', 'in this paper we use the normal - form model, which defines probabilities with the conditional log - linear form in ( 1 ), where y is a derivation and x is a sentence.', 'features are defined in terms of the local trees in the derivation, including lexical head information and wordword dependencies.', 'the normal - form derivations in ccgbank provide the gold standard training data.', 'the feature set we use is from the best performing normal - form model in  #TAUTHOR_TAG.', 'for a given sentence the output of the parser is a dependency structure corresponding to the most probable derivation, which can be found using the viterbi algorithm.', 'the dependency relations are defined in terms of the argument slots of ccg lexical categories.', 'and  #TAUTHOR_TAG give a detailed description of the dependency structures']",7
"['is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the']","['is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the f -']","['. the oracle row shows', 'the parser speed when it is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the']","['', 'is extremely fast, processing almost 50 sentences a second. this configuration of the system would be useful for obtaining data for lexical knowledge acquisition, for example, for which large amounts of data are required. the oracle row shows', 'the parser speed when it is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the f - score for labelled dependencies is almost 98 %. this demonstrates the', 'large amount of information in the lexical categories, and the potential for improving parser accuracy and efficiency by improving the supertagger. finally, the first parser beam row corresponds to the parser using a', 'beam search to further reduce the derivation space. the beam search works by pruning categories from the chart : a category can only be part of a derivation if its beam score is within some factor,', 'α, of the highest scoring category for that cell in the chart. here we simply use the exponential of the inside score of a', 'category as the beam score ; the inside score for a category c is the sum over all sub - derivations dominated by c of the weights of', 'the features in those sub - derivations ( see  #TAUTHOR_TAG']",7
['figures reported in  #TAUTHOR_TAG'],['figures reported in  #TAUTHOR_TAG'],"[', leading to the figures reported in  #TAUTHOR_TAG']","['value of α that we use here reduces the accuracy of the parser on section 00 by a small amount ( 0. 3 % labelled f - score ), but has a significant impact on parser speed, reducing the parse times by a further 33 %.', 'the final parser beam row combines the beam search with the fast, reduced coverage configuration of the parser, producing speeds of over 50 sentences per second.', 'table 5 gives the percentage of sentences which are parsed at each supertagger level, for both the new and old parsing strategies.', 'the results show that, for the old approach, most of the sentences are parsed using the least restrictive setting of the supertagger ( β = 0. 01 ) ; conversely, for the new approach, most of the sentences are parsed using the most restrictive setting ( β = 0. 1 ).', 'as well as investigating parser efficiency, we have also evaluated the accuracy of the parser on section 00 of ccgbank, using both parsing strategies together with the normal - form constraints.', 'the new strategy increases the f - score over labelled dependencies by approximately 0. 5 %, leading to the figures reported in  #TAUTHOR_TAG']",7
"['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with each word assigned a set of lexical categories.', 'a packed chart is used to efficiently represent all of the possible analyses for a sentence, and the cky chart parsing algorithm described in  #AUTHOR_TAG is used to build the chart.', ' #TAUTHOR_TAG evaluate a number of log - linear parsing models for ccg.', 'in this paper we use the normal - form model, which defines probabilities with the conditional log - linear form in ( 1 ), where y is a derivation and x is a sentence.', 'features are defined in terms of the local trees in the derivation, including lexical head information and wordword dependencies.', 'the normal - form derivations in ccgbank provide the gold standard training data.', 'the feature set we use is from the best performing normal - form model in  #TAUTHOR_TAG.', 'for a given sentence the output of the parser is a dependency structure corresponding to the most probable derivation, which can be found using the viterbi algorithm.', 'the dependency relations are defined in terms of the argument slots of ccg lexical categories.', 'and  #TAUTHOR_TAG give a detailed description of the dependency structures']",0
"[' #TAUTHOR_TAG we describe a discriminative method for estimating the parameters of a log - linear parsing model.', 'the estimation method maximises the following objective']","[' #TAUTHOR_TAG we describe a discriminative method for estimating the parameters of a log - linear parsing model.', 'the estimation method maximises the following objective function :', 'the data']","[' #TAUTHOR_TAG we describe a discriminative method for estimating the parameters of a log - linear parsing model.', 'the estimation method maximises the following objective function :', 'the data']","[' #TAUTHOR_TAG we describe a discriminative method for estimating the parameters of a log - linear parsing model.', 'the estimation method maximises the following objective function :', 'the data consists of sentences s 1,..., s m, together with gold standard normal - form derivations,', 'is the log - likelihood of model λ, and g ( λ ) is a gaussian prior term used to avoid overfitting ( n is the number of features ; λ i is the weight for feature f i ; and σ is a parameter of the gaussian ).', 'the objective function is optimised using l - bfgs  #AUTHOR_TAG, an iterative algorithm from the numerical optimisation literature.', 'the algorithm requires the gradient of the objective function, and the value of the objective function, at each iteration.', 'calculation of these values requires all derivations for each sentence in the training data.', 'in  #TAUTHOR_TAG we describe efficient methods for performing the calculations using packed charts.', 'however, a very large amount of memory is still needed to store the packed charts for the complete training data even though the representation is very compact ; in we report a memory usage of 30 gb.', 'to handle this we have developed a parallel implementation of the estimation algorithm which runs on a beowulf cluster.', 'the need for large high - performance computing resources is a disadvantage of our earlier approach.', 'in the next section we show how use of the supertagger, combined with normal - form constraints on the derivations, can significantly reduce the memory requirements for the model estimation']",0
"['.', 'in  #TAUTHOR_TAG we show that the parsing model resulting from training data generated in this']","['original approach.', 'in  #TAUTHOR_TAG we show that the parsing model resulting from training data generated in this']","['over the original approach.', 'in  #TAUTHOR_TAG we show that the parsing model resulting from training data generated in this way']","['', 'the third row shows a further reduction in size when using the eisner normal - form constraints.', 'even with the ccgbank rule constraints, the parser still builds many non - normal - form derivations, since ccgbank does contain cases of composition and type - raising.', '( these are used to analyse some coordination and extraction cases, for example. ) the combination of the two types of normalform constraints reduces the memory requirements by 48 % over the original approach.', 'in  #TAUTHOR_TAG we show that the parsing model resulting from training data generated in this way produces state - of - the - art ccg dependency recovery : 84. 6 f - score over labelled dependencies.', 'the final row corresponds to a more restrictive setting on the supertagger, in which a value of β = 0. 05 is used initially and β = 0. 1 is used if the node limit is exceeded.', 'the two types of normalform constraints are also used.', 'in  #TAUTHOR_TAG we show that using this more restrictive setting has a small negative impact on the accuracy of the resulting parser ( about 0. 6 f - score over labelled dependencies ).', 'however, the memory requirement for training the model is now only 4 gb, a reduction of 87 % compared with the original approach']",0
"['is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the']","['is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the f -']","['. the oracle row shows', 'the parser speed when it is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the']","['', 'is extremely fast, processing almost 50 sentences a second. this configuration of the system would be useful for obtaining data for lexical knowledge acquisition, for example, for which large amounts of data are required. the oracle row shows', 'the parser speed when it is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the f - score for labelled dependencies is almost 98 %. this demonstrates the', 'large amount of information in the lexical categories, and the potential for improving parser accuracy and efficiency by improving the supertagger. finally, the first parser beam row corresponds to the parser using a', 'beam search to further reduce the derivation space. the beam search works by pruning categories from the chart : a category can only be part of a derivation if its beam score is within some factor,', 'α, of the highest scoring category for that cell in the chart. here we simply use the exponential of the inside score of a', 'category as the beam score ; the inside score for a category c is the sum over all sub - derivations dominated by c of the weights of', 'the features in those sub - derivations ( see  #TAUTHOR_TAG']",0
"['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with']","['parser is described in detail in  #TAUTHOR_TAG.', 'it takes pos tagged sentences as input with each word assigned a set of lexical categories.', 'a packed chart is used to efficiently represent all of the possible analyses for a sentence, and the cky chart parsing algorithm described in  #AUTHOR_TAG is used to build the chart.', ' #TAUTHOR_TAG evaluate a number of log - linear parsing models for ccg.', 'in this paper we use the normal - form model, which defines probabilities with the conditional log - linear form in ( 1 ), where y is a derivation and x is a sentence.', 'features are defined in terms of the local trees in the derivation, including lexical head information and wordword dependencies.', 'the normal - form derivations in ccgbank provide the gold standard training data.', 'the feature set we use is from the best performing normal - form model in  #TAUTHOR_TAG.', 'for a given sentence the output of the parser is a dependency structure corresponding to the most probable derivation, which can be found using the viterbi algorithm.', 'the dependency relations are defined in terms of the argument slots of ccg lexical categories.', 'and  #TAUTHOR_TAG give a detailed description of the dependency structures']",5
"['is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the']","['is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the f -']","['. the oracle row shows', 'the parser speed when it is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the']","['', 'is extremely fast, processing almost 50 sentences a second. this configuration of the system would be useful for obtaining data for lexical knowledge acquisition, for example, for which large amounts of data are required. the oracle row shows', 'the parser speed when it is provided with only the correct lexical categories. the parser is extremely fast, and in  #TAUTHOR_TAG we show that the f - score for labelled dependencies is almost 98 %. this demonstrates the', 'large amount of information in the lexical categories, and the potential for improving parser accuracy and efficiency by improving the supertagger. finally, the first parser beam row corresponds to the parser using a', 'beam search to further reduce the derivation space. the beam search works by pruning categories from the chart : a category can only be part of a derivation if its beam score is within some factor,', 'α, of the highest scoring category for that cell in the chart. here we simply use the exponential of the inside score of a', 'category as the beam score ; the inside score for a category c is the sum over all sub - derivations dominated by c of the weights of', 'the features in those sub - derivations ( see  #TAUTHOR_TAG']",5
"[' #TAUTHOR_TAG we describe a discriminative method for estimating the parameters of a log - linear parsing model.', 'the estimation method maximises the following objective']","[' #TAUTHOR_TAG we describe a discriminative method for estimating the parameters of a log - linear parsing model.', 'the estimation method maximises the following objective function :', 'the data']","[' #TAUTHOR_TAG we describe a discriminative method for estimating the parameters of a log - linear parsing model.', 'the estimation method maximises the following objective function :', 'the data']","[' #TAUTHOR_TAG we describe a discriminative method for estimating the parameters of a log - linear parsing model.', 'the estimation method maximises the following objective function :', 'the data consists of sentences s 1,..., s m, together with gold standard normal - form derivations,', 'is the log - likelihood of model λ, and g ( λ ) is a gaussian prior term used to avoid overfitting ( n is the number of features ; λ i is the weight for feature f i ; and σ is a parameter of the gaussian ).', 'the objective function is optimised using l - bfgs  #AUTHOR_TAG, an iterative algorithm from the numerical optimisation literature.', 'the algorithm requires the gradient of the objective function, and the value of the objective function, at each iteration.', 'calculation of these values requires all derivations for each sentence in the training data.', 'in  #TAUTHOR_TAG we describe efficient methods for performing the calculations using packed charts.', 'however, a very large amount of memory is still needed to store the packed charts for the complete training data even though the representation is very compact ; in we report a memory usage of 30 gb.', 'to handle this we have developed a parallel implementation of the estimation algorithm which runs on a beowulf cluster.', 'the need for large high - performance computing resources is a disadvantage of our earlier approach.', 'in the next section we show how use of the supertagger, combined with normal - form constraints on the derivations, can significantly reduce the memory requirements for the model estimation']",1
"['.', 'in  #TAUTHOR_TAG we show that the parsing model resulting from training data generated in this']","['original approach.', 'in  #TAUTHOR_TAG we show that the parsing model resulting from training data generated in this']","['over the original approach.', 'in  #TAUTHOR_TAG we show that the parsing model resulting from training data generated in this way']","['', 'the third row shows a further reduction in size when using the eisner normal - form constraints.', 'even with the ccgbank rule constraints, the parser still builds many non - normal - form derivations, since ccgbank does contain cases of composition and type - raising.', '( these are used to analyse some coordination and extraction cases, for example. ) the combination of the two types of normalform constraints reduces the memory requirements by 48 % over the original approach.', 'in  #TAUTHOR_TAG we show that the parsing model resulting from training data generated in this way produces state - of - the - art ccg dependency recovery : 84. 6 f - score over labelled dependencies.', 'the final row corresponds to a more restrictive setting on the supertagger, in which a value of β = 0. 05 is used initially and β = 0. 1 is used if the node limit is exceeded.', 'the two types of normalform constraints are also used.', 'in  #TAUTHOR_TAG we show that using this more restrictive setting has a small negative impact on the accuracy of the resulting parser ( about 0. 6 f - score over labelled dependencies ).', 'however, the memory requirement for training the model is now only 4 gb, a reduction of 87 % compared with the original approach']",4
['- qa dataset  #TAUTHOR_TAG for vqa was created by parsing coc'],"['properly without augmentation.', 'although training using augmented text data is rare, generating new questions about images has been studied.', 'the coco - qa dataset  #TAUTHOR_TAG for vqa was created by parsing coco captions with a syntactic parser,']","['because large quantities of real data are available, models generalize properly without augmentation.', 'although training using augmented text data is rare, generating new questions about images has been studied.', 'the coco - qa dataset  #TAUTHOR_TAG for vqa was created by parsing coco captions with a syntactic parser,']","['supervised computer vision problems, e. g., image recognition, labels are scarcer than images.', 'this is especially a problem with deep convolutional neural networks ( cnns ) that have millions of parameters.', 'although more human labeled data would be ideal, it is easier to exploit the training dataset to generate new examples.', 'for image classification, common ways to exploit training images to create more labeled examples include mirror reflection, random crops etc.', 'many of these methods were used in training the seminal alexnet  #AUTHOR_TAG, which increased the training data by more than ten folds and produced relative improvement of over 4 % for image classification.', 'compared to vision, where augmentation is common, little work has been done on augmenting text for classification problems.', 'a notable exception is  #AUTHOR_TAG, where a thesaurus was used to replace synonymous words to create more training data for text classification.', 'however, this augmentation produced little improvement and sometimes even hurt performance.', ""the authors'argued that because large quantities of real data are available, models generalize properly without augmentation."", 'although training using augmented text data is rare, generating new questions about images has been studied.', 'the coco - qa dataset  #TAUTHOR_TAG for vqa was created by parsing coco captions with a syntactic parser, and then used this to create qa pairs for four kinds of questions using hand - crafted rules.', 'however, due to inability of the algorithm to cope with complex sentence structures, a significant portion of coco - qa questions have grammatical errors or are oddly phrased.', 'visual question generation was also studied in  #AUTHOR_TAG, with an emphasis on generating questions about images that are beyond the literal visual content of the image.', 'they endeavored to avoid simple questions such as counting and color, which were emphasized in coco - qa.', 'unlike our work, their objective was not data augmentation and they did not try to answer the generated questions']",1
"['- qa  #TAUTHOR_TAG.', ""'""]","[""dataset' #AUTHOR_TAG and coco - qa  #TAUTHOR_TAG."", ""' the vqa dataset'is currently the""]","['- qa  #TAUTHOR_TAG.', ""'""]","[""conduct experiments on two of the most popular vqa datasets :'the vqa dataset' #AUTHOR_TAG and coco - qa  #TAUTHOR_TAG."", ""' the vqa dataset'is currently the most popular vqa dataset and it contains both synthetic and real - world images."", 'the real - world images are from the coco dataset  #AUTHOR_TAG.', 'all questions were generated by human annotators.', 'we refer to this portion as coco - vqa, and use it for our experiments.', ""coco - qa  #TAUTHOR_TAG also uses images from coco, with the questions generated by an nlp algorithm that uses coco's captions."", 'all questions belong to four categories : object, number, color, and location.', 'many algorithms have been proposed for vqa.', 'some notable formulations include attention based methods  #AUTHOR_TAG, bayesian frameworks  #AUTHOR_TAG, and compositional approaches  #AUTHOR_TAG a, b ).', 'detailed reviews of existing methods can be found in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'however, simpler models such as linear classifiers and multilayer perceptrons ( mlps ) perform only slightly worse on many vqa datasets.', 'these baseline methods predict the answer using a vector of image features concatenated to a vector of question features  #TAUTHOR_TAG.', 'we use the mlp model to conduct the bulk of the experiments, but we show that the proposed method is also effective on more sophisticated vqa systems like multimodal compact bilinear pooling ( mcb )  #AUTHOR_TAG']",5
"['- qa  #TAUTHOR_TAG.', ""'""]","[""dataset' #AUTHOR_TAG and coco - qa  #TAUTHOR_TAG."", ""' the vqa dataset'is currently the""]","['- qa  #TAUTHOR_TAG.', ""'""]","[""conduct experiments on two of the most popular vqa datasets :'the vqa dataset' #AUTHOR_TAG and coco - qa  #TAUTHOR_TAG."", ""' the vqa dataset'is currently the most popular vqa dataset and it contains both synthetic and real - world images."", 'the real - world images are from the coco dataset  #AUTHOR_TAG.', 'all questions were generated by human annotators.', 'we refer to this portion as coco - vqa, and use it for our experiments.', ""coco - qa  #TAUTHOR_TAG also uses images from coco, with the questions generated by an nlp algorithm that uses coco's captions."", 'all questions belong to four categories : object, number, color, and location.', 'many algorithms have been proposed for vqa.', 'some notable formulations include attention based methods  #AUTHOR_TAG, bayesian frameworks  #AUTHOR_TAG, and compositional approaches  #AUTHOR_TAG a, b ).', 'detailed reviews of existing methods can be found in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'however, simpler models such as linear classifiers and multilayer perceptrons ( mlps ) perform only slightly worse on many vqa datasets.', 'these baseline methods predict the answer using a vector of image features concatenated to a vector of question features  #TAUTHOR_TAG.', 'we use the mlp model to conduct the bulk of the experiments, but we show that the proposed method is also effective on more sophisticated vqa systems like multimodal compact bilinear pooling ( mcb )  #AUTHOR_TAG']",0
"['- qa  #TAUTHOR_TAG.', ""'""]","[""dataset' #AUTHOR_TAG and coco - qa  #TAUTHOR_TAG."", ""' the vqa dataset'is currently the""]","['- qa  #TAUTHOR_TAG.', ""'""]","[""conduct experiments on two of the most popular vqa datasets :'the vqa dataset' #AUTHOR_TAG and coco - qa  #TAUTHOR_TAG."", ""' the vqa dataset'is currently the most popular vqa dataset and it contains both synthetic and real - world images."", 'the real - world images are from the coco dataset  #AUTHOR_TAG.', 'all questions were generated by human annotators.', 'we refer to this portion as coco - vqa, and use it for our experiments.', ""coco - qa  #TAUTHOR_TAG also uses images from coco, with the questions generated by an nlp algorithm that uses coco's captions."", 'all questions belong to four categories : object, number, color, and location.', 'many algorithms have been proposed for vqa.', 'some notable formulations include attention based methods  #AUTHOR_TAG, bayesian frameworks  #AUTHOR_TAG, and compositional approaches  #AUTHOR_TAG a, b ).', 'detailed reviews of existing methods can be found in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'however, simpler models such as linear classifiers and multilayer perceptrons ( mlps ) perform only slightly worse on many vqa datasets.', 'these baseline methods predict the answer using a vector of image features concatenated to a vector of question features  #TAUTHOR_TAG.', 'we use the mlp model to conduct the bulk of the experiments, but we show that the proposed method is also effective on more sophisticated vqa systems like multimodal compact bilinear pooling ( mcb )  #AUTHOR_TAG']",0
['by  #TAUTHOR_TAG has provided a foundation'],['by  #TAUTHOR_TAG has provided a foundation'],['work by  #TAUTHOR_TAG has provided a foundation'],"['work by  #TAUTHOR_TAG has provided a foundation for measuring syntactic differences between corpora.', 'it uses part - of - speech trigrams as an approximation to syntactic structure, comparing the trigrams of two corpora for statistically significant differences.', 'this paper extends the method and its application.', 'it extends the method by using leafpath ancestors of  #AUTHOR_TAG instead of trigrams, which capture internal syntactic structure - every leaf in a parse tree records the path back to the root.', 'the corpus used for testing is the international corpus of english, great britain  #AUTHOR_TAG, which contains syntactically annotated speech of great britain.', 'the speakers are grouped into geographical regions based on place of birth.', 'this is different in both nature and number than previous experiments, which found differences between two groups of norwegian l2 learners of english.', 'we show that dialectal variation in eleven british regions from the ice - gb is detectable by our algorithm, using both leaf - ancestor paths and trigrams']",0
"['on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method']","['on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method.', 'this method approximates internal syntactic']","['related work on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method.', 'this method approximates internal syntactic structure using vectors of part - of - speech trigrams.', 'the trigram types']","['the measurement of linguistic distance, older work such as seguy ( 1973 ) was able to measure distance in most areas of linguistics, such as phonology, morphology, and syntax.', 'the features used for comparison were hand - picked based on linguistic knowledge of the area being surveyed.', 'these features, while probably lacking in completeness of coverage, certainly allowed a rough comparison of distance in all linguistic domains.', 'in contrast, computational methods have focused on a single area of language.', 'for example, a method for determining phonetic distance is given by  #AUTHOR_TAG.', 'heeringa and others have also done related work on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method.', 'this method approximates internal syntactic structure using vectors of part - of - speech trigrams.', 'the trigram types can then be compared for statistically significant differences using a permutation test.', 'this study can be extended in a few ways.', 'first, the trigram approximation works well, but it does not necessarily capture all the information of syntactic structure such as long - distance movement.', 'second, the experiments did not test data for geographical dialect variation, but compared two generations of norwegian l2 learners of english, with differences between ages of initial acquisition.', 'we address these areas by using the syntactically annotated speech section of the international corpus of english, great britain ( ice - gb )  #AUTHOR_TAG, which provides a corpus with full syntactic annotations, one that can be divided into groups for comparison.', 'the sentences of the corpus, being represented as parse trees rather than a vector of pos tags, are converted into a vector of leafancestor paths, which were developed by  #AUTHOR_TAG to aid in parser evaluation by providing a way to compare gold - standard trees with parser output trees.', '']",0
"['syntactic comparison of  #TAUTHOR_TAG,']","['syntactic comparison of  #TAUTHOR_TAG,']","['two sources.', 'the primary source is the syntactic comparison of  #TAUTHOR_TAG,']","['methods used to implement the syntactic difference test come from two sources.', 'the primary source is the syntactic comparison of  #TAUTHOR_TAG, which uses a permutation test, explained in  #AUTHOR_TAG and in particular for linguistic purposes in  #AUTHOR_TAG.', 'their permutation test collects pos trigrams from a random subcorpus of sentences sampled from the combined corpora.', 'the trigram frequencies are normalized to neutralize the effects of sentence length, then compared to the trigram frequencies of the complete corpora.', 'the principal difference between the work of  #TAUTHOR_TAG and ours is the use of leaf - ancestor paths.', 'leaf - ancestor paths were developed by  #AUTHOR_TAG for estimating parser performance by providing a measure of similarity of two trees, in particular a gold - standard tree and a machine - parsed tree.', 'this distance is not used for our method, since for our purposes, it is enough that leaf - ancestor paths represent syntactic information, such as upper - level tree structure, more explicitly than trigrams.', 'the permutation test used by  #TAUTHOR_TAG is independent of the type of item whose frequency is measured, treating the items as atomic symbols.', 'therefore, leaf - ancestor paths should do just as well as trigrams as long as they do not introduce any additional constraints on how they are generated from the corpus.', 'fortunately, this is not the case ;  #TAUTHOR_TAG generate n − 2 pos trigrams from each sentence of length n ; we generate n leaf - ancestor paths from each parsed sentence in the corpus.', 'normalization is needed to account for the frequency differences caused by sentence length variation ; it is presented below.', 'since the same number ( minus two ) of trigrams and leaf - ancestor paths are generated for each sentence the same normalization can be used for both methods']",0
"['on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method']","['on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method.', 'this method approximates internal syntactic']","['related work on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method.', 'this method approximates internal syntactic structure using vectors of part - of - speech trigrams.', 'the trigram types']","['the measurement of linguistic distance, older work such as seguy ( 1973 ) was able to measure distance in most areas of linguistics, such as phonology, morphology, and syntax.', 'the features used for comparison were hand - picked based on linguistic knowledge of the area being surveyed.', 'these features, while probably lacking in completeness of coverage, certainly allowed a rough comparison of distance in all linguistic domains.', 'in contrast, computational methods have focused on a single area of language.', 'for example, a method for determining phonetic distance is given by  #AUTHOR_TAG.', 'heeringa and others have also done related work on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method.', 'this method approximates internal syntactic structure using vectors of part - of - speech trigrams.', 'the trigram types can then be compared for statistically significant differences using a permutation test.', 'this study can be extended in a few ways.', 'first, the trigram approximation works well, but it does not necessarily capture all the information of syntactic structure such as long - distance movement.', 'second, the experiments did not test data for geographical dialect variation, but compared two generations of norwegian l2 learners of english, with differences between ages of initial acquisition.', 'we address these areas by using the syntactically annotated speech section of the international corpus of english, great britain ( ice - gb )  #AUTHOR_TAG, which provides a corpus with full syntactic annotations, one that can be divided into groups for comparison.', 'the sentences of the corpus, being represented as parse trees rather than a vector of pos tags, are converted into a vector of leafancestor paths, which were developed by  #AUTHOR_TAG to aid in parser evaluation by providing a way to compare gold - standard trees with parser output trees.', '']",1
"['on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method']","['on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method.', 'this method approximates internal syntactic']","['related work on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method.', 'this method approximates internal syntactic structure using vectors of part - of - speech trigrams.', 'the trigram types']","['the measurement of linguistic distance, older work such as seguy ( 1973 ) was able to measure distance in most areas of linguistics, such as phonology, morphology, and syntax.', 'the features used for comparison were hand - picked based on linguistic knowledge of the area being surveyed.', 'these features, while probably lacking in completeness of coverage, certainly allowed a rough comparison of distance in all linguistic domains.', 'in contrast, computational methods have focused on a single area of language.', 'for example, a method for determining phonetic distance is given by  #AUTHOR_TAG.', 'heeringa and others have also done related work on phonological distance in  #AUTHOR_TAG and  #AUTHOR_TAG.', 'a measure of syntactic distance is the obvious next step :  #TAUTHOR_TAG provide one such method.', 'this method approximates internal syntactic structure using vectors of part - of - speech trigrams.', 'the trigram types can then be compared for statistically significant differences using a permutation test.', 'this study can be extended in a few ways.', 'first, the trigram approximation works well, but it does not necessarily capture all the information of syntactic structure such as long - distance movement.', 'second, the experiments did not test data for geographical dialect variation, but compared two generations of norwegian l2 learners of english, with differences between ages of initial acquisition.', 'we address these areas by using the syntactically annotated speech section of the international corpus of english, great britain ( ice - gb )  #AUTHOR_TAG, which provides a corpus with full syntactic annotations, one that can be divided into groups for comparison.', 'the sentences of the corpus, being represented as parse trees rather than a vector of pos tags, are converted into a vector of leafancestor paths, which were developed by  #AUTHOR_TAG to aid in parser evaluation by providing a way to compare gold - standard trees with parser output trees.', '']",1
"['syntactic comparison of  #TAUTHOR_TAG,']","['syntactic comparison of  #TAUTHOR_TAG,']","['two sources.', 'the primary source is the syntactic comparison of  #TAUTHOR_TAG,']","['methods used to implement the syntactic difference test come from two sources.', 'the primary source is the syntactic comparison of  #TAUTHOR_TAG, which uses a permutation test, explained in  #AUTHOR_TAG and in particular for linguistic purposes in  #AUTHOR_TAG.', 'their permutation test collects pos trigrams from a random subcorpus of sentences sampled from the combined corpora.', 'the trigram frequencies are normalized to neutralize the effects of sentence length, then compared to the trigram frequencies of the complete corpora.', 'the principal difference between the work of  #TAUTHOR_TAG and ours is the use of leaf - ancestor paths.', 'leaf - ancestor paths were developed by  #AUTHOR_TAG for estimating parser performance by providing a measure of similarity of two trees, in particular a gold - standard tree and a machine - parsed tree.', 'this distance is not used for our method, since for our purposes, it is enough that leaf - ancestor paths represent syntactic information, such as upper - level tree structure, more explicitly than trigrams.', 'the permutation test used by  #TAUTHOR_TAG is independent of the type of item whose frequency is measured, treating the items as atomic symbols.', 'therefore, leaf - ancestor paths should do just as well as trigrams as long as they do not introduce any additional constraints on how they are generated from the corpus.', 'fortunately, this is not the case ;  #TAUTHOR_TAG generate n − 2 pos trigrams from each sentence of length n ; we generate n leaf - ancestor paths from each parsed sentence in the corpus.', 'normalization is needed to account for the frequency differences caused by sentence length variation ; it is presented below.', 'since the same number ( minus two ) of trigrams and leaf - ancestor paths are generated for each sentence the same normalization can be used for both methods']",4
"['syntactic comparison of  #TAUTHOR_TAG,']","['syntactic comparison of  #TAUTHOR_TAG,']","['two sources.', 'the primary source is the syntactic comparison of  #TAUTHOR_TAG,']","['methods used to implement the syntactic difference test come from two sources.', 'the primary source is the syntactic comparison of  #TAUTHOR_TAG, which uses a permutation test, explained in  #AUTHOR_TAG and in particular for linguistic purposes in  #AUTHOR_TAG.', 'their permutation test collects pos trigrams from a random subcorpus of sentences sampled from the combined corpora.', 'the trigram frequencies are normalized to neutralize the effects of sentence length, then compared to the trigram frequencies of the complete corpora.', 'the principal difference between the work of  #TAUTHOR_TAG and ours is the use of leaf - ancestor paths.', 'leaf - ancestor paths were developed by  #AUTHOR_TAG for estimating parser performance by providing a measure of similarity of two trees, in particular a gold - standard tree and a machine - parsed tree.', 'this distance is not used for our method, since for our purposes, it is enough that leaf - ancestor paths represent syntactic information, such as upper - level tree structure, more explicitly than trigrams.', 'the permutation test used by  #TAUTHOR_TAG is independent of the type of item whose frequency is measured, treating the items as atomic symbols.', 'therefore, leaf - ancestor paths should do just as well as trigrams as long as they do not introduce any additional constraints on how they are generated from the corpus.', 'fortunately, this is not the case ;  #TAUTHOR_TAG generate n − 2 pos trigrams from each sentence of length n ; we generate n leaf - ancestor paths from each parsed sentence in the corpus.', 'normalization is needed to account for the frequency differences caused by sentence length variation ; it is presented below.', 'since the same number ( minus two ) of trigrams and leaf - ancestor paths are generated for each sentence the same normalization can be used for both methods']",4
"['by  #TAUTHOR_TAG,']","['by  #TAUTHOR_TAG,']","['by  #TAUTHOR_TAG, the experiment was also run with pos trigrams.', '']","['', 'for comparison to the experiment conducted by  #TAUTHOR_TAG, the experiment was also run with pos trigrams.', 'finally, a control experiment was conducted by comparing two permutations from the same corpus and ensuring that they were not significantly different.', 'ice - gb reports the place of birth of each speaker, which is the best available approximation to which dialect a speaker uses.', 'as a simple, objective partitioning, the speakers were divided into 11 geographical regions based on the 9 government office regions of england with wales and scotland added as single regions.', 'some speakers had to be thrown out at this point because they lacked brithplace information or were born outside the uk.', 'each region varied in size ; however, the average number of sentences per corpus was 4682, with an average of 44, 726 words per corpus ( see table 1 ).', '']",4
"['work extends that of  #TAUTHOR_TAG in a number of ways.', 'we have shown that an alternate method of representing syntax still allows the permutation test to find significant differences between corpora.', 'in']","['work extends that of  #TAUTHOR_TAG in a number of ways.', 'we have shown that an alternate method of representing syntax still allows the permutation test to find significant differences between corpora.', 'in addition, we have shown differences between corpora divided']","['work extends that of  #TAUTHOR_TAG in a number of ways.', 'we have shown that an alternate method of representing syntax still allows the permutation test to find significant differences between corpora.', 'in']","['work extends that of  #TAUTHOR_TAG in a number of ways.', 'we have shown that an alternate method of representing syntax still allows the permutation test to find significant differences between corpora.', 'in addition, we have shown differences between corpora divided by geographical area rather than language proficiency, with many more corpora than before.', 'finally, we have shown that the size of the corpus can be reduced somewhat and still obtain significant results.', 'furthermore, we also have shown that both leafancestor paths and pos trigrams give similar results, although the more complex paths require more data.', 'however, there are a number of directions that this experiment should be extended.', 'a comparison that divides the speakers into traditional british dialect areas is needed to see if the same differences can be detected.', 'this is very likely, because corpus divisions that better reflect reality have a better chance of achieving a significant difference.', ""in fact, even though leaf - ancestor paths should provide finer distinctions than trigrams and thus require more data for detectable significance, the regional corpora presented here were smaller than the norwegian speakers'corpora in  #TAUTHOR_TAG by up to a factor of 10."", 'this raises the question of a lower limit on corpus size.', 'our experiment suggests that the two corpora must have at least 250, 000 words, although we suspect that better divisions will allow smaller corpus sizes.', 'while we are reducing corpus size, we might as well compare the increasing numbers of smaller and smaller corpora in an advantageous order.', 'it should be possible to cluster corpora by the point at which they fail to achieve a significant difference when split from a larger corpus.', 'in this way, regions could be grouped by their detectable boundaries, not a priori distinctions based on geography or existing knowledge of dialect boundaries.', 'of course this indirect method would not be needed if one had a direct method for clustering speakers, by distance or other measure.', 'development of such a method is worthwhile research for the future']",4
"['work extends that of  #TAUTHOR_TAG in a number of ways.', 'we have shown that an alternate method of representing syntax still allows the permutation test to find significant differences between corpora.', 'in']","['work extends that of  #TAUTHOR_TAG in a number of ways.', 'we have shown that an alternate method of representing syntax still allows the permutation test to find significant differences between corpora.', 'in addition, we have shown differences between corpora divided']","['work extends that of  #TAUTHOR_TAG in a number of ways.', 'we have shown that an alternate method of representing syntax still allows the permutation test to find significant differences between corpora.', 'in']","['work extends that of  #TAUTHOR_TAG in a number of ways.', 'we have shown that an alternate method of representing syntax still allows the permutation test to find significant differences between corpora.', 'in addition, we have shown differences between corpora divided by geographical area rather than language proficiency, with many more corpora than before.', 'finally, we have shown that the size of the corpus can be reduced somewhat and still obtain significant results.', 'furthermore, we also have shown that both leafancestor paths and pos trigrams give similar results, although the more complex paths require more data.', 'however, there are a number of directions that this experiment should be extended.', 'a comparison that divides the speakers into traditional british dialect areas is needed to see if the same differences can be detected.', 'this is very likely, because corpus divisions that better reflect reality have a better chance of achieving a significant difference.', ""in fact, even though leaf - ancestor paths should provide finer distinctions than trigrams and thus require more data for detectable significance, the regional corpora presented here were smaller than the norwegian speakers'corpora in  #TAUTHOR_TAG by up to a factor of 10."", 'this raises the question of a lower limit on corpus size.', 'our experiment suggests that the two corpora must have at least 250, 000 words, although we suspect that better divisions will allow smaller corpus sizes.', 'while we are reducing corpus size, we might as well compare the increasing numbers of smaller and smaller corpora in an advantageous order.', 'it should be possible to cluster corpora by the point at which they fail to achieve a significant difference when split from a larger corpus.', 'in this way, regions could be grouped by their detectable boundaries, not a priori distinctions based on geography or existing knowledge of dialect boundaries.', 'of course this indirect method would not be needed if one had a direct method for clustering speakers, by distance or other measure.', 'development of such a method is worthwhile research for the future']",6
"['generation from text passages.', ' #TAUTHOR_TAG utilized the answer - position, and linguistic features']","['generation from text passages.', ' #TAUTHOR_TAG utilized the answer - position, and linguistic features']","['- sequence learning for question generation from text passages.', ' #TAUTHOR_TAG utilized the answer - position, and linguistic features']","['', 'we believe this is the first work that explores world - knowledge in the form of linked entities and fine grained entity types as features to improve neural question generation models.', 'recently, works on question generation have drifted towards neural - based approaches.', 'these approaches typically involve end - to - end supervised learning to generate questions.', ' #AUTHOR_TAG proposed sequence - to - sequence learning for question generation from text passages.', ' #TAUTHOR_TAG utilized the answer - position, and linguistic features such as named entity recognition ( ner ) and parts of speech ( pos ) information to further improve the qg performance as the model is aware that for which answer a question need to be generated.', 'in the work of a multi - perspective context matching algorithm is employed']",0
"['use a two - layer bidirectional lstm ( bi - lstm ).', 'inspired by the success of using linguistic features in  #TAUTHOR_TAG,']","['use a two - layer bidirectional lstm ( bi - lstm ).', 'inspired by the success of using linguistic features in  #TAUTHOR_TAG,']","['to capture more contextual information, we use a two - layer bidirectional lstm ( bi - lstm ).', 'inspired by the success of using linguistic features in  #TAUTHOR_TAG, we exploit word knowledge in']","['proposed model is based on the sequence - tosequence  #AUTHOR_TAG paradigm.', 'for the encoder, we utilize a long short term memory ( lstm )  #AUTHOR_TAG network.', 'in order to capture more contextual information, we use a two - layer bidirectional lstm ( bi - lstm ).', 'inspired by the success of using linguistic features in  #TAUTHOR_TAG, we exploit word knowledge in the form of entity linking and fine - grained entity typing in the encoder of the network.', 'a bi - lstm encoder reads the passage words and their associated world knowledge features ( c. f. section 3. 1. 1, 3. 1. 2 ) to produce a sequence of word - and - feature vectors.', 'the word vectors, the embedded world knowledge feature vectors and the answer position indicator embedding vectors are concatenated and passed as input to the bi - lstm encoder']",7
"['features ( ner ) being used in literature  #TAUTHOR_TAG, we also report the following experiments.', 'table 3, 4']","['features ( ner ) being used in literature  #TAUTHOR_TAG, we also report the following experiments.', 'table 3, 4']","[' #AUTHOR_TAG.', 'in order to compare our models with the existing coarse - grained entity features ( ner ) being used in literature  #TAUTHOR_TAG, we also report the following experiments.', 'table 3, 4']","['conducted series of experiments as follows :', '( 1 ) s2s + att : baseline encoder - decoder based seq2seq network with attention mechanism.', '( 2 ) nqg : extension of s2s + att with answer position feature.', '( 3 ) nqg + el : extension of nqg with the entity linking feature ( 500 dimension ) discussed in section 3. 1. 1. ( 4 ) nqg + el ( pre ) : nqg + entity linking with the pre - trained entity linking feature obtained from the joint training of word and wikipedia entity using  #AUTHOR_TAG.', 'in order to compare our models with the existing coarse - grained entity features ( ner ) being used in literature  #TAUTHOR_TAG, we also report the following experiments.', 'table 3, 4']",7
"['previous works  #TAUTHOR_TAG, named']","['previous works  #TAUTHOR_TAG, named']","['previous works  #TAUTHOR_TAG, named entity type features have been used.', 'these features, however, only allow for the encoding of coarse level information']","['previous works  #TAUTHOR_TAG, named entity type features have been used.', ""these features, however, only allow for the encoding of coarse level information such as knowledge of if an entity belongs to a set of predefined categories such as'person ','location'and'organi - zation '."", 'to alleviate this, we use the knowledge in the form of linked entities.', 'in our experiments, we use wikipedia as the knowledge base for which to link entities.', 'this specific task ( also known as wikification  #AUTHOR_TAG ) is the task of identifying concepts and entities in text and disambiguation them into the most specific corresponding wikipedia pages.', 'we followed the approach by  #AUTHOR_TAG for the wikification.', 'the wikification process is performed on the input passage p having n words { w for multi - word mentions, we assign the same wikipedia title to each word of the mention.', 'in order to project the word and entity in the same vector space, we jointly learn pre - trained word - entity vector embeddings using the method proposed by  #AUTHOR_TAG']",1
"['split as  #TAUTHOR_TAG.', 'ms marco datasets contains 1']","['split as  #TAUTHOR_TAG.', 'ms marco datasets contains 1']","['##6 wikipedia articles.', 'we used the same split as  #TAUTHOR_TAG.', 'ms marco datasets contains']","['evaluated the performance of our approach on squad  #AUTHOR_TAG and ms marco v2. 1  #AUTHOR_TAG.', 'squad is composed of more than 100k questions posed by crowd workers on 536 wikipedia articles.', 'we used the same split as  #TAUTHOR_TAG.', 'ms marco datasets contains 1 million queries with corresponding answers and passages.', 'all questions are sampled from real anonymized user queries and context passages are extracted from real web documents.', 'we picked a subset of ms marco data where answers ( < = 10 words ) are sub - spans within the passages ( < = 600 words ), and use dev set as test set ( 7, 849 ), and split train set with ratio 90 % - 10 % into train ( 1, 36, 337 ) and dev ( 15, 148 ) sets']",3
"['split as  #TAUTHOR_TAG.', 'ms marco datasets contains 1']","['split as  #TAUTHOR_TAG.', 'ms marco datasets contains 1']","['##6 wikipedia articles.', 'we used the same split as  #TAUTHOR_TAG.', 'ms marco datasets contains']","['evaluated the performance of our approach on squad  #AUTHOR_TAG and ms marco v2. 1  #AUTHOR_TAG.', 'squad is composed of more than 100k questions posed by crowd workers on 536 wikipedia articles.', 'we used the same split as  #TAUTHOR_TAG.', 'ms marco datasets contains 1 million queries with corresponding answers and passages.', 'all questions are sampled from real anonymized user queries and context passages are extracted from real web documents.', 'we picked a subset of ms marco data where answers ( < = 10 words ) are sub - spans within the passages ( < = 600 words ), and use dev set as test set ( 7, 849 ), and split train set with ratio 90 % - 10 % into train ( 1, 36, 337 ) and dev ( 15, 148 ) sets']",5
"[' #AUTHOR_TAG, sentence generation  #TAUTHOR_TAG, dialogue control  #AUTHOR_TAG a ), sentiment']","[' #AUTHOR_TAG, sentence generation  #TAUTHOR_TAG, dialogue control  #AUTHOR_TAG a ), sentiment classification, recommendation system,']","[', text segmentation  #AUTHOR_TAG, information extraction  #AUTHOR_TAG, image caption generation  #AUTHOR_TAG, sentence generation  #TAUTHOR_TAG, dialogue control  #AUTHOR_TAG a ), sentiment classification, recommendation']","['tutorial introduces the advances in deep bayesian learning with abundant applications for natural language understanding ranging from speech recognition  #AUTHOR_TAG to document summarization  #AUTHOR_TAG, text classification  #AUTHOR_TAG, text segmentation  #AUTHOR_TAG, information extraction  #AUTHOR_TAG, image caption generation  #AUTHOR_TAG, sentence generation  #TAUTHOR_TAG, dialogue control  #AUTHOR_TAG a ), sentiment classification, recommendation system, question answering  #AUTHOR_TAG and machine translation, to name a few.', 'traditionally, "" deep learning "" is taken to be a learning process where the inference or optimization is based on the real - valued deterministic model.', 'the "" semantic structure "" in words, sentences, entities, actions and documents drawn from a large vocabulary may not be well expressed or correctly optimized in mathematical logic or computer programs.', 'the "" distribution function "" in discrete or continuous latent variable model for natural language may not be properly decomposed or estimated in model inference.', 'this tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced bayesian models and deep models including hierarchical dirichlet process, chinese restaurant process  #AUTHOR_TAG, hierarchical pitman - yor process  #AUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural network  #AUTHOR_TAG, long short - term memory  #AUTHOR_TAG sequence - to - sequence model  #AUTHOR_TAG, variational auto - encoder  #AUTHOR_TAG, generative adversarial network  #AUTHOR_TAG, attention mechanism  #AUTHOR_TAG, memory - augmented neural network  #AUTHOR_TAG, stochastic neural network  #AUTHOR_TAG, predictive state neural network  #AUTHOR_TAG, policy gradient  #AUTHOR_TAG and reinforcement learning  #AUTHOR_TAG.', '']",5
['to social media data  #TAUTHOR_TAG'],['pos taggers to social media data  #TAUTHOR_TAG'],"['pos taggers to social media data  #TAUTHOR_TAG.', 'additionally, lexical normalisation and other preprocessing strategies have been shown to enhance the performance of nlp tools over social media data  #AUTHOR_TAG han et al']","['', 'however, there have been recent successes in adapting parsers and pos taggers to social media data  #TAUTHOR_TAG.', 'additionally, lexical normalisation and other preprocessing strategies have been shown to enhance the performance of nlp tools over social media data  #AUTHOR_TAG han et al., to appear ).', 'furthermore, social media posts tend to be short and the content highly varied, meaning it is difficult to adapt a tool to the domain, or harness textual context to disambiguate the content.', 'there is also the engineering challenge of real - time processing of the text stream, as much of nlp research is carried out offline with only secondary concern for throughput.', 'as such, we might conclude that social media data is a foe of nlp, in that it challenges traditional assumptions made in nlp research on the nature of the target text and the requirements for real - time responsiveness.', 'however, if we look beyond the immediate text content of social media, we quickly realise that there are various non - textual data sources that can be used to enhance the robustness and accuracy of nlp models, in']",0
"[' #TAUTHOR_TAG, a']","[' #TAUTHOR_TAG, a']","[' #TAUTHOR_TAG, a dataset of escort ads for which anti - trafficking']","['', 'leverage several regularization techniques for deep neural networks to further improve model performance, such as residual con - nection  #AUTHOR_TAG and batch', 'normalization  #AUTHOR_TAG. we conduct our experiments on trafficking - 10k  #TAUTHOR_TAG, a dataset of escort ads for which anti - trafficking experts assigned each sample', 'one of seven ordered labels ranging from "" 1 : very unlikely ( to come from traffickers ) "" to "" 7 : very likely "". our proposed model significantly outperforms', 'previously published models  #TAUTHOR_TAG on trafficking - 10k as well as', 'a variety of baseline ordinal regression models. in addition, we analyze the emojis used in escort ads with word2vec and t - sne ( van der  #AUTHOR_TAG, and we show that the lexicon of trafficking - related emojis can be subsequently expanded. in section 2, we discuss related work on human', 'trafficking detection and ordinal regression. in section 3, we present our proposed model and detail', 'its components. in section 4, we present the experimental results, including the trafficking - 10k benchmark, a qualitative analysis of the predictions on raw', '']",0
"[' #TAUTHOR_TAG, a']","[' #TAUTHOR_TAG, a']","[' #TAUTHOR_TAG, a dataset of escort ads for which anti - trafficking']","['', 'leverage several regularization techniques for deep neural networks to further improve model performance, such as residual con - nection  #AUTHOR_TAG and batch', 'normalization  #AUTHOR_TAG. we conduct our experiments on trafficking - 10k  #TAUTHOR_TAG, a dataset of escort ads for which anti - trafficking experts assigned each sample', 'one of seven ordered labels ranging from "" 1 : very unlikely ( to come from traffickers ) "" to "" 7 : very likely "". our proposed model significantly outperforms', 'previously published models  #TAUTHOR_TAG on trafficking - 10k as well as', 'a variety of baseline ordinal regression models. in addition, we analyze the emojis used in escort ads with word2vec and t - sne ( van der  #AUTHOR_TAG, and we show that the lexicon of trafficking - related emojis can be subsequently expanded. in section 2, we discuss related work on human', 'trafficking detection and ordinal regression. in section 3, we present our proposed model and detail', 'its components. in section 4, we present the experimental results, including the trafficking - 10k benchmark, a qualitative analysis of the predictions on raw', '']",0
"[')  #TAUTHOR_TAG.', 'ht']","['( htdn )  #TAUTHOR_TAG.', 'htdn has']","[')  #TAUTHOR_TAG.', 'ht']","['detection : there have been several software products designed to aid anti - trafficking efforts.', 'examples include memex 1 which focuses on search functionalities in the dark web ; spotlight 2 which flags suspicious ads and links images appearing in multiple ads ; traffic jam 3 which seeks to identify patterns that connect multiple ads to the same trafficking organization ; and traffickcam 4 which aims to construct a crowd - sourced database of hotel room images to geo - locate victims.', 'these research efforts have largely been isolated, and few research articles on machine learning for trafficking detection have been published.', 'closest to our work is the human trafficking deep network ( htdn )  #TAUTHOR_TAG.', '']",0
"[')  #TAUTHOR_TAG.', 'ht']","['( htdn )  #TAUTHOR_TAG.', 'htdn has']","[')  #TAUTHOR_TAG.', 'ht']","['detection : there have been several software products designed to aid anti - trafficking efforts.', 'examples include memex 1 which focuses on search functionalities in the dark web ; spotlight 2 which flags suspicious ads and links images appearing in multiple ads ; traffic jam 3 which seeks to identify patterns that connect multiple ads to the same trafficking organization ; and traffickcam 4 which aims to construct a crowd - sourced database of hotel room images to geo - locate victims.', 'these research efforts have largely been isolated, and few research articles on machine learning for trafficking detection have been published.', 'closest to our work is the human trafficking deep network ( htdn )  #TAUTHOR_TAG.', '']",0
"['ads instead of using previously published embeddings  #TAUTHOR_TAG.', 'we use 168, 337 ads scraped from backpage as our training corpus and the skipgram model with negative sampling  #AUTHOR_TAG b ) as our model']","['ads instead of using previously published embeddings  #TAUTHOR_TAG.', 'we use 168, 337 ads scraped from backpage as our training corpus and the skipgram model with negative sampling  #AUTHOR_TAG b ) as our model']","['##ort ads instead of using previously published embeddings  #TAUTHOR_TAG.', 'we use 168, 337 ads scraped from backpage as our training corpus and the skipgram model with negative sampling  #AUTHOR_TAG b ) as our model']","['representations of words, also known as word embeddings, can be obtained through unsupervised learning on a large text corpus so that certain linguistic regularities and patterns are encoded.', 'compared to latent semantic analysis  #AUTHOR_TAG, embedding algorithms using neural networks are particularly good at preserving linear regularities among words in addition to grouping similar words together  #AUTHOR_TAG a ).', 'such embeddings can in turn help other algorithms achieve better performances in various natural language processing tasks  #AUTHOR_TAG b ).', 'unfortunately, the escort ads contain a plethora of emojis, acronyms, and ( sometimes deliberate ) typographical errors that are not encountered in more standard text data, which suggests that it is likely better to learn word embeddings from scratch on a large collection of escort ads instead of using previously published embeddings  #TAUTHOR_TAG.', 'we use 168, 337 ads scraped from backpage as our training corpus and the skipgram model with negative sampling  #AUTHOR_TAG b ) as our model']",0
['labeled texts e.  #TAUTHOR_TAG used to'],['labeled texts e.  #TAUTHOR_TAG used to'],"['pre - train the word embeddings, and use the same labeled texts e.  #TAUTHOR_TAG used to']","['use raw texts scraped from backpage and tnaboard to pre - train the word embeddings, and use the same labeled texts e.  #TAUTHOR_TAG used to conduct model comparisons.', 'the raw text dataset consists of 44, 105 ads from tnaboard and 124, 220 ads from backpage.', 'data cleaning / preprocessing includes joining the title and the body of an ad ; adding white spaces around every emoji so that it can be tokenized properly ; stripping tabs, line breaks, punctuations, and extra white spaces ; removing phone numbers ; and converting all letters to lower case.', 'we have ensured that the raw dataset has no overlap with the labeled dataset to avoid bias in test accuracy.', 'while it is possible to scrape more raw data, we did not observe significant improvements in model performances when the size of raw data increased from ∼70, 000 to ∼170, 000, hence we assume that the current raw dataset is sufficiently large.', 'the labeled dataset is called trafficking - 10k.', 'it consists of 12, 350 ads from backpage labeled by experts in human trafficking detection 6  #TAUTHOR_TAG.', 'each label is one of seven ordered levels of likelihood that the corresponding ad comes from a human trafficker.', 'descriptions and sample proportions of the labels are in table 1.', 'the original trafficking - 10k includes both texts and images, but as mentioned in section 1, only the texts are used in our case.', 'we apply the same preprocessing to trafficking - 10k as we do to raw data']",0
['labeled texts e.  #TAUTHOR_TAG used to'],['labeled texts e.  #TAUTHOR_TAG used to'],"['pre - train the word embeddings, and use the same labeled texts e.  #TAUTHOR_TAG used to']","['use raw texts scraped from backpage and tnaboard to pre - train the word embeddings, and use the same labeled texts e.  #TAUTHOR_TAG used to conduct model comparisons.', 'the raw text dataset consists of 44, 105 ads from tnaboard and 124, 220 ads from backpage.', 'data cleaning / preprocessing includes joining the title and the body of an ad ; adding white spaces around every emoji so that it can be tokenized properly ; stripping tabs, line breaks, punctuations, and extra white spaces ; removing phone numbers ; and converting all letters to lower case.', 'we have ensured that the raw dataset has no overlap with the labeled dataset to avoid bias in test accuracy.', 'while it is possible to scrape more raw data, we did not observe significant improvements in model performances when the size of raw data increased from ∼70, 000 to ∼170, 000, hence we assume that the current raw dataset is sufficiently large.', 'the labeled dataset is called trafficking - 10k.', 'it consists of 12, 350 ads from backpage labeled by experts in human trafficking detection 6  #TAUTHOR_TAG.', 'each label is one of seven ordered levels of likelihood that the corresponding ad comes from a human trafficker.', 'descriptions and sample proportions of the labels are in table 1.', 'the original trafficking - 10k includes both texts and images, but as mentioned in section 1, only the texts are used in our case.', 'we apply the same preprocessing to trafficking - 10k as we do to raw data']",0
"[')  #TAUTHOR_TAG,']","['( htdn )  #TAUTHOR_TAG,']","[')  #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],0
"['advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law']","['advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law']","['advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law enforcement maintains a lexicon of trafficking flags mapping certain emojis']","['fight against human traffickers is adversarial and dynamic.', 'traffickers often avoid using explicit keywords when advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law enforcement maintains a lexicon of trafficking flags mapping certain emojis to their potential true meanings ( e. g., the cherry emoji can indicate an underaged victim ), but compiling such a lexicon manually is expensive, requires frequent updating, and relies on domain expertise that is hard to obtain ( e. g., insider information from traffickers or their victims ).', 'to make matters worse, traffickers change their dictionaries over time and regularly switch to new emojis to replace certain keywords  #TAUTHOR_TAG.', 'in such a dynamic and adversarial environment, the need for a data - driven approach in updating the existing lexicon is evident.', 'as mentioned in section 3. 1, training a skipgram model on a text corpus can map words ( including emojis ) used in similar contexts to similar numeric vectors.', 'besides using the vectors learned from the raw escort ads to train ornn, we can directly visualize the vectors for the emojis to help identify their relationships, by mapping the vectors to a 2 - dimensional space using t - sne 9 ( van der  #AUTHOR_TAG ( figure 3 ).', 'we can first empirically assess the quality of the emoji map by noting that similar emojis do seem clustered together : the smileys near the coordinate ( 2, 3 ), the flowers near ( - 6, - 1 ), the heart shapes near ( - 8, 1 ), the phones near ( - 2, 4 ) and so on.', ""it is worth emphasizing that the skip - gram model learns the vectors of these emojis based on their contexts in escort ads and not their visual representations, so the fact that the visually similar emojis are close to one another in the map suggests that figure 3 : emoji map produced by applying t - sne to the emojis'vectors learned from escort ads using skip - gram model."", 'for visual clarity, only the emojis that appeared most frequently in the escort ads we scraped are shown out of the total 968 emojis that appeared.', 'the vectors have been learned as desired.', 'the emoji map can assist anti - trafficking experts in expanding the existing lexicon of trafficking flags.', 'for example, according to the lexicon we obtained from global emancipation network 10, the cherry emoji and the lollipop']",0
"['advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law']","['advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law']","['advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law enforcement maintains a lexicon of trafficking flags mapping certain emojis']","['fight against human traffickers is adversarial and dynamic.', 'traffickers often avoid using explicit keywords when advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law enforcement maintains a lexicon of trafficking flags mapping certain emojis to their potential true meanings ( e. g., the cherry emoji can indicate an underaged victim ), but compiling such a lexicon manually is expensive, requires frequent updating, and relies on domain expertise that is hard to obtain ( e. g., insider information from traffickers or their victims ).', 'to make matters worse, traffickers change their dictionaries over time and regularly switch to new emojis to replace certain keywords  #TAUTHOR_TAG.', 'in such a dynamic and adversarial environment, the need for a data - driven approach in updating the existing lexicon is evident.', 'as mentioned in section 3. 1, training a skipgram model on a text corpus can map words ( including emojis ) used in similar contexts to similar numeric vectors.', 'besides using the vectors learned from the raw escort ads to train ornn, we can directly visualize the vectors for the emojis to help identify their relationships, by mapping the vectors to a 2 - dimensional space using t - sne 9 ( van der  #AUTHOR_TAG ( figure 3 ).', 'we can first empirically assess the quality of the emoji map by noting that similar emojis do seem clustered together : the smileys near the coordinate ( 2, 3 ), the flowers near ( - 6, - 1 ), the heart shapes near ( - 8, 1 ), the phones near ( - 2, 4 ) and so on.', ""it is worth emphasizing that the skip - gram model learns the vectors of these emojis based on their contexts in escort ads and not their visual representations, so the fact that the visually similar emojis are close to one another in the map suggests that figure 3 : emoji map produced by applying t - sne to the emojis'vectors learned from escort ads using skip - gram model."", 'for visual clarity, only the emojis that appeared most frequently in the escort ads we scraped are shown out of the total 968 emojis that appeared.', 'the vectors have been learned as desired.', 'the emoji map can assist anti - trafficking experts in expanding the existing lexicon of trafficking flags.', 'for example, according to the lexicon we obtained from global emancipation network 10, the cherry emoji and the lollipop']",0
['on trafficking - 10k  #TAUTHOR_TAG'],['on trafficking - 10k  #TAUTHOR_TAG'],"['on trafficking - 10k  #TAUTHOR_TAG.', 'we also']","['trafficking is a form of modern day slavery that victimizes millions of people.', 'it has become 10 global emancipation network is a non - profit organization dedicated to combating human trafficking.', 'for more information see https : / / www. globalemancipation. ngo.', 'the norm for sex traffickers to use escort websites to openly advertise their victims.', 'we designed an ordinal regression neural network ( ornn ) to predict the likelihood that an escort ad comes from a trafficker, which can drastically narrow down the set of possible leads for law enforcement.', 'our ornn achieved the state - of - the - art performance on trafficking - 10k  #TAUTHOR_TAG.', 'we also conducted an emoji analysis and showed how to use word embeddings learned from raw text data to help expand the lexicon of trafficking flags.', 'since our experiments, there have been considerable advancements in language representation models, such as bert  #AUTHOR_TAG.', 'the new language representation models can be combined with our ordinal regression layer, replacing the skip - gram model and gf - rnn, to potentially further improve our results.', 'however, our contributions of improving the cost function for ordinal regression neural networks, qualitatively analyzing patterns in the predicted samples, and expanding the trafficking lexicon through a data - driven approach are not dependent on a particular choice of language representation model.', 'as for future work in trafficking detection, we can design multi - modal ordinal regression networks that utilize both image and text data. but given the time and resources required to label escort ads, we may explore more unsupervised learning or transfer learning algorithms, such as using object detection  #AUTHOR_TAG and matching algorithms to match hotel rooms in the images']",0
"[' #TAUTHOR_TAG, a']","[' #TAUTHOR_TAG, a']","[' #TAUTHOR_TAG, a dataset of escort ads for which anti - trafficking']","['', 'leverage several regularization techniques for deep neural networks to further improve model performance, such as residual con - nection  #AUTHOR_TAG and batch', 'normalization  #AUTHOR_TAG. we conduct our experiments on trafficking - 10k  #TAUTHOR_TAG, a dataset of escort ads for which anti - trafficking experts assigned each sample', 'one of seven ordered labels ranging from "" 1 : very unlikely ( to come from traffickers ) "" to "" 7 : very likely "". our proposed model significantly outperforms', 'previously published models  #TAUTHOR_TAG on trafficking - 10k as well as', 'a variety of baseline ordinal regression models. in addition, we analyze the emojis used in escort ads with word2vec and t - sne ( van der  #AUTHOR_TAG, and we show that the lexicon of trafficking - related emojis can be subsequently expanded. in section 2, we discuss related work on human', 'trafficking detection and ordinal regression. in section 3, we present our proposed model and detail', 'its components. in section 4, we present the experimental results, including the trafficking - 10k benchmark, a qualitative analysis of the predictions on raw', '']",5
['classification model by e.  #TAUTHOR_TAG'],['state - of - the - art classification model by e.  #TAUTHOR_TAG'],"['well as the previous state - of - the - art classification model by e.  #TAUTHOR_TAG.', 'to assess the effect of each component in our model, we perform an ablation test where the components']","['', 'then we present a detailed comparison of our proposed model with commonly used ordinal regression models as well as the previous state - of - the - art classification model by e.  #TAUTHOR_TAG.', 'to assess the effect of each component in our model, we perform an ablation test where the components are swapped by their more standard alternatives one at a time.', 'next, we perform a qualitative analysis on the model predictions on the raw data, which are scraped from a different escort website than the one that provides the labeled training data.', 'finally, we conduct an emoji analysis using the word embeddings trained on raw escort ads']",5
['labeled texts e.  #TAUTHOR_TAG used to'],['labeled texts e.  #TAUTHOR_TAG used to'],"['pre - train the word embeddings, and use the same labeled texts e.  #TAUTHOR_TAG used to']","['use raw texts scraped from backpage and tnaboard to pre - train the word embeddings, and use the same labeled texts e.  #TAUTHOR_TAG used to conduct model comparisons.', 'the raw text dataset consists of 44, 105 ads from tnaboard and 124, 220 ads from backpage.', 'data cleaning / preprocessing includes joining the title and the body of an ad ; adding white spaces around every emoji so that it can be tokenized properly ; stripping tabs, line breaks, punctuations, and extra white spaces ; removing phone numbers ; and converting all letters to lower case.', 'we have ensured that the raw dataset has no overlap with the labeled dataset to avoid bias in test accuracy.', 'while it is possible to scrape more raw data, we did not observe significant improvements in model performances when the size of raw data increased from ∼70, 000 to ∼170, 000, hence we assume that the current raw dataset is sufficiently large.', 'the labeled dataset is called trafficking - 10k.', 'it consists of 12, 350 ads from backpage labeled by experts in human trafficking detection 6  #TAUTHOR_TAG.', 'each label is one of seven ordered levels of likelihood that the corresponding ad comes from a human trafficker.', 'descriptions and sample proportions of the labels are in table 1.', 'the original trafficking - 10k includes both texts and images, but as mentioned in section 1, only the texts are used in our case.', 'we apply the same preprocessing to trafficking - 10k as we do to raw data']",5
['labeled texts e.  #TAUTHOR_TAG used to'],['labeled texts e.  #TAUTHOR_TAG used to'],"['pre - train the word embeddings, and use the same labeled texts e.  #TAUTHOR_TAG used to']","['use raw texts scraped from backpage and tnaboard to pre - train the word embeddings, and use the same labeled texts e.  #TAUTHOR_TAG used to conduct model comparisons.', 'the raw text dataset consists of 44, 105 ads from tnaboard and 124, 220 ads from backpage.', 'data cleaning / preprocessing includes joining the title and the body of an ad ; adding white spaces around every emoji so that it can be tokenized properly ; stripping tabs, line breaks, punctuations, and extra white spaces ; removing phone numbers ; and converting all letters to lower case.', 'we have ensured that the raw dataset has no overlap with the labeled dataset to avoid bias in test accuracy.', 'while it is possible to scrape more raw data, we did not observe significant improvements in model performances when the size of raw data increased from ∼70, 000 to ∼170, 000, hence we assume that the current raw dataset is sufficiently large.', 'the labeled dataset is called trafficking - 10k.', 'it consists of 12, 350 ads from backpage labeled by experts in human trafficking detection 6  #TAUTHOR_TAG.', 'each label is one of seven ordered levels of likelihood that the corresponding ad comes from a human trafficker.', 'descriptions and sample proportions of the labels are in table 1.', 'the original trafficking - 10k includes both texts and images, but as mentioned in section 1, only the texts are used in our case.', 'we apply the same preprocessing to trafficking - 10k as we do to raw data']",5
"[')  #TAUTHOR_TAG,']","['( htdn )  #TAUTHOR_TAG,']","[')  #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],5
"[' #TAUTHOR_TAG, a']","[' #TAUTHOR_TAG, a']","[' #TAUTHOR_TAG, a dataset of escort ads for which anti - trafficking']","['', 'leverage several regularization techniques for deep neural networks to further improve model performance, such as residual con - nection  #AUTHOR_TAG and batch', 'normalization  #AUTHOR_TAG. we conduct our experiments on trafficking - 10k  #TAUTHOR_TAG, a dataset of escort ads for which anti - trafficking experts assigned each sample', 'one of seven ordered labels ranging from "" 1 : very unlikely ( to come from traffickers ) "" to "" 7 : very likely "". our proposed model significantly outperforms', 'previously published models  #TAUTHOR_TAG on trafficking - 10k as well as', 'a variety of baseline ordinal regression models. in addition, we analyze the emojis used in escort ads with word2vec and t - sne ( van der  #AUTHOR_TAG, and we show that the lexicon of trafficking - related emojis can be subsequently expanded. in section 2, we discuss related work on human', 'trafficking detection and ordinal regression. in section 3, we present our proposed model and detail', 'its components. in section 4, we present the experimental results, including the trafficking - 10k benchmark, a qualitative analysis of the predictions on raw', '']",4
"[')  #TAUTHOR_TAG.', 'ht']","['( htdn )  #TAUTHOR_TAG.', 'htdn has']","[')  #TAUTHOR_TAG.', 'ht']","['detection : there have been several software products designed to aid anti - trafficking efforts.', 'examples include memex 1 which focuses on search functionalities in the dark web ; spotlight 2 which flags suspicious ads and links images appearing in multiple ads ; traffic jam 3 which seeks to identify patterns that connect multiple ads to the same trafficking organization ; and traffickcam 4 which aims to construct a crowd - sourced database of hotel room images to geo - locate victims.', 'these research efforts have largely been isolated, and few research articles on machine learning for trafficking detection have been published.', 'closest to our work is the human trafficking deep network ( htdn )  #TAUTHOR_TAG.', '']",4
"[')  #TAUTHOR_TAG.', 'ht']","['( htdn )  #TAUTHOR_TAG.', 'htdn has']","[')  #TAUTHOR_TAG.', 'ht']","['detection : there have been several software products designed to aid anti - trafficking efforts.', 'examples include memex 1 which focuses on search functionalities in the dark web ; spotlight 2 which flags suspicious ads and links images appearing in multiple ads ; traffic jam 3 which seeks to identify patterns that connect multiple ads to the same trafficking organization ; and traffickcam 4 which aims to construct a crowd - sourced database of hotel room images to geo - locate victims.', 'these research efforts have largely been isolated, and few research articles on machine learning for trafficking detection have been published.', 'closest to our work is the human trafficking deep network ( htdn )  #TAUTHOR_TAG.', '']",4
['on trafficking - 10k  #TAUTHOR_TAG'],['on trafficking - 10k  #TAUTHOR_TAG'],"['on trafficking - 10k  #TAUTHOR_TAG.', 'we also']","['trafficking is a form of modern day slavery that victimizes millions of people.', 'it has become 10 global emancipation network is a non - profit organization dedicated to combating human trafficking.', 'for more information see https : / / www. globalemancipation. ngo.', 'the norm for sex traffickers to use escort websites to openly advertise their victims.', 'we designed an ordinal regression neural network ( ornn ) to predict the likelihood that an escort ad comes from a trafficker, which can drastically narrow down the set of possible leads for law enforcement.', 'our ornn achieved the state - of - the - art performance on trafficking - 10k  #TAUTHOR_TAG.', 'we also conducted an emoji analysis and showed how to use word embeddings learned from raw text data to help expand the lexicon of trafficking flags.', 'since our experiments, there have been considerable advancements in language representation models, such as bert  #AUTHOR_TAG.', 'the new language representation models can be combined with our ordinal regression layer, replacing the skip - gram model and gf - rnn, to potentially further improve our results.', 'however, our contributions of improving the cost function for ordinal regression neural networks, qualitatively analyzing patterns in the predicted samples, and expanding the trafficking lexicon through a data - driven approach are not dependent on a particular choice of language representation model.', 'as for future work in trafficking detection, we can design multi - modal ordinal regression networks that utilize both image and text data. but given the time and resources required to label escort ads, we may explore more unsupervised learning or transfer learning algorithms, such as using object detection  #AUTHOR_TAG and matching algorithms to match hotel rooms in the images']",4
"[')  #TAUTHOR_TAG.', 'ht']","['( htdn )  #TAUTHOR_TAG.', 'htdn has']","[')  #TAUTHOR_TAG.', 'ht']","['detection : there have been several software products designed to aid anti - trafficking efforts.', 'examples include memex 1 which focuses on search functionalities in the dark web ; spotlight 2 which flags suspicious ads and links images appearing in multiple ads ; traffic jam 3 which seeks to identify patterns that connect multiple ads to the same trafficking organization ; and traffickcam 4 which aims to construct a crowd - sourced database of hotel room images to geo - locate victims.', 'these research efforts have largely been isolated, and few research articles on machine learning for trafficking detection have been published.', 'closest to our work is the human trafficking deep network ( htdn )  #TAUTHOR_TAG.', '']",6
"['ads instead of using previously published embeddings  #TAUTHOR_TAG.', 'we use 168, 337 ads scraped from backpage as our training corpus and the skipgram model with negative sampling  #AUTHOR_TAG b ) as our model']","['ads instead of using previously published embeddings  #TAUTHOR_TAG.', 'we use 168, 337 ads scraped from backpage as our training corpus and the skipgram model with negative sampling  #AUTHOR_TAG b ) as our model']","['##ort ads instead of using previously published embeddings  #TAUTHOR_TAG.', 'we use 168, 337 ads scraped from backpage as our training corpus and the skipgram model with negative sampling  #AUTHOR_TAG b ) as our model']","['representations of words, also known as word embeddings, can be obtained through unsupervised learning on a large text corpus so that certain linguistic regularities and patterns are encoded.', 'compared to latent semantic analysis  #AUTHOR_TAG, embedding algorithms using neural networks are particularly good at preserving linear regularities among words in addition to grouping similar words together  #AUTHOR_TAG a ).', 'such embeddings can in turn help other algorithms achieve better performances in various natural language processing tasks  #AUTHOR_TAG b ).', 'unfortunately, the escort ads contain a plethora of emojis, acronyms, and ( sometimes deliberate ) typographical errors that are not encountered in more standard text data, which suggests that it is likely better to learn word embeddings from scratch on a large collection of escort ads instead of using previously published embeddings  #TAUTHOR_TAG.', 'we use 168, 337 ads scraped from backpage as our training corpus and the skipgram model with negative sampling  #AUTHOR_TAG b ) as our model']",1
"['advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law']","['advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law']","['advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law enforcement maintains a lexicon of trafficking flags mapping certain emojis']","['fight against human traffickers is adversarial and dynamic.', 'traffickers often avoid using explicit keywords when advertising victims, but instead use acronyms, intentional typos, and emojis  #TAUTHOR_TAG.', 'law enforcement maintains a lexicon of trafficking flags mapping certain emojis to their potential true meanings ( e. g., the cherry emoji can indicate an underaged victim ), but compiling such a lexicon manually is expensive, requires frequent updating, and relies on domain expertise that is hard to obtain ( e. g., insider information from traffickers or their victims ).', 'to make matters worse, traffickers change their dictionaries over time and regularly switch to new emojis to replace certain keywords  #TAUTHOR_TAG.', 'in such a dynamic and adversarial environment, the need for a data - driven approach in updating the existing lexicon is evident.', 'as mentioned in section 3. 1, training a skipgram model on a text corpus can map words ( including emojis ) used in similar contexts to similar numeric vectors.', 'besides using the vectors learned from the raw escort ads to train ornn, we can directly visualize the vectors for the emojis to help identify their relationships, by mapping the vectors to a 2 - dimensional space using t - sne 9 ( van der  #AUTHOR_TAG ( figure 3 ).', 'we can first empirically assess the quality of the emoji map by noting that similar emojis do seem clustered together : the smileys near the coordinate ( 2, 3 ), the flowers near ( - 6, - 1 ), the heart shapes near ( - 8, 1 ), the phones near ( - 2, 4 ) and so on.', ""it is worth emphasizing that the skip - gram model learns the vectors of these emojis based on their contexts in escort ads and not their visual representations, so the fact that the visually similar emojis are close to one another in the map suggests that figure 3 : emoji map produced by applying t - sne to the emojis'vectors learned from escort ads using skip - gram model."", 'for visual clarity, only the emojis that appeared most frequently in the escort ads we scraped are shown out of the total 968 emojis that appeared.', 'the vectors have been learned as desired.', 'the emoji map can assist anti - trafficking experts in expanding the existing lexicon of trafficking flags.', 'for example, according to the lexicon we obtained from global emancipation network 10, the cherry emoji and the lollipop']",1
"[')  #TAUTHOR_TAG,']","['( htdn )  #TAUTHOR_TAG,']","[')  #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],3
['head - driven statistical parsing model of  #TAUTHOR_TAG as a simultaneous language model and parser for largevo'],"['head - driven statistical parsing model of  #TAUTHOR_TAG as a simultaneous language model and parser for largevocabulary speech recognition.', 'the model is adapted to an online']",['present the first application of the head - driven statistical parsing model of  #TAUTHOR_TAG as a simultaneous language model and parser for largevo'],"['present the first application of the head - driven statistical parsing model of  #TAUTHOR_TAG as a simultaneous language model and parser for largevocabulary speech recognition.', 'the model is adapted to an online left to right chart - parser for word lattices, integrating acoustic, n - gram, and parser probabilities.', 'the parser uses structural and lexical dependencies not considered by ngram models, conditioning recognition on more linguistically - grounded relationships.', 'experiments on the wall street journal treebank and lattice corpora show word error rates competitive with the standard n - gram language model while extracting additional structural information useful for speech understanding']",5
"['', 'our work is different from  #AUTHOR_TAG in that we use a bottom - up parsing algorithm with dynamic programming based on the parsing model ii of  #TAUTHOR_TAG.', 'bottom - up chart parsing, through various forms of extensions to']","['and wer.', 'our work is different from  #AUTHOR_TAG in that we use a bottom - up parsing algorithm with dynamic programming based on the parsing model ii of  #TAUTHOR_TAG.', 'bottom - up chart parsing, through various forms of extensions to']","['', 'our work is different from  #AUTHOR_TAG in that we use a bottom - up parsing algorithm with dynamic programming based on the parsing model ii of  #TAUTHOR_TAG.', 'bottom - up chart parsing, through various forms of extensions to the cky algorithm, has been applied to word lattices for speech recognition  #AUTHOR_TAG.', 'full acoustic and n - best lattices filtered by trigram scores have been']","['', 'this method is algorithmically simpler than parsing lattices, as one can use a model developed for strings, which need not operate strictly left to right.', 'however, we confirm the observation of  #AUTHOR_TAG that parsing word lattices saves computation time by only parsing common substrings once.', ' #AUTHOR_TAG reports wer reduction by rescoring word lattices with scores of a structured language model  #AUTHOR_TAG, interpolated with trigram scores.', 'word predictions of the structured language model are conditioned on the two previous phrasal heads not yet contained in a bigger constituent.', 'this is a computationally intensive process, as the dependencies considered can be of arbitrarily long distances.', 'all possible sentence prefixes are considered at each extension step.', ' #AUTHOR_TAG reports on the use of a lexicalized probabilistic top - down parser for word lattices, evaluated both on parse accuracy and wer.', 'our work is different from  #AUTHOR_TAG in that we use a bottom - up parsing algorithm with dynamic programming based on the parsing model ii of  #TAUTHOR_TAG.', 'bottom - up chart parsing, through various forms of extensions to the cky algorithm, has been applied to word lattices for speech recognition  #AUTHOR_TAG.', 'full acoustic and n - best lattices filtered by trigram scores have been parsed.', ' #AUTHOR_TAG use a best - first probabilistic context free grammar ( pcfg ) to parse the input lattice, pruning to a set of local trees ( candidate partial parse trees ), which are then passed to a version of the parser of  #AUTHOR_TAG for more refined parsing.', 'unlike  #AUTHOR_TAG,  #AUTHOR_TAG achieve improvement in wer over the trigram model without interpolating its lattice parser probabilities directly with trigram probabilities']",5
"['', 'these models use much less conditioning information than the parsing models of  #TAUTHOR_TAG,']","['', 'these models use much less conditioning information than the parsing models of  #TAUTHOR_TAG,']","[' #AUTHOR_TAG.', 'these models use much less conditioning information than the parsing models of  #TAUTHOR_TAG,']","['models based on headword dependency relationships have been reported, such as the structured language model of  #AUTHOR_TAG.', 'these models use much less conditioning information than the parsing models of  #TAUTHOR_TAG, and do not provide penn treebank format parse trees as output.', 'in this section we outline the adaptation of the  #TAUTHOR_TAG parsing model to word lattices.', 'the intended action of the parser is illustrated in figure 1, which shows parse trees built directly upon a word lattice']",5
"['of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities -']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities - the probability of']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities -']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities - the probability of some event of interest ( e. g., a left - modifier attachment ) given a context ( e. g., parent non - terminal, distance, headword ).', 'one notable difference between the word lattice parser and the original implementation of  #TAUTHOR_TAG is the handling of part - of - speech ( pos ) tagging of unknown words ( words seen fewer than 5 times in training ).', 'the conditioning context of the parsing model parameters includes pos tagging.', ' #TAUTHOR_TAG falls back to the pos tagging of  #AUTHOR_TAG for words seen fewer than 5 times in the training corpus.', 'as the tagger of  #AUTHOR_TAG cannot tag a word lattice, we cannot back off to this tagging.', 'we rely on the tag assigned by the parsing model in all cases.', 'edges created by the bottom - up parsing are assigned a score which is the product of the inside and outside probabilities of the  #TAUTHOR_TAG model']",5
"['of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities -']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities - the probability of']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities -']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities - the probability of some event of interest ( e. g., a left - modifier attachment ) given a context ( e. g., parent non - terminal, distance, headword ).', 'one notable difference between the word lattice parser and the original implementation of  #TAUTHOR_TAG is the handling of part - of - speech ( pos ) tagging of unknown words ( words seen fewer than 5 times in training ).', 'the conditioning context of the parsing model parameters includes pos tagging.', ' #TAUTHOR_TAG falls back to the pos tagging of  #AUTHOR_TAG for words seen fewer than 5 times in the training corpus.', 'as the tagger of  #AUTHOR_TAG cannot tag a word lattice, we cannot back off to this tagging.', 'we rely on the tag assigned by the parsing model in all cases.', 'edges created by the bottom - up parsing are assigned a score which is the product of the inside and outside probabilities of the  #TAUTHOR_TAG model']",5
"['- off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are']","['parameter estimation techniques ( smoothing and back - off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are']","['- off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are required to prune the search space of possible parses,']","['parameter estimation techniques ( smoothing and back - off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are required to prune the search space of possible parses, due to the complexity of the parsing algorithm and the size of the word lattices.', 'the main technique we employ is a variation of the beam search of  #TAUTHOR_TAG to restrict the chart size by excluding low probability edges.', 'the total score ( combined acoustic and language model scores ) of candidate edges are compared against edge with the same span and category.', 'proposed edges with score outside the beam are not added to the chart.', 'the drawback to this process is that we can no longer guarantee that a model - optimal solution will be found.', 'in practice, these heuristics have a negative effect on parse accuracy, but the amount of pruning can be tuned to balance relative time and space savings against precision and recall degradation  #TAUTHOR_TAG.', ' #TAUTHOR_TAG uses a fixed size beam ( 10 000 ).', 'we experiment with several variable beam ( b ) sizes, where the beam is some function of a base beam ( b ) and the edge width ( the number of terminals dominated by an edge ).', '']",5
"['word lattices.', 'two different corpora were used in training the parsing model on word lattices :', 'sections  #TAUTHOR_TAG.', 'section']","['word lattices.', 'two different corpora were used in training the parsing model on word lattices :', 'sections  #TAUTHOR_TAG.', 'section "" 1987 "" of the bllip corpus  #AUTHOR_TAG [ 20']","['by parsing strings carries over approximately to parsing word lattices.', 'two different corpora were used in training the parsing model on word lattices :', 'sections  #TAUTHOR_TAG.', 'section "" 1987 "" of the bllip corpus  #AUTHOR_TAG [ 20 million']","['success of the parsing model as a language model for speech recognition was measured both by parsing accuracy ( parsing strings with annotated reference parses ), and by wer.', 'wer is measured by parsing word lattices and comparing the sentence yield of the highest scoring parse tree to the reference transcription ( using nist sclite for alignment and error calculation ).', '5 we assume the parsing performance achieved by parsing strings carries over approximately to parsing word lattices.', 'two different corpora were used in training the parsing model on word lattices :', 'sections  #TAUTHOR_TAG.', 'section "" 1987 "" of the bllip corpus  #AUTHOR_TAG [ 20 million words ] the bllip corpus is a collection of penn treebank - style parses of the three - year ( 1987 ) ( 1988 ) ( 1989 ) wall street journal collection from the acl / dci corpus ( approximately 30 million words ).', '6 the parses were automatically produced by the parser of  #AUTHOR_TAG.', 'as the memory usage of our model corresponds directly to the amount of training data used, we were restricted by available memory to use only one section ( 1987 ) of the total corpus.', '']",5
"['automated speech understanding, such as in higher semantic parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG presents three lexicalized models which consider long - distance dependencies within a']","['automated speech understanding, such as in higher semantic parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG presents three lexicalized models which consider long - distance dependencies within a sentence.', 'grammar productions']","['automated speech understanding, such as in higher semantic parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG presents three lexicalized models which consider long - distance dependencies within a sentence.', 'grammar productions are conditioned on headwords']","['question of how to integrate high - level knowledge representations of language with automatic speech recognition ( asr ) is becoming more important as ( 1 ) speech recognition technology matures, ( 2 ) the rate of improvement of recognition accuracy decreases, and ( 3 ) the need for additional information ( beyond simple transcriptions ) becomes evident.', 'most of the currently best asr systems use an n - gram language model of the type pioneered by  #AUTHOR_TAG.', 'recently, research has begun to show progress towards application of new and better models of spoken language  #AUTHOR_TAG.', 'our goal is integration of head - driven lexicalized parsing with acoustic and n - gram models for speech recognition, extracting high - level structure from speech, while simultaneously selecting the best path in a word lattice.', 'parse trees generated by this process will be useful for automated speech understanding, such as in higher semantic parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG presents three lexicalized models which consider long - distance dependencies within a sentence.', 'grammar productions are conditioned on headwords.', 'the conditioning context is thus more focused than that of a large n - gram covering the same span, so the sparse data problems arising from the sheer size of the parameter space are less pressing.', 'however, sparse data problems arising from the limited availability of annotated training data become a problem.', 'we test the head - driven statistical lattice parser with word lattices from the nist hub - 1 corpus, which has been used by others in related work  #AUTHOR_TAG.', '']",0
"['', 'these models use much less conditioning information than the parsing models of  #TAUTHOR_TAG,']","['', 'these models use much less conditioning information than the parsing models of  #TAUTHOR_TAG,']","[' #AUTHOR_TAG.', 'these models use much less conditioning information than the parsing models of  #TAUTHOR_TAG,']","['models based on headword dependency relationships have been reported, such as the structured language model of  #AUTHOR_TAG.', 'these models use much less conditioning information than the parsing models of  #TAUTHOR_TAG, and do not provide penn treebank format parse trees as output.', 'in this section we outline the adaptation of the  #TAUTHOR_TAG parsing model to word lattices.', 'the intended action of the parser is illustrated in figure 1, which shows parse trees built directly upon a word lattice']",0
"['of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities -']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities - the probability of']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities -']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities - the probability of some event of interest ( e. g., a left - modifier attachment ) given a context ( e. g., parent non - terminal, distance, headword ).', 'one notable difference between the word lattice parser and the original implementation of  #TAUTHOR_TAG is the handling of part - of - speech ( pos ) tagging of unknown words ( words seen fewer than 5 times in training ).', 'the conditioning context of the parsing model parameters includes pos tagging.', ' #TAUTHOR_TAG falls back to the pos tagging of  #AUTHOR_TAG for words seen fewer than 5 times in the training corpus.', 'as the tagger of  #AUTHOR_TAG cannot tag a word lattice, we cannot back off to this tagging.', 'we rely on the tag assigned by the parsing model in all cases.', 'edges created by the bottom - up parsing are assigned a score which is the product of the inside and outside probabilities of the  #TAUTHOR_TAG model']",0
"['- off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are']","['parameter estimation techniques ( smoothing and back - off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are']","['- off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are required to prune the search space of possible parses,']","['parameter estimation techniques ( smoothing and back - off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are required to prune the search space of possible parses, due to the complexity of the parsing algorithm and the size of the word lattices.', 'the main technique we employ is a variation of the beam search of  #TAUTHOR_TAG to restrict the chart size by excluding low probability edges.', 'the total score ( combined acoustic and language model scores ) of candidate edges are compared against edge with the same span and category.', 'proposed edges with score outside the beam are not added to the chart.', 'the drawback to this process is that we can no longer guarantee that a model - optimal solution will be found.', 'in practice, these heuristics have a negative effect on parse accuracy, but the amount of pruning can be tuned to balance relative time and space savings against precision and recall degradation  #TAUTHOR_TAG.', ' #TAUTHOR_TAG uses a fixed size beam ( 10 000 ).', 'we experiment with several variable beam ( b ) sizes, where the beam is some function of a base beam ( b ) and the edge width ( the number of terminals dominated by an edge ).', '']",0
"['- off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are']","['parameter estimation techniques ( smoothing and back - off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are']","['- off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are required to prune the search space of possible parses,']","['parameter estimation techniques ( smoothing and back - off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are required to prune the search space of possible parses, due to the complexity of the parsing algorithm and the size of the word lattices.', 'the main technique we employ is a variation of the beam search of  #TAUTHOR_TAG to restrict the chart size by excluding low probability edges.', 'the total score ( combined acoustic and language model scores ) of candidate edges are compared against edge with the same span and category.', 'proposed edges with score outside the beam are not added to the chart.', 'the drawback to this process is that we can no longer guarantee that a model - optimal solution will be found.', 'in practice, these heuristics have a negative effect on parse accuracy, but the amount of pruning can be tuned to balance relative time and space savings against precision and recall degradation  #TAUTHOR_TAG.', ' #TAUTHOR_TAG uses a fixed size beam ( 10 000 ).', 'we experiment with several variable beam ( b ) sizes, where the beam is some function of a base beam ( b ) and the edge width ( the number of terminals dominated by an edge ).', '']",0
"['automated speech understanding, such as in higher semantic parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG presents three lexicalized models which consider long - distance dependencies within a']","['automated speech understanding, such as in higher semantic parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG presents three lexicalized models which consider long - distance dependencies within a sentence.', 'grammar productions']","['automated speech understanding, such as in higher semantic parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG presents three lexicalized models which consider long - distance dependencies within a sentence.', 'grammar productions are conditioned on headwords']","['question of how to integrate high - level knowledge representations of language with automatic speech recognition ( asr ) is becoming more important as ( 1 ) speech recognition technology matures, ( 2 ) the rate of improvement of recognition accuracy decreases, and ( 3 ) the need for additional information ( beyond simple transcriptions ) becomes evident.', 'most of the currently best asr systems use an n - gram language model of the type pioneered by  #AUTHOR_TAG.', 'recently, research has begun to show progress towards application of new and better models of spoken language  #AUTHOR_TAG.', 'our goal is integration of head - driven lexicalized parsing with acoustic and n - gram models for speech recognition, extracting high - level structure from speech, while simultaneously selecting the best path in a word lattice.', 'parse trees generated by this process will be useful for automated speech understanding, such as in higher semantic parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG presents three lexicalized models which consider long - distance dependencies within a sentence.', 'grammar productions are conditioned on headwords.', 'the conditioning context is thus more focused than that of a large n - gram covering the same span, so the sparse data problems arising from the sheer size of the parameter space are less pressing.', 'however, sparse data problems arising from the limited availability of annotated training data become a problem.', 'we test the head - driven statistical lattice parser with word lattices from the nist hub - 1 corpus, which has been used by others in related work  #AUTHOR_TAG.', '']",6
"['- off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are']","['parameter estimation techniques ( smoothing and back - off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are']","['- off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are required to prune the search space of possible parses,']","['parameter estimation techniques ( smoothing and back - off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are required to prune the search space of possible parses, due to the complexity of the parsing algorithm and the size of the word lattices.', 'the main technique we employ is a variation of the beam search of  #TAUTHOR_TAG to restrict the chart size by excluding low probability edges.', 'the total score ( combined acoustic and language model scores ) of candidate edges are compared against edge with the same span and category.', 'proposed edges with score outside the beam are not added to the chart.', 'the drawback to this process is that we can no longer guarantee that a model - optimal solution will be found.', 'in practice, these heuristics have a negative effect on parse accuracy, but the amount of pruning can be tuned to balance relative time and space savings against precision and recall degradation  #TAUTHOR_TAG.', ' #TAUTHOR_TAG uses a fixed size beam ( 10 000 ).', 'we experiment with several variable beam ( b ) sizes, where the beam is some function of a base beam ( b ) and the edge width ( the number of terminals dominated by an edge ).', '']",6
"['original implementation of  #TAUTHOR_TAG.', 'the wer scores for this, the first application of the  #TAUTHOR_TAG model to parsing word lattices, are comparable to other recent work in syntactic language modelling, and better than a simple trigram model trained on the same data.', '3 parse trees are commonly scored with the parseval set of metrics  #AUTHOR_TAG']","['original implementation of  #TAUTHOR_TAG.', 'the wer scores for this, the first application of the  #TAUTHOR_TAG model to parsing word lattices, are comparable to other recent work in syntactic language modelling, and better than a simple trigram model trained on the same data.', '3 parse trees are commonly scored with the parseval set of metrics  #AUTHOR_TAG']","['parsing strings which are lower than the original implementation of  #TAUTHOR_TAG.', 'the wer scores for this, the first application of the  #TAUTHOR_TAG model to parsing word lattices, are comparable to other recent work in syntactic language modelling, and better than a simple trigram model trained on the same data.', '3 parse trees are commonly scored with the parseval set of metrics  #AUTHOR_TAG']","['word lattice parser was evaluated with several metrics - wer, labelled precision and recall, crossing brackets, and time and space resource usage.', ' #AUTHOR_TAG, we conducted evaluations using two experimental sets - strings and word lattices.', 'we optimized settings ( thresholds, variable beam function, base beam value ) for parsing using development test data consisting of strings for which we have annotated parse trees.', 'the parsing accuracy for parsing word lattices was not directly evaluated as we did not have annotated parse trees for comparison.', 'furthermore, standard parsing measures such as labelled precision and recall are not directly applicable in cases where the number of words differs between the proposed parse tree and the gold standard.', 'results show scores for parsing strings which are lower than the original implementation of  #TAUTHOR_TAG.', 'the wer scores for this, the first application of the  #TAUTHOR_TAG model to parsing word lattices, are comparable to other recent work in syntactic language modelling, and better than a simple trigram model trained on the same data.', '3 parse trees are commonly scored with the parseval set of metrics  #AUTHOR_TAG']",6
['parsing model of  #TAUTHOR_TAG for'],['parsing model of  #TAUTHOR_TAG for'],['this work we present an adaptation of the parsing model of  #TAUTHOR_TAG for'],"['this work we present an adaptation of the parsing model of  #TAUTHOR_TAG for application to asr.', 'the system was evaluated over two sets of data : strings and word lattices.', 'as parseval measures are not applicable to word lattices, we measured the parsing accuracy using string input.', 'the resulting scores were lower than that original implementation of the model.', 'despite this, the model was successful as a language model for speech recognition, as measured by wer and ability to extract high - level information.', 'here, the system performs better than a simple n - gram model trained on the same data, while simultaneously providing syntactic information in the form of parse trees.', 'wer scores are comparable to related works in this area.', 'the large size of the parameter set of this parsing model necessarily restricts the size of training data that may be used.', 'in addition, the resource requirements currently present a challenge for scaling up from the relatively sparse word lattices of the nist hub - 1 corpus ( created in a lab setting by professional readers ) to lattices created with spontaneous speech in non - ideal conditions.', 'an investigation into the relevant importance of each parameter for the speech recognition task may allow a reduction in the size of the parameter space, with minimal loss of recognition accuracy.', 'a speedup may be achieved, and additional training data could be used.', 'tuning of parameters using em has lead to improved wer for other models.', 'we encourage investigation of this technique for lexicalized head - driven lattice parsing']",6
"['of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities -']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities - the probability of']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities -']","['parameterization of model ii of  #TAUTHOR_TAG is used in our word lattice parser.', 'parameters are maximum likelihood estimates of conditional probabilities - the probability of some event of interest ( e. g., a left - modifier attachment ) given a context ( e. g., parent non - terminal, distance, headword ).', 'one notable difference between the word lattice parser and the original implementation of  #TAUTHOR_TAG is the handling of part - of - speech ( pos ) tagging of unknown words ( words seen fewer than 5 times in training ).', 'the conditioning context of the parsing model parameters includes pos tagging.', ' #TAUTHOR_TAG falls back to the pos tagging of  #AUTHOR_TAG for words seen fewer than 5 times in the training corpus.', 'as the tagger of  #AUTHOR_TAG cannot tag a word lattice, we cannot back off to this tagging.', 'we rely on the tag assigned by the parsing model in all cases.', 'edges created by the bottom - up parsing are assigned a score which is the product of the inside and outside probabilities of the  #TAUTHOR_TAG model']",4
"['- off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are']","['parameter estimation techniques ( smoothing and back - off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are']","['- off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are required to prune the search space of possible parses,']","['parameter estimation techniques ( smoothing and back - off ) of  #TAUTHOR_TAG are reimplemented.', 'additional techniques are required to prune the search space of possible parses, due to the complexity of the parsing algorithm and the size of the word lattices.', 'the main technique we employ is a variation of the beam search of  #TAUTHOR_TAG to restrict the chart size by excluding low probability edges.', 'the total score ( combined acoustic and language model scores ) of candidate edges are compared against edge with the same span and category.', 'proposed edges with score outside the beam are not added to the chart.', 'the drawback to this process is that we can no longer guarantee that a model - optimal solution will be found.', 'in practice, these heuristics have a negative effect on parse accuracy, but the amount of pruning can be tuned to balance relative time and space savings against precision and recall degradation  #TAUTHOR_TAG.', ' #TAUTHOR_TAG uses a fixed size beam ( 10 000 ).', 'we experiment with several variable beam ( b ) sizes, where the beam is some function of a base beam ( b ) and the edge width ( the number of terminals dominated by an edge ).', '']",4
"['original implementation of  #TAUTHOR_TAG.', 'the wer scores for this, the first application of the  #TAUTHOR_TAG model to parsing word lattices, are comparable to other recent work in syntactic language modelling, and better than a simple trigram model trained on the same data.', '3 parse trees are commonly scored with the parseval set of metrics  #AUTHOR_TAG']","['original implementation of  #TAUTHOR_TAG.', 'the wer scores for this, the first application of the  #TAUTHOR_TAG model to parsing word lattices, are comparable to other recent work in syntactic language modelling, and better than a simple trigram model trained on the same data.', '3 parse trees are commonly scored with the parseval set of metrics  #AUTHOR_TAG']","['parsing strings which are lower than the original implementation of  #TAUTHOR_TAG.', 'the wer scores for this, the first application of the  #TAUTHOR_TAG model to parsing word lattices, are comparable to other recent work in syntactic language modelling, and better than a simple trigram model trained on the same data.', '3 parse trees are commonly scored with the parseval set of metrics  #AUTHOR_TAG']","['word lattice parser was evaluated with several metrics - wer, labelled precision and recall, crossing brackets, and time and space resource usage.', ' #AUTHOR_TAG, we conducted evaluations using two experimental sets - strings and word lattices.', 'we optimized settings ( thresholds, variable beam function, base beam value ) for parsing using development test data consisting of strings for which we have annotated parse trees.', 'the parsing accuracy for parsing word lattices was not directly evaluated as we did not have annotated parse trees for comparison.', 'furthermore, standard parsing measures such as labelled precision and recall are not directly applicable in cases where the number of words differs between the proposed parse tree and the gold standard.', 'results show scores for parsing strings which are lower than the original implementation of  #TAUTHOR_TAG.', 'the wer scores for this, the first application of the  #TAUTHOR_TAG model to parsing word lattices, are comparable to other recent work in syntactic language modelling, and better than a simple trigram model trained on the same data.', '3 parse trees are commonly scored with the parseval set of metrics  #AUTHOR_TAG']",4
"['original implementation of model ii  #TAUTHOR_TAG.', 'this']","['original implementation of model ii  #TAUTHOR_TAG.', 'this']","['the original implementation of model ii  #TAUTHOR_TAG.', 'this difference is likely']","['lattice parser can parse strings by creating a single - path lattice from the input ( all word transitions are assigned an input score of 1. 0 ).', 'the lattice parser was trained on sections 02 - 21 of the wall street journal portion of the penn treebank  #AUTHOR_TAG development testing was carried out on section 23 in order to select model thresholds and variable beam functions.', 'final testing was carried out on section 00, and the parseval measures  #AUTHOR_TAG were used to evaluate the performance.', 'the scores for our experiments are lower than the scores of the original implementation of model ii  #TAUTHOR_TAG.', 'this difference is likely due in part to differences in pos tagging.', 'tag accuracy for our model was 93. 2 %, whereas for the original implementation of  #TAUTHOR_TAG, model ii achieved tag accuracy of 96. 75 %.', 'in addition to different tagging strategies for unknown words, mentioned above, we restrict the tag - set considered by the parser for each word to those suggested by a simple first - stage tagger.', '4 by reducing the tag - set considered by the parsing model, we reduce the search space and increase the speed.', 'however, the simple tagger used to narrow the search also introduces tagging error.', 'the utility of the overparsing extension can be seen in table 1.', 'each of the parseval measures improves when overparsing is used']",4
"['original implementation of model ii  #TAUTHOR_TAG.', 'this']","['original implementation of model ii  #TAUTHOR_TAG.', 'this']","['the original implementation of model ii  #TAUTHOR_TAG.', 'this difference is likely']","['lattice parser can parse strings by creating a single - path lattice from the input ( all word transitions are assigned an input score of 1. 0 ).', 'the lattice parser was trained on sections 02 - 21 of the wall street journal portion of the penn treebank  #AUTHOR_TAG development testing was carried out on section 23 in order to select model thresholds and variable beam functions.', 'final testing was carried out on section 00, and the parseval measures  #AUTHOR_TAG were used to evaluate the performance.', 'the scores for our experiments are lower than the scores of the original implementation of model ii  #TAUTHOR_TAG.', 'this difference is likely due in part to differences in pos tagging.', 'tag accuracy for our model was 93. 2 %, whereas for the original implementation of  #TAUTHOR_TAG, model ii achieved tag accuracy of 96. 75 %.', 'in addition to different tagging strategies for unknown words, mentioned above, we restrict the tag - set considered by the parser for each word to those suggested by a simple first - stage tagger.', '4 by reducing the tag - set considered by the parsing model, we reduce the search space and increase the speed.', 'however, the simple tagger used to narrow the search also introduces tagging error.', 'the utility of the overparsing extension can be seen in table 1.', 'each of the parseval measures improves when overparsing is used']",4
"['time.', 'by contrast,  #TAUTHOR_TAG calculates parameter values by looking up event counts at run - time.', '']","['time.', 'by contrast,  #TAUTHOR_TAG calculates parameter values by looking up event counts at run - time.', '']","['memory usage by the chart and parameter set  #AUTHOR_TAG.', 'to increase parameter lookup speed, all parameter values are calculated for all levels of back - off at training time.', 'by contrast,  #TAUTHOR_TAG calculates parameter values by looking up event counts at run - time.', 'the implementation was then optimized using a memory']","['algorithms and data structures were designed to minimize parameter lookup times and memory usage by the chart and parameter set  #AUTHOR_TAG.', 'to increase parameter lookup speed, all parameter values are calculated for all levels of back - off at training time.', 'by contrast,  #TAUTHOR_TAG calculates parameter values by looking up event counts at run - time.', 'the implementation was then optimized using a memory and processor profiler and debugger.', 'parsing the complete set of hub - 1 lattices ( 213 sentences, a total of 3, 446 words ) on average takes approximately 8 hours, on an intel pentium 4 ( 1. 6ghz ) linux system, using 1gb memory.', 'memory requirements for parsing lattices is vastly greater than equivalent parsing of a single sentence, as chart size increases with the number of divergent paths in a lattice.', 'additional analysis of resource issues can be found in  #AUTHOR_TAG']",4
"['[  #TAUTHOR_TAG ].', 'we']","['clevr [  #TAUTHOR_TAG ].', 'we']","['clevr [  #TAUTHOR_TAG ].', 'we generate acoustic scenes']","['', 'in this task an agent learns to answer questions on the basis of acoustic context.', 'in order to promote research in this area, we propose a data generation paradigm adapted from clevr [  #TAUTHOR_TAG ].', 'we generate acoustic scenes by leveraging a bank of elementary sounds.', 'we also provide a number of functional programs that can be used to compose questions and answers that exploit the relationships between the attributes of the elementary sounds in each scene.', 'we provide aqa datasets of various sizes as well as the data generation code.', 'as a preliminary experiment to validate our data, we report the accuracy of current state of the art visual question answering models when they are applied to the aqa task without modifications.', 'although there is a plethora of question answering tasks based on text, image or video data, to our knowledge, we are the first to propose answering questions directly on audio streams.', 'we hope this contribution will facilitate the development of research in the area']",6
"['in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps']","['in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps']","['in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps']","['are structured in a logical tree introduced in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps required to answer a question given a scene definition.', 'we adapted the original work of  #TAUTHOR_TAG to our acoustical context by updating the function catalog and the relationships between the objects of the scene.', 'for example we added the before and after temporal relationships.', 'in natural language, there is more than one way to ask a question that has the same meaning.', '']",6
"['generation that is an extension of the  #TAUTHOR_TAG paradigm : the acoustic scenes are generated by combining a number of elementary sounds,']","['generation that is an extension of the  #TAUTHOR_TAG paradigm : the acoustic scenes are generated by combining a number of elementary sounds,']","[') as a means to stimulate ai and reasoning research on acoustic scenes.', 'we also propose a paradigm for data generation that is an extension of the  #TAUTHOR_TAG paradigm : the acoustic scenes are generated by combining a number of elementary sounds,']","['introduce the new task of acoustic question answering ( aqa ) as a means to stimulate ai and reasoning research on acoustic scenes.', 'we also propose a paradigm for data generation that is an extension of the  #TAUTHOR_TAG paradigm : the acoustic scenes are generated by combining a number of elementary sounds, and the corresponding questions and answers are generated based on the properties of those sounds and their mutual relationships.', 'we generated a preliminary dataset comprising 50k acoustic scenes composed of 10 musical instrument sounds, and 2m corresponding questions and answers.', 'we also tested the film model on the preliminary dataset obtaining at best 89. 97 % accuracy predicting the right answer from the question and the scene.', 'although these preliminary results are very encouraging, we consider this as a first step in creating datasets that will promote research in acoustic reasoning.', 'the following is a list of limitations that we intend to address in future versions of the dataset']",6
"[' #TAUTHOR_TAG, 2, 25,', '7 ]']","[' #TAUTHOR_TAG, 2, 25,', '7 ]']","[' #TAUTHOR_TAG, 2, 25,', '7 ]']","['e. g. [ 5, 6, 22, 13, 14, 21 ] )', '. in the last case, however, the acoustic information is usually expressed in text form, either with manual transcriptions ( e', '. g. subtitles ) or by automatic speech recognition, and is limited to linguistic information [ 24 ]. the task presented in this paper differs from the above by answering questions directly on audio streams. we argue that the audio modality contains important information that has not been exploited in the question answering domain. this information may allow qa systems to answer relevant questions more accurately', ', or even to answer questions that are not approachable from the visual domain alone. examples of potential applications are the detection of anomalies in machinery where the moving parts are hidden, the detection of threatening', 'or hazardous events, industrial and social robotics. current question answering methods require large amounts of annotated data. in the visual domain, several strategies have been proposed to make this kind of data available to the community [  #TAUTHOR_TAG, 2, 25,', '7 ]. agrawal et al. [ 1 ] noted that the way the questions', 'are created has a huge impact on what information a neural network uses to answer them ( this is a', 'well known problem that can arise with in what part of the scene is the clarinet playing a g note that is before the third violin sound', '? beginning, middle, end ( of the scene ) 3 total 47 all neural network based systems ). this motivated research [ 23, 8,  #TAUTHOR_TAG ]', 'on how to reduce the bias in vqa datasets.', 'the complexity around gathering good labeled data forced some authors [ 23, 8 ] to constrain their work to yes / no questions.  #TAUTHOR_TAG made their way around', 'this constraint by using synthetic data. to generate the questions, they first generate a semantic representation that describes the reasoning steps needed in order to answer the question. this gives them full control over the labelling process and a better understanding of the semantic meaning of the questions. they leverage this ability to reduce the bias in the synthesized data.', 'for example, they ensure that none of the generated questions', 'contains hints about the answer. inspired by the', 'work on  #TAUTHOR_TAG ], we propose an acoustical question answering ( aqa ) task by defining a synthetic', 'dataset that comprises audio scenes composed by sequences of elementary sounds and questions relating properties of the sounds in each scene. we provide the', 'adapted software for aqa data generation as well as a version', 'of the dataset based on musical instrument sounds. we also report preliminary experiments using the film architecture derived from the vqa domain', '']",0
"[' #TAUTHOR_TAG, 2, 25,', '7 ]']","[' #TAUTHOR_TAG, 2, 25,', '7 ]']","[' #TAUTHOR_TAG, 2, 25,', '7 ]']","['e. g. [ 5, 6, 22, 13, 14, 21 ] )', '. in the last case, however, the acoustic information is usually expressed in text form, either with manual transcriptions ( e', '. g. subtitles ) or by automatic speech recognition, and is limited to linguistic information [ 24 ]. the task presented in this paper differs from the above by answering questions directly on audio streams. we argue that the audio modality contains important information that has not been exploited in the question answering domain. this information may allow qa systems to answer relevant questions more accurately', ', or even to answer questions that are not approachable from the visual domain alone. examples of potential applications are the detection of anomalies in machinery where the moving parts are hidden, the detection of threatening', 'or hazardous events, industrial and social robotics. current question answering methods require large amounts of annotated data. in the visual domain, several strategies have been proposed to make this kind of data available to the community [  #TAUTHOR_TAG, 2, 25,', '7 ]. agrawal et al. [ 1 ] noted that the way the questions', 'are created has a huge impact on what information a neural network uses to answer them ( this is a', 'well known problem that can arise with in what part of the scene is the clarinet playing a g note that is before the third violin sound', '? beginning, middle, end ( of the scene ) 3 total 47 all neural network based systems ). this motivated research [ 23, 8,  #TAUTHOR_TAG ]', 'on how to reduce the bias in vqa datasets.', 'the complexity around gathering good labeled data forced some authors [ 23, 8 ] to constrain their work to yes / no questions.  #TAUTHOR_TAG made their way around', 'this constraint by using synthetic data. to generate the questions, they first generate a semantic representation that describes the reasoning steps needed in order to answer the question. this gives them full control over the labelling process and a better understanding of the semantic meaning of the questions. they leverage this ability to reduce the bias in the synthesized data.', 'for example, they ensure that none of the generated questions', 'contains hints about the answer. inspired by the', 'work on  #TAUTHOR_TAG ], we propose an acoustical question answering ( aqa ) task by defining a synthetic', 'dataset that comprises audio scenes composed by sequences of elementary sounds and questions relating properties of the sounds in each scene. we provide the', 'adapted software for aqa data generation as well as a version', 'of the dataset based on musical instrument sounds. we also report preliminary experiments using the film architecture derived from the vqa domain', '']",0
"[' #TAUTHOR_TAG, 2, 25,', '7 ]']","[' #TAUTHOR_TAG, 2, 25,', '7 ]']","[' #TAUTHOR_TAG, 2, 25,', '7 ]']","['e. g. [ 5, 6, 22, 13, 14, 21 ] )', '. in the last case, however, the acoustic information is usually expressed in text form, either with manual transcriptions ( e', '. g. subtitles ) or by automatic speech recognition, and is limited to linguistic information [ 24 ]. the task presented in this paper differs from the above by answering questions directly on audio streams. we argue that the audio modality contains important information that has not been exploited in the question answering domain. this information may allow qa systems to answer relevant questions more accurately', ', or even to answer questions that are not approachable from the visual domain alone. examples of potential applications are the detection of anomalies in machinery where the moving parts are hidden, the detection of threatening', 'or hazardous events, industrial and social robotics. current question answering methods require large amounts of annotated data. in the visual domain, several strategies have been proposed to make this kind of data available to the community [  #TAUTHOR_TAG, 2, 25,', '7 ]. agrawal et al. [ 1 ] noted that the way the questions', 'are created has a huge impact on what information a neural network uses to answer them ( this is a', 'well known problem that can arise with in what part of the scene is the clarinet playing a g note that is before the third violin sound', '? beginning, middle, end ( of the scene ) 3 total 47 all neural network based systems ). this motivated research [ 23, 8,  #TAUTHOR_TAG ]', 'on how to reduce the bias in vqa datasets.', 'the complexity around gathering good labeled data forced some authors [ 23, 8 ] to constrain their work to yes / no questions.  #TAUTHOR_TAG made their way around', 'this constraint by using synthetic data. to generate the questions, they first generate a semantic representation that describes the reasoning steps needed in order to answer the question. this gives them full control over the labelling process and a better understanding of the semantic meaning of the questions. they leverage this ability to reduce the bias in the synthesized data.', 'for example, they ensure that none of the generated questions', 'contains hints about the answer. inspired by the', 'work on  #TAUTHOR_TAG ], we propose an acoustical question answering ( aqa ) task by defining a synthetic', 'dataset that comprises audio scenes composed by sequences of elementary sounds and questions relating properties of the sounds in each scene. we provide the', 'adapted software for aqa data generation as well as a version', 'of the dataset based on musical instrument sounds. we also report preliminary experiments using the film architecture derived from the vqa domain', '']",0
"[' #TAUTHOR_TAG, 2, 25,', '7 ]']","[' #TAUTHOR_TAG, 2, 25,', '7 ]']","[' #TAUTHOR_TAG, 2, 25,', '7 ]']","['e. g. [ 5, 6, 22, 13, 14, 21 ] )', '. in the last case, however, the acoustic information is usually expressed in text form, either with manual transcriptions ( e', '. g. subtitles ) or by automatic speech recognition, and is limited to linguistic information [ 24 ]. the task presented in this paper differs from the above by answering questions directly on audio streams. we argue that the audio modality contains important information that has not been exploited in the question answering domain. this information may allow qa systems to answer relevant questions more accurately', ', or even to answer questions that are not approachable from the visual domain alone. examples of potential applications are the detection of anomalies in machinery where the moving parts are hidden, the detection of threatening', 'or hazardous events, industrial and social robotics. current question answering methods require large amounts of annotated data. in the visual domain, several strategies have been proposed to make this kind of data available to the community [  #TAUTHOR_TAG, 2, 25,', '7 ]. agrawal et al. [ 1 ] noted that the way the questions', 'are created has a huge impact on what information a neural network uses to answer them ( this is a', 'well known problem that can arise with in what part of the scene is the clarinet playing a g note that is before the third violin sound', '? beginning, middle, end ( of the scene ) 3 total 47 all neural network based systems ). this motivated research [ 23, 8,  #TAUTHOR_TAG ]', 'on how to reduce the bias in vqa datasets.', 'the complexity around gathering good labeled data forced some authors [ 23, 8 ] to constrain their work to yes / no questions.  #TAUTHOR_TAG made their way around', 'this constraint by using synthetic data. to generate the questions, they first generate a semantic representation that describes the reasoning steps needed in order to answer the question. this gives them full control over the labelling process and a better understanding of the semantic meaning of the questions. they leverage this ability to reduce the bias in the synthesized data.', 'for example, they ensure that none of the generated questions', 'contains hints about the answer. inspired by the', 'work on  #TAUTHOR_TAG ], we propose an acoustical question answering ( aqa ) task by defining a synthetic', 'dataset that comprises audio scenes composed by sequences of elementary sounds and questions relating properties of the sounds in each scene. we provide the', 'adapted software for aqa data generation as well as a version', 'of the dataset based on musical instrument sounds. we also report preliminary experiments using the film architecture derived from the vqa domain', '']",0
"[' #TAUTHOR_TAG, 2, 25,', '7 ]']","[' #TAUTHOR_TAG, 2, 25,', '7 ]']","[' #TAUTHOR_TAG, 2, 25,', '7 ]']","['e. g. [ 5, 6, 22, 13, 14, 21 ] )', '. in the last case, however, the acoustic information is usually expressed in text form, either with manual transcriptions ( e', '. g. subtitles ) or by automatic speech recognition, and is limited to linguistic information [ 24 ]. the task presented in this paper differs from the above by answering questions directly on audio streams. we argue that the audio modality contains important information that has not been exploited in the question answering domain. this information may allow qa systems to answer relevant questions more accurately', ', or even to answer questions that are not approachable from the visual domain alone. examples of potential applications are the detection of anomalies in machinery where the moving parts are hidden, the detection of threatening', 'or hazardous events, industrial and social robotics. current question answering methods require large amounts of annotated data. in the visual domain, several strategies have been proposed to make this kind of data available to the community [  #TAUTHOR_TAG, 2, 25,', '7 ]. agrawal et al. [ 1 ] noted that the way the questions', 'are created has a huge impact on what information a neural network uses to answer them ( this is a', 'well known problem that can arise with in what part of the scene is the clarinet playing a g note that is before the third violin sound', '? beginning, middle, end ( of the scene ) 3 total 47 all neural network based systems ). this motivated research [ 23, 8,  #TAUTHOR_TAG ]', 'on how to reduce the bias in vqa datasets.', 'the complexity around gathering good labeled data forced some authors [ 23, 8 ] to constrain their work to yes / no questions.  #TAUTHOR_TAG made their way around', 'this constraint by using synthetic data. to generate the questions, they first generate a semantic representation that describes the reasoning steps needed in order to answer the question. this gives them full control over the labelling process and a better understanding of the semantic meaning of the questions. they leverage this ability to reduce the bias in the synthesized data.', 'for example, they ensure that none of the generated questions', 'contains hints about the answer. inspired by the', 'work on  #TAUTHOR_TAG ], we propose an acoustical question answering ( aqa ) task by defining a synthetic', 'dataset that comprises audio scenes composed by sequences of elementary sounds and questions relating properties of the sounds in each scene. we provide the', 'adapted software for aqa data generation as well as a version', 'of the dataset based on musical instrument sounds. we also report preliminary experiments using the film architecture derived from the vqa domain', '']",1
"[' #TAUTHOR_TAG, 12 ]']","[' #TAUTHOR_TAG, 12 ]']","['section presents the dataset and the generation process 1.', 'in this first version ( version 1. 0 ) we created multiple instances of the dataset with 1000, 10000 and 50000 acoustic scenes for which we generated 20 to 40 questions and answers per scene.', 'in total, we generated six instances of the dataset.', 'to represent questions, we use the same semantic representation through functional programs that is proposed in [  #TAUTHOR_TAG, 12 ]']","['section presents the dataset and the generation process 1.', 'in this first version ( version 1. 0 ) we created multiple instances of the dataset with 1000, 10000 and 50000 acoustic scenes for which we generated 20 to 40 questions and answers per scene.', 'in total, we generated six instances of the dataset.', 'to represent questions, we use the same semantic representation through functional programs that is proposed in [  #TAUTHOR_TAG, 12 ]']",5
"['in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps']","['in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps']","['in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps']","['are structured in a logical tree introduced in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps required to answer a question given a scene definition.', 'we adapted the original work of  #TAUTHOR_TAG to our acoustical context by updating the function catalog and the relationships between the objects of the scene.', 'for example we added the before and after temporal relationships.', 'in natural language, there is more than one way to ask a question that has the same meaning.', '']",5
"['in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps']","['in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps']","['in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps']","['are structured in a logical tree introduced in  #TAUTHOR_TAG ] as a functional program.', 'a functional program, defines the reasoning steps required to answer a question given a scene definition.', 'we adapted the original work of  #TAUTHOR_TAG to our acoustical context by updating the function catalog and the relationships between the objects of the scene.', 'for example we added the before and after temporal relationships.', 'in natural language, there is more than one way to ask a question that has the same meaning.', '']",5
"['has been shown to work well on the  #TAUTHOR_TAG ] that shares the same structure of questions as our clear dataset.', 'to represent acoustic scenes in a format compatible with film, we']","['has been shown to work well on the  #TAUTHOR_TAG ] that shares the same structure of questions as our clear dataset.', 'to represent acoustic scenes in a format compatible with film, we']","['evaluate our dataset, we performed preliminary experiments with a film network [ 15 ].', 'it is a good candidate as it has been shown to work well on the  #TAUTHOR_TAG ] that shares the same structure of questions as our clear dataset.', 'to represent acoustic scenes in a format compatible with film, we computed spectro']","['evaluate our dataset, we performed preliminary experiments with a film network [ 15 ].', 'it is a good candidate as it has been shown to work well on the  #TAUTHOR_TAG ] that shares the same structure of questions as our clear dataset.', 'to represent acoustic scenes in a format compatible with film, we computed spectrograms ( log amplitude of the spectrum at regular intervals in time ) and treated them as images.', 'each scene corresponds to a fixed resolution image because we have designed the dataset to include acoustic scenes of the same length in time.', 'the best results were obtained with a training on 35000 scenes and 1400000 questions / answers.', 'it yields a 89. 97 % accuracy on the test set that comprises 7500 scenes and 300000 questions.', 'for the same test set a classifier choosing always the majority class would obtain as little as 7. 6 % accuracy']",5
"['', ' #TAUTHOR_TAG incorporate length normalization in']","['better mappings.', ' #TAUTHOR_TAG incorporate length normalization in']","['better mappings.', ' #TAUTHOR_TAG incorporate length normalization in']","['word embeddings have attracted a lot of attention in recent times  #AUTHOR_TAG kocisky et al., 2014 ; chandar a p et al., 2014 ;  #AUTHOR_TAG gouws and søgaard, 2015 ;  #AUTHOR_TAG.', 'a common approach to obtain them is to train the embeddings in both languages independently and then learn a mapping that minimizes the distances between equivalences listed in a bilingual dictionary.', 'the learned transformation can also be applied to words missing in the dictionary, which can be used to induce new translations with a direct application in machine translation  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'the first method to learn bilingual word embedding mappings was proposed by  #AUTHOR_TAG b ), who learn the linear transformation that minimizes the sum of squared euclidean distances for the dictionary entries.', 'subsequent work has proposed alternative optimization objectives to learn better mappings.', ' #TAUTHOR_TAG incorporate length normalization in the training of word embeddings and try to maximize the cosine similarity instead, introducing an orthogonality constraint to preserve the length normalization after the projection.', ' #AUTHOR_TAG use canonical correlation analysis to project the embeddings in both languages to a shared vector space.', 'beyond linear mappings,  #AUTHOR_TAG apply deep canonical correlation analysis to learn a nonlinear transformation for each language.', 'finally, additional techniques have been used to address the hubness problem in  #AUTHOR_TAG b ), both through the neighbor retrieval method and the training itself.', 'we leave the study of non - linear transformation and other additions for further work.', 'in this paper, we propose a general framework to learn bilingual word embeddings.', 'we start with a basic optimization objective  #AUTHOR_TAG b ) and introduce several meaningful and intuitive constraints that are equivalent or closely related to previously proposed methods  #TAUTHOR_TAG.', 'our framework provides a more general view of bilingual word embedding mappings, showing the underlying connection between the existing methods, revealing some flaws in their theoretical justification and providing an alternative theoretical interpretation for them.', 'our experiments on an existing english - italian word translation induction and an english word analogy task give strong empirical evidence in favor of our theoretical reasoning, while showing that one of our models clearly outperforms previous alternatives']",3
"['.', 'as discussed before,  #AUTHOR_TAG b ) and  #TAUTHOR_TAG were implemented as part of our framework, so']","['without hurting monolingual performance.', 'table 2 shows the results for our best performing configuration in comparison to previous work.', 'as discussed before,  #AUTHOR_TAG b ) and  #TAUTHOR_TAG were implemented as part of our framework, so']","['we obtain further improvements in bilingual performance without hurting monolingual performance.', 'table 2 shows the results for our best performing configuration in comparison to previous work.', 'as discussed before,  #AUTHOR_TAG b ) and  #TAUTHOR_TAG were implemented as part of our framework, so they correspond to our uncostrained mapping with no preprocessing and orthogonal mapping with length normalization, respectively']","['rows in table 1 show, respectively, the results for the original embeddings, the basic mapping proposed by  #AUTHOR_TAG b ) ( cf. section 2 ) and the addition of orthogonality constraint ( cf. section 2. 1 ), with and without length normalization and, incrementally, mean centering.', 'in all the cases, length normalization and mean centering were applied to all embeddings, even if missing from the dictionary.', 'the results show that the orthogonality constraint is key to preserve monolingual performance, and it also improves bilingual performance by enforcing a relevant property ( monolingual invariance ) that the transformation to learn should intuitively have.', 'the contribution of length normalization alone is marginal, but when followed by mean centering we obtain further improvements in bilingual performance without hurting monolingual performance.', 'table 2 shows the results for our best performing configuration in comparison to previous work.', 'as discussed before,  #AUTHOR_TAG b ) and  #TAUTHOR_TAG were implemented as part of our framework, so they correspond to our uncostrained mapping with no preprocessing and orthogonal mapping with length normalization, respectively']",3
"['available as an open source project 5. the code for  #AUTHOR_TAG b ) and', ' #TAUTHOR_TAG ( postprocessing']","['available as an open source project 5. the code for  #AUTHOR_TAG b ) and', ' #TAUTHOR_TAG ( postprocessing']","['is applied to them that changes,', 'this affects all the methods in the exact same way, so the results are perfectly comparable among themselves. with these settings, we obtain a coverage', 'of 64. 98 %. we implemented the proposed method in python using numpy, and make it available as an open source project 5. the code for  #AUTHOR_TAG b ) and', ' #TAUTHOR_TAG ( postprocessing']","['monolingual word embeddings trained with the word2vec toolkit using the cbow method with negative sampling', ' #AUTHOR_TAG a ) 3. the english embeddings were trained on a 2. 8 billion word corpus ( ukwac + wikipedia + bnc ), while the 1. 6 billion word corpus', 'itwac was used to train the italian 1', 'while cca is typically defined in terms of correlation ( thus its name ), correlation is invariant to', 'the scaling of variables, so it is possible to constrain the canonical variables to have a fixed variance, as we do, in which case', 'correlation and covariance become equivalent 2 http : / / clic. cimec. unitn. it / [UNK]. dinu / down / 3 the context window was set to 5 words, the dimension of the embeddings to 300, the sub - sampling to 1e - 05 and the number of negative samples to 10 embeddings. the dataset also contains a bilingual dictionary learned from europarl, split into a training set of 5, 000 word pairs and a test set of 1, 500 word pairs, both of them uniformly distributed in frequency bins. accuracy is', 'the evaluation measure. apart from the performance of the projected embeddings in bilingual terms, we are also interested in the monolingual quality of the source language embeddings after the projection. for that purpose, we use the word', 'analogy task proposed by  #AUTHOR_TAG a ), which measures the accuracy on answering questions like "" what is the word that is similar to small in the same sense as biggest is similar to big? "" using simple word vector arithmetic.', 'the dataset they use consists of', '8, 869 semantic and 10, 675 syntactic questions of this type, and is publicly available 4. in order to speed up the experiments,', 'we follow the authors and perform an approximate evaluation by reducing the vocabulary size according to a frequency threshold of 30, 000  #AUTHOR_TAG a ). since the original embeddings are the same in all the cases and it is only the transformation that is applied to them that changes,', 'this affects all the methods in the exact same way, so the results are perfectly comparable among themselves. with these settings, we obtain a coverage', 'of 64. 98 %. we implemented the proposed method in python using numpy, and make it available as an open source project 5. the code for  #AUTHOR_TAG b ) and', ' #TAUTHOR_TAG ( postprocessing instead of constrained training ). as for the method by  #AUTHOR_TAG, we used their original implementation in python and mat - lab 6, which we extended to cover cases where the dictionary contains more than one entry for', 'the same word']",5
"['.', 'as discussed before,  #AUTHOR_TAG b ) and  #TAUTHOR_TAG were implemented as part of our framework, so']","['without hurting monolingual performance.', 'table 2 shows the results for our best performing configuration in comparison to previous work.', 'as discussed before,  #AUTHOR_TAG b ) and  #TAUTHOR_TAG were implemented as part of our framework, so']","['we obtain further improvements in bilingual performance without hurting monolingual performance.', 'table 2 shows the results for our best performing configuration in comparison to previous work.', 'as discussed before,  #AUTHOR_TAG b ) and  #TAUTHOR_TAG were implemented as part of our framework, so they correspond to our uncostrained mapping with no preprocessing and orthogonal mapping with length normalization, respectively']","['rows in table 1 show, respectively, the results for the original embeddings, the basic mapping proposed by  #AUTHOR_TAG b ) ( cf. section 2 ) and the addition of orthogonality constraint ( cf. section 2. 1 ), with and without length normalization and, incrementally, mean centering.', 'in all the cases, length normalization and mean centering were applied to all embeddings, even if missing from the dictionary.', 'the results show that the orthogonality constraint is key to preserve monolingual performance, and it also improves bilingual performance by enforcing a relevant property ( monolingual invariance ) that the transformation to learn should intuitively have.', 'the contribution of length normalization alone is marginal, but when followed by mean centering we obtain further improvements in bilingual performance without hurting monolingual performance.', 'table 2 shows the results for our best performing configuration in comparison to previous work.', 'as discussed before,  #AUTHOR_TAG b ) and  #TAUTHOR_TAG were implemented as part of our framework, so they correspond to our uncostrained mapping with no preprocessing and orthogonal mapping with length normalization, respectively']",5
"['of  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'it is']","['of  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'it is']","['of  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'it is']","['paper develops a new framework to learn bilingual word embedding mappings, generalizing previous work and providing an efficient exact method to learn the optimal transformation.', 'our experiments show the effectiveness of the proposed model and give strong empirical evidence in favor of our reinterpretation of  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'it is the proposed method with the orthogonality constraint and a global preprocessing with length normalization and dimension - wise mean centering that achieves the best overall results both in monolingual and bilingual terms, surpassing those previous methods.', 'in the future, we would like to study non - linear mappings  #AUTHOR_TAG and the additional techniques in.', 'ish ministry of economy and competitiveness ( tadeep tin2015 - 70214 - p ).', 'mikel artetxe enjoys a doctoral grant from the spanish ministry of education, culture and sports']",6
"[', we have proposed in  #TAUTHOR_TAG an approach based on improving']","['of performance.', 'more recently, and departing from such traditional approaches, we have proposed in  #TAUTHOR_TAG an approach based on improving']","['of performance.', 'more recently, and departing from such traditional approaches, we have proposed in  #TAUTHOR_TAG an approach based on improving the comparability of the corpus under consideration, prior to extracting bilingual lexicons.', 'this approach is interesting']","['lexicons are an important resource in multilingual natural language processing tasks such as statistical machine translation  #AUTHOR_TAG and cross - language information retrieval  #AUTHOR_TAG.', 'because it is expensive to manually build bilingual lexicons adapted to different domains, researchers have tried to automatically extract bilingual lexicons from various corpora.', 'compared with parallel corpora, it is much easier to build high - volume comparable corpora, i. e. corpora consisting of documents in different languages covering overlapping information.', 'several studies have focused on the extraction of bilingual lexicons from comparable corpora ( fung and mc  #AUTHOR_TAG dejean et al., 2002 ;  #AUTHOR_TAG.', 'the basic assumption behind most studies on lexicon extraction from comparable corpora is a distributional hypothesis, stating that words which are translation of each other are likely to appear in similar context across languages.', 'on top of this hypothesis, researchers have investigated the use of better representations for word contexts, as well as the use of different methods for matching words across languages.', 'these approaches seem to have reached a plateau in terms of performance.', 'more recently, and departing from such traditional approaches, we have proposed in  #TAUTHOR_TAG an approach based on improving the comparability of the corpus under consideration, prior to extracting bilingual lexicons.', 'this approach is interesting since there is no point in trying to extract lexicons from a corpus with a low degree of comparability, as the probability of finding translations of any given word is low in such cases.', 'we follow here the same general idea and aim, in a first step, at improving the comparability of a given corpus while preserving most of its vocabulary.', 'however, unlike the previous work, we show here that it is possible to guarantee a certain degree of homogeneity for the improved corpus, and that this homogeneity translates into a significant improvement of both the quality of the resulting corpora and the bilingual lexicons extracted']",0
['use of the measure m developed in  #TAUTHOR_TAG : given a comparable corpus'],['use of the measure m developed in  #TAUTHOR_TAG : given a comparable corpus'],"['order to measure the degree of comparability of bilingual corpora, we make use of the measure m developed in  #TAUTHOR_TAG : given a comparable corpus p consisting of an english part p e and a french part p f, the degree of comparability of p is defined as the expectation of finding the translation of any']","['order to measure the degree of comparability of bilingual corpora, we make use of the measure m developed in  #TAUTHOR_TAG : given a comparable corpus p consisting of an english part p e and a french part p f, the degree of comparability of p is defined as the expectation of finding the translation of any given source / target word in the target / source corpus vocabulary.', 'let σ be a function indicating whether a translation from the translation set t w of the word w is found in the vocabulary p v of a corpus p, i. e. :', '']",5
"['the articles below the category society and societe from the wikipedia dump files 3.', 'the bilingual dictionary used in the experiments is constructed from an online dictionary.', 'it consists of 33k distinct english words and 28k distinct french words, constituting 76k translation pairs.', 'in our experiments, we use the method described in this paper, as well as the one in  #TAUTHOR_TAG which is the only alternative method to enhance corpus comparability']","['the articles below the category society and societe from the wikipedia dump files 3.', 'the bilingual dictionary used in the experiments is constructed from an online dictionary.', 'it consists of 33k distinct english words and 28k distinct french words, constituting 76k translation pairs.', 'in our experiments, we use the method described in this paper, as well as the one in  #TAUTHOR_TAG which is the only alternative method to enhance corpus comparability']","['- en and wiki - fr were built by respectively retrieving all the articles below the category society and societe from the wikipedia dump files 3.', 'the bilingual dictionary used in the experiments is constructed from an online dictionary.', 'it consists of 33k distinct english words and 28k distinct french words, constituting 76k translation pairs.', 'in our experiments, we use the method described in this paper, as well as the one in  #TAUTHOR_TAG which is the only alternative method to enhance corpus comparability']","['experiments we have designed in this paper aim at assessing ( a ) whether the clustering - based algorithm we have introduced yields corpora of higher quality in terms of comparability scores, and ( b ) whether the bilingual lexicons extracted from such corpora are of higher quality.', 'several corpora were used in our experiments : the trec 1 associated press corpus ( ap, english ) and the corpora used in the clef 2 campaign including the los angeles times ( lat94, english ), the glasgow herald ( gh95, english ), le monde ( mon94, french ), sda french 94 ( sda94, french ) and sda french 95 ( sda95, french ).', 'in addition, two monolingual corpora wiki - en and wiki - fr were built by respectively retrieving all the articles below the category society and societe from the wikipedia dump files 3.', 'the bilingual dictionary used in the experiments is constructed from an online dictionary.', 'it consists of 33k distinct english words and 28k distinct french words, constituting 76k translation pairs.', 'in our experiments, we use the method described in this paper, as well as the one in  #TAUTHOR_TAG which is the only alternative method to enhance corpus comparability']",5
"['also used the method described in  #TAUTHOR_TAG on the same data,']","['also used the method described in  #TAUTHOR_TAG on the same data,']","['also used the method described in  #TAUTHOR_TAG on the same data, producing resulting corpora p 1']","['this subsection, the clustering algorithm described in section 2. 2. 1 is employed to improve the quality of the comparable corpus.', 'the corpora gh95 and sda95 are used as the original corpus p 0 ( 56k english documents and 42k french documents ).', 'we consider two external corpora : p 1 t ( 109k english documents and 87k french documents ) consisting of the corpora lat94, mon94 and sda94 ; p 2 t ( 368k english documents and 378k french documents ) consisting of wiki - en and wiki - fr.', 'after the clustering process, we obtain the resulting corpora p 1 ( with the external corpus p 1 t ) and p 2 ( with p 2 t ).', 'as mentioned before, we also used the method described in  #TAUTHOR_TAG on the same data, producing resulting corpora p 1 ( with p 1 t ) and p 2 ( with p 2 t ) from p 0.', 'in terms of lexical coverage, p 1 ( resp. p 2 ) covers 97. 9 % ( resp.', '99. 0 % ) of the vocabulary of p 0.', '']",5
['in  #TAUTHOR_TAG ( p 1 and p 2 )'],['in  #TAUTHOR_TAG ( p 1 and p 2 )'],['in  #TAUTHOR_TAG ( p 1 and p 2 )'],"['a first series of experiments, bilingual lexicons were extracted from the corpora obtained by our approach ( p 1 and p 2 ), the corpora obtained by the approach described in  #TAUTHOR_TAG ( p 1 and p 2 ) and the original corpus p 0, with the fixed n value set to 20.', '']",5
['in  #TAUTHOR_TAG which consists in enhancing'],['in  #TAUTHOR_TAG which consists in enhancing'],"['a very small part of the original corpus, whereas our work aims at preserving most of the vocabulary of the original corpus.', 'we have followed here the general approach in  #TAUTHOR_TAG which consists in']","['previous studies on bilingual lexicon extraction from comparable corpora radically differ on resources used and technical choices, it is very difficult to compare them in a unified framework  #AUTHOR_TAG.', 'we compare in this section our method with some ones in the same vein ( i. e. enhancing bilingual corpora prior to extracting bilingual lexicons from them ).', 'some works like  #AUTHOR_TAG and  #AUTHOR_TAG propose methods to extract parallel fragments from comparable corpora.', 'however, their approach only focuses on a very small part of the original corpus, whereas our work aims at preserving most of the vocabulary of the original corpus.', 'we have followed here the general approach in  #TAUTHOR_TAG which consists in enhancing the quality of a comparable corpus prior to extracting information from it.', 'however, despite this latter work, we have shown here a method which ensures homogeneity of the obtained corpus, and which finally leads to comparable corpora of higher quality.', 'in turn such corpora yield better bilingual lexicons extracted']",5
"['10 ],  #TAUTHOR_TAG.', 'in  #TAUTHOR_TAG, authors have used dnn models']","['of cyberbullying [ 10 ],  #TAUTHOR_TAG.', 'in  #TAUTHOR_TAG, authors have used dnn models']","['of cyberbullying [ 10 ],  #TAUTHOR_TAG.', 'in  #TAUTHOR_TAG, authors have used dnn models']",[' #TAUTHOR_TAG'],5
"['this study, we have first reproduced the experiments conducted in  #TAUTHOR_TAG on the datasets used by']","['this study, we have first reproduced the experiments conducted in  #TAUTHOR_TAG on the datasets used by']","['this study, we have first reproduced the experiments conducted in  #TAUTHOR_TAG on the datasets used by the authors namely, formspring']","['this study, we have first reproduced the experiments conducted in  #TAUTHOR_TAG on the datasets used by the authors namely, formspring [ 12 ], wikipedia [ 14 ], and twitter [ 13 ].', 'we have used the same models and experimental setup for our implementations.', 'in this section, we have briefly introduced the datasets and explained the models and other experiment components.', 'for further details please see the reference literature']",5
"['another related task.', 'following  #TAUTHOR_TAG we also implemented the transfer']","['another related task.', 'following  #TAUTHOR_TAG we also implemented the transfer']","['another related task.', 'following  #TAUTHOR_TAG we also implemented the transfer learning procedure to']","['learning is the process of using a model which has been trained on one task for another related task.', 'following  #TAUTHOR_TAG we also implemented the transfer learning procedure to evaluate to what extent the dnn models trained on a social network, here twitter, formspring, and wiki, can successfully detect cyberbullying posts in another social network, i. e., youtube.', 'for this purpose we used the blstm with attention model and experimented with three different approaches.', 'complete transfer learning.', 'in this approach, a model trained on one dataset is directly used in other datasets without any extra training.', 'as the results in table 6 show, the recalls are quite low but varying in all three datasets.', 'this can indicate that the nature of cyberbullying is different in these different datasets.', 'however, the complete transfer learning approach shows that bullying nature in youtube is more similar to formspring ( f1 - score = 0. 30 ) and then to wikipedia ( f1 - score = 0. 23 ) in comparison to twitter ( f1 - score = 0. 15 ).', 'this might be due to the similarity of the nature of these social networks.', 'youtube, formspring and ( table 6 ) was not significant compared to the feature level learning approach.', 'this indicates that the transfer of network weights is not as essential to cyberbullying detection as the learned word embeddings']",5
['reproduced the reference literature  #TAUTHOR_TAG for'],['reproduced the reference literature  #TAUTHOR_TAG for'],['reproduced the reference literature  #TAUTHOR_TAG for'],"['this study, we successfully reproduced the reference literature  #TAUTHOR_TAG for detection of cyberbullying incidents in social media platforms using dnn based models.', 'the source codes and materials were mostly well organized and accessible.', 'however, there were some details and settings that were not clearly stated.', '']",5
"['systems  #TAUTHOR_TAG, detect only few']","['systems  #TAUTHOR_TAG, detect only few']","['- art systems  #TAUTHOR_TAG, detect only few false negatives in the training data due to their high - precision low - recall features, which were originally proposed by  #AUTHOR_TAG']","['', 'maintain high precision. similar to iterative bootstrapping techniques  #AUTHOR_TAG, this mechanism uses the outputs of the first trained model', 'to expand training data for the second model, but unlike bootstrapping it does not require iteration and avoids the problem', 'of semantic drift. we further note that iterative bootstrapping over a single distant supervision system is difficult, because state - of - the - art systems  #TAUTHOR_TAG, detect only few false negatives in the training data due to their high - precision low - recall features, which were originally proposed by  #AUTHOR_TAG. we present a reliable and novel way to', 'address these issues and achieve significant improvement over the  #TAUTHOR_TAG, increasing recall from 47. 7 % to 61. 2 % at comparable precision. the key to this success is the combination of two different views as in co - training  #AUTHOR_TAG : an information extraction technique with fine features for high precision and an information retrieval technique with coarse features for high recall. our', 'work is developed in parallel with  #AUTHOR_TAG, who take a very different approach by adding additional latent variables to a multi - instance multi - label model  #AUTHOR_TAG to solve this same problem']",1
"['systems  #TAUTHOR_TAG, detect only few']","['systems  #TAUTHOR_TAG, detect only few']","['- art systems  #TAUTHOR_TAG, detect only few false negatives in the training data due to their high - precision low - recall features, which were originally proposed by  #AUTHOR_TAG']","['', 'maintain high precision. similar to iterative bootstrapping techniques  #AUTHOR_TAG, this mechanism uses the outputs of the first trained model', 'to expand training data for the second model, but unlike bootstrapping it does not require iteration and avoids the problem', 'of semantic drift. we further note that iterative bootstrapping over a single distant supervision system is difficult, because state - of - the - art systems  #TAUTHOR_TAG, detect only few false negatives in the training data due to their high - precision low - recall features, which were originally proposed by  #AUTHOR_TAG. we present a reliable and novel way to', 'address these issues and achieve significant improvement over the  #TAUTHOR_TAG, increasing recall from 47. 7 % to 61. 2 % at comparable precision. the key to this success is the combination of two different views as in co - training  #AUTHOR_TAG : an information extraction technique with fine features for high precision and an information retrieval technique with coarse features for high recall. our', 'work is developed in parallel with  #AUTHOR_TAG, who take a very different approach by adding additional latent variables to a multi - instance multi - label model  #AUTHOR_TAG to solve this same problem']",1
"['- source system,  #TAUTHOR_TAG, as the relation']","['use a state - of - the - art open - source system,  #TAUTHOR_TAG, as the relation']","['use a state - of - the - art open - source system,  #TAUTHOR_TAG, as']","['use a state - of - the - art open - source system,  #TAUTHOR_TAG, as the relation extraction component.', ' #TAUTHOR_TAG is based on multi - instance learning, which assumes that at least one sentence of those matching a given entity - pair contains the relation of interest  #AUTHOR_TAG in the given knowledge base to tolerate false positive noise in the training data and superior than previous models  #AUTHOR_TAG by allowing overlapping relations.', ' #TAUTHOR_TAG uses features which are based on  #AUTHOR_TAG and consist of conjunctions of named entity tags, syntactic dependency paths between arguments, and lexical information']",5
"[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system,']","[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system, which we call irmie, combines our passage retrieval component with  #TAUTHOR_TAG.', 'we use the same datasets as in  #TAUTHOR_TAG and  #AUTHOR_TAG, which include 3 - years of new york times articles aligned with freebase.', 'the sentential extraction evaluation is performed on a small amount of manually annotated sentences, sampled from the union of matched sentences and table 1 : overall sentential extraction performance evaluated on the original test set of  #TAUTHOR_TAG and our corrected test set : our proposed relevance feedback technique yields a substantial increase in recall.', 'system predictions.', '']",5
"[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system,']","[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system, which we call irmie, combines our passage retrieval component with  #TAUTHOR_TAG.', 'we use the same datasets as in  #TAUTHOR_TAG and  #AUTHOR_TAG, which include 3 - years of new york times articles aligned with freebase.', 'the sentential extraction evaluation is performed on a small amount of manually annotated sentences, sampled from the union of matched sentences and table 1 : overall sentential extraction performance evaluated on the original test set of  #TAUTHOR_TAG and our corrected test set : our proposed relevance feedback technique yields a substantial increase in recall.', 'system predictions.', '']",5
"[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system,']","[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system, which we call irmie, combines our passage retrieval component with  #TAUTHOR_TAG.', 'we use the same datasets as in  #TAUTHOR_TAG and  #AUTHOR_TAG, which include 3 - years of new york times articles aligned with freebase.', 'the sentential extraction evaluation is performed on a small amount of manually annotated sentences, sampled from the union of matched sentences and table 1 : overall sentential extraction performance evaluated on the original test set of  #TAUTHOR_TAG and our corrected test set : our proposed relevance feedback technique yields a substantial increase in recall.', 'system predictions.', '']",5
"[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system,']","[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system, which we call irmie, combines our passage retrieval component with  #TAUTHOR_TAG.', 'we use the same datasets as in  #TAUTHOR_TAG and  #AUTHOR_TAG, which include 3 - years of new york times articles aligned with freebase.', 'the sentential extraction evaluation is performed on a small amount of manually annotated sentences, sampled from the union of matched sentences and table 1 : overall sentential extraction performance evaluated on the original test set of  #TAUTHOR_TAG and our corrected test set : our proposed relevance feedback technique yields a substantial increase in recall.', 'system predictions.', '']",5
"[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system,']","[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system, which we call irmie, combines our passage retrieval component with  #TAUTHOR_TAG.', 'we use the same datasets as in  #TAUTHOR_TAG and  #AUTHOR_TAG, which include 3 - years of new york times articles aligned with freebase.', 'the sentential extraction evaluation is performed on a small amount of manually annotated sentences, sampled from the union of matched sentences and table 1 : overall sentential extraction performance evaluated on the original test set of  #TAUTHOR_TAG and our corrected test set : our proposed relevance feedback technique yields a substantial increase in recall.', 'system predictions.', '']",5
"[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system,']","[', we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline']","['evaluating extraction accuracy, we follow the experimental setup of  #TAUTHOR_TAG with 50 training iterations as our baseline.', 'our complete system, which we call irmie, combines our passage retrieval component with  #TAUTHOR_TAG.', 'we use the same datasets as in  #TAUTHOR_TAG and  #AUTHOR_TAG, which include 3 - years of new york times articles aligned with freebase.', 'the sentential extraction evaluation is performed on a small amount of manually annotated sentences, sampled from the union of matched sentences and table 1 : overall sentential extraction performance evaluated on the original test set of  #TAUTHOR_TAG and our corrected test set : our proposed relevance feedback technique yields a substantial increase in recall.', 'system predictions.', '']",5
"['text simplification  #TAUTHOR_TAG, i. e.']","['text simplification  #TAUTHOR_TAG, i. e.']","['text simplification  #TAUTHOR_TAG, i. e.']","['##u  #AUTHOR_TAG is an n - grambased evaluation metric, widely used for machine translation ( mt ) evaluation.', 'bleu has also been applied to monolingual translation tasks, such as grammatical error correction  #AUTHOR_TAG, summarization  #AUTHOR_TAG and text simplification  #TAUTHOR_TAG, i. e. the rewriting of a sentence as one or more simpler sentences.', 'along with the application of parallel corpora and mt techniques for ts ( e. g.,  #AUTHOR_TAG, bleu became the main automatic metric for ts, despite its deficiencies ( see § 2 ).', 'indeed, focusing on lexical simplification,  #TAUTHOR_TAG argued that bleu gives high scores to sentences that are close or even identical to the input, especially when multiple references are used.', 'in their experiments, bleu failed to predict simplicity, but obtained a higher correlation with grammaticality and meaning preservation, relative to the sari metric they proposed.', ""in this paper, we further explore the applicability of bleu for ts evaluation, examining bleu's informativeness where sentence splitting is involved."", 'sentence splitting, namely the rewriting of a single sentence as multiple sentences while preserving its meaning, is the main structural simplification operation.', 'it has been shown useful for mt preprocessing  #AUTHOR_TAG and human comprehension  #AUTHOR_TAG, independently from other lexical and structural simplification operations.', '']",0
"['text simplification  #TAUTHOR_TAG, i. e.']","['text simplification  #TAUTHOR_TAG, i. e.']","['text simplification  #TAUTHOR_TAG, i. e.']","['##u  #AUTHOR_TAG is an n - grambased evaluation metric, widely used for machine translation ( mt ) evaluation.', 'bleu has also been applied to monolingual translation tasks, such as grammatical error correction  #AUTHOR_TAG, summarization  #AUTHOR_TAG and text simplification  #TAUTHOR_TAG, i. e. the rewriting of a sentence as one or more simpler sentences.', 'along with the application of parallel corpora and mt techniques for ts ( e. g.,  #AUTHOR_TAG, bleu became the main automatic metric for ts, despite its deficiencies ( see § 2 ).', 'indeed, focusing on lexical simplification,  #TAUTHOR_TAG argued that bleu gives high scores to sentences that are close or even identical to the input, especially when multiple references are used.', 'in their experiments, bleu failed to predict simplicity, but obtained a higher correlation with grammaticality and meaning preservation, relative to the sari metric they proposed.', ""in this paper, we further explore the applicability of bleu for ts evaluation, examining bleu's informativeness where sentence splitting is involved."", 'sentence splitting, namely the rewriting of a single sentence as multiple sentences while preserving its meaning, is the main structural simplification operation.', 'it has been shown useful for mt preprocessing  #AUTHOR_TAG and human comprehension  #AUTHOR_TAG, independently from other lexical and structural simplification operations.', '']",0
"[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt']","[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt system tuned against sari, and', 'the identity function ( outputs are same as inputs ).']","[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt']","['', 'hypotheses in the beam are considered. 10 we further include moses  #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt system tuned against sari, and', 'the identity function ( outputs are same as inputs ). the case which evaluates outputs with sentence splitting additionally', 'includes the four hsplit corpora and the hsplit average scores.', 'for "" hsplit as reference setting "", we consider the outputs of six simplification systems whose main simplification operation is sentence splitting : dss, dss m, semoses, semoses m, semoses lm and semoses m lm, taken from', ' #AUTHOR_TAG b ). human evaluation. we use the evaluation benchmark provided by  #AUTHOR_TAG b ), 11 including system outputs and human evaluation scores corresponding to the first 70 sentences', 'of the test corpus of  #TAUTHOR_TAG', ', and extend it to apply to hsplit as well. the evaluation of hsplit is carried out by 3 in - house native english annotators, who rated the different input - output pairs for the different systems according to 4 parameters : grammaticality ( g ), meaning preservation ( m ), simplicity ( s ) and structural simplicity ( sts ). g and', 'm are measured using a 1 to 5 scale. a - 2 to + 2 scale is used for measuring simplicity and structural simplicity. for', 'computing the', ""inter - annotator agreement of the whole benchmark ( including the system outputs and the hsplit corpora ), we follow  #AUTHOR_TAG and randomly select, for each sentence, one annotator's rating to be the rating of annotator 1 and the rounded average rating of the two other annotators to be the rating of annotator 2."", 'we then compute weighted quadratic κ  #AUTHOR_TAG between annotator 1 and 2. repeating this process 1000 times, the obtained medians and 95 % confidence intervals are 0. 42 ± 0. 002 for g, 0. 77 ± 0. 001 for m and 0. 59 ±', '0. 002 for s and sts']",0
"['text simplification  #TAUTHOR_TAG, i. e.']","['text simplification  #TAUTHOR_TAG, i. e.']","['text simplification  #TAUTHOR_TAG, i. e.']","['##u  #AUTHOR_TAG is an n - grambased evaluation metric, widely used for machine translation ( mt ) evaluation.', 'bleu has also been applied to monolingual translation tasks, such as grammatical error correction  #AUTHOR_TAG, summarization  #AUTHOR_TAG and text simplification  #TAUTHOR_TAG, i. e. the rewriting of a sentence as one or more simpler sentences.', 'along with the application of parallel corpora and mt techniques for ts ( e. g.,  #AUTHOR_TAG, bleu became the main automatic metric for ts, despite its deficiencies ( see § 2 ).', 'indeed, focusing on lexical simplification,  #TAUTHOR_TAG argued that bleu gives high scores to sentences that are close or even identical to the input, especially when multiple references are used.', 'in their experiments, bleu failed to predict simplicity, but obtained a higher correlation with grammaticality and meaning preservation, relative to the sari metric they proposed.', ""in this paper, we further explore the applicability of bleu for ts evaluation, examining bleu's informativeness where sentence splitting is involved."", 'sentence splitting, namely the rewriting of a single sentence as multiple sentences while preserving its meaning, is the main structural simplification operation.', 'it has been shown useful for mt preprocessing  #AUTHOR_TAG and human comprehension  #AUTHOR_TAG, independently from other lexical and structural simplification operations.', '']",5
"['is modified by 4 annotators, according to specific sentence splitting guidelines.', 'we use the complex side of the test corpus of  #TAUTHOR_TAG.', '3  #AUTHOR_TAG recently proposed the semi - automatically compiled']","['is modified by 4 annotators, according to specific sentence splitting guidelines.', 'we use the complex side of the test corpus of  #TAUTHOR_TAG.', '3  #AUTHOR_TAG recently proposed the semi - automatically compiled web - split dataset']","['is modified by 4 annotators, according to specific sentence splitting guidelines.', 'we use the complex side of the test corpus of  #TAUTHOR_TAG.', '3  #AUTHOR_TAG recently proposed the semi - automatically compiled web - split dataset']","['order to investigate the effect of correctly splitting sentences on the automatic metric scores, we build a parallel corpus, where each sentence is modified by 4 annotators, according to specific sentence splitting guidelines.', 'we use the complex side of the test corpus of  #TAUTHOR_TAG.', '3  #AUTHOR_TAG recently proposed the semi - automatically compiled web - split dataset for training automatic sentence splitting systems, here we generate a completely manual corpus, without a - priori splitting points nor do we pre - suppose that all sentences should be split.', 'this corpus enriches the set of references focused on lexical operations that were collected by  #TAUTHOR_TAG for the same source sentences and can also be used as an out - of - domain test set for split - and - rephrase  #AUTHOR_TAG.', 'we use two sets of guidelines.', ""in set 1, annotators are required to split the original as much as possible, while preserving the sentence's gram - maticality, fluency and meaning."", 'the guidelines include two sentence splitting examples.', '4 in set 2, annotators are encouraged to split only in cases where it simplifies the original sentence.', 'that is, simplicity is implicit in set 1 and explicit in set 2.', 'in both sets, the annotators are instructed to leave the source unchanged if splitting violates grammaticality, fluency or meaning preservation.', '5 each set of guidelines is used by two annotators, with native or native - like proficiency in english.', 'the obtained corpora are denoted by hsplit1, hsplit2 ( for set 1 ), and hsplit3 and hsplit4 ( for set 2 ), each containing 359 sentences.', 'table 1 presents statistics for the corpora.', 'both in terms of the number of splits per sentence ( # sents ) and in terms of the proportion of input sentences that have been split ( splitsents ), we observe that the average difference within each set is significantly greater than the average difference between the sets.', '6 this suggests that the number of splits is less affected by the explicit mention of simplicity than by the inter - annotator variability.', '# sents denotes the average number of sentences in the output.', 'splitsents denotes the proportion of input sentences that have been split.', 'the last row presents the average scores of the 4 hsplit corpora']",5
"[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt']","[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt system tuned against sari, and', 'the identity function ( outputs are same as inputs ).']","[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt']","['', 'hypotheses in the beam are considered. 10 we further include moses  #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt system tuned against sari, and', 'the identity function ( outputs are same as inputs ). the case which evaluates outputs with sentence splitting additionally', 'includes the four hsplit corpora and the hsplit average scores.', 'for "" hsplit as reference setting "", we consider the outputs of six simplification systems whose main simplification operation is sentence splitting : dss, dss m, semoses, semoses m, semoses lm and semoses m lm, taken from', ' #AUTHOR_TAG b ). human evaluation. we use the evaluation benchmark provided by  #AUTHOR_TAG b ), 11 including system outputs and human evaluation scores corresponding to the first 70 sentences', 'of the test corpus of  #TAUTHOR_TAG', ', and extend it to apply to hsplit as well. the evaluation of hsplit is carried out by 3 in - house native english annotators, who rated the different input - output pairs for the different systems according to 4 parameters : grammaticality ( g ), meaning preservation ( m ), simplicity ( s ) and structural simplicity ( sts ). g and', 'm are measured using a 1 to 5 scale. a - 2 to + 2 scale is used for measuring simplicity and structural simplicity. for', 'computing the', ""inter - annotator agreement of the whole benchmark ( including the system outputs and the hsplit corpora ), we follow  #AUTHOR_TAG and randomly select, for each sentence, one annotator's rating to be the rating of annotator 1 and the rounded average rating of the two other annotators to be the rating of annotator 2."", 'we then compute weighted quadratic κ  #AUTHOR_TAG between annotator 1 and 2. repeating this process 1000 times, the obtained medians and 95 % confidence intervals are 0. 42 ± 0. 002 for g, 0. 77 ± 0. 001 for m and 0. 59 ±', '0. 002 for s and sts']",5
"[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt']","[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt system tuned against sari, and', 'the identity function ( outputs are same as inputs ).']","[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt']","['', 'hypotheses in the beam are considered. 10 we further include moses  #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt system tuned against sari, and', 'the identity function ( outputs are same as inputs ). the case which evaluates outputs with sentence splitting additionally', 'includes the four hsplit corpora and the hsplit average scores.', 'for "" hsplit as reference setting "", we consider the outputs of six simplification systems whose main simplification operation is sentence splitting : dss, dss m, semoses, semoses m, semoses lm and semoses m lm, taken from', ' #AUTHOR_TAG b ). human evaluation. we use the evaluation benchmark provided by  #AUTHOR_TAG b ), 11 including system outputs and human evaluation scores corresponding to the first 70 sentences', 'of the test corpus of  #TAUTHOR_TAG', ', and extend it to apply to hsplit as well. the evaluation of hsplit is carried out by 3 in - house native english annotators, who rated the different input - output pairs for the different systems according to 4 parameters : grammaticality ( g ), meaning preservation ( m ), simplicity ( s ) and structural simplicity ( sts ). g and', 'm are measured using a 1 to 5 scale. a - 2 to + 2 scale is used for measuring simplicity and structural simplicity. for', 'computing the', ""inter - annotator agreement of the whole benchmark ( including the system outputs and the hsplit corpora ), we follow  #AUTHOR_TAG and randomly select, for each sentence, one annotator's rating to be the rating of annotator 1 and the rounded average rating of the two other annotators to be the rating of annotator 2."", 'we then compute weighted quadratic κ  #AUTHOR_TAG between annotator 1 and 2. repeating this process 1000 times, the obtained medians and 95 % confidence intervals are 0. 42 ± 0. 002 for g, 0. 77 ± 0. 001 for m and 0. 59 ±', '0. 002 for s and sts']",5
"[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt']","[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt system tuned against sari, and', 'the identity function ( outputs are same as inputs ).']","[' #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt']","['', 'hypotheses in the beam are considered. 10 we further include moses  #AUTHOR_TAG and sbmt - sari  #TAUTHOR_TAG, a syntax - based mt system tuned against sari, and', 'the identity function ( outputs are same as inputs ). the case which evaluates outputs with sentence splitting additionally', 'includes the four hsplit corpora and the hsplit average scores.', 'for "" hsplit as reference setting "", we consider the outputs of six simplification systems whose main simplification operation is sentence splitting : dss, dss m, semoses, semoses m, semoses lm and semoses m lm, taken from', ' #AUTHOR_TAG b ). human evaluation. we use the evaluation benchmark provided by  #AUTHOR_TAG b ), 11 including system outputs and human evaluation scores corresponding to the first 70 sentences', 'of the test corpus of  #TAUTHOR_TAG', ', and extend it to apply to hsplit as well. the evaluation of hsplit is carried out by 3 in - house native english annotators, who rated the different input - output pairs for the different systems according to 4 parameters : grammaticality ( g ), meaning preservation ( m ), simplicity ( s ) and structural simplicity ( sts ). g and', 'm are measured using a 1 to 5 scale. a - 2 to + 2 scale is used for measuring simplicity and structural simplicity. for', 'computing the', ""inter - annotator agreement of the whole benchmark ( including the system outputs and the hsplit corpora ), we follow  #AUTHOR_TAG and randomly select, for each sentence, one annotator's rating to be the rating of annotator 1 and the rounded average rating of the two other annotators to be the rating of annotator 2."", 'we then compute weighted quadratic κ  #AUTHOR_TAG between annotator 1 and 2. repeating this process 1000 times, the obtained medians and 95 % confidence intervals are 0. 42 ± 0. 002 for g, 0. 77 ± 0. 001 for m and 0. 59 ±', '0. 002 for s and sts']",5
"['. g.,  #TAUTHOR_TAG, only few works tested its correlation with human']","['ts evaluation ( e. g.,  #TAUTHOR_TAG, only few works tested its correlation with human judgments.', 'using 20 source sentences from the pwkp test corpus  #AUTHOR_TAG with 5 simplified sentences for each of them,  #AUTHOR_TAG reported positive']","['. g.,  #TAUTHOR_TAG, only few works tested its correlation with human judgments.', 'using 20 source sentences from the pwkp test corpus  #AUTHOR_TAG with 5 simplified sentences for each of them,  #AUTHOR_TAG reported positive correlation']","['bleu is standardly used for ts evaluation ( e. g.,  #TAUTHOR_TAG, only few works tested its correlation with human judgments.', 'using 20 source sentences from the pwkp test corpus  #AUTHOR_TAG with 5 simplified sentences for each of them,  #AUTHOR_TAG reported positive correlation of bleu with simplicity ratings, but no correlation with adequacy.', 't - bleu ( stajner et al., 2014 ), a variant of bleu which uses lower n - grams when no overlapping 4 - grams are found, was tested on outputs that applied only structural modifications to the source.', 'it was found to have moderate positive correlation for meaning preservation, and positive but low correlation for grammaticality.', 'correlation with simplicity was not considered in this experiment.', ' #AUTHOR_TAG focused on lexical simplification, finding that bleu obtains reasonable correlation for grammaticality and meaning preservation but fails to capture simplicity, even when multiple references are used.', 'to our knowledge, no previous work has examined the behavior of bleu on sentence splitting, which we investigate here using a manually compiled gold standard']",1
"['is modified by 4 annotators, according to specific sentence splitting guidelines.', 'we use the complex side of the test corpus of  #TAUTHOR_TAG.', '3  #AUTHOR_TAG recently proposed the semi - automatically compiled']","['is modified by 4 annotators, according to specific sentence splitting guidelines.', 'we use the complex side of the test corpus of  #TAUTHOR_TAG.', '3  #AUTHOR_TAG recently proposed the semi - automatically compiled web - split dataset']","['is modified by 4 annotators, according to specific sentence splitting guidelines.', 'we use the complex side of the test corpus of  #TAUTHOR_TAG.', '3  #AUTHOR_TAG recently proposed the semi - automatically compiled web - split dataset']","['order to investigate the effect of correctly splitting sentences on the automatic metric scores, we build a parallel corpus, where each sentence is modified by 4 annotators, according to specific sentence splitting guidelines.', 'we use the complex side of the test corpus of  #TAUTHOR_TAG.', '3  #AUTHOR_TAG recently proposed the semi - automatically compiled web - split dataset for training automatic sentence splitting systems, here we generate a completely manual corpus, without a - priori splitting points nor do we pre - suppose that all sentences should be split.', 'this corpus enriches the set of references focused on lexical operations that were collected by  #TAUTHOR_TAG for the same source sentences and can also be used as an out - of - domain test set for split - and - rephrase  #AUTHOR_TAG.', 'we use two sets of guidelines.', ""in set 1, annotators are required to split the original as much as possible, while preserving the sentence's gram - maticality, fluency and meaning."", 'the guidelines include two sentence splitting examples.', '4 in set 2, annotators are encouraged to split only in cases where it simplifies the original sentence.', 'that is, simplicity is implicit in set 1 and explicit in set 2.', 'in both sets, the annotators are instructed to leave the source unchanged if splitting violates grammaticality, fluency or meaning preservation.', '5 each set of guidelines is used by two annotators, with native or native - like proficiency in english.', 'the obtained corpora are denoted by hsplit1, hsplit2 ( for set 1 ), and hsplit3 and hsplit4 ( for set 2 ), each containing 359 sentences.', 'table 1 presents statistics for the corpora.', 'both in terms of the number of splits per sentence ( # sents ) and in terms of the proportion of input sentences that have been split ( splitsents ), we observe that the average difference within each set is significantly greater than the average difference between the sets.', '6 this suggests that the number of splits is less affected by the explicit mention of simplicity than by the inter - annotator variability.', '# sents denotes the average number of sentences in the output.', 'splitsents denotes the proportion of input sentences that have been split.', 'the last row presents the average scores of the 4 hsplit corpora']",6
"['for identity, also observed by  #TAUTHOR_TAG, indicate that bleu is a not a good predictor for relative simplicity to the input.', 'the drop in the ble']","['for identity, also observed by  #TAUTHOR_TAG, indicate that bleu is a not a good predictor for relative simplicity to the input.', 'the drop in the bleu scores for hsplit is not reflected by the human evaluation scores']","['for identity, also observed by  #TAUTHOR_TAG, indicate that bleu is a not a good predictor for relative simplicity to the input.', 'the drop in the bleu scores for hsplit is not reflected by the human evaluation scores']","['', 'for s and sts, the differences are 0. 45 and 0. 49 ( σ = 0. 18 ).', 'at the sentence level, considering 490 sentences ( 70 for each of the system / corpora ), the g and m scores vary from 1 to 5 ( σ equals 0. 78 and 1. 01 respectively ), and the s and sts scores from - 1 to 2 ( σ equals 0. 51 and 0. 46 ).', 'comparing hsplit to identity.', 'comparing the bleu score on the input ( the identity function ) and on the hsplit corpora, we observe that the former yields much higher bleu scores.', 'indeed, bleu - 1ref obtains 59. 85 for the input and 43. 90 for the hsplit corpora ( averaged over the 4 hsplit corpora ).', 'bleu - 8ref obtains 94. 63 for the input and 73. 03 for hsplit.', '12 the high scores obtained for identity, also observed by  #TAUTHOR_TAG, indicate that bleu is a not a good predictor for relative simplicity to the input.', 'the drop in the bleu scores for hsplit is not reflected by the human evaluation scores for grammaticality ( 4. 43']",3
"[', 17,  #TAUTHOR_TAG']","['[ 24, 25, 26, 27 ] and correlations [ 26, 27, 17,  #TAUTHOR_TAG']","[', 17,  #TAUTHOR_TAG.', 'in recent studies, sentence length analysis have been related to style and authorship']","['quantitative patterns have been identified in the structure of written texts.', ""for example, the zipf's law states that the frequency of a word in a text is inversely proportional to its rank [ 1, 2 ]."", 'moreover, it was also observed that punctuation marks also obey this law [ 3 ].', ""heaps'or herdan's law states that the vocabulary increases as a power law of a finite sample size of the text [ 4, 5 ]."", 'these laws have been generalized to account for more general patterns [ 6, 7, 8, 9, 10, 11, 12, 13 ].', 'mapping a text into a time series can also reveal hidden structural patterns.', 'methods applied to investigate text structure at word level include investigations on probability distributions [ 14 ], correlations [ 15, 16, 17, 18, 19 ], and networks properties [ 20, 21, 22, 23 ].', 'another way to investigate text structure is by the analysis of sentence lengths.', 'typically, each sentence carries a full message and transmits an idea in contrast with an isolated word.', 'therefore, mapping a text into a time series of sentence lengths is a natural way to investigate text structures.', 'recent methods applied to study texts at sentence level include probability distributions [ 24, 25, 26, 27 ] and correlations [ 26, 27, 17,  #TAUTHOR_TAG.', 'in recent studies, sentence length analysis have been related to style and authorship [ 29, 26, 27 ].', 'in general, sentence lengths have been quantified by the number of words [ 24, 29, 25,  #TAUTHOR_TAG or characters [ 30, 31, 26, 27 ].', 'also, note that the recurrence time of full stops also quantifies the sentence length [ 3 ].', 'however, there are other possible variations, such as word length or word frequency mappings, where all words are brought to lower case and punctuation marks are removed.', 'other possible variations are the removal of stop words and the lemmatization [ 21 ].', 'in a similar way, the number of characters and variations related to lemmatization and stop words removal could also be considered at sentence level.', 'however, to choose between words or characters to measure a sentence may lead to doubts.', 'for instance, the japanese language has three alphabets and the number of characters may differ for the same word [ 25 ].', 'in the present work, we investigated the robustness of distinct measures of sentence lengths.', 'by using a database containing about five hundred books in english, we extracted six distinct measures of sentence length.', 'we employed three widely known tests to compare these six measures']",0
"[', 17,  #TAUTHOR_TAG']","['[ 24, 25, 26, 27 ] and correlations [ 26, 27, 17,  #TAUTHOR_TAG']","[', 17,  #TAUTHOR_TAG.', 'in recent studies, sentence length analysis have been related to style and authorship']","['quantitative patterns have been identified in the structure of written texts.', ""for example, the zipf's law states that the frequency of a word in a text is inversely proportional to its rank [ 1, 2 ]."", 'moreover, it was also observed that punctuation marks also obey this law [ 3 ].', ""heaps'or herdan's law states that the vocabulary increases as a power law of a finite sample size of the text [ 4, 5 ]."", 'these laws have been generalized to account for more general patterns [ 6, 7, 8, 9, 10, 11, 12, 13 ].', 'mapping a text into a time series can also reveal hidden structural patterns.', 'methods applied to investigate text structure at word level include investigations on probability distributions [ 14 ], correlations [ 15, 16, 17, 18, 19 ], and networks properties [ 20, 21, 22, 23 ].', 'another way to investigate text structure is by the analysis of sentence lengths.', 'typically, each sentence carries a full message and transmits an idea in contrast with an isolated word.', 'therefore, mapping a text into a time series of sentence lengths is a natural way to investigate text structures.', 'recent methods applied to study texts at sentence level include probability distributions [ 24, 25, 26, 27 ] and correlations [ 26, 27, 17,  #TAUTHOR_TAG.', 'in recent studies, sentence length analysis have been related to style and authorship [ 29, 26, 27 ].', 'in general, sentence lengths have been quantified by the number of words [ 24, 29, 25,  #TAUTHOR_TAG or characters [ 30, 31, 26, 27 ].', 'also, note that the recurrence time of full stops also quantifies the sentence length [ 3 ].', 'however, there are other possible variations, such as word length or word frequency mappings, where all words are brought to lower case and punctuation marks are removed.', 'other possible variations are the removal of stop words and the lemmatization [ 21 ].', 'in a similar way, the number of characters and variations related to lemmatization and stop words removal could also be considered at sentence level.', 'however, to choose between words or characters to measure a sentence may lead to doubts.', 'for instance, the japanese language has three alphabets and the number of characters may differ for the same word [ 25 ].', 'in the present work, we investigated the robustness of distinct measures of sentence lengths.', 'by using a database containing about five hundred books in english, we extracted six distinct measures of sentence length.', 'we employed three widely known tests to compare these six measures']",0
"['of sentence length to the word length. "" this comment is consistent with the one in  #TAUTHOR_TAG asserting that the menzerath - altmann']","['of sentence length to the word length. "" this comment is consistent with the one in  #TAUTHOR_TAG asserting that the menzerath - altmann']","['somewhat more problematic is the relation of sentence length to the word length. "" this comment is consistent with the one in  #TAUTHOR_TAG asserting that the menzerath - altmann law does not']","['', 'since r is very close to one, the fluctuation of information due to the transformations has little implications.', 'due to these results, we estimate that, with good approximation for each book, the terms of one series can be written in terms of the other by a transformation such as', 'where n c ( n w ) is a term of the time series n c ( n w ) and α c and β c are constants.', ""other tests such as the goodman and kruskal's γ test [ 34 ], the kendall's τ test [ 35 ], and the spearman's test [ 36 ] were also performed to study the correlations."", 'these tests are based on the null hypothesis that the two distributions are independent.', 'all comparisons for all books rejected the null hypothesis for these tests.', 'before concluding this subsection, we discuss fig. 2a in connection with the menzerathaltmann law.', 'basically, this law states that the bigger the whole, the smaller its parts and vice - versa.', 'however, an issue about this relationship was addressed in [ 37 ] : "" somewhat more problematic is the relation of sentence length to the word length. "" this comment is consistent with the one in  #TAUTHOR_TAG asserting that the menzerath - altmann law does not hold if the']",0
"['is consistent with the multifractal analysis performed in  #TAUTHOR_TAG.', 'in addition, the values for the difference between hurst exponents ( ∆h ) of a given book are shown in fig. 4c, where we can observe that the variation of the hurst exponents is small from one series to another.', 'also, the standard deviation for h within each book was close to 0. 001.', 'lastly, no correlations were found between the number of sentences in a text and the hurst exponent']","['is consistent with the multifractal analysis performed in  #TAUTHOR_TAG.', 'in addition, the values for the difference between hurst exponents ( ∆h ) of a given book are shown in fig. 4c, where we can observe that the variation of the hurst exponents is small from one series to another.', 'also, the standard deviation for h within each book was close to 0. 001.', 'lastly, no correlations were found between the number of sentences in a text and the hurst exponent']","['. 75 ).', 'this result is consistent with the multifractal analysis performed in  #TAUTHOR_TAG.', 'in addition, the values for the difference between hurst exponents ( ∆h ) of a given book are shown in fig. 4c, where we can observe that the variation of the hurst exponents is small from one series to another.', 'also, the standard deviation for h within each book was close to 0. 001.', 'lastly, no correlations were found between the number of sentences in a text and the hurst exponent']","['', 'using the the brothers karamazov as example again, fig. 4a and 4b illustrate, respectively, f ( m ) and the differences between the hurst exponents for all six series.', 'we can infer that h differs very little from one series to another and that their values are close to 0. 8, with h * ∼ 0. 5, implying in long - range correlations.', 'all the series from the other books reflects this behavior ( h ∼ 0. 75 ).', 'this result is consistent with the multifractal analysis performed in  #TAUTHOR_TAG.', 'in addition, the values for the difference between hurst exponents ( ∆h ) of a given book are shown in fig. 4c, where we can observe that the variation of the hurst exponents is small from one series to another.', 'also, the standard deviation for h within each book was close to 0. 001.', 'lastly, no correlations were found between the number of sentences in a text and the hurst exponent']",3
"['on three available lexicalsample datasets  #TAUTHOR_TAG.', 'this']","['on three available lexicalsample datasets  #TAUTHOR_TAG.', 'this']","['to specific domains has been evaluated on three available lexicalsample datasets  #TAUTHOR_TAG.', 'this kind of dataset contains hand - labeled examples for a handful of selected target words.', '']","['sense disambiguation ( wsd ) competitions have focused on general domain texts, as attested in the last senseval and semeval competitions  #AUTHOR_TAG.', 'specific domains pose fresh challenges to wsd systems : the context in which the senses occur might change, distributions and predominant senses vary, some words tend to occur in fewer senses in specific domains, and new senses and terms might be involved.', 'both supervised and knowledge - based systems are affected by these issues : while the first suffer from different context and sense priors, the later suffer from lack of coverage of domain - related words and information.', 'domain adaptation of supervised techniques is a hot issue in natural language processing, including word sense disambiguation.', 'supervised word sense disambiguation systems trained on general corpora are known to perform worse when applied to specific domains  #AUTHOR_TAG martinez and  #AUTHOR_TAG, and domain adaptation techniques have been proposed as a solution to this problem with mixed results.', 'current research on applying wsd to specific domains has been evaluated on three available lexicalsample datasets  #TAUTHOR_TAG.', 'this kind of dataset contains hand - labeled examples for a handful of selected target words.', 'as the systems are evaluated on a few words, the actual performance of the systems over complete texts can not be measured.', '']",0
"['of domain - specific examples.', ' #TAUTHOR_TAG present a corpus were the examples are']","['of domain - specific examples.', ' #TAUTHOR_TAG present a corpus were the examples are']","['of domain - specific examples.', ' #TAUTHOR_TAG present a corpus were the examples are drawn from the balanced bnc corpus  #AUTHOR_TAG and']","['', '191 polysemous words ( nouns and verbs ) of high frequency in wsj and bc were selected and a total of 192, 800 occurrences of these words were tagged with wordnet 1. 5 senses, more than 1, 000 instances per word in average.', 'the examples from bc comprise 78, 080 occurrences of word senses, and examples from wsj consist on 114, 794 occurrences.', 'in domain adaptation experiments, the brown corpus examples play the role of general corpora, and the examples from the wsj play the role of domain - specific examples.', ' #TAUTHOR_TAG present a corpus were the examples are drawn from the balanced bnc corpus  #AUTHOR_TAG and the sports and finances sections of the newswire reuters corpus  #AUTHOR_TAG, comprising around 300 examples ( roughly 100 from each of those corpora ) for each of the 41 nouns.', '']",0
"['domains in the context of the  #TAUTHOR_TAG dataset.', 'while ws']","['domains in the context of the  #TAUTHOR_TAG dataset.', 'while wsd systems trained on']","['to the domains in the context of the  #TAUTHOR_TAG dataset.', 'while wsd systems trained on']","['work on domain adaptation for wsd systems showed that wsd systems were not able to obtain better results on the source or adaptation settings compared to the target settings  #AUTHOR_TAG, showing that a generic wsd system ( i. e. based on hand - annotated examples from a generic corpus ) would not be useful when moved to new domains.', ' #AUTHOR_TAG tested the supervised adaptation scenario on the dso corpus, which had examples from the brown corpus and wall street journal corpus.', 'they found that the source corpus did not help when tagging the target corpus, showing that tagged corpora from each domain would suffice, and concluding that hand tagging a large general corpus would not guarantee robust broad - coverage wsd.', 'agirre and martinez ( 2000 ) used the same dso corpus and showed that training on the subset of the source corpus that is topically related to the target corpus does allow for domain adaptation, obtaining better results than training on the target data alone.', 'in ( agirre and lopez de  #AUTHOR_TAG, the authors also show that state - of - the - art wsd systems are not able to adapt to the domains in the context of the  #TAUTHOR_TAG dataset.', '']",0
"['in the  #TAUTHOR_TAG data was marginal.', 'better results have been']","['on wsd in the  #TAUTHOR_TAG data was marginal.', 'better results have been']","['in the  #TAUTHOR_TAG data was marginal.', 'better results have been obtained using purposebuilt adaptation methods.', ' #AUTHOR_TAG performed supervised domain adaptation on a']","['adaptation for other nlp tasks has been widely reported.', 'for instance, ( daume iii, 2007 ) shows that a simple feature augmentation method for svm is able to effectively use both labeled target and source data to provide the best domainadaptation results in a number of nlp tasks.', 'his method improves or equals over previously explored more sophisticated methods ( daume iii and  #AUTHOR_TAG.', 'in contrast, ) reimplemented this method and showed that the improvement on wsd in the  #TAUTHOR_TAG data was marginal.', 'better results have been obtained using purposebuilt adaptation methods.', ' #AUTHOR_TAG performed supervised domain adaptation on a manually selected subset of 21 nouns from the dso corpus.', 'they used active learning, count - merging, and predominant sense estimation in order to save target annotation effort.', 'they showed that adding just 30 % of the target data to the source examples the same precision as the full combination of target and source data could be achieved.', 'they also showed that using the source corpus significantly improved results when only 10 % - 30 % of the target corpus was used for training.', 'in followup work ( zhong et projections for 2100 suggest that temperature in europe will have risen by between 2 to 6. 3 c above 1990 levels.', 'the sea level is projected to rise, and a greater frequency and intensity of extreme weather events are expected.', 'even if emissions of greenhouse gases stop today, these changes would continue for many decades and in the case of sea level for centuries.', 'this is due to the historical build up of the gases in the atmosphere and time lags in the response of climatic and oceanic systems to changes in the atmospheric concentration of the gases.', 'al., 2008 ), the feature augmentation approach was combined with active learning and tested on the ontonotes corpus, on a large domain - adaptation experiment.', 'they significantly reduced the effort of hand - tagging, but only obtained positive domainadaptation results for smaller fractions of the target corpus.', 'in ) the authors report successful adaptation on the  #TAUTHOR_TAG dataset on supervised setting.', 'their method is based on the use of unlabeled data, reducing the feature space with svd, and combination of features using an ensemble of kernel methods.', 'they report 22 % error reduction when using both source and target data compared to a classifier trained on target the target data alone, even when the full dataset is used']",0
"['in the  #TAUTHOR_TAG data was marginal.', 'better results have been']","['on wsd in the  #TAUTHOR_TAG data was marginal.', 'better results have been']","['in the  #TAUTHOR_TAG data was marginal.', 'better results have been obtained using purposebuilt adaptation methods.', ' #AUTHOR_TAG performed supervised domain adaptation on a']","['adaptation for other nlp tasks has been widely reported.', 'for instance, ( daume iii, 2007 ) shows that a simple feature augmentation method for svm is able to effectively use both labeled target and source data to provide the best domainadaptation results in a number of nlp tasks.', 'his method improves or equals over previously explored more sophisticated methods ( daume iii and  #AUTHOR_TAG.', 'in contrast, ) reimplemented this method and showed that the improvement on wsd in the  #TAUTHOR_TAG data was marginal.', 'better results have been obtained using purposebuilt adaptation methods.', ' #AUTHOR_TAG performed supervised domain adaptation on a manually selected subset of 21 nouns from the dso corpus.', 'they used active learning, count - merging, and predominant sense estimation in order to save target annotation effort.', 'they showed that adding just 30 % of the target data to the source examples the same precision as the full combination of target and source data could be achieved.', 'they also showed that using the source corpus significantly improved results when only 10 % - 30 % of the target corpus was used for training.', 'in followup work ( zhong et projections for 2100 suggest that temperature in europe will have risen by between 2 to 6. 3 c above 1990 levels.', 'the sea level is projected to rise, and a greater frequency and intensity of extreme weather events are expected.', 'even if emissions of greenhouse gases stop today, these changes would continue for many decades and in the case of sea level for centuries.', 'this is due to the historical build up of the gases in the atmosphere and time lags in the response of climatic and oceanic systems to changes in the atmospheric concentration of the gases.', 'al., 2008 ), the feature augmentation approach was combined with active learning and tested on the ontonotes corpus, on a large domain - adaptation experiment.', 'they significantly reduced the effort of hand - tagging, but only obtained positive domainadaptation results for smaller fractions of the target corpus.', 'in ) the authors report successful adaptation on the  #TAUTHOR_TAG dataset on supervised setting.', 'their method is based on the use of unlabeled data, reducing the feature space with svd, and combination of features using an ensemble of kernel methods.', 'they report 22 % error reduction when using both source and target data compared to a classifier trained on target the target data alone, even when the full dataset is used']",0
['to specific domains in  #TAUTHOR_TAG'],['to specific domains in  #TAUTHOR_TAG'],"['to specific domains in  #TAUTHOR_TAG.', 'the methos has two steps : in the first, a corpus of untagged text from the target domain is used']","['this context, we take unsupervised to mean knowledge - based methods which do not require hand - tagged corpora.', 'the predominant sense acquisition method was succesfully applied to specific domains in  #TAUTHOR_TAG.', 'the methos has two steps : in the first, a corpus of untagged text from the target domain is used to construct a thesaurus of similar words.', 'in the second, each target word is disambiguated using pairwise wordnet - based similarity measures, taking as pairs the target word and each of the most related words according to the thesaurus up to a certain threshold.', 'this method aims to obtain, for each target word, the sense which is the most predominant for the target corpus.', 'when a general corpus is used, the most predominant sense in general is obtained, and when a domain - specific corpus is used, the most predominant sense for that corpus is obtained  #TAUTHOR_TAG.', 'the main motivation of the authors is that the most frequent sense is a very powerful baseline, but it is one which requires hand - tagging text, while their method yields similar information automatically.', 'the results show that they are able to obtain good results.', 'in related work, ) report improved results using the same strategy but applying a graph - based wsd method, and highlight the domain - adaptation potential of unsupervised knowledge - based wsd systems compared to supervised wsd']",0
['to specific domains in  #TAUTHOR_TAG'],['to specific domains in  #TAUTHOR_TAG'],"['to specific domains in  #TAUTHOR_TAG.', 'the methos has two steps : in the first, a corpus of untagged text from the target domain is used']","['this context, we take unsupervised to mean knowledge - based methods which do not require hand - tagged corpora.', 'the predominant sense acquisition method was succesfully applied to specific domains in  #TAUTHOR_TAG.', 'the methos has two steps : in the first, a corpus of untagged text from the target domain is used to construct a thesaurus of similar words.', 'in the second, each target word is disambiguated using pairwise wordnet - based similarity measures, taking as pairs the target word and each of the most related words according to the thesaurus up to a certain threshold.', 'this method aims to obtain, for each target word, the sense which is the most predominant for the target corpus.', 'when a general corpus is used, the most predominant sense in general is obtained, and when a domain - specific corpus is used, the most predominant sense for that corpus is obtained  #TAUTHOR_TAG.', 'the main motivation of the authors is that the most frequent sense is a very powerful baseline, but it is one which requires hand - tagging text, while their method yields similar information automatically.', 'the results show that they are able to obtain good results.', 'in related work, ) report improved results using the same strategy but applying a graph - based wsd method, and highlight the domain - adaptation potential of unsupervised knowledge - based wsd systems compared to supervised wsd']",5
['to specific domains in  #TAUTHOR_TAG'],['to specific domains in  #TAUTHOR_TAG'],"['to specific domains in  #TAUTHOR_TAG.', 'the methos has two steps : in the first, a corpus of untagged text from the target domain is used']","['this context, we take unsupervised to mean knowledge - based methods which do not require hand - tagged corpora.', 'the predominant sense acquisition method was succesfully applied to specific domains in  #TAUTHOR_TAG.', 'the methos has two steps : in the first, a corpus of untagged text from the target domain is used to construct a thesaurus of similar words.', 'in the second, each target word is disambiguated using pairwise wordnet - based similarity measures, taking as pairs the target word and each of the most related words according to the thesaurus up to a certain threshold.', 'this method aims to obtain, for each target word, the sense which is the most predominant for the target corpus.', 'when a general corpus is used, the most predominant sense in general is obtained, and when a domain - specific corpus is used, the most predominant sense for that corpus is obtained  #TAUTHOR_TAG.', 'the main motivation of the authors is that the most frequent sense is a very powerful baseline, but it is one which requires hand - tagging text, while their method yields similar information automatically.', 'the results show that they are able to obtain good results.', 'in related work, ) report improved results using the same strategy but applying a graph - based wsd method, and highlight the domain - adaptation potential of unsupervised knowledge - based wsd systems compared to supervised wsd']",3
['protected groups  #TAUTHOR_TAG dixon et'],"['protected groups  #TAUTHOR_TAG dixon et al. ;  #AUTHOR_TAG.', 'more specifically, word embeddings has been an']",['various protected groups  #TAUTHOR_TAG dixon et'],"[""have found a variety of ways in which dangerous unintended bias can show up in nlp applications ( blodgett and o' #AUTHOR_TAG."", 'mitigating such biases is a difficult problem, and researchers have created many ways to make fairer nlp applications.', 'much of the focus for mitigating unintended bias in nlp is either targeted at reducing gender stereotypes in text  #AUTHOR_TAG b, a ;  #AUTHOR_TAG, or inequality of sentiment or toxicity for various protected groups  #TAUTHOR_TAG dixon et al. ;  #AUTHOR_TAG.', 'more specifically, word embeddings has been an area of focus for evaluating unintended bias.', ' #AUTHOR_TAG b ) defines a useful metric for identifying gender bias and  #TAUTHOR_TAG defines a metric called the weat score for evaluating unfair correlations with sentiment for various demographics in text.', 'unfortunately metrics like these leverage vector space arguments between only two identities at a time like man vs woman  #AUTHOR_TAG a ), or european american names vs. african american names  #TAUTHOR_TAG.', 'though geometrically intuitive, these tests do not have a direct relation to discrimination in general.', 'our framework and rnsb metric enable a clear evaluation of discrimination with respect to word embedding bias for a whole class of demographics']",0
['protected groups  #TAUTHOR_TAG dixon et'],"['protected groups  #TAUTHOR_TAG dixon et al. ;  #AUTHOR_TAG.', 'more specifically, word embeddings has been an']",['various protected groups  #TAUTHOR_TAG dixon et'],"[""have found a variety of ways in which dangerous unintended bias can show up in nlp applications ( blodgett and o' #AUTHOR_TAG."", 'mitigating such biases is a difficult problem, and researchers have created many ways to make fairer nlp applications.', 'much of the focus for mitigating unintended bias in nlp is either targeted at reducing gender stereotypes in text  #AUTHOR_TAG b, a ;  #AUTHOR_TAG, or inequality of sentiment or toxicity for various protected groups  #TAUTHOR_TAG dixon et al. ;  #AUTHOR_TAG.', 'more specifically, word embeddings has been an area of focus for evaluating unintended bias.', ' #AUTHOR_TAG b ) defines a useful metric for identifying gender bias and  #TAUTHOR_TAG defines a metric called the weat score for evaluating unfair correlations with sentiment for various demographics in text.', 'unfortunately metrics like these leverage vector space arguments between only two identities at a time like man vs woman  #AUTHOR_TAG a ), or european american names vs. african american names  #TAUTHOR_TAG.', 'though geometrically intuitive, these tests do not have a direct relation to discrimination in general.', 'our framework and rnsb metric enable a clear evaluation of discrimination with respect to word embedding bias for a whole class of demographics']",0
['protected groups  #TAUTHOR_TAG dixon et'],"['protected groups  #TAUTHOR_TAG dixon et al. ;  #AUTHOR_TAG.', 'more specifically, word embeddings has been an']",['various protected groups  #TAUTHOR_TAG dixon et'],"[""have found a variety of ways in which dangerous unintended bias can show up in nlp applications ( blodgett and o' #AUTHOR_TAG."", 'mitigating such biases is a difficult problem, and researchers have created many ways to make fairer nlp applications.', 'much of the focus for mitigating unintended bias in nlp is either targeted at reducing gender stereotypes in text  #AUTHOR_TAG b, a ;  #AUTHOR_TAG, or inequality of sentiment or toxicity for various protected groups  #TAUTHOR_TAG dixon et al. ;  #AUTHOR_TAG.', 'more specifically, word embeddings has been an area of focus for evaluating unintended bias.', ' #AUTHOR_TAG b ) defines a useful metric for identifying gender bias and  #TAUTHOR_TAG defines a metric called the weat score for evaluating unfair correlations with sentiment for various demographics in text.', 'unfortunately metrics like these leverage vector space arguments between only two identities at a time like man vs woman  #AUTHOR_TAG a ), or european american names vs. african american names  #TAUTHOR_TAG.', 'though geometrically intuitive, these tests do not have a direct relation to discrimination in general.', 'our framework and rnsb metric enable a clear evaluation of discrimination with respect to word embedding bias for a whole class of demographics']",0
"['word2vec embeddings have been shown to contain unintended bias in  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'conceptnet has been shown to be less biased than these models  #AUTHOR_TAG due to the mixture of curated corpora used']","['word2vec embeddings have been shown to contain unintended bias in  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'conceptnet has been shown to be less biased than these models  #AUTHOR_TAG due to the mixture of curated corpora used']","['word2vec embeddings have been shown to contain unintended bias in  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'conceptnet has been shown to be less biased than these models  #AUTHOR_TAG due to the mixture of curated corpora used']","['evaluate three pretrained embedding models : glove  #AUTHOR_TAG, word2vec  #AUTHOR_TAG ( trained on the large google news corpus ), and conceptnet.', 'glove and word2vec embeddings have been shown to contain unintended bias in  #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'conceptnet has been shown to be less biased than these models  #AUTHOR_TAG due to the mixture of curated corpora used for training.', 'as part of our pipeline, we also use a labeled positive / negative sentiment training set  #AUTHOR_TAG.', 'this dataset has been shown to be a trustworthy lexicon for negative and positive sentiment words  #AUTHOR_TAG.', 'we trust these labels to be unbiased so that we may isolate the unintended biases entering our system to the word embeddings.', 'finally, we use a simple logistic regression algorithm to predict negative sentiment.', 'although the choice of ml model can have an impact on fairness for sentiment applications as shown in  #AUTHOR_TAG, we choose a simple ml model to limit the possible unintended biases introduced downstream from our word embeddings']",0
['protected groups  #TAUTHOR_TAG dixon et'],"['protected groups  #TAUTHOR_TAG dixon et al. ;  #AUTHOR_TAG.', 'more specifically, word embeddings has been an']",['various protected groups  #TAUTHOR_TAG dixon et'],"[""have found a variety of ways in which dangerous unintended bias can show up in nlp applications ( blodgett and o' #AUTHOR_TAG."", 'mitigating such biases is a difficult problem, and researchers have created many ways to make fairer nlp applications.', 'much of the focus for mitigating unintended bias in nlp is either targeted at reducing gender stereotypes in text  #AUTHOR_TAG b, a ;  #AUTHOR_TAG, or inequality of sentiment or toxicity for various protected groups  #TAUTHOR_TAG dixon et al. ;  #AUTHOR_TAG.', 'more specifically, word embeddings has been an area of focus for evaluating unintended bias.', ' #AUTHOR_TAG b ) defines a useful metric for identifying gender bias and  #TAUTHOR_TAG defines a metric called the weat score for evaluating unfair correlations with sentiment for various demographics in text.', 'unfortunately metrics like these leverage vector space arguments between only two identities at a time like man vs woman  #AUTHOR_TAG a ), or european american names vs. african american names  #TAUTHOR_TAG.', 'though geometrically intuitive, these tests do not have a direct relation to discrimination in general.', 'our framework and rnsb metric enable a clear evaluation of discrimination with respect to word embedding bias for a whole class of demographics']",4
"['.', 'first, we compare the rnsb metric for 3 pretrained word embeddings, showing that our metric is consistent with other word embedding analysis like weat  #TAUTHOR_TAG.', 'we then show that our framework enables an insightful view into word embedding bias']","['these terms via our framework.', 'first, we compare the rnsb metric for 3 pretrained word embeddings, showing that our metric is consistent with other word embedding analysis like weat  #TAUTHOR_TAG.', 'we then show that our framework enables an insightful view into word embedding bias']","['.', 'first, we compare the rnsb metric for 3 pretrained word embeddings, showing that our metric is consistent with other word embedding analysis like weat  #TAUTHOR_TAG.', 'we then show that our framework enables an insightful view into word embedding bias']","['evaluate our framework and metric on two cases studies : national origin discrimination and religious discrimination.', 'for each case study, we create a set of the most frequent identity terms from the protected groups in the wikipedia word corpus and analyze bias with respect to these terms via our framework.', 'first, we compare the rnsb metric for 3 pretrained word embeddings, showing that our metric is consistent with other word embedding analysis like weat  #TAUTHOR_TAG.', 'we then show that our framework enables an insightful view into word embedding bias']",3
"['by  #TAUTHOR_TAG.', 'the weat score shows that word embeddings like word2vec']","['by  #TAUTHOR_TAG.', 'the weat score shows that word embeddings like word2vec']","['by  #TAUTHOR_TAG.', 'the weat score shows that word embeddings like word2vec']","['vary the word embeddings used in our framework and calculate the rnsb metric for each embedding.', 'the results are displayed in table 1.', 'for both case studies, the bias is largest in glove, as shown by the largest rnsb metric.', 'as mentioned earlier, conceptnet is a state of the art model that mixes models like glove and word2vec, creating fairer word embeddings.', 'through the rnsb metric, one can see that the unintended demographic bias of these word embeddings is an order of magnitude lower than glove or word2vec.', 'although the rnsb metric is not directly comparable to weat scores, these results are still consistent with some of the bias predicted by  #TAUTHOR_TAG.', 'the weat score shows that word embeddings like word2vec and glove are biased with respect to national origin because european - american names are more correlated with positive sentiment than africanamerican names.', 'rnsb captures the same types of biases, but has a clear and larger scope, measuring discrimination with respect to more than two demographics within a protected group.', 'table 1 : table showing our rnsb metric for various word embeddings on two case studies.', 'our metric effectively predicts the unintended demographic bias in the presented word embeddings with respect to negative sentiment']",3
"['largest freely available multi - turn based dialog corpus  #TAUTHOR_TAG 1.', 'it was constructed from the ubunt']","['largest freely available multi - turn based dialog corpus  #TAUTHOR_TAG 1.', 'it was constructed from the ubuntu chat logs 2 - a']","['ubuntu dialogue corpus is the largest freely available multi - turn based dialog corpus  #TAUTHOR_TAG 1.', 'it was constructed from the ubuntu chat logs 2 - a collection of logs']","['ubuntu dialogue corpus is the largest freely available multi - turn based dialog corpus  #TAUTHOR_TAG 1.', 'it was constructed from the ubuntu chat logs 2 - a collection of logs from ubuntu - related chat rooms on the freenode irc network.', 'although multiple users can talk at the same time in the chat room, the logs were preprocessed using heuristics to create two - person conversations.', 'the resulting corpus consists of almost one million two - person conversations, where a user seeks help with his / her ubuntu - related problems ( the average length of a dialog is 8 turns, with a minimum of 3 turns ).', 'because of its size, the corpus is well - suited for explorations of deep learning techniques in the context of dialogue systems.', 'in this paper, we introduce our preliminary research and experiments with this corpus, and report state - of - the - art results.', 'the rest of the paper continues as follows : 1. we introduce the setup - the data as well as the evaluation of the task ; 2. we briefly describe the previously evaluated models ; 3. we introduce three different models ( one of them being the same as in the previous work ) ; 4. we evaluate these models and experiment with different amount of training data ; 5. we conclude and discuss our plans for future']",0
"['this section we briefly describe the data and evaluation metrics used in  #TAUTHOR_TAG.', 'first, all the collected']","['this section we briefly describe the data and evaluation metrics used in  #TAUTHOR_TAG.', 'first, all the collected']","['this section we briefly describe the data and evaluation metrics used in  #TAUTHOR_TAG.', 'first, all the collected']","['this section we briefly describe the data and evaluation metrics used in  #TAUTHOR_TAG.', 'first, all the collected data was preprocessed by replacing named entities with corresponding tags ( name, location, organization, url, path ).', 'this is analogical to the prepossessing of [ 2 ] ( note that the it helpdesk dataset used there is not publicly available ).', 'second, these data are further processed to create tuples of ( context, response, f lag ).', 'the f lag is a boolean variable indicating whether the response is correct or incorrect.', 'to form the training set, each utterance ( starting from the third one ) is considered as a potential response, while the previous utterances form its context.', 'so a dialogue of length n yields ( n − 2 ) training examples ( context, response, 1 ) and ( n − 2 ) training examples ( context, response, 0 ).', 'the negative response response is a randomly sampled utterance from the entire corpus.', 'finally, the training examples are shuffled']",0
"['its simplicity.', 'note that pointwise method was also used in the original baselines  #TAUTHOR_TAG']","['its simplicity.', 'note that pointwise method was also used in the original baselines  #TAUTHOR_TAG']","['its simplicity.', 'note that pointwise method was also used in the original baselines  #TAUTHOR_TAG']","['task can naturally be formulated as a ranking problem which is often tackled by three techniques [ 3 ] : ( i ) pointwise ; ( ii ) pairwise and ( iii ) listwise ranking.', 'while pairwise and listwise ranking approaches are empirically superior to the pointwise ranking approach, our preliminary experiments use pointwise ranking approach for its simplicity.', 'note that pointwise method was also used in the original baselines  #TAUTHOR_TAG']",0
['pointwise architectures reported in  #TAUTHOR_TAG included ( i'],['pointwise architectures reported in  #TAUTHOR_TAG included ( i )'],['pointwise architectures reported in  #TAUTHOR_TAG included ( i'],"['pointwise architectures reported in  #TAUTHOR_TAG included ( i ) tf - idf, ( ii ) rnn and ( iii ) lstm.', 'in this section, we briefly describe these models.', 'a neural network is used to compute the embedding for the context and the response, denoted as c and r. these are fed through a sigmoid function to compute the pairwise probability']",0
"['##s from  #TAUTHOR_TAG.', 'meta - parameters of our architectures are the following : our cnn had 400 filters of length 1,']","['##s from  #TAUTHOR_TAG.', 'meta - parameters of our architectures are the following : our cnn had 400 filters of length 1,']","['##s from  #TAUTHOR_TAG.', 'meta - parameters of our architectures are the following : our cnn had 400 filters of length 1, 100']","['##s from  #TAUTHOR_TAG.', 'meta - parameters of our architectures are the following : our cnn had 400 filters of length 1, 100 filters of length 2 and 100 filters of length 3 ; our lstm had 200 hidden units and our bidirectional lstm had 250 hidden units in each network.', 'for cnns and lstms, the best results were achieved with batch size 256.', 'for bi - lstm, the best batch size was 128.', 'turn user text 1 a : anyone know why "" aptitude update "" returns a non - successful status ( 255 )?', '2 b : does apt - get update work?', '3 a : i\'ve been missing updates because my normal process is sudo bash - c "" aptitude update & & aptitude safe - upgrade - y "". ahh, "" e : some index files failed to download.', 'they have been ignored, or old ones used instead. "". so i guess the issue is that "" aptitude update "" isn\'t giving an error at all n - best confidence response 1 * * * * * * 0. 598 does the internet work on that box?', '2 * * * * 0. 444 what time is it saying to going to be released?? 3 * * * 0. 348 ahh ok 4 * * 0. 245 nice table 2 : a dialog context with three turns and a set of four ranked possible responses.', 'the highest ranked response is the ground truth response in this case']",0
"['3 of the previous evaluation  #TAUTHOR_TAG.', '']","['3 of the previous evaluation  #TAUTHOR_TAG.', '']","[""better given enough data ; ( ii ) the recurrent models have not made its peak yet, suggesting that adding more training data would improve the model's accuracy."", 'this agrees with figure 3 of the previous evaluation  #TAUTHOR_TAG.', 'figure 3 : training data size ranging from 100, 000 to the full 1, 000, 000 examples ( x axis ) and']","['also experimented with different training data sizes in order to see how this affects the resulting models.', 'we trained all networks on a training data size ranging from 100, 000 to the full 1, 000, 000 examples.', 'the graph in figure 3 shows the recall @ 1 for all the three models ( reported on the test data ).', 'there are two main observations here : ( i ) cnns outperform recurrent models if the training dataset is small.', 'we believe that this is mostly due to the max operation performed on top of the feature maps.', 'thanks to the simplicity of this operation, the model does not over - fit the data and generalizes better when learned on small training datasets.', ""on the other hand, the simplicity of the operation does not allow the model to properly handle more complicated dependencies ( such as the order in which the n - grams occur in the text ), thus recurrent models perform better given enough data ; ( ii ) the recurrent models have not made its peak yet, suggesting that adding more training data would improve the model's accuracy."", 'this agrees with figure 3 of the previous evaluation  #TAUTHOR_TAG.', 'figure 3 : training data size ranging from 100, 000 to the full 1, 000, 000 examples ( x axis ) and the resulting recall @ 1 ( y axis ).', 'the cnn has 500, 100 and 100 filters of length 1, 2 and 3.', 'the lstm and bi - lstm has both 300 hidden units in each recurrent layer']",0
['match the original setup of  #TAUTHOR_TAG we use the'],['match the original setup of  #TAUTHOR_TAG we use the'],"['match the original setup of  #TAUTHOR_TAG we use the same training data 3.', 'we use one million training examples and we use the same word vectors pre - trained by glove [ 9 ].', 'all our models were implemented using theano [ 10 ] and blocks [ 11 ].', 'for training we use adam learning rule [ 12 ] and binary negative log - likelihood as training objective.', 'we stop the training once recall @ 1 starts increasing on a validation set.', 'the experiments were executed on nvidia k40 gpus.', 'the best meta - parameters were found by simple grid search.', 'in all architectures we tried both : ( i ) learning separate parameters for the networks encoding context and response and ( ii ) learning shared parameters for both networks.', 'here we report only the results for the architectures with shared parameters,']","['match the original setup of  #TAUTHOR_TAG we use the same training data 3.', 'we use one million training examples and we use the same word vectors pre - trained by glove [ 9 ].', 'all our models were implemented using theano [ 10 ] and blocks [ 11 ].', 'for training we use adam learning rule [ 12 ] and binary negative log - likelihood as training objective.', 'we stop the training once recall @ 1 starts increasing on a validation set.', 'the experiments were executed on nvidia k40 gpus.', 'the best meta - parameters were found by simple grid search.', 'in all architectures we tried both : ( i ) learning separate parameters for the networks encoding context and response and ( ii ) learning shared parameters for both networks.', 'here we report only the results for the architectures with shared parameters, since they consistently achieved higher accuracy.', 'aside from learning single models, we also experimented with model ensembles.', 'we found that averaging predictions of multiple models further improves performance, which is common in many machine learning tasks [ 13, 14 ].', 'our best classifier is an ensemble of 11 lstms, 7 bi - lstms and 10 cnns trained with different meta - parameters.', 'table 1 shows performance of the models with the best metaparameters in each category.', 'an example prediction from the ensemble is shown in table 2.', '']",3
['match the original setup of  #TAUTHOR_TAG we use the'],['match the original setup of  #TAUTHOR_TAG we use the'],"['match the original setup of  #TAUTHOR_TAG we use the same training data 3.', 'we use one million training examples and we use the same word vectors pre - trained by glove [ 9 ].', 'all our models were implemented using theano [ 10 ] and blocks [ 11 ].', 'for training we use adam learning rule [ 12 ] and binary negative log - likelihood as training objective.', 'we stop the training once recall @ 1 starts increasing on a validation set.', 'the experiments were executed on nvidia k40 gpus.', 'the best meta - parameters were found by simple grid search.', 'in all architectures we tried both : ( i ) learning separate parameters for the networks encoding context and response and ( ii ) learning shared parameters for both networks.', 'here we report only the results for the architectures with shared parameters,']","['match the original setup of  #TAUTHOR_TAG we use the same training data 3.', 'we use one million training examples and we use the same word vectors pre - trained by glove [ 9 ].', 'all our models were implemented using theano [ 10 ] and blocks [ 11 ].', 'for training we use adam learning rule [ 12 ] and binary negative log - likelihood as training objective.', 'we stop the training once recall @ 1 starts increasing on a validation set.', 'the experiments were executed on nvidia k40 gpus.', 'the best meta - parameters were found by simple grid search.', 'in all architectures we tried both : ( i ) learning separate parameters for the networks encoding context and response and ( ii ) learning shared parameters for both networks.', 'here we report only the results for the architectures with shared parameters, since they consistently achieved higher accuracy.', 'aside from learning single models, we also experimented with model ensembles.', 'we found that averaging predictions of multiple models further improves performance, which is common in many machine learning tasks [ 13, 14 ].', 'our best classifier is an ensemble of 11 lstms, 7 bi - lstms and 10 cnns trained with different meta - parameters.', 'table 1 shows performance of the models with the best metaparameters in each category.', 'an example prediction from the ensemble is shown in table 2.', '']",5
"['##s from  #TAUTHOR_TAG.', 'meta - parameters of our architectures are the following : our cnn had 400 filters of length 1,']","['##s from  #TAUTHOR_TAG.', 'meta - parameters of our architectures are the following : our cnn had 400 filters of length 1,']","['##s from  #TAUTHOR_TAG.', 'meta - parameters of our architectures are the following : our cnn had 400 filters of length 1, 100']","['##s from  #TAUTHOR_TAG.', 'meta - parameters of our architectures are the following : our cnn had 400 filters of length 1, 100 filters of length 2 and 100 filters of length 3 ; our lstm had 200 hidden units and our bidirectional lstm had 250 hidden units in each network.', 'for cnns and lstms, the best results were achieved with batch size 256.', 'for bi - lstm, the best batch size was 128.', 'turn user text 1 a : anyone know why "" aptitude update "" returns a non - successful status ( 255 )?', '2 b : does apt - get update work?', '3 a : i\'ve been missing updates because my normal process is sudo bash - c "" aptitude update & & aptitude safe - upgrade - y "". ahh, "" e : some index files failed to download.', 'they have been ignored, or old ones used instead. "". so i guess the issue is that "" aptitude update "" isn\'t giving an error at all n - best confidence response 1 * * * * * * 0. 598 does the internet work on that box?', '2 * * * * 0. 444 what time is it saying to going to be released?? 3 * * * 0. 348 ahh ok 4 * * 0. 245 nice table 2 : a dialog context with three turns and a set of four ranked possible responses.', 'the highest ranked response is the ground truth response in this case']",5
"['- art results on the next utterance ranking problem recently introduced in  #TAUTHOR_TAG.', 'the best performing system is an ensemble of multiple diverse neural networks.', 'in the']","['this work we achieved a new state - of - the - art results on the next utterance ranking problem recently introduced in  #TAUTHOR_TAG.', 'the best performing system is an ensemble of multiple diverse neural networks.', 'in the future,']","['this work we achieved a new state - of - the - art results on the next utterance ranking problem recently introduced in  #TAUTHOR_TAG.', 'the best performing system is an ensemble of multiple diverse neural networks.', 'in the future, we plan to use our system as a base for more complicated models going beyond the standard neural network paradigm']","['this work we achieved a new state - of - the - art results on the next utterance ranking problem recently introduced in  #TAUTHOR_TAG.', 'the best performing system is an ensemble of multiple diverse neural networks.', 'in the future, we plan to use our system as a base for more complicated models going beyond the standard neural network paradigm']",4
"['- art results on the next utterance ranking problem recently introduced in  #TAUTHOR_TAG.', 'the best performing system is an ensemble of multiple diverse neural networks.', 'in the']","['this work we achieved a new state - of - the - art results on the next utterance ranking problem recently introduced in  #TAUTHOR_TAG.', 'the best performing system is an ensemble of multiple diverse neural networks.', 'in the future,']","['this work we achieved a new state - of - the - art results on the next utterance ranking problem recently introduced in  #TAUTHOR_TAG.', 'the best performing system is an ensemble of multiple diverse neural networks.', 'in the future, we plan to use our system as a base for more complicated models going beyond the standard neural network paradigm']","['this work we achieved a new state - of - the - art results on the next utterance ranking problem recently introduced in  #TAUTHOR_TAG.', 'the best performing system is an ensemble of multiple diverse neural networks.', 'in the future, we plan to use our system as a base for more complicated models going beyond the standard neural network paradigm']",6
"[',  #TAUTHOR_TAG,,']","[',  #TAUTHOR_TAG,,']","[',  #TAUTHOR_TAG,,']","['have been quite a number of recent papers on parallel text :  #AUTHOR_TAG brown et al (, 1991 brown et al (, 1993,  #AUTHOR_TAG,  #TAUTHOR_TAG,,  #AUTHOR_TAG,  #AUTHOR_TAG, 1993 ),  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG, warwick  #AUTHOR_TAG, wu ( to appear ).', 'most of this work has been focused on european language pairs, especially english - french.', 'it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english - japanese and englishchinese.', 'in previous work, we have reported some preliminary success in aligning the english and japanese versions of the awk manual (  #AUTHOR_TAG ), using charalign  #TAUTHOR_TAG, a method that looks for character sequences that are the same in both the source and target.', 'the charalign method was designed for european language pairs, where cognates often share character sequences, e. g., government and gouvernement.', ""in general, this approach doesn't work between languages such as english and japanese which are written in different alphabets."", 'the awk manual happens to contain a large number of examples and technical words that are the same in the english source and target japanese.', 'it remains an open question how we might be able to align a broader class of texts, especially those that are written in different character sets and share relatively few character sequences.', 'the k - vec method attempts to address this question']",0
"[',  #TAUTHOR_TAG,,']","[',  #TAUTHOR_TAG,,']","[',  #TAUTHOR_TAG,,']","['have been quite a number of recent papers on parallel text :  #AUTHOR_TAG brown et al (, 1991 brown et al (, 1993,  #AUTHOR_TAG,  #TAUTHOR_TAG,,  #AUTHOR_TAG,  #AUTHOR_TAG, 1993 ),  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG, warwick  #AUTHOR_TAG, wu ( to appear ).', 'most of this work has been focused on european language pairs, especially english - french.', 'it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english - japanese and englishchinese.', 'in previous work, we have reported some preliminary success in aligning the english and japanese versions of the awk manual (  #AUTHOR_TAG ), using charalign  #TAUTHOR_TAG, a method that looks for character sequences that are the same in both the source and target.', 'the charalign method was designed for european language pairs, where cognates often share character sequences, e. g., government and gouvernement.', ""in general, this approach doesn't work between languages such as english and japanese which are written in different alphabets."", 'the awk manual happens to contain a large number of examples and technical words that are the same in the english source and target japanese.', 'it remains an open question how we might be able to align a broader class of texts, especially those that are written in different character sets and share relatively few character sequences.', 'the k - vec method attempts to address this question']",0
"['of language combinations including possibly english - japanese and english - chinese.', 'currently, word _ align depends on charalign  #TAUTHOR_TAG to generate a starting point, which limits its']","['of language combinations including possibly english - japanese and english - chinese.', 'currently, word _ align depends on charalign  #TAUTHOR_TAG to generate a starting point, which limits its']","['word _ align to a broader class of language combinations including possibly english - japanese and english - chinese.', 'currently, word _ align depends on charalign  #TAUTHOR_TAG to generate a starting point, which limits its']","['k - vec algorithm generates a quick - and - dirty estimate of a bilingual lexicon.', 'this estimate could be used as a starting point for a more detailed alignment algorithm such as word _ align.', 'in this way, we might be able to apply word _ align to a broader class of language combinations including possibly english - japanese and english - chinese.', 'currently, word _ align depends on charalign  #TAUTHOR_TAG to generate a starting point, which limits its applicability to european languages since char _ align was designed for language pairs that share a common alphabet']",0
"[',  #TAUTHOR_TAG,,']","[',  #TAUTHOR_TAG,,']","[',  #TAUTHOR_TAG,,']","['have been quite a number of recent papers on parallel text :  #AUTHOR_TAG brown et al (, 1991 brown et al (, 1993,  #AUTHOR_TAG,  #TAUTHOR_TAG,,  #AUTHOR_TAG,  #AUTHOR_TAG, 1993 ),  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG, warwick  #AUTHOR_TAG, wu ( to appear ).', 'most of this work has been focused on european language pairs, especially english - french.', 'it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english - japanese and englishchinese.', 'in previous work, we have reported some preliminary success in aligning the english and japanese versions of the awk manual (  #AUTHOR_TAG ), using charalign  #TAUTHOR_TAG, a method that looks for character sequences that are the same in both the source and target.', 'the charalign method was designed for european language pairs, where cognates often share character sequences, e. g., government and gouvernement.', ""in general, this approach doesn't work between languages such as english and japanese which are written in different alphabets."", 'the awk manual happens to contain a large number of examples and technical words that are the same in the english source and target japanese.', 'it remains an open question how we might be able to align a broader class of texts, especially those that are written in different character sets and share relatively few character sequences.', 'the k - vec method attempts to address this question']",1
"[',  #TAUTHOR_TAG,,']","[',  #TAUTHOR_TAG,,']","[',  #TAUTHOR_TAG,,']","['have been quite a number of recent papers on parallel text :  #AUTHOR_TAG brown et al (, 1991 brown et al (, 1993,  #AUTHOR_TAG,  #TAUTHOR_TAG,,  #AUTHOR_TAG,  #AUTHOR_TAG, 1993 ),  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG, warwick  #AUTHOR_TAG, wu ( to appear ).', 'most of this work has been focused on european language pairs, especially english - french.', 'it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english - japanese and englishchinese.', 'in previous work, we have reported some preliminary success in aligning the english and japanese versions of the awk manual (  #AUTHOR_TAG ), using charalign  #TAUTHOR_TAG, a method that looks for character sequences that are the same in both the source and target.', 'the charalign method was designed for european language pairs, where cognates often share character sequences, e. g., government and gouvernement.', ""in general, this approach doesn't work between languages such as english and japanese which are written in different alphabets."", 'the awk manual happens to contain a large number of examples and technical words that are the same in the english source and target japanese.', 'it remains an open question how we might be able to align a broader class of texts, especially those that are written in different character sets and share relatively few character sequences.', 'the k - vec method attempts to address this question']",1
['of other studies :  #TAUTHOR_TAG'],['of other studies :  #TAUTHOR_TAG'],"['2 ( at the end of this paper ).', '1 1.', 'these tables were computed from a small fragment of the canadian hansards that has been used in a number of other studies :  #TAUTHOR_TAG']","['- vec starts by estimating the lexicon.', 'consider the example : fisheries - - ~ p ~ ches.', 'the k - vec algorithm will discover this fact by noting that the distribution of fisheries in the english text is similar to the distribution of p ~ ches in the french.', 'the concordances for fisheries and p ~ ches are shown in tables 1 and 2 ( at the end of this paper ).', '1 1.', 'these tables were computed from a small fragment of the canadian hansards that has been used in a number of other studies :  #TAUTHOR_TAG and  #AUTHOR_TAG show where the concordances were found in the texts.', 'we want to know whether the distribution of numbers in table 1 is similar to those in table 2, and if so, we will suspect that fisheries and p ~ ches as can be seen in the concordances in table 3, for k = 10, the vector is < 1, 1, 0, 1, 1, 0, 1, 0, 0, 0 >. by almost any measure of similarity one could imagine, this vector will be found to be quite different from the one for fisheries, and therefore, we will correctly discover that fisheries is not the translation of lections.', 'to make this argument a little more precise, it might help to compare the contingency matrices in tables 5 and 6.', 'the contingency matrices show : ( a ) the number of pieces where both the english and french word were found, ( b ) the number of pieces where just the english word was found, ( c ) the number of pieces where just the french word was found, and ( d ) the number of peices where neither word was found.', 'in general, if the english and french words are good translations of one another, as in table 5, then a should be large, and b and c should be small.', 'in contrast, if the two words are not good translations of one another, as in table 6, then a should be small, and b and c should be large']",5
"['of other studies :  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the 30 significant pairs with the largest mutual information values are shown in']","['of other studies :  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the 30 significant pairs with the largest mutual information values are shown in']","['algorithm was applied to a fragment of the canadian hansards that has been used in a number of other studies :  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the 30 significant pairs with the largest mutual information values are shown in table 9.', 'as can be seen, the results provide a quick - anddirty estimate of a bilingual lexicon.', 'when the pair is not a direct translation,']","['algorithm was applied to a fragment of the canadian hansards that has been used in a number of other studies :  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the 30 significant pairs with the largest mutual information values are shown in table 9.', 'as can be seen, the results provide a quick - anddirty estimate of a bilingual lexicon.', 'when the pair is not a direct translation, it is often the translation of a collocate, as illustrated by acheteur ~ limited and santd - ~ welfare.', '( note that some words in table 9 are spelled with same way in english and french ; this information is not used by the k - vec algorithm ).', 'the equality constraint is relaxed in figure 2.', 'a dot is placed in position i, j whenever the input token at position i is highly associated with the input token at position j as determined by the mutual information score of their respective kvecs.', 'in addition, it shows a detailed, magnified and rotated view of the diagonal line.', 'the alignment program tracks this line with as much precision as possible.', '3. the low frequency words ( frequency less then 3 ) would have been rejected anyways as insignificant']",5
"['of language combinations including possibly english - japanese and english - chinese.', 'currently, word _ align depends on charalign  #TAUTHOR_TAG to generate a starting point, which limits its']","['of language combinations including possibly english - japanese and english - chinese.', 'currently, word _ align depends on charalign  #TAUTHOR_TAG to generate a starting point, which limits its']","['word _ align to a broader class of language combinations including possibly english - japanese and english - chinese.', 'currently, word _ align depends on charalign  #TAUTHOR_TAG to generate a starting point, which limits its']","['k - vec algorithm generates a quick - and - dirty estimate of a bilingual lexicon.', 'this estimate could be used as a starting point for a more detailed alignment algorithm such as word _ align.', 'in this way, we might be able to apply word _ align to a broader class of language combinations including possibly english - japanese and english - chinese.', 'currently, word _ align depends on charalign  #TAUTHOR_TAG to generate a starting point, which limits its applicability to european languages since char _ align was designed for language pairs that share a common alphabet']",5
"['whole parsing community.', 'in this paper, we compare  #TAUTHOR_TAG and hp']","['whole parsing community.', 'in this paper, we compare  #TAUTHOR_TAG and hpsg  #AUTHOR_TAG, following an']","['the whole parsing community.', 'in this paper, we compare  #TAUTHOR_TAG and hp']","['parsing techniques have been developed for lexicalized grammars such as lexicalized tree adjoining grammar ( ltag )  #AUTHOR_TAG, and head - driven phrase structure grammar ( hpsg )  #AUTHOR_TAG.', 'along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms  #AUTHOR_TAG van  #AUTHOR_TAG.', 'however, these realizations sometimes exhibit quite different performance in each grammar formalism  #AUTHOR_TAG.', 'if we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations.', 'this should also allow us to integrate the advantages of the realizations into one generic parsing technique, which yields the further advancement of the whole parsing community.', 'in this paper, we compare  #TAUTHOR_TAG and hpsg  #AUTHOR_TAG, following an approach to parsing comparison among different grammar formalisms ).', 'the key idea of the approach is to use strongly equivalent grammars, which generate equivalent parse results for the same input, obtained by a grammar conversion as demonstrated by.', 'the parsers with cfg filtering predict possible parse trees by a cfg approximated from a given grammar.', 'comparison of those parsers are interesting because effective cfg filters allow us to bring the empirical time complexity of the parsers close to that of cfg parsing.', 'investigating the difference between the ways of context - free ( cf ) approximation of ltag and hpsg will thereby enlighten a way of further optimization for both techniques.', 'we performed a comparison between the existing  #TAUTHOR_TAG and hpsg  #AUTHOR_TAG, using strongly equivalent grammars obtained by converting ltags extracted from the penn treebank  #AUTHOR_TAG into hpsg - style.', 'we compared the parsers with respect to the size of the approximated cfg and its effectiveness as a filter']",1
"['this section, we introduce a grammar conversion ) and  #TAUTHOR_TAG']","['this section, we introduce a grammar conversion ) and  #TAUTHOR_TAG']","['this section, we introduce a grammar conversion ) and  #TAUTHOR_TAG']","['this section, we introduce a grammar conversion ) and  #TAUTHOR_TAG']",0
['initial offline step of  #TAUTHOR_TAG is performed to approximate'],['initial offline step of  #TAUTHOR_TAG is performed to approximate'],['initial offline step of  #TAUTHOR_TAG is performed to approximate'],"['initial offline step of  #TAUTHOR_TAG is performed to approximate a given grammar with a cfg.', 'the obtained cfg is used as an efficient device to compute the necessary conditions for parse trees.', 'the  #TAUTHOR_TAG generally consists of two steps.', '']",0
['initial offline step of  #TAUTHOR_TAG is performed to approximate'],['initial offline step of  #TAUTHOR_TAG is performed to approximate'],['initial offline step of  #TAUTHOR_TAG is performed to approximate'],"['initial offline step of  #TAUTHOR_TAG is performed to approximate a given grammar with a cfg.', 'the obtained cfg is used as an efficient device to compute the necessary conditions for parse trees.', 'the  #TAUTHOR_TAG generally consists of two steps.', '']",0
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG, every branching of elementary trees in']","[' #TAUTHOR_TAG, every branching of elementary trees in a given grammar is extracted as a cfg rule as shown in figure 1']",0
['initial offline step of  #TAUTHOR_TAG is performed to approximate'],['initial offline step of  #TAUTHOR_TAG is performed to approximate'],['initial offline step of  #TAUTHOR_TAG is performed to approximate'],"['initial offline step of  #TAUTHOR_TAG is performed to approximate a given grammar with a cfg.', 'the obtained cfg is used as an efficient device to compute the necessary conditions for parse trees.', 'the  #TAUTHOR_TAG generally consists of two steps.', '']",6
['initial offline step of  #TAUTHOR_TAG is performed to approximate'],['initial offline step of  #TAUTHOR_TAG is performed to approximate'],['initial offline step of  #TAUTHOR_TAG is performed to approximate'],"['initial offline step of  #TAUTHOR_TAG is performed to approximate a given grammar with a cfg.', 'the obtained cfg is used as an efficient device to compute the necessary conditions for parse trees.', 'the  #TAUTHOR_TAG generally consists of two steps.', '']",4
"['of ltag  #TAUTHOR_TAG.', 'by investigating the different ways of cf approximation,']","['of ltag  #TAUTHOR_TAG.', 'by investigating the different ways of cf approximation,']","['of ltag  #TAUTHOR_TAG.', 'by investigating the different ways of cf approximation,']","['presented an empirical comparison of ltag and hpsg parsers with cfg filtering.', 'we compared the parsers with strongly equivalent grammars obtained by converting ltags extracted from the penn treebank into hpsg - style.', 'experimental results showed that the existing cf approximation of hpsg  #AUTHOR_TAG produced a more effective filter than that of ltag  #TAUTHOR_TAG.', 'by investigating the different ways of cf approximation, we concluded that the global constraints in a given grammar is essential to obtain an effective filter.', 'we are going to integrate the advantage of the cf approximation of hpsg into that of ltag in order to establish another  #TAUTHOR_TAG.', 'we will also conduct experiments on trade - offs between the degree of cf approximation and the size of approximated cfgs as in maxwell iii and  #AUTHOR_TAG']",4
"['of ltag  #TAUTHOR_TAG.', 'by investigating the different ways of cf approximation,']","['of ltag  #TAUTHOR_TAG.', 'by investigating the different ways of cf approximation,']","['of ltag  #TAUTHOR_TAG.', 'by investigating the different ways of cf approximation,']","['presented an empirical comparison of ltag and hpsg parsers with cfg filtering.', 'we compared the parsers with strongly equivalent grammars obtained by converting ltags extracted from the penn treebank into hpsg - style.', 'experimental results showed that the existing cf approximation of hpsg  #AUTHOR_TAG produced a more effective filter than that of ltag  #TAUTHOR_TAG.', 'by investigating the different ways of cf approximation, we concluded that the global constraints in a given grammar is essential to obtain an effective filter.', 'we are going to integrate the advantage of the cf approximation of hpsg into that of ltag in order to establish another  #TAUTHOR_TAG.', 'we will also conduct experiments on trade - offs between the degree of cf approximation and the size of approximated cfgs as in maxwell iii and  #AUTHOR_TAG']",2
['6 ]  #TAUTHOR_TAG'],"['[ 6 ]  #TAUTHOR_TAG [ 8 ] [ 9 ] 14 ], but many questions']","['6 ]  #TAUTHOR_TAG [ 8 ] [ 9 ] 14 ], but many questions']","['', 'this approach has achieved promising initial results [ 6 ]  #TAUTHOR_TAG [ 8 ] [ 9 ] 14 ], but many questions remain.', 'two outstanding questions are the best method of learning verb tensors from a corpus, and the best sentence space for a variety of different tasks.', 'this paper presents work in progress which addresses both of these questions.', 'it compares two methods for learning verb representations, the distributional model of  #TAUTHOR_TAG in which positive examples of subject - object pairs for a given verb are structurally mixed, and the regression model of [ 14 ] in which positive and negative examples of subject - object pairs for a given verb are mapped into a plausibility space.', 'a variety of methods for reducing the noun space and composing the verb, subject, and object representations are investigated.', 'the results show that the plausibility training outperforms the distributional method on a verb disambiguation task, while the purely distributional approach performs better on sentence similarity']",1
['6 ]  #TAUTHOR_TAG'],"['[ 6 ]  #TAUTHOR_TAG [ 8 ] [ 9 ] 14 ], but many questions']","['6 ]  #TAUTHOR_TAG [ 8 ] [ 9 ] 14 ], but many questions']","['', 'this approach has achieved promising initial results [ 6 ]  #TAUTHOR_TAG [ 8 ] [ 9 ] 14 ], but many questions remain.', 'two outstanding questions are the best method of learning verb tensors from a corpus, and the best sentence space for a variety of different tasks.', 'this paper presents work in progress which addresses both of these questions.', 'it compares two methods for learning verb representations, the distributional model of  #TAUTHOR_TAG in which positive examples of subject - object pairs for a given verb are structurally mixed, and the regression model of [ 14 ] in which positive and negative examples of subject - object pairs for a given verb are mapped into a plausibility space.', 'a variety of methods for reducing the noun space and composing the verb, subject, and object representations are investigated.', 'the results show that the plausibility training outperforms the distributional method on a verb disambiguation task, while the purely distributional approach performs better on sentence similarity']",7
"['= 200 dist 0. 25 ± 0. 0000 comb : cs, k = 200', 'relational : from  #TAUTHOR_TAG 10 ], the']","['##2014 reg 0. 28 ± 0. 0000 comb : rel, k = 20 dist 0. 35 ± 0. 0000 comb : rel, k = 100 gs2011 reg 0. 37 ± 0. 0037 comb : vo, k = 200 dist 0. 25 ± 0. 0000 comb : cs, k = 200', 'relational : from  #TAUTHOR_TAG 10 ], the']","['##2014 reg 0. 28 ± 0. 0000 comb : rel, k = 20 dist 0. 35 ± 0. 0000 comb : rel, k = 100 gs2011 reg 0. 37 ± 0. 0037 comb : vo, k = 200 dist 0. 25 ± 0. 0000 comb : cs, k = 200', 'relational : from  #TAUTHOR_TAG 10 ], the meaning of']","['##2014 reg 0. 28 ± 0. 0000 comb : rel, k = 20 dist 0. 35 ± 0. 0000 comb : rel, k = 100 gs2011 reg 0. 37 ± 0. 0037 comb : vo, k = 200 dist 0. 25 ± 0. 0000 comb : cs, k = 200', 'relational : from  #TAUTHOR_TAG 10 ], the meaning of a transitive sentence is a matrix, obtained by the following formula, where ⊗ is outer product, [UNK] is elementwise product, and × is matrix multiplication :', '']",7
"['6,  #TAUTHOR_TAG or defined a new space for']","['same topic - based noun space [ 6,  #TAUTHOR_TAG or defined a new space for']","['mapped sentence meaning to the same topic - based noun space [ 6,  #TAUTHOR_TAG or defined a new space for sentence meaning, particularly plausibility space [ 11, 14 ].', 'if the verb function is a multi - linear map, then the verb is naturally represented by a third - order tensor.', 'however, tensor training can be expensive and in practice, for some tasks, the verb can be approximated as a matrix  #TAUTHOR_TAG 14 ].', 'below we describe two ways of learning a verb matrix.', 'in the regression method, the learnt matrix consists of parameters from a plausibility classifier.', 'the classifier is trained to distinguish plausible sentences like animals eat plants from implaus']","['the definition of the functional approach to compositional distributional semantics [ 1 ] [ 2 ] [ 3 ] [ 4 ], a transitive verb is a map that takes as arguments noun vectors representing the subject and object, and produces a vector in the sentence space.', 'typically, noun vectors for subject and object reside in a "" topic space "" where the dimensions correspond to co - occurrence features ; we use a reduced space resulting from applying singular value decomposition ( svd ) to the raw co - occurrence space.', 'the correct sentence space to use is less obvious ; previous approaches have either mapped sentence meaning to the same topic - based noun space [ 6,  #TAUTHOR_TAG or defined a new space for sentence meaning, particularly plausibility space [ 11, 14 ].', 'if the verb function is a multi - linear map, then the verb is naturally represented by a third - order tensor.', 'however, tensor training can be expensive and in practice, for some tasks, the verb can be approximated as a matrix  #TAUTHOR_TAG 14 ].', 'below we describe two ways of learning a verb matrix.', 'in the regression method, the learnt matrix consists of parameters from a plausibility classifier.', 'the classifier is trained to distinguish plausible sentences like animals eat plants from implausible sentences like animals eat planets.', 'in the distributional method, training is based on a sum of positive ( i. e. attested ) svo triples.', 'the acquisition of positive svo data and plausibility training data is described in section 2. 2']",0
"['6,  #TAUTHOR_TAG or defined a new space for']","['same topic - based noun space [ 6,  #TAUTHOR_TAG or defined a new space for']","['mapped sentence meaning to the same topic - based noun space [ 6,  #TAUTHOR_TAG or defined a new space for sentence meaning, particularly plausibility space [ 11, 14 ].', 'if the verb function is a multi - linear map, then the verb is naturally represented by a third - order tensor.', 'however, tensor training can be expensive and in practice, for some tasks, the verb can be approximated as a matrix  #TAUTHOR_TAG 14 ].', 'below we describe two ways of learning a verb matrix.', 'in the regression method, the learnt matrix consists of parameters from a plausibility classifier.', 'the classifier is trained to distinguish plausible sentences like animals eat plants from implaus']","['the definition of the functional approach to compositional distributional semantics [ 1 ] [ 2 ] [ 3 ] [ 4 ], a transitive verb is a map that takes as arguments noun vectors representing the subject and object, and produces a vector in the sentence space.', 'typically, noun vectors for subject and object reside in a "" topic space "" where the dimensions correspond to co - occurrence features ; we use a reduced space resulting from applying singular value decomposition ( svd ) to the raw co - occurrence space.', 'the correct sentence space to use is less obvious ; previous approaches have either mapped sentence meaning to the same topic - based noun space [ 6,  #TAUTHOR_TAG or defined a new space for sentence meaning, particularly plausibility space [ 11, 14 ].', 'if the verb function is a multi - linear map, then the verb is naturally represented by a third - order tensor.', 'however, tensor training can be expensive and in practice, for some tasks, the verb can be approximated as a matrix  #TAUTHOR_TAG 14 ].', 'below we describe two ways of learning a verb matrix.', 'in the regression method, the learnt matrix consists of parameters from a plausibility classifier.', 'the classifier is trained to distinguish plausible sentences like animals eat plants from implausible sentences like animals eat planets.', 'in the distributional method, training is based on a sum of positive ( i. e. attested ) svo triples.', 'the acquisition of positive svo data and plausibility training data is described in section 2. 2']",0
"[' #TAUTHOR_TAG, we generate a']","[' #TAUTHOR_TAG, we generate a']","[' #TAUTHOR_TAG, we generate a k × k matrix']","[' #TAUTHOR_TAG, we generate a k × k matrix for each verb as the average of outer products of subject and verb vectors from the positively labelled subset of the training data :', 'where ⊗ is outer product and n p is the number of positive training examples.', 'the intuition is that the matrix encodes higher weights for contextual features of frequently attested subjects and objects ; for example, multiplying by the matrix for eat may yield a higher scalar value when its subject exhibits features common to animate nouns, and its object exhibits features common to edible nouns']",5
"['##1 dataset  #TAUTHOR_TAG.', 'this']","['we use the gs2011 dataset  #TAUTHOR_TAG.', 'this']","['we use the gs2011 dataset  #TAUTHOR_TAG.', 'this dataset']","['investigate the performance of the regression learning method on two tasks : verb disambiguation, and transitive sentence similarity.', 'in each case the system must compose svo triples and compare the resulting semantic representations.', 'for the verb disambiguation task we use the gs2011 dataset  #TAUTHOR_TAG.', 'this dataset consists of pairs of svo triples in which the subject and object are held constant, and the verb is manipulated to highlight different word senses.', '']",5
['employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG'],['employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG'],"['employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG.', 'in']","['- trained language models, especially bert - the bidirectional encoder representations from transformers [  #AUTHOR_TAG ], have recently become extremely popular and helped to produce significant improvement gains for various nlp tasks.', 'the success of pre - trained bert and its variants has largely been limited to the english language.', 'for other languages, one could retrain a language - specific model using the bert architecture  #AUTHOR_TAG de  #AUTHOR_TAG ] or employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG.', 'in terms of vietnamese language modeling, to the best of our knowledge, there are two main concerns : ( i ) the vietnamese wikipedia corpus is the only data used to train all monolingual language models, and it also is the only vietnamese dataset included in the pre - training data used by all multilingual language models except xlm - r  #TAUTHOR_TAG.', 'it is worth noting that wikipedia data is not representative of a general language use, and the vietnamese wikipedia data is relatively small ( 1gb in size uncompressed ), while pre - trained language models can be significantly improved by using more data [  #AUTHOR_TAG ].', '( ii ) all monolingual and multilingual models, except etnlp, are not aware of the difference between vietnamese syllables and word tokens ( this ambiguity comes from the fact that the white space is also used to separate syllables that constitute words when written in vietnamese ).', 'without doing a pre - process step of vietnamese word segmentation, those models directly apply bype - pair encoding ( bpe ) methods [  #AUTHOR_TAG ] to the syllable - level pre - training vietnamese data.', 'also, although performing word segmentation before applying bpe on the vietnamese wikipedia corpus, etnlp in fact does not publicly release any pre - trained bert - based model.', '1 as a result, we find difficulties in applying existing pre - trained language models for word - level vietnamese nlp tasks.', 'to handle the two concerns above, we train the first largescale monolingual bert - based "" base "" and "" large "" models using a 20gb word - level vietnamese corpus.', 'we evaluate our models on three downstream vietnamese nlp tasks : the two most common ones of part - of - speech ( pos ) tagging and named - entity recognition ( ner ), and a language understanding task of natural language inference ( nli ).', 'experimental results show that our models obtain state - of - the - art ( sota ) performances for all three tasks.', 'we release our models under the name phobert in popular open - source libraries, hoping that phobe']",0
['employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG'],['employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG'],"['employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG.', 'in']","['- trained language models, especially bert - the bidirectional encoder representations from transformers [  #AUTHOR_TAG ], have recently become extremely popular and helped to produce significant improvement gains for various nlp tasks.', 'the success of pre - trained bert and its variants has largely been limited to the english language.', 'for other languages, one could retrain a language - specific model using the bert architecture  #AUTHOR_TAG de  #AUTHOR_TAG ] or employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG.', 'in terms of vietnamese language modeling, to the best of our knowledge, there are two main concerns : ( i ) the vietnamese wikipedia corpus is the only data used to train all monolingual language models, and it also is the only vietnamese dataset included in the pre - training data used by all multilingual language models except xlm - r  #TAUTHOR_TAG.', 'it is worth noting that wikipedia data is not representative of a general language use, and the vietnamese wikipedia data is relatively small ( 1gb in size uncompressed ), while pre - trained language models can be significantly improved by using more data [  #AUTHOR_TAG ].', '( ii ) all monolingual and multilingual models, except etnlp, are not aware of the difference between vietnamese syllables and word tokens ( this ambiguity comes from the fact that the white space is also used to separate syllables that constitute words when written in vietnamese ).', 'without doing a pre - process step of vietnamese word segmentation, those models directly apply bype - pair encoding ( bpe ) methods [  #AUTHOR_TAG ] to the syllable - level pre - training vietnamese data.', 'also, although performing word segmentation before applying bpe on the vietnamese wikipedia corpus, etnlp in fact does not publicly release any pre - trained bert - based model.', '1 as a result, we find difficulties in applying existing pre - trained language models for word - level vietnamese nlp tasks.', 'to handle the two concerns above, we train the first largescale monolingual bert - based "" base "" and "" large "" models using a 20gb word - level vietnamese corpus.', 'we evaluate our models on three downstream vietnamese nlp tasks : the two most common ones of part - of - speech ( pos ) tagging and named - entity recognition ( ner ), and a language understanding task of natural language inference ( nli ).', 'experimental results show that our models obtain state - of - the - art ( sota ) performances for all three tasks.', 'we release our models under the name phobert in popular open - source libraries, hoping that phobe']",0
['employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG'],['employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG'],"['employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG.', 'in']","['- trained language models, especially bert - the bidirectional encoder representations from transformers [  #AUTHOR_TAG ], have recently become extremely popular and helped to produce significant improvement gains for various nlp tasks.', 'the success of pre - trained bert and its variants has largely been limited to the english language.', 'for other languages, one could retrain a language - specific model using the bert architecture  #AUTHOR_TAG de  #AUTHOR_TAG ] or employ existing pre - trained multilingual bert - based models [  #TAUTHOR_TAG.', 'in terms of vietnamese language modeling, to the best of our knowledge, there are two main concerns : ( i ) the vietnamese wikipedia corpus is the only data used to train all monolingual language models, and it also is the only vietnamese dataset included in the pre - training data used by all multilingual language models except xlm - r  #TAUTHOR_TAG.', 'it is worth noting that wikipedia data is not representative of a general language use, and the vietnamese wikipedia data is relatively small ( 1gb in size uncompressed ), while pre - trained language models can be significantly improved by using more data [  #AUTHOR_TAG ].', '( ii ) all monolingual and multilingual models, except etnlp, are not aware of the difference between vietnamese syllables and word tokens ( this ambiguity comes from the fact that the white space is also used to separate syllables that constitute words when written in vietnamese ).', 'without doing a pre - process step of vietnamese word segmentation, those models directly apply bype - pair encoding ( bpe ) methods [  #AUTHOR_TAG ] to the syllable - level pre - training vietnamese data.', 'also, although performing word segmentation before applying bpe on the vietnamese wikipedia corpus, etnlp in fact does not publicly release any pre - trained bert - based model.', '1 as a result, we find difficulties in applying existing pre - trained language models for word - level vietnamese nlp tasks.', 'to handle the two concerns above, we train the first largescale monolingual bert - based "" base "" and "" large "" models using a 20gb word - level vietnamese corpus.', 'we evaluate our models on three downstream vietnamese nlp tasks : the two most common ones of part - of - speech ( pos ) tagging and named - entity recognition ( ner ), and a language understanding task of natural language inference ( nli ).', 'experimental results show that our models obtain state - of - the - art ( sota ) performances for all three tasks.', 'we release our models under the name phobert in popular open - source libraries, hoping that phobe']",1
['0  #TAUTHOR_TAG where the vietnam'],"['test sets from the xnli corpus v1. 0  #TAUTHOR_TAG where the vietnamese training data is machinetranslated from english.', 'unlike']","['test sets from the xnli corpus v1. 0  #TAUTHOR_TAG where the vietnamese training data is machinetranslated from english.', 'unlike the 2013 pos tagging']","['evaluate the performance of phobert on three downstream vietnamese nlp tasks : pos tagging, ner and nli.', 'experimental setup : for the two most common vietnamese pos tagging and ner tasks, we follow the vncorenlp setup, using standard benchmarks of the vlsp 2013 pos tagging dataset and the vlsp 2016 ner dataset [  #AUTHOR_TAG a ].', 'for nli, we use the vietnamese validation and test sets from the xnli corpus v1. 0  #TAUTHOR_TAG where the vietnamese training data is machinetranslated from english.', 'unlike the 2013 pos tagging and 2016 ner datasets which provide the gold word segmentation, for nli, we use rdrsegmenter to segment the text into words before applying fastbpe to produce subwords from word tokens.', 'following devlin et al. [ 2019 ], for pos tagging and ner, we append a linear prediction layer on top of the phobert architecture w. r. t.', 'the first subword token of each word.', 'we fine - tune phobert for each task and each dataset independently, employing the hugging face transformers for pos tagging and ner and the roberta implementation in fairseq for nli.', '']",5
"['drop  #TAUTHOR_TAG,']","['drop  #TAUTHOR_TAG,']","['drop  #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],5
"['on numbers ( § 3. 2 ).', 'following  #TAUTHOR_TAG, we first']","['on numbers ( § 3. 2 ).', 'following  #TAUTHOR_TAG, we first']","[') negation on numbers ( § 3. 2 ).', 'following  #TAUTHOR_TAG, we first']",[' #TAUTHOR_TAG'],5
"['types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type']","['types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type']","['be a span of text, the discrete - reasoning reading comprehension task involves different answer types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type answer predictor']","['than restricting the answer to always be a span of text, the discrete - reasoning reading comprehension task involves different answer types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type answer predictor to selectively produce different kinds of answers such as span, count number, and arithmetic expression.', 'to further increase answer coverage, we propose adding a new answer type to support logical negation.', 'moreover, unlike prior work that separately predicts passage spans and question spans, our approach directly extracts spans from the input sequence.', '']",5
"['types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type']","['types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type']","['be a span of text, the discrete - reasoning reading comprehension task involves different answer types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type answer predictor']","['than restricting the answer to always be a span of text, the discrete - reasoning reading comprehension task involves different answer types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type answer predictor to selectively produce different kinds of answers such as span, count number, and arithmetic expression.', 'to further increase answer coverage, we propose adding a new answer type to support logical negation.', 'moreover, unlike prior work that separately predicts passage spans and question spans, our approach directly extracts spans from the input sequence.', '']",5
"['in  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'we']","['in  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'we']","['in  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'we find all possible annotations that']","['drop does not indicate the answer type but only provides the answer string, we therefore adopt the weakly supervised annotation scheme, as suggested in  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'we find all possible annotations that point to the gold answer, including matching spans, arithmetic expressions, correct count numbers, negation operations, and the number of spans.', '']",5
"['over paragraphs ( drop )  #TAUTHOR_TAG prehensive understanding of the context as well as the ability of numerical reasoning are required.', 'model settings we build our model upon']","['over paragraphs ( drop )  #TAUTHOR_TAG prehensive understanding of the context as well as the ability of numerical reasoning are required.', 'model settings we build our model upon']","['we consider the reading comprehension benchmark that requires discrete reasoning over paragraphs ( drop )  #TAUTHOR_TAG prehensive understanding of the context as well as the ability of numerical reasoning are required.', 'model settings we build our model upon two publicly available uncased versions of bert : bert base and bert large 2, and refer readers to  #AUTHOR_TAG']","['we consider the reading comprehension benchmark that requires discrete reasoning over paragraphs ( drop )  #TAUTHOR_TAG prehensive understanding of the context as well as the ability of numerical reasoning are required.', 'model settings we build our model upon two publicly available uncased versions of bert : bert base and bert large 2, and refer readers to  #AUTHOR_TAG for details on model sizes.', 'we use adam optimizer with a learning rate of 3e - 5 and warmup over the first 5 % steps to train.', 'the maximum number of epochs is set to 10 for base models and 5 for large models, while the batch size is 12 or 24 respectively.', 'a dropout probability of 0. 1 is used unless stated otherwise.', 'the number of counting class is set to 10, and the maximum number of spans is 8.', 'the beam size is 3 by default, while the maximum amount of signed numbers m is set to 4.', 'all texts are tokenized using word - 2 bertbase is the original version while bertlarge is the model augmented with n - gram masking and synthetic self - training :', 'https : / / github. com / google - research / bert.', 'piece vocabulary  #AUTHOR_TAG, and truncated to sequences no longer than 512 tokens']",5
"['solved  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a new benchmark']","['solved  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a new benchmark']","['recent works  #AUTHOR_TAG are designed to extract answers from the passage.', 'despite their success, these datasets only require shallow pattern matching and simple logical reasoning, thus being well solved  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a new benchmark']","['comprehension benchmarks promising advancements have been made for reading comprehension due to the creation of many large datasets.', 'while early research used cloze - style tests  #AUTHOR_TAG, most of recent works  #AUTHOR_TAG are designed to extract answers from the passage.', 'despite their success, these datasets only require shallow pattern matching and simple logical reasoning, thus being well solved  #AUTHOR_TAG.', 'recently,  #TAUTHOR_TAG released a new benchmark named drop that demands discrete reasoning as well as deeper paragraph understanding to find the answers.', ' #AUTHOR_TAG introduced a dataset consisting of different types of mathematics problems to focuses on mathematical computation.', 'we choose to work on drop to test both the numerical reasoning and linguistic comprehension abilities.', 'neural reading models previous neural reading models, such as bidaf  #AUTHOR_TAG, r - net  #AUTHOR_TAG, qanet  #AUTHOR_TAG, reinforced mreader  #AUTHOR_TAG, are usually designed to extract a continuous span of text as the answer.', ' #AUTHOR_TAG enhanced prior single - type prediction to support various answer types such as span, count number, and addition / subtraction.', 'different from these approaches, our model additionally supports a new negation type to increase answer coverage, and learns to dynamically extract one or multiple spans.', 'morevoer, answer reranking has been well studied in several prior works  #AUTHOR_TAG a, b, c ;  #AUTHOR_TAG.', '']",5
"['types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type']","['types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type']","['be a span of text, the discrete - reasoning reading comprehension task involves different answer types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type answer predictor']","['than restricting the answer to always be a span of text, the discrete - reasoning reading comprehension task involves different answer types ( e. g., number, date, span of text ).', 'following  #TAUTHOR_TAG, we design a multi - type answer predictor to selectively produce different kinds of answers such as span, count number, and arithmetic expression.', 'to further increase answer coverage, we propose adding a new answer type to support logical negation.', 'moreover, unlike prior work that separately predicts passage spans and question spans, our approach directly extracts spans from the input sequence.', '']",3
"['##net )  #TAUTHOR_TAG, we introduce a similar baseline']","['augmented qanet ( naqanet )  #TAUTHOR_TAG, we introduce a similar baseline']","['##net )  #TAUTHOR_TAG, we introduce a similar baseline']","['##s following the implementation of augmented qanet ( naqanet )  #TAUTHOR_TAG, we introduce a similar baseline called augmented bert ( nabert ).', 'the main difference is that we replace the encoder of qanet  #AUTHOR_TAG with the pre - trained transformer blocks  #AUTHOR_TAG.', 'moreover, it also supports the prediction of various answer types such as span, arithmetic expression, and count number']",3
['using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],['using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],['spoken captions for mscoco were generated using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],"['the past few years, there has been an increasing interest in research gathering the language and vision ( lavi ) communities.', 'multimodal corpora such as flickr30k [ 1 ] or mscoco [ 2 ] containing images along with natural language captions were made available for research.', 'they were soon extended with speech modality : speech recordings for the captions of flickr8k were collected by [ 3 ] via crowdsourcing ; spoken captions for mscoco were generated using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions of these corpora to other languages than english, such as japanese, were also introduced by [ 6 ].', 'these corpora, as well as deep learning models, lead to contributions in multilingual language grounding and learning of shared and multimodal representations with neural networks  #TAUTHOR_TAG 7, 8, 9, 10, 11, 12, 13 ].', 'this paper focuses on computational models of visually grounded speech that were introduced by [ 14,  #TAUTHOR_TAG.', 'learned representations of such models were analyzed by [ 11, 7,  #TAUTHOR_TAG : [ 11 ] introduced novel methods for interpreting the activation patterns of recurrent neural networks ( rnn ) in a model of visually grounded meaning representation from textual and visual input and showed that rnn pay attention to word tokens belonging to specific lexical categories.', '']",0
['using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],['using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],['spoken captions for mscoco were generated using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],"['the past few years, there has been an increasing interest in research gathering the language and vision ( lavi ) communities.', 'multimodal corpora such as flickr30k [ 1 ] or mscoco [ 2 ] containing images along with natural language captions were made available for research.', 'they were soon extended with speech modality : speech recordings for the captions of flickr8k were collected by [ 3 ] via crowdsourcing ; spoken captions for mscoco were generated using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions of these corpora to other languages than english, such as japanese, were also introduced by [ 6 ].', 'these corpora, as well as deep learning models, lead to contributions in multilingual language grounding and learning of shared and multimodal representations with neural networks  #TAUTHOR_TAG 7, 8, 9, 10, 11, 12, 13 ].', 'this paper focuses on computational models of visually grounded speech that were introduced by [ 14,  #TAUTHOR_TAG.', 'learned representations of such models were analyzed by [ 11, 7,  #TAUTHOR_TAG : [ 11 ] introduced novel methods for interpreting the activation patterns of recurrent neural networks ( rnn ) in a model of visually grounded meaning representation from textual and visual input and showed that rnn pay attention to word tokens belonging to specific lexical categories.', '']",0
['using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],['using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],['spoken captions for mscoco were generated using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],"['the past few years, there has been an increasing interest in research gathering the language and vision ( lavi ) communities.', 'multimodal corpora such as flickr30k [ 1 ] or mscoco [ 2 ] containing images along with natural language captions were made available for research.', 'they were soon extended with speech modality : speech recordings for the captions of flickr8k were collected by [ 3 ] via crowdsourcing ; spoken captions for mscoco were generated using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions of these corpora to other languages than english, such as japanese, were also introduced by [ 6 ].', 'these corpora, as well as deep learning models, lead to contributions in multilingual language grounding and learning of shared and multimodal representations with neural networks  #TAUTHOR_TAG 7, 8, 9, 10, 11, 12, 13 ].', 'this paper focuses on computational models of visually grounded speech that were introduced by [ 14,  #TAUTHOR_TAG.', 'learned representations of such models were analyzed by [ 11, 7,  #TAUTHOR_TAG : [ 11 ] introduced novel methods for interpreting the activation patterns of recurrent neural networks ( rnn ) in a model of visually grounded meaning representation from textual and visual input and showed that rnn pay attention to word tokens belonging to specific lexical categories.', '']",0
['using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],['using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],['spoken captions for mscoco were generated using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],"['the past few years, there has been an increasing interest in research gathering the language and vision ( lavi ) communities.', 'multimodal corpora such as flickr30k [ 1 ] or mscoco [ 2 ] containing images along with natural language captions were made available for research.', 'they were soon extended with speech modality : speech recordings for the captions of flickr8k were collected by [ 3 ] via crowdsourcing ; spoken captions for mscoco were generated using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions of these corpora to other languages than english, such as japanese, were also introduced by [ 6 ].', 'these corpora, as well as deep learning models, lead to contributions in multilingual language grounding and learning of shared and multimodal representations with neural networks  #TAUTHOR_TAG 7, 8, 9, 10, 11, 12, 13 ].', 'this paper focuses on computational models of visually grounded speech that were introduced by [ 14,  #TAUTHOR_TAG.', 'learned representations of such models were analyzed by [ 11, 7,  #TAUTHOR_TAG : [ 11 ] introduced novel methods for interpreting the activation patterns of recurrent neural networks ( rnn ) in a model of visually grounded meaning representation from textual and visual input and showed that rnn pay attention to word tokens belonging to specific lexical categories.', '']",0
"['equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', '']","['equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', '']","['english equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', 'we followed']","['corpora we use for our experiments are based on mscoco [ 2 ].', 'mscoco is a dataset initially thought for computer vision purposes, mainly automatic image captioning.', 'the dataset consists of a set of images, each paired with 5 written captions describing the image.', 'all captions were written in english by humans and faithfully describe the content of the image.', 'the japanese corpus we use is based on the newly created stair dataset [ 6 ].', 'using the same methodology as [ 2 ], [ 6 ] collected 5 japanese captions for each image of the original mscoco dataset.', 'as for the original mscoco dataset, japanese captions were written by native japanese speakers.', 'it is worth insisting on the fact that these japanese captions are original captions and not plain translations of their english equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', 'we followed the same methodology as  #TAUTHOR_TAG and generated synthetic speech for each caption in the japanese stair dataset.', 'we created the spoken stair dataset so it would follow the exact same train / val / test 5 split as  #TAUTHOR_TAG.', 'we thus have two comparable corpora : one featuring images and spoken captions in english, and another one featuring the same images and spoken captions in japanese.', 'this allowed us to compare the behaviour of the same architecture on two typologically different languages.', 'we forced aligned each spoken caption to its transcription ( using the montreal forced aligner [ 18 ] and maus forced aligner [ 19 ] for english and japanese respectively ), resulting in alignments at word and phone level.', 'we also tagged each dataset using treetagger [ 20 ] for english and kytea [ 21 ] for japanese.', 'as the tagset of both taggers differs, we mapped each pos to its universal pos equivalent [ 22 ] enabling us to compare the pos distribution of each corpus.', '6 model r @ 1 r @ 5 r @ 10 r english 0. 060 0. 195 0. 301 25 japanese 0. 054 0. 180 0. 283 28 table 1 : recall at 1, 5, and 10 results as well as median rank r on a speech - image retrieval task ( test part of our datasets with 5k images ).', 'original implementation by  #TAUTHOR_TAG with rhn reports median rank r = 13 on english dataset.', 'chance for median rank r is 2500. 5']",0
['using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],['using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],['spoken captions for mscoco were generated using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions'],"['the past few years, there has been an increasing interest in research gathering the language and vision ( lavi ) communities.', 'multimodal corpora such as flickr30k [ 1 ] or mscoco [ 2 ] containing images along with natural language captions were made available for research.', 'they were soon extended with speech modality : speech recordings for the captions of flickr8k were collected by [ 3 ] via crowdsourcing ; spoken captions for mscoco were generated using google text - to - speech ( tts ) by  #TAUTHOR_TAG and using voxygen tts by [ 5 ] ; extensions of these corpora to other languages than english, such as japanese, were also introduced by [ 6 ].', 'these corpora, as well as deep learning models, lead to contributions in multilingual language grounding and learning of shared and multimodal representations with neural networks  #TAUTHOR_TAG 7, 8, 9, 10, 11, 12, 13 ].', 'this paper focuses on computational models of visually grounded speech that were introduced by [ 14,  #TAUTHOR_TAG.', 'learned representations of such models were analyzed by [ 11, 7,  #TAUTHOR_TAG : [ 11 ] introduced novel methods for interpreting the activation patterns of recurrent neural networks ( rnn ) in a model of visually grounded meaning representation from textual and visual input and showed that rnn pay attention to word tokens belonging to specific lexical categories.', '']",4
"['original model  #TAUTHOR_TAG, we used gru units']","['original model  #TAUTHOR_TAG, we used gru units']","['5 stacked recurrent layers.', 'contrary to the original model  #TAUTHOR_TAG, we used gru units']","['image encoder takes vgg - 16 ( [ 17 ] ) pre - calculated vectors as input 2 instead of raw images.', 'it only consists of a dense layer that learns how to shrink the 4096 dimensional vgg - 16 input vector to a 512 dimensional vector, which is then l2 normalised.', 'the speech encoder ( input is 13 mfcc vectors instead of raw speech ) consists of a convolutional layer followed by 5 stacked recurrent layers.', 'contrary to the original model  #TAUTHOR_TAG, we used gru units instead of rhn units.', '3 results are still acceptable ( see table 1 ) even if gru architecture scores worse than original rhn one']",4
"['model we use for our experiments is based on that of  #TAUTHOR_TAG.', 'it is trained to']","['model we use for our experiments is based on that of  #TAUTHOR_TAG.', 'it is trained to']","['model we use for our experiments is based on that of  #TAUTHOR_TAG.', 'it is trained to']","['model we use for our experiments is based on that of  #TAUTHOR_TAG.', 'it is trained to solve an image retrieval task : given a spoken description it retrieves the closest image that matches the description.', 'to do so, the model projects an image and its spoken description in a common representation space, so that matching image / utterance pairs lie near while mismatching image / utterance pairs lie apart']",5
"['equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', '']","['equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', '']","['english equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', 'we followed']","['corpora we use for our experiments are based on mscoco [ 2 ].', 'mscoco is a dataset initially thought for computer vision purposes, mainly automatic image captioning.', 'the dataset consists of a set of images, each paired with 5 written captions describing the image.', 'all captions were written in english by humans and faithfully describe the content of the image.', 'the japanese corpus we use is based on the newly created stair dataset [ 6 ].', 'using the same methodology as [ 2 ], [ 6 ] collected 5 japanese captions for each image of the original mscoco dataset.', 'as for the original mscoco dataset, japanese captions were written by native japanese speakers.', 'it is worth insisting on the fact that these japanese captions are original captions and not plain translations of their english equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', 'we followed the same methodology as  #TAUTHOR_TAG and generated synthetic speech for each caption in the japanese stair dataset.', 'we created the spoken stair dataset so it would follow the exact same train / val / test 5 split as  #TAUTHOR_TAG.', 'we thus have two comparable corpora : one featuring images and spoken captions in english, and another one featuring the same images and spoken captions in japanese.', 'this allowed us to compare the behaviour of the same architecture on two typologically different languages.', 'we forced aligned each spoken caption to its transcription ( using the montreal forced aligner [ 18 ] and maus forced aligner [ 19 ] for english and japanese respectively ), resulting in alignments at word and phone level.', 'we also tagged each dataset using treetagger [ 20 ] for english and kytea [ 21 ] for japanese.', 'as the tagset of both taggers differs, we mapped each pos to its universal pos equivalent [ 22 ] enabling us to compare the pos distribution of each corpus.', '6 model r @ 1 r @ 5 r @ 10 r english 0. 060 0. 195 0. 301 25 japanese 0. 054 0. 180 0. 283 28 table 1 : recall at 1, 5, and 10 results as well as median rank r on a speech - image retrieval task ( test part of our datasets with 5k images ).', 'original implementation by  #TAUTHOR_TAG with rhn reports median rank r = 13 on english dataset.', 'chance for median rank r is 2500. 5']",5
"['equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', '']","['equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', '']","['english equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', 'we followed']","['corpora we use for our experiments are based on mscoco [ 2 ].', 'mscoco is a dataset initially thought for computer vision purposes, mainly automatic image captioning.', 'the dataset consists of a set of images, each paired with 5 written captions describing the image.', 'all captions were written in english by humans and faithfully describe the content of the image.', 'the japanese corpus we use is based on the newly created stair dataset [ 6 ].', 'using the same methodology as [ 2 ], [ 6 ] collected 5 japanese captions for each image of the original mscoco dataset.', 'as for the original mscoco dataset, japanese captions were written by native japanese speakers.', 'it is worth insisting on the fact that these japanese captions are original captions and not plain translations of their english equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', 'we followed the same methodology as  #TAUTHOR_TAG and generated synthetic speech for each caption in the japanese stair dataset.', 'we created the spoken stair dataset so it would follow the exact same train / val / test 5 split as  #TAUTHOR_TAG.', 'we thus have two comparable corpora : one featuring images and spoken captions in english, and another one featuring the same images and spoken captions in japanese.', 'this allowed us to compare the behaviour of the same architecture on two typologically different languages.', 'we forced aligned each spoken caption to its transcription ( using the montreal forced aligner [ 18 ] and maus forced aligner [ 19 ] for english and japanese respectively ), resulting in alignments at word and phone level.', 'we also tagged each dataset using treetagger [ 20 ] for english and kytea [ 21 ] for japanese.', 'as the tagset of both taggers differs, we mapped each pos to its universal pos equivalent [ 22 ] enabling us to compare the pos distribution of each corpus.', '6 model r @ 1 r @ 5 r @ 10 r english 0. 060 0. 195 0. 301 25 japanese 0. 054 0. 180 0. 283 28 table 1 : recall at 1, 5, and 10 results as well as median rank r on a speech - image retrieval task ( test part of our datasets with 5k images ).', 'original implementation by  #TAUTHOR_TAG with rhn reports median rank r = 13 on english dataset.', 'chance for median rank r is 2500. 5']",5
"['equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', '']","['equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', '']","['english equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', 'we followed']","['corpora we use for our experiments are based on mscoco [ 2 ].', 'mscoco is a dataset initially thought for computer vision purposes, mainly automatic image captioning.', 'the dataset consists of a set of images, each paired with 5 written captions describing the image.', 'all captions were written in english by humans and faithfully describe the content of the image.', 'the japanese corpus we use is based on the newly created stair dataset [ 6 ].', 'using the same methodology as [ 2 ], [ 6 ] collected 5 japanese captions for each image of the original mscoco dataset.', 'as for the original mscoco dataset, japanese captions were written by native japanese speakers.', 'it is worth insisting on the fact that these japanese captions are original captions and not plain translations of their english equivalents.', 'mscoco and stair are thus comparable corpora.', 'we trained our model on extended versions of mscoco and stair.', 'spoken coco dataset was introduced by  #TAUTHOR_TAG for english.', 'we followed the same methodology as  #TAUTHOR_TAG and generated synthetic speech for each caption in the japanese stair dataset.', 'we created the spoken stair dataset so it would follow the exact same train / val / test 5 split as  #TAUTHOR_TAG.', 'we thus have two comparable corpora : one featuring images and spoken captions in english, and another one featuring the same images and spoken captions in japanese.', 'this allowed us to compare the behaviour of the same architecture on two typologically different languages.', 'we forced aligned each spoken caption to its transcription ( using the montreal forced aligner [ 18 ] and maus forced aligner [ 19 ] for english and japanese respectively ), resulting in alignments at word and phone level.', 'we also tagged each dataset using treetagger [ 20 ] for english and kytea [ 21 ] for japanese.', 'as the tagset of both taggers differs, we mapped each pos to its universal pos equivalent [ 22 ] enabling us to compare the pos distribution of each corpus.', '6 model r @ 1 r @ 5 r @ 10 r english 0. 060 0. 195 0. 301 25 japanese 0. 054 0. 180 0. 283 28 table 1 : recall at 1, 5, and 10 results as well as median rank r on a speech - image retrieval task ( test part of our datasets with 5k images ).', 'original implementation by  #TAUTHOR_TAG with rhn reports median rank r = 13 on english dataset.', 'chance for median rank r is 2500. 5']",5
"['predictions ( see figure 2 ).', 'in the original architecture  #TAUTHOR_TAG, attention follows']","['predictions ( see figure 2 ).', 'in the original architecture  #TAUTHOR_TAG, attention follows']","['predictions ( see figure 2 ).', 'in the original architecture  #TAUTHOR_TAG, attention follows']","['of the key component of the model is its attention mechanism.', 'the model computes a weighted sum of the gru activations at all timesteps as following : t αtht.', 'knowing by how much a given vector has been weighted gives us an insight on which portions of the speech signal the network relies to make its predictions ( see figure 2 ).', 'in the original architecture  #TAUTHOR_TAG, attention follows the last recurrent layer.', 'to have more insight on the representation learnt by the network, we added an attention mechanism after the first recurrent layer.', 'final vector produced by the speech encoder is a dot product of the vectors produced by both attentions.', 'however, for the sake of clarity, we will only report in this paper results on the attention weights of the top attention mechanism gru5 ( after the fifth recurrent layer ).', '']",6
"['translations  #TAUTHOR_TAG.', 'we frame the shortcomings of sm']","['crowdsourcing translations  #TAUTHOR_TAG.', 'we frame the shortcomings of smt models']","['crowdsourcing translations  #TAUTHOR_TAG.', 'we frame the shortcomings of smt models']","['statistical machine translation ( smt ) models  #AUTHOR_TAG are trained using large, sentence - aligned parallel corpora.', 'unfortunately, parallel corpora are not always available in large enough quantities to train robust models  #AUTHOR_TAG.', 'in this work, we consider the situation in which we have access to only a small amount of bitext for a given low resource language pair, and we wish to supplement an smt model with additional translations and features estimated using comparable corpora in the source and target languages.', 'assuming access to a small amount * performed while faculty at johns hopkins university of parallel text is realistic, especially considering the recent success of crowdsourcing translations  #TAUTHOR_TAG.', 'we frame the shortcomings of smt models trained on limited amounts of parallel text 1 in terms of accuracy and coverage.', 'in this context, coverage refers to the number of words and phrases that a model has any knowledge of at all, and it is low when the training text is small, which results in a high out - of - vocabulary ( oov ) rate.', 'accuracy refers to the correctness of the translation pairs and their corresponding probability features that make up the translation model.', '']",1
"['', '5 the  #TAUTHOR_TAG also induce translations for source language words which are low frequency in the training data and supplement our smt models with top - k translations, not just the highest']","['mt models.', 'then, in additional sets of experiments, we 4 giza + + intersection alignments over all training data.', '5 the  #TAUTHOR_TAG also induce translations for source language words which are low frequency in the training data and supplement our smt models with top - k translations, not just the highest']","['mt models.', 'then, in additional sets of experiments, we 4 giza + + intersection alignments over all training data.', '5 the  #TAUTHOR_TAG also induce translations for source language words which are low frequency in the training data and supplement our smt models with top - k translations, not just the highest ranked']","['', 'adding these translations by definition improves the coverage of our mt models.', 'then, in additional sets of experiments, we 4 giza + + intersection alignments over all training data.', '5 the  #TAUTHOR_TAG also induce translations for source language words which are low frequency in the training data and supplement our smt models with top - k translations, not just the highest ranked']",4
"['', '9  #TAUTHOR_TAG gathered up to six translations for']","['mt experiments.', '9  #TAUTHOR_TAG gathered up to six translations for']","['mt experiments.', '9  #TAUTHOR_TAG gathered up to six translations for each source word, so some have multiple correct translations appending the top - k translations']","['', '9 performance is lowest for tamil and highest for hindi.', 'for all languages, top - 10 accuracy is much higher than the top - 1 accuracy.', 'in section 4. 4, we explore 7 we experimented with mert and pro as well but saw consistently better baseline performance using batch mira.', '8 described in section 3. 2.', 'we retrain with all training data for mt experiments.', '9  #TAUTHOR_TAG gathered up to six translations for each source word, so some have multiple correct translations appending the top - k translations for oov words to our model instead of just the top - 1.', 'table 4 shows our results adding oov translations, adding features, and then both.', '']",4
"['', '5 the  #TAUTHOR_TAG also induce translations for source language words which are low frequency in the training data and supplement our smt models with top - k translations, not just the highest']","['mt models.', 'then, in additional sets of experiments, we 4 giza + + intersection alignments over all training data.', '5 the  #TAUTHOR_TAG also induce translations for source language words which are low frequency in the training data and supplement our smt models with top - k translations, not just the highest']","['mt models.', 'then, in additional sets of experiments, we 4 giza + + intersection alignments over all training data.', '5 the  #TAUTHOR_TAG also induce translations for source language words which are low frequency in the training data and supplement our smt models with top - k translations, not just the highest ranked']","['', 'adding these translations by definition improves the coverage of our mt models.', 'then, in additional sets of experiments, we 4 giza + + intersection alignments over all training data.', '5 the  #TAUTHOR_TAG also induce translations for source language words which are low frequency in the training data and supplement our smt models with top - k translations, not just the highest ranked']",6
"['', '9  #TAUTHOR_TAG gathered up to six translations for']","['mt experiments.', '9  #TAUTHOR_TAG gathered up to six translations for']","['mt experiments.', '9  #TAUTHOR_TAG gathered up to six translations for each source word, so some have multiple correct translations appending the top - k translations']","['', '9 performance is lowest for tamil and highest for hindi.', 'for all languages, top - 10 accuracy is much higher than the top - 1 accuracy.', 'in section 4. 4, we explore 7 we experimented with mert and pro as well but saw consistently better baseline performance using batch mira.', '8 described in section 3. 2.', 'we retrain with all training data for mt experiments.', '9  #TAUTHOR_TAG gathered up to six translations for each source word, so some have multiple correct translations appending the top - k translations for oov words to our model instead of just the top - 1.', 'table 4 shows our results adding oov translations, adding features, and then both.', '']",6
"[' #TAUTHOR_TAG and, following that']","[' #TAUTHOR_TAG and, following that work, include the dictionaries in the training']","[' #TAUTHOR_TAG and, following that']","['use the data splits given by  #TAUTHOR_TAG and, following that work, include the dictionaries in the training data and report results on the devtest set using case - insensitive bleu and four references.', 'we use the moses phrase - based mt framework  #AUTHOR_TAG.', 'for each language, we extract a phrase table with a phrase limit of seven.', 'in order to make our results comparable to those of  #TAUTHOR_TAG, we follow that work and use table 3 : percent of word types in a held out portion of the training data which are translated correctly by our bilingual lexicon induction technique.', '']",3
"[' #TAUTHOR_TAG and, following that']","[' #TAUTHOR_TAG and, following that work, include the dictionaries in the training']","[' #TAUTHOR_TAG and, following that']","['use the data splits given by  #TAUTHOR_TAG and, following that work, include the dictionaries in the training data and report results on the devtest set using case - insensitive bleu and four references.', 'we use the moses phrase - based mt framework  #AUTHOR_TAG.', 'for each language, we extract a phrase table with a phrase limit of seven.', 'in order to make our results comparable to those of  #TAUTHOR_TAG, we follow that work and use table 3 : percent of word types in a held out portion of the training data which are translated correctly by our bilingual lexicon induction technique.', '']",3
"[' #TAUTHOR_TAG showed, it is']","[' #TAUTHOR_TAG showed, it is']","[' #TAUTHOR_TAG showed, it is']","[' #TAUTHOR_TAG showed, it is reasonable to assume a small parallel corpus for training an smt model even in a low resource setting.', 'we have used comparable corpora to improve the accuracy and coverage of phrase - based mt models built using small bilingual corpora for six low resource languages.', 'we have shown that our methods improve bleu score performance independently and that their combined impact is nearly additive.', 'additionally, our results show that adding induced translations of low frequency words improves performance beyond what is achieved by inducing translations for oovs alone.', 'finally, our results show that our techniques improve relative performance most when very little parallel training data is available']",3
"[' #TAUTHOR_TAG and, following that']","[' #TAUTHOR_TAG and, following that work, include the dictionaries in the training']","[' #TAUTHOR_TAG and, following that']","['use the data splits given by  #TAUTHOR_TAG and, following that work, include the dictionaries in the training data and report results on the devtest set using case - insensitive bleu and four references.', 'we use the moses phrase - based mt framework  #AUTHOR_TAG.', 'for each language, we extract a phrase table with a phrase limit of seven.', 'in order to make our results comparable to those of  #TAUTHOR_TAG, we follow that work and use table 3 : percent of word types in a held out portion of the training data which are translated correctly by our bilingual lexicon induction technique.', '']",5
"[' #TAUTHOR_TAG and, following that']","[' #TAUTHOR_TAG and, following that work, include the dictionaries in the training']","[' #TAUTHOR_TAG and, following that']","['use the data splits given by  #TAUTHOR_TAG and, following that work, include the dictionaries in the training data and report results on the devtest set using case - insensitive bleu and four references.', 'we use the moses phrase - based mt framework  #AUTHOR_TAG.', 'for each language, we extract a phrase table with a phrase limit of seven.', 'in order to make our results comparable to those of  #TAUTHOR_TAG, we follow that work and use table 3 : percent of word types in a held out portion of the training data which are translated correctly by our bilingual lexicon induction technique.', '']",5
['released by  #TAUTHOR_TAG'],['released by  #TAUTHOR_TAG'],"['improving the accuracy and coverage of models trained on small amounts of bitext using the full parallel training corpora released by  #TAUTHOR_TAG.', 'here, we apply the same techniques but vary the amount of parallel data in']","['the experiments above, we only evaluated our methods for improving the accuracy and coverage of models trained on small amounts of bitext using the full parallel training corpora released by  #TAUTHOR_TAG.', 'here, we apply the same techniques but vary the amount of parallel data in order to generate learning curves.', 'figure 2 shows learning cures for all six languages.', 'in all cases, results are averaged over three tuning runs.', 'we sample both parallel sentences and dictionary entries.', 'all six learning curves show similar trends.', '']",5
"['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder - decoder architecture, namely listen, attend, and spell ( las ), achieves a new stateof - the - art wer', 'on a 12500 hour english voice search task using the word piece models ( wpm ) [ 10 ]. our previous work  #TAUTHOR_TAG demonstrates that the lexicon independent models can outperform lexicon dependent models on mandarin chinese asr', 'tasks by the asr transformer and the character based model establishes a new state - of - the - art character error rate ( cer ) on hkust datasets. since the acoustic, pronunciation and language model are integrated into a single neural network by sequence - to - sequence', 'attention - based models, it makes them very suitable for multilingual asr. in this paper, we concentrate on multil', '##ingual asr on low - resource languages. building on our work  #TAUTHOR_TAG, we employ sub - words generated by byte pair encoding ( bpe ) [ 11 ] as the multilingual modeling unit, which do not need any pron', '##unciation lexicon. the asr transformer is chosen to be the basic architecture of sequence - to - sequence attention - based model  #TAUTHOR_TAG 12 ]', '. to alleviate the problem of few training data on low - resource languages, a well - trained asr transformer from a', 'high - resource language is adopted as the initial model rather than random initialization, whose softmax layer is replaced by the language - specific softmax layer.', 'we then look at incorporating language information into the model by inserting the language symbol at the beginning or at the end of the original sub - words sequence [ 13 ] under the condition of language information being known during training. a comparison with shl - mlstm [ 5 ] with residual learning is investigated', 'on call - home datasets with 6 languages. experimental results reveal that the multilingual asr transformer with the language symbol at the end performs better and can obtain relatively 10. 5 % average wer reduction compared to shl - mlstm with residual learning. we go on', 'to show that, assuming the language information being known during training and testing, about relatively 12. 4 % average wer reduction can be observed compared to shl - mlstm with residual learning through giving', 'the language symbol as the sentence start token. the rest of the paper is organized as', 'follows. after an overview of the related work in section 2, section 3 describes the proposed method in detail. we then show experimental results in section 4 and conclude this work in section 5']",0
"['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder - decoder architecture, namely listen, attend, and spell ( las ), achieves a new stateof - the - art wer', 'on a 12500 hour english voice search task using the word piece models ( wpm ) [ 10 ]. our previous work  #TAUTHOR_TAG demonstrates that the lexicon independent models can outperform lexicon dependent models on mandarin chinese asr', 'tasks by the asr transformer and the character based model establishes a new state - of - the - art character error rate ( cer ) on hkust datasets. since the acoustic, pronunciation and language model are integrated into a single neural network by sequence - to - sequence', 'attention - based models, it makes them very suitable for multilingual asr. in this paper, we concentrate on multil', '##ingual asr on low - resource languages. building on our work  #TAUTHOR_TAG, we employ sub - words generated by byte pair encoding ( bpe ) [ 11 ] as the multilingual modeling unit, which do not need any pron', '##unciation lexicon. the asr transformer is chosen to be the basic architecture of sequence - to - sequence attention - based model  #TAUTHOR_TAG 12 ]', '. to alleviate the problem of few training data on low - resource languages, a well - trained asr transformer from a', 'high - resource language is adopted as the initial model rather than random initialization, whose softmax layer is replaced by the language - specific softmax layer.', 'we then look at incorporating language information into the model by inserting the language symbol at the beginning or at the end of the original sub - words sequence [ 13 ] under the condition of language information being known during training. a comparison with shl - mlstm [ 5 ] with residual learning is investigated', 'on call - home datasets with 6 languages. experimental results reveal that the multilingual asr transformer with the language symbol at the end performs better and can obtain relatively 10. 5 % average wer reduction compared to shl - mlstm with residual learning. we go on', 'to show that, assuming the language information being known during training and testing, about relatively 12. 4 % average wer reduction can be observed compared to shl - mlstm with residual learning through giving', 'the language symbol as the sentence start token. the rest of the paper is organized as', 'follows. after an overview of the related work in section 2, section 3 describes the proposed method in detail. we then show experimental results in section 4 and conclude this work in section 5']",0
['training the asr transformer  #TAUTHOR_TAG'],['training the asr transformer  #TAUTHOR_TAG'],"['22 ], since it is', 'always beneficial for training the asr transformer  #TAUTHOR_TAG']","['corresponding to a language. for example, we add the symbol < s en > into the symbol vocabulary when including english. if the language information of training data can only', 'be known beforehand, two methods of adding the language symbol are explored, i. e.', ""inserting at the beginning ( transformer - b ) or at the end ( transformer - e ) of the original sub - words sequence [ 13, 18 ]. what's more, if the language information of both training and testing data can be known beforehand, we directly take the language symbol <"", 's lang > as the sentence start token ( transformer - b2 ) rather than original sentence start token < s >. it can force the multilingual asr transformer to decode a speech utterance into the pointed language, which is able to alleviate the language confusion greatly during testing. the difference between transformer - b and transformer - b2 is whether to utilize the language information during testing. the sentence start token is < s', '> in transformer - b. it first predicts a language symbol by itself and then the following tokens are predicted', 'as usual. therefore, transformer - b do not need to know the language information beforehand during testing. in contrast, transformer - b2 employs < s', 'lang > as its sentence start token and predicts the following tokens as usual, which need to', 'know the language information beforehand during testing. an example of adding the language symbol is shown in table 1. the datasets in the paper come from callhome corpora collected by linguistic data consortium', '( ldc ). the following six languages are used : mand', '##arin ( ma ), english ( en ), japanese ( ja ), arabic ( ar ),', 'german ( ge ) and spanish ( sp ). we follow the kaldi [ 19 ] recipe to process callhome datasets 2. the detailed information is listed below in table 2. we', 'train the asr transformer with a given number of epochs, so validation sets are not', 'employed in this paper. all experiments are conducted using', '80 - dimensional log - mel filterbank features, computed with a 25ms window and shifted every 10ms. the', 'features are normalized via mean subtraction and variance normalization on the speaker basis. similar to [ 20, 21 ], at the current frame t', ', these features are stacked with 3 frames to the left and downsampled', 'to a 30ms frame rate. we generate more training data by linearly scaling the audio lengths by factors of 0. 9 and 1. 1 [ 22 ], since it is', 'always beneficial for training the asr transformer  #TAUTHOR_TAG']",0
"['##1024 - h16 )  #TAUTHOR_TAG 17 ] of the asr transformer.', 'table 3 lists our experimental parameters.', 'the adam algorithm']","['our experiments on the big model ( d1024 - h16 )  #TAUTHOR_TAG 17 ] of the asr transformer.', 'table 3 lists our experimental parameters.', 'the adam algorithm [ 23 ] with gradient clipping and warmup is used for optimization.', 'during training, label smoothing of value ls = 0. 1 is employed [ 24 ].', 'after trained,']","['##1024 - h16 )  #TAUTHOR_TAG 17 ] of the asr transformer.', 'table 3 lists our experimental parameters.', 'the adam algorithm [ 23 ] with gradient clipping and warmup is used for optimization.', 'during training, label smoothing of value ls = 0. 1 is employed']","['perform our experiments on the big model ( d1024 - h16 )  #TAUTHOR_TAG 17 ] of the asr transformer.', 'table 3 lists our experimental parameters.', 'the adam algorithm [ 23 ] with gradient clipping and warmup is used for optimization.', 'during training, label smoothing of value ls = 0. 1 is employed [ 24 ].', 'after trained, the last 20 checkpoints are averaged to make the performance more stable [ 17 ].', 'at the beginning we train the asr transformer on english data with a random initialization, but the result is poor although the ce loss looks good.', 'we propose that one reason for the poor performance could be the training data is too few but the parameters of the asr transformer are relatively large which is about 230m in this work.', 'to compensate the lack of training data on low - resource languages, a well - trained asr transformer with a cer of 26. 64 % on hkust dataset, a corpus of mandarin chinese conversational telephone speech, is adopted from our work  #TAUTHOR_TAG.', 'its softmax layer is replaced by the language - specific softmax layer which is initialized randomly.', 'through this initialization method, the asr transformer can converge very well.', 'all experiments in this paper are conducted by this initialization method']",0
"['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder - decoder architecture, namely listen, attend, and spell ( las ), achieves a new stateof - the - art wer', 'on a 12500 hour english voice search task using the word piece models ( wpm ) [ 10 ]. our previous work  #TAUTHOR_TAG demonstrates that the lexicon independent models can outperform lexicon dependent models on mandarin chinese asr', 'tasks by the asr transformer and the character based model establishes a new state - of - the - art character error rate ( cer ) on hkust datasets. since the acoustic, pronunciation and language model are integrated into a single neural network by sequence - to - sequence', 'attention - based models, it makes them very suitable for multilingual asr. in this paper, we concentrate on multil', '##ingual asr on low - resource languages. building on our work  #TAUTHOR_TAG, we employ sub - words generated by byte pair encoding ( bpe ) [ 11 ] as the multilingual modeling unit, which do not need any pron', '##unciation lexicon. the asr transformer is chosen to be the basic architecture of sequence - to - sequence attention - based model  #TAUTHOR_TAG 12 ]', '. to alleviate the problem of few training data on low - resource languages, a well - trained asr transformer from a', 'high - resource language is adopted as the initial model rather than random initialization, whose softmax layer is replaced by the language - specific softmax layer.', 'we then look at incorporating language information into the model by inserting the language symbol at the beginning or at the end of the original sub - words sequence [ 13 ] under the condition of language information being known during training. a comparison with shl - mlstm [ 5 ] with residual learning is investigated', 'on call - home datasets with 6 languages. experimental results reveal that the multilingual asr transformer with the language symbol at the end performs better and can obtain relatively 10. 5 % average wer reduction compared to shl - mlstm with residual learning. we go on', 'to show that, assuming the language information being known during training and testing, about relatively 12. 4 % average wer reduction can be observed compared to shl - mlstm with residual learning through giving', 'the language symbol as the sentence start token. the rest of the paper is organized as', 'follows. after an overview of the related work in section 2, section 3 describes the proposed method in detail. we then show experimental results in section 4 and conclude this work in section 5']",4
"['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder - decoder architecture, namely listen, attend, and spell ( las ), achieves a new stateof - the - art wer', 'on a 12500 hour english voice search task using the word piece models ( wpm ) [ 10 ]. our previous work  #TAUTHOR_TAG demonstrates that the lexicon independent models can outperform lexicon dependent models on mandarin chinese asr', 'tasks by the asr transformer and the character based model establishes a new state - of - the - art character error rate ( cer ) on hkust datasets. since the acoustic, pronunciation and language model are integrated into a single neural network by sequence - to - sequence', 'attention - based models, it makes them very suitable for multilingual asr. in this paper, we concentrate on multil', '##ingual asr on low - resource languages. building on our work  #TAUTHOR_TAG, we employ sub - words generated by byte pair encoding ( bpe ) [ 11 ] as the multilingual modeling unit, which do not need any pron', '##unciation lexicon. the asr transformer is chosen to be the basic architecture of sequence - to - sequence attention - based model  #TAUTHOR_TAG 12 ]', '. to alleviate the problem of few training data on low - resource languages, a well - trained asr transformer from a', 'high - resource language is adopted as the initial model rather than random initialization, whose softmax layer is replaced by the language - specific softmax layer.', 'we then look at incorporating language information into the model by inserting the language symbol at the beginning or at the end of the original sub - words sequence [ 13 ] under the condition of language information being known during training. a comparison with shl - mlstm [ 5 ] with residual learning is investigated', 'on call - home datasets with 6 languages. experimental results reveal that the multilingual asr transformer with the language symbol at the end performs better and can obtain relatively 10. 5 % average wer reduction compared to shl - mlstm with residual learning. we go on', 'to show that, assuming the language information being known during training and testing, about relatively 12. 4 % average wer reduction can be observed compared to shl - mlstm with residual learning through giving', 'the language symbol as the sentence start token. the rest of the paper is organized as', 'follows. after an overview of the related work in section 2, section 3 describes the proposed method in detail. we then show experimental results in section 4 and conclude this work in section 5']",4
"['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder - decoder architecture, namely listen, attend, and spell ( las ), achieves a new stateof - the - art wer', 'on a 12500 hour english voice search task using the word piece models ( wpm ) [ 10 ]. our previous work  #TAUTHOR_TAG demonstrates that the lexicon independent models can outperform lexicon dependent models on mandarin chinese asr', 'tasks by the asr transformer and the character based model establishes a new state - of - the - art character error rate ( cer ) on hkust datasets. since the acoustic, pronunciation and language model are integrated into a single neural network by sequence - to - sequence', 'attention - based models, it makes them very suitable for multilingual asr. in this paper, we concentrate on multil', '##ingual asr on low - resource languages. building on our work  #TAUTHOR_TAG, we employ sub - words generated by byte pair encoding ( bpe ) [ 11 ] as the multilingual modeling unit, which do not need any pron', '##unciation lexicon. the asr transformer is chosen to be the basic architecture of sequence - to - sequence attention - based model  #TAUTHOR_TAG 12 ]', '. to alleviate the problem of few training data on low - resource languages, a well - trained asr transformer from a', 'high - resource language is adopted as the initial model rather than random initialization, whose softmax layer is replaced by the language - specific softmax layer.', 'we then look at incorporating language information into the model by inserting the language symbol at the beginning or at the end of the original sub - words sequence [ 13 ] under the condition of language information being known during training. a comparison with shl - mlstm [ 5 ] with residual learning is investigated', 'on call - home datasets with 6 languages. experimental results reveal that the multilingual asr transformer with the language symbol at the end performs better and can obtain relatively 10. 5 % average wer reduction compared to shl - mlstm with residual learning. we go on', 'to show that, assuming the language information being known during training and testing, about relatively 12. 4 % average wer reduction can be observed compared to shl - mlstm with residual learning through giving', 'the language symbol as the sentence start token. the rest of the paper is organized as', 'follows. after an overview of the related work in section 2, section 3 describes the proposed method in detail. we then show experimental results in section 4 and conclude this work in section 5']",6
"['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder']","['to remove this dependency on the pronunciation lexicon [ 8,  #TAUTHOR_TAG 10 ]. chiu et al', '. shows that attention - based encoder - decoder architecture, namely listen, attend, and spell ( las ), achieves a new stateof - the - art wer', 'on a 12500 hour english voice search task using the word piece models ( wpm ) [ 10 ]. our previous work  #TAUTHOR_TAG demonstrates that the lexicon independent models can outperform lexicon dependent models on mandarin chinese asr', 'tasks by the asr transformer and the character based model establishes a new state - of - the - art character error rate ( cer ) on hkust datasets. since the acoustic, pronunciation and language model are integrated into a single neural network by sequence - to - sequence', 'attention - based models, it makes them very suitable for multilingual asr. in this paper, we concentrate on multil', '##ingual asr on low - resource languages. building on our work  #TAUTHOR_TAG, we employ sub - words generated by byte pair encoding ( bpe ) [ 11 ] as the multilingual modeling unit, which do not need any pron', '##unciation lexicon. the asr transformer is chosen to be the basic architecture of sequence - to - sequence attention - based model  #TAUTHOR_TAG 12 ]', '. to alleviate the problem of few training data on low - resource languages, a well - trained asr transformer from a', 'high - resource language is adopted as the initial model rather than random initialization, whose softmax layer is replaced by the language - specific softmax layer.', 'we then look at incorporating language information into the model by inserting the language symbol at the beginning or at the end of the original sub - words sequence [ 13 ] under the condition of language information being known during training. a comparison with shl - mlstm [ 5 ] with residual learning is investigated', 'on call - home datasets with 6 languages. experimental results reveal that the multilingual asr transformer with the language symbol at the end performs better and can obtain relatively 10. 5 % average wer reduction compared to shl - mlstm with residual learning. we go on', 'to show that, assuming the language information being known during training and testing, about relatively 12. 4 % average wer reduction can be observed compared to shl - mlstm with residual learning through giving', 'the language symbol as the sentence start token. the rest of the paper is organized as', 'follows. after an overview of the related work in section 2, section 3 describes the proposed method in detail. we then show experimental results in section 4 and conclude this work in section 5']",6
[' #TAUTHOR_TAG 12 ] which is shown in'],[' #TAUTHOR_TAG 12 ] which is shown in'],['as our work  #TAUTHOR_TAG 12 ] which is shown in figure 1'],"['asr transformer architecture used in this work is the same as our work  #TAUTHOR_TAG 12 ] which is shown in figure 1.', 'it stacks multihead attention ( mha ) [ 17 ] and position - wise, fully connected layers for both the encode and decoder.', 'the encoder is composed of a stack of n identical layers.', '']",3
[' #TAUTHOR_TAG 12 ] which is shown in'],[' #TAUTHOR_TAG 12 ] which is shown in'],['as our work  #TAUTHOR_TAG 12 ] which is shown in figure 1'],"['asr transformer architecture used in this work is the same as our work  #TAUTHOR_TAG 12 ] which is shown in figure 1.', 'it stacks multihead attention ( mha ) [ 17 ] and position - wise, fully connected layers for both the encode and decoder.', 'the encoder is composed of a stack of n identical layers.', '']",5
"['##1024 - h16 )  #TAUTHOR_TAG 17 ] of the asr transformer.', 'table 3 lists our experimental parameters.', 'the adam algorithm']","['our experiments on the big model ( d1024 - h16 )  #TAUTHOR_TAG 17 ] of the asr transformer.', 'table 3 lists our experimental parameters.', 'the adam algorithm [ 23 ] with gradient clipping and warmup is used for optimization.', 'during training, label smoothing of value ls = 0. 1 is employed [ 24 ].', 'after trained,']","['##1024 - h16 )  #TAUTHOR_TAG 17 ] of the asr transformer.', 'table 3 lists our experimental parameters.', 'the adam algorithm [ 23 ] with gradient clipping and warmup is used for optimization.', 'during training, label smoothing of value ls = 0. 1 is employed']","['perform our experiments on the big model ( d1024 - h16 )  #TAUTHOR_TAG 17 ] of the asr transformer.', 'table 3 lists our experimental parameters.', 'the adam algorithm [ 23 ] with gradient clipping and warmup is used for optimization.', 'during training, label smoothing of value ls = 0. 1 is employed [ 24 ].', 'after trained, the last 20 checkpoints are averaged to make the performance more stable [ 17 ].', 'at the beginning we train the asr transformer on english data with a random initialization, but the result is poor although the ce loss looks good.', 'we propose that one reason for the poor performance could be the training data is too few but the parameters of the asr transformer are relatively large which is about 230m in this work.', 'to compensate the lack of training data on low - resource languages, a well - trained asr transformer with a cer of 26. 64 % on hkust dataset, a corpus of mandarin chinese conversational telephone speech, is adopted from our work  #TAUTHOR_TAG.', 'its softmax layer is replaced by the language - specific softmax layer which is initialized randomly.', 'through this initialization method, the asr transformer can converge very well.', 'all experiments in this paper are conducted by this initialization method']",5
"['recently by  #TAUTHOR_TAG in a study using latent semantic analysis ( latent semantic indexing, deerwester']","['recently by  #TAUTHOR_TAG in a study using latent semantic analysis ( latent semantic indexing, deerwester et al. 1990 ) to extract a semantic space']","['recently by  #TAUTHOR_TAG in a study using latent semantic analysis ( latent semantic indexing, deerwester et']","['for a solution to problems encountered when sentences belonging to a unique topic do not share common words due to the use of hyperonyms or syn', '##onyms and allow words that are semantically related to be taken as positive evidence for topic continuity. empirical arguments in favor of these methods have been provided recently by  #TAUTHOR_TAG in a study using latent semantic analysis ( latent semantic indexing, deerwester et al. 1990 ) to extract a semantic space from a corpus allowing determination of the similarity of meanings of words, sentences, or paragraphs. by comparing the accuracy of the very same algorithm according to whether or not it takes into account complementary semantic knowledge,  #TAUTHOR_TAG were able to show the benefit derived from such knowledge. however, implications of  #TAUTHOR_TAG for text segmentation and for the use of lsa in natural language processing are unclear due to the methodology employed. in  #TAUTHOR_TAG, semantic knowledge was acquired from a corpus containing the materials to be segmented in the test phase. one could speculate whether the largest', '']",5
"[' #TAUTHOR_TAG, was built using']","[' #TAUTHOR_TAG, was built using']","[' #TAUTHOR_TAG, was built using the entire brown corpus as the lsa corpus.', 'four hundred different without spaces were built, one for each test sample, by each time removing from']","['experiment was based on the procedure and test materials designed by  #AUTHOR_TAG, which was also used by several authors as a benchmark for comparing segmentation systems ( brants et al. 2002 ; ferret 2002 ; kehagias et al. 2003 ; utiyama and isahara 2001 ).', 'the task consists in finding the boundaries between concatenated texts.', 'each test sample is a concatenation of ten text segments.', 'each segment consisted in the first n sentences of a randomly selected text from two sub - sections of the brown corpus.', 'for the present experiment, i used the most general test materials built by  #AUTHOR_TAG, in which the size of the segments within each sample varies randomly from 3 to 11 sentences.', 'it is composed of 400 samples.', 'the analysis related to the comparison between the accuracy of the algorithm when the test materials were included in the lsa corpus ( within ) and when it was not ( without ).', 'one within semantic space, which corresponds to the one used by  #TAUTHOR_TAG, was built using the entire brown corpus as the lsa corpus.', 'four hundred different without spaces were built, one for each test sample, by each time removing from the brown corpus only the sentences that make this sample.', 'to extract the lsa space and to apply the segmentation algorithm, a series of parameters had to be set.', 'first of all, paragraphs were used as documents for building the lexical tables because  #TAUTHOR_TAG observed that such middle - sized units were more effective than shorter units ( i. e., sentences ).', ""the words on choi's stoplist were removed, as were those that appeared only once in the whole corpus."", 'words were not stemmed, as in  #TAUTHOR_TAG.', 'to build the lsa space, the singular value decomposition was realized using the program svdpackc ( berry 1992 ; berry et al. 1993 ), and the first 300 singular vectors were retained.', 'concerning the segmentation algorithm, i used the version in which the number of boundaries to be found is imposed, and thus fixed at nine.', 'an 11 × 11 rank mask was used for the ordinal transformation, as recommended by  #AUTHOR_TAG']",5
"[' #TAUTHOR_TAG, was built using']","[' #TAUTHOR_TAG, was built using']","[' #TAUTHOR_TAG, was built using the entire brown corpus as the lsa corpus.', 'four hundred different without spaces were built, one for each test sample, by each time removing from']","['experiment was based on the procedure and test materials designed by  #AUTHOR_TAG, which was also used by several authors as a benchmark for comparing segmentation systems ( brants et al. 2002 ; ferret 2002 ; kehagias et al. 2003 ; utiyama and isahara 2001 ).', 'the task consists in finding the boundaries between concatenated texts.', 'each test sample is a concatenation of ten text segments.', 'each segment consisted in the first n sentences of a randomly selected text from two sub - sections of the brown corpus.', 'for the present experiment, i used the most general test materials built by  #AUTHOR_TAG, in which the size of the segments within each sample varies randomly from 3 to 11 sentences.', 'it is composed of 400 samples.', 'the analysis related to the comparison between the accuracy of the algorithm when the test materials were included in the lsa corpus ( within ) and when it was not ( without ).', 'one within semantic space, which corresponds to the one used by  #TAUTHOR_TAG, was built using the entire brown corpus as the lsa corpus.', 'four hundred different without spaces were built, one for each test sample, by each time removing from the brown corpus only the sentences that make this sample.', 'to extract the lsa space and to apply the segmentation algorithm, a series of parameters had to be set.', 'first of all, paragraphs were used as documents for building the lexical tables because  #TAUTHOR_TAG observed that such middle - sized units were more effective than shorter units ( i. e., sentences ).', ""the words on choi's stoplist were removed, as were those that appeared only once in the whole corpus."", 'words were not stemmed, as in  #TAUTHOR_TAG.', 'to build the lsa space, the singular value decomposition was realized using the program svdpackc ( berry 1992 ; berry et al. 1993 ), and the first 300 singular vectors were retained.', 'concerning the segmentation algorithm, i used the version in which the number of boundaries to be found is imposed, and thus fixed at nine.', 'an 11 × 11 rank mask was used for the ordinal transformation, as recommended by  #AUTHOR_TAG']",5
"[' #TAUTHOR_TAG : the pk measure of segmentation inaccuracy ( beeferman, berger, and laf']","[' #TAUTHOR_TAG : the pk measure of segmentation inaccuracy ( beeferman, berger, and lafferty 1999 ),']","[' #TAUTHOR_TAG : the pk measure of segmentation inaccuracy ( beeferman, berger, and laf']","['segmentation accuracy was evaluated by means of the index reported by  #TAUTHOR_TAG : the pk measure of segmentation inaccuracy ( beeferman, berger, and lafferty 1999 ), which gives the proportion of sentences that are wrongly predicted to belong to the same segment or wrongly predicted to belong to different segments.', 'i also report, for potential future comparison,  #AUTHOR_TAG windowdiff index, which remedies several problems in the pk measure.', 'results are provided in table 1.', '1 compared with the within condition, the performance in the without condition is definitely worse, as confirmed by t tests for paired sample ( each test sample being used as an observation ) that are significant for an alpha smaller than 0. 0001.', 'the c99 algorithm, which does not employ lsa to estimate the similarities between the sentences, produces a pk of 0. 13  #TAUTHOR_TAG, table 3, line 3 : no stemming ).', 'it appears that although the without condition is still better than c99, the benefit is very small.', 'before concluding that the presence of the test materials in the lsa corpus strongly modified the semantic space, an alternative explanation must be considered.', '']",5
"[' #TAUTHOR_TAG : the pk measure of segmentation inaccuracy ( beeferman, berger, and laf']","[' #TAUTHOR_TAG : the pk measure of segmentation inaccuracy ( beeferman, berger, and lafferty 1999 ),']","[' #TAUTHOR_TAG : the pk measure of segmentation inaccuracy ( beeferman, berger, and laf']","['segmentation accuracy was evaluated by means of the index reported by  #TAUTHOR_TAG : the pk measure of segmentation inaccuracy ( beeferman, berger, and lafferty 1999 ), which gives the proportion of sentences that are wrongly predicted to belong to the same segment or wrongly predicted to belong to different segments.', 'i also report, for potential future comparison,  #AUTHOR_TAG windowdiff index, which remedies several problems in the pk measure.', 'results are provided in table 1.', '1 compared with the within condition, the performance in the without condition is definitely worse, as confirmed by t tests for paired sample ( each test sample being used as an observation ) that are significant for an alpha smaller than 0. 0001.', 'the c99 algorithm, which does not employ lsa to estimate the similarities between the sentences, produces a pk of 0. 13  #TAUTHOR_TAG, table 3, line 3 : no stemming ).', 'it appears that although the without condition is still better than c99, the benefit is very small.', 'before concluding that the presence of the test materials in the lsa corpus strongly modified the semantic space, an alternative explanation must be considered.', '']",5
"['1 was conducted on the  #TAUTHOR_TAG lsa corpus, a 1, 000,']","['1 was conducted on the  #TAUTHOR_TAG lsa corpus, a 1, 000, 000 - word collection of texts from very different genres and with varied themes.', 'the smallness of the corpus and diversity of the texts']","['1 was conducted on the  #TAUTHOR_TAG lsa corpus, a 1, 000, 000 - word collection of texts from very different genres and with varied themes.', 'the smallness of the corpus and diversity of the texts']","['1 was conducted on the  #TAUTHOR_TAG lsa corpus, a 1, 000, 000 - word collection of texts from very different genres and with varied themes.', 'the smallness of the corpus and diversity of the texts could have affected the results at two levels.', 'first, removing a few sentences of a text should have less impact if the corpus contains a lot of texts on similar topics.', 'second, a larger corpus would probably also permit the extraction of a more stable and efficient semantic space.', 'this could produce a greater difference between the lsa version of the algorithm and the version that does not use additional semantic knowledge ( c99 ).', 'for these reasons, a second experiment was conducted on the basis of a much larger corpus consisting of the articles published during 1997 and 1998 in the belgian french - speaking newspaper le soir ( roughly 52, 000 articles and 26, 000, 000 words ).', 'in this corpus, the test materials from each sample account for - on average - 0. 0066 % of the complete corpus.', 'this second experiment also made it possible to compare the within and without spaces with a former space composed of articles published in the same newspaper, but during the years 1995 and 1996 ( roughly 50, 000 articles and more than 22, 000, 000 words ).', 'this condition will show the possibility of using lsa to build even more generic semantic knowledge, since the lsa corpus is earlier than the text to segment']",5
"['', 'recently,  #TAUTHOR_TAG have showed that fast and accurate']","['', 'recently,  #TAUTHOR_TAG have showed that fast and accurate']","['', 'recently,  #TAUTHOR_TAG have showed that fast and accurate']","['- reduce parsing is interesting for practical realworld applications like parsing the web, since parsing can be achieved in linear time.', 'although greedy parsers are fast, accuracies of these parsers are typically much lower than graph - based parsers.', 'conversely, beam - search parsers achieve accuracies comparable to graph - based parsers  #AUTHOR_TAG but are much slower than their greedy counterparts.', 'recently,  #TAUTHOR_TAG have showed that fast and accurate parsing can be achieved using neural network based parsers.', 'improving their work, presented a structured neural network model which gave stateof - the - art results for english dependency parsing.', 'there has been increasing interest in combinatory categorial grammar ( ccg )  #AUTHOR_TAG parsing due to the simplicity of its interface between syntax and semantics.', 'in addition to predicateargument structure, ccg captures the unbounded dependencies found in grammatical constructions like relativization, coordination, etc.', 'we present a neural network based shift - reduce ccg parser, the first neural network based parser for ccg.', ""we first adapt  #TAUTHOR_TAG's shift - reduce dependency parser for ccg parsing."", 'we then develop a structured neural network model based on, in order to explore the impact of a beamsearch on the parser.', 'we also analyze the impact of neural network taggers ( for both pos - tagging and ccg supertagging ) as compared to maximum entropy taggers.', '']",0
"['constituent based parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG developed a neural']","['constituent based parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG developed a neural']","['constituent based parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG developed a neural network architecture for dependency parsing.', 'this parser was fast and accurate, parsing']","['network parsers are attracting interest for both speed and accuracy.', 'there has been some work on neural networks for constituent based parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG developed a neural network architecture for dependency parsing.', 'this parser was fast and accurate, parsing around 1000 sentences per second and achieving an unlabeled attachment score of 92. 0 % on the standard penn treebank test data for english.', "" #TAUTHOR_TAG's parser used a feed forward neural network."", 'several improvements were made to this architecture in terms of using long short - term memory ( lstm ) networks  #AUTHOR_TAG, deep neural networks and structured neural networks  #AUTHOR_TAG']",0
"['constituent based parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG developed a neural']","['constituent based parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG developed a neural']","['constituent based parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG developed a neural network architecture for dependency parsing.', 'this parser was fast and accurate, parsing']","['network parsers are attracting interest for both speed and accuracy.', 'there has been some work on neural networks for constituent based parsing  #AUTHOR_TAG.', ' #TAUTHOR_TAG developed a neural network architecture for dependency parsing.', 'this parser was fast and accurate, parsing around 1000 sentences per second and achieving an unlabeled attachment score of 92. 0 % on the standard penn treebank test data for english.', "" #TAUTHOR_TAG's parser used a feed forward neural network."", 'several improvements were made to this architecture in terms of using long short - term memory ( lstm ) networks  #AUTHOR_TAG, deep neural networks and structured neural networks  #AUTHOR_TAG']",0
"[""' s parser is a greedy parser and it is not straight forward to add a beam during training into their parser."", 'as a way of introducing a beam, presented a structured percept']","[""' s parser is a greedy parser and it is not straight forward to add a beam during training into their parser."", 'as a way of introducing a beam, presented a structured perceptron training for the neural']","[""' s parser is a greedy parser and it is not straight forward to add a beam during training into their parser."", 'as a way of introducing a beam, presented a structured perceptron training for the neural network parser.', 'they first pre - trained']","[""' s parser is a greedy parser and it is not straight forward to add a beam during training into their parser."", 'as a way of introducing a beam, presented a structured perceptron training for the neural network parser.', 'they first pre - trained their neural network model.', '']",0
"['', 'recently,  #TAUTHOR_TAG have showed that fast and accurate']","['', 'recently,  #TAUTHOR_TAG have showed that fast and accurate']","['', 'recently,  #TAUTHOR_TAG have showed that fast and accurate']","['- reduce parsing is interesting for practical realworld applications like parsing the web, since parsing can be achieved in linear time.', 'although greedy parsers are fast, accuracies of these parsers are typically much lower than graph - based parsers.', 'conversely, beam - search parsers achieve accuracies comparable to graph - based parsers  #AUTHOR_TAG but are much slower than their greedy counterparts.', 'recently,  #TAUTHOR_TAG have showed that fast and accurate parsing can be achieved using neural network based parsers.', 'improving their work, presented a structured neural network model which gave stateof - the - art results for english dependency parsing.', 'there has been increasing interest in combinatory categorial grammar ( ccg )  #AUTHOR_TAG parsing due to the simplicity of its interface between syntax and semantics.', 'in addition to predicateargument structure, ccg captures the unbounded dependencies found in grammatical constructions like relativization, coordination, etc.', 'we present a neural network based shift - reduce ccg parser, the first neural network based parser for ccg.', ""we first adapt  #TAUTHOR_TAG's shift - reduce dependency parser for ccg parsing."", 'we then develop a structured neural network model based on, in order to explore the impact of a beamsearch on the parser.', 'we also analyze the impact of neural network taggers ( for both pos - tagging and ccg supertagging ) as compared to maximum entropy taggers.', '']",6
"['of  #TAUTHOR_TAG.', 'we present the details of the network and the model settings in this section.', 'we also discuss our structured neural network model.', 'figure 1 shows the']","['of  #TAUTHOR_TAG.', 'we present the details of the network and the model settings in this section.', 'we also discuss our structured neural network model.', 'figure 1 shows the']","['of  #TAUTHOR_TAG.', 'we present the details of the network and the model settings in this section.', 'we also discuss our structured neural network model.', 'figure 1 shows the architecture of our neural network parser.', 'there are three layers in']","['architecture of our neural network based shift - reduce ccg parser is similar to that of  #TAUTHOR_TAG.', 'we present the details of the network and the model settings in this section.', 'we also discuss our structured neural network model.', 'figure 1 shows the architecture of our neural network parser.', 'there are three layers in the parser : input, hidden and output layers.', 'we first extract discrete features like words, pos - tags and ccg su - ( 2014 ) )']",3
"['.', 'following  #TAUTHOR_TAG, we use a cube activation function and softmax']","['corresponding embeddings and use them in the input layer.', 'following  #TAUTHOR_TAG, we use a cube activation function and softmax']","['corresponding embeddings and use them in the input layer.', 'following  #TAUTHOR_TAG, we use a cube activation function and softmax']","['##ags from the parser configuration.', 'for each of these discrete features we obtain a continuous vector representation in the form of their corresponding embeddings and use them in the input layer.', 'following  #TAUTHOR_TAG, we use a cube activation function and softmax for output layer']",5
"['', 'we use the training settings of  #TAUTHOR_TAG for our parser']","['parser configuration instead of all the actions.', 'we use the training settings of  #TAUTHOR_TAG for our parser.', 'the training objective is to minimize the cross - entropy loss with an l 2 - regularization and the training error derivatives are']","['softmax probabilities only for the actions which are possible in a particular parser configuration instead of all the actions.', 'we use the training settings of  #TAUTHOR_TAG for our parser']","['', 'we use the training settings of  #TAUTHOR_TAG for our parser.', 'the training objective is to minimize the cross - entropy loss with an l 2 - regularization and the training error derivatives are backpropagated during training.', 'for optimization we use adagrad  #AUTHOR_TAG.', '10 −8 and 0. 01 are the values for regularization parameter and adagrad initial learning rate respectively.', 'parameters that give the best labeled f - score on the development data are used for testing data']",5
"[""' s parser is a greedy parser and it is not straight forward to add a beam during training into their parser."", 'as a way of introducing a beam, presented a structured percept']","[""' s parser is a greedy parser and it is not straight forward to add a beam during training into their parser."", 'as a way of introducing a beam, presented a structured perceptron training for the neural']","[""' s parser is a greedy parser and it is not straight forward to add a beam during training into their parser."", 'as a way of introducing a beam, presented a structured perceptron training for the neural network parser.', 'they first pre - trained']","[""' s parser is a greedy parser and it is not straight forward to add a beam during training into their parser."", 'as a way of introducing a beam, presented a structured perceptron training for the neural network parser.', 'they first pre - trained their neural network model.', '']",5
"['neural network parser differs from  #TAUTHOR_TAG in a number of respects.', 'we use ccg supertags in the input']","['neural network parser differs from  #TAUTHOR_TAG in a number of respects.', 'we use ccg supertags in the input']","['neural network parser differs from  #TAUTHOR_TAG in a number of respects.', 'we use ccg supertags in the input layer rather than dependency labels.', 'for word embeddings, we use turian embeddings']","['neural network parser differs from  #TAUTHOR_TAG in a number of respects.', 'we use ccg supertags in the input layer rather than dependency labels.', 'for word embeddings, we use turian embeddings']",4
"['reordering words in a japanese sentence based on concurrent execution with dependency parsing so that the sentence becomes more readable.', 'our contributions are summarized as follows : ( 1 ) we extend a probablistic model used in the  #TAUTHOR_TAG']","['reordering words in a japanese sentence based on concurrent execution with dependency parsing so that the sentence becomes more readable.', 'our contributions are summarized as follows : ( 1 ) we extend a probablistic model used in the  #TAUTHOR_TAG']","['reordering words in a japanese sentence based on concurrent execution with dependency parsing so that the sentence becomes more readable.', 'our contributions are summarized as follows : ( 1 ) we extend a probablistic model used in the  #TAUTHOR_TAG']","['paper proposes a method for reordering words in a japanese sentence based on concurrent execution with dependency parsing so that the sentence becomes more readable.', 'our contributions are summarized as follows : ( 1 ) we extend a probablistic model used in the  #TAUTHOR_TAG']",6
"['word order in newspaper article sentences  #TAUTHOR_TAG.', 'however,']","['word order in newspaper article sentences  #TAUTHOR_TAG.', 'however,']","['proposed method using evaluation data created by randomly changing the word order in newspaper article sentences  #TAUTHOR_TAG.', 'however,']","['', 'to solve the problem, we previously proposed a method for concurrently performing word reordering and dependency parsing and confirmed the effectiveness of their proposed method using evaluation data created by randomly changing the word order in newspaper article sentences  #TAUTHOR_TAG.', 'however, since some of the just automatically created sentences are unlikely to be spontaneously written by a native, the evaluation is thought to be not enough.', 'in addition, the probablistic model has room for improvement in targeting at sentences which a native is likely to spontaneously write.', 'this paper proposes a new method on japanese word reordering based on concurrent execution with dependency parsing by extending the probablistic model proposed by  #TAUTHOR_TAG, and describes an evaluation experiment using our 1 bunsetsu is a linguistic unit in japanese that roughly corresponds to a basic phrase in english.', 'a bunsetsu consists of one independent word and zero or more ancillary words.', '']",6
"['by  #TAUTHOR_TAG, which can']","['by  #TAUTHOR_TAG, which can']","['by  #TAUTHOR_TAG, which can']","['', 'we use the same search algorithm as one proposed by  #TAUTHOR_TAG, which can efficiently find the approximate solution from a huge number of candidates of the pattern by extending cyk algorithm used in conventional dependency parsing.', 'in this paper, we refine the probabilistic model proposed by  #TAUTHOR_TAG to improve the accuracy.', 'note our method reorders bunsetsus in a sentence without paraphrasing and does not reorder morphemes within a bunsetsu.', 'in addition, we assume there are not any inverted structures and commas in an input sentence']",6
"[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","['a sequence of bunsetsus in an input sentence b = b 1 · · · b n is provided, our method identifies the structure s which maximizes p ( s | b ).', 'the structure s is defined as a tuple s = [UNK] o, d [UNK] where in the probablistic model proposed by  #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG and calculate p ( s | b ) as follows :', 'where α is a weight and 0 ≤ α ≤ 1. formula ( 2 ) is obtained for the weighted geometric average 2 between the following two formulas ( 3 ) and ( 4 ).', 'here, formulas ( 3 ) and ( 4 ) are derived by expanding p ( o, d | b ) based on multiplication theorem.', '']",6
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],"['paper proposed the method for reordering bunsetsus in a japanese sentence based on executing concurrently with dependency parsing.', 'especially, we extended the probablistic model proposed by  #TAUTHOR_TAG to deal with sentences spontaneously written by a native.', 'in addition, we conducted the experiment using our semiautomatically constructed evaluation data so that the sentences are likely to be spontaneously written by a native.', 'the experimental results showed the effectiveness of our method.', 'in the future, we would like to develop a word reordering method which can take account of comma positions by integrating our method with a method for identifying proper comma positions ( for example,  #AUTHOR_TAG']",6
"['word order in newspaper article sentences  #TAUTHOR_TAG.', 'however,']","['word order in newspaper article sentences  #TAUTHOR_TAG.', 'however,']","['proposed method using evaluation data created by randomly changing the word order in newspaper article sentences  #TAUTHOR_TAG.', 'however,']","['', 'to solve the problem, we previously proposed a method for concurrently performing word reordering and dependency parsing and confirmed the effectiveness of their proposed method using evaluation data created by randomly changing the word order in newspaper article sentences  #TAUTHOR_TAG.', 'however, since some of the just automatically created sentences are unlikely to be spontaneously written by a native, the evaluation is thought to be not enough.', 'in addition, the probablistic model has room for improvement in targeting at sentences which a native is likely to spontaneously write.', 'this paper proposes a new method on japanese word reordering based on concurrent execution with dependency parsing by extending the probablistic model proposed by  #TAUTHOR_TAG, and describes an evaluation experiment using our 1 bunsetsu is a linguistic unit in japanese that roughly corresponds to a basic phrase in english.', 'a bunsetsu consists of one independent word and zero or more ancillary words.', '']",0
"[',  #TAUTHOR_TAG artificially generated sentences']","['evaluation with a focus solely on word order.', 'therefore,  #TAUTHOR_TAG artificially generated sentences']","[',  #TAUTHOR_TAG artificially generated sentences']","['a viewpoint of utilizing our method for support revision, it is desirable to use less - readable sentences spontaneously written by japanese natives in the experiment.', 'however, it is not easy to collect a large amount of pairs composed of such a sentence and the corresponding sentence which was modified by hand so that the word order becomes readable, and also, such data is unavailable.', 'in addition, since spontaneously written sentences have many factors other than word order which decrease the readability, it is difficult to conduct the evaluation with a focus solely on word order.', 'therefore,  #TAUTHOR_TAG artificially generated sentences which were not easy to read, by just automatically changing the word order of newspaper article sentences in kyoto text corpus 3 based on the dependency structure.', 'however, just automatically changing the word order may create sentences which are unlikely to be written by a native.', 'to solve the problem, we semi - automatically constructed the evaluation data by adding human judgement.', 'that is, if a subject judges that a sentence generated by automatically changing the word order in the same way as  #TAUTHOR_TAG may have spontaneously written by a native.', 'our constructed data has 552 sentences including 4, 906 bunsetsus']",0
"[',  #TAUTHOR_TAG artificially generated sentences']","['evaluation with a focus solely on word order.', 'therefore,  #TAUTHOR_TAG artificially generated sentences']","[',  #TAUTHOR_TAG artificially generated sentences']","['a viewpoint of utilizing our method for support revision, it is desirable to use less - readable sentences spontaneously written by japanese natives in the experiment.', 'however, it is not easy to collect a large amount of pairs composed of such a sentence and the corresponding sentence which was modified by hand so that the word order becomes readable, and also, such data is unavailable.', 'in addition, since spontaneously written sentences have many factors other than word order which decrease the readability, it is difficult to conduct the evaluation with a focus solely on word order.', 'therefore,  #TAUTHOR_TAG artificially generated sentences which were not easy to read, by just automatically changing the word order of newspaper article sentences in kyoto text corpus 3 based on the dependency structure.', 'however, just automatically changing the word order may create sentences which are unlikely to be written by a native.', 'to solve the problem, we semi - automatically constructed the evaluation data by adding human judgement.', 'that is, if a subject judges that a sentence generated by automatically changing the word order in the same way as  #TAUTHOR_TAG may have spontaneously written by a native.', 'our constructed data has 552 sentences including 4, 906 bunsetsus']",0
"['by  #TAUTHOR_TAG, which can']","['by  #TAUTHOR_TAG, which can']","['by  #TAUTHOR_TAG, which can']","['', 'we use the same search algorithm as one proposed by  #TAUTHOR_TAG, which can efficiently find the approximate solution from a huge number of candidates of the pattern by extending cyk algorithm used in conventional dependency parsing.', 'in this paper, we refine the probabilistic model proposed by  #TAUTHOR_TAG to improve the accuracy.', 'note our method reorders bunsetsus in a sentence without paraphrasing and does not reorder morphemes within a bunsetsu.', 'in addition, we assume there are not any inverted structures and commas in an input sentence']",5
"[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","['a sequence of bunsetsus in an input sentence b = b 1 · · · b n is provided, our method identifies the structure s which maximizes p ( s | b ).', 'the structure s is defined as a tuple s = [UNK] o, d [UNK] where in the probablistic model proposed by  #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG and calculate p ( s | b ) as follows :', 'where α is a weight and 0 ≤ α ≤ 1. formula ( 2 ) is obtained for the weighted geometric average 2 between the following two formulas ( 3 ) and ( 4 ).', 'here, formulas ( 3 ) and ( 4 ) are derived by expanding p ( o, d | b ) based on multiplication theorem.', '']",5
"[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","['a sequence of bunsetsus in an input sentence b = b 1 · · · b n is provided, our method identifies the structure s which maximizes p ( s | b ).', 'the structure s is defined as a tuple s = [UNK] o, d [UNK] where in the probablistic model proposed by  #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG and calculate p ( s | b ) as follows :', 'where α is a weight and 0 ≤ α ≤ 1. formula ( 2 ) is obtained for the weighted geometric average 2 between the following two formulas ( 3 ) and ( 4 ).', 'here, formulas ( 3 ) and ( 4 ) are derived by expanding p ( o, d | b ) based on multiplication theorem.', '']",5
['were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG'],"['correctly ), which were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG']",['were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG'],"['', 'the sentences in which all the dependencies are analyzed correctly ), which were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG and two conventional sequential methods.', 'both the sequential methods execute the dependency parsing primarily, and then, perform the word reordering by using the conventional word reordering method  #AUTHOR_TAG. the difference between the two is the method of dependency parsing. the sequential methods 1 and 2 use the dependency parsing method proposed by  #AUTHOR_TAG and the dependency parsing tool cabocha 5, respectively', '. all of the methods used the same training features as those described in  #TAUTHOR_TAG. table 1 shows the experimental results on word reordering of each method', '. here, the last row shows the agreements measured by comparing the input word order with the correct word order. the agreements mean the values which can be achieved with no reordering. the both agreements of our method are micro averages for the agreements of each', 'of the 5 sets. as the result of decision of α', 'by using the held - out data, the α for 3 sets was 0. 66, and the α for the other two sets was 0', '. 75. the both agreements of our method were highest among', 'all. we can confirm the effectiveness of our method. although the purpose of our method is reordering to improve readability, our', 'method generates a dependency structure as a by - product. here, for reference', ', we show the experimental results on dependency parsing in table 2. the', 'dependency accuracy of our method was significantly lower than that of the two sequential methods, and was higher than that', 'of  #TAUTHOR_TAG although there was no significant difference. on the other hand,', 'the sentence accuracy of our method was highest among  #TAUTHOR_TAG although there were no significant differences in them.', 'as a result of analysis, especially, our method and  #TAUTHOR_TAG tended to improve the sentence accuracy very well in case of short sentences. on the other hand, cabocha, which is a', 'dependency parser in sequential 2, tended not to depend very', 'well on the length of sentences']",5
['were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG'],"['correctly ), which were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG']",['were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG'],"['', 'the sentences in which all the dependencies are analyzed correctly ), which were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG and two conventional sequential methods.', 'both the sequential methods execute the dependency parsing primarily, and then, perform the word reordering by using the conventional word reordering method  #AUTHOR_TAG. the difference between the two is the method of dependency parsing. the sequential methods 1 and 2 use the dependency parsing method proposed by  #AUTHOR_TAG and the dependency parsing tool cabocha 5, respectively', '. all of the methods used the same training features as those described in  #TAUTHOR_TAG. table 1 shows the experimental results on word reordering of each method', '. here, the last row shows the agreements measured by comparing the input word order with the correct word order. the agreements mean the values which can be achieved with no reordering. the both agreements of our method are micro averages for the agreements of each', 'of the 5 sets. as the result of decision of α', 'by using the held - out data, the α for 3 sets was 0. 66, and the α for the other two sets was 0', '. 75. the both agreements of our method were highest among', 'all. we can confirm the effectiveness of our method. although the purpose of our method is reordering to improve readability, our', 'method generates a dependency structure as a by - product. here, for reference', ', we show the experimental results on dependency parsing in table 2. the', 'dependency accuracy of our method was significantly lower than that of the two sequential methods, and was higher than that', 'of  #TAUTHOR_TAG although there was no significant difference. on the other hand,', 'the sentence accuracy of our method was highest among  #TAUTHOR_TAG although there were no significant differences in them.', 'as a result of analysis, especially, our method and  #TAUTHOR_TAG tended to improve the sentence accuracy very well in case of short sentences. on the other hand, cabocha, which is a', 'dependency parser in sequential 2, tended not to depend very', 'well on the length of sentences']",5
"[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","[' #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG']","['a sequence of bunsetsus in an input sentence b = b 1 · · · b n is provided, our method identifies the structure s which maximizes p ( s | b ).', 'the structure s is defined as a tuple s = [UNK] o, d [UNK] where in the probablistic model proposed by  #TAUTHOR_TAG, p ( s | b ) was calculated as follows :', 'we extend  #TAUTHOR_TAG and calculate p ( s | b ) as follows :', 'where α is a weight and 0 ≤ α ≤ 1. formula ( 2 ) is obtained for the weighted geometric average 2 between the following two formulas ( 3 ) and ( 4 ).', 'here, formulas ( 3 ) and ( 4 ) are derived by expanding p ( o, d | b ) based on multiplication theorem.', '']",4
['were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG'],"['correctly ), which were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG']",['were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG'],"['', 'the sentences in which all the dependencies are analyzed correctly ), which were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG and two conventional sequential methods.', 'both the sequential methods execute the dependency parsing primarily, and then, perform the word reordering by using the conventional word reordering method  #AUTHOR_TAG. the difference between the two is the method of dependency parsing. the sequential methods 1 and 2 use the dependency parsing method proposed by  #AUTHOR_TAG and the dependency parsing tool cabocha 5, respectively', '. all of the methods used the same training features as those described in  #TAUTHOR_TAG. table 1 shows the experimental results on word reordering of each method', '. here, the last row shows the agreements measured by comparing the input word order with the correct word order. the agreements mean the values which can be achieved with no reordering. the both agreements of our method are micro averages for the agreements of each', 'of the 5 sets. as the result of decision of α', 'by using the held - out data, the α for 3 sets was 0. 66, and the α for the other two sets was 0', '. 75. the both agreements of our method were highest among', 'all. we can confirm the effectiveness of our method. although the purpose of our method is reordering to improve readability, our', 'method generates a dependency structure as a by - product. here, for reference', ', we show the experimental results on dependency parsing in table 2. the', 'dependency accuracy of our method was significantly lower than that of the two sequential methods, and was higher than that', 'of  #TAUTHOR_TAG although there was no significant difference. on the other hand,', 'the sentence accuracy of our method was highest among  #TAUTHOR_TAG although there were no significant differences in them.', 'as a result of analysis, especially, our method and  #TAUTHOR_TAG tended to improve the sentence accuracy very well in case of short sentences. on the other hand, cabocha, which is a', 'dependency parser in sequential 2, tended not to depend very', 'well on the length of sentences']",4
['were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG'],"['correctly ), which were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG']",['were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG'],"['', 'the sentences in which all the dependencies are analyzed correctly ), which were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG and two conventional sequential methods.', 'both the sequential methods execute the dependency parsing primarily, and then, perform the word reordering by using the conventional word reordering method  #AUTHOR_TAG. the difference between the two is the method of dependency parsing. the sequential methods 1 and 2 use the dependency parsing method proposed by  #AUTHOR_TAG and the dependency parsing tool cabocha 5, respectively', '. all of the methods used the same training features as those described in  #TAUTHOR_TAG. table 1 shows the experimental results on word reordering of each method', '. here, the last row shows the agreements measured by comparing the input word order with the correct word order. the agreements mean the values which can be achieved with no reordering. the both agreements of our method are micro averages for the agreements of each', 'of the 5 sets. as the result of decision of α', 'by using the held - out data, the α for 3 sets was 0. 66, and the α for the other two sets was 0', '. 75. the both agreements of our method were highest among', 'all. we can confirm the effectiveness of our method. although the purpose of our method is reordering to improve readability, our', 'method generates a dependency structure as a by - product. here, for reference', ', we show the experimental results on dependency parsing in table 2. the', 'dependency accuracy of our method was significantly lower than that of the two sequential methods, and was higher than that', 'of  #TAUTHOR_TAG although there was no significant difference. on the other hand,', 'the sentence accuracy of our method was highest among  #TAUTHOR_TAG although there were no significant differences in them.', 'as a result of analysis, especially, our method and  #TAUTHOR_TAG tended to improve the sentence accuracy very well in case of short sentences. on the other hand, cabocha, which is a', 'dependency parser in sequential 2, tended not to depend very', 'well on the length of sentences']",4
"[',  #TAUTHOR_TAG artificially generated sentences']","['evaluation with a focus solely on word order.', 'therefore,  #TAUTHOR_TAG artificially generated sentences']","[',  #TAUTHOR_TAG artificially generated sentences']","['a viewpoint of utilizing our method for support revision, it is desirable to use less - readable sentences spontaneously written by japanese natives in the experiment.', 'however, it is not easy to collect a large amount of pairs composed of such a sentence and the corresponding sentence which was modified by hand so that the word order becomes readable, and also, such data is unavailable.', 'in addition, since spontaneously written sentences have many factors other than word order which decrease the readability, it is difficult to conduct the evaluation with a focus solely on word order.', 'therefore,  #TAUTHOR_TAG artificially generated sentences which were not easy to read, by just automatically changing the word order of newspaper article sentences in kyoto text corpus 3 based on the dependency structure.', 'however, just automatically changing the word order may create sentences which are unlikely to be written by a native.', 'to solve the problem, we semi - automatically constructed the evaluation data by adding human judgement.', 'that is, if a subject judges that a sentence generated by automatically changing the word order in the same way as  #TAUTHOR_TAG may have spontaneously written by a native.', 'our constructed data has 552 sentences including 4, 906 bunsetsus']",1
['were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG'],"['correctly ), which were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG']",['were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG'],"['', 'the sentences in which all the dependencies are analyzed correctly ), which were defined by  #AUTHOR_TAG. we compared our method to  #TAUTHOR_TAG and two conventional sequential methods.', 'both the sequential methods execute the dependency parsing primarily, and then, perform the word reordering by using the conventional word reordering method  #AUTHOR_TAG. the difference between the two is the method of dependency parsing. the sequential methods 1 and 2 use the dependency parsing method proposed by  #AUTHOR_TAG and the dependency parsing tool cabocha 5, respectively', '. all of the methods used the same training features as those described in  #TAUTHOR_TAG. table 1 shows the experimental results on word reordering of each method', '. here, the last row shows the agreements measured by comparing the input word order with the correct word order. the agreements mean the values which can be achieved with no reordering. the both agreements of our method are micro averages for the agreements of each', 'of the 5 sets. as the result of decision of α', 'by using the held - out data, the α for 3 sets was 0. 66, and the α for the other two sets was 0', '. 75. the both agreements of our method were highest among', 'all. we can confirm the effectiveness of our method. although the purpose of our method is reordering to improve readability, our', 'method generates a dependency structure as a by - product. here, for reference', ', we show the experimental results on dependency parsing in table 2. the', 'dependency accuracy of our method was significantly lower than that of the two sequential methods, and was higher than that', 'of  #TAUTHOR_TAG although there was no significant difference. on the other hand,', 'the sentence accuracy of our method was highest among  #TAUTHOR_TAG although there were no significant differences in them.', 'as a result of analysis, especially, our method and  #TAUTHOR_TAG tended to improve the sentence accuracy very well in case of short sentences. on the other hand, cabocha, which is a', 'dependency parser in sequential 2, tended not to depend very', 'well on the length of sentences']",3
['with deep neural network  #AUTHOR_TAG and convolutional neural network  #TAUTHOR_TAG to'],['with deep neural network  #AUTHOR_TAG and convolutional neural network  #TAUTHOR_TAG to'],"[', research works have been carried out by using machine learning with lexical features  #AUTHOR_TAG and deep learning with deep neural network  #AUTHOR_TAG and convolutional neural network  #TAUTHOR_TAG to']","['identification is a process of identifying the emotions automatically from different modalities.', 'several research work have been presented on detecting emotions from text  #AUTHOR_TAG abdul  #AUTHOR_TAG al  #AUTHOR_TAG, speech  #AUTHOR_TAG, images  #AUTHOR_TAG and video  #AUTHOR_TAG.', 'emotion understanding from video may be easier by analyzing the body language, speech variations and facial expressions.', 'however, identification of emotions from textual conversations is a challenging problem due to absence of above factors.', 'emotions in text are not only identified by its cue words such as happy, good, bore, hurt, hate and fun, but also the presence of interjections ( e. g. "" whoops "" ), emoticons ( e. g. "" : ) "" ), idiomatic expressions ( e. g. "" am in cloud nine "" ), metaphors ( e. g. "" sending clouds "" ) and other descriptors mark the existence of emotions in the conversational text.', 'recently, the growth of text messaging applications for communications require emotion detection from conversation transcripts.', 'this helps conversational agents, chat bots and messengers to avoid emotional cues and miscommunications by detecting the emotions during conversation.', 'emocontext @ semeval2019 shared task  #AUTHOR_TAG goal is to encourage more research in the field of contextual emotion detection in textual conversations.', 'the shared task focuses on identifying emotions namely angry, happy, sad and others from conversation with three turns.', 'since, emotion detection is a classification problem, research works have been carried out by using machine learning with lexical features  #AUTHOR_TAG and deep learning with deep neural network  #AUTHOR_TAG and convolutional neural network  #TAUTHOR_TAG to detect the emotions from text.', 'however, we have adopted seq2seq deep neural network for detecting the emotions from textual conversations which include sequence of phrases.', 'this paper elaborates our seq2seq approach for identifying emotions from text sequences']",0
"[' #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is']","['from text / tweets  #AUTHOR_TAG abdul  #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is']","[' #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is used to assign an emotional value which is derived from a fuzzy set function.', ' #AUTHOR_TAG classified twitter text into']","['section reviews the research work reported for emotion detection from text / tweets  #AUTHOR_TAG abdul  #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is used to assign an emotional value which is derived from a fuzzy set function.', ' #AUTHOR_TAG classified twitter text into emotion by using textual and syntactic features with smo and decision tree classifiers.', 'the tweets are annotated manually by  #AUTHOR_TAG with 28 fine - grained emotion categories and experimented with different machine learning algorithms.', 'results show that svm and bayesnet classifiers produce consistently good performance for fine - grained emotion classification.', ' #AUTHOR_TAG developed an emotion lexicon from wordnet.', 'the conversation utterances are mapped to the lexicons and 22 features are extracted using rule - based algorithm.', '']",0
"[' #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is']","['from text / tweets  #AUTHOR_TAG abdul  #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is']","[' #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is used to assign an emotional value which is derived from a fuzzy set function.', ' #AUTHOR_TAG classified twitter text into']","['section reviews the research work reported for emotion detection from text / tweets  #AUTHOR_TAG abdul  #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is used to assign an emotional value which is derived from a fuzzy set function.', ' #AUTHOR_TAG classified twitter text into emotion by using textual and syntactic features with smo and decision tree classifiers.', 'the tweets are annotated manually by  #AUTHOR_TAG with 28 fine - grained emotion categories and experimented with different machine learning algorithms.', 'results show that svm and bayesnet classifiers produce consistently good performance for fine - grained emotion classification.', ' #AUTHOR_TAG developed an emotion lexicon from wordnet.', 'the conversation utterances are mapped to the lexicons and 22 features are extracted using rule - based algorithm.', '']",5
"[' #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is']","['from text / tweets  #AUTHOR_TAG abdul  #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is']","[' #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is used to assign an emotional value which is derived from a fuzzy set function.', ' #AUTHOR_TAG classified twitter text into']","['section reviews the research work reported for emotion detection from text / tweets  #AUTHOR_TAG abdul  #AUTHOR_TAG al  #AUTHOR_TAG and text conversations  #TAUTHOR_TAG.', ' #AUTHOR_TAG proposed a methodology to create a lexicon - a vocabulary consisting of positive and negative expressions.', 'this lexicon is used to assign an emotional value which is derived from a fuzzy set function.', ' #AUTHOR_TAG classified twitter text into emotion by using textual and syntactic features with smo and decision tree classifiers.', 'the tweets are annotated manually by  #AUTHOR_TAG with 28 fine - grained emotion categories and experimented with different machine learning algorithms.', 'results show that svm and bayesnet classifiers produce consistently good performance for fine - grained emotion classification.', ' #AUTHOR_TAG developed an emotion lexicon from wordnet.', 'the conversation utterances are mapped to the lexicons and 22 features are extracted using rule - based algorithm.', '']",1
"['from weighted alignment matrix  #TAUTHOR_TAG.', '']","['from weighted alignment matrix  #TAUTHOR_TAG.', '']","['hierarchical rules from weighted alignment matrix  #TAUTHOR_TAG.', '']","['', 'to alleviate this problem, we extract hierarchical rules from weighted alignment matrix  #TAUTHOR_TAG.', '']",1
"['', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides']","['( a ).', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides']","['', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides']","['', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides an elegant solution to these two drawbacks, we apply it to the hierarchical phrase - based model  #AUTHOR_TAG and the tree - to - string model  #AUTHOR_TAG.', 'while such an idea seems intuitive, it is non - trivial to extract hierarchical rules from weighted alignment matrices.', '']",1
"['', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides']","['( a ).', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides']","['', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides']","['', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides an elegant solution to these two drawbacks, we apply it to the hierarchical phrase - based model  #AUTHOR_TAG and the tree - to - string model  #AUTHOR_TAG.', 'while such an idea seems intuitive, it is non - trivial to extract hierarchical rules from weighted alignment matrices.', '']",5
"['lexical weights of phrase pairs as in  #TAUTHOR_TAG, we only focus on the']","['lexical weights of phrase pairs as in  #TAUTHOR_TAG, we only focus on the']","['lexical weights of phrase pairs as in  #TAUTHOR_TAG, we only focus on the calculation of variable rules']","['hierarchical rules, both source and target sides are strings with nts.', 'in tree - to - string rules, the source side is a tree with nts, while the target side is a string with nts.', 'since the tree structure of source side has no effect on the calculations of relative frequencies and lexical weights, we can represent both tree - to - string and hierarchical rules as below :', 'where x is a nonterminal, γ and α are source and target strings ( consist of terminals and nts ), and ∼ represents word alignments between nts in γ and α.', 'the bulk of syntax grammars consists of two parts : phrase pairs and variable rules.', 'the difference between them is containing nts or not.', 'since we can calculate relative frequencies and lexical weights of phrase pairs as in  #TAUTHOR_TAG, we only focus on the calculation of variable rules']",5
"['follow  #TAUTHOR_TAG to calculate relative frequencies using the product of inside and outside probabilities.', 'we now extend the definitions of inside']","['follow  #TAUTHOR_TAG to calculate relative frequencies using the product of inside and outside probabilities.', 'we now extend the definitions of inside']","['follow  #TAUTHOR_TAG to calculate relative frequencies using the product of inside and outside probabilities.', 'we now extend the definitions of inside']","['follow  #TAUTHOR_TAG to calculate relative frequencies using the product of inside and outside probabilities.', 'we now extend the definitions of inside and outside probabilities to hierarchical rules that contain nts.', ""table 2 : some hierarchical rules generated from the phrase pair ( zhongguo de jingji, china's economy ) in figure 3 ( suppose the structure of zhongguo de jingji is a complete sub - tree )."", 'here α is inside probability, β is outside probability, and count is fractional count.', '']",5
"['follow  #TAUTHOR_TAG to calculate relative frequencies using the product of inside and outside probabilities.', 'we now extend the definitions of inside']","['follow  #TAUTHOR_TAG to calculate relative frequencies using the product of inside and outside probabilities.', 'we now extend the definitions of inside']","['follow  #TAUTHOR_TAG to calculate relative frequencies using the product of inside and outside probabilities.', 'we now extend the definitions of inside']","['follow  #TAUTHOR_TAG to calculate relative frequencies using the product of inside and outside probabilities.', 'we now extend the definitions of inside and outside probabilities to hierarchical rules that contain nts.', ""table 2 : some hierarchical rules generated from the phrase pair ( zhongguo de jingji, china's economy ) in figure 3 ( suppose the structure of zhongguo de jingji is a complete sub - tree )."", 'here α is inside probability, β is outside probability, and count is fractional count.', '']",5
['follow  #TAUTHOR_TAG'],['follow  #TAUTHOR_TAG'],"[' #AUTHOR_TAG to all 20 × 20 bidirectional alignment pairs.', 'we follow  #TAUTHOR_TAG']","['experiments are on chinese - english translation based on replications of hierarchical phrasebased system  #AUTHOR_TAG and tree - to - string system.', 'we train a 4 - gram language model on the xinhua portion of giga - word corpus using the sri language modeling toolkit  #AUTHOR_TAG with modified kneserney smoothing  #AUTHOR_TAG to obtain weighted alignment matrices, we follow  #AUTHOR_TAG to produce n - best lists via giza + +.', 'we produce 20 - best lists in two translation directions, then used "" grow - diag - finaland ""  #AUTHOR_TAG to all 20 × 20 bidirectional alignment pairs.', 'we follow  #TAUTHOR_TAG to use p s2t × p t2s as the probabilities of an alignment pair.', 'analogously, we abandon duplicate alignments that are produced from different alignment pairs.', 'after these steps, there are 110 candidate alignments on average for each sentence pair.', 'we obtained n - best lists by selecting the top n alignments from 110 - best lists.', 'we re - estimated the probability of each alignment in the n - best list using re - normalization  #AUTHOR_TAG.', 'finally, we construct weighted alignment matrices from these n - best alignments.', 'we will first report results trained on a smallscaled corpus, and then scale to a larger one.', 'when extracting tree - to - string rules, we limit the maximal height of rules to 3.', 'we use the pruning threshold : t = 0. 5']",5
"['', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides']","['( a ).', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides']","['', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides']","['', 'since  #TAUTHOR_TAG show that weighted alignment matrix provides an elegant solution to these two drawbacks, we apply it to the hierarchical phrase - based model  #AUTHOR_TAG and the tree - to - string model  #AUTHOR_TAG.', 'while such an idea seems intuitive, it is non - trivial to extract hierarchical rules from weighted alignment matrices.', '']",4
['- scoring models  #TAUTHOR_TAG'],"['in a part.', 'the discriminative re - scoring models  #TAUTHOR_TAG']","['because there is only one grammar rule in a part.', 'the discriminative re - scoring models  #TAUTHOR_TAG']","['', 'similarly, we can define the order of constituent parsing in terms of the number of grammar rules in a part.', 'then, the previous discriminative constituent parsing models  #AUTHOR_TAG a ; * the research reported in this paper was partially supported by the research grants council of hksar, china, through the grf grant 9041597 ( cityu 144410 ).', ' #AUTHOR_TAG b ;  #AUTHOR_TAG are the first - order ones, because there is only one grammar rule in a part.', 'the discriminative re - scoring models  #TAUTHOR_TAG can be viewed as previous attempts to higher - order constituent parsing, using some parts containing more than one grammar rule as non - local features.', 'in this paper, we present a higher - order constituent parsing model 1 based on these previous works.', '']",0
"['', 'following  #TAUTHOR_TAG, this']","['factorization of the parsing model allows us to develop an exact decoding algorithm for it.', 'following  #TAUTHOR_TAG, this']","['', 'following  #TAUTHOR_TAG, this algorithm']","['factorization of the parsing model allows us to develop an exact decoding algorithm for it.', 'following  #TAUTHOR_TAG, this algorithm traverses a parse forest in a bottom - up manner.', '']",0
"['', 'following  #TAUTHOR_TAG, this']","['factorization of the parsing model allows us to develop an exact decoding algorithm for it.', 'following  #TAUTHOR_TAG, this']","['', 'following  #TAUTHOR_TAG, this algorithm']","['factorization of the parsing model allows us to develop an exact decoding algorithm for it.', 'following  #TAUTHOR_TAG, this algorithm traverses a parse forest in a bottom - up manner.', '']",5
"['algorithm, following  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'the']","['parsing model are estimated from a training set using an averaged perceptron algorithm, following  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'the']","[' #AUTHOR_TAG 92.', '4  #AUTHOR_TAG 92. 3  #AUTHOR_TAG 91. 85 41. 9  #AUTHOR_TAG  #AUTHOR_TAG.', 'the parameters θ of each parsing model are estimated from a training set using an averaged perceptron algorithm, following  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'the performance of our first']","['parsing models are evaluated on both english and chinese treebanks, i. e., the wsj section of penn treebank 3. 0 ( ldc99t42 ) and the chinese treebank 5. 1 ( ldc2005t01u01 ).', 'in order to compare with previous works, we opt for the same split as in  #AUTHOR_TAG, as listed in table 2.', 'for parser combination, we follow the setting of  #AUTHOR_TAG, using section 24 instead of section 22 of wsj treebank as development set.', 'in this work, the lexical model of  #AUTHOR_TAG is combined with our syntactic model under the framework of product - of - experts  #AUTHOR_TAG.', 'a factor λ is introduced to balance the two models.', 'it is tuned on a development set using the gold sec - ( 2003 ) 90. 70  #AUTHOR_TAG 91. 1  #AUTHOR_TAG 89. 70  #AUTHOR_TAG 91. 02 the parser of charniak and johnson 91. 40 43. 54  #AUTHOR_TAG 91. 69 43. 5  #AUTHOR_TAG 92.', '4  #AUTHOR_TAG 92. 3  #AUTHOR_TAG 91. 85 41. 9  #AUTHOR_TAG  #AUTHOR_TAG.', 'the parameters θ of each parsing model are estimated from a training set using an averaged perceptron algorithm, following  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'the performance of our first - and higher - order parsing models on all sentences of the two test sets is presented in table 3, where λ indicates a tuned balance factor.', 'this parser is also combined with the parser of  #AUTHOR_TAG 2 and the stanford.', 'parser 3 the best combination results in table 3 are achieved with k = 70 for english and k = 100 for chinese for selecting the k - best parses.', 'our results are compared with the best previous ones on the same test sets in tables 4 and']",5
"['', 'following  #TAUTHOR_TAG, this']","['factorization of the parsing model allows us to develop an exact decoding algorithm for it.', 'following  #TAUTHOR_TAG, this']","['', 'following  #TAUTHOR_TAG, this algorithm']","['factorization of the parsing model allows us to develop an exact decoding algorithm for it.', 'following  #TAUTHOR_TAG, this algorithm traverses a parse forest in a bottom - up manner.', '']",4
"['11,  #TAUTHOR_TAG', 'or']","['translation pairs [ 11,  #TAUTHOR_TAG', 'or']","['translation pairs [ 11,  #TAUTHOR_TAG', 'or document - aligned comparable']","['', 'g., wikipedia or babelnet ) [ 4, 20 ]. however, the concept coverage is limited for resource - lean languages, and all content not present in a knowledge base is effectively ignored by a clir system. bilingual text embeddings, while displaying a wider applicability and versa', '##tility than the two other paradigms, still suffer from one important limitation : a bilingual supervision signal is required to induce shared cross - lingual semantic spaces', '. this supervision takes form of sentence - aligned parallel data [ 5 ], pre - built word translation pairs [ 11,  #TAUTHOR_TAG', 'or document - aligned comparable data [ 21 ]. 1 recently, methods for inducing shared cross - lingual embedding spaces without the need for any bilingual signal ( not even word translation pairs ) have been proposed [ 1, 3 ]. these methods exploit inherent structural similarities of induced monolingual', 'embedding spaces to learn vector space transformations that align the source language space to the target language space, with strong results observed for bilingual', 'lexicon extraction. in this work, we show that these unsupervised cross - lingual word embeddings offer strong support', 'to the construction of fully unsupervised adhoc clir models. we propose two different clir models : 1 ) termby - term translation through the shared cross - lingual space, and 2 ) query and document representations as idf - weighted', 'sums of constituent word vectors. to the best of our knowledge, our clir methodology is the first to allow the construction of clir models without any bilingual data and supervision at all, relying solely on', 'monolingual corpora. experimental evaluation on standard clef clir data for three different language pairs shows that the proposed fully unsupervised clir models outperform competitive baselines', 'and models that exploit word translation pairs or comparable corpora. our clir code and multilingual embedding spaces are publicly available at : https : / / github. com / rlitschk / unsup', '##clir']",3
['2 ) word translation pairs  #TAUTHOR_TAG ; and 3 ) no bilingual data at all'],['2 ) word translation pairs  #TAUTHOR_TAG ; and 3 ) no bilingual data at all [ 3 ]'],['2 ) word translation pairs  #TAUTHOR_TAG ; and 3 ) no bilingual data at all [ 3 ]'],"['our proposed clir models, we investigate cross - lingual embedding spaces produced with state - of - the - art representative methods requiring different amount and type of bilingual supervision : 1 ) document - aligned comparable data [ 21 ], 2 ) word translation pairs  #TAUTHOR_TAG ; and 3 ) no bilingual data at all [ 3 ]']",3
"['of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i']","['of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i. e., mappings )']","['class of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i']","['class of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i. e., mappings ) between independently trained monolingual embedding spaces.', 'let { s w i } v s i = 1, s w i ∈ r ds be the monolingual word embedding space of the source language l s with v s vectors, and { t w i } v t i = 1, t w i ∈ r dt the monolingual space for the target language l t containing v t vectors ; ds and dt are the respective space dimensionalities.', '']",3
['.  #TAUTHOR_TAG. let'],['al.  #TAUTHOR_TAG. let'],['.  #TAUTHOR_TAG. let'],"['recently, conneau et al. [ 3 ] have proposed an adversarial learning - based model in order to automatically, in a fully unsupervised fashion, create word translation pairs that can then be used to learn the same projection functions f s and f t as in the model of smith et al.  #TAUTHOR_TAG. let x be the set of all monolingual word embeddings from the source language, and y the set of all target language embeddings.', 'in the first, adversarial learning step, they jointly learn ( 1 ) the projection matrix w that maps one embedding space to the other and ( 2 ) the parameters of the discriminator model which, given an embedding vector ( either w x where x ∈ x, or ∈ y ) needs to predict whether it is an original vector from the target embedding space ( ), nor a vector from the source embedding space mapped via projection w to the target embedding space ( w x ).', 'the discriminator model is a multi - layer perceptron network.', 'in the second step, the projection matrix w trained with adversarial objective is used to find the mutual nearest neighbors between the two vocabularies - this set of automatically obtained word translation pairs becomes a synthetic training set for the refined projection functions f s and f t computed via the svd - based method similar to the previously described model of smith et al.  #TAUTHOR_TAG']",3
['.  #TAUTHOR_TAG. let'],['al.  #TAUTHOR_TAG. let'],['.  #TAUTHOR_TAG. let'],"['recently, conneau et al. [ 3 ] have proposed an adversarial learning - based model in order to automatically, in a fully unsupervised fashion, create word translation pairs that can then be used to learn the same projection functions f s and f t as in the model of smith et al.  #TAUTHOR_TAG. let x be the set of all monolingual word embeddings from the source language, and y the set of all target language embeddings.', 'in the first, adversarial learning step, they jointly learn ( 1 ) the projection matrix w that maps one embedding space to the other and ( 2 ) the parameters of the discriminator model which, given an embedding vector ( either w x where x ∈ x, or ∈ y ) needs to predict whether it is an original vector from the target embedding space ( ), nor a vector from the source embedding space mapped via projection w to the target embedding space ( w x ).', 'the discriminator model is a multi - layer perceptron network.', 'in the second step, the projection matrix w trained with adversarial objective is used to find the mutual nearest neighbors between the two vocabularies - this set of automatically obtained word translation pairs becomes a synthetic training set for the refined projection functions f s and f t computed via the svd - based method similar to the previously described model of smith et al.  #TAUTHOR_TAG']",3
"['- nl compared', 'to en - it ( see, e. g.,  #TAUTHOR_TAG. we observe the']","['##ing phenomenon in word formation, which is present in nl, but is', 'not a property of en and it. the reported performance on bilingual lexicon extraction ( ble ) using cross - lingual embedding spaces is also lower for en - nl compared', 'to en - it ( see, e. g.,  #TAUTHOR_TAG. we observe the same pattern (']","['- nl compared', 'to en - it ( see, e. g.,  #TAUTHOR_TAG. we observe the']","['', 'is lexically and typologically more distant from english than italian and dutch. however, even though nl is linguistically closer to en than it, for the unsupervised clir models we generally observe', 'slightly better performance for en→it than for en→nl. we speculate that this is due to the compounding phenomenon in word formation, which is present in nl, but is', 'not a property of en and it. the reported performance on bilingual lexicon extraction ( ble ) using cross - lingual embedding spaces is also lower for en - nl compared', 'to en - it ( see, e. g.,  #TAUTHOR_TAG. we observe the same pattern ( 4 - 5 % lower ble performance for en - nl than for en - it ) with the cl - unsup embedding spaces. the weighted variant of bwe - agg ( bwe', '- agg - idf', ') outperforms the simpler non - weighted summation model ( bwe - agg - add ) across the board. these', 'results suggest that the common ir assumption about document - specific terms being more important than the terms occurring collection - wide is also valid for constructing dense document representations by summing word embeddings']",3
"['11,  #TAUTHOR_TAG', 'or']","['translation pairs [ 11,  #TAUTHOR_TAG', 'or']","['translation pairs [ 11,  #TAUTHOR_TAG', 'or document - aligned comparable']","['', 'g., wikipedia or babelnet ) [ 4, 20 ]. however, the concept coverage is limited for resource - lean languages, and all content not present in a knowledge base is effectively ignored by a clir system. bilingual text embeddings, while displaying a wider applicability and versa', '##tility than the two other paradigms, still suffer from one important limitation : a bilingual supervision signal is required to induce shared cross - lingual semantic spaces', '. this supervision takes form of sentence - aligned parallel data [ 5 ], pre - built word translation pairs [ 11,  #TAUTHOR_TAG', 'or document - aligned comparable data [ 21 ]. 1 recently, methods for inducing shared cross - lingual embedding spaces without the need for any bilingual signal ( not even word translation pairs ) have been proposed [ 1, 3 ]. these methods exploit inherent structural similarities of induced monolingual', 'embedding spaces to learn vector space transformations that align the source language space to the target language space, with strong results observed for bilingual', 'lexicon extraction. in this work, we show that these unsupervised cross - lingual word embeddings offer strong support', 'to the construction of fully unsupervised adhoc clir models. we propose two different clir models : 1 ) termby - term translation through the shared cross - lingual space, and 2 ) query and document representations as idf - weighted', 'sums of constituent word vectors. to the best of our knowledge, our clir methodology is the first to allow the construction of clir models without any bilingual data and supervision at all, relying solely on', 'monolingual corpora. experimental evaluation on standard clef clir data for three different language pairs shows that the proposed fully unsupervised clir models outperform competitive baselines', 'and models that exploit word translation pairs or comparable corpora. our clir code and multilingual embedding spaces are publicly available at : https : / / github. com / rlitschk / unsup', '##clir']",5
['2 ) word translation pairs  #TAUTHOR_TAG ; and 3 ) no bilingual data at all'],['2 ) word translation pairs  #TAUTHOR_TAG ; and 3 ) no bilingual data at all [ 3 ]'],['2 ) word translation pairs  #TAUTHOR_TAG ; and 3 ) no bilingual data at all [ 3 ]'],"['our proposed clir models, we investigate cross - lingual embedding spaces produced with state - of - the - art representative methods requiring different amount and type of bilingual supervision : 1 ) document - aligned comparable data [ 21 ], 2 ) word translation pairs  #TAUTHOR_TAG ; and 3 ) no bilingual data at all [ 3 ]']",5
"['of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i']","['of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i. e., mappings )']","['class of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i']","['class of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i. e., mappings ) between independently trained monolingual embedding spaces.', 'let { s w i } v s i = 1, s w i ∈ r ds be the monolingual word embedding space of the source language l s with v s vectors, and { t w i } v t i = 1, t w i ∈ r dt the monolingual space for the target language l t containing v t vectors ; ds and dt are the respective space dimensionalities.', '']",5
['.  #TAUTHOR_TAG. let'],['al.  #TAUTHOR_TAG. let'],['.  #TAUTHOR_TAG. let'],"['recently, conneau et al. [ 3 ] have proposed an adversarial learning - based model in order to automatically, in a fully unsupervised fashion, create word translation pairs that can then be used to learn the same projection functions f s and f t as in the model of smith et al.  #TAUTHOR_TAG. let x be the set of all monolingual word embeddings from the source language, and y the set of all target language embeddings.', 'in the first, adversarial learning step, they jointly learn ( 1 ) the projection matrix w that maps one embedding space to the other and ( 2 ) the parameters of the discriminator model which, given an embedding vector ( either w x where x ∈ x, or ∈ y ) needs to predict whether it is an original vector from the target embedding space ( ), nor a vector from the source embedding space mapped via projection w to the target embedding space ( w x ).', 'the discriminator model is a multi - layer perceptron network.', 'in the second step, the projection matrix w trained with adversarial objective is used to find the mutual nearest neighbors between the two vocabularies - this set of automatically obtained word translation pairs becomes a synthetic training set for the refined projection functions f s and f t computed via the svd - based method similar to the previously described model of smith et al.  #TAUTHOR_TAG']",5
['.  #TAUTHOR_TAG. let'],['al.  #TAUTHOR_TAG. let'],['.  #TAUTHOR_TAG. let'],"['recently, conneau et al. [ 3 ] have proposed an adversarial learning - based model in order to automatically, in a fully unsupervised fashion, create word translation pairs that can then be used to learn the same projection functions f s and f t as in the model of smith et al.  #TAUTHOR_TAG. let x be the set of all monolingual word embeddings from the source language, and y the set of all target language embeddings.', 'in the first, adversarial learning step, they jointly learn ( 1 ) the projection matrix w that maps one embedding space to the other and ( 2 ) the parameters of the discriminator model which, given an embedding vector ( either w x where x ∈ x, or ∈ y ) needs to predict whether it is an original vector from the target embedding space ( ), nor a vector from the source embedding space mapped via projection w to the target embedding space ( w x ).', 'the discriminator model is a multi - layer perceptron network.', 'in the second step, the projection matrix w trained with adversarial objective is used to find the mutual nearest neighbors between the two vocabularies - this set of automatically obtained word translation pairs becomes a synthetic training set for the refined projection functions f s and f t computed via the svd - based method similar to the previously described model of smith et al.  #TAUTHOR_TAG']",5
"['of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i']","['of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i. e., mappings )']","['class of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i']","['class of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i. e., mappings ) between independently trained monolingual embedding spaces.', 'let { s w i } v s i = 1, s w i ∈ r ds be the monolingual word embedding space of the source language l s with v s vectors, and { t w i } v t i = 1, t w i ∈ r dt the monolingual space for the target language l t containing v t vectors ; ds and dt are the respective space dimensionalities.', '']",0
"['of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i']","['of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i. e., mappings )']","['class of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i']","['class of models [ 1, 11,  #TAUTHOR_TAG focuses on learning the projections ( i. e., mappings ) between independently trained monolingual embedding spaces.', 'let { s w i } v s i = 1, s w i ∈ r ds be the monolingual word embedding space of the source language l s with v s vectors, and { t w i } v t i = 1, t w i ∈ r dt the monolingual space for the target language l t containing v t vectors ; ds and dt are the respective space dimensionalities.', '']",0
['.  #TAUTHOR_TAG use 10k translation pairs'],['al.  #TAUTHOR_TAG use 10k translation pairs'],['.  #TAUTHOR_TAG use 10k translation pairs'],"['pairs and training data.', 'we experiment with three language pairs of varying degree of similarity : english ( en ) - { dutch ( nl ), italian ( it ), finnish ( fi ) }. 6 we use precomputed monolingual t vectors [ 2 ] ( available online ) 7 as monolingual word embeddings required by cl - wt and cl - unsup embedding models.', 'for the cl - cd embeddings, the bwesg model trains on full documentaligned wikipedias 8 using sgns with suggested parameters from prior work [ 22 ] : 15 negative samples, global decreasing learning rate is. 025, subsampling rate is 1e − 4, window size is 16.', 'the cl - wt embeddings of smith et al.  #TAUTHOR_TAG use 10k translation pairs obtained from google translate to learn the linear mapping functions.', 'the cl - unsup training setup closely follows the default setup of conneau et al. [ 3 ] : we refer the reader to the original 4 note that with both variants of bwe - agg, we effectively ignore both query and document terms that are not represented in the cross - lingual embedding space.', '5 if the representation of a query term t q i is not present in the cross - lingual embedding space, we retain the query term t q i itself.', 'we have also attempted eliminating out - ofvocabulary query terms, but the former consistently leads to better performance.', '6 english and dutch are germanic languages, italian is a romance language, whereas finnish is an uralic language ( i. e., not indo - european ) 7 table 1 : basic statistics of used clef test collections : number of documents ( # doc ), number of tokens ( # tok ), and average number of relevant documents per query ( # rel ).', 'paper and the model implementation accessible online for more information and technical details.', '9 test collections and queries.', 'we evaluate the models on the standard test collections from the clef 2000 - 2003 ad - hoc retrieval test suite.', '10 we select all nl, it, and fi document collections from years 2001 - 2003 11 and paired them with english queries from the respective year.', 'the statistics for test collections are shown in table 1.', 'following a standard practice [ 7, 21 ], queries were created by concatenating the title and the description of each clef "" topic "".', 'the test collections for years 2001 - 2003 respectively contain 50, 50, and 60 en queries.', 'queries and documents were lowercased ; stop words, punctuations and one']",4
"['small ( 2, 500 messages,  #TAUTHOR_TAG']","['small ( 2, 500 messages,  #TAUTHOR_TAG']","['are either small ( 2, 500 messages,  #TAUTHOR_TAG']","['a group of people communicate in a common channel there are often multiple conversations occurring concurrently.', 'often there is no explicit structure identifying conversations or their structure, such as in internet relay chat ( irc ), google hangout, and comment sections on websites.', 'even when structure is provided it often has limited depth, such as threads in slack, which provide one layer of branching.', 'in all of these cases, conversations are entangled : all messages appear together, with no indication of separate conversations.', 'automatic disentanglement could be used to provide more interpretable results when searching over chat logs, and to help users understand what is happening when they join a channel.', 'over a decade of research has considered conversation disentanglement  #AUTHOR_TAG, but using datasets that are either small ( 2, 500 messages,  #TAUTHOR_TAG or not released  #AUTHOR_TAG.', '* jkummerf @ umich. edu', 'we introduce a conversation disentanglement dataset of 77, 563 messages of irc manually annotated with reply - to relations between messages.', '1 our data is sampled from a technical support channel at 173 points in time between 2004 and 2018, providing a diverse set of speakers and topics, while remaining in a single domain.', 'our data is the first to include context, which differentiates messages that start a conversation from messages that are responding to an earlier point in time.', 'we are also the first to adjudicate disagreements in disentanglement annotations, producing higher quality development and test sets.', 'we also developed a simple model that is more effective than prior work, and showed that having diverse data makes it perform better and more consistently.', 'we also analyze prior disentanglement work.', 'in particular, a recent approach from  #AUTHOR_TAG lowe et al. (, 2017.', 'by applying disentanglement to an enormous log of irc messages, they developed a resource that has been widely used ( over 315 citations ), indicating the value of disentanglement in dialogue research.', 'however, they lacked annotated data to evaluate the conversations produced by their method.', 'we find that 20 % of the conversations are completely right or a prefix of a true conversation ; 58 % are missing messages, 3 % contain messages from other conversations, and 19 % have both issues.', 'as a result, systems trained on the data will not be learning from accurate humanhuman dialogues']",1
"['small ( 2, 500 messages,  #TAUTHOR_TAG']","['small ( 2, 500 messages,  #TAUTHOR_TAG']","['are either small ( 2, 500 messages,  #TAUTHOR_TAG']","['a group of people communicate in a common channel there are often multiple conversations occurring concurrently.', 'often there is no explicit structure identifying conversations or their structure, such as in internet relay chat ( irc ), google hangout, and comment sections on websites.', 'even when structure is provided it often has limited depth, such as threads in slack, which provide one layer of branching.', 'in all of these cases, conversations are entangled : all messages appear together, with no indication of separate conversations.', 'automatic disentanglement could be used to provide more interpretable results when searching over chat logs, and to help users understand what is happening when they join a channel.', 'over a decade of research has considered conversation disentanglement  #AUTHOR_TAG, but using datasets that are either small ( 2, 500 messages,  #TAUTHOR_TAG or not released  #AUTHOR_TAG.', '* jkummerf @ umich. edu', 'we introduce a conversation disentanglement dataset of 77, 563 messages of irc manually annotated with reply - to relations between messages.', '1 our data is sampled from a technical support channel at 173 points in time between 2004 and 2018, providing a diverse set of speakers and topics, while remaining in a single domain.', 'our data is the first to include context, which differentiates messages that start a conversation from messages that are responding to an earlier point in time.', 'we are also the first to adjudicate disagreements in disentanglement annotations, producing higher quality development and test sets.', 'we also developed a simple model that is more effective than prior work, and showed that having diverse data makes it perform better and more consistently.', 'we also analyze prior disentanglement work.', 'in particular, a recent approach from  #AUTHOR_TAG lowe et al. (, 2017.', 'by applying disentanglement to an enormous log of irc messages, they developed a resource that has been widely used ( over 315 citations ), indicating the value of disentanglement in dialogue research.', 'however, they lacked annotated data to evaluate the conversations produced by their method.', 'we find that 20 % of the conversations are completely right or a prefix of a true conversation ; 58 % are missing messages, 3 % contain messages from other conversations, and 19 % have both issues.', 'as a result, systems trained on the data will not be learning from accurate humanhuman dialogues']",0
"['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially re - annotated by  #AUTHOR_TAG with reply - structure graphs ), and has been used for training and']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially re - annotated by  #AUTHOR_TAG with reply - structure graphs ), and has been used for training and evaluation in subsequent', 'work  #AUTHOR_TAG. we are aware of', 'three other irc disentanglement datasets.  #AUTHOR_TAG studied disentanglement', 'and topic identification, but did not release their data.  #AUTHOR_TAG annotated conversations and discourse relations in the # ubuntu -', 'fr channel ( french ubuntu support ).  #AUTHOR_TAG lowe et al', '. (, 2017 heuristically extracted conversations from the # ubuntu channel. 2 their work opened up a new research opportunity by providing 930,', '000 disentangled conversations, and has already been the basis of many papers ( 315 citations ), particularly', 'on developing dialogue agents. this is far', 'beyond the size of resources previously collected, even with crowdsourcing  #AUTHOR_TAG.', 'using our data we provide the first empirical evaluation of their method. other disent', '##anglement data : irc is not the only form of synchronous group conversation online. other platforms', 'with similar communication formats have been studied in settings such as classes', ' #AUTHOR_TAG, support communities  #AUTHOR_TAG, and customer service  #AUTHOR_TAG. unfortunately, only one of these resources  #AUTHOR_TAG is available, possibly due to privacy concerns. another stream of', 'research has used userprovided structure to get conversation labels  #AUTHOR_TAG and replyto relations ( wang and rose, 2010 ;  #AUTHOR_TAG a ;  #AUTHOR_TAG balali et al.,, 2014  #AUTHOR_TAG a ). by removing', 'these labels and mixing conversations they create a disentanglement problem. while convenient, this risks introducing a bias, as people write differently when explicit structure is defined, and only a few papers have released data  #AUTHOR_TAG.', 'models :  #TAUTHOR_TAG explored various message - pair feature sets and linear classifiers,', 'combined with local and global inference methods. their system is the only publicly released statistical model', 'for disentanglement of chat conversation, but most of the other work cited above applied similar models. we evaluate', 'their model on both our data and our re - annotated version of their data. recent work has applied neural', 'networks  #AUTHOR_TAG  #AUTHOR_TAG 1, 500 1 48 hr 5 n / a 2 table 1 : annotated disentanglement dataset comparison. our data is much larger than prior work, one of the only released sets', "", and the only one with context and adjudication.'+ a'indicates there"", ""was an adjudication step to resolve disagreements. '?"", ""' indicates the value is not in the paper and the authors no longer have access to the data""]",0
"['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially re - annotated by  #AUTHOR_TAG with reply - structure graphs ), and has been used for training and']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially re - annotated by  #AUTHOR_TAG with reply - structure graphs ), and has been used for training and evaluation in subsequent', 'work  #AUTHOR_TAG. we are aware of', 'three other irc disentanglement datasets.  #AUTHOR_TAG studied disentanglement', 'and topic identification, but did not release their data.  #AUTHOR_TAG annotated conversations and discourse relations in the # ubuntu -', 'fr channel ( french ubuntu support ).  #AUTHOR_TAG lowe et al', '. (, 2017 heuristically extracted conversations from the # ubuntu channel. 2 their work opened up a new research opportunity by providing 930,', '000 disentangled conversations, and has already been the basis of many papers ( 315 citations ), particularly', 'on developing dialogue agents. this is far', 'beyond the size of resources previously collected, even with crowdsourcing  #AUTHOR_TAG.', 'using our data we provide the first empirical evaluation of their method. other disent', '##anglement data : irc is not the only form of synchronous group conversation online. other platforms', 'with similar communication formats have been studied in settings such as classes', ' #AUTHOR_TAG, support communities  #AUTHOR_TAG, and customer service  #AUTHOR_TAG. unfortunately, only one of these resources  #AUTHOR_TAG is available, possibly due to privacy concerns. another stream of', 'research has used userprovided structure to get conversation labels  #AUTHOR_TAG and replyto relations ( wang and rose, 2010 ;  #AUTHOR_TAG a ;  #AUTHOR_TAG balali et al.,, 2014  #AUTHOR_TAG a ). by removing', 'these labels and mixing conversations they create a disentanglement problem. while convenient, this risks introducing a bias, as people write differently when explicit structure is defined, and only a few papers have released data  #AUTHOR_TAG.', 'models :  #TAUTHOR_TAG explored various message - pair feature sets and linear classifiers,', 'combined with local and global inference methods. their system is the only publicly released statistical model', 'for disentanglement of chat conversation, but most of the other work cited above applied similar models. we evaluate', 'their model on both our data and our re - annotated version of their data. recent work has applied neural', 'networks  #AUTHOR_TAG  #AUTHOR_TAG 1, 500 1 48 hr 5 n / a 2 table 1 : annotated disentanglement dataset comparison. our data is much larger than prior work, one of the only released sets', "", and the only one with context and adjudication.'+ a'indicates there"", ""was an adjudication step to resolve disagreements. '?"", ""' indicates the value is not in the paper and the authors no longer have access to the data""]",0
"['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially re - annotated by  #AUTHOR_TAG with reply - structure graphs ), and has been used for training and']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially re - annotated by  #AUTHOR_TAG with reply - structure graphs ), and has been used for training and evaluation in subsequent', 'work  #AUTHOR_TAG. we are aware of', 'three other irc disentanglement datasets.  #AUTHOR_TAG studied disentanglement', 'and topic identification, but did not release their data.  #AUTHOR_TAG annotated conversations and discourse relations in the # ubuntu -', 'fr channel ( french ubuntu support ).  #AUTHOR_TAG lowe et al', '. (, 2017 heuristically extracted conversations from the # ubuntu channel. 2 their work opened up a new research opportunity by providing 930,', '000 disentangled conversations, and has already been the basis of many papers ( 315 citations ), particularly', 'on developing dialogue agents. this is far', 'beyond the size of resources previously collected, even with crowdsourcing  #AUTHOR_TAG.', 'using our data we provide the first empirical evaluation of their method. other disent', '##anglement data : irc is not the only form of synchronous group conversation online. other platforms', 'with similar communication formats have been studied in settings such as classes', ' #AUTHOR_TAG, support communities  #AUTHOR_TAG, and customer service  #AUTHOR_TAG. unfortunately, only one of these resources  #AUTHOR_TAG is available, possibly due to privacy concerns. another stream of', 'research has used userprovided structure to get conversation labels  #AUTHOR_TAG and replyto relations ( wang and rose, 2010 ;  #AUTHOR_TAG a ;  #AUTHOR_TAG balali et al.,, 2014  #AUTHOR_TAG a ). by removing', 'these labels and mixing conversations they create a disentanglement problem. while convenient, this risks introducing a bias, as people write differently when explicit structure is defined, and only a few papers have released data  #AUTHOR_TAG.', 'models :  #TAUTHOR_TAG explored various message - pair feature sets and linear classifiers,', 'combined with local and global inference methods. their system is the only publicly released statistical model', 'for disentanglement of chat conversation, but most of the other work cited above applied similar models. we evaluate', 'their model on both our data and our re - annotated version of their data. recent work has applied neural', 'networks  #AUTHOR_TAG  #AUTHOR_TAG 1, 500 1 48 hr 5 n / a 2 table 1 : annotated disentanglement dataset comparison. our data is much larger than prior work, one of the only released sets', "", and the only one with context and adjudication.'+ a'indicates there"", ""was an adjudication step to resolve disagreements. '?"", ""' indicates the value is not in the paper and the authors no longer have access to the data""]",5
"['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially re - annotated by  #AUTHOR_TAG with reply - structure graphs ), and has been used for training and']","['channel  #TAUTHOR_TAG 2011 ). until now, their dataset was the only publicly available set of messages with annotated conversations', '( partially re - annotated by  #AUTHOR_TAG with reply - structure graphs ), and has been used for training and evaluation in subsequent', 'work  #AUTHOR_TAG. we are aware of', 'three other irc disentanglement datasets.  #AUTHOR_TAG studied disentanglement', 'and topic identification, but did not release their data.  #AUTHOR_TAG annotated conversations and discourse relations in the # ubuntu -', 'fr channel ( french ubuntu support ).  #AUTHOR_TAG lowe et al', '. (, 2017 heuristically extracted conversations from the # ubuntu channel. 2 their work opened up a new research opportunity by providing 930,', '000 disentangled conversations, and has already been the basis of many papers ( 315 citations ), particularly', 'on developing dialogue agents. this is far', 'beyond the size of resources previously collected, even with crowdsourcing  #AUTHOR_TAG.', 'using our data we provide the first empirical evaluation of their method. other disent', '##anglement data : irc is not the only form of synchronous group conversation online. other platforms', 'with similar communication formats have been studied in settings such as classes', ' #AUTHOR_TAG, support communities  #AUTHOR_TAG, and customer service  #AUTHOR_TAG. unfortunately, only one of these resources  #AUTHOR_TAG is available, possibly due to privacy concerns. another stream of', 'research has used userprovided structure to get conversation labels  #AUTHOR_TAG and replyto relations ( wang and rose, 2010 ;  #AUTHOR_TAG a ;  #AUTHOR_TAG balali et al.,, 2014  #AUTHOR_TAG a ). by removing', 'these labels and mixing conversations they create a disentanglement problem. while convenient, this risks introducing a bias, as people write differently when explicit structure is defined, and only a few papers have released data  #AUTHOR_TAG.', 'models :  #TAUTHOR_TAG explored various message - pair feature sets and linear classifiers,', 'combined with local and global inference methods. their system is the only publicly released statistical model', 'for disentanglement of chat conversation, but most of the other work cited above applied similar models. we evaluate', 'their model on both our data and our re - annotated version of their data. recent work has applied neural', 'networks  #AUTHOR_TAG  #AUTHOR_TAG 1, 500 1 48 hr 5 n / a 2 table 1 : annotated disentanglement dataset comparison. our data is much larger than prior work, one of the only released sets', "", and the only one with context and adjudication.'+ a'indicates there"", ""was an adjudication step to resolve disagreements. '?"", ""' indicates the value is not in the paper and the authors no longer have access to the data""]",5
"['linux data enables comparison with  #TAUTHOR_TAG, while']","['# linux irc channel.', '4 annotating the # linux data enables comparison with  #TAUTHOR_TAG, while']","['##3 messages : 74, 963 from the # ubuntu irc channel, 3 and 2, 600 messages from the # linux irc channel.', '4 annotating the # linux data enables comparison with  #TAUTHOR_TAG, while']","['introduce a manually annotated dataset of 77, 563 messages : 74, 963 from the # ubuntu irc channel, 3 and 2, 600 messages from the # linux irc channel.', '4 annotating the # linux data enables comparison with  #TAUTHOR_TAG, while the # ubuntu channel has over 34 million messages, making it an interesting largescale resource for dialogue research.', ""it also allows us to evaluate  #AUTHOR_TAG lowe et al. (, 2017's widely used heuristically disentangled conversations."", 'when choosing samples we had to strike a balance between the number of samples and the size of each one.', 'we sampled the training set in three ways : ( 1 ) 95 uniform length samples, ( 2 ) 10 smaller samples to check annotator agreement, and ( 3 ) 48 time spans of one hour that are diverse in terms of the number of messages, the number of participants, and what percentage of messages are directed.', 'for additional details of the data selection process, see the supplementary material']",5
"['( 1 - 1,  #TAUTHOR_TAG.', 'percentage overlap when conversations from two annotations']","['( 1 - 1,  #TAUTHOR_TAG.', 'percentage overlap when conversations from two annotations']","['that larger values are better.', '( 2 ) one - to - one overlap ( 1 - 1,  #TAUTHOR_TAG.', 'percentage overlap when conversations from two annotations are optimally paired up using the max - flow algorithm.', 'we follow  #AUTHOR_TAG']","['consider three metrics : 6 ( 1 ) variation of information ( vi,  #AUTHOR_TAG.', 'a measure of information gained or lost when going from one clustering to another.', 'it is the sum of conditional entropies h ( y | x ) + h ( x | y ), where x and y are clusterings of the same set of items.', 'we consider a scaled version, using the bound for n items that vi ( x ; y ) ≤ log ( n ), and present 1−vi so that larger values are better.', '( 2 ) one - to - one overlap ( 1 - 1,  #TAUTHOR_TAG.', 'percentage overlap when conversations from two annotations are optimally paired up using the max - flow algorithm.', 'we follow  #AUTHOR_TAG and keep system messages.', '( 3 ) exact match f 1.', 'calculated using the number of perfectly matching conversations, excluding conversations with only one message ( mostly system messages ).', 'this is an extremely challenging metric.', 'we include it because it is easy to understand and it directly measures a desired value ( perfectly extracted conversations ).', 'our scores are higher in 4 cases and lower in 5.', 'interestingly, while κ was higher for us than  #AUTHOR_TAG, our scores for conversations are lower.', 'this is possible because a single link can merge two conversations, meaning a single disagreement in links can cause a major difference in conversations.', 'this may reflect the fact that our annotation guide was developed for the ubuntu channel, which differs in conversation style from the channel two data.', 'manually comparing the annotations, there was no clear differences in the types of disagreements.', 'agreement is lower on the channel two data, particularly on its test set.', 'from this we conclude that there is substantial variation in the difficulty of conversation disentanglement across datasets.', '']",5
"['forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across']","['forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across']","['it forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across the exact conversation extraction metrics.', 'third, our methods do best, with x10 vote best in all cases except precision, where the intersect approach is much better.', 'dataset variations : table 5 shows results for the feedforward model with several modifications to the training set, designed to test corpus design decisions.', 'removing context does not substantially impact results.', ""decreasing the data size to match  #TAUTHOR_TAG's training set leads to worse results, both if the sentences are from diverse contexts (""]","['', 'our models perform much better than the baseline.', 'as we would expect, vote has higher precision, while union has higher recall.', 'vote has higher recall than a single feedforward model because it identifies more of the selflink cases ( its default when there is no agreement ).', 'conversations : table 4 presents results on the metrics defined in section 4. 3.', 'there are three regions of performance.', 'first, the baseline has consistently low scores since it forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across the exact conversation extraction metrics.', 'third, our methods do best, with x10 vote best in all cases except precision, where the intersect approach is much better.', 'dataset variations : table 5 shows results for the feedforward model with several modifications to the training set, designed to test corpus design decisions.', 'removing context does not substantially impact results.', ""decreasing the data size to match  #TAUTHOR_TAG's training set leads to worse results, both if the sentences are from diverse contexts ( 3rd row ), and if they are from just two contexts ( bottom row )."", 'we also see a substantial increase in the standard deviation when only two samples are used, indicating that performance is not robust when the data is not widely sampled']",5
"['forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across']","['forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across']","['it forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across the exact conversation extraction metrics.', 'third, our methods do best, with x10 vote best in all cases except precision, where the intersect approach is much better.', 'dataset variations : table 5 shows results for the feedforward model with several modifications to the training set, designed to test corpus design decisions.', 'removing context does not substantially impact results.', ""decreasing the data size to match  #TAUTHOR_TAG's training set leads to worse results, both if the sentences are from diverse contexts (""]","['', 'our models perform much better than the baseline.', 'as we would expect, vote has higher precision, while union has higher recall.', 'vote has higher recall than a single feedforward model because it identifies more of the selflink cases ( its default when there is no agreement ).', 'conversations : table 4 presents results on the metrics defined in section 4. 3.', 'there are three regions of performance.', 'first, the baseline has consistently low scores since it forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across the exact conversation extraction metrics.', 'third, our methods do best, with x10 vote best in all cases except precision, where the intersect approach is much better.', 'dataset variations : table 5 shows results for the feedforward model with several modifications to the training set, designed to test corpus design decisions.', 'removing context does not substantially impact results.', ""decreasing the data size to match  #TAUTHOR_TAG's training set leads to worse results, both if the sentences are from diverse contexts ( 3rd row ), and if they are from just two contexts ( bottom row )."", 'we also see a substantial increase in the standard deviation when only two samples are used, indicating that performance is not robust when the data is not widely sampled']",5
"[""underlying text : ours and  #TAUTHOR_TAG's."", 'to compare with prior work,']","[""underlying text : ours and  #TAUTHOR_TAG's."", 'to compare with prior work,']","[""two annotations of the same underlying text : ours and  #TAUTHOR_TAG's."", 'to compare with prior work, we use the metrics defined by  #AUTHOR_TAG, shen ) and  #AUTHOR_TAG, loc ).', '8 we do not use these for our data']","[""channel two, we consider two annotations of the same underlying text : ours and  #TAUTHOR_TAG's."", 'to compare with prior work, we use the metrics defined by  #AUTHOR_TAG, shen ) and  #AUTHOR_TAG, loc ).', '8 we do not use these for our data as they have been superseded by more rigorously studied metrics ( vi for shen ) or make strong assumptions about the data ( loc ).', ""we do not evaluate on graphs because  #TAUTHOR_TAG's annotations do not include them."", 'this also prevents us from training our method on their data.', ""model comparison : for elsner's annotations ( top section of table 6 ), their approach remains the most effective with just channel two data."", 'however, training on our ubuntu data, treating channel two as an out - of - domain sample, yields substantially higher performance on two metrics and comparable performance on the third.', 'on our annotations ( bottom section ), we see the same trend.', 'in both cases, the heuristic from  #AUTHOR_TAG lowe et al. (, 2017 performs poorly.', 'we suspect our model trained only on channel two data is overfitting, as the graph f - score on the training data is 94, whereas on the ubuntu data it is 80.', '']",5
"[""underlying text : ours and  #TAUTHOR_TAG's."", 'to compare with prior work,']","[""underlying text : ours and  #TAUTHOR_TAG's."", 'to compare with prior work,']","[""two annotations of the same underlying text : ours and  #TAUTHOR_TAG's."", 'to compare with prior work, we use the metrics defined by  #AUTHOR_TAG, shen ) and  #AUTHOR_TAG, loc ).', '8 we do not use these for our data']","[""channel two, we consider two annotations of the same underlying text : ours and  #TAUTHOR_TAG's."", 'to compare with prior work, we use the metrics defined by  #AUTHOR_TAG, shen ) and  #AUTHOR_TAG, loc ).', '8 we do not use these for our data as they have been superseded by more rigorously studied metrics ( vi for shen ) or make strong assumptions about the data ( loc ).', ""we do not evaluate on graphs because  #TAUTHOR_TAG's annotations do not include them."", 'this also prevents us from training our method on their data.', ""model comparison : for elsner's annotations ( top section of table 6 ), their approach remains the most effective with just channel two data."", 'however, training on our ubuntu data, treating channel two as an out - of - domain sample, yields substantially higher performance on two metrics and comparable performance on the third.', 'on our annotations ( bottom section ), we see the same trend.', 'in both cases, the heuristic from  #AUTHOR_TAG lowe et al. (, 2017 performs poorly.', 'we suspect our model trained only on channel two data is overfitting, as the graph f - score on the training data is 94, whereas on the ubuntu data it is 80.', '']",5
"['as these.', ""in channel two, we also see mistakes and ambiguous cases, including a particularly long discussion about a user's financial difficulties that could be divided in multiple ways ( also noted by  #TAUTHOR_TAG."", ""graphs : we measure agreement on the graph structure annotation using  #AUTHOR_TAG's κ."", 'this']","['as these.', ""in channel two, we also see mistakes and ambiguous cases, including a particularly long discussion about a user's financial difficulties that could be divided in multiple ways ( also noted by  #TAUTHOR_TAG."", ""graphs : we measure agreement on the graph structure annotation using  #AUTHOR_TAG's κ."", 'this']","['as these.', ""in channel two, we also see mistakes and ambiguous cases, including a particularly long discussion about a user's financial difficulties that could be divided in multiple ways ( also noted by  #TAUTHOR_TAG."", ""graphs : we measure agreement on the graph structure annotation using  #AUTHOR_TAG's κ."", 'this measure of inter - rater reliability corrects for chance agreement, accounting']","['annotations define two levels of structure : ( 1 ) links between pairs of messages, and ( 2 ) sets of messages, where each set is one conversation.', 'annotators label ( 1 ), from which ( 2 ) can be inferred.', 'table 2 presents inter - annotator agreement measures for both cases.', 'these are measured in the standard manner, by comparing the labels from different annotators on the same data.', 'we also include measurements for annotations in prior work.', 'figure 2 shows ambiguous examples from our data to provide some intuition for the source of disagreements.', 'in both examples the disagreement involves one link, but the conversation structure in the second case is substantially changed.', 'some disagreements in our data are mistakes, where one annotation is clearly incorrect, and some are ambiguous cases, such as these.', ""in channel two, we also see mistakes and ambiguous cases, including a particularly long discussion about a user's financial difficulties that could be divided in multiple ways ( also noted by  #TAUTHOR_TAG."", ""graphs : we measure agreement on the graph structure annotation using  #AUTHOR_TAG's κ."", 'this measure of inter - rater reliability corrects for chance agreement, accounting for the class imbalance between linked and not - linked pairs.', ""values are in the good agreement range proposed by  #AUTHOR_TAG, and slightly higher than for  #AUTHOR_TAG's annotations."", 'results are not shown for  #TAUTHOR_TAG because they did not annotate graphs']",3
"['as these.', ""in channel two, we also see mistakes and ambiguous cases, including a particularly long discussion about a user's financial difficulties that could be divided in multiple ways ( also noted by  #TAUTHOR_TAG."", ""graphs : we measure agreement on the graph structure annotation using  #AUTHOR_TAG's κ."", 'this']","['as these.', ""in channel two, we also see mistakes and ambiguous cases, including a particularly long discussion about a user's financial difficulties that could be divided in multiple ways ( also noted by  #TAUTHOR_TAG."", ""graphs : we measure agreement on the graph structure annotation using  #AUTHOR_TAG's κ."", 'this']","['as these.', ""in channel two, we also see mistakes and ambiguous cases, including a particularly long discussion about a user's financial difficulties that could be divided in multiple ways ( also noted by  #TAUTHOR_TAG."", ""graphs : we measure agreement on the graph structure annotation using  #AUTHOR_TAG's κ."", 'this measure of inter - rater reliability corrects for chance agreement, accounting']","['annotations define two levels of structure : ( 1 ) links between pairs of messages, and ( 2 ) sets of messages, where each set is one conversation.', 'annotators label ( 1 ), from which ( 2 ) can be inferred.', 'table 2 presents inter - annotator agreement measures for both cases.', 'these are measured in the standard manner, by comparing the labels from different annotators on the same data.', 'we also include measurements for annotations in prior work.', 'figure 2 shows ambiguous examples from our data to provide some intuition for the source of disagreements.', 'in both examples the disagreement involves one link, but the conversation structure in the second case is substantially changed.', 'some disagreements in our data are mistakes, where one annotation is clearly incorrect, and some are ambiguous cases, such as these.', ""in channel two, we also see mistakes and ambiguous cases, including a particularly long discussion about a user's financial difficulties that could be divided in multiple ways ( also noted by  #TAUTHOR_TAG."", ""graphs : we measure agreement on the graph structure annotation using  #AUTHOR_TAG's κ."", 'this measure of inter - rater reliability corrects for chance agreement, accounting for the class imbalance between linked and not - linked pairs.', ""values are in the good agreement range proposed by  #AUTHOR_TAG, and slightly higher than for  #AUTHOR_TAG's annotations."", 'results are not shown for  #TAUTHOR_TAG because they did not annotate graphs']",4
"['forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across']","['forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across']","['it forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across the exact conversation extraction metrics.', 'third, our methods do best, with x10 vote best in all cases except precision, where the intersect approach is much better.', 'dataset variations : table 5 shows results for the feedforward model with several modifications to the training set, designed to test corpus design decisions.', 'removing context does not substantially impact results.', ""decreasing the data size to match  #TAUTHOR_TAG's training set leads to worse results, both if the sentences are from diverse contexts (""]","['', 'our models perform much better than the baseline.', 'as we would expect, vote has higher precision, while union has higher recall.', 'vote has higher recall than a single feedforward model because it identifies more of the selflink cases ( its default when there is no agreement ).', 'conversations : table 4 presents results on the metrics defined in section 4. 3.', 'there are three regions of performance.', 'first, the baseline has consistently low scores since it forms a single conversation containing all messages.', 'second,  #TAUTHOR_TAG do consistently better across the exact conversation extraction metrics.', 'third, our methods do best, with x10 vote best in all cases except precision, where the intersect approach is much better.', 'dataset variations : table 5 shows results for the feedforward model with several modifications to the training set, designed to test corpus design decisions.', 'removing context does not substantially impact results.', ""decreasing the data size to match  #TAUTHOR_TAG's training set leads to worse results, both if the sentences are from diverse contexts ( 3rd row ), and if they are from just two contexts ( bottom row )."", 'we also see a substantial increase in the standard deviation when only two samples are used, indicating that performance is not robust when the data is not widely sampled']",4
"['apart consecutive messages in a conversation are :  #TAUTHOR_TAG and  #AUTHOR_TAG use a limit of 129 seconds,  #AUTHOR_TAG limit']","['apart consecutive messages in a conversation are :  #TAUTHOR_TAG and  #AUTHOR_TAG use a limit of 129 seconds,  #AUTHOR_TAG limit']","['.', 'this demonstrates the importance of evaluating on data from more than one point in time to get a robust estimate of performance.', 'how far apart consecutive messages in a conversation are :  #TAUTHOR_TAG and  #AUTHOR_TAG use a limit of 129 seconds,  #AUTHOR_TAG limit']","['', 'this demonstrates the importance of evaluating on data from more than one point in time to get a robust estimate of performance.', 'how far apart consecutive messages in a conversation are :  #TAUTHOR_TAG and  #AUTHOR_TAG use a limit of 129 seconds,  #AUTHOR_TAG limit to within 1 hour,  #AUTHOR_TAG limit to within 8 messages, and we limit to within 100 messages.', 'figure 4 shows the distribution of time differences in our conversations.', '']",4
"['##2vec package available in  #TAUTHOR_TAG.', 'these models proved to be robust']","['capture.', 'in particular, we are interested in the word2vec package available in  #TAUTHOR_TAG.', 'these models proved to be robust']","['', 'in particular, we are interested in the word2vec package available in  #TAUTHOR_TAG.', 'these models proved to be robust']","['translation ( mt ) systems are nowadays achieving a high - quality performance.', 'however, they are typically developed at sentence level using only local information and ignoring the document - level one.', 'recent work claims that discourse - wide context can help to translate individual words in a way that leads to more coherent translations  #AUTHOR_TAG.', 'standard smt systems use n - gram models to represent words in the target language.', 'however, there are other word representation techniques that use vectors of contextual information.', 'recently, several distributed word representation models have been introduced that have interesting properties regarding to the semantic information that they capture.', 'in particular, we are interested in the word2vec package available in  #TAUTHOR_TAG.', 'these models proved to be robust and powerful for predicting semantic relations between words and even across languages.', 'however, they are not able to handle lexical ambiguity as they conflate word senses of polysemous words into one common representation.', 'this limitation is already discussed in  #AUTHOR_TAG b ) and in  #AUTHOR_TAG, in which bilingual extensions of the word2vec architecture are proposed.', 'in contrast to their approach, we are not interested in monolingual applications but instead like to concentrate directly on the bilingual case in connection with mt.', 'we built bilingual word representation models based on word - aligned parallel corpora by an application of the continuous bag - of - words ( cbow ) algorithm to the bilingual case ( section 2 ).', 'we made a twofold preliminary evaluation of the acquired word - pair representations on two different tasks ( section 3 ) : predicting semantically related words ( 3. 1 ) and cross - lingual lexical substitution ( 3. 2 ).', 'section 4 draws the conclusions and sets the future work in a direct application of these models to mt']",1
['in  #TAUTHOR_TAG for a cbow architecture but trained with 783'],['in  #TAUTHOR_TAG for a cbow architecture but trained with 783'],['in  #TAUTHOR_TAG for a cbow architecture but trained with 783 million words ( 50. 4'],"['first evaluate the quality of the models based on the task of predicting semantically related words.', 'a spanish native speaker built the bilingual test set similarly to the process done to the training data from a list of 19, 544 questions introduced by  #AUTHOR_TAG c ).', 'in our bilingual scenario, the task is to predict a pair of words given two pairs of related words.', 'for instance, given the pair athens | atenas greece | grecia and the question london | londres, the task is to predict england | inglaterra.', 'table 1 shows the results, both overall accuracy and accuracy over the known words for the models.', 'using the first 30, 000 entries of the model ( the most frequent ones ), we obtain 32 % of accuracy for english ( mono en ) and 10 % for spanish ( mono es ).', 'we chose these parameters for our system to obtain comparable results to the ones in  #TAUTHOR_TAG for a cbow architecture but trained with 783 million words ( 50. 4 % ).', 'decay for the model in spanish can be due to the fact that it was built from automatic translations.', 'in the bilingual case ( bi en - es ), the accuracy is lower than for english probably due to the noise in translations and word alignment']",1
"[' #TAUTHOR_TAG.', '']","[' #TAUTHOR_TAG.', '']","['##ow  #TAUTHOR_TAG.', 'the algorithm uses a neural network (']","['basic architecture that we use to build our models is cbow  #TAUTHOR_TAG.', 'the algorithm uses a neural network ( nn ) to predict a word taking into account its context, but without considering word order.', 'despite its drawbacks, we chose to use it since we presume that the translation task applies the same strategy as the cbow architecture, i. e., from a set of context words try to predict a translation of a specific given word.', 'in the monolingual case, the nn is trained using a monolingual corpus to obtain the corresponding projection matrix that encloses the vector representations of the words.', 'in order to introduce the semantic information in a bilingual scenario, we use a parallel corpus and automatic word alignment to extract a training corpus of word pairs : ( w i, s | w i, t ).', 'this approach is different from  #AUTHOR_TAG who build an independent model for each language.', 'with our method, we try to capture simultaneously the semantic information associated to the source word and the information in the target side of the translation.', 'in this way, we hope to better capture the semantic information that is implicitly given by translating a text']",5
['in  #TAUTHOR_TAG for a cbow architecture but trained with 783'],['in  #TAUTHOR_TAG for a cbow architecture but trained with 783'],['in  #TAUTHOR_TAG for a cbow architecture but trained with 783 million words ( 50. 4'],"['first evaluate the quality of the models based on the task of predicting semantically related words.', 'a spanish native speaker built the bilingual test set similarly to the process done to the training data from a list of 19, 544 questions introduced by  #AUTHOR_TAG c ).', 'in our bilingual scenario, the task is to predict a pair of words given two pairs of related words.', 'for instance, given the pair athens | atenas greece | grecia and the question london | londres, the task is to predict england | inglaterra.', 'table 1 shows the results, both overall accuracy and accuracy over the known words for the models.', 'using the first 30, 000 entries of the model ( the most frequent ones ), we obtain 32 % of accuracy for english ( mono en ) and 10 % for spanish ( mono es ).', 'we chose these parameters for our system to obtain comparable results to the ones in  #TAUTHOR_TAG for a cbow architecture but trained with 783 million words ( 50. 4 % ).', 'decay for the model in spanish can be due to the fact that it was built from automatic translations.', 'in the bilingual case ( bi en - es ), the accuracy is lower than for english probably due to the noise in translations and word alignment']",3
"[' #TAUTHOR_TAG, in that argument']","[' #TAUTHOR_TAG, in that argument']","[' #TAUTHOR_TAG, in that argument extraction']",[' #TAUTHOR_TAG'],3
['in  #TAUTHOR_TAG with'],['in  #TAUTHOR_TAG with'],['in  #TAUTHOR_TAG with the model'],"['first evaluate the components for which we introduce new features.', 'we use gold annotations for evaluating the individual components below.', 'explicit sense classifier : table 2 evaluates the explicit sense classifier.', 'we compare our baseline model that implements the features proposed in  #TAUTHOR_TAG with the model that employs additional features introduced in 4. 4.', '']",4
['in  #TAUTHOR_TAG with'],['in  #TAUTHOR_TAG with'],['in  #TAUTHOR_TAG with the model'],"['first evaluate the components for which we introduce new features.', 'we use gold annotations for evaluating the individual components below.', 'explicit sense classifier : table 2 evaluates the explicit sense classifier.', 'we compare our baseline model that implements the features proposed in  #TAUTHOR_TAG with the model that employs additional features introduced in 4. 4.', '']",4
"['networks  #TAUTHOR_TAG ; 2012 ), s - ls']","['networks  #TAUTHOR_TAG ; 2012 ), s - lstm has the potentials of avoiding gradient vanishing']","[' #TAUTHOR_TAG ; 2012 ), s - ls']","['years have seen a revival of the long short - term memory ( lstm )  #AUTHOR_TAG, with its effectiveness being demonstrated on a wide range of problems such as speech recognition  #AUTHOR_TAG, machine translation  #AUTHOR_TAG, and image - to - text conversion, on february 6th, 2015, this work was submitted to the international conference on machine learning ( icml ).', 'among many others, in which history is summarized and coded in the memory cell in a full - order time sequence.', 'recursion is a fundamental process associated with many problems - a recursive process and hierarchical structure so formed are common in different modalities.', 'for example, semantics of sentences in human languages is believed to be carried by not merely a linear concatenation of words ; instead, sentences have parse structures ( manning & schutze, 1999 ).', 'image understanding, as another example, benefits from recursive modeling over structures, which yielded the state - of - the - art performance on tasks like scene segmentation  #AUTHOR_TAG.', 'in this paper, we extend lstm to tree structures, in which we learn memory cells that can reflect the history memories of multiple child cells and hence multiple descendant cells.', 'we call the model s - lstm.', 'compared with previous recursive neural networks  #TAUTHOR_TAG ; 2012 ), s - lstm has the potentials of avoiding gradient vanishing and hence may model long - distance interaction over trees.', 'this is a desirable characteristic as many of such structures are deep.', 's - lstm can be considered as bringing the merits of a recursive neural network and a recurrent neural network togetherstanford sentiment tree bank  #TAUTHOR_TAG to determine the sentiment for different granularities of phrases in a tree.', ' #TAUTHOR_TAG provides with human annotations at all nodes of the trees, enabling us to comprehensively explore the properties of s - lstm.', 'we experimentally show that s - lstm outperforms a stateof - the - art recursive model by simply replacing the original tensor - enhanced composition with the s - lstm memory block we propose here.', 'we showed that utilizing the given structures is helpful in achieving a better performance than that without considering the structures']",4
"['in natural language processing and image segmentation  #TAUTHOR_TAG ; 2011 ).', ' #TAUTHOR_TAG are defined over']","['in natural language processing and image segmentation  #TAUTHOR_TAG ; 2011 ).', ' #TAUTHOR_TAG are defined over']","['as semantic analysis in natural language processing and image segmentation  #TAUTHOR_TAG ; 2011 ).', ' #TAUTHOR_TAG are defined over']","['neural networks recursion is a fundamental process in different modalities.', 'in recent years, recursive neural networks ( rvnn ) have been introduced and demonstrated to achieve state - of - the - art performances on different problems such as semantic analysis in natural language processing and image segmentation  #TAUTHOR_TAG ; 2011 ).', '']",4
['structures  #TAUTHOR_TAG. the major difference'],['structures  #TAUTHOR_TAG. the major difference'],['parameter can be calculated efficiently via backpropagation over structures  #TAUTHOR_TAG. the major difference'],"['memory block is specified in the following equations. where σ is the element - wise logistic function used to confine the', 'gating signals to be in the range of [ 0, 1 ] ; f l and f r are the left and right forget gate, respectively ; b is bias and w is network weight matrices ; the sign', '⊗ is a hadamard product, i. e., element - wise product. the subscripts of the weight matrices', 'indicate what they are used for. for example, w ho is a matrix mapping a hidden', 'vector to an output gate. backpropagation over structures during training, the gradient of the objective function with respect to each parameter can be calculated efficiently via backpropagation over structures  #TAUTHOR_TAG. the major difference from that of  #TAUTHOR_TAG', 'is we use lstm - like backpropagation, where unlike a regular lstm, pass of error needs to discriminate between the left and right', 'children, or in a topology with more than two children, needs to discriminate between children', '. obtaining the backprop formulas is tedious but we list them below to facilitate duplication of our work 2', '. we will discuss the specific objective function later in experiments. for each memory block, assume that the error passed to the hidden vector is o 2 the code will be published at www. icml - placeholderonly. com where σ ′ ( x ) is the element - wise derivative of the logistic function over vector x. since it can be computed with the activation', 'of x, we abuse the notation a bit to write it over the', 'activated vectors in these equations. o c t is the derivative over the cell vector.', '']",4
"['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the accuracies of different models on the test set of the  #TAUTHOR_TAG.', 'we present the results on']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the accuracies of different models on the test set of the  #TAUTHOR_TAG.', 'we present the results on 5 - category sentiment prediction at both the sentence level ( i. e., the roots column in the table ) and for all phrases including roots ( the phrases column ) 3.', '']",4
"['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the accuracies of different models on the test set of the  #TAUTHOR_TAG.', 'we present the results on']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the accuracies of different models on the test set of the  #TAUTHOR_TAG.', 'we present the results on 5 - category sentiment prediction at both the sentence level ( i. e., the roots column in the table ) and for all phrases including roots ( the phrases column ) 3.', '']",4
"['not correspond to that in the  #TAUTHOR_TAG, but the roots and']","['these models', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and leafs annotations are still the', '']","['since for these models', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and']","['', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and leafs annotations are still the', 'same, so we run two versions of our experiments : one uses only training signals from roots and the other includes also leaf annotations.', 'it can be observed from table 3 that the given parsing structure helps improve', 'the predictive accuracy. in the case of using only root labels, the left recursive s - lstm and right recursive s - lstm have similar performance ( 40. 2', 'and 40. 3, respectively ), both inferior to s - lstm ( 43. 5 ). when using gold leaf labels', ', the gaps', 'are smaller, but still, using the parse structure are better. note that in real applications, where there is no out - of - vocabulary issue (', 'i. e., some leafs are not seen in the sentiment dictionaries ), the', 'difference between s - lstm and the recursive version without using the structures are expected to be between the gaps', 'we observed here']",4
"['benchmark data  #TAUTHOR_TAG.', '']","['benchmark data  #TAUTHOR_TAG.', '']","['phrases in a tree, within the stanford sentiment tree bank benchmark data  #TAUTHOR_TAG.', '']","['discussed earlier, recursion is a basic process inherent to many problems.', 'in this paper, we leverage the proposed model to solve semantic composition for the meanings of pieces of text, a fundamental problem in understanding human languages.', 'we specifically attempt to determine the sentiment of different granularities of phrases in a tree, within the stanford sentiment tree bank benchmark data  #TAUTHOR_TAG.', 'in obtaining the sentiment of a long piece of text, early work often factorized the problem to consider smaller pieces of component words or phrases with bag - of - words or bag - ofphrases models  #AUTHOR_TAG.', 'more recent work has started to model composition  #AUTHOR_TAG, a more principled approach to modeling the formation of semantics.', 'in this paper, we put the proposed lstm memory blocks at tree nodes - we replaced the tensorenhanced composition layer at each tree node presented in  #TAUTHOR_TAG with a s - lstm memory block.', 'we used the  #TAUTHOR_TAG, the stanford sentiment tree bank, to evaluate the performances of the models.', 'in addition to being a benchmark for much previous work,  #TAUTHOR_TAG provide with human annotations at all nodes of the trees, facilitating a more comprehensive exploration of the properties of s - lstm']",6
"['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the accuracies of different models on the test set of the  #TAUTHOR_TAG.', 'we present the results on']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the accuracies of different models on the test set of the  #TAUTHOR_TAG.', 'we present the results on 5 - category sentiment prediction at both the sentence level ( i. e., the roots column in the table ) and for all phrases including roots ( the phrases column ) 3.', '']",7
"['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the accuracies of different models on the test set of the  #TAUTHOR_TAG.', 'we present the results on']","['the default setting, we conducted experiments as in  #TAUTHOR_TAG.', 'table 1 shows the accuracies of different models on the test set of the  #TAUTHOR_TAG.', 'we present the results on 5 - category sentiment prediction at both the sentence level ( i. e., the roots column in the table ) and for all phrases including roots ( the phrases column ) 3.', '']",7
"['not correspond to that in the  #TAUTHOR_TAG, but the roots and']","['these models', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and leafs annotations are still the', '']","['since for these models', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and']","['', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and leafs annotations are still the', 'same, so we run two versions of our experiments : one uses only training signals from roots and the other includes also leaf annotations.', 'it can be observed from table 3 that the given parsing structure helps improve', 'the predictive accuracy. in the case of using only root labels, the left recursive s - lstm and right recursive s - lstm have similar performance ( 40. 2', 'and 40. 3, respectively ), both inferior to s - lstm ( 43. 5 ). when using gold leaf labels', ', the gaps', 'are smaller, but still, using the parse structure are better. note that in real applications, where there is no out - of - vocabulary issue (', 'i. e., some leafs are not seen in the sentiment dictionaries ), the', 'difference between s - lstm and the recursive version without using the structures are expected to be between the gaps', 'we observed here']",7
"['not correspond to that in the  #TAUTHOR_TAG, but the roots and']","['these models', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and leafs annotations are still the', '']","['since for these models', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and']","['', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and leafs annotations are still the', 'same, so we run two versions of our experiments : one uses only training signals from roots and the other includes also leaf annotations.', 'it can be observed from table 3 that the given parsing structure helps improve', 'the predictive accuracy. in the case of using only root labels, the left recursive s - lstm and right recursive s - lstm have similar performance ( 40. 2', 'and 40. 3, respectively ), both inferior to s - lstm ( 43. 5 ). when using gold leaf labels', ', the gaps', 'are smaller, but still, using the parse structure are better. note that in real applications, where there is no out - of - vocabulary issue (', 'i. e., some leafs are not seen in the sentiment dictionaries ), the', 'difference between s - lstm and the recursive version without using the structures are expected to be between the gaps', 'we observed here']",2
"['not correspond to that in the  #TAUTHOR_TAG, but the roots and']","['these models', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and leafs annotations are still the', '']","['since for these models', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and']","['', ', phrase - level training signals are not available - the nodes here do not correspond to that in the  #TAUTHOR_TAG, but the roots and leafs annotations are still the', 'same, so we run two versions of our experiments : one uses only training signals from roots and the other includes also leaf annotations.', 'it can be observed from table 3 that the given parsing structure helps improve', 'the predictive accuracy. in the case of using only root labels, the left recursive s - lstm and right recursive s - lstm have similar performance ( 40. 2', 'and 40. 3, respectively ), both inferior to s - lstm ( 43. 5 ). when using gold leaf labels', ', the gaps', 'are smaller, but still, using the parse structure are better. note that in real applications, where there is no out - of - vocabulary issue (', 'i. e., some leafs are not seen in the sentiment dictionaries ), the', 'difference between s - lstm and the recursive version without using the structures are expected to be between the gaps', 'we observed here']",3
"['##mo  #TAUTHOR_TAG, and bert  #AUTHOR_TAG embeddings.', 'the unique thing about contextualized']","['simply substituting distributional word embeddings with flair  #AUTHOR_TAG, elmo  #TAUTHOR_TAG, and bert  #AUTHOR_TAG embeddings.', 'the unique thing about contextualized']","['##mo  #TAUTHOR_TAG, and bert  #AUTHOR_TAG embeddings.', 'the unique thing about contextualized word embeddings is that different representations are generated']","['##ized word embeddings have played an essential role in many nlp tasks.', 'one could expect considerable performance boosts by simply substituting distributional word embeddings with flair  #AUTHOR_TAG, elmo  #TAUTHOR_TAG, and bert  #AUTHOR_TAG embeddings.', 'the unique thing about contextualized word embeddings is that different representations are generated for the same word type with different topical senses.', 'this work focuses on interpreting embedding representations for word senses.', 'we propose an algorithm ( section 3 ) that learns the dimension importance in representing sense information and then mask unessential dimensions that are deemed less meaningful in word sense representations to 0.', 'the effectiveness of our approach is validated by a word sense disambiguation task ( wsd ) that aims to distinguish the correct senses of words under different contexts, as well as two intrinsic evaluations of embedding groups on the masked embeddings.', 'in addition to the final outputs of flair, elmo and bert embeddings, hidden layer outputs from elmo and bert are also extracted and compared.', 'our results show that masking unessential dimensions of word embeddings does not impair the performance on wsd ; moreover, discarding those dimensions can improve the performance up to 3 %, which suggests a new method for embedding distillation for more efficient neural network modeling']",0
"[' #TAUTHOR_TAG.', 'flair is a character - level bidirectional ls']","[' #TAUTHOR_TAG.', 'flair is a character - level bidirectional lstm language']","['with a final linear projection output layer  #TAUTHOR_TAG.', 'flair is a character - level bidirectional lstm language model on sequences of characters  #AUTHOR_TAG.', 'bert has an architecture of a multi - layer bidirectional transformer encoder  #AUTHOR_TAG']","['popular word embedding algorithms are used for our experiments with various dimensions : elmo, flair, and bert.', 'elmo is a deep word - level bidirectional lstm language model with character level convolution networks along with a final linear projection output layer  #TAUTHOR_TAG.', 'flair is a character - level bidirectional lstm language model on sequences of characters  #AUTHOR_TAG.', 'bert has an architecture of a multi - layer bidirectional transformer encoder  #AUTHOR_TAG']",0
"['', ' #AUTHOR_TAG b ) utilize bi - lstm networks with attention mechanism and a softmax layer.', ' #AUTHOR_TAG and  #TAUTHOR_TAG also adopt bi - lstm networks with knn classifiers']","[' #AUTHOR_TAG a ).', 'depending on the evaluation dataset, the state - of - art in wsd varies.', ' #AUTHOR_TAG b ) utilize bi - lstm networks with attention mechanism and a softmax layer.', ' #AUTHOR_TAG and  #TAUTHOR_TAG also adopt bi - lstm networks with knn classifiers.', 'later']","['', ' #AUTHOR_TAG b ) utilize bi - lstm networks with attention mechanism and a softmax layer.', ' #AUTHOR_TAG and  #TAUTHOR_TAG also adopt bi - lstm networks with knn classifiers.', 'later work incorporates word features such as gloss and pos information into memory networks  #AUTHOR_TAG']","['', 'depending on the evaluation dataset, the state - of - art in wsd varies.', ' #AUTHOR_TAG b ) utilize bi - lstm networks with attention mechanism and a softmax layer.', ' #AUTHOR_TAG and  #TAUTHOR_TAG also adopt bi - lstm networks with knn classifiers.', 'later work incorporates word features such as gloss and pos information into memory networks  #AUTHOR_TAG']",0
"[') approach is adopted from both elmo  #TAUTHOR_TAG and con - text2vec  #AUTHOR_TAG to establish strong baseline approaches.', 'sense']","['( knn ) approach is adopted from both elmo  #TAUTHOR_TAG and con - text2vec  #AUTHOR_TAG to establish strong baseline approaches.', 'sense - based']","[') approach is adopted from both elmo  #TAUTHOR_TAG and con - text2vec  #AUTHOR_TAG to establish strong baseline approaches.', 'sense']","['- nearest neighbor ( knn ) approach is adopted from both elmo  #TAUTHOR_TAG and con - text2vec  #AUTHOR_TAG to establish strong baseline approaches.', 'sense - based knn adapted from elmo  #TAUTHOR_TAG with k = 1, words that have the same senses are clustered together, and the average of that cluster is used as the sense vector, which is then fitted using a one knn classifier.', 'unseen words from the test corpus fall back using the first sense from wordnet  #AUTHOR_TAG.', 'word - based knn following context2vec  #AUTHOR_TAG, a cluster of each lemma occurrences in the training set is formed.', 'each word has a distinct classifier, which will assign labels based on k, where k = min ( # of occurrences, 5 ).', 'unseen words from test corpus fall back using the first sense from wordnet']",5
"[') approach is adopted from both elmo  #TAUTHOR_TAG and con - text2vec  #AUTHOR_TAG to establish strong baseline approaches.', 'sense']","['( knn ) approach is adopted from both elmo  #TAUTHOR_TAG and con - text2vec  #AUTHOR_TAG to establish strong baseline approaches.', 'sense - based']","[') approach is adopted from both elmo  #TAUTHOR_TAG and con - text2vec  #AUTHOR_TAG to establish strong baseline approaches.', 'sense']","['- nearest neighbor ( knn ) approach is adopted from both elmo  #TAUTHOR_TAG and con - text2vec  #AUTHOR_TAG to establish strong baseline approaches.', 'sense - based knn adapted from elmo  #TAUTHOR_TAG with k = 1, words that have the same senses are clustered together, and the average of that cluster is used as the sense vector, which is then fitted using a one knn classifier.', 'unseen words from the test corpus fall back using the first sense from wordnet  #AUTHOR_TAG.', 'word - based knn following context2vec  #AUTHOR_TAG, a cluster of each lemma occurrences in the training set is formed.', 'each word has a distinct classifier, which will assign labels based on k, where k = min ( # of occurrences, 5 ).', 'unseen words from test corpus fall back using the first sense from wordnet']",5
"[' #TAUTHOR_TAG,  #AUTHOR_TAG and  #AUTHOR_TAG, n = 10.', 'the germ']","[' #TAUTHOR_TAG,  #AUTHOR_TAG and  #AUTHOR_TAG, n = 10.', 'the germ']","[' #TAUTHOR_TAG,  #AUTHOR_TAG and  #AUTHOR_TAG, n = 10.', 'the germ']","['dirichlet allocation ( "" lda "" :  #AUTHOR_TAG ) is an approach to document clustering, in which "" topics "" ( multinomial distributions over terms ) and topic allocations ( multinomial distributions over topics per document ) are jointly learned.', 'when the topic model output is to be presented to humans, optimisation of the number of topics is a non - trivial problem.', 'in the seminal paper of  #AUTHOR_TAG, e. g., the authors showed thatcontrary to expectations - extrinsically measured topic coherence correlates negatively with model perplexity.', 'they introduced the word intrusion task, whereby a randomly selected "" intruder "" word is injected into the top - n words of a given topic and users are asked to identify the intruder word.', 'low reliability in identifying the intruder word indicates low coherence ( and vice versa ), based on the intuition that the more coherent the topic, the more clearly the intruder word should be an outlier.', 'since then, several methodologies have been introduced to automate the evaluation of topic coherence.', ' #AUTHOR_TAG found that aggregate pairwise pmi scores over the top - n topic words correlated well with human ratings.', ' #AUTHOR_TAG proposed replacing pmi with conditional probability based on co - document frequency.', ' #AUTHOR_TAG showed that coherence can be measured by a classical distributional similarity approach.', 'more recently,  #AUTHOR_TAG proposed a methodology to automate the word intrusion task directly.', 'their results also reveal the differences between these methodologies in their assessment of topic coherence.', 'a hyper - parameter in all these methodologies is the number of topic words, or its cardinality.', 'these methodologies evaluate coherence over the top - n topic words, where n is selected arbitrarily : for  #AUTHOR_TAG, n = 5, whereas for  #TAUTHOR_TAG,  #AUTHOR_TAG and  #AUTHOR_TAG, n = 10.', 'the germ of this paper came when using the automatic word intrusion methodology  #AUTHOR_TAG, and noticing that introducing one extra word to a given topic can dramatically change the accuracy of intruder word prediction.', 'this forms the kernel of this paper : to better understand the impact of the topic cardinality hyper - parameter on the evaluation of topic coherence.', 'to investigate this, we develop a new dataset with human - annotated coherence judgements for a range of cardinality settings ( n = { 5, 10, 15, 20 } ).', 'we experiment with the automatic word intrusion  #AUTHOR_TAG and discover that correlation with human ratings decreases systematically as cardinality increases.', 'we also test the pmi methodology  #TAUTHOR_TAG and make the same observation.', 'to remedy this, we show that performance can be substantially improved if system scores and human ratings are aggregated over different cardinality settings before computing the correlation.', 'this has broad implications for topic']",0
"['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting (']","['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting ( e. g. 5 or 10 ).', 'we thus develop a new dataset']","['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting (']","['examine the relationship between topic cardinality and topic coherence, we require a dataset that has topics for a range of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting ( e. g. 5 or 10 ).', 'we thus develop a new dataset for this experiment.', ' #AUTHOR_TAG, we use two domains : ( 1 ) wiki, a collection of 3. 3 million english wikipedia articles ( retrieved november 28th 2009 ) ; and ( 2 ) news, a collection of 1. 2 million new york times articles from 1994 to 2004 ( english gigaword ).', 'we sub - sample approximately 50m tokens ( 100k and 50k articles for wiki and news respectively ) from both domains to create two smaller document collections.', 'we then generate 300 lda topics for each of the sub - sampled collection.', '2 there are two primary approaches to assessing topic coherence : ( 1 ) via word intrusion ( chang et ( 2 ) by directly measuring observed coherence  #TAUTHOR_TAG.', 'with the first method,  #AUTHOR_TAG injects an intruder word into the top - 5 topic words, shuffles the topic words, and sets the task of selecting the single intruder word out of the 6 words.', 'in preliminary experiments, we found that the word intrusion task becomes unreasonably difficult for human annotators when the topic cardinality is high, e. g. when n = 20.', 'as such, we use the second approach as the means for generating our gold standard, asking users to judge topic coherence directly over different topic cardinalities.', '3 to collect the coherence judgements, we used amazon mechanical turk and asked turkers to rate topics in terms of coherence using a 3 - point ordinal scale, where 1 indicates incoherent and 3 very coherent  #TAUTHOR_TAG.', 'for each topic ( 600 topics in total ) we experiment with 4 cardinality settings : n = { 5, 10, 15, 20 }. for example, for n = 5, we display the top - 5 topic words for coherence judgement.', 'for annotation quality control, we embed a bad topic generated using random words into each hit.', 'workers who fail to consistently rate these bad topics low are filtered out.', '4 on average, we collected approximately 9 ratings per topic in each cardinality setting ( post - filtered ), from which we generate the gold standard via the arithmetic mean.', 'to understand the impact of cardinality ( n ) on topic coherence, we analyse : ( a ) the mean topic rating for each n ( table 1 ), and ( b ) the pairwise pearson correlation coefficient between']",0
"['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting (']","['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting ( e. g. 5 or 10 ).', 'we thus develop a new dataset']","['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting (']","['examine the relationship between topic cardinality and topic coherence, we require a dataset that has topics for a range of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting ( e. g. 5 or 10 ).', 'we thus develop a new dataset for this experiment.', ' #AUTHOR_TAG, we use two domains : ( 1 ) wiki, a collection of 3. 3 million english wikipedia articles ( retrieved november 28th 2009 ) ; and ( 2 ) news, a collection of 1. 2 million new york times articles from 1994 to 2004 ( english gigaword ).', 'we sub - sample approximately 50m tokens ( 100k and 50k articles for wiki and news respectively ) from both domains to create two smaller document collections.', 'we then generate 300 lda topics for each of the sub - sampled collection.', '2 there are two primary approaches to assessing topic coherence : ( 1 ) via word intrusion ( chang et ( 2 ) by directly measuring observed coherence  #TAUTHOR_TAG.', 'with the first method,  #AUTHOR_TAG injects an intruder word into the top - 5 topic words, shuffles the topic words, and sets the task of selecting the single intruder word out of the 6 words.', 'in preliminary experiments, we found that the word intrusion task becomes unreasonably difficult for human annotators when the topic cardinality is high, e. g. when n = 20.', 'as such, we use the second approach as the means for generating our gold standard, asking users to judge topic coherence directly over different topic cardinalities.', '3 to collect the coherence judgements, we used amazon mechanical turk and asked turkers to rate topics in terms of coherence using a 3 - point ordinal scale, where 1 indicates incoherent and 3 very coherent  #TAUTHOR_TAG.', 'for each topic ( 600 topics in total ) we experiment with 4 cardinality settings : n = { 5, 10, 15, 20 }. for example, for n = 5, we display the top - 5 topic words for coherence judgement.', 'for annotation quality control, we embed a bad topic generated using random words into each hit.', 'workers who fail to consistently rate these bad topics low are filtered out.', '4 on average, we collected approximately 9 ratings per topic in each cardinality setting ( post - filtered ), from which we generate the gold standard via the arithmetic mean.', 'to understand the impact of cardinality ( n ) on topic coherence, we analyse : ( a ) the mean topic rating for each n ( table 1 ), and ( b ) the pairwise pearson correlation coefficient between']",0
"[' #TAUTHOR_TAG,  #AUTHOR_TAG and  #AUTHOR_TAG, n = 10.', 'the germ']","[' #TAUTHOR_TAG,  #AUTHOR_TAG and  #AUTHOR_TAG, n = 10.', 'the germ']","[' #TAUTHOR_TAG,  #AUTHOR_TAG and  #AUTHOR_TAG, n = 10.', 'the germ']","['dirichlet allocation ( "" lda "" :  #AUTHOR_TAG ) is an approach to document clustering, in which "" topics "" ( multinomial distributions over terms ) and topic allocations ( multinomial distributions over topics per document ) are jointly learned.', 'when the topic model output is to be presented to humans, optimisation of the number of topics is a non - trivial problem.', 'in the seminal paper of  #AUTHOR_TAG, e. g., the authors showed thatcontrary to expectations - extrinsically measured topic coherence correlates negatively with model perplexity.', 'they introduced the word intrusion task, whereby a randomly selected "" intruder "" word is injected into the top - n words of a given topic and users are asked to identify the intruder word.', 'low reliability in identifying the intruder word indicates low coherence ( and vice versa ), based on the intuition that the more coherent the topic, the more clearly the intruder word should be an outlier.', 'since then, several methodologies have been introduced to automate the evaluation of topic coherence.', ' #AUTHOR_TAG found that aggregate pairwise pmi scores over the top - n topic words correlated well with human ratings.', ' #AUTHOR_TAG proposed replacing pmi with conditional probability based on co - document frequency.', ' #AUTHOR_TAG showed that coherence can be measured by a classical distributional similarity approach.', 'more recently,  #AUTHOR_TAG proposed a methodology to automate the word intrusion task directly.', 'their results also reveal the differences between these methodologies in their assessment of topic coherence.', 'a hyper - parameter in all these methodologies is the number of topic words, or its cardinality.', 'these methodologies evaluate coherence over the top - n topic words, where n is selected arbitrarily : for  #AUTHOR_TAG, n = 5, whereas for  #TAUTHOR_TAG,  #AUTHOR_TAG and  #AUTHOR_TAG, n = 10.', 'the germ of this paper came when using the automatic word intrusion methodology  #AUTHOR_TAG, and noticing that introducing one extra word to a given topic can dramatically change the accuracy of intruder word prediction.', 'this forms the kernel of this paper : to better understand the impact of the topic cardinality hyper - parameter on the evaluation of topic coherence.', 'to investigate this, we develop a new dataset with human - annotated coherence judgements for a range of cardinality settings ( n = { 5, 10, 15, 20 } ).', 'we experiment with the automatic word intrusion  #AUTHOR_TAG and discover that correlation with human ratings decreases systematically as cardinality increases.', 'we also test the pmi methodology  #TAUTHOR_TAG and make the same observation.', 'to remedy this, we show that performance can be substantially improved if system scores and human ratings are aggregated over different cardinality settings before computing the correlation.', 'this has broad implications for topic']",5
"['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting (']","['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting ( e. g. 5 or 10 ).', 'we thus develop a new dataset']","['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting (']","['examine the relationship between topic cardinality and topic coherence, we require a dataset that has topics for a range of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting ( e. g. 5 or 10 ).', 'we thus develop a new dataset for this experiment.', ' #AUTHOR_TAG, we use two domains : ( 1 ) wiki, a collection of 3. 3 million english wikipedia articles ( retrieved november 28th 2009 ) ; and ( 2 ) news, a collection of 1. 2 million new york times articles from 1994 to 2004 ( english gigaword ).', 'we sub - sample approximately 50m tokens ( 100k and 50k articles for wiki and news respectively ) from both domains to create two smaller document collections.', 'we then generate 300 lda topics for each of the sub - sampled collection.', '2 there are two primary approaches to assessing topic coherence : ( 1 ) via word intrusion ( chang et ( 2 ) by directly measuring observed coherence  #TAUTHOR_TAG.', 'with the first method,  #AUTHOR_TAG injects an intruder word into the top - 5 topic words, shuffles the topic words, and sets the task of selecting the single intruder word out of the 6 words.', 'in preliminary experiments, we found that the word intrusion task becomes unreasonably difficult for human annotators when the topic cardinality is high, e. g. when n = 20.', 'as such, we use the second approach as the means for generating our gold standard, asking users to judge topic coherence directly over different topic cardinalities.', '3 to collect the coherence judgements, we used amazon mechanical turk and asked turkers to rate topics in terms of coherence using a 3 - point ordinal scale, where 1 indicates incoherent and 3 very coherent  #TAUTHOR_TAG.', 'for each topic ( 600 topics in total ) we experiment with 4 cardinality settings : n = { 5, 10, 15, 20 }. for example, for n = 5, we display the top - 5 topic words for coherence judgement.', 'for annotation quality control, we embed a bad topic generated using random words into each hit.', 'workers who fail to consistently rate these bad topics low are filtered out.', '4 on average, we collected approximately 9 ratings per topic in each cardinality setting ( post - filtered ), from which we generate the gold standard via the arithmetic mean.', 'to understand the impact of cardinality ( n ) on topic coherence, we analyse : ( a ) the mean topic rating for each n ( table 1 ), and ( b ) the pairwise pearson correlation coefficient between']",5
"['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting (']","['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting ( e. g. 5 or 10 ).', 'we thus develop a new dataset']","['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting (']","['examine the relationship between topic cardinality and topic coherence, we require a dataset that has topics for a range of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting ( e. g. 5 or 10 ).', 'we thus develop a new dataset for this experiment.', ' #AUTHOR_TAG, we use two domains : ( 1 ) wiki, a collection of 3. 3 million english wikipedia articles ( retrieved november 28th 2009 ) ; and ( 2 ) news, a collection of 1. 2 million new york times articles from 1994 to 2004 ( english gigaword ).', 'we sub - sample approximately 50m tokens ( 100k and 50k articles for wiki and news respectively ) from both domains to create two smaller document collections.', 'we then generate 300 lda topics for each of the sub - sampled collection.', '2 there are two primary approaches to assessing topic coherence : ( 1 ) via word intrusion ( chang et ( 2 ) by directly measuring observed coherence  #TAUTHOR_TAG.', 'with the first method,  #AUTHOR_TAG injects an intruder word into the top - 5 topic words, shuffles the topic words, and sets the task of selecting the single intruder word out of the 6 words.', 'in preliminary experiments, we found that the word intrusion task becomes unreasonably difficult for human annotators when the topic cardinality is high, e. g. when n = 20.', 'as such, we use the second approach as the means for generating our gold standard, asking users to judge topic coherence directly over different topic cardinalities.', '3 to collect the coherence judgements, we used amazon mechanical turk and asked turkers to rate topics in terms of coherence using a 3 - point ordinal scale, where 1 indicates incoherent and 3 very coherent  #TAUTHOR_TAG.', 'for each topic ( 600 topics in total ) we experiment with 4 cardinality settings : n = { 5, 10, 15, 20 }. for example, for n = 5, we display the top - 5 topic words for coherence judgement.', 'for annotation quality control, we embed a bad topic generated using random words into each hit.', 'workers who fail to consistently rate these bad topics low are filtered out.', '4 on average, we collected approximately 9 ratings per topic in each cardinality setting ( post - filtered ), from which we generate the gold standard via the arithmetic mean.', 'to understand the impact of cardinality ( n ) on topic coherence, we analyse : ( a ) the mean topic rating for each n ( table 1 ), and ( b ) the pairwise pearson correlation coefficient between']",5
"['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting (']","['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting ( e. g. 5 or 10 ).', 'we thus develop a new dataset']","['of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting (']","['examine the relationship between topic cardinality and topic coherence, we require a dataset that has topics for a range of cardinality settings.', 'although there are existing datasets with human - annotated coherence scores  #TAUTHOR_TAG, these topics were annotated using a fixed cardinality setting ( e. g. 5 or 10 ).', 'we thus develop a new dataset for this experiment.', ' #AUTHOR_TAG, we use two domains : ( 1 ) wiki, a collection of 3. 3 million english wikipedia articles ( retrieved november 28th 2009 ) ; and ( 2 ) news, a collection of 1. 2 million new york times articles from 1994 to 2004 ( english gigaword ).', 'we sub - sample approximately 50m tokens ( 100k and 50k articles for wiki and news respectively ) from both domains to create two smaller document collections.', 'we then generate 300 lda topics for each of the sub - sampled collection.', '2 there are two primary approaches to assessing topic coherence : ( 1 ) via word intrusion ( chang et ( 2 ) by directly measuring observed coherence  #TAUTHOR_TAG.', 'with the first method,  #AUTHOR_TAG injects an intruder word into the top - 5 topic words, shuffles the topic words, and sets the task of selecting the single intruder word out of the 6 words.', 'in preliminary experiments, we found that the word intrusion task becomes unreasonably difficult for human annotators when the topic cardinality is high, e. g. when n = 20.', 'as such, we use the second approach as the means for generating our gold standard, asking users to judge topic coherence directly over different topic cardinalities.', '3 to collect the coherence judgements, we used amazon mechanical turk and asked turkers to rate topics in terms of coherence using a 3 - point ordinal scale, where 1 indicates incoherent and 3 very coherent  #TAUTHOR_TAG.', 'for each topic ( 600 topics in total ) we experiment with 4 cardinality settings : n = { 5, 10, 15, 20 }. for example, for n = 5, we display the top - 5 topic words for coherence judgement.', 'for annotation quality control, we embed a bad topic generated using random words into each hit.', 'workers who fail to consistently rate these bad topics low are filtered out.', '4 on average, we collected approximately 9 ratings per topic in each cardinality setting ( post - filtered ), from which we generate the gold standard via the arithmetic mean.', 'to understand the impact of cardinality ( n ) on topic coherence, we analyse : ( a ) the mean topic rating for each n ( table 1 ), and ( b ) the pairwise pearson correlation coefficient between']",4
"['more', 'recently,  #TAUTHOR_TAG proposed an efficient character - based decoder for']","['chinese. however, it requires to computationally expensive multiple beams to compare words of different lengths using beam search. more', 'recently,  #TAUTHOR_TAG proposed an efficient character - based decoder for']","['chinese. however, it requires to computationally expensive multiple beams to compare words of different lengths using beam search. more', 'recently,  #TAUTHOR_TAG proposed an efficient character - based decoder for']","['for chinese. however, it requires to computationally expensive multiple beams to compare words of different lengths using beam search. more', 'recently,  #TAUTHOR_TAG proposed an efficient character - based decoder for their word - based model. in their new model, a single beam suffices for decoding ;', 'hence, they reported that their model is practically ten times as fast as their original model. to incorporate the word - level', 'features into the character - based decoder, the features are decomposed into substring - level features, which are effective for', 'incomplete words to have comparable scores to complete words in the beam. because we found', 'that even an incremental approach with beam search is intractable if we perform the wordbased decoding, we take a character - based approach to produce', '']",3
"['more', 'recently,  #TAUTHOR_TAG proposed an efficient character - based decoder for']","['chinese. however, it requires to computationally expensive multiple beams to compare words of different lengths using beam search. more', 'recently,  #TAUTHOR_TAG proposed an efficient character - based decoder for']","['chinese. however, it requires to computationally expensive multiple beams to compare words of different lengths using beam search. more', 'recently,  #TAUTHOR_TAG proposed an efficient character - based decoder for']","['for chinese. however, it requires to computationally expensive multiple beams to compare words of different lengths using beam search. more', 'recently,  #TAUTHOR_TAG proposed an efficient character - based decoder for their word - based model. in their new model, a single beam suffices for decoding ;', 'hence, they reported that their model is practically ten times as fast as their original model. to incorporate the word - level', 'features into the character - based decoder, the features are decomposed into substring - level features, which are effective for', 'incomplete words to have comparable scores to complete words in the beam. because we found', 'that even an incremental approach with beam search is intractable if we perform the wordbased decoding, we take a character - based approach to produce', '']",0
"['step index. we can first think of using the number of shifted characters as the', 'step index, as  #TAUTHOR_TAG']","['step index. we can first think of using the number of shifted characters as the', 'step index, as  #TAUTHOR_TAG']","['step index. we can first think of using the number of shifted characters as the', 'step index, as  #TAUTHOR_TAG does. however,']","[', all states with the same index must be comparable, and all terminal states should have the same step index. we can first think of using the number of shifted characters as the', ""step index, as  #TAUTHOR_TAG does. however, because rl / rr actions can be performed without incrementing the step index, the decoder tends to prefer states with more dependency arcs, resulting more likely in premature choice of '"", ""reduce'actions or oversegmentation of words. alternatively, we can consider using the number of actions that have been applied as the step index, as  #AUTHOR_TAG"", '']",4
"['of our ckb completion model is similar to that of  #TAUTHOR_TAG.', 'the main difference between ours and']","['of our ckb completion model is similar to that of  #TAUTHOR_TAG.', 'the main difference between ours and theirs is that our method learns the ckb completion']","['basic structure of our ckb completion model is similar to that of  #TAUTHOR_TAG.', 'the main difference between ours and']","['basic structure of our ckb completion model is similar to that of  #TAUTHOR_TAG.', 'the main difference between ours and theirs is that our method learns the ckb completion and generation tasks jointly.', 'the completion model only considers the binary classification task, and therefore, it can be easily overfitted when there are not enough training data.', 'by incorporating the generation model, the shared layers are trained for both binary classification and phrase generation.', 'this is expected to be a good constraint to prevent overfitting.', 'previous model  #TAUTHOR_TAG defined a ckb completion model that estimates a confidence score of an arbitrary triple [UNK] t 1, r, t 2 [UNK]. they used a simple neural network model to formulate score ( t 1, r, t 2 ) ∈ r.', 'where', '']",3
['##n lstm models  #TAUTHOR_TAG'],['dnn lstm models  #TAUTHOR_TAG'],['##n lstm models  #TAUTHOR_TAG'],"['##b completion as baselines, we used the dnn avg and dnn lstm models  #TAUTHOR_TAG that were described in section 3. 1.', 'to assess the effectiveness of joint learning, we compared our ckb completion model only ( proposed w / o ckb generation ) and the joint model ( proposed w / ckb generation ).', 'moreover, we evaluated the effectiveness of simply adding augmentation data, as described in section 4 to the training data ( + auggen ).', 'we used the accuracy of binary classification as the evaluation measure.', 'the threshold was determined by using the validation1 data to maximize the accuracy of binary classification for each method, as in  #TAUTHOR_TAG.', 'ckb generation we used a simple attentional encoder - decoder model that does not use relation information as a baseline ( base ).', 'we compared the proposed model with and without joint learning ( proposed and proposed w / o ckbc ).', 'we also evaluated the effectiveness of simply adding augmentation data as described in section 4 to the training data ( + auggen )']",3
['relation according to  #TAUTHOR_TAG'],['relation according to  #TAUTHOR_TAG'],['by using the pos tag sequence pattern for each relation according to  #TAUTHOR_TAG'],"['##ctive evaluations of the quality of the triples generated with our model.', 'first, we generated two types of query pairs : ones generated from conceptnet ( cn gen ) and ones generated from wikipedia ( wiki gen ).', 'in cn gen, we used all phrase and relation pairs [UNK] t, r [UNK] appearing in the test data.', 'in wiki gen, we used triples extracted by using the pos tag sequence pattern for each relation according to  #TAUTHOR_TAG and scored each triple with ckb completion scores.', 'then, we used [UNK] t, r [UNK] pairs of 10000 triples that had higher scores than a threshold as the input query pairs.', '']",3
"['of our ckb completion model is similar to that of  #TAUTHOR_TAG.', 'the main difference between ours and']","['of our ckb completion model is similar to that of  #TAUTHOR_TAG.', 'the main difference between ours and theirs is that our method learns the ckb completion']","['basic structure of our ckb completion model is similar to that of  #TAUTHOR_TAG.', 'the main difference between ours and']","['basic structure of our ckb completion model is similar to that of  #TAUTHOR_TAG.', 'the main difference between ours and theirs is that our method learns the ckb completion and generation tasks jointly.', 'the completion model only considers the binary classification task, and therefore, it can be easily overfitted when there are not enough training data.', 'by incorporating the generation model, the shared layers are trained for both binary classification and phrase generation.', 'this is expected to be a good constraint to prevent overfitting.', 'previous model  #TAUTHOR_TAG defined a ckb completion model that estimates a confidence score of an arbitrary triple [UNK] t 1, r, t 2 [UNK]. they used a simple neural network model to formulate score ( t 1, r, t 2 ) ∈ r.', 'where', '']",4
"['reported in  #TAUTHOR_TAG.', 'the results indicate that our method']","['reported in  #TAUTHOR_TAG.', 'the results indicate that our method']","['reported in  #TAUTHOR_TAG.', 'the results indicate that our method']","['', 'the bottom two lines show the best performances reported in  #TAUTHOR_TAG.', 'the results indicate that our method improved the accuracy of ckb completion compared with the previous method.', 'our method achieved 0. 945 accuracy on the validation2 data.', '']",4
"['as the number of positive examples according to  #TAUTHOR_TAG. the details are', 'described in the supplementary material']","['as the number of positive examples according to  #TAUTHOR_TAG. the details are', 'described in the supplementary material']","['as the number of positive examples according to  #TAUTHOR_TAG. the details are', 'described in the supplementary material']","['', 'validation data, we randomly sampled negative examples,', 'as described in section 4, whose size was the same as the number of positive examples according to  #TAUTHOR_TAG. the details are', 'described in the supplementary material']",5
['##n lstm models  #TAUTHOR_TAG'],['dnn lstm models  #TAUTHOR_TAG'],['##n lstm models  #TAUTHOR_TAG'],"['##b completion as baselines, we used the dnn avg and dnn lstm models  #TAUTHOR_TAG that were described in section 3. 1.', 'to assess the effectiveness of joint learning, we compared our ckb completion model only ( proposed w / o ckb generation ) and the joint model ( proposed w / ckb generation ).', 'moreover, we evaluated the effectiveness of simply adding augmentation data, as described in section 4 to the training data ( + auggen ).', 'we used the accuracy of binary classification as the evaluation measure.', 'the threshold was determined by using the validation1 data to maximize the accuracy of binary classification for each method, as in  #TAUTHOR_TAG.', 'ckb generation we used a simple attentional encoder - decoder model that does not use relation information as a baseline ( base ).', 'we compared the proposed model with and without joint learning ( proposed and proposed w / o ckbc ).', 'we also evaluated the effectiveness of simply adding augmentation data as described in section 4 to the training data ( + auggen )']",5
['##n lstm models  #TAUTHOR_TAG'],['dnn lstm models  #TAUTHOR_TAG'],['##n lstm models  #TAUTHOR_TAG'],"['##b completion as baselines, we used the dnn avg and dnn lstm models  #TAUTHOR_TAG that were described in section 3. 1.', 'to assess the effectiveness of joint learning, we compared our ckb completion model only ( proposed w / o ckb generation ) and the joint model ( proposed w / ckb generation ).', 'moreover, we evaluated the effectiveness of simply adding augmentation data, as described in section 4 to the training data ( + auggen ).', 'we used the accuracy of binary classification as the evaluation measure.', 'the threshold was determined by using the validation1 data to maximize the accuracy of binary classification for each method, as in  #TAUTHOR_TAG.', 'ckb generation we used a simple attentional encoder - decoder model that does not use relation information as a baseline ( base ).', 'we compared the proposed model with and without joint learning ( proposed and proposed w / o ckbc ).', 'we also evaluated the effectiveness of simply adding augmentation data as described in section 4 to the training data ( + auggen )']",5
['relation according to  #TAUTHOR_TAG'],['relation according to  #TAUTHOR_TAG'],['by using the pos tag sequence pattern for each relation according to  #TAUTHOR_TAG'],"['##ctive evaluations of the quality of the triples generated with our model.', 'first, we generated two types of query pairs : ones generated from conceptnet ( cn gen ) and ones generated from wikipedia ( wiki gen ).', 'in cn gen, we used all phrase and relation pairs [UNK] t, r [UNK] appearing in the test data.', 'in wiki gen, we used triples extracted by using the pos tag sequence pattern for each relation according to  #TAUTHOR_TAG and scored each triple with ckb completion scores.', 'then, we used [UNK] t, r [UNK] pairs of 10000 triples that had higher scores than a threshold as the input query pairs.', '']",5
"['', 'in particular,  #TAUTHOR_TAG and  #AUTHOR_TAG proposed a simple kbc model for ckb.', ""the formulations of ckb completion in the two studies are the same, and we evaluated  #TAUTHOR_TAG's method as a baseline""]","['phrase and relation embeddings that can robustly represent arbitrary phrases.', 'there are a few studies on ckb completion models.', 'in particular,  #TAUTHOR_TAG and  #AUTHOR_TAG proposed a simple kbc model for ckb.', ""the formulations of ckb completion in the two studies are the same, and we evaluated  #TAUTHOR_TAG's method as a baseline."", 'open']","['', 'in particular,  #TAUTHOR_TAG and  #AUTHOR_TAG proposed a simple kbc model for ckb.', ""the formulations of ckb completion in the two studies are the same, and we evaluated  #TAUTHOR_TAG's method as a baseline."", '']","['', 'knowledge base completion for commonsense triples in commonsense knowledge base completion, the nodes of the kb consist of arbitrary phrases ( word sequences ), and there are a huge number of unique nodes.', 'in such case, the kb graph becomes very sparse, and consequently, there is almost no merit to considering the topological features of the kbs.', 'moreover, on - the - fly kbc is needed because we have to handle new nodes as input.', 'it is thus more important to formulate phrase and relation embeddings that can robustly represent arbitrary phrases.', 'there are a few studies on ckb completion models.', 'in particular,  #TAUTHOR_TAG and  #AUTHOR_TAG proposed a simple kbc model for ckb.', ""the formulations of ckb completion in the two studies are the same, and we evaluated  #TAUTHOR_TAG's method as a baseline."", 'open information extraction open information extraction ( openie ) aims to extract triple knowledge from raw text.', 'it finds triples that have specific predefined relations by using lexical and syntactic patterns  #AUTHOR_TAG.', 'several neural - network - based relation extraction methods have been proposed  #AUTHOR_TAG.', 'these models construct classifiers to estimate the relation between two arbitrary entities.', 'openie models are trained with sentence - level annotation data or distant supervision, while our model is']",5
"['as the number of positive examples according to  #TAUTHOR_TAG. the details are', 'described in the supplementary material']","['as the number of positive examples according to  #TAUTHOR_TAG. the details are', 'described in the supplementary material']","['as the number of positive examples according to  #TAUTHOR_TAG. the details are', 'described in the supplementary material']","['', 'validation data, we randomly sampled negative examples,', 'as described in section 4, whose size was the same as the number of positive examples according to  #TAUTHOR_TAG. the details are', 'described in the supplementary material']",7
[' #TAUTHOR_TAG for fine -'],[' #TAUTHOR_TAG for fine - grained entity typing employs an attentive neural'],"['', 'the state - of - the - art approach  #TAUTHOR_TAG for fine -']","['', 'the state - of - the - art approach  #TAUTHOR_TAG for fine - grained entity typing employs an attentive neural architecture to learn representations of the entity mention as well as its context.', '']",0
"['context  #TAUTHOR_TAG.', '1 the']","['in contrast to prior work which only takes sentence - level context  #TAUTHOR_TAG.', '1 the']","['in contrast to prior work which only takes sentence - level context  #TAUTHOR_TAG.', '1 the output of featurizer [UNK] is the concatenation of these feature vectors :', 'we define the computation of these feature vectors in the followings.', '']","['shown in figure 1, featurizer [UNK] in our model contains three encoders which encode entity e and its context x into feature vectors, and we consider both sentence - level context x s and document - level context x d in contrast to prior work which only takes sentence - level context  #TAUTHOR_TAG.', '1 the output of featurizer [UNK] is the concatenation of these feature vectors :', 'we define the computation of these feature vectors in the followings.', 'entity encoder : the entity encoder f computes the average of all the embeddings of tokens in entity e.', 'where − → f and ← − f are l - layer stacked lstms units  #AUTHOR_TAG.', 'this is different from  #TAUTHOR_TAG who use two separate bi - directional rnns for context on each side of the entity mention.', 'attention : the feature representation for x s is a weighted sum of the hidden states : g s ( x s, e ) = n i = 1 a i h i, where a i is the attention to hidden state h i.', 'we employ the dot - product attention  #AUTHOR_TAG.', 'it computes attention based on the alignment between the entity and its context :', 'where w a is the weight matrix.', 'the dot - product attention differs from the self attention  #TAUTHOR_TAG which only considers the context.', 'document - level context encoder : the encoder g d for document - level context x d is a multi - layer perceptron :', 'where dm is a pretrained distributed memory model  #AUTHOR_TAG which converts the document - level context into a distributed representation.', 'w d 1 and w d 2 are weight matrices']",4
"['context  #TAUTHOR_TAG.', '1 the']","['in contrast to prior work which only takes sentence - level context  #TAUTHOR_TAG.', '1 the']","['in contrast to prior work which only takes sentence - level context  #TAUTHOR_TAG.', '1 the output of featurizer [UNK] is the concatenation of these feature vectors :', 'we define the computation of these feature vectors in the followings.', '']","['shown in figure 1, featurizer [UNK] in our model contains three encoders which encode entity e and its context x into feature vectors, and we consider both sentence - level context x s and document - level context x d in contrast to prior work which only takes sentence - level context  #TAUTHOR_TAG.', '1 the output of featurizer [UNK] is the concatenation of these feature vectors :', 'we define the computation of these feature vectors in the followings.', 'entity encoder : the entity encoder f computes the average of all the embeddings of tokens in entity e.', 'where − → f and ← − f are l - layer stacked lstms units  #AUTHOR_TAG.', 'this is different from  #TAUTHOR_TAG who use two separate bi - directional rnns for context on each side of the entity mention.', 'attention : the feature representation for x s is a weighted sum of the hidden states : g s ( x s, e ) = n i = 1 a i h i, where a i is the attention to hidden state h i.', 'we employ the dot - product attention  #AUTHOR_TAG.', 'it computes attention based on the alignment between the entity and its context :', 'where w a is the weight matrix.', 'the dot - product attention differs from the self attention  #TAUTHOR_TAG which only considers the context.', 'document - level context encoder : the encoder g d for document - level context x d is a multi - layer perceptron :', 'where dm is a pretrained distributed memory model  #AUTHOR_TAG which converts the document - level context into a distributed representation.', 'w d 1 and w d 2 are weight matrices']",4
"['context  #TAUTHOR_TAG.', '1 the']","['in contrast to prior work which only takes sentence - level context  #TAUTHOR_TAG.', '1 the']","['in contrast to prior work which only takes sentence - level context  #TAUTHOR_TAG.', '1 the output of featurizer [UNK] is the concatenation of these feature vectors :', 'we define the computation of these feature vectors in the followings.', '']","['shown in figure 1, featurizer [UNK] in our model contains three encoders which encode entity e and its context x into feature vectors, and we consider both sentence - level context x s and document - level context x d in contrast to prior work which only takes sentence - level context  #TAUTHOR_TAG.', '1 the output of featurizer [UNK] is the concatenation of these feature vectors :', 'we define the computation of these feature vectors in the followings.', 'entity encoder : the entity encoder f computes the average of all the embeddings of tokens in entity e.', 'where − → f and ← − f are l - layer stacked lstms units  #AUTHOR_TAG.', 'this is different from  #TAUTHOR_TAG who use two separate bi - directional rnns for context on each side of the entity mention.', 'attention : the feature representation for x s is a weighted sum of the hidden states : g s ( x s, e ) = n i = 1 a i h i, where a i is the attention to hidden state h i.', 'we employ the dot - product attention  #AUTHOR_TAG.', 'it computes attention based on the alignment between the entity and its context :', 'where w a is the weight matrix.', 'the dot - product attention differs from the self attention  #TAUTHOR_TAG which only considers the context.', 'document - level context encoder : the encoder g d for document - level context x d is a multi - layer perceptron :', 'where dm is a pretrained distributed memory model  #AUTHOR_TAG which converts the document - level context into a distributed representation.', 'w d 1 and w d 2 are weight matrices']",4
"['types  #TAUTHOR_TAG.', 'we instead assign a different threshold to']","['types  #TAUTHOR_TAG.', 'we instead assign a different threshold to']","['prior work, a fixed threshold ( r t = 0. 5 ) is used for classification of all types  #TAUTHOR_TAG.', 'we instead assign a different threshold to each type that is optimized to maximize']","['prior work, a fixed threshold ( r t = 0. 5 ) is used for classification of all types  #TAUTHOR_TAG.', 'we instead assign a different threshold to each type that is optimized to maximize the overall strict f 1 on the dev set.', 'we show the definition of strict f 1 in section 3. 1']",4
['features  #TAUTHOR_TAG'],['1 ; ( 2 ) adding hand - crafted features  #TAUTHOR_TAG'],['micro f 1 ; ( 2 ) adding hand - crafted features  #TAUTHOR_TAG does not improve'],"['compare experimental results of our approach with previous approaches 3, and study contribution of our base model architecture, documentlevel contexts and adaptive thresholds via ablation.', 'to ensure our findings are reliable, we run each experiment twice and report the average performance.', 'overall, our approach significantly increases the state - of - the - art macro f 1 on both ontonotes and bbn datasets.', 'on ontonotes ( table 3 ), our approach improves the state of the art across all three metrics.', 'note that ( 1 ) without adaptive thresholds or document - level contexts, our approach still outperforms other approaches on macro f 1 and micro f 1 ; ( 2 ) adding hand - crafted features  #TAUTHOR_TAG does not improve the performance.', ' #AUTHOR_TAG 49. 30 68. 23 61. 27 afet  #AUTHOR_TAG a ) 55. 10 71. 10 64. 70 fnet  #AUTHOR_TAG 52. 20 68. 50 63. 30 neural  #TAUTHOR_TAG this indicates the benefits of our proposed model architecture for learning fine - grained entity typing, which is discussed in detail in section 3. 4 ; and ( 3 ) binary and kwasibie were trained on a different dataset, so their results are not directly comparable']",4
['features  #TAUTHOR_TAG'],['1 ; ( 2 ) adding hand - crafted features  #TAUTHOR_TAG'],['micro f 1 ; ( 2 ) adding hand - crafted features  #TAUTHOR_TAG does not improve'],"['compare experimental results of our approach with previous approaches 3, and study contribution of our base model architecture, documentlevel contexts and adaptive thresholds via ablation.', 'to ensure our findings are reliable, we run each experiment twice and report the average performance.', 'overall, our approach significantly increases the state - of - the - art macro f 1 on both ontonotes and bbn datasets.', 'on ontonotes ( table 3 ), our approach improves the state of the art across all three metrics.', 'note that ( 1 ) without adaptive thresholds or document - level contexts, our approach still outperforms other approaches on macro f 1 and micro f 1 ; ( 2 ) adding hand - crafted features  #TAUTHOR_TAG does not improve the performance.', ' #AUTHOR_TAG 49. 30 68. 23 61. 27 afet  #AUTHOR_TAG a ) 55. 10 71. 10 64. 70 fnet  #AUTHOR_TAG 52. 20 68. 50 63. 30 neural  #TAUTHOR_TAG this indicates the benefits of our proposed model architecture for learning fine - grained entity typing, which is discussed in detail in section 3. 4 ; and ( 3 ) binary and kwasibie were trained on a different dataset, so their results are not directly comparable']",4
['40 neural  #TAUTHOR_TAG proach'],['69. 30 66. 40 neural  #TAUTHOR_TAG proach'],['30 69. 30 66. 40 neural  #TAUTHOR_TAG proach'],[' #TAUTHOR_TAG'],4
['40 neural  #TAUTHOR_TAG proach'],['69. 30 66. 40 neural  #TAUTHOR_TAG proach'],['30 69. 30 66. 40 neural  #TAUTHOR_TAG proach'],[' #TAUTHOR_TAG'],4
['40 neural  #TAUTHOR_TAG proach'],['69. 30 66. 40 neural  #TAUTHOR_TAG proach'],['30 69. 30 66. 40 neural  #TAUTHOR_TAG proach'],[' #TAUTHOR_TAG'],6
['health applications ( smm4h ) shared task  #TAUTHOR_TAG hosts four tasks'],['health applications ( smm4h ) shared task  #TAUTHOR_TAG hosts four tasks'],"['health applications ( smm4h ) shared task  #TAUTHOR_TAG hosts four tasks aiming to identify mentions of different aspects medication use on twitter.', 'briefly, the tasks and their descriptions are : task 1 : automatic detection of posts mentioning drug names.', '']","['increasing use of social media platforms world wide offers an interesting application of natural language processing tools for monitoring public health and health - related events on the social media.', 'the social media mining for health applications ( smm4h ) shared task  #TAUTHOR_TAG hosts four tasks aiming to identify mentions of different aspects medication use on twitter.', 'briefly, the tasks and their descriptions are : task 1 : automatic detection of posts mentioning drug names.', '']",0
"[',', 'respectively. further information on the data sets can be found', 'in  #TAUTHOR_TAG. table 1 presents f 1 - scores of the models on']","['negative class,', 'respectively. further information on the data sets can be found', 'in  #TAUTHOR_TAG. table 1 presents f 1 - scores of the models on']","['belonged to the negative class,', 'respectively. further information on the data sets can be found', 'in  #TAUTHOR_TAG. table 1 presents f 1 - scores of the models on']","['', 'respectively. further information on the data sets can be found', 'in  #TAUTHOR_TAG. table 1 presents f 1 - scores of the models on each task. in general, we do not observe substantial differences between the term weighting schemes, but for some tasks the gap between training and development set scores', 'is rather large. we do not know the system rankings at the time of writing, but only know that the results above are above the mean of the', 'best - scores from all participating teams']",7
['.  #TAUTHOR_TAG establish a preliminary'],"['social and intersectional bias.', 'may et al.  #TAUTHOR_TAG establish a preliminary']","['.  #TAUTHOR_TAG establish a preliminary study of social bias in bert, but']","['', 'may et al.  #TAUTHOR_TAG establish a preliminary study of social bias in bert, but their analysis relies only on sentence level encodings.', '']",0
"['25 ] word embeddings, whereas may et al.  #TAUTHOR_TAG evaluate various models of contextual word representations on a sentential generalization of']","['representations in some specific settings.', 'zhao et al. [ 35 ] and basta et al. [ 1 ] demonstrate gender bias in elmo [ 25 ] word embeddings, whereas may et al.  #TAUTHOR_TAG evaluate various models of contextual word representations on a sentential generalization of weat.', 'our']","['. [ 1 ] demonstrate gender bias in elmo [ 25 ] word embeddings, whereas may et al.  #TAUTHOR_TAG evaluate various models of contextual word representations on a sentential generalization of']","['bias in language has been demonstrated to exist upstream in a variety of corpora and datasets ; on a corpus elicited from crowdworkers [ 28 ], and on the 1 billion word benchmark corpus [ 7 ] where it was observed that there was gender skew in proportions of gendered pronouns and associations with occupation words zhao et al. [ 35 ].', 'gender bias has also been demonstrated downstream on several applications of natural language processing, including sentiment analysis [ 18, 30 ], abusive language detection [ 23 ], image captioning [ 16 ] and text classification [ 11 ].', 'these models not only reflect the bias in training data, but also amplify the bias [ 32, 5 ].', 'our work extends the upstream corpus level analysis in two ways : 1 ) we include the non - gendered or collective pronoun in occurrence counts, and 2 ) we apply the analysis on other datasets like bookscorpus [ 36 ], wikipedia, and webtext [ 27 ].', 'significant work has been done to show social bias ( in particular gender bias ) in word embeddings.', 'bolukbasi et al. [ 2 ] and caliskan et al. [ 5 ] demonstrate that word embeddings associate occupations with their stereotypical gender roles ( eg. doctors are stereotypically male, nurses are stereotypically female ) by evaluating occupation words with word embedding association tests ( weats ) to gender words.', 'inspired by implicit association tests, weats compute the differences in distances when word vectors are asked to pair two concepts that are similar ( e. g., stereotypically female occupation words and female gender words ) as opposed to two concepts that are different ( e. g., stereotypically male occupation words and female gender words ).', 'brunet et al. [ 4 ] trace the internalization of gender bias to representational differences at the corpus level.', 'this line of work has very recently been extended to evaluate gender bias in contextual word representations in some specific settings.', 'zhao et al. [ 35 ] and basta et al. [ 1 ] demonstrate gender bias in elmo [ 25 ] word embeddings, whereas may et al.  #TAUTHOR_TAG evaluate various models of contextual word representations on a sentential generalization of weat.', 'our work extends such analyses in two ways : 1 ) we consider a wide variety of contextual word embedding tools including state - of - the - art approaches such as bert and gpt - 2, 2 ) we extend the evaluation to consider contextual word representations as opposed to prior work, which either used word embeddings without context or used sentence - level embeddings that can have']",0
"['.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'calisk']","['et al.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'caliskan']","['.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'calisk']","['adopt the methodology of caliskan et al. [ 5 ] and may et al.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'caliskan et al. [ 5 ] proposed word embedding association tests ( weats ), which follows human implicit association tests [ 14 ] in measuring the association between two target concepts and two attributes.', 'we follow may et al.  #TAUTHOR_TAG in describing weats and seats.', 'let x and y be equal - size sets of target concept embeddings, and a and b be sets of attribute embeddings.', 'these embeddings are obtained after encoding a set of words which define the concept or attribute.', 'intuitively, weats measure the effect size of the association between a concept x with attribute a and concept y with attribute b, as opposed to concept x with attribute b and concept y with attribute a. the test statistic is', 'where each addend is the difference between the mean of cosine similarities of the respective attributes :', 's ( w, a, b ) = mean a∈a cos ( w, a ) − mean b∈b cos ( w, b ).', 'to compute the significance of the association between ( a, b ) and ( x, y ), a permutation test on s ( x, y, a, b ) is used.', 'where the probability is computed over the space of partitions ( x i, y i ) of x ∪ y so that x i and y i are of equal size.', 'the effect size is defined to be', 'a larger effect size corresponds to more severe pro - stereotypical representations, controlling for significance.', 'may et al.  #TAUTHOR_TAG adopt the weat tests [ 5 ] into sentence encoder association tests ( seats ) to test biases using sentence encodings.', 'the embeddings used in the association tests are encodings of a sentence, which are obtained by pooling per token contextual representations, or by using the representation of the first or last token.', 'seats are constructed from weats by using "" semantically bleached "" sentence templates such as "" this is a [ doctor ] "" or "" [ alice ] is here "".', 'these "" semantically bleached "" templates were created to observe the effect of a sentence encoding based on a given term, instead of the associations made with the context of other potentially semantically meaningful words.', 'we refer to weats and seats as caliskan tests [ 5 ]']",0
['et al.  #TAUTHOR_TAG suggest that although they find less bias in'],['et al.  #TAUTHOR_TAG suggest that although they find less bias in'],"['et al.  #TAUTHOR_TAG suggest that although they find less bias in sentence encoders than context free word embeddings, the sentence templates']","['et al.  #TAUTHOR_TAG suggest that although they find less bias in sentence encoders than context free word embeddings, the sentence templates may not be as semantically bleached as expected, and that a lack of evidence of bias should not be taken as a lack of bias.', 'we propose to assess bias at the contextual word level.', 'this allows an investigation into the bias of contextual word representation models ( which allow for sentence encoding ), and at the same time avoids confounding contextual effects at the sentence level, which can obscure bias.', 'to determine underlying bias in contextual word representations, we adopt seats and make a simple modification.', 'instead of using the sentence encoding for the association tests, we use the contextual word representation of the token of interest ( i. e. we use the representation of the word before it is pooled ).', 'for example, in bert the sentence encoding is obtained as the representation of the [CLS] token ; in gpt it is the representation of the last token ; in elmo it is obtained by mean - pooling over all token representations.', 'however, in all cases we instead use the contextual word encoding corresponding to the token representation of interest.', 'more precise implementation details are in the supplementary material']",0
"['bind [ 15,  #TAUTHOR_TAG.', '']","['bind [ 15,  #TAUTHOR_TAG.', '']","['arts ) [ 5 ] and the heilman double bind [ 15,  #TAUTHOR_TAG.', '']","['investigate social and intersectional bias, we introduce new embedding association tests to more comprehensively target race, gender and intersectional identities.', 'the new tests are prefixed by a "" + "" in tables 3, 4 and 5.', 'for race and gender, we are interested in attributes of pleasantness ( p / u : pleasant / unpleasant ), work ( career / family ), discipline ( science / arts ) [ 5 ] and the heilman double bind [ 15,  #TAUTHOR_TAG.', 'the heilman double bind refers to how women, when clearly succeeding in a stereotypically male occupation, are perceived as less likable than similar men, and how women, when success is more ambiguous, are perceived as less competent than similar men.', 'although the heilman double bind originated in the context of gender, we also extend the attribute lists 3 of competence and likability to the context of race.', 'we preserve and report the original weats, seats and tests introduced by may et al.  #TAUTHOR_TAG where possible.', 'we also prefer tests using names ( e. g. alice ) as concept words over group terms ( e. g. european american ), since names were demonstrated to have a significant association more often than group terms  #TAUTHOR_TAG for intersectional identities, we are focused primarily on the identity which is the subject of discussion in the work of crenshaw [ 9 ] : being both african american and female.', 'specifically,  #TAUTHOR_TAG, which targets the stereotype of black women as loud, angry, and imposing [ 8 ].', '']",0
"['bind [ 15,  #TAUTHOR_TAG.', '']","['bind [ 15,  #TAUTHOR_TAG.', '']","['arts ) [ 5 ] and the heilman double bind [ 15,  #TAUTHOR_TAG.', '']","['investigate social and intersectional bias, we introduce new embedding association tests to more comprehensively target race, gender and intersectional identities.', 'the new tests are prefixed by a "" + "" in tables 3, 4 and 5.', 'for race and gender, we are interested in attributes of pleasantness ( p / u : pleasant / unpleasant ), work ( career / family ), discipline ( science / arts ) [ 5 ] and the heilman double bind [ 15,  #TAUTHOR_TAG.', 'the heilman double bind refers to how women, when clearly succeeding in a stereotypically male occupation, are perceived as less likable than similar men, and how women, when success is more ambiguous, are perceived as less competent than similar men.', 'although the heilman double bind originated in the context of gender, we also extend the attribute lists 3 of competence and likability to the context of race.', 'we preserve and report the original weats, seats and tests introduced by may et al.  #TAUTHOR_TAG where possible.', 'we also prefer tests using names ( e. g. alice ) as concept words over group terms ( e. g. european american ), since names were demonstrated to have a significant association more often than group terms  #TAUTHOR_TAG for intersectional identities, we are focused primarily on the identity which is the subject of discussion in the work of crenshaw [ 9 ] : being both african american and female.', 'specifically,  #TAUTHOR_TAG, which targets the stereotype of black women as loud, angry, and imposing [ 8 ].', '']",0
['.  #TAUTHOR_TAG and'],['et al.  #TAUTHOR_TAG and'],"['.  #TAUTHOR_TAG and the original word [ 26 ], we use the representation corresponding']","['to may et al.  #TAUTHOR_TAG and the original word [ 26 ], we use the representation corresponding to the last word in the sequence as the sentence encoding.', 'at the contextual word level, we use the representation corresponding to the token of interest.', 'gpt also uses subword tokenization, so the start of the token is used if the token of interest is subword tokenized.', 'both encoding types are 768 - dimensional.', 'different from may et al.  #TAUTHOR_TAG, we use the implementation of gpt from hugging face, and not the jiant project 10.', 'prefix weat but sentence level tests have the prefix sent - weat.', '']",0
['.  #TAUTHOR_TAG establish a preliminary'],"['social and intersectional bias.', 'may et al.  #TAUTHOR_TAG establish a preliminary']","['.  #TAUTHOR_TAG establish a preliminary study of social bias in bert, but']","['', 'may et al.  #TAUTHOR_TAG establish a preliminary study of social bias in bert, but their analysis relies only on sentence level encodings.', '']",1
['.  #TAUTHOR_TAG establish a preliminary'],"['social and intersectional bias.', 'may et al.  #TAUTHOR_TAG establish a preliminary']","['.  #TAUTHOR_TAG establish a preliminary study of social bias in bert, but']","['', 'may et al.  #TAUTHOR_TAG establish a preliminary study of social bias in bert, but their analysis relies only on sentence level encodings.', '']",6
"['.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'calisk']","['et al.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'caliskan']","['.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'calisk']","['adopt the methodology of caliskan et al. [ 5 ] and may et al.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'caliskan et al. [ 5 ] proposed word embedding association tests ( weats ), which follows human implicit association tests [ 14 ] in measuring the association between two target concepts and two attributes.', 'we follow may et al.  #TAUTHOR_TAG in describing weats and seats.', 'let x and y be equal - size sets of target concept embeddings, and a and b be sets of attribute embeddings.', 'these embeddings are obtained after encoding a set of words which define the concept or attribute.', 'intuitively, weats measure the effect size of the association between a concept x with attribute a and concept y with attribute b, as opposed to concept x with attribute b and concept y with attribute a. the test statistic is', 'where each addend is the difference between the mean of cosine similarities of the respective attributes :', 's ( w, a, b ) = mean a∈a cos ( w, a ) − mean b∈b cos ( w, b ).', 'to compute the significance of the association between ( a, b ) and ( x, y ), a permutation test on s ( x, y, a, b ) is used.', 'where the probability is computed over the space of partitions ( x i, y i ) of x ∪ y so that x i and y i are of equal size.', 'the effect size is defined to be', 'a larger effect size corresponds to more severe pro - stereotypical representations, controlling for significance.', 'may et al.  #TAUTHOR_TAG adopt the weat tests [ 5 ] into sentence encoder association tests ( seats ) to test biases using sentence encodings.', 'the embeddings used in the association tests are encodings of a sentence, which are obtained by pooling per token contextual representations, or by using the representation of the first or last token.', 'seats are constructed from weats by using "" semantically bleached "" sentence templates such as "" this is a [ doctor ] "" or "" [ alice ] is here "".', 'these "" semantically bleached "" templates were created to observe the effect of a sentence encoding based on a given term, instead of the associations made with the context of other potentially semantically meaningful words.', 'we refer to weats and seats as caliskan tests [ 5 ]']",5
"['.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'calisk']","['et al.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'caliskan']","['.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'calisk']","['adopt the methodology of caliskan et al. [ 5 ] and may et al.  #TAUTHOR_TAG to test social and intersectional bias using embedding association tests with contextual word representations.', 'caliskan et al. [ 5 ] proposed word embedding association tests ( weats ), which follows human implicit association tests [ 14 ] in measuring the association between two target concepts and two attributes.', 'we follow may et al.  #TAUTHOR_TAG in describing weats and seats.', 'let x and y be equal - size sets of target concept embeddings, and a and b be sets of attribute embeddings.', 'these embeddings are obtained after encoding a set of words which define the concept or attribute.', 'intuitively, weats measure the effect size of the association between a concept x with attribute a and concept y with attribute b, as opposed to concept x with attribute b and concept y with attribute a. the test statistic is', 'where each addend is the difference between the mean of cosine similarities of the respective attributes :', 's ( w, a, b ) = mean a∈a cos ( w, a ) − mean b∈b cos ( w, b ).', 'to compute the significance of the association between ( a, b ) and ( x, y ), a permutation test on s ( x, y, a, b ) is used.', 'where the probability is computed over the space of partitions ( x i, y i ) of x ∪ y so that x i and y i are of equal size.', 'the effect size is defined to be', 'a larger effect size corresponds to more severe pro - stereotypical representations, controlling for significance.', 'may et al.  #TAUTHOR_TAG adopt the weat tests [ 5 ] into sentence encoder association tests ( seats ) to test biases using sentence encodings.', 'the embeddings used in the association tests are encodings of a sentence, which are obtained by pooling per token contextual representations, or by using the representation of the first or last token.', 'seats are constructed from weats by using "" semantically bleached "" sentence templates such as "" this is a [ doctor ] "" or "" [ alice ] is here "".', 'these "" semantically bleached "" templates were created to observe the effect of a sentence encoding based on a given term, instead of the associations made with the context of other potentially semantically meaningful words.', 'we refer to weats and seats as caliskan tests [ 5 ]']",5
"['bind [ 15,  #TAUTHOR_TAG.', '']","['bind [ 15,  #TAUTHOR_TAG.', '']","['arts ) [ 5 ] and the heilman double bind [ 15,  #TAUTHOR_TAG.', '']","['investigate social and intersectional bias, we introduce new embedding association tests to more comprehensively target race, gender and intersectional identities.', 'the new tests are prefixed by a "" + "" in tables 3, 4 and 5.', 'for race and gender, we are interested in attributes of pleasantness ( p / u : pleasant / unpleasant ), work ( career / family ), discipline ( science / arts ) [ 5 ] and the heilman double bind [ 15,  #TAUTHOR_TAG.', 'the heilman double bind refers to how women, when clearly succeeding in a stereotypically male occupation, are perceived as less likable than similar men, and how women, when success is more ambiguous, are perceived as less competent than similar men.', 'although the heilman double bind originated in the context of gender, we also extend the attribute lists 3 of competence and likability to the context of race.', 'we preserve and report the original weats, seats and tests introduced by may et al.  #TAUTHOR_TAG where possible.', 'we also prefer tests using names ( e. g. alice ) as concept words over group terms ( e. g. european american ), since names were demonstrated to have a significant association more often than group terms  #TAUTHOR_TAG for intersectional identities, we are focused primarily on the identity which is the subject of discussion in the work of crenshaw [ 9 ] : being both african american and female.', 'specifically,  #TAUTHOR_TAG, which targets the stereotype of black women as loud, angry, and imposing [ 8 ].', '']",5
"['bind [ 15,  #TAUTHOR_TAG.', '']","['bind [ 15,  #TAUTHOR_TAG.', '']","['arts ) [ 5 ] and the heilman double bind [ 15,  #TAUTHOR_TAG.', '']","['investigate social and intersectional bias, we introduce new embedding association tests to more comprehensively target race, gender and intersectional identities.', 'the new tests are prefixed by a "" + "" in tables 3, 4 and 5.', 'for race and gender, we are interested in attributes of pleasantness ( p / u : pleasant / unpleasant ), work ( career / family ), discipline ( science / arts ) [ 5 ] and the heilman double bind [ 15,  #TAUTHOR_TAG.', 'the heilman double bind refers to how women, when clearly succeeding in a stereotypically male occupation, are perceived as less likable than similar men, and how women, when success is more ambiguous, are perceived as less competent than similar men.', 'although the heilman double bind originated in the context of gender, we also extend the attribute lists 3 of competence and likability to the context of race.', 'we preserve and report the original weats, seats and tests introduced by may et al.  #TAUTHOR_TAG where possible.', 'we also prefer tests using names ( e. g. alice ) as concept words over group terms ( e. g. european american ), since names were demonstrated to have a significant association more often than group terms  #TAUTHOR_TAG for intersectional identities, we are focused primarily on the identity which is the subject of discussion in the work of crenshaw [ 9 ] : being both african american and female.', 'specifically,  #TAUTHOR_TAG, which targets the stereotype of black women as loud, angry, and imposing [ 8 ].', '']",5
"['bind [ 15,  #TAUTHOR_TAG.', '']","['bind [ 15,  #TAUTHOR_TAG.', '']","['arts ) [ 5 ] and the heilman double bind [ 15,  #TAUTHOR_TAG.', '']","['investigate social and intersectional bias, we introduce new embedding association tests to more comprehensively target race, gender and intersectional identities.', 'the new tests are prefixed by a "" + "" in tables 3, 4 and 5.', 'for race and gender, we are interested in attributes of pleasantness ( p / u : pleasant / unpleasant ), work ( career / family ), discipline ( science / arts ) [ 5 ] and the heilman double bind [ 15,  #TAUTHOR_TAG.', 'the heilman double bind refers to how women, when clearly succeeding in a stereotypically male occupation, are perceived as less likable than similar men, and how women, when success is more ambiguous, are perceived as less competent than similar men.', 'although the heilman double bind originated in the context of gender, we also extend the attribute lists 3 of competence and likability to the context of race.', 'we preserve and report the original weats, seats and tests introduced by may et al.  #TAUTHOR_TAG where possible.', 'we also prefer tests using names ( e. g. alice ) as concept words over group terms ( e. g. european american ), since names were demonstrated to have a significant association more often than group terms  #TAUTHOR_TAG for intersectional identities, we are focused primarily on the identity which is the subject of discussion in the work of crenshaw [ 9 ] : being both african american and female.', 'specifically,  #TAUTHOR_TAG, which targets the stereotype of black women as loud, angry, and imposing [ 8 ].', '']",5
"['1,  #TAUTHOR_TAG 35 ], we also report on other word representation models : cbow - glove']","['work [ 1,  #TAUTHOR_TAG 35 ], we also report on other word representation models : cbow - glove [ 24 ], elmo [ 25 ]']","['its 117m and 345m versions.', 'for comparison with previous work [ 1,  #TAUTHOR_TAG 35 ], we also report on other word representation models : cbow - glove [ 24 ], elmo [ 25 ]']","['investigate biases in gpt - 2 [ 27 ], one of the state - of - the - art models for contextual word representations, in both its 117m and 345m versions.', 'for comparison with previous work [ 1,  #TAUTHOR_TAG 35 ], we also report on other word representation models : cbow - glove [ 24 ], elmo [ 25 ], bert bert - base - cased ( bbc ) and bert - large - cased ( blc ) versions [ 10 ], and gpt [ 26 ].', 'for all association tests, we use p = 0. 01 for significance testing.', 'we use pytorch, as well as the framework and code from may et al.  #TAUTHOR_TAG, to conduct the experiments 6']",5
"['1,  #TAUTHOR_TAG 35 ], we also report on other word representation models : cbow - glove']","['work [ 1,  #TAUTHOR_TAG 35 ], we also report on other word representation models : cbow - glove [ 24 ], elmo [ 25 ]']","['its 117m and 345m versions.', 'for comparison with previous work [ 1,  #TAUTHOR_TAG 35 ], we also report on other word representation models : cbow - glove [ 24 ], elmo [ 25 ]']","['investigate biases in gpt - 2 [ 27 ], one of the state - of - the - art models for contextual word representations, in both its 117m and 345m versions.', 'for comparison with previous work [ 1,  #TAUTHOR_TAG 35 ], we also report on other word representation models : cbow - glove [ 24 ], elmo [ 25 ], bert bert - base - cased ( bbc ) and bert - large - cased ( blc ) versions [ 10 ], and gpt [ 26 ].', 'for all association tests, we use p = 0. 01 for significance testing.', 'we use pytorch, as well as the framework and code from may et al.  #TAUTHOR_TAG, to conduct the experiments 6']",5
"['.  #TAUTHOR_TAG, the']","['may et al.  #TAUTHOR_TAG, the']","['.  #TAUTHOR_TAG, the sentence encoding of elmo is a sequence of vectors, one for each token.', 'we use mean - pooling over the tokens, followed by']","['may et al.  #TAUTHOR_TAG, the sentence encoding of elmo is a sequence of vectors, one for each token.', '']",5
['.  #TAUTHOR_TAG and'],['et al.  #TAUTHOR_TAG and'],"['.  #TAUTHOR_TAG and the original word [ 26 ], we use the representation corresponding']","['to may et al.  #TAUTHOR_TAG and the original word [ 26 ], we use the representation corresponding to the last word in the sequence as the sentence encoding.', 'at the contextual word level, we use the representation corresponding to the token of interest.', 'gpt also uses subword tokenization, so the start of the token is used if the token of interest is subword tokenized.', 'both encoding types are 768 - dimensional.', 'different from may et al.  #TAUTHOR_TAG, we use the implementation of gpt from hugging face, and not the jiant project 10.', 'prefix weat but sentence level tests have the prefix sent - weat.', '']",5
"['.  #TAUTHOR_TAG, in the continuous bag of words (']","['al.  #TAUTHOR_TAG, in the continuous bag of words ( cbow ) model we encode sentences as the average of word embeddings using 300 - dimensional glove vectors 7 trained on the common crawl corpus [ 24 ].', 'there is no corresponding contextual word level equivalent since glove is context - free']","['.  #TAUTHOR_TAG, in the continuous bag of words (']","['', 'furthermore, methods for de - biasing specifically across race, gender, and intersectional identities remains a challenging open question.', 'similar to may et al.  #TAUTHOR_TAG, in the continuous bag of words ( cbow ) model we encode sentences as the average of word embeddings using 300 - dimensional glove vectors 7 trained on the common crawl corpus [ 24 ].', 'there is no corresponding contextual word level equivalent since glove is context - free']",3
['.  #TAUTHOR_TAG and'],['et al.  #TAUTHOR_TAG and'],"['.  #TAUTHOR_TAG and the original word [ 26 ], we use the representation corresponding']","['to may et al.  #TAUTHOR_TAG and the original word [ 26 ], we use the representation corresponding to the last word in the sequence as the sentence encoding.', 'at the contextual word level, we use the representation corresponding to the token of interest.', 'gpt also uses subword tokenization, so the start of the token is used if the token of interest is subword tokenized.', 'both encoding types are 768 - dimensional.', 'different from may et al.  #TAUTHOR_TAG, we use the implementation of gpt from hugging face, and not the jiant project 10.', 'prefix weat but sentence level tests have the prefix sent - weat.', '']",3
['.  #TAUTHOR_TAG and'],['et al.  #TAUTHOR_TAG and'],"['.  #TAUTHOR_TAG and the original word [ 26 ], we use the representation corresponding']","['to may et al.  #TAUTHOR_TAG and the original word [ 26 ], we use the representation corresponding to the last word in the sequence as the sentence encoding.', 'at the contextual word level, we use the representation corresponding to the token of interest.', 'gpt also uses subword tokenization, so the start of the token is used if the token of interest is subword tokenized.', 'both encoding types are 768 - dimensional.', 'different from may et al.  #TAUTHOR_TAG, we use the implementation of gpt from hugging face, and not the jiant project 10.', 'prefix weat but sentence level tests have the prefix sent - weat.', '']",4
"['adjusting the text to the reader (', 'danescu - niculescu -  #AUTHOR_TAG, but can also play an important role in identifying authorial style  #TAUTHOR_TAG', '. davenport and de  #AUTHOR_TAG report negative']","['adjusting the text to the reader (', 'danescu - niculescu -  #AUTHOR_TAG, but can also play an important role in identifying authorial style  #TAUTHOR_TAG', '. davenport and de  #AUTHOR_TAG report negative']","['adjusting the text to the reader (', 'danescu - niculescu -  #AUTHOR_TAG, but can also play an important role in identifying authorial style  #TAUTHOR_TAG', '. davenport and de  #AUTHOR_TAG report negative']","['measuring stylistic differences. we examine writing style of users on twitter in relation to their age and income', '. both attributes should be closely related to writing style : users of older age write on average more standard', '- conform ( up to a certain point ), and higher income is an indicator of education and conscientiousness  #AUTHOR_TAG, which determines writing style. indeed, many features that aim to measure the complexity of the language use have been developed in', 'order to study human cognitive abilities, e. g., cognitive decline ( boye et al., 2014 ;  #AUTHOR_TAG. the relationship between age and language has been extensively studied by psychologists, and more recently by computational linguists in various corpora, including social media.  #AUTHOR_TAG', 'connect language use with style and personality, while  #AUTHOR_TAG automatically classified blogs text', 'into three classes based on self - reported age using part - of - speech features.  #AUTHOR_TAG uncover some consistent age patterns in part - of - speech usage across languages, while rosenthal and mc  #AUTHOR_TAG studies the use', 'of internet specific phenomena such as slang, acronyms and capitalisation patterns. preotiuc -  #AUTHOR_TAG study differences in paraphrase choice between older and younger twitter users as a', 'measure of style.  #AUTHOR_TAG analyzed the relationship between language use and age', ', modelled as a continuous variable. they found similar language usage trends for both genders, with increasing word', 'and tweet length with age, and an increasing tendency to write more grammatically correct, standardized text. such findings encourage further research in the area of measuring readability, which not only facilitates adjusting the text to the reader (', 'danescu - niculescu -  #AUTHOR_TAG, but can also play an important role in identifying authorial style  #TAUTHOR_TAG', '. davenport and de  #AUTHOR_TAG report negative correlation between tweet readability (', 'i. e., simplicity ) and the percentage of people with college degree in the area.  #AUTHOR_TAG employ language use as a socio - demographic predictor. in this paper we analyze two data sets of millions of tweets produced by thousands of users annotated with', 'their age and income. we define a set of features ranging from readability and style to syntactic features. we use both linear and non - linear machine learning regression methods to predict and analyze user income and age. we', 'show that writing style measures give large correlations with both age and income, and that writing style is predictive of income even beyond age. finally,', 'twitter data allows the unique possibility to study the variation in writing with time. we explore the effects of time of day in user behavior dependent in part on the socio -', 'demographic group']",0
"['measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","['measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","[':', 'surface we measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","['use a variety of features to capture the language behavior of a user.', 'we group these features into :', 'surface we measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG, we also measure the ratio of words longer than five letters.', 'we further calculate the type - token ratio per user, which indicates the lexical density of text and is considered to be a readability predictor  #AUTHOR_TAG.', 'additionally we capture the number of positive and negative smileys in the tweet and the number of urls.', 'readability after filtering tweets to contain only words, we use the most prominent readability measures per user : the automatic readability index  #AUTHOR_TAG, the fleschkincaid grade level  #AUTHOR_TAG, the coleman - liau index  #AUTHOR_TAG, the flesch reading ease  #AUTHOR_TAG, the lix index  #AUTHOR_TAG, the smog grade ( mc  #AUTHOR_TAG and the gunning - fog index  #AUTHOR_TAG.', 'the majority of those are computed using the average word and sentence lengths and number of syllables per sentence, combined with weights.', 'syntax researchers argue about longer sentences not necessarily being more complex in terms of syntax  #TAUTHOR_TAG.', 'however, advanced sentence parsing on twitter remains a challenging task.', 'we thus limit ourselves in this study to the part - of - speech ( pos ) information.', 'in previous work on writing style  #AUTHOR_TAG, a text with more nouns and articles as opposed to pronouns and adverbs is considered more formal.', 'we thus measure the ratio of each pos using the universal tagset  #AUTHOR_TAG.', 'style we implemented a contextuality measure, based on the work of  #AUTHOR_TAG, which assesses explicitness of the text based on the pos used and serves as a proxy for formality.', 'using stanford named entity recognizer  #AUTHOR_TAG, we measure the proportion of named entities ( 3 - classed ) to words, as their presence potentially decreases readability  #AUTHOR_TAG, and netspeak aspects such as the proportion of elongations ( wooow ) and words with numbers ( good n8 ).', 'we quantify the number of hedges  #AUTHOR_TAG and abstract words 1 used, and the ratio of standalone numbers stated per user as these are indicators of specificity  #TAUTHOR_TAG.', 'we also capture the ratio of hapax legomena, and of superlatives and plurals using stanford pos tagger 1 www. englishbanana. com  #AUTHOR_TAG using the twitter model']",0
"['measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","['measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","[':', 'surface we measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","['use a variety of features to capture the language behavior of a user.', 'we group these features into :', 'surface we measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG, we also measure the ratio of words longer than five letters.', 'we further calculate the type - token ratio per user, which indicates the lexical density of text and is considered to be a readability predictor  #AUTHOR_TAG.', 'additionally we capture the number of positive and negative smileys in the tweet and the number of urls.', 'readability after filtering tweets to contain only words, we use the most prominent readability measures per user : the automatic readability index  #AUTHOR_TAG, the fleschkincaid grade level  #AUTHOR_TAG, the coleman - liau index  #AUTHOR_TAG, the flesch reading ease  #AUTHOR_TAG, the lix index  #AUTHOR_TAG, the smog grade ( mc  #AUTHOR_TAG and the gunning - fog index  #AUTHOR_TAG.', 'the majority of those are computed using the average word and sentence lengths and number of syllables per sentence, combined with weights.', 'syntax researchers argue about longer sentences not necessarily being more complex in terms of syntax  #TAUTHOR_TAG.', 'however, advanced sentence parsing on twitter remains a challenging task.', 'we thus limit ourselves in this study to the part - of - speech ( pos ) information.', 'in previous work on writing style  #AUTHOR_TAG, a text with more nouns and articles as opposed to pronouns and adverbs is considered more formal.', 'we thus measure the ratio of each pos using the universal tagset  #AUTHOR_TAG.', 'style we implemented a contextuality measure, based on the work of  #AUTHOR_TAG, which assesses explicitness of the text based on the pos used and serves as a proxy for formality.', 'using stanford named entity recognizer  #AUTHOR_TAG, we measure the proportion of named entities ( 3 - classed ) to words, as their presence potentially decreases readability  #AUTHOR_TAG, and netspeak aspects such as the proportion of elongations ( wooow ) and words with numbers ( good n8 ).', 'we quantify the number of hedges  #AUTHOR_TAG and abstract words 1 used, and the ratio of standalone numbers stated per user as these are indicators of specificity  #TAUTHOR_TAG.', 'we also capture the ratio of hapax legomena, and of superlatives and plurals using stanford pos tagger 1 www. englishbanana. com  #AUTHOR_TAG using the twitter model']",0
"['measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","['measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","[':', 'surface we measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","['use a variety of features to capture the language behavior of a user.', 'we group these features into :', 'surface we measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG, we also measure the ratio of words longer than five letters.', 'we further calculate the type - token ratio per user, which indicates the lexical density of text and is considered to be a readability predictor  #AUTHOR_TAG.', 'additionally we capture the number of positive and negative smileys in the tweet and the number of urls.', 'readability after filtering tweets to contain only words, we use the most prominent readability measures per user : the automatic readability index  #AUTHOR_TAG, the fleschkincaid grade level  #AUTHOR_TAG, the coleman - liau index  #AUTHOR_TAG, the flesch reading ease  #AUTHOR_TAG, the lix index  #AUTHOR_TAG, the smog grade ( mc  #AUTHOR_TAG and the gunning - fog index  #AUTHOR_TAG.', 'the majority of those are computed using the average word and sentence lengths and number of syllables per sentence, combined with weights.', 'syntax researchers argue about longer sentences not necessarily being more complex in terms of syntax  #TAUTHOR_TAG.', 'however, advanced sentence parsing on twitter remains a challenging task.', 'we thus limit ourselves in this study to the part - of - speech ( pos ) information.', 'in previous work on writing style  #AUTHOR_TAG, a text with more nouns and articles as opposed to pronouns and adverbs is considered more formal.', 'we thus measure the ratio of each pos using the universal tagset  #AUTHOR_TAG.', 'style we implemented a contextuality measure, based on the work of  #AUTHOR_TAG, which assesses explicitness of the text based on the pos used and serves as a proxy for formality.', 'using stanford named entity recognizer  #AUTHOR_TAG, we measure the proportion of named entities ( 3 - classed ) to words, as their presence potentially decreases readability  #AUTHOR_TAG, and netspeak aspects such as the proportion of elongations ( wooow ) and words with numbers ( good n8 ).', 'we quantify the number of hedges  #AUTHOR_TAG and abstract words 1 used, and the ratio of standalone numbers stated per user as these are indicators of specificity  #TAUTHOR_TAG.', 'we also capture the ratio of hapax legomena, and of superlatives and plurals using stanford pos tagger 1 www. englishbanana. com  #AUTHOR_TAG using the twitter model']",0
"['measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","['measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","[':', 'surface we measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","['use a variety of features to capture the language behavior of a user.', 'we group these features into :', 'surface we measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG, we also measure the ratio of words longer than five letters.', 'we further calculate the type - token ratio per user, which indicates the lexical density of text and is considered to be a readability predictor  #AUTHOR_TAG.', 'additionally we capture the number of positive and negative smileys in the tweet and the number of urls.', 'readability after filtering tweets to contain only words, we use the most prominent readability measures per user : the automatic readability index  #AUTHOR_TAG, the fleschkincaid grade level  #AUTHOR_TAG, the coleman - liau index  #AUTHOR_TAG, the flesch reading ease  #AUTHOR_TAG, the lix index  #AUTHOR_TAG, the smog grade ( mc  #AUTHOR_TAG and the gunning - fog index  #AUTHOR_TAG.', 'the majority of those are computed using the average word and sentence lengths and number of syllables per sentence, combined with weights.', 'syntax researchers argue about longer sentences not necessarily being more complex in terms of syntax  #TAUTHOR_TAG.', 'however, advanced sentence parsing on twitter remains a challenging task.', 'we thus limit ourselves in this study to the part - of - speech ( pos ) information.', 'in previous work on writing style  #AUTHOR_TAG, a text with more nouns and articles as opposed to pronouns and adverbs is considered more formal.', 'we thus measure the ratio of each pos using the universal tagset  #AUTHOR_TAG.', 'style we implemented a contextuality measure, based on the work of  #AUTHOR_TAG, which assesses explicitness of the text based on the pos used and serves as a proxy for formality.', 'using stanford named entity recognizer  #AUTHOR_TAG, we measure the proportion of named entities ( 3 - classed ) to words, as their presence potentially decreases readability  #AUTHOR_TAG, and netspeak aspects such as the proportion of elongations ( wooow ) and words with numbers ( good n8 ).', 'we quantify the number of hedges  #AUTHOR_TAG and abstract words 1 used, and the ratio of standalone numbers stated per user as these are indicators of specificity  #TAUTHOR_TAG.', 'we also capture the ratio of hapax legomena, and of superlatives and plurals using stanford pos tagger 1 www. englishbanana. com  #AUTHOR_TAG using the twitter model']",5
"['measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","['measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","[':', 'surface we measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG,']","['use a variety of features to capture the language behavior of a user.', 'we group these features into :', 'surface we measure the length of tweets in words and characters, and the length of words.', 'as shorter words are considered more readable  #TAUTHOR_TAG, we also measure the ratio of words longer than five letters.', 'we further calculate the type - token ratio per user, which indicates the lexical density of text and is considered to be a readability predictor  #AUTHOR_TAG.', 'additionally we capture the number of positive and negative smileys in the tweet and the number of urls.', 'readability after filtering tweets to contain only words, we use the most prominent readability measures per user : the automatic readability index  #AUTHOR_TAG, the fleschkincaid grade level  #AUTHOR_TAG, the coleman - liau index  #AUTHOR_TAG, the flesch reading ease  #AUTHOR_TAG, the lix index  #AUTHOR_TAG, the smog grade ( mc  #AUTHOR_TAG and the gunning - fog index  #AUTHOR_TAG.', 'the majority of those are computed using the average word and sentence lengths and number of syllables per sentence, combined with weights.', 'syntax researchers argue about longer sentences not necessarily being more complex in terms of syntax  #TAUTHOR_TAG.', 'however, advanced sentence parsing on twitter remains a challenging task.', 'we thus limit ourselves in this study to the part - of - speech ( pos ) information.', 'in previous work on writing style  #AUTHOR_TAG, a text with more nouns and articles as opposed to pronouns and adverbs is considered more formal.', 'we thus measure the ratio of each pos using the universal tagset  #AUTHOR_TAG.', 'style we implemented a contextuality measure, based on the work of  #AUTHOR_TAG, which assesses explicitness of the text based on the pos used and serves as a proxy for formality.', 'using stanford named entity recognizer  #AUTHOR_TAG, we measure the proportion of named entities ( 3 - classed ) to words, as their presence potentially decreases readability  #AUTHOR_TAG, and netspeak aspects such as the proportion of elongations ( wooow ) and words with numbers ( good n8 ).', 'we quantify the number of hedges  #AUTHOR_TAG and abstract words 1 used, and the ratio of standalone numbers stated per user as these are indicators of specificity  #TAUTHOR_TAG.', 'we also capture the ratio of hapax legomena, and of superlatives and plurals using stanford pos tagger 1 www. englishbanana. com  #AUTHOR_TAG using the twitter model']",5
"['are many methods for recognising timexes that are widely used in natural language engineering.', 'for english ( but not exclusively ), in approaches based on supervised learning, sequence labelling methods are often used, especially conditional random fields [ 15 ].', 'a review of the methods in the article  #TAUTHOR_TAG about the']","['are many methods for recognising timexes that are widely used in natural language engineering.', 'for english ( but not exclusively ), in approaches based on supervised learning, sequence labelling methods are often used, especially conditional random fields [ 15 ].', 'a review of the methods in the article  #TAUTHOR_TAG about the']","['are many methods for recognising timexes that are widely used in natural language engineering.', 'for english ( but not exclusively ), in approaches based on supervised learning, sequence labelling methods are often used, especially conditional random fields [ 15 ].', 'a review of the methods in the article  #TAUTHOR_TAG about the recognition of timexes for english and spanish has shown a certain shift within']","['are many methods for recognising timexes that are widely used in natural language engineering.', 'for english ( but not exclusively ), in approaches based on supervised learning, sequence labelling methods are often used, especially conditional random fields [ 15 ].', 'a review of the methods in the article  #TAUTHOR_TAG about the recognition of timexes for english and spanish has shown a certain shift within the most popular solutions.', 'as with the normalisation of timexes, the best results are still achieved with rule - based methods, many new solutions have been introduced in the area of recognition.', 'the best systems listed in  #TAUTHOR_TAG, called tipsem [ 16 ] and cleartk [ 1 ], use crfs for recognition, so initially, we decided to apply the crf - based approach for this task.', 'the results were described in [ 12, 10 ].', 'in recent years, solutions based on deep neural networks, using word representation in the form of word embeddings, created with the use of large linguistic corpus, have begun to dominate in the field of recognition of word expressions.', 'the most popular solutions include bidirectional long short - term memory neural networks ( henceforth bi - lstm ), often in combination with conditional random fields, as presented in the paper [ 5 ] dedicated to the recognition of proper names.', 'for the polish language, deep networks have also recently been used to recognise word expressions.', 'in the issue of recognition of timexes, a bidirectional gated recurrent unit network ( gru ) has been used [ 21, 22 ].', 'gru network is described in detail in the article [ 3 ].', 'in case of recognition of event descriptions using bi - lstm and bi - gru, where most of the liner2 features were included in the input feature vector, better results were obtained [ 8 ] than for the liner2 method ( but without taking into account domain dictionaries ).', ""in last year's publication on the issue of named entities recognition using bilstm + crf ( together with g4. 19 group 9 members ), we received a statistically significant improvement in the quality of recognition compared to a solution using crf only."", 'the solution has been called poldeepner 10 [ 17 ]']",5
"['are many methods for recognising timexes that are widely used in natural language engineering.', 'for english ( but not exclusively ), in approaches based on supervised learning, sequence labelling methods are often used, especially conditional random fields [ 15 ].', 'a review of the methods in the article  #TAUTHOR_TAG about the']","['are many methods for recognising timexes that are widely used in natural language engineering.', 'for english ( but not exclusively ), in approaches based on supervised learning, sequence labelling methods are often used, especially conditional random fields [ 15 ].', 'a review of the methods in the article  #TAUTHOR_TAG about the']","['are many methods for recognising timexes that are widely used in natural language engineering.', 'for english ( but not exclusively ), in approaches based on supervised learning, sequence labelling methods are often used, especially conditional random fields [ 15 ].', 'a review of the methods in the article  #TAUTHOR_TAG about the recognition of timexes for english and spanish has shown a certain shift within']","['are many methods for recognising timexes that are widely used in natural language engineering.', 'for english ( but not exclusively ), in approaches based on supervised learning, sequence labelling methods are often used, especially conditional random fields [ 15 ].', 'a review of the methods in the article  #TAUTHOR_TAG about the recognition of timexes for english and spanish has shown a certain shift within the most popular solutions.', 'as with the normalisation of timexes, the best results are still achieved with rule - based methods, many new solutions have been introduced in the area of recognition.', 'the best systems listed in  #TAUTHOR_TAG, called tipsem [ 16 ] and cleartk [ 1 ], use crfs for recognition, so initially, we decided to apply the crf - based approach for this task.', 'the results were described in [ 12, 10 ].', 'in recent years, solutions based on deep neural networks, using word representation in the form of word embeddings, created with the use of large linguistic corpus, have begun to dominate in the field of recognition of word expressions.', 'the most popular solutions include bidirectional long short - term memory neural networks ( henceforth bi - lstm ), often in combination with conditional random fields, as presented in the paper [ 5 ] dedicated to the recognition of proper names.', 'for the polish language, deep networks have also recently been used to recognise word expressions.', 'in the issue of recognition of timexes, a bidirectional gated recurrent unit network ( gru ) has been used [ 21, 22 ].', 'gru network is described in detail in the article [ 3 ].', 'in case of recognition of event descriptions using bi - lstm and bi - gru, where most of the liner2 features were included in the input feature vector, better results were obtained [ 8 ] than for the liner2 method ( but without taking into account domain dictionaries ).', ""in last year's publication on the issue of named entities recognition using bilstm + crf ( together with g4. 19 group 9 members ), we received a statistically significant improvement in the quality of recognition compared to a solution using crf only."", 'the solution has been called poldeepner 10 [ 17 ]']",5
"['in  #TAUTHOR_TAG.', 'the first part is described as task a, the purpose of which is to']","['in  #TAUTHOR_TAG.', 'the first part is described as task a, the purpose of which is to']","['in  #TAUTHOR_TAG.', 'the first part is described as task a, the purpose of which is to']","['were carried out by the method proposed in  #TAUTHOR_TAG.', 'the first part is described as task a, the purpose of which is to identify the boundaries of timexes and assign them to one of the following classes :', '9 http : / / nlp. pwr. edu. pl / 10 https : / / github. com / clarin - pl / poldeepner date, time, duration, set.', '[ % ] all 1635 100 train 1227 50 test 408 25 table 5 : evaluation data sets ( source : kpwr )']",5
"['using more detailed measures for timexes, presented in  #TAUTHOR_TAG.', 'the following measures were used to']","['using more detailed measures for timexes, presented in  #TAUTHOR_TAG.', 'the following measures were used to']","['##1 - scores for all models.', 'then we evaluated these results using more detailed measures for timexes, presented in  #TAUTHOR_TAG.', 'the following measures were used to']","['trained the final models using the train set and we evaluated it using the test set, which was the reproduction of analysis performed in articles [ 11, 9 ].', 'the division is presented in table??.', 'we used bilstm + crf classifier as in previous work [ 17 ].', 'we used precision, recall and f1 metrics from the classic ner task [ 17 ], where true positive system answer has the same boundaries and type as annotation in gold data set.', 'we evaluated all 17 word embeddings models using these metrics.', 'the results are presented in tables 6, 7 and 8.', 'we chose the best 3 results from each word embeddings group ( ee, ep, ec ) from table 8 presenting f1 - scores for all models.', 'then we evaluated these results using more detailed measures for timexes, presented in  #TAUTHOR_TAG.', 'the following measures were used to evaluate the quality of boundaries and class recognition, socalled strict match : strict precision ( str. p ), strict recall ( str. r ) and strict f1 - score ( str. f1 ).', 'a relaxed match ( rel.', '']",5
"['using more detailed measures for timexes, presented in  #TAUTHOR_TAG.', 'the following measures were used to']","['using more detailed measures for timexes, presented in  #TAUTHOR_TAG.', 'the following measures were used to']","['##1 - scores for all models.', 'then we evaluated these results using more detailed measures for timexes, presented in  #TAUTHOR_TAG.', 'the following measures were used to']","['trained the final models using the train set and we evaluated it using the test set, which was the reproduction of analysis performed in articles [ 11, 9 ].', 'the division is presented in table??.', 'we used bilstm + crf classifier as in previous work [ 17 ].', 'we used precision, recall and f1 metrics from the classic ner task [ 17 ], where true positive system answer has the same boundaries and type as annotation in gold data set.', 'we evaluated all 17 word embeddings models using these metrics.', 'the results are presented in tables 6, 7 and 8.', 'we chose the best 3 results from each word embeddings group ( ee, ep, ec ) from table 8 presenting f1 - scores for all models.', 'then we evaluated these results using more detailed measures for timexes, presented in  #TAUTHOR_TAG.', 'the following measures were used to evaluate the quality of boundaries and class recognition, socalled strict match : strict precision ( str. p ), strict recall ( str. r ) and strict f1 - score ( str. f1 ).', 'a relaxed match ( rel.', '']",5
['8 ) using the following measures from  #TAUTHOR_TAG : strict'],"['8 ) using the following measures from  #TAUTHOR_TAG : strict precision, strict recall, strict f1 - score, relaxed precision, relaxed recall, relaxed f1 - score, type f1 - score']","['9 word embeddings models ( 3 best models from each embeddings group : ee, ep, ec from table 8 ) using the following measures from  #TAUTHOR_TAG : strict precision, strict recall, strict f1 - score, relaxed precision, relaxed recall, relaxed f1 - score, type f1 - score']","['', 'table 9 : evaluation results for all timex3 classes ( total ) for 9 word embeddings models ( 3 best models from each embeddings group : ee, ep, ec from table 8 ) using the following measures from  #TAUTHOR_TAG : strict precision, strict recall, strict f1 - score, relaxed precision, relaxed recall, relaxed f1 - score, type f1 - score']",5
['##speech ( pos ) tagging  #TAUTHOR_TAG'],['( pos ) tagging  #TAUTHOR_TAG'],"['neural cross - lingual part - ofspeech ( pos ) tagging  #TAUTHOR_TAG.', 'however, little is known on']","['natural language processing, the deep learning revolution has shifted the focus from conventional hand - crafted symbolic representations to dense inputs, which are adequate representations learned automatically from corpora.', 'however, particularly when working with low - resource languages, small amounts of symbolic lexical resources such as user - generated lexicons are often available even when gold - standard corpora are not.', 'recent work has shown benefits of combining conventional lexical information into neural cross - lingual part - ofspeech ( pos ) tagging  #TAUTHOR_TAG.', 'however, little is known on how complementary such additional information is, and to what extent improvements depend on the coverage and quality of these external resources.', ""the contribution of this paper is in the analysis of the contributions of models'components ( tagger transfer through annotation projection vs. the contribution of encoding lexical and morphosyntactic resources )."", 'we seek to understand under which conditions a low - resource neural tagger benefits from external lexical knowledge.', 'in particular : a ) we evaluate the neural tagger across a total of 20 + languages, proposing a novel baseline which uses retrofitting ; b ) we investigate the reliance on dictionary size and properties ; c ) we analyze model - internal representations via a probing task to investigate to what extent model - internal representations capture morphosyntactic information.', 'our experiments confirm the synergetic effect between a neural tagger and symbolic linguistic knowledge.', 'moreover, our analysis shows that the composition of the dictionary plays a more important role than its coverage']",0
"['1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection to build the taggers for new languages, we resort to annotation projection following  #TAUTHOR_TAG.', 'in particular, they employ the approach by agic et al. ( 2016 ), where labels are projected from multiple sources to multiple targets and then decoded through weighted majority voting with word alignment probabilities and source pos tagger confidences.', 'the wide - coverage watchtower corpus ( wtc ) by agic et al. ( 2016 ) is used, where 5k instances are selected via data selection by alignment coverage following  #TAUTHOR_TAG.', 'baselines we compare to the following alternatives : type - constraint wiktionary supervision  #AUTHOR_TAG and retrofitting initialization.', 'hyperparameters we use the same setup as  #TAUTHOR_TAG, i. e., 10 epochs, word dropout rate ( p =. 25 ) and l = 40 - dimensional lexicon embeddings for dsds, except for downscaling the hidden dimensionality of the character representations from 100 to 32 dimensions.', 'this ensures that our probing tasks always get the same input dimensionality : 64 ( 2x32 ) dimensions for cw, which is the same dimension as the off - theshelf word embeddings.', 'language - specific hyperparameters could lead to optimized models for each language.', 'however, we use identical settings for each language which worked well and is less expensive, following  #AUTHOR_TAG.', 'for all experiments, we average over 3 randomly seeded runs, and provide mean accuracy.', 'we use the off - the - shelf polyglot word embeddings ( al -  #AUTHOR_TAG.', 'word embedding initialization provides a consistent and considerable boost in this cross - lingual setup, up to 10 % absolute improvements across 21 languages when only 500 projected training instances are available  #TAUTHOR_TAG.', 'note that we em - pirically find it to be best to not update the word embeddings in this noisy training setup, as that results in better performance, see section 4. 4']",0
['##speech ( pos ) tagging  #TAUTHOR_TAG'],['( pos ) tagging  #TAUTHOR_TAG'],"['neural cross - lingual part - ofspeech ( pos ) tagging  #TAUTHOR_TAG.', 'however, little is known on']","['natural language processing, the deep learning revolution has shifted the focus from conventional hand - crafted symbolic representations to dense inputs, which are adequate representations learned automatically from corpora.', 'however, particularly when working with low - resource languages, small amounts of symbolic lexical resources such as user - generated lexicons are often available even when gold - standard corpora are not.', 'recent work has shown benefits of combining conventional lexical information into neural cross - lingual part - ofspeech ( pos ) tagging  #TAUTHOR_TAG.', 'however, little is known on how complementary such additional information is, and to what extent improvements depend on the coverage and quality of these external resources.', ""the contribution of this paper is in the analysis of the contributions of models'components ( tagger transfer through annotation projection vs. the contribution of encoding lexical and morphosyntactic resources )."", 'we seek to understand under which conditions a low - resource neural tagger benefits from external lexical knowledge.', 'in particular : a ) we evaluate the neural tagger across a total of 20 + languages, proposing a novel baseline which uses retrofitting ; b ) we investigate the reliance on dictionary size and properties ; c ) we analyze model - internal representations via a probing task to investigate to what extent model - internal representations capture morphosyntactic information.', 'our experiments confirm the synergetic effect between a neural tagger and symbolic linguistic knowledge.', 'moreover, our analysis shows that the composition of the dictionary plays a more important role than its coverage']",1
[' #TAUTHOR_TAG'],['tagger  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['use linguistic resources that are user - generated and available for many languages.', 'the first is wiktionary, a word type dictionary that maps words to one of the 12 universal pos tags  #AUTHOR_TAG.', 'the second resource is unimorph, a morphological dictionary that provides inflectional paradigms for 350 languages  #AUTHOR_TAG.', 'for wiktionary, we use the freely available dictionaries from  #AUTHOR_TAG.', 'unimorph covers between 8 - 38 morphological properties ( for english and finnish, respectively ).', '1 the sizes of the dictionaries vary considerably, from a few thousand entries ( e. g., for hindi and bulgarian ) to 2m entries ( finnish uni - morph ).', 'we study the impact of smaller dictionary sizes in section 4. 1.', 'the tagger we analyze in this paper is an extension of the base tagger, called distant supervision from disparate sources ( dsds ) tagger  #TAUTHOR_TAG.', 'it is trained on projected data and further differs from the base tagger by the integration of lexicon information.', 'in particular, given a lexicon src, dsds uses e src to embed the lexicon into an l - dimensional space, where e src is the concatenation of all embedded m properties of length l ( empirically set, see section 2. 2 ), and a zero vector for words not in the lexicon.', 'a property here is a possible pos tag ( for wiktionary ) or a morphological feature ( for unimorph ).', 'to integrate the type - level supervision, the lexicon embeddings vector is created and concatenated to the word and character - level representations for every token : w • cw • e.', 'we compare dsds to alternative ways of using lexical information.', 'the first approach uses lexical information directly during decoding ( tackstrom et al., 2013 ).', 'the second approach is more implicit and uses the lexicon to induce better word embeddings for tagger initialization.', 'in particular, we use the dictionary for retrofitting off - the - shelf embeddings  #AUTHOR_TAG to initialize the tagger with those.', 'the latter is a novel approach which, to the best of our knowledge, has not yet been evaluated in the neural tagging literature.', 'the idea is to bring the off - theshelf embeddings closer to the pos tagging task by retrofitting the embeddings with syntactic clusters derived from the lexicon.', 'we take a deeper look at the quality of the lex - 1 more details : http : / / unimorph. org / icons by comparing tag sets to the gold treebank data, inspired by  #AUTHOR_TAG.', 'in particular, let t be the dictionary derived from the gold treebank ( development data']",5
"['1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection to build the taggers for new languages, we resort to annotation projection following  #TAUTHOR_TAG.', 'in particular, they employ the approach by agic et al. ( 2016 ), where labels are projected from multiple sources to multiple targets and then decoded through weighted majority voting with word alignment probabilities and source pos tagger confidences.', 'the wide - coverage watchtower corpus ( wtc ) by agic et al. ( 2016 ) is used, where 5k instances are selected via data selection by alignment coverage following  #TAUTHOR_TAG.', 'baselines we compare to the following alternatives : type - constraint wiktionary supervision  #AUTHOR_TAG and retrofitting initialization.', 'hyperparameters we use the same setup as  #TAUTHOR_TAG, i. e., 10 epochs, word dropout rate ( p =. 25 ) and l = 40 - dimensional lexicon embeddings for dsds, except for downscaling the hidden dimensionality of the character representations from 100 to 32 dimensions.', 'this ensures that our probing tasks always get the same input dimensionality : 64 ( 2x32 ) dimensions for cw, which is the same dimension as the off - theshelf word embeddings.', 'language - specific hyperparameters could lead to optimized models for each language.', 'however, we use identical settings for each language which worked well and is less expensive, following  #AUTHOR_TAG.', 'for all experiments, we average over 3 randomly seeded runs, and provide mean accuracy.', 'we use the off - the - shelf polyglot word embeddings ( al -  #AUTHOR_TAG.', 'word embedding initialization provides a consistent and considerable boost in this cross - lingual setup, up to 10 % absolute improvements across 21 languages when only 500 projected training instances are available  #TAUTHOR_TAG.', 'note that we em - pirically find it to be best to not update the word embeddings in this noisy training setup, as that results in better performance, see section 4. 4']",5
"['1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection to build the taggers for new languages, we resort to annotation projection following  #TAUTHOR_TAG.', 'in particular, they employ the approach by agic et al. ( 2016 ), where labels are projected from multiple sources to multiple targets and then decoded through weighted majority voting with word alignment probabilities and source pos tagger confidences.', 'the wide - coverage watchtower corpus ( wtc ) by agic et al. ( 2016 ) is used, where 5k instances are selected via data selection by alignment coverage following  #TAUTHOR_TAG.', 'baselines we compare to the following alternatives : type - constraint wiktionary supervision  #AUTHOR_TAG and retrofitting initialization.', 'hyperparameters we use the same setup as  #TAUTHOR_TAG, i. e., 10 epochs, word dropout rate ( p =. 25 ) and l = 40 - dimensional lexicon embeddings for dsds, except for downscaling the hidden dimensionality of the character representations from 100 to 32 dimensions.', 'this ensures that our probing tasks always get the same input dimensionality : 64 ( 2x32 ) dimensions for cw, which is the same dimension as the off - theshelf word embeddings.', 'language - specific hyperparameters could lead to optimized models for each language.', 'however, we use identical settings for each language which worked well and is less expensive, following  #AUTHOR_TAG.', 'for all experiments, we average over 3 randomly seeded runs, and provide mean accuracy.', 'we use the off - the - shelf polyglot word embeddings ( al -  #AUTHOR_TAG.', 'word embedding initialization provides a consistent and considerable boost in this cross - lingual setup, up to 10 % absolute improvements across 21 languages when only 500 projected training instances are available  #TAUTHOR_TAG.', 'note that we em - pirically find it to be best to not update the word embeddings in this noisy training setup, as that results in better performance, see section 4. 4']",5
"['1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection to build the taggers for new languages, we resort to annotation projection following  #TAUTHOR_TAG.', 'in particular, they employ the approach by agic et al. ( 2016 ), where labels are projected from multiple sources to multiple targets and then decoded through weighted majority voting with word alignment probabilities and source pos tagger confidences.', 'the wide - coverage watchtower corpus ( wtc ) by agic et al. ( 2016 ) is used, where 5k instances are selected via data selection by alignment coverage following  #TAUTHOR_TAG.', 'baselines we compare to the following alternatives : type - constraint wiktionary supervision  #AUTHOR_TAG and retrofitting initialization.', 'hyperparameters we use the same setup as  #TAUTHOR_TAG, i. e., 10 epochs, word dropout rate ( p =. 25 ) and l = 40 - dimensional lexicon embeddings for dsds, except for downscaling the hidden dimensionality of the character representations from 100 to 32 dimensions.', 'this ensures that our probing tasks always get the same input dimensionality : 64 ( 2x32 ) dimensions for cw, which is the same dimension as the off - theshelf word embeddings.', 'language - specific hyperparameters could lead to optimized models for each language.', 'however, we use identical settings for each language which worked well and is less expensive, following  #AUTHOR_TAG.', 'for all experiments, we average over 3 randomly seeded runs, and provide mean accuracy.', 'we use the off - the - shelf polyglot word embeddings ( al -  #AUTHOR_TAG.', 'word embedding initialization provides a consistent and considerable boost in this cross - lingual setup, up to 10 % absolute improvements across 21 languages when only 500 projected training instances are available  #TAUTHOR_TAG.', 'note that we em - pirically find it to be best to not update the word embeddings in this noisy training setup, as that results in better performance, see section 4. 4']",5
"['1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection to build the taggers for new languages, we resort to annotation projection following  #TAUTHOR_TAG.', 'in particular, they employ the approach by agic et al. ( 2016 ), where labels are projected from multiple sources to multiple targets and then decoded through weighted majority voting with word alignment probabilities and source pos tagger confidences.', 'the wide - coverage watchtower corpus ( wtc ) by agic et al. ( 2016 ) is used, where 5k instances are selected via data selection by alignment coverage following  #TAUTHOR_TAG.', 'baselines we compare to the following alternatives : type - constraint wiktionary supervision  #AUTHOR_TAG and retrofitting initialization.', 'hyperparameters we use the same setup as  #TAUTHOR_TAG, i. e., 10 epochs, word dropout rate ( p =. 25 ) and l = 40 - dimensional lexicon embeddings for dsds, except for downscaling the hidden dimensionality of the character representations from 100 to 32 dimensions.', 'this ensures that our probing tasks always get the same input dimensionality : 64 ( 2x32 ) dimensions for cw, which is the same dimension as the off - theshelf word embeddings.', 'language - specific hyperparameters could lead to optimized models for each language.', 'however, we use identical settings for each language which worked well and is less expensive, following  #AUTHOR_TAG.', 'for all experiments, we average over 3 randomly seeded runs, and provide mean accuracy.', 'we use the off - the - shelf polyglot word embeddings ( al -  #AUTHOR_TAG.', 'word embedding initialization provides a consistent and considerable boost in this cross - lingual setup, up to 10 % absolute improvements across 21 languages when only 500 projected training instances are available  #TAUTHOR_TAG.', 'note that we em - pirically find it to be best to not update the word embeddings in this noisy training setup, as that results in better performance, see section 4. 4']",5
"['of  #TAUTHOR_TAG, spanning from 1, 000 entries to considerable dictionaries of several hundred thousands entries.', 'in']","['of  #TAUTHOR_TAG, spanning from 1, 000 entries to considerable dictionaries of several hundred thousands entries.', 'in']","['of  #TAUTHOR_TAG, spanning from 1, 000 entries to considerable dictionaries of several hundred thousands entries.', 'in a low - resource setup, large dictionaries']","['lexicons we use so far are of different sizes ( shown in table 1 of  #TAUTHOR_TAG, spanning from 1, 000 entries to considerable dictionaries of several hundred thousands entries.', 'in a low - resource setup, large dictionaries might not be available.', 'it is thus interesting to examine how tagging accuracy is affected by dictionary size.', 'we examine two cases : randomly sampling dictionary entries and sampling by word frequency, over increasing dictionary sizes : 50, 100, 200, 400, 800, 1600 word types.', 'the latter is motivated by the fact that an informed dictionary creation ( under limited resources ) might be more beneficial.', 'we estimate word frequency by using the ud training data sets ( which are otherwise not used ).', 'guages ( with confidence intervals of ±1 standard deviation based on three runs ).', 'we note that sampling by frequency is overall more beneficial than random sampling.', 'the biggest effect of sampling by frequency is observed for the romance language family, see figure 3 ( b ).', 'it is noteworthy that more dictionary data is not always necessarily beneficial.', 'sometimes a small but high - frequency dictionary approximates the entire dictionary well.', ""this is for instance the case for danish, where sampling by frequency approximates the entire dictionary well ('all'achieves 90. 1, while using 100 most frequent entries is close : 89. 93 )."", 'frequency sampling also helps clearly for italian, but here having the entire dictionary results in the overall highest performance.', 'for some languages, the inclusion of lexical information does not help, not even at smaller dictionary sizes.', 'this is the case for hungarian, french and czech.', 'for hungarian using the entire dictionary drops performance below the baseline.', 'for czech, this is less pronounced, as the performance stays around baseline.', 'relating these negative ef - fects to the results from the tag set agreement analysis ( figure 1 ), we note that hungarian is the language with the largest disjoint tag set.', 'albeit the coverage for hungarian is good ( around. 5 ), including too much contradictory tag information has a clear deteriorating effect.', 'consequently, neither sampling strategy works.', 'czech, which has less coverage, sees a negative effect as well : half of the dictionary entries have disjoint tag sets.', 'italian is the language with the highest dictionary coverage and the highest proportion of equal tag sets, thereby providing a large positive benefit.', 'we conclude that when dictionaries are not available, creating them by targeting highfrequency items is a pragmatic and valuable strategy.', 'a small dictionary, which does not contain too contradictory tag sets, can be beneficial']",5
['model  #TAUTHOR_TAG'],['model  #TAUTHOR_TAG'],"['model  #TAUTHOR_TAG.', 'most prior work in this direction can be found on machine translation  #AUTHOR_TAG,']","['', 'therefore, we train the tagger with pre - trained embeddings on projected wtc data and freeze the word embeddings lookup layer during training.', 'in recent years, natural language processing has witnessed a move towards deep learning approaches, in which automatic representation learning has become the de facto standard methodology  #AUTHOR_TAG.', 'one of the first works that combines neural representations with semantic symbolic lexicons is the work on retrofitting  #AUTHOR_TAG.', 'the main idea is to use the relations defined in semantic lexicons to refine word embedding representations, such that words linked in the lexical resource are encouraged to be closer to each other in the distributional space.', 'the majority of recent work on neural sequence prediction follows the commonly perceived wisdom that hand - crafted features are obsolete for deep learning methods.', 'they rely on end - to - end training without resorting to additional linguistic resources.', 'our study contributes to the increasing literature to show the utility of linguistic resources for deep learning models by providing a deep analysis of a recently proposed model  #TAUTHOR_TAG.', 'most prior work in this direction can be found on machine translation  #AUTHOR_TAG, work on named entity recognition  #AUTHOR_TAG and pos tagging ( sagot and martinez  #AUTHOR_TAG who use lexicons, but as n - hot features and without examining the crosslingual aspect.', 'somewhat complementary to evaluating the utility of linguistic resources empirically is the increasing body of work that uses linguistic insights to try to understand what properties neural - based representations capture ( kadar et al., 2017 ;  #AUTHOR_TAG.', "" #AUTHOR_TAG and  #AUTHOR_TAG introduced the idea of probing tasks ( or'diagnostic classifiers'), see belinkov and glass for a recent survey  #AUTHOR_TAG."", ' #AUTHOR_TAG evaluate several kinds of sentence encoders and propose a range of probing tasks around isolated aspects of sentence']",5
"['##s neural representations and symbolic linguistic knowledge by integrating them in a soft manner.', 'we replicated the results of  #TAUTHOR_TAG, showing that the more implicit use of embedding user - generated dictionaries']","['dsds, a recently - proposed lowresource tagger that symbiotically leverages neural representations and symbolic linguistic knowledge by integrating them in a soft manner.', 'we replicated the results of  #TAUTHOR_TAG, showing that the more implicit use of embedding user - generated dictionaries']","['##s neural representations and symbolic linguistic knowledge by integrating them in a soft manner.', 'we replicated the results of  #TAUTHOR_TAG, showing that the more implicit use of embedding user - generated dictionaries turns out to be more beneficial than approaches that rely more explicitly on symbolic knowledge, such a type constraints or retrofitting.', 'by analyzing the reliance']","['analyze dsds, a recently - proposed lowresource tagger that symbiotically leverages neural representations and symbolic linguistic knowledge by integrating them in a soft manner.', 'we replicated the results of  #TAUTHOR_TAG, showing that the more implicit use of embedding user - generated dictionaries turns out to be more beneficial than approaches that rely more explicitly on symbolic knowledge, such a type constraints or retrofitting.', 'by analyzing the reliance of dsds on the linguistic knowledge, we found that the composition of the lexicon is more important than its size.', 'moreover, the tagger benefits from small dictionaries, as long as they do not contain tag set information contradictory to the evaluation data.', 'our quantitative analysis also sheds light on the internal representations, showing that they get more sensitive to the task.', 'finally, we found that freezing pre - trained word embeddings complement the learning signal well in this noisy data regime']",5
[' #TAUTHOR_TAG'],['tagger  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['use linguistic resources that are user - generated and available for many languages.', 'the first is wiktionary, a word type dictionary that maps words to one of the 12 universal pos tags  #AUTHOR_TAG.', 'the second resource is unimorph, a morphological dictionary that provides inflectional paradigms for 350 languages  #AUTHOR_TAG.', 'for wiktionary, we use the freely available dictionaries from  #AUTHOR_TAG.', 'unimorph covers between 8 - 38 morphological properties ( for english and finnish, respectively ).', '1 the sizes of the dictionaries vary considerably, from a few thousand entries ( e. g., for hindi and bulgarian ) to 2m entries ( finnish uni - morph ).', 'we study the impact of smaller dictionary sizes in section 4. 1.', 'the tagger we analyze in this paper is an extension of the base tagger, called distant supervision from disparate sources ( dsds ) tagger  #TAUTHOR_TAG.', 'it is trained on projected data and further differs from the base tagger by the integration of lexicon information.', 'in particular, given a lexicon src, dsds uses e src to embed the lexicon into an l - dimensional space, where e src is the concatenation of all embedded m properties of length l ( empirically set, see section 2. 2 ), and a zero vector for words not in the lexicon.', 'a property here is a possible pos tag ( for wiktionary ) or a morphological feature ( for unimorph ).', 'to integrate the type - level supervision, the lexicon embeddings vector is created and concatenated to the word and character - level representations for every token : w • cw • e.', 'we compare dsds to alternative ways of using lexical information.', 'the first approach uses lexical information directly during decoding ( tackstrom et al., 2013 ).', 'the second approach is more implicit and uses the lexicon to induce better word embeddings for tagger initialization.', 'in particular, we use the dictionary for retrofitting off - the - shelf embeddings  #AUTHOR_TAG to initialize the tagger with those.', 'the latter is a novel approach which, to the best of our knowledge, has not yet been evaluated in the neural tagging literature.', 'the idea is to bring the off - theshelf embeddings closer to the pos tagging task by retrofitting the embeddings with syntactic clusters derived from the lexicon.', 'we take a deeper look at the quality of the lex - 1 more details : http : / / unimorph. org / icons by comparing tag sets to the gold treebank data, inspired by  #AUTHOR_TAG.', 'in particular, let t be the dictionary derived from the gold treebank ( development data']",6
"['##s neural representations and symbolic linguistic knowledge by integrating them in a soft manner.', 'we replicated the results of  #TAUTHOR_TAG, showing that the more implicit use of embedding user - generated dictionaries']","['dsds, a recently - proposed lowresource tagger that symbiotically leverages neural representations and symbolic linguistic knowledge by integrating them in a soft manner.', 'we replicated the results of  #TAUTHOR_TAG, showing that the more implicit use of embedding user - generated dictionaries']","['##s neural representations and symbolic linguistic knowledge by integrating them in a soft manner.', 'we replicated the results of  #TAUTHOR_TAG, showing that the more implicit use of embedding user - generated dictionaries turns out to be more beneficial than approaches that rely more explicitly on symbolic knowledge, such a type constraints or retrofitting.', 'by analyzing the reliance']","['analyze dsds, a recently - proposed lowresource tagger that symbiotically leverages neural representations and symbolic linguistic knowledge by integrating them in a soft manner.', 'we replicated the results of  #TAUTHOR_TAG, showing that the more implicit use of embedding user - generated dictionaries turns out to be more beneficial than approaches that rely more explicitly on symbolic knowledge, such a type constraints or retrofitting.', 'by analyzing the reliance of dsds on the linguistic knowledge, we found that the composition of the lexicon is more important than its size.', 'moreover, the tagger benefits from small dictionaries, as long as they do not contain tag set information contradictory to the evaluation data.', 'our quantitative analysis also sheds light on the internal representations, showing that they get more sensitive to the task.', 'finally, we found that freezing pre - trained word embeddings complement the learning signal well in this noisy data regime']",6
"['1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that ds']","['this section we describe the baselines, the data and the tagger hyperparameters.', 'data we use the 12 universal pos tags  #AUTHOR_TAG.', 'the set of languages is motivated by accessibility to embeddings and dictionaries.', 'we here focus on 21 dev sets of the universal dependencies 2. 1 ( nivre and et al., 2017 ), test set results are reported by  #TAUTHOR_TAG showing that dsds provides a viable alternative.', 'annotation projection to build the taggers for new languages, we resort to annotation projection following  #TAUTHOR_TAG.', 'in particular, they employ the approach by agic et al. ( 2016 ), where labels are projected from multiple sources to multiple targets and then decoded through weighted majority voting with word alignment probabilities and source pos tagger confidences.', 'the wide - coverage watchtower corpus ( wtc ) by agic et al. ( 2016 ) is used, where 5k instances are selected via data selection by alignment coverage following  #TAUTHOR_TAG.', 'baselines we compare to the following alternatives : type - constraint wiktionary supervision  #AUTHOR_TAG and retrofitting initialization.', 'hyperparameters we use the same setup as  #TAUTHOR_TAG, i. e., 10 epochs, word dropout rate ( p =. 25 ) and l = 40 - dimensional lexicon embeddings for dsds, except for downscaling the hidden dimensionality of the character representations from 100 to 32 dimensions.', 'this ensures that our probing tasks always get the same input dimensionality : 64 ( 2x32 ) dimensions for cw, which is the same dimension as the off - theshelf word embeddings.', 'language - specific hyperparameters could lead to optimized models for each language.', 'however, we use identical settings for each language which worked well and is less expensive, following  #AUTHOR_TAG.', 'for all experiments, we average over 3 randomly seeded runs, and provide mean accuracy.', 'we use the off - the - shelf polyglot word embeddings ( al -  #AUTHOR_TAG.', 'word embedding initialization provides a consistent and considerable boost in this cross - lingual setup, up to 10 % absolute improvements across 21 languages when only 500 projected training instances are available  #TAUTHOR_TAG.', 'note that we em - pirically find it to be best to not update the word embeddings in this noisy training setup, as that results in better performance, see section 4. 4']",4
"[', confirming  #TAUTHOR_TAG : embedding lexical information into a neural tag']","['tagging accuracy, confirming  #TAUTHOR_TAG : embedding lexical information into a neural tagger improves tagging']","['tagging accuracy, confirming  #TAUTHOR_TAG : embedding lexical information into a neural tagger improves tagging']","['the best of two worlds results in the overall best tagging accuracy, confirming  #TAUTHOR_TAG : embedding lexical information into a neural tagger improves tagging accuracy from 83. 4 to 84. 1 ( means over 21 languages ).', 'on 15 out of 21 languages, dsds is the best performing model.', '']",3
"['standard form of written arabic is modern standard arabic ( msa ).', 'it differs significantly from various spoken varieties of arabic  #TAUTHOR_TAG']","['standard form of written arabic is modern standard arabic ( msa ).', 'it differs significantly from various spoken varieties of arabic  #TAUTHOR_TAG']","['standard form of written arabic is modern standard arabic ( msa ).', 'it differs significantly from various spoken varieties of arabic  #TAUTHOR_TAG.', 'even though these dialects do not originally exist in written form,']","['standard form of written arabic is modern standard arabic ( msa ).', 'it differs significantly from various spoken varieties of arabic  #TAUTHOR_TAG.', 'even though these dialects do not originally exist in written form, they are present in social media texts.', 'recently a dataset of dialectal arabic has been made available in the form of the arabic online commentary ( aoc ) set ( zaidan and callison -  #AUTHOR_TAG zaidan and callison  #AUTHOR_TAG.', 'the data consists of reader commentary from the online versions of arabic newspapers, which have a high degree of dialect content.', 'data for the following dialects has been collected : levantine, gulf, and egyptian.', 'the data had been obtained by a crowd - sourcing effort.', ""in the current paper, we present results for a binary classification task only, where we predict the dialect of egyptian arabic arz vs. msa sentences from the al - youm al - sabe'newspaper online commentaries 1."", 'our ultimate goal is to use the dialect classifier for building a dialect - aware arabic - english statistical machine translation ( smt ) system.', 'our arabic - english training data contains a significant amount of egyptian dialect data only, and we would like to adapt the components of our hierarchical phrase - based smt system ( zhao and al -  #AUTHOR_TAG to that data.', 'similar to  #TAUTHOR_TAG, we present a sentence - level classifier that is trained in a supervised manner.', 'our approach is based on an arabic tokenizer, but we do not use a range of specialized tokenizers or orthography normalizers.', 'in contrast to the language - model ( lm ) based classifier used by ( zaidan and callison -  #AUTHOR_TAG, we present a linear classifier approach that works best without the use of lmbased features.', 'some improvements in terms of classification accuracy and 10 - fold cross validation under the same data conditions as  #TAUTHOR_TAG are presented.', 'in general, we aim at a smaller amount of domain specific feature engineering than previous related approaches.', 'the paper is structured as follows.', 'in section 2, we present related work on language and dialect identification.', 'in section 3, we discuss the linear classification model used in this paper.', 'in section 4, we evaluate the classifier performance in terms of classification accuracy on two data sets and present some error analysis.', 'finally, in section 5, we discuss future work on improved dialect - level classification and its application to system adaptation for machine translation']",0
"['of sentence - level classification  #TAUTHOR_TAG.', 'the']","['of sentence - level classification  #TAUTHOR_TAG.', 'the']","['of sentence - level classification  #TAUTHOR_TAG.', 'the work is based on the data collection effort by ( za']","['', ' #AUTHOR_TAG generates n - gram features based on character or word sequences to classify dialectal documents in a dutch - language fairy - tale collection.', 'their baseline model uses n - gram based text classification techniques as popularised in the textcat tool  #AUTHOR_TAG.', 'following  #AUTHOR_TAG, the authors extend the usage of n - gram features with nearest neighbour and nearest - prototype models together with appropriately chosen similarity metrics.', ' #AUTHOR_TAG classify two varieties of the same language : european and brazilian portuguese.', 'they use word and character - based language model classification techniques similar to ( zaidan and callison -  #AUTHOR_TAG.', ' #AUTHOR_TAG present simple bag - of - word techniques to classify varieties of chinese from the chinese gigaword corpus.', ' #AUTHOR_TAG extend the use of ngram features to using string kernels : they may take into account all possible sub - strings for comparison purposes.', 'the resulting kernel - based classifier is compared against the method in  #AUTHOR_TAG.', ' #AUTHOR_TAG present a dialect classification approach to identify australian, british, and canadian english.', 'they present results where they draw training and test data from different sources.', 'the successful transfer of models from one text source to another is evidence that their classifier indeed captures dialectal rather than stylistic or formal differences.', 'language identification of related languages is also addressed in the dsl ( discriminating similar languages ) task of the present vardial workshop at coling 14  #AUTHOR_TAG.', 'while most of the above work focuses on document - level language classification, recent work on handling arabic dialect data addresses the problem of sentence - level classification  #TAUTHOR_TAG.', 'the work is based on the data collection effort by ( zaidan and callison -  #AUTHOR_TAG which crowdsources the annotation task to workers on amazons mechanical turk.', 'the classification results by ( zaidan and callison -  #AUTHOR_TAG are based on n - gram language - models, where the n - grams are defined both on words']",1
"['##n and callison -  #AUTHOR_TAG which also has been used in the experiments in  #TAUTHOR_TAG.', 'we focus on the binary classification between msa and arz.', 'details on the data sources can be found in table 1.', 'we present accuracy results in terms of 10 - fold stratified']","[""a label of'+ 1'represents egyptian dialect."", 'during training, we solve the following optimization problem :', 'i. e. we use l1 regularized l2 - loss support vector classification.', 'we set the penalty term c = 0. 5.', 'for our experiments, we use the data set provided in ( zaidan and callison -  #AUTHOR_TAG which also has been used in the experiments in  #TAUTHOR_TAG.', 'we focus on the binary classification between msa and arz.', 'details on the data sources can be found in table 1.', 'we present accuracy results in terms of 10 - fold stratified cross - validation which are comparable to previously published work']","['##n and callison -  #AUTHOR_TAG which also has been used in the experiments in  #TAUTHOR_TAG.', 'we focus on the binary classification between msa and arz.', 'details on the data sources can be found in table 1.', 'we present accuracy results in terms of 10 - fold stratified']","['use a linear model and compute a score s ( t n 1 ) for a tokenized input sentence consisting of n tokens t i :', 'where φ s ( c i, t i ) is a binary feature function which takes into account the context c i of token t i.', 'w ∈ r d is a high - dimensional weight vector obtained during training.', ""in our experiments, we classify a tokenized table 1 : we used the following dialect data : 1 ) the arz - msa portion of the aoc data from commentaries of the egyptian newspaper al - youm al - sabe ', and 2 ) the dev12 tune set ( 1219 sentences ) which is the ldc2012e30 corpus bolt phase 1 dev - tune set."", 'the dev12 tune set was annotated by a native speaker of arabic.', 'sentence as being egyptian dialect ( arz ) if s ( t n 1 ) > 0.', 'to train the weights w in eq. 1, we use a linear svm approach  #AUTHOR_TAG.', 'the trainer can easily handle a huge number of instances and features.', 'the training data is given as instance - label pairs ( x i, y i ) where i ∈ { 1, · · ·, l } and l is the number of training sentences.', 'the x i are d - dimensional vectors of integer - valued features that count how often a binary feature fired for a tokenized sentence t n 1.', ""y i ∈ { + 1, −1 } are the class labels where a label of'+ 1'represents egyptian dialect."", 'during training, we solve the following optimization problem :', 'i. e. we use l1 regularized l2 - loss support vector classification.', 'we set the penalty term c = 0. 5.', 'for our experiments, we use the data set provided in ( zaidan and callison -  #AUTHOR_TAG which also has been used in the experiments in  #TAUTHOR_TAG.', 'we focus on the binary classification between msa and arz.', 'details on the data sources can be found in table 1.', 'we present accuracy results in terms of 10 - fold stratified cross - validation which are comparable to previously published work']",5
"['defined in  #TAUTHOR_TAG.', 'for example, we define a feature φ excl ( t n 1 ) which is equal to the length of the longest consecutive sequence of excl']","['defined in  #TAUTHOR_TAG.', 'for example, we define a feature φ excl ( t n 1 ) which is equal to the length of the longest consecutive sequence of exclamation marks in the tokenized']","['defined in  #TAUTHOR_TAG.', 'for example, we define a feature φ excl ( t n 1 ) which is equal to the length of the longest consecutive sequence of excl']","['our work, we employ a simple set of binary feature functions based on the tokenized arabic sentence.', 'for example, we define a token bigram feature as follows :', 'token unigram and trigram features are defined accordingly.', 'we also define unigram, bigram, and trigram features based on pos tags.', 'currently, just pos unigrams are used in the experiments.', 'we define dictionary - based features as follows :', 'where we use the two dictionaries dict 1 and dict 2 as described in section 3. 1.', 'the dictionaries are handled as token sets and we generate separate features for each of them.', 'we generate some features based on the aida tool output.', 'aida provides a dialect label for each input token t k as well as a single dialect label at the sentence level.', 'a sentence - level binary feature based on the aida sentence level classification is defined as follows :', 'where aida ( t n 1 ) is the sentence - level classification of the aida tool.', 'a word - level feature φ aida ( t k ) is defined accordingly.', 'these features improve the classification accuracy of our best system significantly.', 'we have also experimented with some real - valued feature.', 'for example, we derived a feature from dialect - specific language model probabilities :', 'where log ( p arz ( t n 1 ) ) is the language - model log probability for the dialect class arz.', 'we used a trigram language model.', 'p msa ( · ) is defined accordingly.', ""in addition, we have implemented a range of so - called'meta'features similar to the ones defined in  #TAUTHOR_TAG."", 'for example, we define a feature φ excl ( t n 1 ) which is equal to the length of the longest consecutive sequence of exclamation marks in the tokenized sentence t n 1.', 'similarly, we define features that count the longest sequence of punctuation marks, the number of tokens, the averaged character - length of a token in the sentence, and the percentage of words with word - lengthening effects.', 'these features do not directly model dialectalness of the data but rather try to capture the degree of in - formalness.', 'contrary to  #TAUTHOR_TAG we find that those features do not improve accuracy of our best model in the cross - validation experiments.', 'on the dev12 set, the use of the meta features results in a significant drop in accuracy']",4
"['.', 'in comparison,  #TAUTHOR_TAG reports an']","['dev12 tune set.', 'in comparison,  #TAUTHOR_TAG reports an']","['', 'in comparison,  #TAUTHOR_TAG reports an accuracy of 80']","['', 'in comparison,  #TAUTHOR_TAG reports an accuracy of 80. 4 % as perplexity - based baseline.', 'we have carried out additional experiments with a simple feature set that consists of only unigram token and bigram token features as defined in eq. 3.', '']",4
['proposed previously  #TAUTHOR_TAG'],['proposed previously  #TAUTHOR_TAG'],"['does not compute features like the percentage of punctuation, numbers, or averaged word length as has been proposed previously  #TAUTHOR_TAG.', '']","['ultimate goal is to use the arz vs. msa dialect classifier for training an adapted smt system.', 'we split the training data at the sentence level using our classifier and train dialect - specific systems on each of these splits along with a general dialect - independent system.', 'we will be using techniques similar to  #AUTHOR_TAG to adapt the general smt system to a target domain with a predominant dialect.', 'or, we will be adopting an smt system to a development or test set where we use the classifier to predict the dialect for each sentence and use a dialect - specific smt system on each of them individually.', 'our approach of using just binary feature functions in connection with a sentence - level global linear model can be related to work on pos - tagging  #AUTHOR_TAG.', ' #AUTHOR_TAG trains a linear model based on viterbi decoding and the perceptron algorithm.', 'the gold - standard pos tags are given at the word - level, but the training uses a global representation at the sentence level.', 'similarly, we use linear svms to train a classification model at the sentence level without access to sentence length statistics, i. e. our best performing classifier does not compute features like the percentage of punctuation, numbers, or averaged word length as has been proposed previously  #TAUTHOR_TAG.', '']",4
['##li  #TAUTHOR_TAG'],['alignment system is structured identically to manli  #TAUTHOR_TAG'],['##li  #TAUTHOR_TAG'],"['alignment system is structured identically to manli  #TAUTHOR_TAG and uses the same phrase - based alignment representation.', 'an alignment e between two fragments of text t 1 and t 2 is represented by a set of edits { e 1, e 2,... }, each belonging to one of the following types :', '• ins and del edits covering unaligned words in t 1 and t 2 respectively • sub and eq edits connecting a phrase in t 1 to a phrase in t 2.', 'eq edits are a specific case of sub edits that denote a word / lemma match ; we refer to both types as sub edits in this paper.', 'every token in t 1 and t 2 participates in exactly one edit.', 'while alignments are one - to - one at the phrase level, a phrase - based representation effectively permits many - to - many alignments at the token level.', 'this enables the aligner to properly link paraphrases such as death penalty and capital punishment by exploiting lexical resources']",5
['as  #TAUTHOR_TAG'],['as  #TAUTHOR_TAG'],['as  #TAUTHOR_TAG'],"['##li was trained and evaluated on a corpus of human - generated alignment annotations produced by microsoft research  #AUTHOR_TAG for inference problems from the second recognizing textual entailment ( rte2 ) challenge ( bar -  #AUTHOR_TAG.', 'the corpus consists of a development set and test set that both feature 800 inference problems, each of which consists of a premise, a hypothesis and three independently - annotated human alignments.', 'in our experiments, we merge the annotations using majority rule in the same manner as  #TAUTHOR_TAG']",5
['of features as  #TAUTHOR_TAG with some minor changes : we use a shallow parser ( daume and  #AUTHOR_TAG'],['of features as  #TAUTHOR_TAG with some minor changes : we use a shallow parser ( daume and  #AUTHOR_TAG'],['of features as  #TAUTHOR_TAG with some minor changes : we use a shallow parser ( daume and  #AUTHOR_TAG'],"['manli alignment is scored as a sum of weighted feature values over the edits that it contains.', 'features encode the type of edit, the size of the phrases involved in sub edits, whether the phrases are constituents and their similarity ( determined by leveraging various lexical resources ).', 'additionally, contextual features note the similarity of neighboring words and the relative positions of phrases while a positional distortion feature accounts for the difference between the relative positions of sub edit phrases in their respective sentences.', 'our implementation uses the same set of features as  #TAUTHOR_TAG with some minor changes : we use a shallow parser ( daume and  #AUTHOR_TAG for detecting constituents and employ only string similarity and wordnet for determining semantic relatedness, forgoing nombank and the distributional similarity resources used in the original manli implementation']",5
"['##2 alignment corpus ( cf.', '§ 3. 1 ) using the training parameters specified in  #TAUTHOR_TAG']","['on the development section of the microsoft research rte2 alignment corpus ( cf.', '§ 3. 1 ) using the training parameters specified in  #TAUTHOR_TAG']","['described in § 3.', 'all models are trained on the development section of the microsoft research rte2 alignment corpus ( cf.', '§ 3. 1 ) using the training parameters specified in  #TAUTHOR_TAG.', 'aligner performance is determined by counting aligned token pairs per problem and']","['evaluation purposes, we compare the performance of approximate search decoding against exact ilp - based decoding on a reimplementation of manli as described in § 3.', 'all models are trained on the development section of the microsoft research rte2 alignment corpus ( cf.', '§ 3. 1 ) using the training parameters specified in  #TAUTHOR_TAG.', 'aligner performance is determined by counting aligned token pairs per problem and macro - averaging over all problems.', 'the results are shown in table 1.', '']",5
['of features as  #TAUTHOR_TAG with some minor changes : we use a shallow parser ( daume and  #AUTHOR_TAG'],['of features as  #TAUTHOR_TAG with some minor changes : we use a shallow parser ( daume and  #AUTHOR_TAG'],['of features as  #TAUTHOR_TAG with some minor changes : we use a shallow parser ( daume and  #AUTHOR_TAG'],"['manli alignment is scored as a sum of weighted feature values over the edits that it contains.', 'features encode the type of edit, the size of the phrases involved in sub edits, whether the phrases are constituents and their similarity ( determined by leveraging various lexical resources ).', 'additionally, contextual features note the similarity of neighboring words and the relative positions of phrases while a positional distortion feature accounts for the difference between the relative positions of sub edit phrases in their respective sentences.', 'our implementation uses the same set of features as  #TAUTHOR_TAG with some minor changes : we use a shallow parser ( daume and  #AUTHOR_TAG for detecting constituents and employ only string similarity and wordnet for determining semantic relatedness, forgoing nombank and the distributional similarity resources used in the original manli implementation']",6
"['algorithm  #AUTHOR_TAG, an intuitive structured prediction technique.', 'we deviate from  #TAUTHOR_TAG and do not introduce l2 normalization of weights during learning as this could have an unpredictable effect on the averaged parameters.', 'for efficiency reasons, we parallel']","['structured perceptron algorithm  #AUTHOR_TAG, an intuitive structured prediction technique.', 'we deviate from  #TAUTHOR_TAG and do not introduce l2 normalization of weights during learning as this could have an unpredictable effect on the averaged parameters.', 'for efficiency reasons, we parallelize']","['averaged structured perceptron algorithm  #AUTHOR_TAG, an intuitive structured prediction technique.', 'we deviate from  #TAUTHOR_TAG and do not introduce l2 normalization of weights during learning as this could have an unpredictable effect on the averaged parameters.', 'for efficiency reasons, we parallelize the training procedure using iterative parameter mixing ( mc  #AUTHOR_TAG in our experiments']","['weights are learned using the averaged structured perceptron algorithm  #AUTHOR_TAG, an intuitive structured prediction technique.', 'we deviate from  #TAUTHOR_TAG and do not introduce l2 normalization of weights during learning as this could have an unpredictable effect on the averaged parameters.', 'for efficiency reasons, we parallelize the training procedure using iterative parameter mixing ( mc  #AUTHOR_TAG in our experiments']",6
"['algorithm  #AUTHOR_TAG, an intuitive structured prediction technique.', 'we deviate from  #TAUTHOR_TAG and do not introduce l2 normalization of weights during learning as this could have an unpredictable effect on the averaged parameters.', 'for efficiency reasons, we parallel']","['structured perceptron algorithm  #AUTHOR_TAG, an intuitive structured prediction technique.', 'we deviate from  #TAUTHOR_TAG and do not introduce l2 normalization of weights during learning as this could have an unpredictable effect on the averaged parameters.', 'for efficiency reasons, we parallelize']","['averaged structured perceptron algorithm  #AUTHOR_TAG, an intuitive structured prediction technique.', 'we deviate from  #TAUTHOR_TAG and do not introduce l2 normalization of weights during learning as this could have an unpredictable effect on the averaged parameters.', 'for efficiency reasons, we parallelize the training procedure using iterative parameter mixing ( mc  #AUTHOR_TAG in our experiments']","['weights are learned using the averaged structured perceptron algorithm  #AUTHOR_TAG, an intuitive structured prediction technique.', 'we deviate from  #TAUTHOR_TAG and do not introduce l2 normalization of weights during learning as this could have an unpredictable effect on the averaged parameters.', 'for efficiency reasons, we parallelize the training procedure using iterative parameter mixing ( mc  #AUTHOR_TAG in our experiments']",4
"['##2 alignment corpus ( cf.', '§ 3. 1 ) using the training parameters specified in  #TAUTHOR_TAG']","['on the development section of the microsoft research rte2 alignment corpus ( cf.', '§ 3. 1 ) using the training parameters specified in  #TAUTHOR_TAG']","['described in § 3.', 'all models are trained on the development section of the microsoft research rte2 alignment corpus ( cf.', '§ 3. 1 ) using the training parameters specified in  #TAUTHOR_TAG.', 'aligner performance is determined by counting aligned token pairs per problem and']","['evaluation purposes, we compare the performance of approximate search decoding against exact ilp - based decoding on a reimplementation of manli as described in § 3.', 'all models are trained on the development section of the microsoft research rte2 alignment corpus ( cf.', '§ 3. 1 ) using the training parameters specified in  #TAUTHOR_TAG.', 'aligner performance is determined by counting aligned token pairs per problem and macro - averaging over all problems.', 'the results are shown in table 1.', '']",4
['in  #TAUTHOR_TAG'],['in  #TAUTHOR_TAG'],['in  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],4
['corpora ; this was also noted by  #TAUTHOR_TAG with regard to the original man'],"['better paraphrase corpora ; this was also noted by  #TAUTHOR_TAG with regard to the original manli system.', 'in addition, stricter constraints']","['better paraphrase corpora ; this was also noted by  #TAUTHOR_TAG with regard to the original manli system.', 'in']","['results of our evaluation indicate that exact decoding via ilp is a robust and efficient technique for solving alignment problems.', 'furthermore, the incorporation of simple constraints over a dependency parse can help to shape more accurate alignments.', 'an examination of the alignments produced by our system reveals that many remaining errors can be tackled by the use of named - entity recognition and better paraphrase corpora ; this was also noted by  #TAUTHOR_TAG with regard to the original manli system.', 'in addition, stricter constraints that enforce the alignment of syntactically - related tokens ( rather than just their inclusion in the solution ) may also yield performance gains.', ""although manli's structured prediction approach to the alignment problem allows us to encode preferences as features and learn their weights via the structured perceptron, the decoding constraints used here can be used to establish dynamic links between alignment edits which cannot be determined a priori."", 'the interaction between the selection of soft features for structured prediction and hard constraints for decoding is an interesting avenue for further research on this task.', ""initial experiments with a feature that considers the similarity of dependency heads of tokens in an edit ( similar to manli's contextual features that look at preceding and following words ) yielded some improvement over the baseline models ; however, this did not perform as well as the simple constraints described above."", 'specific features that approximate soft variants of these constraints could also be devised but this was not explored here.', 'in addition to the nli applications considered in this work, we have also employed the manli alignment technique to tackle alignment problems that are not inherently asymmetric such as the sentence fusion problems from mc  #AUTHOR_TAG.', 'although the absence of asymmetric alignment features affects performance marginally over the rte2 dataset, all the performance gains exhibited by exact decoding with constraints appear to be preserved in symmetric settings']",3
['corpora ; this was also noted by  #TAUTHOR_TAG with regard to the original man'],"['better paraphrase corpora ; this was also noted by  #TAUTHOR_TAG with regard to the original manli system.', 'in addition, stricter constraints']","['better paraphrase corpora ; this was also noted by  #TAUTHOR_TAG with regard to the original manli system.', 'in']","['results of our evaluation indicate that exact decoding via ilp is a robust and efficient technique for solving alignment problems.', 'furthermore, the incorporation of simple constraints over a dependency parse can help to shape more accurate alignments.', 'an examination of the alignments produced by our system reveals that many remaining errors can be tackled by the use of named - entity recognition and better paraphrase corpora ; this was also noted by  #TAUTHOR_TAG with regard to the original manli system.', 'in addition, stricter constraints that enforce the alignment of syntactically - related tokens ( rather than just their inclusion in the solution ) may also yield performance gains.', ""although manli's structured prediction approach to the alignment problem allows us to encode preferences as features and learn their weights via the structured perceptron, the decoding constraints used here can be used to establish dynamic links between alignment edits which cannot be determined a priori."", 'the interaction between the selection of soft features for structured prediction and hard constraints for decoding is an interesting avenue for further research on this task.', ""initial experiments with a feature that considers the similarity of dependency heads of tokens in an edit ( similar to manli's contextual features that look at preceding and following words ) yielded some improvement over the baseline models ; however, this did not perform as well as the simple constraints described above."", 'specific features that approximate soft variants of these constraints could also be devised but this was not explored here.', 'in addition to the nli applications considered in this work, we have also employed the manli alignment technique to tackle alignment problems that are not inherently asymmetric such as the sentence fusion problems from mc  #AUTHOR_TAG.', 'although the absence of asymmetric alignment features affects performance marginally over the rte2 dataset, all the performance gains exhibited by exact decoding with constraints appear to be preserved in symmetric settings']",2
"['by the degree to which those phrases are compositional.', 'in this paper, we use a compound noun compositionality dataset  #TAUTHOR_TAG to investigate the']","['by the degree to which those phrases are compositional.', 'in this paper, we use a compound noun compositionality dataset  #TAUTHOR_TAG to investigate the']","['by the degree to which those phrases are compositional.', 'in this paper, we use a compound noun compositionality dataset  #TAUTHOR_TAG to investigate the extent to']","['current focus within the field of distributional semantics is enabling systems to make inferences about phrase - level or sentence - level similarity.', 'one popular approach  #AUTHOR_TAG is to build phrase or sentence - level representations by composing word - level representations and then measuring similarity directly.', 'success is usually measured in terms of correlation with human similarity judgments.', 'however, evaluating measures of phrase - level similarity directly against human judgments of similarity ignores the problem that it is not always possible to determine meaning in a compositional manner.', 'if we compose the meaning representations for red and herring, we might expect to get a very different representation from the one which could be directly inferred from corpus observations of the phrase red herring.', 'thus any judgements of the similarity of two composed phrases may be confounded by the degree to which those phrases are compositional.', ""in this paper, we use a compound noun compositionality dataset  #TAUTHOR_TAG to investigate the extent to which the underlying definition of context has an effect on a model's ability to support composition."", 'we compare the anchored packed tree ( apt ) model  #AUTHOR_TAG, where composition is an integral part of the distributional model, with the commonly employed approach of applying naive compositional operations to state - of - the - art distributional representations.', 'consider the occurrence of the word student in the sentence "" the recently graduated student folded the dry clothes. "" different distributional representations leverage the context, e. g., the fact that the target word student has occurred in the context folded, in different ways.', 'table 1 illustrates the contextual features which might be generated for student given different definitions of context.', 'the most commonly used definition of context, in both traditional count - based representations and in more recent distributed embeddings, is proximity, i. e., the contextual features of a word occurrence are all those words which occur within a certain context window around the occurrence.', 'however, contextual features may also be defined in terms of dependency relations.', 'for example, in a dependency parse of the sentence we would expect to see a direct - object relation from folded to student.', 'contextual features based on dependency relations may be typed ( i. e., include the name of the dependency relation ) or untyped  #AUTHOR_TAG.', 'pado and  #AUTHOR_TAG proposed using dependency paths to define untyped contextual features ; here any word in the context which has a dependency path to the target is considered a contextual feature.', ' #AUTHOR_TAG proposed using dependency paths to define typed contextual features which could be used to align representations before composition.', 'this idea is further refined in the apt framework of  #AUTHOR_TAG']",5
"['baseline of weighted addition on the  #TAUTHOR_TAG evaluation task when trained on the bnc.', 'however, these results were still significantly lower than']","['baseline of weighted addition on the  #TAUTHOR_TAG evaluation task when trained on the bnc.', 'however, these results were still significantly lower than']","['modeling the compositionality of noun - noun compounds.', 'using interpolation to mitigate the sparse data problem, their model beat the baseline of weighted addition on the  #TAUTHOR_TAG evaluation task when trained on the bnc.', 'however, these results were still significantly lower than']","['each word and compound phrase, elementary apt representations were constructed using the method and recommended settings of  #AUTHOR_TAG.', 'for efficiency, we did not consider paths of length 3 or more.', 'in relation to the construction of the elementary apts, the most obvious parameter is the nature of the weight associated with each feature.', 'we consider both the use of probabilities 2 and positive pointwise mutual information ( ppmi )', '1  #AUTHOR_TAG proposed using generative models for modeling the compositionality of noun - noun compounds.', 'using interpolation to mitigate the sparse data problem, their model beat the baseline of weighted addition on the  #TAUTHOR_TAG evaluation task when trained on the bnc.', 'however, these results were still significantly lower than those reported by  #TAUTHOR_TAG using the larger ukwac corpus.', '2 referred to as normalised counts by  #AUTHOR_TAG values.', ' #AUTHOR_TAG showed that the use of context distribution smoothing ( α = 0. 75 ) in the pmi calculation can lead to performance comparable with state - of - the - art word embeddings on word similarity tasks.', 'we use this modified definition of pmi and experiment with α = 0. 75 and α = 1.', '3 having constructed elementary apts, the apt composition process involves aligning and composing these elementary apts.', ""we investigate using int, which takes the minimum of each of the constituent's feature values and uni, which performs pointwise addition."", 'following  #TAUTHOR_TAG, when using the uni operation, we experiment with weighting the contributions of each constituent to the composed apt representation using the parameter, h. for example, if a 2 is the apt associated with the head of the phrase and a δ 1 is the properly aligned apt associated with the modifier where δ is the dependency path from the head to the modifier ( e. g. nmod or amod ), the composition operations can be defined as :', '( 1 )', ""we have also considered composition without alignment of the modifier's apt, i. e, using a 1 :"", 'in general, one would expect there to be little overlap between apts which have not been properly aligned.', 'however, in the case where δ is the nmod relation, i. e., the internal relation in the vast majority of the compound phrases, both modifier and head are nouns and therefore there may well be considerable overlap between their unaligned dependency features.', 'in order to examine the contribution of both the aligned and unaligned apts in the composition process, we used a hybrid method where the composed representation is defined as : table 2 : average ρ using neural word embeddings', 'in the case']",5
['##ity detection  #TAUTHOR_TAG involves deciding whether a given multiword expression is compositional or not'],"['##ity detection  #TAUTHOR_TAG involves deciding whether a given multiword expression is compositional or not i. e., whether the meaning can be understood from the literal meaning of its parts.', ' #TAUTHOR_TAG introduced a dataset consisting of']",['##ity detection  #TAUTHOR_TAG involves deciding whether a given multiword expression is compositional or not'],"['##ity detection  #TAUTHOR_TAG involves deciding whether a given multiword expression is compositional or not i. e., whether the meaning can be understood from the literal meaning of its parts.', ' #TAUTHOR_TAG introduced a dataset consisting of 90 compound nouns along with human judgments of their literality or compositionally at both the constituent and the phrase level.', 'all judgments are given on a scale of 0 to 5, where 5 is high.', 'for example, the phrase spelling bee is deemed to have high literalness in its use of the first constituent, low literalness in its use of the second constituent and a medium level of literalness with respect to the whole phrase.', 'assuming the distributional hypothesis  #AUTHOR_TAG, the observed co - occurrences of compositional target phrases are highly likely to have occurred with one or both of the constituents independently.', 'on the other hand, the observed cooccurrences of non - compositional target phrases are much less likely to have occurred with either of the constituents independently.', 'thus, a good compositionality function, without any access to the observed co - occurrences of the target phrases, is highly likely to return vectors which are similar to observed phrasal vectors for compositional phrases but much less likely to return similar vectors for non - compositional phrases.', 'accordingly, as observed elsewhere  #TAUTHOR_TAG, compositional methods can be evaluated by correlating the similarity of composed and observed phrase representations with the human judgments of compositionality.', 'a similar idea is also explored by  #AUTHOR_TAG who detect noncompositional phrases by comparing the neighbourhoods of phrases where individual words have been substituted for similar words.', ' #TAUTHOR_TAG carried out experiments with a vector space model built from ukwac  #AUTHOR_TAG using untyped co - occurrences ( window size = 100 ).', 'used 3 - fold cross - validation,  #TAUTHOR_TAG found that using weighted addition outperformed multiplication as a compositionality function.', ""with  #TAUTHOR_TAG achieved a spearman's rank correlation coefficient of 0. 714 with the human judgments, which remains the state - of - the - art on this dataset 1."", 'for consistency with the experiments of  #TAUTHOR_TAG, the corpus used in this experiment is the same fullyannotated version of the web - derived ukwac corpus  #AUTHOR_TAG.', 'this corpus has been tokenised, pos - tagged and lemmatised with treetagger  #AUTHOR_TAG and dependency - parsed with the malt parser  #AUTHOR_TAG.', '']",1
"['reported in  #TAUTHOR_TAG.', 'since both of these models are based on untyped cooccurrences, this performance gain can be seen as the result of implicit parameter optimisation.', '']","['previous state - ofthe - art reported in  #TAUTHOR_TAG.', 'since both of these models are based on untyped cooccurrences, this performance gain can be seen as the result of implicit parameter optimisation.', '']","['reported in  #TAUTHOR_TAG.', 'since both of these models are based on untyped cooccurrences, this performance gain can be seen as the result of implicit parameter optimisation.', '']","['used repeated 3 - fold cross - validation to enable us to estimate 4 the model parameters h and q. results for all models are then reported in terms of average spearman rank correlation scores ( ρ ) of phrase compositionality scores with human judgements on the corresponding testing samples.', 'we used a sufficiently large number of repetitions that errors are all small ( ≤ 0. 0015 ) and thus any difference observed which is greater than 0. 005 is statistically significant at the 95 % level.', 'boldface is used to indicate the best performing configuration of parameters for a particular model.', 'table 2 summarises results for different parameter settings for the neural word embeddings.', 'looking at the results in table 2, we see that the cbow model significantly outperforms the skip - gram model.', 'using the cbow model with 100 dimensions and a subsampling threshold of t = 10 −3 gives a performance of 0. 74 which is significantly higher than the previous state - ofthe - art reported in  #TAUTHOR_TAG.', 'since both of these models are based on untyped cooccurrences, this performance gain can be seen as the result of implicit parameter optimisation.', 'table 3 : average ρ using apt representations.', 'apt representations.', '']",4
"['reported in  #TAUTHOR_TAG.', 'since both of these models are based on untyped cooccurrences, this performance gain can be seen as the result of implicit parameter optimisation.', '']","['previous state - ofthe - art reported in  #TAUTHOR_TAG.', 'since both of these models are based on untyped cooccurrences, this performance gain can be seen as the result of implicit parameter optimisation.', '']","['reported in  #TAUTHOR_TAG.', 'since both of these models are based on untyped cooccurrences, this performance gain can be seen as the result of implicit parameter optimisation.', '']","['used repeated 3 - fold cross - validation to enable us to estimate 4 the model parameters h and q. results for all models are then reported in terms of average spearman rank correlation scores ( ρ ) of phrase compositionality scores with human judgements on the corresponding testing samples.', 'we used a sufficiently large number of repetitions that errors are all small ( ≤ 0. 0015 ) and thus any difference observed which is greater than 0. 005 is statistically significant at the 95 % level.', 'boldface is used to indicate the best performing configuration of parameters for a particular model.', 'table 2 summarises results for different parameter settings for the neural word embeddings.', 'looking at the results in table 2, we see that the cbow model significantly outperforms the skip - gram model.', 'using the cbow model with 100 dimensions and a subsampling threshold of t = 10 −3 gives a performance of 0. 74 which is significantly higher than the previous state - ofthe - art reported in  #TAUTHOR_TAG.', 'since both of these models are based on untyped cooccurrences, this performance gain can be seen as the result of implicit parameter optimisation.', 'table 3 : average ρ using apt representations.', 'apt representations.', '']",4
"['word segmentation  #TAUTHOR_TAG,']","['word segmentation  #TAUTHOR_TAG,']","['( nlp ) tasks, including word segmentation  #TAUTHOR_TAG,']","['tutorial discusses a framework of online global discriminative learning and beam - search decoding for syntactic processing  #AUTHOR_TAG b ), which has recently been applied to a wide variety of natural language processing ( nlp ) tasks, including word segmentation  #TAUTHOR_TAG, dependency parsing  #AUTHOR_TAG b ;  #AUTHOR_TAG, context free grammar ( cfg ) parsing  #AUTHOR_TAG, combinational categorial grammar ( ccg ) parsing  #AUTHOR_TAG a ;  #AUTHOR_TAG and machine translation  #AUTHOR_TAG, achieving stateof - the - art accuracies and efficiencies.', '']",0
"['efficient implementation issues  #TAUTHOR_TAG, as well']","['efficient implementation issues  #TAUTHOR_TAG, as well']","['efficient implementation issues  #TAUTHOR_TAG, as well']","['this tutorial, we make an introduction to the framework, illustrating how it can be applied to a range of nlp problems, giving theoretical discussions and demonstrating a software implementation.', 'we start with a detailed introduction of the framework, describing the averaged perceptron algorithm  #AUTHOR_TAG and its efficient implementation issues  #TAUTHOR_TAG, as well as beam - search and the early - update strategy  #AUTHOR_TAG.', 'we then illustrate how the framework can be applied to nlp tasks, including word segmentation, joint segmentation & pos - tagging, labeled and unlabeled dependency parsing, joint pos - tagging and dependency parsing, cfg parsing, ccg parsing, and joint segmentation, pos - tagging and parsing.', 'in each case, we illustrate how the task is turned into an incremental left - to - right output - building process, and how rich features are defined to give competitive accuracies.', 'these examples can serve as guidance in applying the framework to other structural prediction tasks.', 'in the second part of the tutorial, we give some analysis on why the framework is effective.', 'we discuss several alternative learning algorithms, 13 and compare beam - search with greedy search on dependency parsing.', 'we show that accuracy benefits from interaction between learning and search.', 'finally, the tutorial concludes with an introduction to zpar, an open source toolkit that provides optimized c + + implementations of of all the above tasks.', 'ting liu is a professor at hit - scir.', 'his research interest includes social computing, information retrieval and natural language processing']",1
"['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender']","['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender']","['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender bias is']","['intelligence ( ai ) acquired from machine learning is becoming more prominent in decisionmaking tasks in areas as diverse as industry, healthcare and education.', ""ai - informed decisions depend on ai systems'input training data which, unfortunately, can contain implicit racial, gender or ideological biases."", 'such ai - informed decisions can thus lead to unfair treatment of certain groups.', 'for example, in natural language processing ( nlp ), resume search engines can produce rankings that disadvantage some candidates, when these ranking algorithms take demographic features into account ( directly or indirectly )  #AUTHOR_TAG, while abusive online language detection systems have been observed to produce false positives on terms associated with minorities and women  #AUTHOR_TAG.', 'another example where bias ( specifically gender bias ) can be harmful is in personal pronoun coreference resolution, where systems carry the risk of relying on societal stereotypes present in the training data  #AUTHOR_TAG.', 'whilst gender bias in the form of concepts of masculinity and femininity has been found inscribed in implicit ways in ai systems more broadly  #AUTHOR_TAG, this paper focuses on gender bias on word embeddings.', 'word embeddings are one of the most common techniques for giving semantic meaning to words in text and are used as input in virtually every neural nlp system  #AUTHOR_TAG.', 'it has been shown that word embeddings capture human biases ( such as gender bias ) present in these corpora in how they relate words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender bias is understood as the inclination towards or prejudice against one gender.', 'several methods have been proposed to test for the presence of gender bias in word embeddings ; an example being the word embedding association test ( weat )  #TAUTHOR_TAG.', 'weat is a statistical test that detects bias in word embeddings using cosine similarity and averaging methods, paired with hypothesis testing.', 'weat\'s authors applied these tests to the publicly - available glove embeddings trained on the english - language "" common crawl "" corpus  #AUTHOR_TAG as well as the skip - gram ( word2vec ) embeddings trained on the google news corpus  #AUTHOR_TAG.', 'however, there is a diverse range of publicly - available word embeddings trained on corpora of different domains.', 'to address this, we applied the weat test on four sets of word embeddings trained on corpora from four domains : social media ( twit - ter ), a wikipedia - based gender - balanced corpus ( gap ) and a biomedical corpus ( pubmed ) and news ( google news, in order to reproduce and validate our results against those of  #TAUTHOR_TAG ( see section 3 ).', ' #AUTHOR_TAG confirmed the presence of gender bias using three categories of words wellknown to']",0
"['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender']","['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender']","['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender bias is']","['intelligence ( ai ) acquired from machine learning is becoming more prominent in decisionmaking tasks in areas as diverse as industry, healthcare and education.', ""ai - informed decisions depend on ai systems'input training data which, unfortunately, can contain implicit racial, gender or ideological biases."", 'such ai - informed decisions can thus lead to unfair treatment of certain groups.', 'for example, in natural language processing ( nlp ), resume search engines can produce rankings that disadvantage some candidates, when these ranking algorithms take demographic features into account ( directly or indirectly )  #AUTHOR_TAG, while abusive online language detection systems have been observed to produce false positives on terms associated with minorities and women  #AUTHOR_TAG.', 'another example where bias ( specifically gender bias ) can be harmful is in personal pronoun coreference resolution, where systems carry the risk of relying on societal stereotypes present in the training data  #AUTHOR_TAG.', 'whilst gender bias in the form of concepts of masculinity and femininity has been found inscribed in implicit ways in ai systems more broadly  #AUTHOR_TAG, this paper focuses on gender bias on word embeddings.', 'word embeddings are one of the most common techniques for giving semantic meaning to words in text and are used as input in virtually every neural nlp system  #AUTHOR_TAG.', 'it has been shown that word embeddings capture human biases ( such as gender bias ) present in these corpora in how they relate words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender bias is understood as the inclination towards or prejudice against one gender.', 'several methods have been proposed to test for the presence of gender bias in word embeddings ; an example being the word embedding association test ( weat )  #TAUTHOR_TAG.', 'weat is a statistical test that detects bias in word embeddings using cosine similarity and averaging methods, paired with hypothesis testing.', 'weat\'s authors applied these tests to the publicly - available glove embeddings trained on the english - language "" common crawl "" corpus  #AUTHOR_TAG as well as the skip - gram ( word2vec ) embeddings trained on the google news corpus  #AUTHOR_TAG.', 'however, there is a diverse range of publicly - available word embeddings trained on corpora of different domains.', 'to address this, we applied the weat test on four sets of word embeddings trained on corpora from four domains : social media ( twit - ter ), a wikipedia - based gender - balanced corpus ( gap ) and a biomedical corpus ( pubmed ) and news ( google news, in order to reproduce and validate our results against those of  #TAUTHOR_TAG ( see section 3 ).', ' #AUTHOR_TAG confirmed the presence of gender bias using three categories of words wellknown to']",0
"[' #TAUTHOR_TAG.', 'the input is']","[' #TAUTHOR_TAG.', 'the input is']","[' #TAUTHOR_TAG.', 'the input is a suspected gender bias word category represented by']","['largely follow the weat hypothesis testing protocol introduced by  #TAUTHOR_TAG.', 'the input is a suspected gender bias word category represented by two lists, x and y, of target words, i. e. words which are suspected to be biased to one or another gender.', 'e. g. x = { programmer, engineer, scientist }, y = { nurse, teacher, librarian }. we wish to test whether x or y is more biased to one gender or the other, or whether there is not difference in bias between the two lists.', 'bias is compared in relation to two reference lists of words that represent unequivocally male and female concepts.', '']",0
"['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender']","['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender']","['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender bias is']","['intelligence ( ai ) acquired from machine learning is becoming more prominent in decisionmaking tasks in areas as diverse as industry, healthcare and education.', ""ai - informed decisions depend on ai systems'input training data which, unfortunately, can contain implicit racial, gender or ideological biases."", 'such ai - informed decisions can thus lead to unfair treatment of certain groups.', 'for example, in natural language processing ( nlp ), resume search engines can produce rankings that disadvantage some candidates, when these ranking algorithms take demographic features into account ( directly or indirectly )  #AUTHOR_TAG, while abusive online language detection systems have been observed to produce false positives on terms associated with minorities and women  #AUTHOR_TAG.', 'another example where bias ( specifically gender bias ) can be harmful is in personal pronoun coreference resolution, where systems carry the risk of relying on societal stereotypes present in the training data  #AUTHOR_TAG.', 'whilst gender bias in the form of concepts of masculinity and femininity has been found inscribed in implicit ways in ai systems more broadly  #AUTHOR_TAG, this paper focuses on gender bias on word embeddings.', 'word embeddings are one of the most common techniques for giving semantic meaning to words in text and are used as input in virtually every neural nlp system  #AUTHOR_TAG.', 'it has been shown that word embeddings capture human biases ( such as gender bias ) present in these corpora in how they relate words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender bias is understood as the inclination towards or prejudice against one gender.', 'several methods have been proposed to test for the presence of gender bias in word embeddings ; an example being the word embedding association test ( weat )  #TAUTHOR_TAG.', 'weat is a statistical test that detects bias in word embeddings using cosine similarity and averaging methods, paired with hypothesis testing.', 'weat\'s authors applied these tests to the publicly - available glove embeddings trained on the english - language "" common crawl "" corpus  #AUTHOR_TAG as well as the skip - gram ( word2vec ) embeddings trained on the google news corpus  #AUTHOR_TAG.', 'however, there is a diverse range of publicly - available word embeddings trained on corpora of different domains.', 'to address this, we applied the weat test on four sets of word embeddings trained on corpora from four domains : social media ( twit - ter ), a wikipedia - based gender - balanced corpus ( gap ) and a biomedical corpus ( pubmed ) and news ( google news, in order to reproduce and validate our results against those of  #TAUTHOR_TAG ( see section 3 ).', ' #AUTHOR_TAG confirmed the presence of gender bias using three categories of words wellknown to']",3
"[' #TAUTHOR_TAG.', 'the input is']","[' #TAUTHOR_TAG.', 'the input is']","[' #TAUTHOR_TAG.', 'the input is a suspected gender bias word category represented by']","['largely follow the weat hypothesis testing protocol introduced by  #TAUTHOR_TAG.', 'the input is a suspected gender bias word category represented by two lists, x and y, of target words, i. e. words which are suspected to be biased to one or another gender.', 'e. g. x = { programmer, engineer, scientist }, y = { nurse, teacher, librarian }. we wish to test whether x or y is more biased to one gender or the other, or whether there is not difference in bias between the two lists.', 'bias is compared in relation to two reference lists of words that represent unequivocally male and female concepts.', '']",3
"[', bias had already been detected by  #TAUTHOR_TAG and  #AUTHOR_TAG using methods similar to ours.', 'this is not']","['in a news corpus, given that its authors are professional journalists, bias had already been detected by  #TAUTHOR_TAG and  #AUTHOR_TAG using methods similar to ours.', 'this is not']","['would hope to find little gender bias in a news corpus, given that its authors are professional journalists, bias had already been detected by  #TAUTHOR_TAG and  #AUTHOR_TAG using methods similar to ours.', 'this is not']","['experimentation we expected to find a great deal of gender bias across the google news and twitter embedding sets and far less in the pubmed and gap sets.', 'however, results in table 2 are somewhat different to our expectations :', 'google news we detect statistically significant ( p - values in bold ) gender bias in all 5 categories ( b1 - b5 ) on this corpus.', 'although one would hope to find little gender bias in a news corpus, given that its authors are professional journalists, bias had already been detected by  #TAUTHOR_TAG and  #AUTHOR_TAG using methods similar to ours.', '']",3
"['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender']","['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender']","['words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender bias is']","['intelligence ( ai ) acquired from machine learning is becoming more prominent in decisionmaking tasks in areas as diverse as industry, healthcare and education.', ""ai - informed decisions depend on ai systems'input training data which, unfortunately, can contain implicit racial, gender or ideological biases."", 'such ai - informed decisions can thus lead to unfair treatment of certain groups.', 'for example, in natural language processing ( nlp ), resume search engines can produce rankings that disadvantage some candidates, when these ranking algorithms take demographic features into account ( directly or indirectly )  #AUTHOR_TAG, while abusive online language detection systems have been observed to produce false positives on terms associated with minorities and women  #AUTHOR_TAG.', 'another example where bias ( specifically gender bias ) can be harmful is in personal pronoun coreference resolution, where systems carry the risk of relying on societal stereotypes present in the training data  #AUTHOR_TAG.', 'whilst gender bias in the form of concepts of masculinity and femininity has been found inscribed in implicit ways in ai systems more broadly  #AUTHOR_TAG, this paper focuses on gender bias on word embeddings.', 'word embeddings are one of the most common techniques for giving semantic meaning to words in text and are used as input in virtually every neural nlp system  #AUTHOR_TAG.', 'it has been shown that word embeddings capture human biases ( such as gender bias ) present in these corpora in how they relate words to each other  #TAUTHOR_TAG.', 'for the purposes of this paper, gender bias is understood as the inclination towards or prejudice against one gender.', 'several methods have been proposed to test for the presence of gender bias in word embeddings ; an example being the word embedding association test ( weat )  #TAUTHOR_TAG.', 'weat is a statistical test that detects bias in word embeddings using cosine similarity and averaging methods, paired with hypothesis testing.', 'weat\'s authors applied these tests to the publicly - available glove embeddings trained on the english - language "" common crawl "" corpus  #AUTHOR_TAG as well as the skip - gram ( word2vec ) embeddings trained on the google news corpus  #AUTHOR_TAG.', 'however, there is a diverse range of publicly - available word embeddings trained on corpora of different domains.', 'to address this, we applied the weat test on four sets of word embeddings trained on corpora from four domains : social media ( twit - ter ), a wikipedia - based gender - balanced corpus ( gap ) and a biomedical corpus ( pubmed ) and news ( google news, in order to reproduce and validate our results against those of  #TAUTHOR_TAG ( see section 3 ).', ' #AUTHOR_TAG confirmed the presence of gender bias using three categories of words wellknown to']",5
"[' #TAUTHOR_TAG.', 'the input is']","[' #TAUTHOR_TAG.', 'the input is']","[' #TAUTHOR_TAG.', 'the input is a suspected gender bias word category represented by']","['largely follow the weat hypothesis testing protocol introduced by  #TAUTHOR_TAG.', 'the input is a suspected gender bias word category represented by two lists, x and y, of target words, i. e. words which are suspected to be biased to one or another gender.', 'e. g. x = { programmer, engineer, scientist }, y = { nurse, teacher, librarian }. we wish to test whether x or y is more biased to one gender or the other, or whether there is not difference in bias between the two lists.', 'bias is compared in relation to two reference lists of words that represent unequivocally male and female concepts.', '']",5
['translation pairs  #TAUTHOR_TAG'],['translation pairs  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['', 'representing documents as points in a lowdimensional shared latent space abstracts away from the specific words used in each document, thereby facilitating the analysis of relationships between documents written using different vocabularies.', 'for instance, topic models have been used to identify scientific communities working on related problems in different disciplines, e. g., work on cancer funded by multiple institutes within the nih  #AUTHOR_TAG.', 'while vocabulary mismatch occurs within the realm of one language, naturally this mismatch occurs across different languages.', 'therefore, mapping documents in different languages into a common latent topic space can be of great benefit when detecting document translation pairs  #TAUTHOR_TAG.', 'aside from the benefits that it offers in the task of detecting document translation pairs, topic models offer potential benefits to the task of creating translation lexica, aligning passages, etc.', 'the process of discovering relationship between documents using topic models involves : ( 1 ) representing documents in the latent space by inferring their topic distributions and ( 2 ) comparing pairs of topic distributions to find close matches.', 'many widely used techniques do not scale efficiently, however, as the size of the document collection grows.', 'posterior inference by gibbs sampling, for instance, may make thousands of passes through the data.', 'for the task of comparing topic distributions, recent work has also resorted to comparing all pairs of documents  #AUTHOR_TAG.', 'this paper presents efficient methods for both of these steps and performs empirical evaluations on the task of detected translated document pairs embedded in a large multilingual corpus.', 'unlike some more exploratory applications of topic models, translation detection is easy to evaluate.', 'the need for bilingual training data in many language pairs and domains also makes it attractive to mitigate the quadratic runtime of brute force translation detection.', 'we begin in § 2 by extending the online variational bayes approach of  #AUTHOR_TAG to polylingual topic models  #AUTHOR_TAG.', 'then, in § 3, we']",1
[' #TAUTHOR_TAG ; ja'],"[' #TAUTHOR_TAG ; jagarlamudi and daume, 2010 ;  #AUTHOR_TAG, to name a few.', 'in this paper, we focus on the polylingual topic model,']","['widespread use on monolingual text, topic models have also been used to model multilingual data  #TAUTHOR_TAG ; ja']","['generative bayesian models, such as topic models, have proven to be very effective for modeling document collections and discovering underlying latent semantic structures.', 'most current topic models are based on latent dirichlet allocation ( lda ).', 'in some early work on the subject, showed the usefulness of lda on the task of automatic annotation of images.', ' #AUTHOR_TAG used lda to analyze historical trends in the scientific literature ;  #AUTHOR_TAG showed improvements on an information retrieval task.', 'more recently  #AUTHOR_TAG modeled geographic linguistic variation using twitter data.', 'aside from their widespread use on monolingual text, topic models have also been used to model multilingual data  #TAUTHOR_TAG ; jagarlamudi and daume, 2010 ;  #AUTHOR_TAG, to name a few.', 'in this paper, we focus on the polylingual topic model, introduced by  #AUTHOR_TAG.', 'given a multilingual set of aligned documents, the pltm assumes that across an aligned multilingual document tuple, there exists a single, tuple - specific, distribution across topics.', 'in addition, pltm assumes that for each language - topic pair, there exists a distribution over words in that language β l.', '']",0
"['( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of principal']","['( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of principal']","['( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of']","['multilingual documents into a common, language - independent vector space for the purpose of improving machine translation ( mt ) and performing cross - language information retrieval ( clir ) tasks has been explored through various techniques.', ' #AUTHOR_TAG introduced polylingual topic models ( pltm ), an extension of latent dirichlet allocation ( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of principal component analysis ( pca ) and probabilistic latent semantic indexing ( plsi ).', 'both the pltm and plsi represent bilingual documents in the probability simplex, and thus the task of finding document translation pairs is formulated as finding similar probability distributions.', 'while the nature of both works was exploratory, results shown on fairly large collections of bilingual documents ( less than 20k documents ) offer convincing argument of their potential.', 'expanding these approaches to much large collections of multilingual documents would require utilizing fast nn search for computing similarity in the probability simplex.', 'while there are many other proposed approaches to the task of finding document translation pairs that represent documents in metric space, such as  #AUTHOR_TAG which utilizes lsh for cosine distance, there is no evidence that they yield good results on documents of small lengths such as paragraphs and even sen - tences.', 'in this section, we empirically show how to utilize approaches that deal with representing documents in the probability simplex without a significant loss in accuracy while significantly improving the processing time.', 'we use pltm representations of bilingual documents.', 'in addition, we show how the results as reported by  #TAUTHOR_TAG can be obtained using the pltm representation with a significant speed improvement.', 'as in  #TAUTHOR_TAG and  #AUTHOR_TAG the task is to find document translation pairs in a multilingual collection of documents by representing documents in the probability simplex and computing similarity between their probability distribution representation across all document pairs.', 'for this experimental setup, accuracy is defined as the number of times ( in percentage ) that the target language document was discovered at rank 1 ( i. e. % @ rank 1. ) across the whole test collection']",0
"['( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of principal']","['( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of principal']","['( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of']","['multilingual documents into a common, language - independent vector space for the purpose of improving machine translation ( mt ) and performing cross - language information retrieval ( clir ) tasks has been explored through various techniques.', ' #AUTHOR_TAG introduced polylingual topic models ( pltm ), an extension of latent dirichlet allocation ( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of principal component analysis ( pca ) and probabilistic latent semantic indexing ( plsi ).', 'both the pltm and plsi represent bilingual documents in the probability simplex, and thus the task of finding document translation pairs is formulated as finding similar probability distributions.', 'while the nature of both works was exploratory, results shown on fairly large collections of bilingual documents ( less than 20k documents ) offer convincing argument of their potential.', 'expanding these approaches to much large collections of multilingual documents would require utilizing fast nn search for computing similarity in the probability simplex.', 'while there are many other proposed approaches to the task of finding document translation pairs that represent documents in metric space, such as  #AUTHOR_TAG which utilizes lsh for cosine distance, there is no evidence that they yield good results on documents of small lengths such as paragraphs and even sen - tences.', 'in this section, we empirically show how to utilize approaches that deal with representing documents in the probability simplex without a significant loss in accuracy while significantly improving the processing time.', 'we use pltm representations of bilingual documents.', 'in addition, we show how the results as reported by  #TAUTHOR_TAG can be obtained using the pltm representation with a significant speed improvement.', 'as in  #TAUTHOR_TAG and  #AUTHOR_TAG the task is to find document translation pairs in a multilingual collection of documents by representing documents in the probability simplex and computing similarity between their probability distribution representation across all document pairs.', 'for this experimental setup, accuracy is defined as the number of times ( in percentage ) that the target language document was discovered at rank 1 ( i. e. % @ rank 1. ) across the whole test collection']",4
"['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case']","['of the four pltm models and the performance across the four different similarity measurements was evaluated based on the percentage of document translation pairs ( out of the whole test set ) that were discovered at rank one.', 'this same approach was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case of the previous two tasks, in order to evaluate the approximate, lsh based, hellinger distance we used values of r = 0. 4, r = 0. 6 and r = 0. 8.', 'since in  #TAUTHOR_TAG numbers were reported on the test speeches whose word length is greater or equal to 100, we used the same subset ( total of 14150 speeches ) of the original test collection.', 'shown in table 1 are results across the four different measurements for all four pltm models.', 'when using regular js divergence, our pltm model with 200 topics performs the best with 99. 42 % of the top one ranked candidate translation documents being true translations.', 'when using approximate, kd - trees based, hellinger distance, we outperform regular js and hellinger divergence across all topics and for t = 500 we achieve the best overall accuracy of 99. 61 %.', 'we believe that this is due to the small amount of error in the search introduced by ann, due to its approximate nature, which for this task yields positive results.', 'on the same data set,  #TAUTHOR_TAG report accuracy of 98. 9 % using 50 topics, a slightly different prior distribution, and map instead of posterior inference.', 'shown in table 2 are the relative differences in time between all pairs js divergence, approximate kd - trees and lsh based hellinger distance with different value of r. rather than showing absolute speed numbers, which are often influenced by the processor configuration and available memory, we show relative speed improvements where we take the slowest running configuration as a referent value.', 'in our case we assign the referent speed value of 1 to the configuration with t = 500 and allpairs js computation.', 'results shown are based on comparing running time of e2lsh and ann against the all - pairs similarity comparison implementation that uses hash tables to store all documents in the bilingual collection which is significantly faster than the other code implementation.', 'for the approximate, lsh based, hellinger distance with t = 100 we obtain a speed improvement of 24. 2 times compared to regular all - pairs js divergence while maintaining the same performance compared to hellinger distance metric and insignificant loss over all - pairs js divergence.', 'from table 2 it is evident that as we increase the radius r we reduce the relative']",4
"['( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of principal']","['( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of principal']","['( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of']","['multilingual documents into a common, language - independent vector space for the purpose of improving machine translation ( mt ) and performing cross - language information retrieval ( clir ) tasks has been explored through various techniques.', ' #AUTHOR_TAG introduced polylingual topic models ( pltm ), an extension of latent dirichlet allocation ( lda ), and, more recently,  #TAUTHOR_TAG proposed extensions of principal component analysis ( pca ) and probabilistic latent semantic indexing ( plsi ).', 'both the pltm and plsi represent bilingual documents in the probability simplex, and thus the task of finding document translation pairs is formulated as finding similar probability distributions.', 'while the nature of both works was exploratory, results shown on fairly large collections of bilingual documents ( less than 20k documents ) offer convincing argument of their potential.', 'expanding these approaches to much large collections of multilingual documents would require utilizing fast nn search for computing similarity in the probability simplex.', 'while there are many other proposed approaches to the task of finding document translation pairs that represent documents in metric space, such as  #AUTHOR_TAG which utilizes lsh for cosine distance, there is no evidence that they yield good results on documents of small lengths such as paragraphs and even sen - tences.', 'in this section, we empirically show how to utilize approaches that deal with representing documents in the probability simplex without a significant loss in accuracy while significantly improving the processing time.', 'we use pltm representations of bilingual documents.', 'in addition, we show how the results as reported by  #TAUTHOR_TAG can be obtained using the pltm representation with a significant speed improvement.', 'as in  #TAUTHOR_TAG and  #AUTHOR_TAG the task is to find document translation pairs in a multilingual collection of documents by representing documents in the probability simplex and computing similarity between their probability distribution representation across all document pairs.', 'for this experimental setup, accuracy is defined as the number of times ( in percentage ) that the target language document was discovered at rank 1 ( i. e. % @ rank 1. ) across the whole test collection']",3
"['set used in  #TAUTHOR_TAG.', 'that paper used the']","['set used in  #TAUTHOR_TAG.', 'that paper used the']","['used in  #TAUTHOR_TAG.', 'that paper used the europarl  #AUTHOR_TAG  #AUTHOR_TAG, these performance comparisons are not']","[""use mallet's ( mc  #AUTHOR_TAG implementation of the pltm to train and infer topics on the same data set used in  #TAUTHOR_TAG."", 'that paper used the europarl  #AUTHOR_TAG  #AUTHOR_TAG, these performance comparisons are not done on the same training and test sets - a gap that we fill below.', 'we train pltm models with number of topics t set to 50, 100, 200, and 500.', 'in order to compare exactly the same topic distributions when computing speed vs. accuracy of various approximate and exhaustive all - pairs comparisons we focus only on one inference approach - the gibbs sampling and ignore the online vb approach as it yields similar performance.', 'for all four topic models, we use the same settings for pltm ( hyperparameter values and number of gibbs sampling iterations ) as in  #AUTHOR_TAG 2.', 'topic distributions were then inferred on the test collection using the trained topics.', 'we then performed all - pairs comparison using js divergence, hellinger distance, and approximate, lsh and kd - trees based, hellinger distance.', 'we measured the total time that it takes to perform exhaustive all - pairs comparison using js divergence, the lsh and kdtrees version on a single machine consisting of a core 2 duo quad processors with a clock speed of 2. 66ghz on each core and a total of 8gb of memory.', 'since the time performance of the e2lsh depends on the radius r of data set points considered for each query point  #AUTHOR_TAG, we performed measurements with different values of r. for this task, the all - pairs js code implementation first reads both source and target sets of documents and stores them in hash tables.', 'we then go over each entry in the source table and compute divergence against all target table entries.', 'we refer to this code implementation as hash map implementation']",3
"['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case']","['of the four pltm models and the performance across the four different similarity measurements was evaluated based on the percentage of document translation pairs ( out of the whole test set ) that were discovered at rank one.', 'this same approach was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case of the previous two tasks, in order to evaluate the approximate, lsh based, hellinger distance we used values of r = 0. 4, r = 0. 6 and r = 0. 8.', 'since in  #TAUTHOR_TAG numbers were reported on the test speeches whose word length is greater or equal to 100, we used the same subset ( total of 14150 speeches ) of the original test collection.', 'shown in table 1 are results across the four different measurements for all four pltm models.', 'when using regular js divergence, our pltm model with 200 topics performs the best with 99. 42 % of the top one ranked candidate translation documents being true translations.', 'when using approximate, kd - trees based, hellinger distance, we outperform regular js and hellinger divergence across all topics and for t = 500 we achieve the best overall accuracy of 99. 61 %.', 'we believe that this is due to the small amount of error in the search introduced by ann, due to its approximate nature, which for this task yields positive results.', 'on the same data set,  #TAUTHOR_TAG report accuracy of 98. 9 % using 50 topics, a slightly different prior distribution, and map instead of posterior inference.', 'shown in table 2 are the relative differences in time between all pairs js divergence, approximate kd - trees and lsh based hellinger distance with different value of r. rather than showing absolute speed numbers, which are often influenced by the processor configuration and available memory, we show relative speed improvements where we take the slowest running configuration as a referent value.', 'in our case we assign the referent speed value of 1 to the configuration with t = 500 and allpairs js computation.', 'results shown are based on comparing running time of e2lsh and ann against the all - pairs similarity comparison implementation that uses hash tables to store all documents in the bilingual collection which is significantly faster than the other code implementation.', 'for the approximate, lsh based, hellinger distance with t = 100 we obtain a speed improvement of 24. 2 times compared to regular all - pairs js divergence while maintaining the same performance compared to hellinger distance metric and insignificant loss over all - pairs js divergence.', 'from table 2 it is evident that as we increase the radius r we reduce the relative']",3
"['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case']","['of the four pltm models and the performance across the four different similarity measurements was evaluated based on the percentage of document translation pairs ( out of the whole test set ) that were discovered at rank one.', 'this same approach was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case of the previous two tasks, in order to evaluate the approximate, lsh based, hellinger distance we used values of r = 0. 4, r = 0. 6 and r = 0. 8.', 'since in  #TAUTHOR_TAG numbers were reported on the test speeches whose word length is greater or equal to 100, we used the same subset ( total of 14150 speeches ) of the original test collection.', 'shown in table 1 are results across the four different measurements for all four pltm models.', 'when using regular js divergence, our pltm model with 200 topics performs the best with 99. 42 % of the top one ranked candidate translation documents being true translations.', 'when using approximate, kd - trees based, hellinger distance, we outperform regular js and hellinger divergence across all topics and for t = 500 we achieve the best overall accuracy of 99. 61 %.', 'we believe that this is due to the small amount of error in the search introduced by ann, due to its approximate nature, which for this task yields positive results.', 'on the same data set,  #TAUTHOR_TAG report accuracy of 98. 9 % using 50 topics, a slightly different prior distribution, and map instead of posterior inference.', 'shown in table 2 are the relative differences in time between all pairs js divergence, approximate kd - trees and lsh based hellinger distance with different value of r. rather than showing absolute speed numbers, which are often influenced by the processor configuration and available memory, we show relative speed improvements where we take the slowest running configuration as a referent value.', 'in our case we assign the referent speed value of 1 to the configuration with t = 500 and allpairs js computation.', 'results shown are based on comparing running time of e2lsh and ann against the all - pairs similarity comparison implementation that uses hash tables to store all documents in the bilingual collection which is significantly faster than the other code implementation.', 'for the approximate, lsh based, hellinger distance with t = 100 we obtain a speed improvement of 24. 2 times compared to regular all - pairs js divergence while maintaining the same performance compared to hellinger distance metric and insignificant loss over all - pairs js divergence.', 'from table 2 it is evident that as we increase the radius r we reduce the relative']",3
"['set used in  #TAUTHOR_TAG.', 'that paper used the']","['set used in  #TAUTHOR_TAG.', 'that paper used the']","['used in  #TAUTHOR_TAG.', 'that paper used the europarl  #AUTHOR_TAG  #AUTHOR_TAG, these performance comparisons are not']","[""use mallet's ( mc  #AUTHOR_TAG implementation of the pltm to train and infer topics on the same data set used in  #TAUTHOR_TAG."", 'that paper used the europarl  #AUTHOR_TAG  #AUTHOR_TAG, these performance comparisons are not done on the same training and test sets - a gap that we fill below.', 'we train pltm models with number of topics t set to 50, 100, 200, and 500.', 'in order to compare exactly the same topic distributions when computing speed vs. accuracy of various approximate and exhaustive all - pairs comparisons we focus only on one inference approach - the gibbs sampling and ignore the online vb approach as it yields similar performance.', 'for all four topic models, we use the same settings for pltm ( hyperparameter values and number of gibbs sampling iterations ) as in  #AUTHOR_TAG 2.', 'topic distributions were then inferred on the test collection using the trained topics.', 'we then performed all - pairs comparison using js divergence, hellinger distance, and approximate, lsh and kd - trees based, hellinger distance.', 'we measured the total time that it takes to perform exhaustive all - pairs comparison using js divergence, the lsh and kdtrees version on a single machine consisting of a core 2 duo quad processors with a clock speed of 2. 66ghz on each core and a total of 8gb of memory.', 'since the time performance of the e2lsh depends on the radius r of data set points considered for each query point  #AUTHOR_TAG, we performed measurements with different values of r. for this task, the all - pairs js code implementation first reads both source and target sets of documents and stores them in hash tables.', 'we then go over each entry in the source table and compute divergence against all target table entries.', 'we refer to this code implementation as hash map implementation']",5
"['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case']","['of the four pltm models and the performance across the four different similarity measurements was evaluated based on the percentage of document translation pairs ( out of the whole test set ) that were discovered at rank one.', 'this same approach was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case of the previous two tasks, in order to evaluate the approximate, lsh based, hellinger distance we used values of r = 0. 4, r = 0. 6 and r = 0. 8.', 'since in  #TAUTHOR_TAG numbers were reported on the test speeches whose word length is greater or equal to 100, we used the same subset ( total of 14150 speeches ) of the original test collection.', 'shown in table 1 are results across the four different measurements for all four pltm models.', 'when using regular js divergence, our pltm model with 200 topics performs the best with 99. 42 % of the top one ranked candidate translation documents being true translations.', 'when using approximate, kd - trees based, hellinger distance, we outperform regular js and hellinger divergence across all topics and for t = 500 we achieve the best overall accuracy of 99. 61 %.', 'we believe that this is due to the small amount of error in the search introduced by ann, due to its approximate nature, which for this task yields positive results.', 'on the same data set,  #TAUTHOR_TAG report accuracy of 98. 9 % using 50 topics, a slightly different prior distribution, and map instead of posterior inference.', 'shown in table 2 are the relative differences in time between all pairs js divergence, approximate kd - trees and lsh based hellinger distance with different value of r. rather than showing absolute speed numbers, which are often influenced by the processor configuration and available memory, we show relative speed improvements where we take the slowest running configuration as a referent value.', 'in our case we assign the referent speed value of 1 to the configuration with t = 500 and allpairs js computation.', 'results shown are based on comparing running time of e2lsh and ann against the all - pairs similarity comparison implementation that uses hash tables to store all documents in the bilingual collection which is significantly faster than the other code implementation.', 'for the approximate, lsh based, hellinger distance with t = 100 we obtain a speed improvement of 24. 2 times compared to regular all - pairs js divergence while maintaining the same performance compared to hellinger distance metric and insignificant loss over all - pairs js divergence.', 'from table 2 it is evident that as we increase the radius r we reduce the relative']",5
"['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case']","['of the four pltm models and the performance across the four different similarity measurements was evaluated based on the percentage of document translation pairs ( out of the whole test set ) that were discovered at rank one.', 'this same approach was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case of the previous two tasks, in order to evaluate the approximate, lsh based, hellinger distance we used values of r = 0. 4, r = 0. 6 and r = 0. 8.', 'since in  #TAUTHOR_TAG numbers were reported on the test speeches whose word length is greater or equal to 100, we used the same subset ( total of 14150 speeches ) of the original test collection.', 'shown in table 1 are results across the four different measurements for all four pltm models.', 'when using regular js divergence, our pltm model with 200 topics performs the best with 99. 42 % of the top one ranked candidate translation documents being true translations.', 'when using approximate, kd - trees based, hellinger distance, we outperform regular js and hellinger divergence across all topics and for t = 500 we achieve the best overall accuracy of 99. 61 %.', 'we believe that this is due to the small amount of error in the search introduced by ann, due to its approximate nature, which for this task yields positive results.', 'on the same data set,  #TAUTHOR_TAG report accuracy of 98. 9 % using 50 topics, a slightly different prior distribution, and map instead of posterior inference.', 'shown in table 2 are the relative differences in time between all pairs js divergence, approximate kd - trees and lsh based hellinger distance with different value of r. rather than showing absolute speed numbers, which are often influenced by the processor configuration and available memory, we show relative speed improvements where we take the slowest running configuration as a referent value.', 'in our case we assign the referent speed value of 1 to the configuration with t = 500 and allpairs js computation.', 'results shown are based on comparing running time of e2lsh and ann against the all - pairs similarity comparison implementation that uses hash tables to store all documents in the bilingual collection which is significantly faster than the other code implementation.', 'for the approximate, lsh based, hellinger distance with t = 100 we obtain a speed improvement of 24. 2 times compared to regular all - pairs js divergence while maintaining the same performance compared to hellinger distance metric and insignificant loss over all - pairs js divergence.', 'from table 2 it is evident that as we increase the radius r we reduce the relative']",5
"['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the']","['was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case']","['of the four pltm models and the performance across the four different similarity measurements was evaluated based on the percentage of document translation pairs ( out of the whole test set ) that were discovered at rank one.', 'this same approach was used by  #TAUTHOR_TAG to show the absolute performance comparison.', 'as in the case of the previous two tasks, in order to evaluate the approximate, lsh based, hellinger distance we used values of r = 0. 4, r = 0. 6 and r = 0. 8.', 'since in  #TAUTHOR_TAG numbers were reported on the test speeches whose word length is greater or equal to 100, we used the same subset ( total of 14150 speeches ) of the original test collection.', 'shown in table 1 are results across the four different measurements for all four pltm models.', 'when using regular js divergence, our pltm model with 200 topics performs the best with 99. 42 % of the top one ranked candidate translation documents being true translations.', 'when using approximate, kd - trees based, hellinger distance, we outperform regular js and hellinger divergence across all topics and for t = 500 we achieve the best overall accuracy of 99. 61 %.', 'we believe that this is due to the small amount of error in the search introduced by ann, due to its approximate nature, which for this task yields positive results.', 'on the same data set,  #TAUTHOR_TAG report accuracy of 98. 9 % using 50 topics, a slightly different prior distribution, and map instead of posterior inference.', 'shown in table 2 are the relative differences in time between all pairs js divergence, approximate kd - trees and lsh based hellinger distance with different value of r. rather than showing absolute speed numbers, which are often influenced by the processor configuration and available memory, we show relative speed improvements where we take the slowest running configuration as a referent value.', 'in our case we assign the referent speed value of 1 to the configuration with t = 500 and allpairs js computation.', 'results shown are based on comparing running time of e2lsh and ann against the all - pairs similarity comparison implementation that uses hash tables to store all documents in the bilingual collection which is significantly faster than the other code implementation.', 'for the approximate, lsh based, hellinger distance with t = 100 we obtain a speed improvement of 24. 2 times compared to regular all - pairs js divergence while maintaining the same performance compared to hellinger distance metric and insignificant loss over all - pairs js divergence.', 'from table 2 it is evident that as we increase the radius r we reduce the relative']",6
"['workplace interactions  #TAUTHOR_TAG.', '']","['workplace interactions  #TAUTHOR_TAG.', '']","['workplace interactions  #TAUTHOR_TAG.', 'the corporate environment is one social context in which power dynamics have a clearly defined structure and shape the interactions between individuals, making']","['the availability and abundance of linguistic data that captures different avenues of human social interactions, there is an unprecedented opportunity to expand nlp to not only understand language, but also to understand the people who speak it and the social relations between them.', 'social power structures are ubiquitous in human interactions, and since power is often reflected through language, computational research at the intersection of language and power has gained interest recently.', 'this research has been applied to a wide array of domains such as wikipedia talk pages  #AUTHOR_TAG danescu - niculescu -  #AUTHOR_TAG, blogs  #AUTHOR_TAG as well as workplace interactions  #TAUTHOR_TAG.', 'the corporate environment is one social context in which power dynamics have a clearly defined structure and shape the interactions between individuals, making it an interesting case study on how language and power interact.', 'organizations stand to benefit greatly from being able to detect power dynamics within their internal interactions, in order to address disparities and ensure inclusive and productive workplaces.', 'for instance,  #AUTHOR_TAG reports that women are more likely to experience incivility, often from superiors.', 'it has also been shown that incivility may breed more incivility  #AUTHOR_TAG, and that it can lead to increased stress and lack of commitment  #AUTHOR_TAG.', 'prior work has investigated the use of nlp techniques to study manifestations of different types of power using the enron email corpus  #AUTHOR_TAG.', 'while early work  #TAUTHOR_TAG focused on surface level lexical features aggregated at corpus level, more recent work has looked into the thread structure of emails as well  #AUTHOR_TAG.', 'however, both  #TAUTHOR_TAG and  #AUTHOR_TAG group all messages sent by an individual to another individual ( at the corpus - level and at the thread - level, respectively ) and rely on word - ngram * authors ( listed in alphabetical order ) contributed equally']",0
"['workplace interactions  #TAUTHOR_TAG.', '']","['workplace interactions  #TAUTHOR_TAG.', '']","['workplace interactions  #TAUTHOR_TAG.', 'the corporate environment is one social context in which power dynamics have a clearly defined structure and shape the interactions between individuals, making']","['the availability and abundance of linguistic data that captures different avenues of human social interactions, there is an unprecedented opportunity to expand nlp to not only understand language, but also to understand the people who speak it and the social relations between them.', 'social power structures are ubiquitous in human interactions, and since power is often reflected through language, computational research at the intersection of language and power has gained interest recently.', 'this research has been applied to a wide array of domains such as wikipedia talk pages  #AUTHOR_TAG danescu - niculescu -  #AUTHOR_TAG, blogs  #AUTHOR_TAG as well as workplace interactions  #TAUTHOR_TAG.', 'the corporate environment is one social context in which power dynamics have a clearly defined structure and shape the interactions between individuals, making it an interesting case study on how language and power interact.', 'organizations stand to benefit greatly from being able to detect power dynamics within their internal interactions, in order to address disparities and ensure inclusive and productive workplaces.', 'for instance,  #AUTHOR_TAG reports that women are more likely to experience incivility, often from superiors.', 'it has also been shown that incivility may breed more incivility  #AUTHOR_TAG, and that it can lead to increased stress and lack of commitment  #AUTHOR_TAG.', 'prior work has investigated the use of nlp techniques to study manifestations of different types of power using the enron email corpus  #AUTHOR_TAG.', 'while early work  #TAUTHOR_TAG focused on surface level lexical features aggregated at corpus level, more recent work has looked into the thread structure of emails as well  #AUTHOR_TAG.', 'however, both  #TAUTHOR_TAG and  #AUTHOR_TAG group all messages sent by an individual to another individual ( at the corpus - level and at the thread - level, respectively ) and rely on word - ngram * authors ( listed in alphabetical order ) contributed equally']",0
"['workplace interactions  #TAUTHOR_TAG.', '']","['workplace interactions  #TAUTHOR_TAG.', '']","['workplace interactions  #TAUTHOR_TAG.', 'the corporate environment is one social context in which power dynamics have a clearly defined structure and shape the interactions between individuals, making']","['the availability and abundance of linguistic data that captures different avenues of human social interactions, there is an unprecedented opportunity to expand nlp to not only understand language, but also to understand the people who speak it and the social relations between them.', 'social power structures are ubiquitous in human interactions, and since power is often reflected through language, computational research at the intersection of language and power has gained interest recently.', 'this research has been applied to a wide array of domains such as wikipedia talk pages  #AUTHOR_TAG danescu - niculescu -  #AUTHOR_TAG, blogs  #AUTHOR_TAG as well as workplace interactions  #TAUTHOR_TAG.', 'the corporate environment is one social context in which power dynamics have a clearly defined structure and shape the interactions between individuals, making it an interesting case study on how language and power interact.', 'organizations stand to benefit greatly from being able to detect power dynamics within their internal interactions, in order to address disparities and ensure inclusive and productive workplaces.', 'for instance,  #AUTHOR_TAG reports that women are more likely to experience incivility, often from superiors.', 'it has also been shown that incivility may breed more incivility  #AUTHOR_TAG, and that it can lead to increased stress and lack of commitment  #AUTHOR_TAG.', 'prior work has investigated the use of nlp techniques to study manifestations of different types of power using the enron email corpus  #AUTHOR_TAG.', 'while early work  #TAUTHOR_TAG focused on surface level lexical features aggregated at corpus level, more recent work has looked into the thread structure of emails as well  #AUTHOR_TAG.', 'however, both  #TAUTHOR_TAG and  #AUTHOR_TAG group all messages sent by an individual to another individual ( at the corpus - level and at the thread - level, respectively ) and rely on word - ngram * authors ( listed in alphabetical order ) contributed equally']",0
['in this problem  #TAUTHOR_TAG'],['in this problem  #TAUTHOR_TAG'],"['in this problem  #TAUTHOR_TAG.', 'we use the performance reported by  #AUTHOR_TAG using svm as baseline for']","['use support vector machine ( svm ) based approaches as our baseline, since they are the state - of - the art in this problem  #TAUTHOR_TAG.', 'we use the performance reported by  #AUTHOR_TAG using svm as baseline for the per - thread formulation ( using the same train - dev - test splits ) and implemented an svm baseline for the grouped formulation ( not directly comparable to performance reported by  #TAUTHOR_TAG ).', 'for each of our neural net models, we trained for 30 - 70 epochs until the performance on the development set stopped improving, in order to avoid overfitting.', 'we used hyperas to tune hyperparameters on our development dataset for the same set of parameter options for each task formulation, varying activation functions, hidden layer size, batch size, dropout, number of filters, and number of words to include per email.', '']",0
"['workplace interactions  #TAUTHOR_TAG.', '']","['workplace interactions  #TAUTHOR_TAG.', '']","['workplace interactions  #TAUTHOR_TAG.', 'the corporate environment is one social context in which power dynamics have a clearly defined structure and shape the interactions between individuals, making']","['the availability and abundance of linguistic data that captures different avenues of human social interactions, there is an unprecedented opportunity to expand nlp to not only understand language, but also to understand the people who speak it and the social relations between them.', 'social power structures are ubiquitous in human interactions, and since power is often reflected through language, computational research at the intersection of language and power has gained interest recently.', 'this research has been applied to a wide array of domains such as wikipedia talk pages  #AUTHOR_TAG danescu - niculescu -  #AUTHOR_TAG, blogs  #AUTHOR_TAG as well as workplace interactions  #TAUTHOR_TAG.', 'the corporate environment is one social context in which power dynamics have a clearly defined structure and shape the interactions between individuals, making it an interesting case study on how language and power interact.', 'organizations stand to benefit greatly from being able to detect power dynamics within their internal interactions, in order to address disparities and ensure inclusive and productive workplaces.', 'for instance,  #AUTHOR_TAG reports that women are more likely to experience incivility, often from superiors.', 'it has also been shown that incivility may breed more incivility  #AUTHOR_TAG, and that it can lead to increased stress and lack of commitment  #AUTHOR_TAG.', 'prior work has investigated the use of nlp techniques to study manifestations of different types of power using the enron email corpus  #AUTHOR_TAG.', 'while early work  #TAUTHOR_TAG focused on surface level lexical features aggregated at corpus level, more recent work has looked into the thread structure of emails as well  #AUTHOR_TAG.', 'however, both  #TAUTHOR_TAG and  #AUTHOR_TAG group all messages sent by an individual to another individual ( at the corpus - level and at the thread - level, respectively ) and rely on word - ngram * authors ( listed in alphabetical order ) contributed equally']",1
"['between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground']","['between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground']","['##s a sent to b across all threads in the corpus, and vice versa, and use these sets of emails to predict the power relation between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground truth of power relations from  #AUTHOR_TAG ; however, we created an svm model that uses word - ngram features similar to theirs as a baseline to our proposed neural architectures']","['use the version of the enron email corpus released by  #AUTHOR_TAG that captures the organizational power relation between 13, 724 pairs of enron employees, in addition to the reconstructed thread structure of email messages added by  #AUTHOR_TAG.', 'we mask greetings and signature lines in the email content to prevent our model from being biased by the roles held by specific employees.', 'prior work on nlp approaches to predict power in organizational email has used two different problem formulations - per - thread and grouped.', 'we investigate both formulations in this paper.', 'table 1 shows the number of data instances in each problem formulation.', 'per - thread : this formulation was introduced by  #AUTHOR_TAG in which, for a given thread t and a pair of related interacting participant pairs ( a, b ), the direction of power between a and b is predicted ( where the assignment of labels a and b is arbitrary ).', 'the participants in these pairs are 1 ) interacting : at least one message exists in the thread such that either a is the sender and b is a recipient or vice versa, and 2 ) related : a and b are related by a dominance relation ( either superior or subordinate ) based on the organizational hierarchy.', 'as in  #AUTHOR_TAG, we exclude pairs of employees who are peers, and we use the same train - dev - test splits so our results are comparable.', 'grouped : here, we group all emails a sent to b across all threads in the corpus, and vice versa, and use these sets of emails to predict the power relation between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground truth of power relations from  #AUTHOR_TAG ; however, we created an svm model that uses word - ngram features similar to theirs as a baseline to our proposed neural architectures']",4
['in this problem  #TAUTHOR_TAG'],['in this problem  #TAUTHOR_TAG'],"['in this problem  #TAUTHOR_TAG.', 'we use the performance reported by  #AUTHOR_TAG using svm as baseline for']","['use support vector machine ( svm ) based approaches as our baseline, since they are the state - of - the art in this problem  #TAUTHOR_TAG.', 'we use the performance reported by  #AUTHOR_TAG using svm as baseline for the per - thread formulation ( using the same train - dev - test splits ) and implemented an svm baseline for the grouped formulation ( not directly comparable to performance reported by  #TAUTHOR_TAG ).', 'for each of our neural net models, we trained for 30 - 70 epochs until the performance on the development set stopped improving, in order to avoid overfitting.', 'we used hyperas to tune hyperparameters on our development dataset for the same set of parameter options for each task formulation, varying activation functions, hidden layer size, batch size, dropout, number of filters, and number of words to include per email.', '']",4
"['between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground']","['between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground']","['##s a sent to b across all threads in the corpus, and vice versa, and use these sets of emails to predict the power relation between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground truth of power relations from  #AUTHOR_TAG ; however, we created an svm model that uses word - ngram features similar to theirs as a baseline to our proposed neural architectures']","['use the version of the enron email corpus released by  #AUTHOR_TAG that captures the organizational power relation between 13, 724 pairs of enron employees, in addition to the reconstructed thread structure of email messages added by  #AUTHOR_TAG.', 'we mask greetings and signature lines in the email content to prevent our model from being biased by the roles held by specific employees.', 'prior work on nlp approaches to predict power in organizational email has used two different problem formulations - per - thread and grouped.', 'we investigate both formulations in this paper.', 'table 1 shows the number of data instances in each problem formulation.', 'per - thread : this formulation was introduced by  #AUTHOR_TAG in which, for a given thread t and a pair of related interacting participant pairs ( a, b ), the direction of power between a and b is predicted ( where the assignment of labels a and b is arbitrary ).', 'the participants in these pairs are 1 ) interacting : at least one message exists in the thread such that either a is the sender and b is a recipient or vice versa, and 2 ) related : a and b are related by a dominance relation ( either superior or subordinate ) based on the organizational hierarchy.', 'as in  #AUTHOR_TAG, we exclude pairs of employees who are peers, and we use the same train - dev - test splits so our results are comparable.', 'grouped : here, we group all emails a sent to b across all threads in the corpus, and vice versa, and use these sets of emails to predict the power relation between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground truth of power relations from  #AUTHOR_TAG ; however, we created an svm model that uses word - ngram features similar to theirs as a baseline to our proposed neural architectures']",6
['in this problem  #TAUTHOR_TAG'],['in this problem  #TAUTHOR_TAG'],"['in this problem  #TAUTHOR_TAG.', 'we use the performance reported by  #AUTHOR_TAG using svm as baseline for']","['use support vector machine ( svm ) based approaches as our baseline, since they are the state - of - the art in this problem  #TAUTHOR_TAG.', 'we use the performance reported by  #AUTHOR_TAG using svm as baseline for the per - thread formulation ( using the same train - dev - test splits ) and implemented an svm baseline for the grouped formulation ( not directly comparable to performance reported by  #TAUTHOR_TAG ).', 'for each of our neural net models, we trained for 30 - 70 epochs until the performance on the development set stopped improving, in order to avoid overfitting.', 'we used hyperas to tune hyperparameters on our development dataset for the same set of parameter options for each task formulation, varying activation functions, hidden layer size, batch size, dropout, number of filters, and number of words to include per email.', '']",6
"['between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground']","['between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground']","['##s a sent to b across all threads in the corpus, and vice versa, and use these sets of emails to predict the power relation between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground truth of power relations from  #AUTHOR_TAG ; however, we created an svm model that uses word - ngram features similar to theirs as a baseline to our proposed neural architectures']","['use the version of the enron email corpus released by  #AUTHOR_TAG that captures the organizational power relation between 13, 724 pairs of enron employees, in addition to the reconstructed thread structure of email messages added by  #AUTHOR_TAG.', 'we mask greetings and signature lines in the email content to prevent our model from being biased by the roles held by specific employees.', 'prior work on nlp approaches to predict power in organizational email has used two different problem formulations - per - thread and grouped.', 'we investigate both formulations in this paper.', 'table 1 shows the number of data instances in each problem formulation.', 'per - thread : this formulation was introduced by  #AUTHOR_TAG in which, for a given thread t and a pair of related interacting participant pairs ( a, b ), the direction of power between a and b is predicted ( where the assignment of labels a and b is arbitrary ).', 'the participants in these pairs are 1 ) interacting : at least one message exists in the thread such that either a is the sender and b is a recipient or vice versa, and 2 ) related : a and b are related by a dominance relation ( either superior or subordinate ) based on the organizational hierarchy.', 'as in  #AUTHOR_TAG, we exclude pairs of employees who are peers, and we use the same train - dev - test splits so our results are comparable.', 'grouped : here, we group all emails a sent to b across all threads in the corpus, and vice versa, and use these sets of emails to predict the power relation between a and b. this formulation is similar those in  #TAUTHOR_TAG, but our results are not directly comparable since, unlike them, we rely on the ground truth of power relations from  #AUTHOR_TAG ; however, we created an svm model that uses word - ngram features similar to theirs as a baseline to our proposed neural architectures']",3
['in this problem  #TAUTHOR_TAG'],['in this problem  #TAUTHOR_TAG'],"['in this problem  #TAUTHOR_TAG.', 'we use the performance reported by  #AUTHOR_TAG using svm as baseline for']","['use support vector machine ( svm ) based approaches as our baseline, since they are the state - of - the art in this problem  #TAUTHOR_TAG.', 'we use the performance reported by  #AUTHOR_TAG using svm as baseline for the per - thread formulation ( using the same train - dev - test splits ) and implemented an svm baseline for the grouped formulation ( not directly comparable to performance reported by  #TAUTHOR_TAG ).', 'for each of our neural net models, we trained for 30 - 70 epochs until the performance on the development set stopped improving, in order to avoid overfitting.', 'we used hyperas to tune hyperparameters on our development dataset for the same set of parameter options for each task formulation, varying activation functions, hidden layer size, batch size, dropout, number of filters, and number of words to include per email.', '']",5
['on neural constituency parsing  #TAUTHOR_TAG has found multiple'],['on neural constituency parsing  #TAUTHOR_TAG has found multiple'],['work on neural constituency parsing  #TAUTHOR_TAG has found multiple cases where generative scoring models for which inference is'],"['work on neural constituency parsing  #TAUTHOR_TAG has found multiple cases where generative scoring models for which inference is complex outperform base models for which inference is simpler.', '']",0
"['rd  #TAUTHOR_TAG.', '']","['rd  #TAUTHOR_TAG.', '']","['rd  #TAUTHOR_TAG.', 'the standard beam search procedure,']","['work on discriminative neural constituency parsers has shown the effectiveness of beam search with a small beam  #AUTHOR_TAG or even greedy search, as in the case of rd  #TAUTHOR_TAG.', 'the standard beam search procedure, which we refer to as action - synchronous, maintains a beam of k partially - completed parses that all have the same number of actions taken.', 'at each stage, a pool of successors is constructed by extending each candidate in the beam with each of its possible next actions.', 'the k highest - probability successors are chosen as the next beam.', 'unfortunately, we find that action - synchronous beam search breaks down for both generative models we explore in this work, failing to find parses that are high scoring under the model.', 'this stems from the probabilities of the actions nt ( x ) for all labels x almost always being greater than the probability of gen ( w ) for the particular word w which must be produced next in a given sentence.', 'qualitatively, the search procedure prefers to open constituents repeatedly up until the maximum number allowed by the model.', 'while these long chains of non - terminals will usually have lower probability than the correct sequence at the point where they finally generate the next word, they often have higher probability up until the word is generated, and so they tend to push the correct sequence off the beam before this point is reached.', 'this search failure produces very low evaluation performance : with a beam of size k = 100, action - synchronous beam search achieves 29. 1 f1 for rg and 27. 4 f1 for lm on the development set']",0
['on neural constituency parsing  #TAUTHOR_TAG has found multiple'],['on neural constituency parsing  #TAUTHOR_TAG has found multiple'],['work on neural constituency parsing  #TAUTHOR_TAG has found multiple cases where generative scoring models for which inference is'],"['work on neural constituency parsing  #TAUTHOR_TAG has found multiple cases where generative scoring models for which inference is complex outperform base models for which inference is simpler.', '']",5

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import cuda\n",
    "import sys\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LMTokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "LMModel = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATASET = 'acl_arc'\n",
    "TYPE = 'd_nc'\n",
    "CONTEXT = 'token_scibert_total'\n",
    "\n",
    "if TYPE == 'fc':\n",
    "    train_dataset = pd.read_csv(f'/raid/deallab/CCE_Data/model_evaluation/classification_task/data/{DATASET}/{TYPE}/{CONTEXT}/train.csv', sep=',')\n",
    "    testing_dataset = pd.read_csv(f'/raid/deallab/CCE_Data/model_evaluation/classification_task/data/{DATASET}/{TYPE}/{CONTEXT}/test.csv', sep=',')\n",
    "elif TYPE in ['d_nc', 'd_c']:\n",
    "    train_dataset = pd.read_csv(f'/raid/deallab/CCE_Data/model_evaluation/classification_task/data/{DATASET}/finecite/{TYPE}/{CONTEXT}/train.csv', sep=',')\n",
    "    testing_dataset = pd.read_csv(f'/raid/deallab/CCE_Data/model_evaluation/classification_task/data/{DATASET}/finecite/{TYPE}/{CONTEXT}/test.csv', sep=',')\n",
    "\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 5e-6\n",
    "drop_out = 0.4\n",
    "EPOCHS = 20\n",
    "tokenizer = LMTokenizer\n",
    "CLS_COUNT = 8 if sys.argv[1] == 'multicite' else 6\n",
    "\n",
    "output_file_name = f'results/{DATASET}/{TYPE}_{CONTEXT}_{TRAIN_BATCH_SIZE}_{LEARNING_RATE}_{drop_out}'\n",
    "os.makedirs(output_file_name,exist_ok=True)\n",
    "file = open(f'{output_file_name}.txt','w')\n",
    "\n",
    "def set_seed(seed_value=99):\n",
    "    # Set seed for reproducibility.\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:35<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 29.53714981729598\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:38<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Macro: 0.0842725646287225   Validation Micro: 0.11347517730496454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'results/acl_arc/d_nc_token_scibert_total_8_5e-06_0.4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 219\u001b[0m\n\u001b[1;32m    217\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    218\u001b[0m     file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 219\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    Accuracy in Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_acc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_acc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    Macro F1 in Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_ma_f1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_ma_f1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    Micro F1 in Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_mi_f1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_mi_f1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    222\u001b[0m file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/lasse/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'results/acl_arc/d_nc_token_scibert_total_8_5e-06_0.4'"
     ]
    }
   ],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        CC = literal_eval(self.data.CC[index])\n",
    "        CC = ' [SEP] '.join(CC)\n",
    "        CC = \" \".join(CC.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            CC,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        CC_ids = inputs['input_ids']\n",
    "        CC_mask = inputs['attention_mask']\n",
    "\n",
    "        return {       \n",
    "            'CC_ids': torch.tensor(CC_ids, dtype=torch.long),\n",
    "            'CC_mask': torch.tensor(CC_mask, dtype=torch.long),\n",
    "            \n",
    "            'targets': torch.tensor(self.data.label[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(testing_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "class LMClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LMClass, self).__init__()\n",
    "        self.l1 = torch.nn.DataParallel(LMModel)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(drop_out)\n",
    "        self.classifier = torch.nn.Linear(768, CLS_COUNT)\n",
    "\n",
    "    def forward(self, data):\n",
    "        input_ids = data['CC_ids'].to(device, dtype = torch.long)\n",
    "        attention_mask = data['CC_mask'].to(device, dtype = torch.long)\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state1 = output_1[0]\n",
    "        pooler = hidden_state1[:, 0, :]\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "\n",
    "model = LMClass()\n",
    "model.to(device)\n",
    "if DATASET == 'sdp_act':\n",
    "    weights = [0.30435841, 1.34843581, 2.91375291, 7.57575758, 1.78062678, 1.06837607] #sdp_act\n",
    "elif DATASET == 'acl_arc':\n",
    "    weights = [0.32256169, 0.92424242, 4.65254237, 4.81578947, 3.8125, 0.88263666]  # acl_arc\n",
    "elif DATASET == 'multicite':\n",
    "    weights = [0.39627130681818185, 2.27178338762215, 17.88301282051282, 1.1386734693877552, 0.9527834699453552, 0.42179467795585124, 2.15258487654321, 4.603547854785479]\n",
    "else: \n",
    "    sys.exit('unknown dataset')\n",
    "    \n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW(optimizer_parameters, lr=LEARNING_RATE, eps=1e-8)\n",
    "\n",
    "num_training_steps = len(training_loader) * EPOCHS\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#             optimizer,\n",
    "#             num_warmup_steps=num_training_steps * 0.1,\n",
    "#             num_training_steps=num_training_steps,\n",
    "#         )\n",
    "\n",
    "\n",
    "def calcuate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    pred = []\n",
    "    act = []\n",
    "    for _,data in enumerate(tqdm(training_loader), 0):\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accu(big_idx, targets)\n",
    "        pred += big_idx.tolist()\n",
    "        act += targets.tolist()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "    file.write(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}\\n')\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}\\n')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    file.write(f\"Training Loss Epoch: {epoch_loss}\\n\")\n",
    "    file.write(f\"Training Accuracy Epoch: {epoch_accu}\\n\")\n",
    "    ma_f1 = f1_score(act, pred, average='macro')\n",
    "    mi_f1 = f1_score(act, pred, average='micro')\n",
    "    file.write(f\"Train Macro F1: {ma_f1}\\n\")\n",
    "    file.write(f\"Train Micro F1: {mi_f1}\\n\")\n",
    "    file.write(\"\\n\")\n",
    "    return\n",
    "\n",
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; tr_loss = 0\n",
    "    nb_tr_steps =0\n",
    "    nb_tr_examples =0\n",
    "    pred = []\n",
    "    act = []\n",
    "    val_targets = []\n",
    "    val_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            val_targets.extend(targets.tolist())\n",
    "            outputs = model(data)\n",
    "            val_outputs.extend(outputs.argmax(-1).tolist())\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calcuate_accu(big_idx, targets)\n",
    "            pred += big_idx.tolist()\n",
    "            act += targets.tolist()\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "    \n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    file.write(f\"Validation Loss Epoch: {epoch_loss}\\n\")\n",
    "    file.write(f\"Validation Accuracy Epoch: {epoch_accu}\\n\")\n",
    "    ma_f1 = f1_score(act, pred, average='macro')\n",
    "    mi_f1 = f1_score(act, pred, average='micro')\n",
    "    file.write(f\"Validation Macro F1: {ma_f1}\\n\")\n",
    "    file.write(f\"Validation Micro F1: {mi_f1}\\n\")\n",
    "    i_f1_string = 'Class F1:'\n",
    "    for i in range(6):\n",
    "        i_target = [1 if t == i else 0 for t in val_targets]\n",
    "        i_preds = [1 if p == i else 0 for p in val_outputs]\n",
    "        i_f1 = f1_score(i_target, i_preds)\n",
    "        i_f1_string += f' {i}:{i_f1},'\n",
    "    file.write(i_f1_string + '\\n')\n",
    "    print(f'Validation Macro: {ma_f1}   Validation Micro: {mi_f1}')\n",
    "    return ma_f1, mi_f1, epoch_accu,\n",
    "\n",
    "best_ma_f1 = {\n",
    "    'epoch': 0,\n",
    "    'score': 0\n",
    "}\n",
    "best_mi_f1 = {\n",
    "    'epoch': 0,\n",
    "    'score': 0\n",
    "}\n",
    "best_acc = {\n",
    "    'epoch': 0,\n",
    "    'score': 0\n",
    "}\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    train(epoch)\n",
    "    ma_f1, mi_f1 ,acc = valid(model, testing_loader)\n",
    "    if ma_f1 > best_ma_f1['score']:\n",
    "        best_ma_f1['score'] = ma_f1\n",
    "        best_ma_f1['epoch'] = epoch\n",
    "    if mi_f1 > best_mi_f1['score']:\n",
    "        best_mi_f1['score'] = mi_f1\n",
    "        best_mi_f1['epoch'] = epoch\n",
    "    if acc > best_acc['score']:\n",
    "        best_acc['score'] = acc\n",
    "        best_acc['epoch'] = epoch\n",
    "\n",
    "\n",
    "    file.write(\"\\n\\n\")\n",
    "    file.close()\n",
    "    file = open(output_file_name,'a')\n",
    "\n",
    "file.write(f'Best:\\n    Accuracy in Epoch {best_acc[\"epoch\"]}: {best_acc[\"score\"]}\\n    Macro F1 in Epoch {best_ma_f1[\"epoch\"]}: {best_ma_f1[\"score\"]}\\n    Micro F1 in Epoch {best_mi_f1[\"epoch\"]}: {best_mi_f1[\"score\"]}')\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

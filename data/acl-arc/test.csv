,citing_int_id,cited_int_id,intent_labels,section_name,citance,context,citing_ss_id,citing_title,citing_year,citing_authors,cited_ss_id,cited_title,cited_year,cited_authors
1,N01-1013,J98-2002,[4],,"This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an overgeneralisation compared with those given in <TARGET_CITATION/> .","The reason is that person), which is close to (entity), and dominated by (entity), has two parents: (iif e_f orm) and (causal_agent). This DAGlike property was responsible for the overgeneralisation, and so we removed the link between / per son) and causal_agent). This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an overgeneralisation compared with those given in <TARGET_CITATION/> . This appeared to solve the problem, and the results presented later for the average degree of generalisation do not show an overgeneralisation compared with those given in <CITATION/>.This DAGlike property was responsible for the overgeneralisation, and so we removed the link between / per son) and causal_agent). The reason is that person), which is close to (entity), and dominated by (entity), has two parents: (iif e_f orm) and (causal_agent).",636a9580ca9a2554a2a388696ec12f5c3181dd52,Class-Based Probability Estimation Using a Semantic Hierarchy,2001,S. Clark; David J. Weir,d037236de0b1bc0cb5d95601b313cc90ed0b38a5,Generalizing Case Frames Using a Thesaurus and the MDL Principle,1995,Hang Li; N. Abe
5,W05-0709,External_55196,[0],,Arabic has two kinds of plurals : broken plurals and sound plurals <TARGET_CITATION/> .,"he first token  is a mention that refers to an organization, whereas the second token  is also a mention, but one that may refer to a person. Also, the prepositions (i.e.,  and ) not be considered a part of the mention. Arabic has two kinds of plurals : broken plurals and sound plurals <TARGET_CITATION/> . Arabic has two kinds of plurals: broken plurals and sound plurals <CITATION/>. Also, the prepositions (i.e.,  and ) not be considered a part of the mention. he first token  is a mention that refers to an organization, whereas the second token  is also a mention, but one that may refer to a person.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,bed701ff56ae91ae438fa32558765f979885a92f,Building an Arabic Stemmer for Information Retrieval,2002,Aitao Chen; F. Gey
7,J13-1008,External_2259,[0],related work,"<CITATION/> reports experiments on Arabic parsing using his MaltParser <TARGET_CITATION/> , trained on the PADT .","As for work on Arabic (MSA), results have been reported on the PATB <CITATION/>, the Prague Dependency Treebank (PADT) <CITATION/> and the CATiB <CITATION/>. <CITATION/> analyzed the PATB for annotation consistency, and introduced an enhanced splitstate constituency grammar, including labels for short idafa constructions and verbal or equational clauses. <CITATION/> reports experiments on Arabic parsing using his MaltParser <TARGET_CITATION/> , trained on the PADT . <CITATION/> reports experiments on Arabic parsing using his MaltParser <CITATION/>, trained on the PADT. <CITATION/> analyzed the PATB for annotation consistency, and introduced an enhanced splitstate constituency grammar, including labels for short idafa constructions and verbal or equational clauses. As for work on Arabic (MSA), results have been reported on the PATB <CITATION/>, the Prague Dependency Treebank (PADT) <CITATION/> and the CATiB <CITATION/>.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,,atanas chanev gulsen eryigit sandra kubler svetoslav marinov and erwin marsi,2007,Joakim Nivre; Johan Hall; Jens Nilsson
11,J07-1005,External_2736,[2],,"Our knowledge extractors rely extensively on MetaMap <TARGET_CITATION/> , a system for identifying segments of text that correspond to concepts in the UMLS Metathesaurus .","For an example of a completely annotated abstract, see Figure 2. Each individual PICO extractor takes as input the abstract text of a MEDLINE citation and identifies the relevant elements: Outcomes are complete sentences, while population, problems, and interventions are short noun phrases. Our knowledge extractors rely extensively on MetaMap <TARGET_CITATION/> , a system for identifying segments of text that correspond to concepts in the UMLS Metathesaurus . Our knowledge extractors rely extensively on MetaMap <CITATION/>, a system for identifying segments of text that correspond to concepts in the UMLS Metathesaurus. Each individual PICO extractor takes as input the abstract text of a MEDLINE citation and identifies the relevant elements: Outcomes are complete sentences, while population, problems, and interventions are short noun phrases. For an example of a completely annotated abstract, see Figure 2.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,1406f6b5ed4034b72ed2dccc3fcfa4c5c0810924,Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program,2001,A. Aronson
17,J13-1008,H05-1100,[0],related work,"Similarly , <TARGET_CITATION/> report that the use of a subset of Spanish morphological features ( number for adjectives , determiners , nouns , pronouns , and verbs ; and mode for verbs ) outperforms other combinations .","The results for Czech are the opposite of our results for Arabic, as we will see. This may be due to CASE tagging having a lower error rate in Czech (5.0%) <CITATION/> compared with Arabic (14.0%, see Table 3). Similarly , <TARGET_CITATION/> report that the use of a subset of Spanish morphological features ( number for adjectives , determiners , nouns , pronouns , and verbs ; and mode for verbs ) outperforms other combinations . <CITATION/> report that the use of a subset of Spanish morphological features (number for adjectives, determiners, nouns, pronouns, and verbs; and mode for verbs) outperforms other combinations. This may be due to CASE tagging having a lower error rate in Czech (5.0%) <CITATION/> compared with Arabic (14.0%, see Table 3). The results for Czech are the opposite of our results for Arabic, as we will see.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,f27fac3c6ba73de99b6c60cf204e67999a29c76e,Morphology and Reranking for the Statistical Parsing of Spanish,2005,Brooke Cowan; M. Collins
25,J10-3007,External_527,[2],,"results are based on a corpus of movie subtitles <CITATION/> , and are consequently shorter sentences , whereas the En  Es results are based on a corpus of parliamentary proceedings <TARGET_CITATION/> .","Vertical axis: percentage of transferred edges that are correct. Horizontal axis: average number of transferred edges per sentence. results are based on a corpus of movie subtitles <CITATION/> , and are consequently shorter sentences , whereas the En  Es results are based on a corpus of parliamentary proceedings <TARGET_CITATION/> . results are based on a corpus of movie subtitles <CITATION/>, and are consequently shorter sentences, whereas the EnEs results are based on a corpus of parliamentary proceedings <CITATION/>. Horizontal axis: average number of transferred edges per sentence. Vertical axis: percentage of transferred edges that are correct.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,694b3c58712deefb59502847ba1b52b192c413e5,Europarl: A Parallel Corpus for Statistical Machine Translation,2005,Philipp Koehn
27,J91-2003,External_4948,[4],introduction,"This Principle of Finitism is also assumed by <TARGET_CITATION/> , and implicitly or explicitly by almost all researchers in computational linguistics .","Therefore these notions, and all other constructs we are going to define (axioms, metarules, definitions etc.) are computational, although usually we will not provide explicit algorithms for computing them. The issues of control are not so important for us at this point; we restrict ourselves to describing the logic. This Principle of Finitism is also assumed by <TARGET_CITATION/> , and implicitly or explicitly by almost all researchers in computational linguistics . This Principle of Finitism is also assumed by <CITATION/>, and implicitly or explicitly by almost all researchers in computational linguistics. The issues of control are not so important for us at this point; we restrict ourselves to describing the logic. Therefore these notions, and all other constructs we are going to define (axioms, metarules, definitions etc.) are computational, although usually we will not provide explicit algorithms for computing them.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,a theory of truth and semantic representationquot,1981,H Kamp
30,J07-1005,External_17760,[0],introduction,The PICO framework <TARGET_CITATION/> for capturing wellformulated clinical queries ( described in Section 2 ) can serve as the basis of a knowledge representation that bridges the needs of clinicians and analytical capabilities of a system .,"The Semantic Network provides a consistent categorization of all concepts represented in the UMLS Metathesaurus. Third, the paradigm of evidencebased medicine <CITATION/> provides a taskbased model of the clinical informationseeking process. The PICO framework <TARGET_CITATION/> for capturing wellformulated clinical queries ( described in Section 2 ) can serve as the basis of a knowledge representation that bridges the needs of clinicians and analytical capabilities of a system . The PICO framework <CITATION/> for capturing wellformulated clinical queries (described in Section 2) can serve as the basis of a knowledge representation that bridges the needs of clinicians and analytical capabilities of a system. Third, the paradigm of evidencebased medicine <CITATION/> provides a taskbased model of the clinical informationseeking process. The Semantic Network provides a consistent categorization of all concepts represented in the UMLS Metathesaurus.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,,the wellbuilt clinical question a key to evidencebased decisions,1995,W Scott Richardson; Mark C Wilson; James Nishikawa; Robert S Hayward
52,A00-2004,External_30123,[4],,"This confirms that although Kozima 's approach <TARGET_CITATION/> is computationally expensive , it does produce more precise segmentation .","The cosine coefficient (R98(s,0) and dot density measure (R98(m,doo ) yield similar results. Our spread activation based semantic measure (R98(,sa)) improved accuracy. This confirms that although Kozima 's approach <TARGET_CITATION/> is computationally expensive , it does produce more precise segmentation . This confirms that although Kozima's approach <CITATION/> is computationally expensive, it does produce more precise segmentation. Our spread activation based semantic measure (R98(,sa)) improved accuracy. The cosine coefficient (R98(s,0) and dot density measure (R98(m,doo ) yield similar results.",448aa9b04905e421a8ef6e864c183f7ca6a7bb45,Advances in domain independent linear text segmentation,2000,Freddy Y. Y. Choi,6fc74be27e660130014129c03d5961f974499fcb,Text Segmentation Based on Similarity between Words,1993,H. Kozima
56,J07-1005,External_20682,[3],,"This section , which elaborates on preliminary results reported in <TARGET_CITATION/> , describes extraction algorithms for population , problems , interventions , outcomes , and the strength of evidence .","The automatic extraction of PICO elements from MEDLINE citations represents a key capability integral to clinical question answering. This section , which elaborates on preliminary results reported in <TARGET_CITATION/> , describes extraction algorithms for population , problems , interventions , outcomes , and the strength of evidence . This section, which elaborates on preliminary results reported in <CITATION/>, describes extraction algorithms for population, problems, interventions, outcomes, and the strength of evidence. The automatic extraction of PICO elements from MEDLINE citations represents a key capability integral to clinical question answering.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,58e3df962aeea5ece0857ab6e37870857a54ee07,Knowledge Extraction for Clinical Question Answering: Preliminary Results,2005,Dina Demner-Fushman; Jimmy J. Lin
57,J91-2003,External_76184,[4],introduction,It would seem therefore that the iteration of the PT operation to form a closure is needed ( cfXXX <TARGET_CITATION/> ) .,The partial theories pick up from the referential level the most obvious or the most important information about a formula. This immediate information may be insufficient to decide the truth of certain predicates. It would seem therefore that the iteration of the PT operation to form a closure is needed ( cfXXX <TARGET_CITATION/> ) . It would seem therefore that the iteration of the PT operation to form a closure is needed (cfXXX Zadrozny 1987b).This immediate information may be insufficient to decide the truth of certain predicates. The partial theories pick up from the referential level the most obvious or the most important information about a formula.,c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,intended models circumscription and commonsense reasoningquot,1987,W Zadrozny
62,E99-1022,C94-2204,[0],, See <TARGET_CITATION/> for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG .,2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in <CITATION/>. Typed feature structures as normal form TFC terms are merely syntactic objects. See <TARGET_CITATION/> for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG . See <CITATION/> for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG.Typed feature structures as normal form TFC terms are merely syntactic objects. 2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in <CITATION/>.,3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,bcb603de7948e47f3e5876a300e7390dfa81dbe5,Typed Feature Structures as Descriptions,1994,P. J. King
72,N01-1003,External_32728,[0],,"The representations used by <CITATION/> , or <TARGET_CITATION/> are similar , but do not ( always ) explicitly represent the clause combining operations as labeled nodes .","The SPG is designed in such a way that if a DSyntS is associated with the root node, it is a valid structure which can be realized.3The sptree is inspired by <CITATION/>. The representations used by <CITATION/> , or <TARGET_CITATION/> are similar , but do not ( always ) explicitly represent the clause combining operations as labeled nodes . The representations used by <CITATION/>, or <CITATION/> are similar, but do not (always) explicitly represent the clause combining operations as labeled nodes.3The sptree is inspired by <CITATION/>. The SPG is designed in such a way that if a DSyntS is associated with the root node, it is a valid structure which can be realized.",ee6892b9c7f1a491e0925b913b66281c48408f74,SPoT: A Trainable Sentence Planner,2001,M. Walker; Owen Rambow; Monica Rogati,3373e740290e0e0287a74729161ea6b97cb47482,Sentence Planning as Description Using Tree Adjoining Grammar,1997,Matthew Stone; Christine Doran
73,W01-0706,External_2081,[3],experiments,"Since earlier versions of the SNoW based CSCL were used only to identify single phrases <TARGET_CITATION/> and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL2000 ( Tjong Kim <CITATION/> ) to compare it to other shallow parsers .","Indeed, in CSCL (constraint satisfaction with classifiers), SNoW is used to learn several different classifiers  each detects the beginning or end of a phrase of some type (noun phrase, verb phrase, etc.). The outcomes of these classifiers are then combined in a way that satisfies some constraints  nonoverlapping constraints in this case  using an efficient constraint satisfaction mechanism that makes use of the confidence in the classifier's outcomes. Since earlier versions of the SNoW based CSCL were used only to identify single phrases <TARGET_CITATION/> and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL2000 ( Tjong Kim <CITATION/> ) to compare it to other shallow parsers . Since earlier versions of the SNoW based CSCL were used only to identify single phrases <CITATION/> and never to identify a collection of several phrases at the same time, as we do here, we also trained and tested it under the exact conditions of CoNLL2000 (Tjong Kim <CITATION/>) to compare it to other shallow parsers. The outcomes of these classifiers are then combined in a way that satisfies some constraints  nonoverlapping constraints in this case  using an efficient constraint satisfaction mechanism that makes use of the confidence in the classifier's outcomes. Indeed, in CSCL (constraint satisfaction with classifiers), SNoW is used to learn several different classifiers  each detects the beginning or end of a phrase of some type (noun phrase, verb phrase, etc.).",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,3fab92869cfab684b3ffb1c16a771e9c3b774acd,The Use of Classifiers in Sequential Inference,2001,Vasin Punyakanok; D. Roth
75,J07-1005,W04-0508,[0],related work,"The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers <TARGET_CITATION/> , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .","Although the system incorporates both a user and a task model, it does not explicitly capture the principles of evidencebased medicine. Patient information is no doubt important to answering clinical questions, and our work could certainly benefit from experiences gained in the PERSIVAL project. The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers <TARGET_CITATION/> , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 . The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers <CITATION/>, and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005. Patient information is no doubt important to answering clinical questions, and our work could certainly benefit from experiences gained in the PERSIVAL project. Although the system incorporates both a user and a task model, it does not explicitly capture the principles of evidencebased medicine.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,61c17def362aa782001df9d5e3b74a8d73aa772c,Answering Questions in the Genomics Domain,2004,Fabio Rinaldi; James Dowdall; Gerold Schneider; Andreas Persidis
81,W05-0709,External_87913,[2],experiments,"As stated before , the experiments are run in the ACE '04 framework <TARGET_CITATION/> where the system will identify mentions and will label them ( cfXXX Section 4 ) with a type ( person , organization , etc ) , a subtype ( OrgCommercial , OrgGovernmental , etc ) , a mention level ( named , nominal , etc ) , and a class ( specific , generic , etc ) .","We want to investigate the usefulness of stem ngram features in the mention detection system. As stated before , the experiments are run in the ACE '04 framework <TARGET_CITATION/> where the system will identify mentions and will label them ( cfXXX Section 4 ) with a type ( person , organization , etc ) , a subtype ( OrgCommercial , OrgGovernmental , etc ) , a mention level ( named , nominal , etc ) , and a class ( specific , generic , etc ) . As stated before, the experiments are run in the ACE'04 framework (NIST, 2004) where the system will identify mentions and will label them (cfXXX Section 4) with a type (person, organization, etc), a subtype (OrgCommercial, OrgGovernmental, etc), a mention level (named, nominal, etc), and a class (specific, generic, etc). We want to investigate the usefulness of stem ngram features in the mention detection system.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,,proceedings of ace evaluation and pi meeting,2004,NIST
88,N01-1013,External_6119,[4],experiments,"The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by <TARGET_CITATION/> that the G2 statistic is better suited for use in corpusbased NLP .","Thefigures in brackets give the average number of generalised levels. The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by <TARGET_CITATION/> that the G2 statistic is better suited for use in corpusbased NLP . The X2 statistic is performing at least as well as G2, throwing doubt on the claim by <CITATION/> that the G2 statistic is better suited for use in corpusbased NLP. figures in brackets give the average number of generalised levels. The",636a9580ca9a2554a2a388696ec12f5c3181dd52,Class-Based Probability Estimation Using a Semantic Hierarchy,2001,S. Clark; David J. Weir,025464b73f805e76689a7a20a48a9e9c0f4ff3ef,Accurate Methods for the Statistics of Surprise and Coincidence,1993,T. Dunning
94,J13-1008,External_4464,[0],experiments,7 We ignore the rare  false idafa '' construction <TARGET_CITATION/> .,"Traditional Arabic grammars often describe a very general threeway distinction into verbs, nominals, and particles. In comparison, the tag set of the Buckwalter Morphological Analyzer <CITATION/> used in the PATB has a core POS set of 44 tags (CORE44) before morphological extension.8 Crosslinguistically, a core set containing around 12 tags is often 7 We ignore the rare  false idafa '' construction <TARGET_CITATION/> . 7 We ignore the rare false idafa'' construction <CITATION/>. In comparison, the tag set of the Buckwalter Morphological Analyzer <CITATION/> used in the PATB has a core POS set of 44 tags (CORE44) before morphological extension.8 Crosslinguistically, a core set containing around 12 tags is oftenTraditional Arabic grammars often describe a very general threeway distinction into verbs, nominals, and particles.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,2a733deaa7c55e427337860c7643e6b5f8b750fc,Book Reviews: Introduction to Arabic Natural Language Processing by Nizar Y. Habash,2010,Nizar Habash
100,D15-1148,P14-2047,[4],related work,Our approach to the problem is more compatible with the empirical evidence we presented in our prior work <TARGET_CITATION/> where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality .,"Similar to work in text simplification, the simplification rules are applied to all sentences meeting certain criteria, normally to all sentences longer than a predefined threshold or where certain conjunctions or coordinations are present. In contrast, the model we propose here can be used to predict when segmentation is at all necessary. Our approach to the problem is more compatible with the empirical evidence we presented in our prior work <TARGET_CITATION/> where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality . Our approach to the problem is more compatible with the empirical evidence we presented in our prior work <CITATION/> where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality. In contrast, the model we propose here can be used to predict when segmentation is at all necessary. Similar to work in text simplification, the simplification rules are applied to all sentences meeting certain criteria, normally to all sentences longer than a predefined threshold or where certain conjunctions or coordinations are present.",3a3487d2178d4426f611ca37b99ab95bf5bc670f,Detecting Content-Heavy Sentences: A Cross-Language Case Study,2015,Junyi Jessy Li; A. Nenkova,bd5ead1047bd7389f418af247f697c65c3cc5cd6,Assessing the Discourse Factors that Influence the Quality of Machine Translation,2014,Junyi Jessy Li; Marine Carpuat; A. Nenkova
101,J13-1008,External_1998,[2],related work,"For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 <TARGET_CITATION/> , a transitionbased parser with an input buffer and a stack , which uses SVM classifiers","For all experiments, unless specified otherwise, we used the dev set.10 We kept the test unseen (blind'') during training and model development. Statistics about this split (after conversion to the CATiB dependency format) are given in Table 1. For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 <TARGET_CITATION/> , a transitionbased parser with an input buffer and a stack , which uses SVM classifiers For all experiments reported in this section we used the syntactic dependency parser MaltParser v1.3 (Nivre 2003, 2008; Kbler, McDonald, and Nivre 2009), a transitionbased parser with an input buffer and a stack, which uses SVM classifiersStatistics about this split (after conversion to the CATiB dependency format) are given in Table 1. For all experiments, unless specified otherwise, we used the dev set.10 We kept the test unseen (blind'') during training and model development.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,,an efficient algorithm for projective dependency parsing,2003,Joakim Nivre
116,J10-3007,N01-1026,[1],introduction,"But their importance has grown far beyond machine translation : for instance , transferring annotations between languages <TARGET_CITATION/> ; discovery of paraphrases <CITATION/> ; and joint unsupervised POS and parser induction across languages <CITATION/> .","Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as forMT system combination <CITATION/>. But their importance has grown far beyond machine translation : for instance , transferring annotations between languages <TARGET_CITATION/> ; discovery of paraphrases <CITATION/> ; and joint unsupervised POS and parser induction across languages <CITATION/> . But their importance has grown far beyond machine translation: for instance, transferring annotations between languages <CITATION/>; discovery of paraphrases <CITATION/>; and joint unsupervised POS and parser induction across languages <CITATION/>. MT system combination <CITATION/>. Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as for",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,327c88dd06722a967be9c6b1176fbd79554967e7,Inducing Multilingual POS Taggers and NP Bracketers via Robust Projection Across Aligned Corpora,2001,David Yarowsky; G. Ngai
122,W01-0706,External_29000,[0],introduction,"Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) .","to ] [NP only $ 1.8 billion ] [PP in ] [NP September] . While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) . Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,5db4b1405a1e77311a4a78414fe7eedc7712c4ed,Cascaded Grammatical Relation Assignment,1999,S. Buchholz; Jorn Veenstra; Walter Daelemans
125,W05-0709,P04-1018,[4],introduction,Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in <CITATION/> and the coreference resolution system is similar to the one described in <TARGET_CITATION/> .,"derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <CITATION/>. Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in <CITATION/> and the coreference resolution system is similar to the one described in <TARGET_CITATION/> . Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in <CITATION/> and the coreference resolution system is similar to the one described in <CITATION/>. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <CITATION/>. derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,4f8dd94c1a1454cc34475a4f533e137c7e4afd8d,A Mention-Synchronous Coreference Resolution Algorithm Based On the Bell Tree,2004,Xiaoqiang Luo; Abraham Ittycheriah; Hongyan Jing; N. Kambhatla; S. Roukos
127,J91-2003,External_34286,[4],introduction,"Although there are other discussions of the paragraph as a central element of discourse <TARGET_CITATION/> , all of them share a certain limitation in their formal techniques for analyzing paragraph structure ."," Although there are other discussions of the paragraph as a central element of discourse <TARGET_CITATION/> , all of them share a certain limitation in their formal techniques for analyzing paragraph structure . Although there are other discussions of the paragraph as a central element of discourse <CITATION/>, all of them share a certain limitation in their formal techniques for analyzing paragraph structure.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,the flow of thought and the flow of languagequot,1979,W L Chafe
128,W01-0706,External_5861,[0],introduction,"Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <TARGET_CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <CITATION/> ; Tjong Kim <CITATION/> ) .","to ] [NP only $ 1.8 billion ] [PP in ] [NP September] . While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <TARGET_CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <CITATION/> ; Tjong Kim <CITATION/> ) . Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,54c846ee00c6132d70429cc279e8577f63ed05e4,A Linear Observed Time Statistical Parser Based on Maximum Entropy Models,1997,A. Ratnaparkhi
133,J13-1008,C10-1045,[0],related work,"As for work on Arabic ( MSA ) , results have been reported on the PATB <TARGET_CITATION/> , the Prague Dependency Treebank ( PADT ) <CITATION/> and the CATiB <CITATION/> .","We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima'an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic ( MSA ) , results have been reported on the PATB <TARGET_CITATION/> , the Prague Dependency Treebank ( PADT ) <CITATION/> and the CATiB <CITATION/> . As for work on Arabic (MSA), results have been reported on the PATB <CITATION/>, the Prague Dependency Treebank (PADT) <CITATION/> and the CATiB <CITATION/>. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima'an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. We also find that the number feature helps for Arabic.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,70c2d71a68df279d057471db5173fab0a8aa19ae,"Better Arabic Parsing: Baselines, Evaluations, and Analysis",2010,Spence Green; Christopher D. Manning
141,W01-0706,J93-2004,[2],experiments,"Training was done on the Penn Treebank <TARGET_CITATION/> Wall Street Journal data , sections 0221 ."," Training was done on the Penn Treebank <TARGET_CITATION/> Wall Street Journal data , sections 0221 . Training was done on the Penn Treebank <CITATION/> Wall Street Journal data, sections 0221.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,0b44fcbeea9415d400c5f5789d6b892b6f98daff,Building a Large Annotated Corpus of English: The Penn Treebank,1993,Mitchell P. Marcus; Beatrice Santorini; Mary Ann Marcinkiewicz
148,W05-0709,External_3692,[2],,"where mk is one mention in entity e , and the basic model building block PL ( L = 1  e , mk , m ) is an exponential or maximum entropy model <TARGET_CITATION/> .","In our implementation, the link model between a candidate entity e and the current mention m is computed as2Thus, the difference to token ngrams is that the tokens of different type are removed from the streams, before the features are created. where mk is one mention in entity e , and the basic model building block PL ( L = 1  e , mk , m ) is an exponential or maximum entropy model <TARGET_CITATION/> . where mk is one mention in entity e, and the basic model building block PL(L = 1e, mk, m) is an exponential or maximum entropy model <CITATION/>. 2Thus, the difference to token ngrams is that the tokens of different type are removed from the streams, before the features are created. In our implementation, the link model between a candidate entity e and the current mention m is computed as",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,fb486e03369a64de2d5b0df86ec0a7b55d3907db,A Maximum Entropy Approach to Natural Language Processing,1996,Adam L. Berger; S. D. Pietra; V. D. Pietra
151,J13-1008,N10-1115,[2],experiments,"In this section , we validate the contribution of key tag sets and morphological features  and combinations thereof  using a different parser : the EasyFirst Parser <TARGET_CITATION/> ."," In this section , we validate the contribution of key tag sets and morphological features  and combinations thereof  using a different parser : the EasyFirst Parser <TARGET_CITATION/> . In this section, we validate the contribution of key tag sets and morphological features and combinations thereofusing a different parser: the EasyFirst Parser <CITATION/>.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,3ce0f00d6c949192107f1bd6a167c03e1fb7393a,An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing,2010,Yoav Goldberg; Michael Elhadad
153,J91-2003,External_5163,[0],introduction,"Later , <TARGET_CITATION/> ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using  salience '' in choosing facts from this knowledge base .","But syntactic relations do not suffice to resolve anaphora: Hobbs' (1976) algorithm for resolving the reference of pronouns, depending only on the surface syntax of sentences in the text, when applied to it'' in the example paragraph, fails in both cases to identify the most likely referent NP. Adding selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the 0 knowledge necessary for reference disambiguation. Later , <TARGET_CITATION/> ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using  salience '' in choosing facts from this knowledge base . Later, Hobbs (1979, 1982) proposed a knowledge base in which information about language and the world would be encoded, and he emphasized the need for using salience'' in choosing facts from this knowledge base. Adding selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the 0 knowledge necessary for reference disambiguation. But syntactic relations do not suffice to resolve anaphora: Hobbs' (1976) algorithm for resolving the reference of pronouns, depending only on the surface syntax of sentences in the text, when applied to it'' in the example paragraph, fails in both cases to identify the most likely referent NP.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,coherence and coreferencequot,1979,J R Hobbs
156,J91-2003,External_504,[0],introduction,"Opposition ( called  adversative '' or  contrarytoexpectation '' by <TARGET_CITATION/> ; cfXXX also Quirk et al. 1972 , p. 672 ) .","However, but'' does not behave quite like the other twosemantically, but'' signals a contradiction, and in this role it seems to have three subfunctions:1. Opposition ( called  adversative '' or  contrarytoexpectation '' by <TARGET_CITATION/> ; cfXXX also Quirk et al. 1972 , p. 672 ) . Opposition (called adversative'' or contrarytoexpectation'' by Halliday and Hasan 1976; cfXXX also Quirk et al. 1972, p. 672).1. However, but'' does not behave quite like the other twosemantically, but'' signals a contradiction, and in this role it seems to have three subfunctions:",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,b4d5633b96ea5e0f9e90e03df58e8ad0f6f3dee7,Cohesion in English,1976,M. Halliday; R. Hasan
158,J13-1008,External_4979,[4],related work,"Previous work with MaltParser in Russian , Turkish , and Hindi showed gains with CASE but not with agreement features <TARGET_CITATION/> .","Our results agree with previous work on Arabic and Hebrew in that marking the definite article is helpful for parsing. We go beyond previous work, however, and explore additional lexical and inflectional features. Previous work with MaltParser in Russian , Turkish , and Hindi showed gains with CASE but not with agreement features <TARGET_CITATION/> . Previous work with MaltParser in Russian, Turkish, and Hindi showed gains with CASE but not with agreement features <CITATION/>. We go beyond previous work, however, and explore additional lexical and inflectional features. Our results agree with previous work on Arabic and Hebrew in that marking the definite article is helpful for parsing.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,60dad30438b1543c20ab67cf02107b4ed7250dc1,Parsing Indian Languages with MaltParser,2009,Joakim Nivre
165,J10-3007,P06-1072,[0],related work,"For the task of unsupervised dependency parsing , <TARGET_CITATION/> add a constraint of the form  the average length of dependencies should be X '' to capture the locality of syntax ( at least half of the dependencies are between adjacent words ) , using a scheme they call structural annealing .","Without any restrictions, likelihood prefers to always use longer phrases and the authors try to control this behavior by multiplying every transition probability by a constant ri > 1. This encourages more transitions and hence shorter phrases. For the task of unsupervised dependency parsing , <TARGET_CITATION/> add a constraint of the form  the average length of dependencies should be X '' to capture the locality of syntax ( at least half of the dependencies are between adjacent words ) , using a scheme they call structural annealing . For the task of unsupervised dependency parsing, <CITATION/> add a constraint of the form the average length of dependencies should be X'' to capture the locality of syntax (at least half of the dependencies are between adjacent words), using a scheme they call structural annealing. This encourages more transitions and hence shorter phrases. Without any restrictions, likelihood prefers to always use longer phrases and the authors try to control this behavior by multiplying every transition probability by a constant ri > 1.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,20a05c9397e048a0ebc66379a78085e8050f54d1,Annealing Structural Bias in Multilingual Weighted Grammar Induction,2006,Noah A. Smith; Jason Eisner
191,J91-2003,External_76216,[0],introduction,"Since sentences can refer to events described by other sentences , we may need also a quotation operator ; <TARGET_CITATION/> describes how first order logic can be augmented with such an operator .","So it is not necessary now to present a formal semantics here. The reader may consult recent papers on this subject <CITATION/> to see what a formal interpretation of events in time might look like. Since sentences can refer to events described by other sentences , we may need also a quotation operator ; <TARGET_CITATION/> describes how first order logic can be augmented with such an operator . Since sentences can refer to events described by other sentences, we may need also a quotation operator; <CITATION/> describes how first order logic can be augmented with such an operator. The reader may consult recent papers on this subject <CITATION/> to see what a formal interpretation of events in time might look like. So it is not necessary now to present a formal semantics here.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,languages with self reference i foundationsquot,1985,D Perlis
193,W11-0218,W03-1306,[5],conclusion,A possible future direction would be to compare the query string to retrieved results using a method similar to that of <TARGET_CITATION/> .,proving our initial hypothesis we argue that our results calls for further study due to several concerns raised by the results remaining unanswered. It may be that our notion of distance to lexical resource entries is too naive. A possible future direction would be to compare the query string to retrieved results using a method similar to that of <TARGET_CITATION/> . A possible future direction would be to compare the query string to retrieved results using a method similar to that of <CITATION/>. It may be that our notion of distance to lexical resource entries is too naive. proving our initial hypothesis we argue that our results calls for further study due to several concerns raised by the results remaining unanswered.,19aea4f778920549a151af278fcd0ace5e88a707,SimSem: Fast Approximate String Matching in Relation to Semantic Category Disambiguation,2011,Pontus Stenetorp; S. Pyysalo; Junichi Tsujii,d48f6efea9ad4b606c389b79f9e4a864fd589cdc,Boosting Precision and Recall of Dictionary-Based Protein Name Recognition,2003,Yoshimasa Tsuruoka; Junichi Tsujii
196,J91-2003,External_1853,[0],introduction,"The necessity of this kind of merging of arguments has been recognized before : <CITATION/> call it abductive unification/matching , <TARGET_CITATION/> ) refers to such operations using the terms knitting or petty conversational implicature .","This relation would hold, for instance, between the object theory of our example paragraph and a formula expressing the equality of two constants, i and i', denoting (respectively) the infection'' in the sentence Within twentyfour hours of infection..., and the infection'' of the theory (d1)a disease is an illness caused by an infection. This equality i = i' cannot be proven, but it may be reasonably assumedwe know that in this case the infection i' caused the illness, which, in turn, caused the death. The necessity of this kind of merging of arguments has been recognized before : <CITATION/> call it abductive unification/matching , <TARGET_CITATION/> ) refers to such operations using the terms knitting or petty conversational implicature . The necessity of this kind of merging of arguments has been recognized before: <CITATION/> call it abductive unification/matching, Hobbs (1978, 1979) refers to such operations using the terms knitting or petty conversational implicature. This equality i = i' cannot be proven, but it may be reasonably assumedwe know that in this case the infection i' caused the illness, which, in turn, caused the death. This relation would hold, for instance, between the object theory of our example paragraph and a formula expressing the equality of two constants, i and i', denoting (respectively) the infection'' in the sentence Within twentyfour hours of infection..., and the infection'' of the theory (d1)a disease is an illness caused by an infection.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,61c0eaf156647ffad23921a65e3d7b3296f7afd5,Resolving pronoun references,1986,Jerry R. Hobbs
199,J91-2003,External_34288,[0],introduction,Other psycholinguistic studies that confirm the validity of paragraph units can be found in <TARGET_CITATION/> et al. ( 1980 ) .,"These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit. Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentencecount information. Other psycholinguistic studies that confirm the validity of paragraph units can be found in <TARGET_CITATION/> . Other psycholinguistic studies that confirm the validity of paragraph units can be found in <CITATION/>. Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentencecount information. These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,episodes as chunks in narrative memoryquot,1979,J B Black; G H Bower
205,J07-1005,External_57139,[5],,"Note that although our current system uses MeSH headings assigned by human indexers , manually assigned terms can be replaced with automatic processing if needed <TARGET_CITATION/> .","The task score, Stask, is given by:The function (t) maps a MeSH term to a positive score if the term is a positive indicator for that particular task type, or a negative score if the term is a negative indicator for the clinical task. Note that although our current system uses MeSH headings assigned by human indexers , manually assigned terms can be replaced with automatic processing if needed <TARGET_CITATION/> . Note that although our current system uses MeSH headings assigned by human indexers, manually assigned terms can be replaced with automatic processing if needed <CITATION/>. The function (t) maps a MeSH term to a positive score if the term is a positive indicator for that particular task type, or a negative score if the term is a negative indicator for the clinical task. The task score, Stask, is given by:",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,47ac91cef4607aa5dad7afa2727e97a89428114a,The NLM Indexing Initiative's Medical Text Indexer,2004,A. Aronson; James G. Mork; Clifford W. Gay; Susanne M. Humphrey; Willie J. Rogers
207,J12-4003,P10-1160,[3],conclusion,"Previously <TARGET_CITATION/> , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests ."," Previously <TARGET_CITATION/> , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests . Previously <CITATION/>, we assessed the importance of various implicit argument feature groups by conducting feature ablation tests.",acbac8a75b25384bcc10953b2becc8278b9240c9,Semantic Role Labeling of Implicit Arguments for Nominal Predicates,2012,Matthew Gerber; J. Chai,d8259bcbe9cb0cf5bad6ea25645f4407fc544a1c,Beyond NomBank: A Study of Implicit Arguments for Nominal Predicates,2010,Matthew Gerber; J. Chai
209,J91-2003,External_15145,[1],introduction,"For instance , <TARGET_CITATION/> ) says that the sentence  Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question  What is Kissinger 's favorite fruit ? ''","It is the smallest linguistic representation of what, in logic, is called a model,'' and it is the first reasonable domain of anaphora resolution, and of coherent thought about a central topic. A paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicateargument) structure can be definitely assigned to sentences/strings. For instance , <TARGET_CITATION/> ) says that the sentence  Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question  What is Kissinger 's favorite fruit ? '' For instance, <CITATION/> says that the sentence Reagan thinks bananas,'' which is otherwise strange, is in fact acceptable if it occurs as an answer to the question What is Kissinger's favorite fruit?'' A paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicateargument) structure can be definitely assigned to sentences/strings. It is the smallest linguistic representation of what, in logic, is called a model,'' and it is the first reasonable domain of anaphora resolution, and of coherent thought about a central topic.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,lectures on contemporary syntactic theories csli lecture notes,1985,P Sells
215,J00-3001,External_244,[0],conclusion,"While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure <TARGET_CITATION/> :","Note that this technique is optimal for the extraction of the lowestfrequency words, leading to identical performance for G2 and Fisher's exact test for these words. For the higherfrequency words, Fisher's exact test leads to a slightly better recall with the same precision scores (0.31 for both tests). While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure <TARGET_CITATION/> : While we have observed reasonable results with both G2 and Fisher's exact test, we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information (MI) measure <CITATION/>:For the higherfrequency words, Fisher's exact test leads to a slightly better recall with the same precision scores (0.31 for both tests). Note that this technique is optimal for the extraction of the lowestfrequency words, leading to identical performance for G2 and Fisher's exact test for these words.",886dffd5b9d41c77365fb3893dd05f2067862d13,Extracting the lowest-frequency words: pitfalls and possibilities,2000,M. Weeber; R. Vos; R. Baayen,9e2caa39ac534744a180972a30a320ad0ae41ea3,"Word Association Norms, Mutual Information, and Lexicography",1989,Kenneth Ward Church; Patrick Hanks
230,N01-1009,External_1172,[0],introduction,<TARGET_CITATION/> avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify .,"An easy problem is usually a problem that is easy to solve, whereas a difficult language is a language that is difficult to learn, speak, or write. Adjectives like good allow either verbsubject or verbobject interpretations: a good cook is a cook who cooks well whereas good soup is soup that tastes good or soup that is good to eat. <TARGET_CITATION/> avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify . <CITATION/> avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify. Adjectives like good allow either verbsubject or verbobject interpretations: a good cook is a cook who cooks well whereas good soup is soup that tastes good or soup that is good to eat. An easy problem is usually a problem that is easy to solve, whereas a difficult language is a language that is difficult to learn, speak, or write.",3d4226a01208653d3598685cfa571390e193791d,A Corpus-based Account of Regular Polysemy: The Case of Context-sensitive Adjectives,2001,Maria Lapata,259d0304adcb49e40436137684b78a80c9ef097b,The Generative Lexicon,1991,J. Pustejovsky
231,J13-1008,N12-1032,[0],related work,<TARGET_CITATION/> have conducted a study on dependency parsing for 21 languages using features that encode whether the values for certain attributes are equal or not for a node and its governor .,"Our work is the first to show gains using agreement in MaltParser and in Arabic dependency parsing, and the first to use functional features for this task. Furthermore, we demonstrate that our results carry over successfully to another parser, the EasyFirst Parser <CITATION/> (Section 6). <TARGET_CITATION/> have conducted a study on dependency parsing for 21 languages using features that encode whether the values for certain attributes are equal or not for a node and its governor . <CITATION/> have conducted a study on dependency parsing for 21 languages using features that encode whether the values for certain attributes are equal or not for a node and its governor. Furthermore, we demonstrate that our results carry over successfully to another parser, the EasyFirst Parser <CITATION/> (Section 6). Our work is the first to show gains using agreement in MaltParser and in Arabic dependency parsing, and the first to use functional features for this task.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,50c0d8b36fc516b4fc04aa636a62a9f2aee2240e,Getting More from Morphology in Multilingual Dependency Parsing,2012,Matthew Hohensee; Emily M. Bender
248,J10-3007,N04-1035,[0],introduction,"Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ <TARGET_CITATION/> ; Chiang et al. 2005 ] ) as well as for","The seminal work of <CITATION/> introduced a series of probabilistic models (IBM Models 15) for statistical machine translation and the concept of wordbyword'' alignment, the correspondence between words in source and target languages. Although no longer competitive as endtoend translation models, the IBM Models, as well as the hidden Markov model (HMM) of <CITATION/>, are still widely used for word alignment. Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ <TARGET_CITATION/> ; Chiang et al. 2005 ] ) as well as for Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as forAlthough no longer competitive as endtoend translation models, the IBM Models, as well as the hidden Markov model (HMM) of <CITATION/>, are still widely used for word alignment. The seminal work of <CITATION/> introduced a series of probabilistic models (IBM Models 15) for statistical machine translation and the concept of wordbyword'' alignment, the correspondence between words in source and target languages.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,a7e925a65860e90b2b4eb427a8bc497f76b2fe6e,What’s in a translation rule?,2004,Michel Galley; Mark Hopkins; Kevin Knight; D. Marcu
251,J91-2003,External_76184,[3],introduction,"We have shown elsewhere ( Jensen and Binot 1988 ; <TARGET_CITATION/> , 1987b ) that natural language programs , such as online grammars and dictionaries , can be used as referential levels for commonsense reasoning  for example , to disambiguate PP attachment .","Since not all logically permissible models are linguistically appropriate, one needs a place, namely the metalevel, to put constraints on types of models. Gricean maxims belong there; Section 6 will be devoted to a presentation of the metalevel rules corresponding to them. We have shown elsewhere <TARGET_CITATION/> that natural language programs , such as online grammars and dictionaries , can be used as referential levels for commonsense reasoning  for example , to disambiguate PP attachment . We have shown elsewhere (Jensen and Binot 1988; Zadrozny 1987a, 1987b) that natural language programs, such as online grammars and dictionaries, can be used as referential levels for commonsense reasoningfor example, to disambiguate PP attachment. Gricean maxims belong there; Section 6 will be devoted to a presentation of the metalevel rules corresponding to them.Since not all logically permissible models are linguistically appropriate, one needs a place, namely the metalevel, to put constraints on types of models.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,intended models circumscription and commonsense reasoningquot,1987,W Zadrozny
253,W01-0706,External_555,[0],introduction,"Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <TARGET_CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <CITATION/> ; Tjong Kim <CITATION/> ) .","to ] [NP only $ 1.8 billion ] [PP in ] [NP September] . While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <TARGET_CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <CITATION/> ; Tjong Kim <CITATION/> ) . Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,0ffa423a5283396c88ff3d4033d541796bd039cc,"Three Generative, Lexicalised Models for Statistical Parsing",1997,M. Collins
256,J07-1005,External_17760,[0],,The following four components have been identified as the key elements of a question related to patient care <TARGET_CITATION/> :,"The results of this research are implemented in the PubMed Clinical Queries tools, which can be used to retrieve taskspecific citations (more about this in the next section). The second facet is independent of the clinical task and pertains to the structure of a wellbuilt clinical question. The following four components have been identified as the key elements of a question related to patient care <TARGET_CITATION/> : The following four components have been identified as the key elements of a question related to patient care <CITATION/>:The second facet is independent of the clinical task and pertains to the structure of a wellbuilt clinical question. The results of this research are implemented in the PubMed Clinical Queries tools, which can be used to retrieve taskspecific citations (more about this in the next section).",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,,the wellbuilt clinical question a key to evidencebased decisions,1995,W Scott Richardson; Mark C Wilson; James Nishikawa; Robert S Hayward
260,J13-1008,P11-2062,[2],conclusion,"We use the agreement checker code developed by <TARGET_CITATION/> and evaluate our baseline ( MaltParser using only CORE12 ) , best performing model ( EasyFirst Parser using CORE12 + DET+LMM+PERSON+FN * NGR g + p ) , and the gold reference .","Grammaticality of parse trees. We now turn to our second type of error analysis, the evaluation of the grammaticality of the parse trees in terms of gender and number agreement patterns. We use the agreement checker code developed by <TARGET_CITATION/> and evaluate our baseline ( MaltParser using only CORE12 ) , best performing model ( EasyFirst Parser using CORE12 + DET+LMM+PERSON+FN * NGR g + p ) , and the gold reference . We use the agreement checker code developed by <CITATION/> and evaluate our baseline (MaltParser using only CORE12), best performing model (EasyFirst Parser using CORE12 + DET+LMM+PERSON+FN*NGR g+p), and the gold reference. We now turn to our second type of error analysis, the evaluation of the grammaticality of the parse trees in terms of gender and number agreement patterns. Grammaticality of parse trees.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,cc91b4439d1e15fcd10bb0a2f04c6bb8f4909915,"A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality",2011,Sarah Alkuhlani; Nizar Habash
267,J10-3007,P05-1074,[1],introduction,"But their importance has grown far beyond machine translation : for instance , transferring annotations between languages <CITATION/> ; discovery of paraphrases <TARGET_CITATION/> ; and joint unsupervised POS and parser induction across languages <CITATION/> .","Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as forMT system combination <CITATION/>. But their importance has grown far beyond machine translation : for instance , transferring annotations between languages <CITATION/> ; discovery of paraphrases <TARGET_CITATION/> ; and joint unsupervised POS and parser induction across languages <CITATION/> . But their importance has grown far beyond machine translation: for instance, transferring annotations between languages <CITATION/>; discovery of paraphrases <CITATION/>; and joint unsupervised POS and parser induction across languages <CITATION/>. MT system combination <CITATION/>. Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as for",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,36e8b8b35e51e5b39fcafdb5c2bc763796d0672e,Paraphrasing with Bilingual Parallel Corpora,2005,Colin Bannard; Chris Callison-Burch
268,J07-1005,External_498,[2],,each relevant document is retrieved <TARGET_CITATION/> ., Precision at ten retrieved documents (P10) measures the fraction of relevant documents in the top ten results.  Mean Average Precision (MAP) is the average of precision values after each relevant document is retrieved <TARGET_CITATION/> . each relevant document is retrieved <CITATION/>.  Mean Average Precision (MAP) is the average of precision values after Precision at ten retrieved documents (P10) measures the fraction of relevant documents in the top ten results.,9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,49af3e80343eb80c61e727ae0c27541628c7c5e2,Introduction to Modern Information Retrieval,1983,Gerard Salton; Michael McGill
275,P05-3005,External_35215,[2],,"The system utilizes several large size biological databases including three NCBI databases ( <CITATION/> , RefSeq <TARGET_CITATION/> , and Entrez GENE <CITATION/> ) , PSD database from Protein Information Resources ( PIR ) <CITATION/> , and"," The system utilizes several large size biological databases including three NCBI databases ( <CITATION/> , RefSeq <TARGET_CITATION/> , and Entrez GENE <CITATION/> ) , PSD database from Protein Information Resources ( PIR ) <CITATION/> , and The system utilizes several large size biological databases including three NCBI databases (<CITATION/>, and Entrez GENE <CITATION/>), PSD database from Protein Information Resources (PIR) <CITATION/>, and",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,,dr introducing refseq and locuslink curated human genome resources at the ncbi trends genet,2000,Pruitt KD; Katz KS; H Sicotte; Maglott
276,E12-1068,External_361,[2],experiments,The LM uses the monolingual data and is trained as a fivegram9 using the SRILMToolkit <TARGET_CITATION/> .,We symmetrize using the growdiagfinaland'' heuristic. Our Moses systems use default settings. The LM uses the monolingual data and is trained as a fivegram9 using the SRILMToolkit <TARGET_CITATION/> . The LM uses the monolingual data and is trained as a fivegram9 using the SRILMToolkit <CITATION/>. Our Moses systems use default settings. We symmetrize using the growdiagfinaland'' heuristic.,d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,399da68d3b97218b6c80262df7963baa89dcc71b,SRILM - an extensible language modeling toolkit,2002,A. Stolcke
279,J91-2003,External_1368,[1],introduction,"Secondly , the cooperative principle of <TARGET_CITATION/> ) , under the assumption that referential levels of a writer and a reader are quite similar , implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader ; and this seems to imply that he should appeal only to the most direct knowledge of the reader .","However, there are at least three arguments against iterating PT. First of all, iteration would increase the complexity of building a model of a paragraph; infinite iteration would almost certainly make impossible such a construction in real time. Secondly , the cooperative principle of <TARGET_CITATION/> ) , under the assumption that referential levels of a writer and a reader are quite similar , implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader ; and this seems to imply that he should appeal only to the most direct knowledge of the reader . Secondly, the cooperative principle of Grice (1975, 1978), under the assumption that referential levels of a writer and a reader are quite similar, implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader; and this seems to imply that he should appeal only to the most direct knowledge of the reader. First of all, iteration would increase the complexity of building a model of a paragraph; infinite iteration would almost certainly make impossible such a construction in real time. However, there are at least three arguments against iterating PT.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,b25e5bca74d74abb1687315fa3c637bb9911554d,Logic and Conversation,2005,Siobhan Chapman
286,J91-2003,External_5163,[4],introduction,"We are going to make such a comparison with the theories proposed by J. <TARGET_CITATION/> ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W. <CITATION/> , who are more interested in addressing psychological and cognitive aspects of discourse coherence .","At this point it may be proper to comment on the relationship between our theory of coherence and theories advocated by others. We are going to make such a comparison with the theories proposed by J. <TARGET_CITATION/> ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W. <CITATION/> , who are more interested in addressing psychological and cognitive aspects of discourse coherence . We are going to make such a comparison with the theories proposed by J. Hobbs (1979, 1982) that represent a more computationally oriented approach to coherence, and those of T.A. van Dijk and W. <CITATION/>, who are more interested in addressing psychological and cognitive aspects of discourse coherence. At this point it may be proper to comment on the relationship between our theory of coherence and theories advocated by others.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,coherence and coreferencequot,1979,J R Hobbs
291,J07-1005,External_87362,[0],related work,"Although originally developed as a tool to assist in query formulation , <TARGET_CITATION/> pointed out that PICO frames can be employed to structure IR results for improving precision .","The goal was to automatically classify citations for taskspecific retrieval, similar in spirit to the Hedges Project <CITATION/>. Cimino and Mendonca reported good performance for etiology, diagnosis, and in particular therapy, but not prognosis. Although originally developed as a tool to assist in query formulation , <TARGET_CITATION/> pointed out that PICO frames can be employed to structure IR results for improving precision . Although originally developed as a tool to assist in query formulation, <CITATION/> pointed out that PICO frames can be employed to structure IR results for improving precision. Cimino and Mendonca reported good performance for etiology, diagnosis, and in particular therapy, but not prognosis. The goal was to automatically classify citations for taskspecific retrieval, similar in spirit to the Hedges Project <CITATION/>.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,61c0eaca30df206565ffd0c6d63f43c5f9cf0336,Formulating the Question,1974,M. Schlick
298,W05-0709,External_87919,[0],introduction,It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <TARGET_CITATION/> .,"In addition to the different forms of the Arabic word that result from thederivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <TARGET_CITATION/> . It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <CITATION/>. derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. In addition to the different forms of the Arabic word that result from the",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,,trec2001 crosslingual retrieval at bbn,2001,J Xu; A Fraser; R Weischedel
299,W01-0706,W00-0726,[2],experiments,The first is the one used in the chunking competition in CoNLL2000 ( Tjong Kim <TARGET_CITATION/> ) .,"For the purpose of this study, we chose to use two different definitions. Both can be formally defined and they reflect different levels of shallow parsing patterns. The first is the one used in the chunking competition in CoNLL2000 ( Tjong Kim <TARGET_CITATION/> ) . The first is the one used in the chunking competition in CoNLL2000 (Tjong Kim <CITATION/>). Both can be formally defined and they reflect different levels of shallow parsing patterns. For the purpose of this study, we chose to use two different definitions.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,9e85832b04cc3700c2c26d6ba93fdeae39cac04a,Introduction to the CoNLL-2000 Shared Task Chunking,2000,E. Tjong Kim Sang; S. Buchholz
304,E12-1068,W11-2129,[2],experiments,"Following the work of <TARGET_CITATION/> , we implement a linearchain CRF merging system using the following features : stemmed ( separated ) surface form , partofspeech14 and frequencies from the training corpus for bigrams/merging of word and word +1 , word as true prefix , word +1 as true suffix , plus frequency comparisons of these .","Two decisions have to be taken: i) where tomerge and ii) how to merge. Following the work of <TARGET_CITATION/> , we implement a linearchain CRF merging system using the following features : stemmed ( separated ) surface form , partofspeech14 and frequencies from the training corpus for bigrams/merging of word and word +1 , word as true prefix , word +1 as true suffix , plus frequency comparisons of these . Following the work of <CITATION/>, we implement a linearchain CRF merging system using the following features: stemmed (separated) surface form, partofspeech14 and frequencies from the training corpus for bigrams/merging of word and word+1, word as true prefix, word+1 as true suffix, plus frequency comparisons of these. merge and ii) how to merge. Two decisions have to be taken: i) where to",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,320e8429092f89ccc67a94cad75622d958c6313f,Productive Generation of Compound Words in Statistical Machine Translation,2011,Sara Stymne; Nicola Cancedda
307,W01-0706,External_56797,[0],introduction,"Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text <TARGET_CITATION/> .","Shallow parsing is studied as an alternative to fullsentence parsing. Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text <TARGET_CITATION/> . Rather than producing a complete analysis of sentences, the alternative is to perform only partial analysis of the syntactic structures in a text <CITATION/>. Shallow parsing is studied as an alternative to fullsentence parsing.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,,cooccurrence and transformation in linguistic structure,1957,Z S Harris
308,W01-0706,External_1102,[0],introduction,"Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <TARGET_CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <CITATION/> ; Tjong Kim <CITATION/> ) .","to ] [NP only $ 1.8 billion ] [PP in ] [NP September] . While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <TARGET_CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <CITATION/> ; Tjong Kim <CITATION/> ) . Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,,statistical parsing with a contextfree grammar and word statistics,1997,E Charniak
313,J10-3007,External_33382,[2],,"Here , PV ( A ) represents an ascent direction chosen as follows : For inequality constraints , it is the projected gradient <TARGET_CITATION/> ; for equality constraints with slack , we use conjugate gradient <CITATION/> , noting that when A = 0 , the objective is not differentiable .","We optimize the dual objective using the gradient based methods shown in Algorithm 1. Here 11 is an optimization precision, oc is a step size chosen with the strong Wolfe's rule <CITATION/>. Here , PV ( A ) represents an ascent direction chosen as follows : For inequality constraints , it is the projected gradient <TARGET_CITATION/> ; for equality constraints with slack , we use conjugate gradient <CITATION/> , noting that when A = 0 , the objective is not differentiable . Here, PV(A) represents an ascent direction chosen as follows: For inequality constraints, it is the projected gradient <CITATION/>; for equality constraints with slack, we use conjugate gradient <CITATION/>, noting that when A = 0, the objective is not differentiable. Here 11 is an optimization precision, oc is a step size chosen with the strong Wolfe's rule <CITATION/>. We optimize the dual objective using the gradient based methods shown in Algorithm 1.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,,nonlinear programming 2nd edition athena scientific,1999,Dimitri P Bertsekas
316,J91-2003,External_44424,[4],introduction,",  domain circumscription '' ( cfXXX <TARGET_CITATION/> ) , and their kin .","This strategy is certainly the right one to start out with, since anaphora is always the more typical direction of reference in English prose <CITATION/>. Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of uniquename assumption'' <CITATION/>, domain closure assumption'' (ibid.) ,  domain circumscription '' ( cfXXX <TARGET_CITATION/> ) , and their kin . , domain circumscription'' (cfXXX Etherington and Mercer 1987), and their kin. Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of uniquename assumption'' <CITATION/>, domain closure assumption'' (ibid.)This strategy is certainly the right one to start out with, since anaphora is always the more typical direction of reference in English prose <CITATION/>.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,domain circumscription a reevaluationquot,1987,D W Etherington; R E Mercer
319,N01-1003,External_63,[4],,"Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below , in a manner similar to that used by <TARGET_CITATION/> .","Therefore, instead of carefully choosing a small number of features by hand which may be useful, we generated a very large number of features and let RankBoost choose the relevant ones. In total, we used 3,291 features in training the SPR. Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below , in a manner similar to that used by <TARGET_CITATION/> . Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below, in a manner similar to that used by <CITATION/>. In total, we used 3,291 features in training the SPR. Therefore, instead of carefully choosing a small number of features by hand which may be useful, we generated a very large number of features and let RankBoost choose the relevant ones.",ee6892b9c7f1a491e0925b913b66281c48408f74,SPoT: A Trainable Sentence Planner,2001,M. Walker; Owen Rambow; Monica Rogati,844db702be4bc149b06b822b47247e15f5894cc3,Discriminative Reranking for Natural Language Parsing,2000,M. Collins; Terry Koo
324,W05-0709,P02-1014,[0],introduction,"The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks .","These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc.. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks . The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations <CITATION/>, and have been at the center of evaluations such as: MUC6, MUC7, and the CoNLL'02 and CoNLL'03 shared tasks. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc..",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,08c81389b3ac4b8253d718a7cebe04a5536efa78,Improving Machine Learning Approaches to Coreference Resolution,2002,Vincent Ng; Claire Gardent
326,W01-0706,External_555,[0],introduction,"However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time <TARGET_CITATION/> .","Finally, the hope behind this research direction was that this incremental and modular processing might result in more robust parsing decisions, especially in cases of spoken language or other cases in which the quality of the natural language inputs is low sentences which may have repeated words, missing words, or any other lexical and syntactic mistakes. Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability. However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time <TARGET_CITATION/> . However, since work in this direction has started, a significant progress has also been made in the research on statistical learning of full parsers, both in terms of accuracy and processing time <CITATION/>. Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability. Finally, the hope behind this research direction was that this incremental and modular processing might result in more robust parsing decisions, especially in cases of spoken language or other cases in which the quality of the natural language inputs is low sentences which may have repeated words, missing words, or any other lexical and syntactic mistakes.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,0ffa423a5283396c88ff3d4033d541796bd039cc,"Three Generative, Lexicalised Models for Statistical Parsing",1997,M. Collins
332,E12-1068,W10-1734,[2],related work,"For compound splitting , we follow <TARGET_CITATION/> , using linguistic knowledge encoded in a rulebased morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies .","al.'s work showed that it is most important to model target side coherence and our stem markup also allows us to access source side information. Using additional source side information beyond the markup did not produce a gain in performance. For compound splitting , we follow <TARGET_CITATION/> , using linguistic knowledge encoded in a rulebased morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies . For compound splitting, we follow <CITATION/>, using linguistic knowledge encoded in a rulebased morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies. Using additional source side information beyond the markup did not produce a gain in performance. al.'s work showed that it is most important to model target side coherence and our stem markup also allows us to access source side information.",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,389cae0f6fac08fc9cfddcb8703fe98e95bf8ced,How to Avoid Burning Ducks: Combining Linguistic Analysis and Corpus Statistics for German Compound Processing,2010,Fabienne Fritzinger; Alexander M. Fraser
333,E12-1068,D07-1091,[0],introduction,"<TARGET_CITATION/> showed that the use of a POS factor only results in negligible BLEU improvements , but we need access to the POS in our inflection prediction models .","Having access to inflected verb forms has a positive influence on case prediction in the second2We use an additional target factor to obtain the coarse POS for each stem, applying a 7gram POS model. <TARGET_CITATION/> showed that the use of a POS factor only results in negligible BLEU improvements , but we need access to the POS in our inflection prediction models . <CITATION/> showed that the use of a POS factor only results in negligible BLEU improvements, but we need access to the POS in our inflection prediction models.2We use an additional target factor to obtain the coarse POS for each stem, applying a 7gram POS model. Having access to inflected verb forms has a positive influence on case prediction in the second",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,659f1f754954d093e684ead4842832052f7bf748,Factored Translation Models,2007,Philipp Koehn; Hieu D. Hoang
335,J07-1005,External_1878,[2],,"We first identified the most informative unigrams and bigrams using the information gain measure <TARGET_CITATION/> , and then selected only the positive outcome predictors using odds ratio <CITATION/> .","The unigram bag of words'' classifier is a naive Bayes classifier implemented with the API provided by the MALLET toolkit.4 This classifier outputs the probability of a class assignment. The ngram based classifier is also a naive Bayes classifier, but it operates on a different set of features. We first identified the most informative unigrams and bigrams using the information gain measure <TARGET_CITATION/> , and then selected only the positive outcome predictors using odds ratio <CITATION/> . We first identified the most informative unigrams and bigrams using the information gain measure <CITATION/>, and then selected only the positive outcome predictors using odds ratio <CITATION/>. The ngram based classifier is also a naive Bayes classifier, but it operates on a different set of features. The unigram bag of words'' classifier is a naive Bayes classifier implemented with the API provided by the MALLET toolkit.4 This classifier outputs the probability of a class assignment.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,c3ebcef26c22a373b6f26a67934213eb0582804e,A Comparative Study on Feature Selection in Text Categorization,1997,Yiming Yang; Jan O. Pedersen
341,J07-1005,External_39268,[4],related work,"The PERSIVAL project , the most comprehensive study of such techniques applied on medical texts to date , leverages patient records to generate personalized summaries in response to physicians ' queries <TARGET_CITATION/> .","In a similar vein, <CITATION/> report on the identification of speculative statements in MEDLINE abstracts, but once again, this work is not directly applicable to clinical question answering. In addition to question answering, multidocument summarization provides a complementary approach to addressing clinical information needs. The PERSIVAL project , the most comprehensive study of such techniques applied on medical texts to date , leverages patient records to generate personalized summaries in response to physicians ' queries <TARGET_CITATION/> . The PERSIVAL project, the most comprehensive study of such techniques applied on medical texts to date, leverages patient records to generate personalized summaries in response to physicians' queries <CITATION/>. In addition to question answering, multidocument summarization provides a complementary approach to addressing clinical information needs. In a similar vein, <CITATION/> report on the identification of speculative statements in MEDLINE abstracts, but once again, this work is not directly applicable to clinical question answering.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,e8c436eebeb3ef4e9c559c517eecf7d31b7f4203,Customization in a unified framework for summarizing medical literature,2005,Noémie Elhadad; Min-Yen Kan; Judith L. Klavans; K. McKeown
342,J10-3007,External_22886,[0],,See <TARGET_CITATION/> for further discussion .,"When we include only high confidence alignments, more phrases are extracted but many of these are erroneous. Potentially this leads to a poor estimate of the phrase probabilities. See <TARGET_CITATION/> for further discussion . See <CITATION/> for further discussion.Potentially this leads to a poor estimate of the phrase probabilities. When we include only high confidence alignments, more phrases are extracted but many of these are erroneous.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,,wordbased alignment phrasebased translation whats the link,2006,Adam Lopez; Philip Resnik
372,J13-1008,External_1438,[4],experiments,"In comparison , the tag set of the Buckwalter Morphological Analyzer <TARGET_CITATION/> used in the PATB has a core POS set of 44 tags ( CORE44 ) before morphological extension .8 Crosslinguistically , a core set containing around 12 tags is often","Linguistically, words have associated POS tags, e.g., verb'' or noun,'' which further abstract over morphologically and syntactically similar lexemes. Traditional Arabic grammars often describe a very general threeway distinction into verbs, nominals, and particles. In comparison , the tag set of the Buckwalter Morphological Analyzer <TARGET_CITATION/> used in the PATB has a core POS set of 44 tags ( CORE44 ) before morphological extension .8 Crosslinguistically , a core set containing around 12 tags is often In comparison, the tag set of the Buckwalter Morphological Analyzer <CITATION/> used in the PATB has a core POS set of 44 tags (CORE44) before morphological extension.8 Crosslinguistically, a core set containing around 12 tags is oftenTraditional Arabic grammars often describe a very general threeway distinction into verbs, nominals, and particles. Linguistically, words have associated POS tags, e.g., verb'' or noun,'' which further abstract over morphologically and syntactically similar lexemes.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,,buckwalter arabic morphological analyzer version 20 linguistic data consortium,2004,Timothy A Buckwalter
379,N01-1009,External_1172,[2],method,Table 1 gives the interpretations of eight adjectivenoun combinations discussed in <TARGET_CITATION/> .,In what follows we explain the properties of the model by applying it to a small number of adjectivenoun combinations taken from the lexical semantics literature. Table 1 gives the interpretations of eight adjectivenoun combinations discussed in <TARGET_CITATION/> . Table 1 gives the interpretations of eight adjectivenoun combinations discussed in <CITATION/>. In what follows we explain the properties of the model by applying it to a small number of adjectivenoun combinations taken from the lexical semantics literature.,3d4226a01208653d3598685cfa571390e193791d,A Corpus-based Account of Regular Polysemy: The Case of Context-sensitive Adjectives,2001,Maria Lapata,259d0304adcb49e40436137684b78a80c9ef097b,The Generative Lexicon,1991,J. Pustejovsky
396,J10-3007,External_3667,[0],introduction,"Many researchers use the GIZA + + software package <TARGET_CITATION/> as a black box , selecting IBM Model 4 as a compromise between alignment quality and efficiency .","IBM Models 1 and 2 and the HMM are simple and tractable probabilistic models, which produce the target sentence one target word at a time by choosing a source word and generating its translation. IBM Models 3, 4, and 5 attempt to capture fertility (the tendency of each source word to generate several target words), resulting in probabilistically deficient, intractable models that require local heuristic search and are difficult to implement and extend. Many researchers use the GIZA + + software package <TARGET_CITATION/> as a black box , selecting IBM Model 4 as a compromise between alignment quality and efficiency . Many researchers use the GIZA++ software package <CITATION/> as a black box, selecting IBM Model 4 as a compromise between alignment quality and efficiency. IBM Models 3, 4, and 5 attempt to capture fertility (the tendency of each source word to generate several target words), resulting in probabilistically deficient, intractable models that require local heuristic search and are difficult to implement and extend. IBM Models 1 and 2 and the HMM are simple and tractable probabilistic models, which produce the target sentence one target word at a time by choosing a source word and generating its translation.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,de2df29b0a0312de7270c3f5a0af6af5645cf91a,A Systematic Comparison of Various Statistical Alignment Models,2003,F. Och; H. Ney
424,J13-1008,C10-1045,[2],conclusion,"For better comparison with work of others , we adopt the suggestion made by <TARGET_CITATION/> to evaluate the parsing quality on sentences up to 70 tokens long ."," For better comparison with work of others , we adopt the suggestion made by <TARGET_CITATION/> to evaluate the parsing quality on sentences up to 70 tokens long . For better comparison with work of others, we adopt the suggestion made by <CITATION/> to evaluate the parsing quality on sentences up to 70 tokens long.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,70c2d71a68df279d057471db5173fab0a8aa19ae,"Better Arabic Parsing: Baselines, Evaluations, and Analysis",2010,Spence Green; Christopher D. Manning
428,J91-2003,External_25105,[0],introduction,W. <TARGET_CITATION/> discussed sentences of the form * This is a chair but you can sit on it .,"If we subscribe to a more realistic view where definitions are given by a collection of central/prototypical and peripheral conditions, only the peripheral ones can be contradicted by but.'' In either formalization we get BUT_Cl as a consequence: Since laws'' cannot be deleted, BUT can't be applied, and hence its use in those kinds of sentences would be incorrect. W. <TARGET_CITATION/> discussed sentences of the form * This is a chair but you can sit on it . W. <CITATION/> discussed sentences of the form *This is a chair but you can sit on it. In either formalization we get BUT_Cl as a consequence: Since laws'' cannot be deleted, BUT can't be applied, and hence its use in those kinds of sentences would be incorrect. If we subscribe to a more realistic view where definitions are given by a collection of central/prototypical and peripheral conditions, only the peripheral ones can be contradicted by but.''",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,the boundaries of words and their meaningsquot,1973,W Labov
438,J13-1008,J08-4003,[0],related work,"As for work on Arabic ( MSA ) , results have been reported on the PATB <CITATION/> , the Prague Dependency Treebank ( PADT ) <TARGET_CITATION/> and the CATiB <CITATION/> .","We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima'an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic ( MSA ) , results have been reported on the PATB <CITATION/> , the Prague Dependency Treebank ( PADT ) <TARGET_CITATION/> and the CATiB <CITATION/> . As for work on Arabic (MSA), results have been reported on the PATB <CITATION/>, the Prague Dependency Treebank (PADT) <CITATION/> and the CATiB <CITATION/>. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima'an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. We also find that the number feature helps for Arabic.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,053f1cf10ced2321c1853f307075f0a6a83b6840,Algorithms for Deterministic Incremental Dependency Parsing,2008,Joakim Nivre
439,J07-1005,W06-3309,[0],related work,"For example , <CITATION/> describe a machine learning approach to automatically label sentences as belonging to introduction , methods , results , or conclusion using structured abstracts as training data ( see also <TARGET_CITATION/> ) .","8 Although note that answer generation from the PubMed results also requires the use of the outcome extractor.The literature also contains work on sentencelevel classification of MEDLINE abstracts for nonclinical purposes. For example , <CITATION/> describe a machine learning approach to automatically label sentences as belonging to introduction , methods , results , or conclusion using structured abstracts as training data ( see also <TARGET_CITATION/> ) . For example, <CITATION/> describe a machine learning approach to automatically label sentences as belonging to introduction, methods, results, or conclusion using structured abstracts as training data (see also Lin et al. 2006). The literature also contains work on sentencelevel classification of MEDLINE abstracts for nonclinical purposes. 8 Although note that answer generation from the PubMed results also requires the use of the outcome extractor.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,33f33197434dbcb6dbe5b2f5e27d646262fcd19d,Generative Content Models for Structural Analysis of Medical Abstracts,2006,Jimmy J. Lin; Damianos G. Karakos; Dina Demner-Fushman; S. Khudanpur
443,J91-2003,External_12390,[0],introduction,Opposition ( called  adversative '' or  contrarytoexpectation '' by Halliday and Hasan 1976 ; cfXXX also <TARGET_CITATION/> ) .,"However, but'' does not behave quite like the other twosemantically, but'' signals a contradiction, and in this role it seems to have three subfunctions:1. Opposition ( called  adversative '' or  contrarytoexpectation '' by Halliday and Hasan 1976 ; cfXXX also <TARGET_CITATION/> ) . Opposition (called adversative'' or contrarytoexpectation'' by Halliday and Hasan 1976; cfXXX also Quirk et al. 1972, p. 672).1. However, but'' does not behave quite like the other twosemantically, but'' signals a contradiction, and in this role it seems to have three subfunctions:",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,a grammar of contemporary english longman group limited,1972,Randolph Quirk; Sidney Greenbaum; Geoffrey Leech; Jan Svartvik
448,J91-2003,External_504,[4],introduction,"Although there are other discussions of the paragraph as a central element of discourse <TARGET_CITATION/> , all of them share a certain limitation in their formal techniques for analyzing paragraph structure ."," Although there are other discussions of the paragraph as a central element of discourse <TARGET_CITATION/> , all of them share a certain limitation in their formal techniques for analyzing paragraph structure . Although there are other discussions of the paragraph as a central element of discourse <CITATION/>, all of them share a certain limitation in their formal techniques for analyzing paragraph structure.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,b4d5633b96ea5e0f9e90e03df58e8ad0f6f3dee7,Cohesion in English,1976,M. Halliday; R. Hasan
451,J10-3007,External_5250,[2],,"Here 11 is an optimization precision , oc is a step size chosen with the strong Wolfe 's rule <TARGET_CITATION/> .","Hence the projection step uses the same inference algorithm (forwardbackward for HMMs) to compute the gradient, only modifying the local factors using the current setting of .We optimize the dual objective using the gradient based methods shown in Algorithm 1. Here 11 is an optimization precision , oc is a step size chosen with the strong Wolfe 's rule <TARGET_CITATION/> . Here 11 is an optimization precision, oc is a step size chosen with the strong Wolfe's rule <CITATION/>. We optimize the dual objective using the gradient based methods shown in Algorithm 1. Hence the projection step uses the same inference algorithm (forwardbackward for HMMs) to compute the gradient, only modifying the local factors using the current setting of .",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,43c3bfffdcd313c549b2045980855ea001d6f13b,Numerical Optimization,2018,J. Nocedal; Stephen J. Wright
455,W05-0709,External_87913,[2],introduction,"Instead , we will adopt the nomenclature of the Automatic Content Extraction program <TARGET_CITATION/> : we will call the instances of textual references to objects/abstractions mentions , which can be either named ( e.g. John Mayor ) , nominal ( the president ) or pronominal ( she , it ) .","The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations <CITATION/>, and have been at the center of evaluations such as: MUC6, MUC7, and the CoNLL'02 and CoNLL'03 shared tasks. Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences. Instead , we will adopt the nomenclature of the Automatic Content Extraction program <TARGET_CITATION/> : we will call the instances of textual references to objects/abstractions mentions , which can be either named ( e.g. John Mayor ) , nominal ( the president ) or pronominal ( she , it ) . Instead, we will adopt the nomenclature of the Automatic Content Extraction program (NIST, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. John Mayor), nominal (the president) or pronominal (she, it). Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences. The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations <CITATION/>, and have been at the center of evaluations such as: MUC6, MUC7, and the CoNLL'02 and CoNLL'03 shared tasks.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,,proceedings of ace evaluation and pi meeting,2004,NIST
464,W05-0709,J96-3004,[4],,"In addition to the model based upon a dictionary of stems and words , we also experimented with models based upon character ngrams , similar to those used for Chinese segmentation <TARGET_CITATION/> ."," In addition to the model based upon a dictionary of stems and words , we also experimented with models based upon character ngrams , similar to those used for Chinese segmentation <TARGET_CITATION/> . In addition to the model based upon a dictionary of stems and words, we also experimented with models based upon character ngrams, similar to those used for Chinese segmentation <CITATION/>.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,54e985fb5b0af022ed4ef6fd19f920ca3d79b51e,A Stochastic Finite-State Word-Segmentation Algorithm for Chinese,1996,R. Sproat; Chilin Shih; W. Gale; Nancy Chang
468,J13-1008,P09-2056,[2],experiments,We use the Columbia Arabic Treebank ( CATiB ) <TARGET_CITATION/> ., We use the Columbia Arabic Treebank ( CATiB ) <TARGET_CITATION/> . We use the Columbia Arabic Treebank (CATiB) <CITATION/>.,4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,25f60908cc3613ddca64638bc9aa119f4c55e78a,CATiB: The Columbia Arabic Treebank,2009,Nizar Habash; Ryan Roth
469,J91-2003,External_17593,[0],introduction,"This problem may be similar to the situation in which current formal grammars allow nonsensical but parsable collections of words ( e.g. ,  colorless green ideas ... '' ) , while before the advent of Chomskyan formalisms , a sentence was defined as the smallest meaningful collection of words ; <TARGET_CITATION/> ) gives 10 definitions of a sentence .","The question of paragraph length can probably be attended to by limiting the size of pmodels, perhaps after introducing some kind of metric on logical data structures. Still, our definition of coherence may not be restrictive enough: two collections of sentences, one referring to black'' (about black pencils, black pullovers, and black poodles), the other one about death'' (war, cancer, etc.), connected by a sentence referring to both of these, could be interpreted as one paragraph about the new, broader topic black + death.'' This problem may be similar to the situation in which current formal grammars allow nonsensical but parsable collections of words ( e.g. ,  colorless green ideas ... '' ) , while before the advent of Chomskyan formalisms , a sentence was defined as the smallest meaningful collection of words ; <TARGET_CITATION/> ) gives 10 definitions of a sentence . This problem may be similar to the situation in which current formal grammars allow nonsensical but parsable collections of words (e.g., colorless green ideas... ''), while before the advent of Chomskyan formalisms, a sentence was defined as the smallest meaningful collection of words; <CITATION/> gives 10 definitions of a sentence. Still, our definition of coherence may not be restrictive enough: two collections of sentences, one referring to black'' (about black pencils, black pullovers, and black poodles), the other one about death'' (war, cancer, etc.), connected by a sentence referring to both of these, could be interpreted as one paragraph about the new, broader topic black + death.'' The question of paragraph length can probably be attended to by limiting the size of pmodels, perhaps after introducing some kind of metric on logical data structures.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,9a144ccd12e184b6a6e2be7522fbd111a0df9d6e,A Dictionary of Modern English Usage,1926,B. Strang; H. Fowler
471,J13-1008,P99-1065,[1],introduction,"For example , modeling CASE in Czech improves Czech parsing <TARGET_CITATION/> : CASE is relevant , not redundant , and can be predicted with sufficient accuracy .","Different languages vary with respect to which features may be most helpful given various tradeoffs among these three factors. In the past, it has been shown that if we can recognize the relevant morphological features in assignment configurations well enough, then they contribute to parsing accuracy. For example , modeling CASE in Czech improves Czech parsing <TARGET_CITATION/> : CASE is relevant , not redundant , and can be predicted with sufficient accuracy . For example, modeling CASE in Czech improves Czech parsing <CITATION/>: CASE is relevant, not redundant, and can be predicted with sufficient accuracy. In the past, it has been shown that if we can recognize the relevant morphological features in assignment configurations well enough, then they contribute to parsing accuracy. Different languages vary with respect to which features may be most helpful given various tradeoffs among these three factors.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,0cb912b4a208b217c45d57e28fc0f59599f92330,A Statistical Parser for Czech,1999,M. Collins; Jan Hajic; L. Ramshaw; Christoph Tillmann
477,J10-3007,D07-1006,[4],,"This is the approach taken by IBM Models 4 + <CITATION/> , and more recently by the LEAF model <TARGET_CITATION/> .","Word alignment models in general and the HMM in particular are very gross oversimplifications of the translation process and the optimal likelihood parameters learned often do not correspond to sensible alignments. One solution to this problem is to add more complexity to the model to better reflect the translation process. This is the approach taken by IBM Models 4 + <CITATION/> , and more recently by the LEAF model <TARGET_CITATION/> . This is the approach taken by IBM Models 4+ <CITATION/>, and more recently by the LEAF model <CITATION/>. One solution to this problem is to add more complexity to the model to better reflect the translation process. Word alignment models in general and the HMM in particular are very gross oversimplifications of the translation process and the optimal likelihood parameters learned often do not correspond to sensible alignments.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,53db1adf5f3943e107a6064efe801667501ae9f8,Getting the Structure Right for Word Alignment: LEAF,2007,Alexander M. Fraser; D. Marcu
478,J07-1005,H05-1117,[4],,"We have noted that many of these desiderata make complex question answering quite similar to multidocument summarization <TARGET_CITATION/> , but these features are also beyond the capabilities of current summarization systems .","Ideally, answers should integrate information from multiple clinical studies, pointing out both similarities and differences. The system should collate concurrences, that is, if multiple abstracts arrive at the same conclusionit need not be repeated unless the physician wishes to drill down''; the system should reconcile contradictions, for example, if two abstracts disagree on a particular treatment because they studied different patient populations. We have noted that many of these desiderata make complex question answering quite similar to multidocument summarization <TARGET_CITATION/> , but these features are also beyond the capabilities of current summarization systems . We have noted that many of these desiderata make complex question answering quite similar to multidocument summarization <CITATION/>, but these features are also beyond the capabilities of current summarization systems. The system should collate concurrences, that is, if multiple abstracts arrive at the same conclusionit need not be repeated unless the physician wishes to drill down''; the system should reconcile contradictions, for example, if two abstracts disagree on a particular treatment because they studied different patient populations. Ideally, answers should integrate information from multiple clinical studies, pointing out both similarities and differences.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,570bfcb94270e1d565450fb6029a9f6e7c8749a2,Automatically Evaluating Answers to Definition Questions,2005,Jimmy J. Lin; Dina Demner-Fushman
494,J91-2003,External_9402,[4],introduction,"This Principle of Finitism is also assumed by <TARGET_CITATION/> , and implicitly or explicitly by almost all researchers in computational linguistics .","Therefore these notions, and all other constructs we are going to define (axioms, metarules, definitions etc.) are computational, although usually we will not provide explicit algorithms for computing them. The issues of control are not so important for us at this point; we restrict ourselves to describing the logic. This Principle of Finitism is also assumed by <TARGET_CITATION/> , and implicitly or explicitly by almost all researchers in computational linguistics . This Principle of Finitism is also assumed by <CITATION/>, and implicitly or explicitly by almost all researchers in computational linguistics. The issues of control are not so important for us at this point; we restrict ourselves to describing the logic. Therefore these notions, and all other constructs we are going to define (axioms, metarules, definitions etc.) are computational, although usually we will not provide explicit algorithms for computing them.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,d9b5750bbc3f819e24431cbfa106a9ad0cb7e6d2,Mental Models,2019,Peter Hollins
498,W01-0706,External_555,[2],experiments,"For the full parser , we use the one developed by Michael Collins <TARGET_CITATION/>  one of the most accurate full parsers around .","We perform our comparison using two stateoftheart parsers. For the full parser , we use the one developed by Michael Collins <TARGET_CITATION/>  one of the most accurate full parsers around . For the full parser, we use the one developed by Michael Collins <CITATION/>  one of the most accurate full parsers around. We perform our comparison using two stateoftheart parsers.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,0ffa423a5283396c88ff3d4033d541796bd039cc,"Three Generative, Lexicalised Models for Statistical Parsing",1997,M. Collins
500,J07-1005,External_3427,[0],related work,<TARGET_CITATION/> have demonstrated that differential weighting of automatically labeled sections can lead to improved retrieval performance .,"The literature also contains work on sentencelevel classification of MEDLINE abstracts for nonclinical purposes. For example, <CITATION/> describe a machine learning approach to automatically label sentences as belonging to introduction, methods, results, or conclusion using structured abstracts as training data (see also Lin et al. 2006). <TARGET_CITATION/> have demonstrated that differential weighting of automatically labeled sections can lead to improved retrieval performance . <CITATION/> have demonstrated that differential weighting of automatically labeled sections can lead to improved retrieval performance. For example, <CITATION/> describe a machine learning approach to automatically label sentences as belonging to introduction, methods, results, or conclusion using structured abstracts as training data (see also Lin et al. 2006). The literature also contains work on sentencelevel classification of MEDLINE abstracts for nonclinical purposes.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,0cd2281d0aeb1013ad0bd7c06dbb07377fbcb9b9,Using argumentation to retrieve articles with similar citations: An inquiry into improving related articles search in the MEDLINE digital library,2006,I. Tbahriti; C. Chichester; F. Lisacek; Patrick Ruch
507,J10-3007,P07-2045,[2],,5 The open source Moses <TARGET_CITATION/> toolkit from www.statmt.org/moses/ .,"Symmetrization has almost no effect on alignments produced by SHMM, but we use it for uniformity in the experiments. We tested three values of the threshold (0.2, 0.4, 0.6) which try to capture different tradeoffs 5 The open source Moses <TARGET_CITATION/> toolkit from www.statmt.org/moses/ . 5 The open source Moses <CITATION/> toolkit from www.statmt.org/moses/. We tested three values of the threshold (0.2, 0.4, 0.6) which try to capture different tradeoffsSymmetrization has almost no effect on alignments produced by SHMM, but we use it for uniformity in the experiments.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,4ee2eab4c298c1824a9fb8799ad8eed21be38d21,Moses: Open Source Toolkit for Statistical Machine Translation,2007,Philipp Koehn; Hieu T. Hoang; Alexandra Birch; Chris Callison-Burch; Marcello Federico; N. Bertoldi; Brooke Cowan; Wade Shen; C. Moran; Richard Zens; Chris Dyer; Ondrej Bojar; Alexandra Constantin; Evan Herbst
510,P05-3005,External_95863,[2],,"Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <TARGET_CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> .","The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META. The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <TARGET_CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> . Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary, i.e., mouse Mouse Genome Database (MGD) <CITATION/>, fly <CITATION/>, yeast Saccharomyces Genome Database (SGD) <CITATION/>, rat  Rat Genome Database (RGD) <CITATION/>, worm  <CITATION/>, Human Nomenclature Database (HUGO) <CITATION/>, Online Mendelian Inheritance in Man (OMIM) <CITATION/>, and Enzyme Nomenclature Database (ECNUM) <CITATION/>.The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META.",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,,sgd saccharomyces genome database nucleic acids res,1998,Cherry JM; C Adler; C Ball; Chervitz SA; Dwight SS; Hester ET; Y Jia; G Juvik; T Roe; M Schroeder
512,J07-1005,External_87363,[0],introduction,"However , studies have shown that existing systems for searching MEDLINE ( such as PubMed , the search service provided by the National Library of Medicine ) are often inadequate and unable to supply clinically relevant answers in a timely manner <TARGET_CITATION/> .","Furthermore, the need to answer questions related to patient care at the point of service has been well studied and documented (Covell, Uman, and Manning 1985; Gorman, Ash, and Wykoff 1994; Ely et al. 1999, 2005). MEDLINE, the authoritative repository of abstracts from the medical and biomedical primary literature maintained by the National Library of Medicine, provides the clinically relevant sources for answering physicians' questions, and is commonly used in that capacity (Cogdill and Moore 1997; De Groote and Dorsch 2003). However , studies have shown that existing systems for searching MEDLINE ( such as PubMed , the search service provided by the National Library of Medicine ) are often inadequate and unable to supply clinically relevant answers in a timely manner <TARGET_CITATION/> . However, studies have shown that existing systems for searching MEDLINE (such as PubMed, the search service provided by the National Library of Medicine) are often inadequate and unable to supply clinically relevant answers in a timely manner <CITATION/>. MEDLINE, the authoritative repository of abstracts from the medical and biomedical primary literature maintained by the National Library of Medicine, provides the clinically relevant sources for answering physicians' questions, and is commonly used in that capacity (Cogdill and Moore 1997; De Groote and Dorsch 2003). Furthermore, the need to answer questions related to patient care at the point of service has been well studied and documented (Covell, Uman, and Manning 1985; Gorman, Ash, and Wykoff 1994; Ely et al. 1999, 2005).",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,3c03b666795072a1eeba1acfa1d78d4d135e086c,Guides: Resources for Answering Clinical Questions: Contact us,2018,Librarians Library Engagement
514,J13-1008,External_471,[2],related work,"For all the experiments reported in this article , we used the training portion of PATB Part 3 v3 .1 <TARGET_CITATION/> , converted to the CATiB Treebank format , as mentioned in Section 2.5 ."," For all the experiments reported in this article , we used the training portion of PATB Part 3 v3 .1 <TARGET_CITATION/> , converted to the CATiB Treebank format , as mentioned in Section 2.5 . For all the experiments reported in this article, we used the training portion of PATB Part 3 v3.1 <CITATION/>, converted to the CATiB Treebank format, as mentioned in Section 2.5.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,c2ac213982e189e4ad4c7f60608914a489ec9051,The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus,2004,M. Maamouri; Ann Bies; Tim Buckwalter; Wigdan Mekki
519,P10-2005,P09-1105,[4],introduction,"More recently , an alignment selection approach was proposed in <TARGET_CITATION/> , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a handpicked threshold .","It tries to maximize the number of phrases that can be extracted in the combined alignments. A greedy search method was utilized and it achieved higher translation performance than the baseline. More recently , an alignment selection approach was proposed in <TARGET_CITATION/> , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a handpicked threshold . More recently, an alignment selection approach was proposed in <CITATION/>, which computes confidence scores for each link and prunes the links from multiple sets of alignments using a handpicked threshold. A greedy search method was utilized and it achieved higher translation performance than the baseline. It tries to maximize the number of phrases that can be extracted in the combined alignments.",48309ec2f651527915647153976380df94293eaf,Diversify and Combine: Improving Word Alignment for Machine Translation on Low-Resource Languages,2010,Bing Xiang; Yonggang Deng; Bowen Zhou,a4ed5febd3f77a4ec1db440ccb4335c54e7036e5,Confidence Measure for Word Alignment,2009,Fei Huang
525,J10-3007,External_2511,[2],,"results are based on a corpus of movie subtitles <TARGET_CITATION/> , and are consequently shorter sentences , whereas the En  Es results are based on a corpus of parliamentary proceedings <CITATION/> .","Vertical axis: percentage of transferred edges that are correct. Horizontal axis: average number of transferred edges per sentence. results are based on a corpus of movie subtitles <TARGET_CITATION/> , and are consequently shorter sentences , whereas the En  Es results are based on a corpus of parliamentary proceedings <CITATION/> . results are based on a corpus of movie subtitles <CITATION/>, and are consequently shorter sentences, whereas the EnEs results are based on a corpus of parliamentary proceedings <CITATION/>. Horizontal axis: average number of transferred edges per sentence. Vertical axis: percentage of transferred edges that are correct.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,0d0eb34ab56f7b48b6d611b5d0767bc59ba8b9fc,Building a Multilingual Parallel Subtitle Corpus,2007,J. Tiedemann
528,D08-1016,P05-1022,[5],conclusion,"For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrasestructure and lattice parsing , and in trying other higherorder features , such as those used in parse reranking <TARGET_CITATION/> and historybased parsing <CITATION/> .","Belief propagation improves nonprojective dependency parsing with features that would make exact inference intractable. For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrasestructure and lattice parsing , and in trying other higherorder features , such as those used in parse reranking <TARGET_CITATION/> and historybased parsing <CITATION/> . For projective parsing, it is significantly faster than exact dynamic programming, at the cost of small amounts of search error, We are interested in extending these ideas to phrasestructure and lattice parsing, and in trying other higherorder features, such as those used in parse reranking <CITATION/> and historybased parsing <CITATION/>. Belief propagation improves nonprojective dependency parsing with features that would make exact inference intractable.",ebbb58b2e616435b6ededbc103acfef6dc79bd51,Dependency Parsing by Belief Propagation,2008,David A. Smith; Jason Eisner,0ecb33ced5b0976accdf13817151f80568b6fdcb,Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking,2005,Eugene Charniak; Mark Johnson
529,J10-3007,H05-1098,[0],introduction,"Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ Galley et al. 2004 ; <TARGET_CITATION/> ] ) as well as for","The seminal work of <CITATION/> introduced a series of probabilistic models (IBM Models 15) for statistical machine translation and the concept of wordbyword'' alignment, the correspondence between words in source and target languages. Although no longer competitive as endtoend translation models, the IBM Models, as well as the hidden Markov model (HMM) of <CITATION/>, are still widely used for word alignment. Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ Galley et al. 2004 ; <TARGET_CITATION/> ] ) as well as for Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as forAlthough no longer competitive as endtoend translation models, the IBM Models, as well as the hidden Markov model (HMM) of <CITATION/>, are still widely used for word alignment. The seminal work of <CITATION/> introduced a series of probabilistic models (IBM Models 15) for statistical machine translation and the concept of wordbyword'' alignment, the correspondence between words in source and target languages.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,08c0f93bcc64afddfdfb01532bb8369679f00e7b,"The Hiero Machine Translation System: Extensions, Evaluation, and Analysis",2005,David Chiang; Adam Lopez; Nitin Madnani; Christof Monz; P. Resnik; M. Subotin
541,J91-2003,External_4948,[4],introduction,"But , obviously , there are other possibilities  for instance , the discourse representation structures ( DRS 's ) of <TARGET_CITATION/> , which have been used to translate a subset of English into logical formulas , to model text ( identified with a list of sentences ) , to analyze a fragment of English , and to deal with anaphora .","Its details are not important for our aim of giving a semantic interpretation of paragraphs; the main theses of our theory do not depend on a logical notation. So we will use a very simple formalism, like the one above, resembling the standard first order language. But , obviously , there are other possibilities  for instance , the discourse representation structures ( DRS 's ) of <TARGET_CITATION/> , which have been used to translate a subset of English into logical formulas , to model text ( identified with a list of sentences ) , to analyze a fragment of English , and to deal with anaphora . But, obviously, there are other possibilitiesfor instance, the discourse representation structures (DRS's) of <CITATION/>, which have been used to translate a subset of English into logical formulas, to model text (identified with a list of sentences), to analyze a fragment of English, and to deal with anaphora. So we will use a very simple formalism, like the one above, resembling the standard first order language. Its details are not important for our aim of giving a semantic interpretation of paragraphs; the main theses of our theory do not depend on a logical notation.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,a theory of truth and semantic representationquot,1981,H Kamp
550,W01-0706,External_1102,[0],introduction,"However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time <TARGET_CITATION/> .","Finally, the hope behind this research direction was that this incremental and modular processing might result in more robust parsing decisions, especially in cases of spoken language or other cases in which the quality of the natural language inputs is low sentences which may have repeated words, missing words, or any other lexical and syntactic mistakes. Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability. However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time <TARGET_CITATION/> . However, since work in this direction has started, a significant progress has also been made in the research on statistical learning of full parsers, both in terms of accuracy and processing time <CITATION/>. Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability. Finally, the hope behind this research direction was that this incremental and modular processing might result in more robust parsing decisions, especially in cases of spoken language or other cases in which the quality of the natural language inputs is low sentences which may have repeated words, missing words, or any other lexical and syntactic mistakes.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,,statistical parsing with a contextfree grammar and word statistics,1997,E Charniak
555,J13-1008,P11-2062,[2],related work,"18 In this article , we use a newer version of the corpus by <TARGET_CITATION/> than the one we used in <CITATION/> .","16 http://sourceforge.net/projects/elixirfm. 17 We also applied the manipulations described in Section A.3 to FNNUM, giving us the variants FNNUMDGT and FNNUMDGTBIN, which we tested similarly. 18 In this article , we use a newer version of the corpus by <TARGET_CITATION/> than the one we used in <CITATION/> . 18 In this article, we use a newer version of the corpus by <CITATION/> than the one we used in <CITATION/>. 17 We also applied the manipulations described in Section A.3 to FNNUM, giving us the variants FNNUMDGT and FNNUMDGTBIN, which we tested similarly. 16 http://sourceforge.net/projects/elixirfm.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,cc91b4439d1e15fcd10bb0a2f04c6bb8f4909915,"A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality",2011,Sarah Alkuhlani; Nizar Habash
557,J10-3007,W02-1019,[2],introduction,Another possibility that often works better is to use Minimum BayesRisk ( MBR ) decoding <TARGET_CITATION/> .,lattice). Another possibility that often works better is to use Minimum BayesRisk ( MBR ) decoding <TARGET_CITATION/> . Another possibility that often works better is to use Minimum BayesRisk (MBR) decoding <CITATION/>. lattice).,270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,3016b4bd4fb78780eb3244e19b41143efecaaf70,Minimum Bayes-Risk Word Alignments of Bilingual Texts,2002,Shankar Kumar; W. Byrne
569,P05-3005,External_95866,[2],,"Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <TARGET_CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> .","The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META. The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <TARGET_CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> . Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary, i.e., mouse Mouse Genome Database (MGD) <CITATION/>, fly <CITATION/>, yeast Saccharomyces Genome Database (SGD) <CITATION/>, rat  Rat Genome Database (RGD) <CITATION/>, worm  <CITATION/>, Human Nomenclature Database (HUGO) <CITATION/>, Online Mendelian Inheritance in Man (OMIM) <CITATION/>, and Enzyme Nomenclature Database (ECNUM) <CITATION/>.The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META.",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,,boddy wj et al the mouse genome database mgd integrating biology with the genome nucleic acids res,2004,Bult CJ; Blake JA; Richardson JE; Kadin JA; Eppig JT; Baldarelli RM; K Barsanti; M Baya; Beal JS
570,E99-1022,External_7877,[0],,2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in <TARGET_CITATION/> .,For expository reasons we represent the ARG n features of the append relation as separate arguments. Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar <CITATION/>.3 <CITATION/> propose a compilation of lexical rules into TIT definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in <TARGET_CITATION/> . 2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in <CITATION/>. Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar <CITATION/>.3 <CITATION/> propose a compilation of lexical rules into TIT definite clausesFor expository reasons we represent the ARG n features of the append relation as separate arguments.,3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,48d6038cbf55280042a736fb9349a0b95ff66f28,The logic of typed feature structures,1992,Bob Carpenter
579,J10-3007,External_3667,[2],,"We used a standard implementation of IBM Model 4 <TARGET_CITATION/> and because changing the existing code is not trivial , we could not use the same stopping criterion to avoid overfitting and we are not able to produce precision/recall curves .","However, we would like to note that IBM Model 4 is a more complex model, able to capture more structure, albeit at the cost of intractable inference. Because our approach is orthogonal to the base model used, the constraints described here could be applied in principle to IBM Model 4 if exact inference was efficient, hopefully yielding similar improvements. We used a standard implementation of IBM Model 4 <TARGET_CITATION/> and because changing the existing code is not trivial , we could not use the same stopping criterion to avoid overfitting and we are not able to produce precision/recall curves . We used a standard implementation of IBM Model 4 <CITATION/> and because changing the existing code is not trivial, we could not use the same stopping criterion to avoid overfitting and we are not able to produce precision/recall curves. Because our approach is orthogonal to the base model used, the constraints described here could be applied in principle to IBM Model 4 if exact inference was efficient, hopefully yielding similar improvements. However, we would like to note that IBM Model 4 is a more complex model, able to capture more structure, albeit at the cost of intractable inference.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,de2df29b0a0312de7270c3f5a0af6af5645cf91a,A Systematic Comparison of Various Statistical Alignment Models,2003,F. Och; H. Ney
582,D08-1016,P08-1067,[5],conclusion,"For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrasestructure and lattice parsing , and in trying other higherorder features , such as those used in parse reranking <TARGET_CITATION/> and historybased parsing <CITATION/> .","Belief propagation improves nonprojective dependency parsing with features that would make exact inference intractable. For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrasestructure and lattice parsing , and in trying other higherorder features , such as those used in parse reranking <TARGET_CITATION/> and historybased parsing <CITATION/> . For projective parsing, it is significantly faster than exact dynamic programming, at the cost of small amounts of search error, We are interested in extending these ideas to phrasestructure and lattice parsing, and in trying other higherorder features, such as those used in parse reranking <CITATION/> and historybased parsing <CITATION/>. Belief propagation improves nonprojective dependency parsing with features that would make exact inference intractable.",ebbb58b2e616435b6ededbc103acfef6dc79bd51,Dependency Parsing by Belief Propagation,2008,David A. Smith; Jason Eisner,1ba700aec9f23ecb76622f2202badf25f6ad896e,Forest Reranking: Discriminative Parsing with Non-Local Features,2008,Liang Huang
584,P05-3005,External_95860,[2],,"Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  WormBase <TARGET_CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> .","The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META. The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  WormBase <TARGET_CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> . Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary, i.e., mouse Mouse Genome Database (MGD) <CITATION/>, fly <CITATION/>, yeast Saccharomyces Genome Database (SGD) <CITATION/>, rat  Rat Genome Database (RGD) <CITATION/>, worm  <CITATION/>, Human Nomenclature Database (HUGO) <CITATION/>, Online Mendelian Inheritance in Man (OMIM) <CITATION/>, and Enzyme Nomenclature Database (ECNUM) <CITATION/>.The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META.",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,,al wormbase a multispecies resource for nematode biology and genomics nucleic acids res,2004,Harris TW; N Chen; F Cunningham; M TelloRuiz; I Antoshechkin; C Bastiani; T Bieri; D Blasiar; K Bradnam; Chan J et
585,J91-2003,External_9642,[0],introduction,"Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping <TARGET_CITATION/> must play a role , too .","We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution. They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it). Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping <TARGET_CITATION/> must play a role , too . Other factors, such as the role of focus (Grosz 1977, 1978; Sidner 1983) or quantifier scoping <CITATION/> must play a role, too. They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it). We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,so what can we talk about nowquot,1983,B Webber
586,J07-1005,External_57139,[0],,"Since mid2002 , the Library has been employing software that automatically suggests MeSH headings based on content <TARGET_CITATION/> .","separate thesaurus. Indexing is performed by approximately 100 indexers with at least bachelor's degrees in life sciences and formal training in indexing provided by NLM. Since mid2002 , the Library has been employing software that automatically suggests MeSH headings based on content <TARGET_CITATION/> . Since mid2002, the Library has been employing software that automatically suggests MeSH headings based on content <CITATION/>. Indexing is performed by approximately 100 indexers with at least bachelor's degrees in life sciences and formal training in indexing provided by NLM. separate thesaurus.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,47ac91cef4607aa5dad7afa2727e97a89428114a,The NLM Indexing Initiative's Medical Text Indexer,2004,A. Aronson; James G. Mork; Clifford W. Gay; Susanne M. Humphrey; Willie J. Rogers
595,W01-0706,External_5235,[2],experiments,"SNoW <TARGET_CITATION/> is a multiclass classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .","The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 <CITATION/>. The shallow parser used is the SNoWbased CSCL parser <CITATION/>. SNoW <TARGET_CITATION/> is a multiclass classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example . SNoW <CITATION/> is a multiclass classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example. The shallow parser used is the SNoWbased CSCL parser <CITATION/>. The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 <CITATION/>.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,,the snow learning architecture,1999,A Carleson; C Cumby; J Rosen; D Roth
600,J91-2003,External_5163,[4],introduction,"According to <TARGET_CITATION/> ) , these two sentences are incoherent .","To see the advantage of assuming that coherence is a property of a fragment of a text/discourse, and not a relation between subsequent sentences, let us consider for instance the text John took a train from Paris to Istanbul. He likes spinach. According to <TARGET_CITATION/> ) , these two sentences are incoherent . According to <CITATION/>, these two sentences are incoherent. He likes spinach. To see the advantage of assuming that coherence is a property of a fragment of a text/discourse, and not a relation between subsequent sentences, let us consider for instance the text John took a train from Paris to Istanbul.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,coherence and coreferencequot,1979,J R Hobbs
601,W01-0706,External_32929,[0],introduction,"Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) .","to ] [NP only $ 1.8 billion ] [PP in ] [NP September] . While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) . Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,a7e084fe51a40eeaaf79bf0b78e837d5bc4a8e10,A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text,1988,Kenneth Ward Church
606,J13-1008,E12-1069,[2],experiments,"In this article , we use an inhouse system which provides functional gender , number , and rationality features <TARGET_CITATION/> .","6 Note that the functional and formbased feature values for verbs always coincide.functional inflectional number feature, but not full functional gender (only for adjectives and verbs but not for nouns), nor rationality. In this article , we use an inhouse system which provides functional gender , number , and rationality features <TARGET_CITATION/> . In this article, we use an inhouse system which provides functional gender, number, and rationality features <CITATION/>. functional inflectional number feature, but not full functional gender (only for adjectives and verbs but not for nouns), nor rationality. 6 Note that the functional and formbased feature values for verbs always coincide.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,58fdacf0d40ddcb304536992a04fa2000022d8de,"Identifying Broken Plurals, Irregular Gender, and Rationality in Arabic Text",2012,Sarah Alkuhlani; Nizar Habash
613,J13-1008,P09-2056,[0],related work,"As for work on Arabic ( MSA ) , results have been reported on the PATB <CITATION/> , the Prague Dependency Treebank ( PADT ) <CITATION/> and the CATiB <TARGET_CITATION/> .","We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima'an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic ( MSA ) , results have been reported on the PATB <CITATION/> , the Prague Dependency Treebank ( PADT ) <CITATION/> and the CATiB <TARGET_CITATION/> . As for work on Arabic (MSA), results have been reported on the PATB <CITATION/>, the Prague Dependency Treebank (PADT) <CITATION/> and the CATiB <CITATION/>. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima'an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. We also find that the number feature helps for Arabic.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,25f60908cc3613ddca64638bc9aa119f4c55e78a,CATiB: The Columbia Arabic Treebank,2009,Nizar Habash; Ryan Roth
623,N01-1013,External_10315,[4],experiments,The task we used to compare different generalisation techniques is similar to that used by <TARGET_CITATION/> et al. ( 1999 ) ., The task we used to compare different generalisation techniques is similar to that used by <TARGET_CITATION/> . The task we used to compare different generalisation techniques is similar to that used by <CITATION/>.,636a9580ca9a2554a2a388696ec12f5c3181dd52,Class-Based Probability Estimation Using a Semantic Hierarchy,2001,S. Clark; David J. Weir,a69b04113c8f890a09e07ef86d0ccfe6982b8289,40 80 11 v 1 2 2 A ug 1 99 4 DISTRIBUTIONAL CLUSTERING OF ENGLISH WORDS,2011,Fernando C Pereira
627,E99-1022,External_1216,[0],introduction,I A more detailed discussion of various aspects of the proposed parser can be found in <TARGET_CITATION/> .,"See, among others, <CITATION/>. As shown in <CITATION/> The presented research was carried out at the University of Tubingen, Germany, as part of the Sonderforschungsbereich 340. I A more detailed discussion of various aspects of the proposed parser can be found in <TARGET_CITATION/> . I A more detailed discussion of various aspects of the proposed parser can be found in <CITATION/>. As shown in <CITATION/> The presented research was carried out at the University of Tubingen, Germany, as part of the Sonderforschungsbereich 340. See, among others, <CITATION/>.",3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,,offline compilation for efficient processing with constraintlogic grammars,1998,Guido Minnen
631,J07-1005,External_24620,[4],conclusion,"Previously , a user study <TARGET_CITATION/> has shown that people are reluctant to type full natural language questions , even after being told that they were using a questionanswering system and that typing complete questions would result in better performance .","The design and implementation of our current system leaves many open avenues for future exploration, one of which concerns our assumptions about the query interface. Previously , a user study <TARGET_CITATION/> has shown that people are reluctant to type full natural language questions , even after being told that they were using a questionanswering system and that typing complete questions would result in better performance . Previously, a user study <CITATION/> has shown that people are reluctant to type full natural language questions, even after being told that they were using a questionanswering system and that typing complete questions would result in better performance. The design and implementation of our current system leaves many open avenues for future exploration, one of which concerns our assumptions about the query interface.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,51882ef298fc87c73801f3dc80947328860c0a00,What Makes a Good Answer? The Role of Context in Question Answering,2003,Jimmy J. Lin; Dennis Quan; Vineet Sinha; Karun Bakshi; David Huynh; Boris Katz; David R Karger
639,J07-1005,External_44094,[0],related work,"The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers <TARGET_CITATION/> , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .","Although the system incorporates both a user and a task model, it does not explicitly capture the principles of evidencebased medicine. Patient information is no doubt important to answering clinical questions, and our work could certainly benefit from experiences gained in the PERSIVAL project. The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers <TARGET_CITATION/> , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 . The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers <CITATION/>, and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005. Patient information is no doubt important to answering clinical questions, and our work could certainly benefit from experiences gained in the PERSIVAL project. Although the system incorporates both a user and a task model, it does not explicitly capture the principles of evidencebased medicine.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,,towards a medical questionanswering system a feasibility study,2003,Pierre Jacquemart; Pierre Zweigenbaum
651,J13-1008,N10-1115,[2],related work,"Furthermore , we demonstrate that our results carry over successfully to another parser , the EasyFirst Parser <TARGET_CITATION/> ( Section 6 ) .","Previous work with MaltParser in Russian, Turkish, and Hindi showed gains with CASE but not with agreement features <CITATION/>. Our work is the first to show gains using agreement in MaltParser and in Arabic dependency parsing, and the first to use functional features for this task. Furthermore , we demonstrate that our results carry over successfully to another parser , the EasyFirst Parser <TARGET_CITATION/> ( Section 6 ) . Furthermore, we demonstrate that our results carry over successfully to another parser, the EasyFirst Parser <CITATION/> (Section 6). Our work is the first to show gains using agreement in MaltParser and in Arabic dependency parsing, and the first to use functional features for this task. Previous work with MaltParser in Russian, Turkish, and Hindi showed gains with CASE but not with agreement features <CITATION/>.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,3ce0f00d6c949192107f1bd6a167c03e1fb7393a,An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing,2010,Yoav Goldberg; Michael Elhadad
652,J91-2003,External_76362,[0],introduction,"For instance , relating  they '' to  apples '' in the sentence ( cfXXX <TARGET_CITATION/> ; Zadrozny 1987a ) : We bought the boys apples because they were so cheap","This semantics was constructed (Zadrozny 1987a, 1987b) as a formal framework for default and commonsense reasoning. It should not come as a surprise that we can now use this apparatus for text/discourse analysis; after all, many natural language inferences are based on defaults, and quite often they can be reduced to choosing most plausible interpretations of predicates. For instance , relating  they '' to  apples '' in the sentence ( cfXXX <TARGET_CITATION/> ; Zadrozny 1987a ) : We bought the boys apples because they were so cheap For instance, relating they'' to apples'' in the sentence (cfXXX Haugeland 1985 p. 195; Zadrozny 1987a): We bought the boys apples because they were so cheapIt should not come as a surprise that we can now use this apparatus for text/discourse analysis; after all, many natural language inferences are based on defaults, and quite often they can be reduced to choosing most plausible interpretations of predicates. This semantics was constructed (Zadrozny 1987a, 1987b) as a formal framework for default and commonsense reasoning.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,3eb8b8f1bd8fe95dfbeb33cc0cc0b47bc19914f8,Artificial intelligence - the very idea,1987,John Haugeland
654,N01-1009,External_1172,[0],introduction,"Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see <TARGET_CITATION/> and the references therein ) .","Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to. Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see <TARGET_CITATION/> and the references therein ) . Adjectives, more than other categories, are a striking example of regular polysemy since they are able to take on different meanings depending on their context, viz., the noun or noun class they modify (see <CITATION/> and the references therein). Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to.",3d4226a01208653d3598685cfa571390e193791d,A Corpus-based Account of Regular Polysemy: The Case of Context-sensitive Adjectives,2001,Maria Lapata,259d0304adcb49e40436137684b78a80c9ef097b,The Generative Lexicon,1991,J. Pustejovsky
656,J10-3007,P08-1084,[1],introduction,"But their importance has grown far beyond machine translation : for instance , transferring annotations between languages <CITATION/> ; discovery of paraphrases <CITATION/> ; and joint unsupervised POS and parser induction across languages <TARGET_CITATION/> .","Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as forMT system combination <CITATION/>. But their importance has grown far beyond machine translation : for instance , transferring annotations between languages <CITATION/> ; discovery of paraphrases <CITATION/> ; and joint unsupervised POS and parser induction across languages <TARGET_CITATION/> . But their importance has grown far beyond machine translation: for instance, transferring annotations between languages <CITATION/>; discovery of paraphrases <CITATION/>; and joint unsupervised POS and parser induction across languages <CITATION/>. MT system combination <CITATION/>. Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as for",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,36ffcc1cc218ca36de384a107fb48e5abe2e6359,Unsupervised Multilingual Learning for Morphological Segmentation,2008,Benjamin Snyder; R. Barzilay
677,J13-1008,P11-2062,[2],related work,"To address this issue , we use a version of the PATB3 training and dev sets manually annotated with functional gender , number , and rationality <TARGET_CITATION/> .18 This is the first resource providing all three features ( ElixirFm only provides functional number , and to some extent functional gender ) .","The ElixirFM lexical resource used previously provided functional NUMBER feature values but no functional GENDER values, nor RAT (rationality, or humanness) values. To address this issue , we use a version of the PATB3 training and dev sets manually annotated with functional gender , number , and rationality <TARGET_CITATION/> .18 This is the first resource providing all three features ( ElixirFm only provides functional number , and to some extent functional gender ) . To address this issue, we use a version of the PATB3 training and dev sets manually annotated with functional gender, number, and rationality <CITATION/>.18 This is the first resource providing all three features (ElixirFm only provides functional number, and to some extent functional gender). The ElixirFM lexical resource used previously provided functional NUMBER feature values but no functional GENDER values, nor RAT (rationality, or humanness) values.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,cc91b4439d1e15fcd10bb0a2f04c6bb8f4909915,"A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality",2011,Sarah Alkuhlani; Nizar Habash
690,J91-2003,External_44421,[0],introduction,Other psycholinguistic studies that confirm the validity of paragraph units can be found in <TARGET_CITATION/> .,"These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit. Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentencecount information. Other psycholinguistic studies that confirm the validity of paragraph units can be found in <TARGET_CITATION/> . Other psycholinguistic studies that confirm the validity of paragraph units can be found in <CITATION/>. Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentencecount information. These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,the episode schema in story processingquot,1980,K Haberlandt; C Berian; J Sandson
695,W01-0706,External_2081,[0],introduction,"Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) .","to ] [NP only $ 1.8 billion ] [PP in ] [NP September] . While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) . Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,3fab92869cfab684b3ffb1c16a771e9c3b774acd,The Use of Classifiers in Sequential Inference,2001,Vasin Punyakanok; D. Roth
707,J07-1005,External_8545,[0],introduction,"Second , software for utilizing this ontology already exists : MetaMap <CITATION/> identifies concepts in free text , and SemRep <TARGET_CITATION/> extracts relations between the concepts .","This domain is wellsuited for exploring the posed research questions for several reasons. First, substantial understanding of the domain has already been codified in the Unified Medical Language System (UMLS) <CITATION/>. Second , software for utilizing this ontology already exists : MetaMap <CITATION/> identifies concepts in free text , and SemRep <TARGET_CITATION/> extracts relations between the concepts . Second, software for utilizing this ontology already exists: MetaMap <CITATION/> identifies concepts in free text, and SemRep <CITATION/> extracts relations between the concepts. First, substantial understanding of the domain has already been codified in the Unified Medical Language System (UMLS) <CITATION/>. This domain is wellsuited for exploring the posed research questions for several reasons.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,30bafa2d2f9dbe9e89c0efae1e4571809d383328,The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text,2003,Thomas C. Rindflesch; M. Fiszman
710,W05-0709,External_42603,[2],conclusion,"These types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the <TARGET_CITATION/> Arabic data .","The row marked with Truth'' represents the results with true'' mentions while the row marked with System'' represents that mentions are detected by the system. Numbers under ECMF'' are EntityConstrainedMention Fmeasure and numbers under ACEVal'' are ACEvalues. These types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the <TARGET_CITATION/> Arabic data . These types of features result in an improvement in both the mention detection and coreference resolution performance, as shown through experiments on the ACE 2004 Arabic data. Numbers under ECMF'' are EntityConstrainedMention Fmeasure and numbers under ACEVal'' are ACEvalues. The row marked with Truth'' represents the results with true'' mentions while the row marked with System'' represents that mentions are detected by the system.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,99757327b6169ce8d037de1ef9a20ba3f760f829,Automatic Content Extraction for Designing a French Clinical Corpus,2014,Louise Deléger; Cyril Grouin; Aurélie Névéol
727,J13-1008,P05-1071,[2],related work,"Therefore , we repeated the experiments with POS tags predicted by the MADA toolkit <TARGET_CITATION/> 15 ( see Table 2 , 14 Some parsers predict POS tags internally , instead of receiving them as input , but this is not the case in this article .","But in practice, POS tags are annotated by automatic taggers, so parsers get predicted POS tags as input, as opposed to gold (humanannotated) tags.14 The more informative the tag set, the less accurate the tag prediction might be, so the effect on overall parsing quality is unclear. Put differently, we are interested in the tradeoff between relevance and accuracy. Therefore , we repeated the experiments with POS tags predicted by the MADA toolkit <TARGET_CITATION/> 15 ( see Table 2 , 14 Some parsers predict POS tags internally , instead of receiving them as input , but this is not the case in this article . Therefore, we repeated the experiments with POS tags predicted by the MADA toolkit <CITATION/>15 (see Table 2, 14 Some parsers predict POS tags internally, instead of receiving them as input, but this is not the case in this article. Put differently, we are interested in the tradeoff between relevance and accuracy. But in practice, POS tags are annotated by automatic taggers, so parsers get predicted POS tags as input, as opposed to gold (humanannotated) tags.14 The more informative the tag set, the less accurate the tag prediction might be, so the effect on overall parsing quality is unclear.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,dd12392e21999ff795eed1f80a234f92fe045570,"Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop",2005,Nizar Habash; Owen Rambow
734,E12-1068,W11-2129,[2],related work,"We follow <TARGET_CITATION/> , for compound merging .","<CITATION/> used a simple, listbased merging approach, merging all consecutive words included in a merging list. This approach resulted in too many compounds. We follow <TARGET_CITATION/> , for compound merging . We follow <CITATION/>, for compound merging. This approach resulted in too many compounds. <CITATION/> used a simple, listbased merging approach, merging all consecutive words included in a merging list.",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,320e8429092f89ccc67a94cad75622d958c6313f,Productive Generation of Compound Words in Statistical Machine Translation,2011,Sara Stymne; Nicola Cancedda
737,J13-1008,J08-4003,[2],related work,"For statistical significance , we use McNemar 's test on nongold LAS , as implemented by Nilsson and <TARGET_CITATION/> .","All results are reported mainly in terms of labeled attachment accuracy score (the parent word and the type of dependency relation to it, abbreviated as LAS), which is also used for greedy (hillclimbing) decisions for feature combination. Unlabeled attachment accuracy score (UAS) and label accuracy (dependency relation regardless of parent, LS) are also given. For statistical significance , we use McNemar 's test on nongold LAS , as implemented by Nilsson and <TARGET_CITATION/> . For statistical significance, we use McNemar's test on nongold LAS, as implemented by <CITATION/>. Unlabeled attachment accuracy score (UAS) and label accuracy (dependency relation regardless of parent, LS) are also given. All results are reported mainly in terms of labeled attachment accuracy score (the parent word and the type of dependency relation to it, abbreviated as LAS), which is also used for greedy (hillclimbing) decisions for feature combination.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,053f1cf10ced2321c1853f307075f0a6a83b6840,Algorithms for Deterministic Incremental Dependency Parsing,2008,Joakim Nivre
741,E12-1068,W10-1705,[4],related work,<TARGET_CITATION/> improved on this by marking prepositions with the case they mark ( one of the most important markups in our system ) .,We use more complex context features. <CITATION/> tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms. <TARGET_CITATION/> improved on this by marking prepositions with the case they mark ( one of the most important markups in our system ) . <CITATION/> improved on this by marking prepositions with the case they mark (one of the most important markups in our system). <CITATION/> tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms. We use more complex context features.,d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,fab7c3326048ce861be389ebda5301f733ad63f2,2010 Failures in English-Czech Phrase-Based MT,2010,Ondrej Bojar; K. Kos
753,J07-1005,External_52486,[2],,"ear regression adapted for classification <TARGET_CITATION/> , which can be described by the following equation :","The second involved a more principled method using confidence values generated by the base classifiers and least squares lin4 http://mallet.cs.umass.edu/ ear regression adapted for classification <TARGET_CITATION/> , which can be described by the following equation : ear regression adapted for classification <CITATION/>, which can be described by the following equation:4 http://mallet.cs.umass.edu/The second involved a more principled method using confidence values generated by the base classifiers and least squares lin",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,5d5a28ea30e03398f7867ac7ef79dd497fb67864,Issues in Stacked Generalization,2011,K. Ting; I. Witten
762,W01-0706,External_2309,[0],introduction,"Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text <TARGET_CITATION/> .","Shallow parsing is studied as an alternative to fullsentence parsing. Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text <TARGET_CITATION/> . Rather than producing a complete analysis of sentences, the alternative is to perform only partial analysis of the syntactic structures in a text <CITATION/>. Shallow parsing is studied as an alternative to fullsentence parsing.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,56d7826f3afaa374077f87ca3529709b1ca7e044,Parsing By Chunks,1991,Steven P. Abney
763,J07-1005,W04-0509,[4],related work,The feasibility of automatically identifying outcome statements in secondary sources has been demonstrated by <TARGET_CITATION/> .,"PICObased querying in information retrieval is merely an instance of faceted querying, which has been widely used by librarians since the introduction of automated retrieval systems <CITATION/>. The work of <CITATION/> demonstrates that faceted queries can be converted into simple filtering constraints to boost precision. The feasibility of automatically identifying outcome statements in secondary sources has been demonstrated by <TARGET_CITATION/> . The feasibility of automatically identifying outcome statements in secondary sources has been demonstrated by <CITATION/>. The work of <CITATION/> demonstrates that faceted queries can be converted into simple filtering constraints to boost precision. PICObased querying in information retrieval is merely an instance of faceted querying, which has been widely used by librarians since the introduction of automated retrieval systems <CITATION/>.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,bea44eadbc3e380835df1701251c6aa89d03fe0c,Analysis of Semantic Classes in Medical Text for Question Answering,2004,Yun Niu; Graeme Hirst
764,J10-3007,External_3667,[4],,The standard approach is to train two models independently and then intersect their predictions <TARGET_CITATION/> .,"The directional nature of the generative models used to recover word alignments conflicts with their interpretation as translations. In practice, we see that the choice of which language is source versus target matters and changes the mistakes made by the model (the first row of panels in Figure 1). The standard approach is to train two models independently and then intersect their predictions <TARGET_CITATION/> . The standard approach is to train two models independently and then intersect their predictions <CITATION/>. In practice, we see that the choice of which language is source versus target matters and changes the mistakes made by the model (the first row of panels in Figure 1). The directional nature of the generative models used to recover word alignments conflicts with their interpretation as translations.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,de2df29b0a0312de7270c3f5a0af6af5645cf91a,A Systematic Comparison of Various Statistical Alignment Models,2003,F. Och; H. Ney
771,J07-1005,External_2736,[0],introduction,"Second , software for utilizing this ontology already exists : MetaMap <TARGET_CITATION/> identifies concepts in free text , and SemRep <CITATION/> extracts relations between the concepts .","This domain is wellsuited for exploring the posed research questions for several reasons. First, substantial understanding of the domain has already been codified in the Unified Medical Language System (UMLS) <CITATION/>. Second , software for utilizing this ontology already exists : MetaMap <TARGET_CITATION/> identifies concepts in free text , and SemRep <CITATION/> extracts relations between the concepts . Second, software for utilizing this ontology already exists: MetaMap <CITATION/> identifies concepts in free text, and SemRep <CITATION/> extracts relations between the concepts. First, substantial understanding of the domain has already been codified in the Unified Medical Language System (UMLS) <CITATION/>. This domain is wellsuited for exploring the posed research questions for several reasons.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,1406f6b5ed4034b72ed2dccc3fcfa4c5c0810924,Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program,2001,A. Aronson
781,J07-1005,External_82323,[0],related work,The work of <TARGET_CITATION/> demonstrates that faceted queries can be converted into simple filtering constraints to boost precision .,"Although originally developed as a tool to assist in query formulation, <CITATION/> pointed out that PICO frames can be employed to structure IR results for improving precision. PICObased querying in information retrieval is merely an instance of faceted querying, which has been widely used by librarians since the introduction of automated retrieval systems <CITATION/>. The work of <TARGET_CITATION/> demonstrates that faceted queries can be converted into simple filtering constraints to boost precision . The work of <CITATION/> demonstrates that faceted queries can be converted into simple filtering constraints to boost precision. PICObased querying in information retrieval is merely an instance of faceted querying, which has been widely used by librarians since the introduction of automated retrieval systems <CITATION/>. Although originally developed as a tool to assist in query formulation, <CITATION/> pointed out that PICO frames can be employed to structure IR results for improving precision.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,15696bc479adabcf0e9963b4231aa435390e2afc,Improving Full-Text Precision on Short Queries using Simple Constraints,1996,Marti A. Hearst
786,W05-0709,External_80812,[2],,"Character classes , such as punctuation , are defined according to the Unicode Standard <TARGET_CITATION/> .","We define a token and introduce whitespace boundaries between every span of one or more alphabetic or numeric characters. Each punctuation symbol is considered a separate token. Character classes , such as punctuation , are defined according to the Unicode Standard <TARGET_CITATION/> . Character classes, such as punctuation, are defined according to the Unicode Standard <CITATION/>.Each punctuation symbol is considered a separate token. We define a token and introduce whitespace boundaries between every span of one or more alphabetic or numeric characters.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,090199af5fdf09cbf067ff514244a70171034cdd,"The Unicode Standard, Version 11.0",2018,Jamo Extended-A
787,W01-0706,External_93146,[0],introduction,"Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text <TARGET_CITATION/> .","Shallow parsing is studied as an alternative to fullsentence parsing. Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text <TARGET_CITATION/> . Rather than producing a complete analysis of sentences, the alternative is to perform only partial analysis of the syntactic structures in a text <CITATION/>. Shallow parsing is studied as an alternative to fullsentence parsing.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,fed3002240ebfcfbad4ff472748f46191e17e4e0,Evaluation Techniques for Automatic Semantic Extraction: Comparing Syntactic and Window Based Approaches,1996,G. Grefenstette
788,J91-2003,External_44423,[1],introduction,"Finally , it has been shown by <CITATION/> that the ratio of derived to explicit information necessary for understanding a piece of text is about 8:1 ; furthermore , our reading of the analysis of five paragraphs by <TARGET_CITATION/> strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph .","First of all, iteration would increase the complexity of building a model of a paragraph; infinite iteration would almost certainly make impossible such a construction in real time. Secondly, the cooperative principle of Grice (1975, 1978), under the assumption that referential levels of a writer and a reader are quite similar, implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader; and this seems to imply that he should appeal only to the most direct knowledge of the reader. Finally , it has been shown by <CITATION/> that the ratio of derived to explicit information necessary for understanding a piece of text is about 8:1 ; furthermore , our reading of the analysis of five paragraphs by <TARGET_CITATION/> strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph . Finally, it has been shown by <CITATION/> that the ratio of derived to explicit information necessary for understanding a piece of text is about 8:1; furthermore, our reading of the analysis of five paragraphs by <CITATION/> strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph. Secondly, the cooperative principle of Grice (1975, 1978), under the assumption that referential levels of a writer and a reader are quite similar, implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader; and this seems to imply that he should appeal only to the most direct knowledge of the reader. First of all, iteration would increase the complexity of building a model of a paragraph; infinite iteration would almost certainly make impossible such a construction in real time.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,d99f3a684977faef51822bed1dd1eafced8f26c0,Paragraph Structure Inference,1979,E. Crothers
798,J91-2003,External_9316,[4],introduction,"The last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and 0 knowledge ( cfXXX <TARGET_CITATION/> ) .","Even if all 0 knowledge were described, as in our examples, by sets of first order theories, because of the preferences and inconsistencies of meanings, we could not treat R as a flat database of factssuch a model simply would not be realistic. Rather, R must be treated as a separate logical level for these syntactic reasons, and because of its functionbeing a pool of possibly conflicting semantic constraints. The last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and 0 knowledge ( cfXXX <TARGET_CITATION/> ) . The last point may be seen better if we look at some differences between our system and KRYPTON, which also distinguishes between an object theory and 0 knowledge (cfXXX Brachman et al. 1985). Rather, R must be treated as a separate logical level for these syntactic reasons, and because of its functionbeing a pool of possibly conflicting semantic constraints. Even if all 0 knowledge were described, as in our examples, by sets of first order theories, because of the preferences and inconsistencies of meanings, we could not treat R as a flat database of factssuch a model simply would not be realistic.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,krypton a functional approach to knowledge representationquot,1985,R J Brachman; R E Fikes; H J Levesque
801,J13-1008,External_4979,[2],related work,"For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 ( Nivre 2003 , 2008 ; Kbler , McDonald , and <TARGET_CITATION/> ) , a transitionbased parser with an input buffer and a stack , which uses SVM classifiers","For all experiments, unless specified otherwise, we used the dev set.10 We kept the test unseen (blind'') during training and model development. Statistics about this split (after conversion to the CATiB dependency format) are given in Table 1. For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 ( Nivre 2003 , 2008 ; Kbler , McDonald , and <TARGET_CITATION/> ) , a transitionbased parser with an input buffer and a stack , which uses SVM classifiers For all experiments reported in this section we used the syntactic dependency parser MaltParser v1.3 (Nivre 2003, 2008; Kbler, McDonald, and Nivre 2009), a transitionbased parser with an input buffer and a stack, which uses SVM classifiersStatistics about this split (after conversion to the CATiB dependency format) are given in Table 1. For all experiments, unless specified otherwise, we used the dev set.10 We kept the test unseen (blind'') during training and model development.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,60dad30438b1543c20ab67cf02107b4ed7250dc1,Parsing Indian Languages with MaltParser,2009,Joakim Nivre
802,J13-1008,E12-1069,[2],related work,"We conducted experiments with gold features to assess the potential of these features , and with predicted features , obtained from training a simple maximum likelihood estimation classifier on this resource <TARGET_CITATION/> .19 The first part of Table 8 shows that the RAT ( rationality ) feature is very relevant ( in gold ) , but suffers from low accuracy ( no gains in machinepredicted input ) .","The ElixirFM lexical resource used previously provided functional NUMBER feature values but no functional GENDER values, nor RAT (rationality, or humanness) values. To address this issue, we use a version of the PATB3 training and dev sets manually annotated with functional gender, number, and rationality <CITATION/>.18 This is the first resource providing all three features (ElixirFm only provides functional number, and to some extent functional gender). We conducted experiments with gold features to assess the potential of these features , and with predicted features , obtained from training a simple maximum likelihood estimation classifier on this resource <TARGET_CITATION/> .19 The first part of Table 8 shows that the RAT ( rationality ) feature is very relevant ( in gold ) , but suffers from low accuracy ( no gains in machinepredicted input ) . We conducted experiments with gold features to assess the potential of these features, and with predicted features, obtained from training a simple maximum likelihood estimation classifier on this resource <CITATION/>.19 The first part of Table 8 shows that the RAT (rationality) feature is very relevant (in gold), but suffers from low accuracy (no gains in machinepredicted input). To address this issue, we use a version of the PATB3 training and dev sets manually annotated with functional gender, number, and rationality <CITATION/>.18 This is the first resource providing all three features (ElixirFm only provides functional number, and to some extent functional gender). The ElixirFM lexical resource used previously provided functional NUMBER feature values but no functional GENDER values, nor RAT (rationality, or humanness) values.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,58fdacf0d40ddcb304536992a04fa2000022d8de,"Identifying Broken Plurals, Irregular Gender, and Rationality in Arabic Text",2012,Sarah Alkuhlani; Nizar Habash
807,J91-2003,External_83402,[4],introduction,"Similarly , the notion of R + Mabduction is spiritually related to the  abductive inference '' of <TARGET_CITATION/> , the  diagnosis from first principles '' of <CITATION/> ,  explainability '' of <CITATION/> , and the subset principle of <CITATION/> .","Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of uniquename assumption'' <CITATION/>, domain closure assumption'' (ibid.), domain circumscription'' (cfXXX Etherington and Mercer 1987), and their kin. Similarly , the notion of R + Mabduction is spiritually related to the  abductive inference '' of <TARGET_CITATION/> , the  diagnosis from first principles '' of <CITATION/> ,  explainability '' of <CITATION/> , and the subset principle of <CITATION/> . Similarly, the notion of R + Mabduction is spiritually related to the abductive inference'' of <CITATION/>, the diagnosis from first principles'' of <CITATION/>, explainability'' of <CITATION/>, and the subset principle of <CITATION/>. , domain circumscription'' (cfXXX Etherington and Mercer 1987), and their kin. Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of uniquename assumption'' <CITATION/>, domain closure assumption'' (ibid.)",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,abductive inferencequot,1985,J A Reggia
809,J13-1008,External_471,[4],experiments,"To address this inconsistency in the correspondence between inflectional features and morphemes , and inspired by <CITATION/> , we distinguish between two types of inflectional features : formbased ( a.k.a. surface , or illusory ) features and functional features .6 Most available Arabic NLP tools and resources model morphology using formbased (  surface '' ) inflectional features , and do not mark rationality ; this includes the Penn Arabic Treebank ( PATB ) <TARGET_CITATION/> , the Buckwalter morphological analyzer <CITATION/> , and tools using them such as the Morphological Analysis and Disambiguation for Arabic ( MADA ) toolkit <CITATION/> .","This irregular inflection, known as broken plural, is similar to the English mouse/mice, but is much more common in Arabic (over 50% of plurals in our training data). A similar inconsistency appears in feminine nominals that are not inflected using sound gender suffixes, for example, the feminine form of the masculine singular adjective S, l zraq+ (blue') is Abj zarqA'+ not U, jl* *zraq+ah. To address this inconsistency in the correspondence between inflectional features and morphemes , and inspired by <CITATION/> , we distinguish between two types of inflectional features : formbased ( a.k.a. surface , or illusory ) features and functional features .6 Most available Arabic NLP tools and resources model morphology using formbased (  surface '' ) inflectional features , and do not mark rationality ; this includes the Penn Arabic Treebank ( PATB ) <TARGET_CITATION/> , the Buckwalter morphological analyzer <CITATION/> , and tools using them such as the Morphological Analysis and Disambiguation for Arabic ( MADA ) toolkit <CITATION/> . To address this inconsistency in the correspondence between inflectional features and morphemes, and inspired by <CITATION/>, we distinguish between two types of inflectional features: formbased (a.k.a. surface, or illusory) features and functional features.6 Most available Arabic NLP tools and resources model morphology using formbased (surface'') inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) <CITATION/>, the Buckwalter morphological analyzer <CITATION/>, and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit <CITATION/>. A similar inconsistency appears in feminine nominals that are not inflected using sound gender suffixes, for example, the feminine form of the masculine singular adjective S, l zraq+ (blue') is Abj zarqA'+ not U, jl* *zraq+ah. This irregular inflection, known as broken plural, is similar to the English mouse/mice, but is much more common in Arabic (over 50% of plurals in our training data).",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,c2ac213982e189e4ad4c7f60608914a489ec9051,The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus,2004,M. Maamouri; Ann Bies; Tim Buckwalter; Wigdan Mekki
814,P05-3005,External_7220,[0],,The UMLS  the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM ) <TARGET_CITATION/> .,"It records gene names, symbols, and manyother attributes associated with genes and the products they encode. The UMLS  the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM ) <TARGET_CITATION/> . The UMLS  the Unified Medical Language System (UMLS) has been developed and maintained by National Library of Medicine (NLM) <CITATION/>. other attributes associated with genes and the products they encode. It records gene names, symbols, and many",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,1f1eaf19e38b541eec8a02f099e3090536a4c936,The Unified Medical Language System (UMLS): integrating biomedical terminology,2004,O. Bodenreider
817,J91-2003,P87-1021,[0],introduction,The reader may consult recent papers on this subject <TARGET_CITATION/> to see what a formal interpretation of events in time might look like .,We assume that any formal interpretation of time will agree with the intuitive one. So it is not necessary now to present a formal semantics here. The reader may consult recent papers on this subject <TARGET_CITATION/> to see what a formal interpretation of events in time might look like . The reader may consult recent papers on this subject <CITATION/> to see what a formal interpretation of events in time might look like. So it is not necessary now to present a formal semantics here. We assume that any formal interpretation of time will agree with the intuitive one.,c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,876e8b0c873d75ec516dfaf6e8027d4076eba78f,The Interpretation of Tense in Discourse,1987,B. Webber
818,E99-1022,External_24317,[0],,"Proceedings of EACL '99 example , the ALE parser <TARGET_CITATION/> presupposes a phrase structure backbone which can be used to determine whether a constraint is to be interpreted bottomup or topdown .","Combining control strategies depends on a way to differentiate between types of constraints. For Proceedings of EACL '99 example , the ALE parser <TARGET_CITATION/> presupposes a phrase structure backbone which can be used to determine whether a constraint is to be interpreted bottomup or topdown . Proceedings of EACL '99 example, the ALE parser <CITATION/> presupposes a phrase structure backbone which can be used to determine whether a constraint is to be interpreted bottomup or topdown. ForCombining control strategies depends on a way to differentiate between types of constraints.",3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,a3179ab83aaf84c8147fc24a3357c595d10687fb,"ALE : the attribute logic engine user's guide, version 2.0.1",1992,Bob Carpenter; Gerald Penn
821,J00-3001,External_244,[0],introduction,"<TARGET_CITATION/> use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .","It is common practice in information retrieval to discard the lowestfrequency words a priori as nonsignificant <CITATION/>. In Smadja's collocation algorithm Xtract, the lowestfrequency words are effectively discarded as well <CITATION/>. <TARGET_CITATION/> use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five . <CITATION/> use mutual information to identify collocations, a method they claim is reasonably effective for words with a frequency of not less than five. In Smadja's collocation algorithm Xtract, the lowestfrequency words are effectively discarded as well <CITATION/>. It is common practice in information retrieval to discard the lowestfrequency words a priori as nonsignificant <CITATION/>.",886dffd5b9d41c77365fb3893dd05f2067862d13,Extracting the lowest-frequency words: pitfalls and possibilities,2000,M. Weeber; R. Vos; R. Baayen,9e2caa39ac534744a180972a30a320ad0ae41ea3,"Word Association Norms, Mutual Information, and Lexicography",1989,Kenneth Ward Church; Patrick Hanks
824,E99-1022,P96-1033,[0],introduction,"As shown in <TARGET_CITATION/>  The presented research was carried out at the University of Tubingen , Germany , as part of the Sonderforschungsbereich 340 .","Magic is a compilation technique originally developed for goaldirected bottomup processing of logic programs. See, among others, <CITATION/>. As shown in <TARGET_CITATION/>  The presented research was carried out at the University of Tubingen , Germany , as part of the Sonderforschungsbereich 340 . As shown in <CITATION/> The presented research was carried out at the University of Tubingen, Germany, as part of the Sonderforschungsbereich 340. See, among others, <CITATION/>. Magic is a compilation technique originally developed for goaldirected bottomup processing of logic programs.",3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,c02a5310d5f90980841801b4dfe178aba9875bd3,Magic for Filter Optimization in Dynamic Bottom-up Processing,1996,Guido Minnen
825,J91-2003,External_18434,[0],introduction,"According to <TARGET_CITATION/> , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases .","He lists, classifies, and discusses various types of inference, by which he means, generally, the linguisticlogical notions of consequent and presupposition'' Crothers (1979:112) have collected convincing evidence of the existence of language chunksreal structures, not just orthographic conventionsthat are smaller than a discourse, larger than a sentence, generally composed of sentences, and recursive in nature (like sentences). These chunks are sometimes called episodes,'' and sometimes paragraphs.'' According to <TARGET_CITATION/> , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases . According to <CITATION/>, paragraphs are made up of segments, which in turn are made up of sentences or clauses, which in turn are made up of phrases. These chunks are sometimes called episodes,'' and sometimes paragraphs.'' He lists, classifies, and discusses various types of inference, by which he means, generally, the linguisticlogical notions of consequent and presupposition'' Crothers (1979:112) have collected convincing evidence of the existence of language chunksreal structures, not just orthographic conventionsthat are smaller than a discourse, larger than a sentence, generally composed of sentences, and recursive in nature (like sentences).",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,organizational patterns in discoursequot,1979,J Hinds
826,J91-2003,External_83403,[4],introduction,"Similarly , the notion of R + Mabduction is spiritually related to the  abductive inference '' of <CITATION/> , the  diagnosis from first principles '' of <TARGET_CITATION/> ,  explainability '' of <CITATION/> , and the subset principle of <CITATION/> .","Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of uniquename assumption'' <CITATION/>, domain closure assumption'' (ibid.), domain circumscription'' (cfXXX Etherington and Mercer 1987), and their kin. Similarly , the notion of R + Mabduction is spiritually related to the  abductive inference '' of <CITATION/> , the  diagnosis from first principles '' of <TARGET_CITATION/> ,  explainability '' of <CITATION/> , and the subset principle of <CITATION/> . Similarly, the notion of R + Mabduction is spiritually related to the abductive inference'' of <CITATION/>, the diagnosis from first principles'' of <CITATION/>, explainability'' of <CITATION/>, and the subset principle of <CITATION/>. , domain circumscription'' (cfXXX Etherington and Mercer 1987), and their kin. Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of uniquename assumption'' <CITATION/>, domain closure assumption'' (ibid.)",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,a theory of diagnosis from first principlesquot,1987,R Reiter
856,E12-1068,E03-1076,[4],related work,"Other approaches use less deep linguistic resources ( e.g. , POStags <CITATION/> ) or are ( almost ) knowledgefree <TARGET_CITATION/> .","Using additional source side information beyond the markup did not produce a gain in performance. For compound splitting, we follow <CITATION/>, using linguistic knowledge encoded in a rulebased morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies. Other approaches use less deep linguistic resources ( e.g. , POStags <CITATION/> ) or are ( almost ) knowledgefree <TARGET_CITATION/> . Other approaches use less deep linguistic resources (e.g., POStags <CITATION/>) or are (almost) knowledgefree (e.g., <CITATION/>). For compound splitting, we follow <CITATION/>, using linguistic knowledge encoded in a rulebased morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies. Using additional source side information beyond the markup did not produce a gain in performance.",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,cdaae7a8f0db8b280266606004f1c6f164a13f6d,Empirical Methods for Compound Splitting,2003,Philipp Koehn; Kevin Knight
862,E12-1068,W11-2126,[4],related work,<TARGET_CITATION/> used unification in an SMT system to model some of the,<CITATION/> improved on this by marking prepositions with the case they mark (one of the most important markups in our system). Both efforts were ineffective on large data sets. <TARGET_CITATION/> used unification in an SMT system to model some of the <CITATION/> used unification in an SMT system to model some of theBoth efforts were ineffective on large data sets. <CITATION/> improved on this by marking prepositions with the case they mark (one of the most important markups in our system).,d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,03a7130ef80c52555d1c2a27bba5eac628428adc,Agreement Constraints for Statistical Machine Translation into German,2011,Philip Williams; Philipp Koehn
872,J08-2002,External_63,[4],introduction,"Our reranking approach , like the approach to parse reranking of <TARGET_CITATION/> , employs a simpler model  a local semantic role labeling algorithm  as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes .","To tackle the efficiency problem, we adopt dynamic programming and reranking algorithms. To avoid overfitting we encode only a small set of linguistically motivated dependencies in features over sets of the random variables. Our reranking approach , like the approach to parse reranking of <TARGET_CITATION/> , employs a simpler model  a local semantic role labeling algorithm  as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes . Our reranking approach, like the approach to parse reranking of <CITATION/>, employs a simpler modela local semantic role labeling algorithmas a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes. To avoid overfitting we encode only a small set of linguistically motivated dependencies in features over sets of the random variables. To tackle the efficiency problem, we adopt dynamic programming and reranking algorithms.",7ed7a41c275f2870b840a5e6c3eaec8888c9480c,A Global Joint Model for Semantic Role Labeling,2008,Kristina Toutanova; A. Haghighi; Christopher D. Manning,844db702be4bc149b06b822b47247e15f5894cc3,Discriminative Reranking for Natural Language Parsing,2000,M. Collins; Terry Koo
876,W01-0706,External_12855,[0],introduction,"First , it has been noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many largescale language processing applications including information extraction and text summarization <TARGET_CITATION/> .","Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). Research on shallow parsing was inspired by psycholinguistics arguments <CITATION/> that suggest that in many scenarios (e.g., conversational) full parsing is not a realistic strategy for sentence processing and analysis, and was further motivated by several arguments from a natural language engineering viewpoint. First , it has been noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many largescale language processing applications including information extraction and text summarization <TARGET_CITATION/> . First, it has been noted that in many natural language applications it is sufficient to use shallow parsing information; information such as noun phrases (NPs) and other syntactic sequences have been found useful in many largescale language processing applications including information extraction and text summarization <CITATION/>. Research on shallow parsing was inspired by psycholinguistics arguments <CITATION/> that suggest that in many scenarios (e.g., conversational) full parsing is not a realistic strategy for sentence processing and analysis, and was further motivated by several arguments from a natural language engineering viewpoint. Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>).",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,,fastus a finitestate processor for information extraction from realworld text,1993,D Appelt; J Hobbs; J Bear; D Israel; M Tyson
887,W01-0706,W00-0726,[2],experiments,"Since earlier versions of the SNoW based CSCL were used only to identify single phrases <CITATION/> and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL2000 ( Tjong Kim <TARGET_CITATION/> ) to compare it to other shallow parsers .","Indeed, in CSCL (constraint satisfaction with classifiers), SNoW is used to learn several different classifiers  each detects the beginning or end of a phrase of some type (noun phrase, verb phrase, etc.). The outcomes of these classifiers are then combined in a way that satisfies some constraints  nonoverlapping constraints in this case  using an efficient constraint satisfaction mechanism that makes use of the confidence in the classifier's outcomes. Since earlier versions of the SNoW based CSCL were used only to identify single phrases <CITATION/> and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL2000 ( Tjong Kim <TARGET_CITATION/> ) to compare it to other shallow parsers . Since earlier versions of the SNoW based CSCL were used only to identify single phrases <CITATION/> and never to identify a collection of several phrases at the same time, as we do here, we also trained and tested it under the exact conditions of CoNLL2000 (Tjong Kim <CITATION/>) to compare it to other shallow parsers. The outcomes of these classifiers are then combined in a way that satisfies some constraints  nonoverlapping constraints in this case  using an efficient constraint satisfaction mechanism that makes use of the confidence in the classifier's outcomes. Indeed, in CSCL (constraint satisfaction with classifiers), SNoW is used to learn several different classifiers  each detects the beginning or end of a phrase of some type (noun phrase, verb phrase, etc.).",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,9e85832b04cc3700c2c26d6ba93fdeae39cac04a,Introduction to the CoNLL-2000 Shared Task Chunking,2000,E. Tjong Kim Sang; S. Buchholz
897,J13-1008,P05-1071,[4],experiments,"To address this inconsistency in the correspondence between inflectional features and morphemes , and inspired by <CITATION/> , we distinguish between two types of inflectional features : formbased ( a.k.a. surface , or illusory ) features and functional features .6 Most available Arabic NLP tools and resources model morphology using formbased (  surface '' ) inflectional features , and do not mark rationality ; this includes the Penn Arabic Treebank ( PATB ) <CITATION/> , the Buckwalter morphological analyzer <CITATION/> , and tools using them such as the Morphological Analysis and Disambiguation for Arabic ( MADA ) toolkit <TARGET_CITATION/> .","This irregular inflection, known as broken plural, is similar to the English mouse/mice, but is much more common in Arabic (over 50% of plurals in our training data). A similar inconsistency appears in feminine nominals that are not inflected using sound gender suffixes, for example, the feminine form of the masculine singular adjective S, l zraq+ (blue') is Abj zarqA'+ not U, jl* *zraq+ah. To address this inconsistency in the correspondence between inflectional features and morphemes , and inspired by <CITATION/> , we distinguish between two types of inflectional features : formbased ( a.k.a. surface , or illusory ) features and functional features .6 Most available Arabic NLP tools and resources model morphology using formbased (  surface '' ) inflectional features , and do not mark rationality ; this includes the Penn Arabic Treebank ( PATB ) <CITATION/> , the Buckwalter morphological analyzer <CITATION/> , and tools using them such as the Morphological Analysis and Disambiguation for Arabic ( MADA ) toolkit <TARGET_CITATION/> . To address this inconsistency in the correspondence between inflectional features and morphemes, and inspired by <CITATION/>, we distinguish between two types of inflectional features: formbased (a.k.a. surface, or illusory) features and functional features.6 Most available Arabic NLP tools and resources model morphology using formbased (surface'') inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) <CITATION/>, the Buckwalter morphological analyzer <CITATION/>, and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit <CITATION/>. A similar inconsistency appears in feminine nominals that are not inflected using sound gender suffixes, for example, the feminine form of the masculine singular adjective S, l zraq+ (blue') is Abj zarqA'+ not U, jl* *zraq+ah. This irregular inflection, known as broken plural, is similar to the English mouse/mice, but is much more common in Arabic (over 50% of plurals in our training data).",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,dd12392e21999ff795eed1f80a234f92fe045570,"Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop",2005,Nizar Habash; Owen Rambow
901,J13-1008,P09-2056,[2],experiments,"The following are the various tag sets we use in this article : ( a ) the core POS tag sets CORE44 and the newly introduced CORE12 ; ( b ) CATiB Treebank tag set ( CATIB6 ) <TARGET_CITATION/> and its newly introduced extension of CATIBEX created using simple regular expressions on word form , indicating particular morphemes such as the prefix JI Al + or the suffix v ' + wn ; this tag set is the bestperforming tag set for Arabic on predicted values as reported in Section 4 ; ( c ) the PATB full tag set with complete morphological tag ( BW ) <CITATION/> ; and two extensions of the PATB reduced tag set ( PENN POS , a.k.a. RTS , size 24 [ Diab , Hacioglu , and Jurafsky 2004 ] ) , both outperforming it : ( d ) <CITATION/> 's tag set ( KULICK ) , size 43 , one of whose most important extensions is the marking of the definite article clitic , and ( e ) Diab and Benajiba 's ( in preparation ) EXTENDED RTS tag set ( ERTS ) , which marks gender , number , and definiteness , size 134 .","These tag sets are hybrids in the sense that they are neither simply the core POS, nor the complete morphologically enriched tag set, but instead they selectively enrich the core POS tag set with only certain morphological features. A more detailed discussion of the various available Arabic tag sets can be found in <CITATION/>. The following are the various tag sets we use in this article : ( a ) the core POS tag sets CORE44 and the newly introduced CORE12 ; ( b ) CATiB Treebank tag set ( CATIB6 ) <TARGET_CITATION/> and its newly introduced extension of CATIBEX created using simple regular expressions on word form , indicating particular morphemes such as the prefix JI Al + or the suffix v ' + wn ; this tag set is the bestperforming tag set for Arabic on predicted values as reported in Section 4 ; ( c ) the PATB full tag set with complete morphological tag ( BW ) <CITATION/> ; and two extensions of the PATB reduced tag set ( PENN POS , a.k.a. RTS , size 24 [ Diab , Hacioglu , and Jurafsky 2004 ] ) , both outperforming it : ( d ) <CITATION/> 's tag set ( KULICK ) , size 43 , one of whose most important extensions is the marking of the definite article clitic , and ( e ) Diab and Benajiba 's ( in preparation ) EXTENDED RTS tag set ( ERTS ) , which marks gender , number , and definiteness , size 134 . The following are the various tag sets we use in this article: (a) the core POS tag sets CORE44 and the newly introduced CORE12; (b) CATiB Treebank tag set (CATIB6) <CITATION/> and its newly introduced extension of CATIBEX created using simple regular expressions on word form, indicating particular morphemes such as the prefix JI Al+ or the suffix v' +wn; this tag set is the bestperforming tag set for Arabic on predicted values as reported in Section 4; (c) the PATB full tag set with complete morphological tag (BW) <CITATION/>; and two extensions of the PATB reduced tag set (PENN POS, a.k.a. RTS, size 24 [Diab, Hacioglu, and Jurafsky 2004]), both outperforming it: (d) <CITATION/>'s tag set (KULICK), size 43, one of whose most important extensions is the marking of the definite article clitic, and (e) Diab and Benajiba's (in preparation) EXTENDED RTS tag set (ERTS), which marks gender, number, and definiteness, size 134.A more detailed discussion of the various available Arabic tag sets can be found in <CITATION/>. These tag sets are hybrids in the sense that they are neither simply the core POS, nor the complete morphologically enriched tag set, but instead they selectively enrich the core POS tag set with only certain morphological features.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,25f60908cc3613ddca64638bc9aa119f4c55e78a,CATiB: The Columbia Arabic Treebank,2009,Nizar Habash; Ryan Roth
907,J13-1008,External_1438,[4],experiments,"To address this inconsistency in the correspondence between inflectional features and morphemes , and inspired by <CITATION/> , we distinguish between two types of inflectional features : formbased ( a.k.a. surface , or illusory ) features and functional features .6 Most available Arabic NLP tools and resources model morphology using formbased (  surface '' ) inflectional features , and do not mark rationality ; this includes the Penn Arabic Treebank ( PATB ) <CITATION/> , the Buckwalter morphological analyzer <TARGET_CITATION/> , and tools using them such as the Morphological Analysis and Disambiguation for Arabic ( MADA ) toolkit <CITATION/> .","This irregular inflection, known as broken plural, is similar to the English mouse/mice, but is much more common in Arabic (over 50% of plurals in our training data). A similar inconsistency appears in feminine nominals that are not inflected using sound gender suffixes, for example, the feminine form of the masculine singular adjective S, l zraq+ (blue') is Abj zarqA'+ not U, jl* *zraq+ah. To address this inconsistency in the correspondence between inflectional features and morphemes , and inspired by <CITATION/> , we distinguish between two types of inflectional features : formbased ( a.k.a. surface , or illusory ) features and functional features .6 Most available Arabic NLP tools and resources model morphology using formbased (  surface '' ) inflectional features , and do not mark rationality ; this includes the Penn Arabic Treebank ( PATB ) <CITATION/> , the Buckwalter morphological analyzer <TARGET_CITATION/> , and tools using them such as the Morphological Analysis and Disambiguation for Arabic ( MADA ) toolkit <CITATION/> . To address this inconsistency in the correspondence between inflectional features and morphemes, and inspired by <CITATION/>, we distinguish between two types of inflectional features: formbased (a.k.a. surface, or illusory) features and functional features.6 Most available Arabic NLP tools and resources model morphology using formbased (surface'') inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) <CITATION/>, the Buckwalter morphological analyzer <CITATION/>, and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit <CITATION/>. A similar inconsistency appears in feminine nominals that are not inflected using sound gender suffixes, for example, the feminine form of the masculine singular adjective S, l zraq+ (blue') is Abj zarqA'+ not U, jl* *zraq+ah. This irregular inflection, known as broken plural, is similar to the English mouse/mice, but is much more common in Arabic (over 50% of plurals in our training data).",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,,buckwalter arabic morphological analyzer version 20 linguistic data consortium,2004,Timothy A Buckwalter
908,J91-2003,External_44425,[4],introduction,"Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ; <TARGET_CITATION/> ; PatelSchneider 1985 ) .","Form(F). 0 is a ground instance of a formula 0, if 0 contains no variables, and 0 = 00, for some substitution O. Thus, we do not require Th(T) to be closed under substitution instances of tautologies. Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ; <TARGET_CITATION/> ; PatelSchneider 1985 ) . Although in this paper we take modus ponens as the main rule of inference, in general one can consider deductive closures with respect to weaker, nonstandard logics, (cfXXX Levesque 1984; Frisch 1987; PatelSchneider 1985). 0 is a ground instance of a formula 0, if 0 contains no variables, and 0 = 00, for some substitution O. Thus, we do not require Th(T) to be closed under substitution instances of tautologies. Form(F).",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,inference without chainingquot,1987,A Frisch
914,J91-2003,External_76363,[4],introduction,"This means that natural language expressions such as  A is B , ''  A is the same as B , '' etc. are not directly represented by logical equality ; similarly ,  not '' is often not treated as logical negation ; cfXXX <TARGET_CITATION/> .","Unless explicitly stated otherwise, we assume that formulas are expressed in a certain (formal) language L without equality; the extension L(=RRB of L is going to be used only in Section 5 for dealing with noun phrase references. This means that natural language expressions such as  A is B , ''  A is the same as B , '' etc. are not directly represented by logical equality ; similarly ,  not '' is often not treated as logical negation ; cfXXX <TARGET_CITATION/> . This means that natural language expressions such as A is B,'' A is the same as B,'' etc. are not directly represented by logical equality; similarly, not'' is often not treated as logical negation; cfXXX <CITATION/>. Unless explicitly stated otherwise, we assume that formulas are expressed in a certain (formal) language L without equality; the extension L(=RRB of L is going to be used only in Section 5 for dealing with noun phrase references.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,920490d2fa02d9b13fdc38c2ac83fbdc7cf2ae0f,The Game Of Language,1983,J. Hintikka
916,J13-1008,W06-2920,[0],related work,"As for work on Arabic ( MSA ) , results have been reported on the PATB <CITATION/> , the Prague Dependency Treebank ( PADT ) <TARGET_CITATION/> and the CATiB <CITATION/> .","We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima'an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic ( MSA ) , results have been reported on the PATB <CITATION/> , the Prague Dependency Treebank ( PADT ) <TARGET_CITATION/> and the CATiB <CITATION/> . As for work on Arabic (MSA), results have been reported on the PATB <CITATION/>, the Prague Dependency Treebank (PADT) <CITATION/> and the CATiB <CITATION/>. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima'an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. We also find that the number feature helps for Arabic.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,1deed1a4a03e07aee3b8b8e4716f35033c715a57,CoNLL-X Shared Task on Multilingual Dependency Parsing,2006,S. Buchholz; E. Marsi
918,W01-0706,W99-0621,[0],introduction,"Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) .","to ] [NP only $ 1.8 billion ] [PP in ] [NP September] . While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) . Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,a31d6f597f78599c6df66dedf64cd5bc05c5327a,A Learning Approach to Shallow Parsing,1999,Marcia Muñoz; Vasin Punyakanok; D. Roth; Dav Zimak
930,W05-0709,External_87917,[0],introduction,It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <TARGET_CITATION/> .,"In addition to the different forms of the Arabic word that result from thederivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <TARGET_CITATION/> . It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <CITATION/>. derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. In addition to the different forms of the Arabic word that result from the",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,,empirical studies in strategies for arabic information retrieval,2002,J Xu; A Fraser; R Weischedel
932,J13-1008,External_4979,[1],introduction,"It has been more difficult showing that agreement morphology helps parsing , however , with negative results for dependency parsing in several languages <TARGET_CITATION/> .","In the past, it has been shown that if we can recognize the relevant morphological features in assignment configurations well enough, then they contribute to parsing accuracy. For example, modeling CASE in Czech improves Czech parsing <CITATION/>: CASE is relevant, not redundant, and can be predicted with sufficient accuracy. It has been more difficult showing that agreement morphology helps parsing , however , with negative results for dependency parsing in several languages <TARGET_CITATION/> . It has been more difficult showing that agreement morphology helps parsing, however, with negative results for dependency parsing in several languages <CITATION/>. For example, modeling CASE in Czech improves Czech parsing <CITATION/>: CASE is relevant, not redundant, and can be predicted with sufficient accuracy. In the past, it has been shown that if we can recognize the relevant morphological features in assignment configurations well enough, then they contribute to parsing accuracy.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,60dad30438b1543c20ab67cf02107b4ed7250dc1,Parsing Indian Languages with MaltParser,2009,Joakim Nivre
936,W01-0706,External_5861,[0],introduction,"However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time <TARGET_CITATION/> .","Finally, the hope behind this research direction was that this incremental and modular processing might result in more robust parsing decisions, especially in cases of spoken language or other cases in which the quality of the natural language inputs is low sentences which may have repeated words, missing words, or any other lexical and syntactic mistakes. Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability. However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time <TARGET_CITATION/> . However, since work in this direction has started, a significant progress has also been made in the research on statistical learning of full parsers, both in terms of accuracy and processing time <CITATION/>. Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability. Finally, the hope behind this research direction was that this incremental and modular processing might result in more robust parsing decisions, especially in cases of spoken language or other cases in which the quality of the natural language inputs is low sentences which may have repeated words, missing words, or any other lexical and syntactic mistakes.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,54c846ee00c6132d70429cc279e8577f63ed05e4,A Linear Observed Time Statistical Parser Based on Maximum Entropy Models,1997,A. Ratnaparkhi
940,J10-3007,External_2512,[2],introduction,"EM maximizes G ( 0 ) via blockcoordinate ascent on a lower bound F ( q , 0 ) using an auxiliary distribution over the latent variables q ( z  x , y ) <TARGET_CITATION/> :","where E [ f (x, y)] = N n 1 f (xn, yn) denotes the empirical average of a function f (xn, yn ) over the N pairs of sentences LCB(x1,y1)   ,(xN,yN)RCB in the training corpus. Because of the latent alignment variables z, the loglikelihood function for the HMM model is not concave, and the model is fit using the Expectation Maximization (EM) algorithm <CITATION/>. EM maximizes G ( 0 ) via blockcoordinate ascent on a lower bound F ( q , 0 ) using an auxiliary distribution over the latent variables q ( z  x , y ) <TARGET_CITATION/> : EM maximizes G(0) via blockcoordinate ascent on a lower bound F(q, 0) using an auxiliary distribution over the latent variables q(z  x, y) <CITATION/>:Because of the latent alignment variables z, the loglikelihood function for the HMM model is not concave, and the model is fit using the Expectation Maximization (EM) algorithm <CITATION/>. where E [ f (x, y)] = N n 1 f (xn, yn) denotes the empirical average of a function f (xn, yn ) over the N pairs of sentences LCB(x1,y1)   ,(xN,yN)RCB in the training corpus.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,9f87a11a523e4680e61966e36ea2eac516096f23,"A View of the Em Algorithm that Justifies Incremental, Sparse, and other Variants",1998,Radford M. Neal; Geoffrey E. Hinton
948,D08-1016,P08-1108,[5],conclusion,"For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrasestructure and lattice parsing , and in trying other higherorder features , such as those used in parse reranking <CITATION/> and historybased parsing <TARGET_CITATION/> .","Belief propagation improves nonprojective dependency parsing with features that would make exact inference intractable. For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrasestructure and lattice parsing , and in trying other higherorder features , such as those used in parse reranking <CITATION/> and historybased parsing <TARGET_CITATION/> . For projective parsing, it is significantly faster than exact dynamic programming, at the cost of small amounts of search error, We are interested in extending these ideas to phrasestructure and lattice parsing, and in trying other higherorder features, such as those used in parse reranking <CITATION/> and historybased parsing <CITATION/>. Belief propagation improves nonprojective dependency parsing with features that would make exact inference intractable.",ebbb58b2e616435b6ededbc103acfef6dc79bd51,Dependency Parsing by Belief Propagation,2008,David A. Smith; Jason Eisner,dccaa989317fd4f9060cff04a0a94e63176359dd,Integrating Graph-Based and Transition-Based Dependency Parsers,2008,Joakim Nivre; Ryan T. McDonald
949,W05-0709,P04-1018,[4],,The coreference system system is similar to the Bell tree algorithm as described by <TARGET_CITATION/> .,"For example, in the following text, (I) John believes Mary to be the best student'' three mentions John'', Mary'', student'' are underlined. Mary'' and student'' are in the same entity since both refer to the same person. The coreference system system is similar to the Bell tree algorithm as described by <TARGET_CITATION/> . The coreference system system is similar to the Bell tree algorithm as described by <CITATION/>. Mary'' and student'' are in the same entity since both refer to the same person. For example, in the following text, (I) John believes Mary to be the best student'' three mentions John'', Mary'', student'' are underlined.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,4f8dd94c1a1454cc34475a4f533e137c7e4afd8d,A Mention-Synchronous Coreference Resolution Algorithm Based On the Bell Tree,2004,Xiaoqiang Luo; Abraham Ittycheriah; Hongyan Jing; N. Kambhatla; S. Roukos
963,P05-3005,External_7092,[0],introduction,"With the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible <TARGET_CITATION/> ."," With the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible <TARGET_CITATION/> . With the use of computers in storing the explosive amount of biological information, natural language processing (NLP) approaches have been explored to make the task of managing information recorded in free text more feasible <CITATION/>.",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,05ee0ead715d89cfa71768a975946d0c17f3b303,Mining the Biomedical Literature in the Genomic Era: An Overview,2003,H. Shatkay; Ronen Feldman
964,J91-2003,External_76184,[4],introduction,"A formula q5 of L ( =RRB , the language with equality , is weakly R + Mabductible from an object theory T , denoted by T IR + m 0 , iff there exists a partial theory T e PT ( T ) and a preferred model M E PM ( T ) such that M = 0 , i.e. 0 is true in at least one preferred model of the partial theory T. Note : The notions of strong provability and strong R + Mabduction can be introduced by replacing  there exists '' by  all '' in the above definitions ( cfXXX <TARGET_CITATION/> ) .","A preferred model of a theory T is an element of Mods(T) that satisfies metalevel constraints contained in M. The set of all preferred models of T is denoted by PM(T). A formula q5 of L ( =RRB , the language with equality , is weakly R + Mabductible from an object theory T , denoted by T IR + m 0 , iff there exists a partial theory T e PT ( T ) and a preferred model M E PM ( T ) such that M = 0 , i.e. 0 is true in at least one preferred model of the partial theory T. Note : The notions of strong provability and strong R + Mabduction can be introduced by replacing  there exists '' by  all '' in the above definitions ( cfXXX <TARGET_CITATION/> ) . A formula q5 of L(=RRB, the language with equality, is weakly R+ Mabductible from an object theory T, denoted by T IR+m 0, iff there exists a partial theory T e PT(T) and a preferred model M E PM(T) such that M =0, i.e. 0 is true in at least one preferred model of the partial theory T. Note: The notions of strong provability and strong R + Mabduction can be introduced by replacing there exists'' by all'' in the above definitions (cfXXX Zadrozny 1987b). The set of all preferred models of T is denoted by PM(T). A preferred model of a theory T is an element of Mods(T) that satisfies metalevel constraints contained in M.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,intended models circumscription and commonsense reasoningquot,1987,W Zadrozny
969,P05-3005,External_95861,[2],,"Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <TARGET_CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> .","The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META. The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <TARGET_CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> . Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary, i.e., mouse Mouse Genome Database (MGD) <CITATION/>, fly <CITATION/>, yeast Saccharomyces Genome Database (SGD) <CITATION/>, rat  Rat Genome Database (RGD) <CITATION/>, worm  <CITATION/>, Human Nomenclature Database (HUGO) <CITATION/>, Online Mendelian Inheritance in Man (OMIM) <CITATION/>, and Enzyme Nomenclature Database (ECNUM) <CITATION/>.The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META.",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,,online mendelian inheritance in man omim a knowledgebase of human genes and genetic disorders nucleic acids res,2005,A Hamosh; Scott AF; Amberger JS; Bocchini CA; McKusick VA
989,N01-1013,External_22096,[1],,"The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important <TARGET_CITATION/> .","(A rule of thumb often found in text books is that the expected values should be greater than 5.) One response to this problem is to apply some kind of thresholding, and either ignore counts below the threshold, or only apply the test to tables that do not contain low counts. The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important <TARGET_CITATION/> . The problem with this approach is that any threshold is, to some extent, arbitrary, and there is evidence to suggest that, for some tasks, low counts are important <CITATION/>. One response to this problem is to apply some kind of thresholding, and either ignore counts below the threshold, or only apply the test to tables that do not contain low counts. (A rule of thumb often found in text books is that the expected values should be greater than 5.)",636a9580ca9a2554a2a388696ec12f5c3181dd52,Class-Based Probability Estimation Using a Semantic Hierarchy,2001,S. Clark; David J. Weir,,prepositional phrase attachment through a backedoff model,1995,M Collins; J Brooks
999,J13-1008,J08-4003,[2],introduction,The result holds for both the MaltParser <TARGET_CITATION/> and the EasyFirst Parser <CITATION/> .,"In contrast with previous results, we show agreement features are quite helpful in both gold and predicted conditions. This is likely a result of MSA having a rich agreement system, covering both verbsubject and nounadjective relations. The result holds for both the MaltParser <TARGET_CITATION/> and the EasyFirst Parser <CITATION/> . The result holds for both the MaltParser <CITATION/> and the EasyFirst Parser <CITATION/>. This is likely a result of MSA having a rich agreement system, covering both verbsubject and nounadjective relations. In contrast with previous results, we show agreement features are quite helpful in both gold and predicted conditions.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,053f1cf10ced2321c1853f307075f0a6a83b6840,Algorithms for Deterministic Incremental Dependency Parsing,2008,Joakim Nivre
1013,J91-2003,External_70120,[0],introduction,"Adding selectional restrictions ( semantic feature information , <TARGET_CITATION/> ) does not solve the problem , because isolated features offer only part of the 0 knowledge necessary for reference disambiguation .","If the clause modifies port,'' then port'' is the desired referent; if the clause is attached at the level of the main verb of the sentence, then ship'' is the referent. But syntactic relations do not suffice to resolve anaphora: Hobbs' (1976) algorithm for resolving the reference of pronouns, depending only on the surface syntax of sentences in the text, when applied to it'' in the example paragraph, fails in both cases to identify the most likely referent NP. Adding selectional restrictions ( semantic feature information , <TARGET_CITATION/> ) does not solve the problem , because isolated features offer only part of the 0 knowledge necessary for reference disambiguation . Adding selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the 0 knowledge necessary for reference disambiguation. But syntactic relations do not suffice to resolve anaphora: Hobbs' (1976) algorithm for resolving the reference of pronouns, depending only on the surface syntax of sentences in the text, when applied to it'' in the example paragraph, fails in both cases to identify the most likely referent NP. If the clause modifies port,'' then port'' is the desired referent; if the clause is attached at the level of the main verb of the sentence, then ship'' is the referent.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,38 examples of elusive antecedents from published texts,1977,J R Hobbs
1022,J91-2003,External_2003,[0],introduction,The reader may consult recent papers on this subject <TARGET_CITATION/> to see what a formal interpretation of events in time might look like .,We assume that any formal interpretation of time will agree with the intuitive one. So it is not necessary now to present a formal semantics here. The reader may consult recent papers on this subject <TARGET_CITATION/> to see what a formal interpretation of events in time might look like . The reader may consult recent papers on this subject <CITATION/> to see what a formal interpretation of events in time might look like. So it is not necessary now to present a formal semantics here. We assume that any formal interpretation of time will agree with the intuitive one.,c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,temporal ontology in natural languagequot,1987,M Moens; M Steedman
1023,J91-2003,External_76184,[0],introduction,"Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX <TARGET_CITATION/> , 1987b ) .","A path through this graph chooses an interpretation of the sentence S. For instance, the path fint = LCBel, shl, pl, b1, d1RCB and S say together that A large boat (ship) that carries people or goods came into the harbor and carried a disease (illness). Since it is the highest'' path, flit is the most plausible (relative to R) interpretation of the words that appear in the sentence. Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX <TARGET_CITATION/> ) . Because it is also consistent, it will be chosen as a best interpretation of S, (cfXXX Zadrozny 1987a, 1987b). Since it is the highest'' path, flit is the most plausible (relative to R) interpretation of the words that appear in the sentence. A path through this graph chooses an interpretation of the sentence S. For instance, the path fint = LCBel, shl, pl, b1, d1RCB and S say together that A large boat (ship) that carries people or goods came into the harbor and carried a disease (illness).",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,intended models circumscription and commonsense reasoningquot,1987,W Zadrozny
1030,J12-4003,P10-1160,[3],experiments,"This evaluation setup is an improvement versus the one we previously reported <TARGET_CITATION/> , in which fixed partitions were used for training , development , and testing .","In order to remove any confounding factors caused by specific documents, we first randomized the annotated predicate instances. Following this, we split the predicate instances evenly into ten folds and used each fold as testing data for a model trained on the instances outside the fold. This evaluation setup is an improvement versus the one we previously reported <TARGET_CITATION/> , in which fixed partitions were used for training , development , and testing . This evaluation setup is an improvement versus the one we previously reported <CITATION/>, in which fixed partitions were used for training, development, and testing. Following this, we split the predicate instances evenly into ten folds and used each fold as testing data for a model trained on the instances outside the fold. In order to remove any confounding factors caused by specific documents, we first randomized the annotated predicate instances.",acbac8a75b25384bcc10953b2becc8278b9240c9,Semantic Role Labeling of Implicit Arguments for Nominal Predicates,2012,Matthew Gerber; J. Chai,d8259bcbe9cb0cf5bad6ea25645f4407fc544a1c,Beyond NomBank: A Study of Implicit Arguments for Nominal Predicates,2010,Matthew Gerber; J. Chai
1035,P05-3005,External_95869,[2],,"Three UniRef tables UniRef100 , UniRef90 and UniRef50 ) are available for download : UniRef100 combines identical sequences and subfragments into a single UniRef entry ; and UniRef90 and UniRef50 are built by clustering UniRef100 sequences into clusters based on the CDHIT algorithm <TARGET_CITATION/> such that each cluster is composed of sequences that have at least 90 % or 50 % sequence similarity , respectively , to the representative sequence .","TrEMBL consists of computationally analyzed records that await full manual annotation. The UniProt Nonredundant Reference (UniRef) databases combine closely related sequences into a single record where similar sequences are grouped together. Three UniRef tables UniRef100 , UniRef90 and UniRef50 ) are available for download : UniRef100 combines identical sequences and subfragments into a single UniRef entry ; and UniRef90 and UniRef50 are built by clustering UniRef100 sequences into clusters based on the CDHIT algorithm <TARGET_CITATION/> such that each cluster is composed of sequences that have at least 90 % or 50 % sequence similarity , respectively , to the representative sequence . Three UniRef tables UniRef100, UniRef90 and UniRef50) are available for download: UniRef100 combines identical sequences and subfragments into a single UniRef entry; and UniRef90 and UniRef50 are built by clustering UniRef100 sequences into clusters based on the CDHIT algorithm <CITATION/> such that each cluster is composed of sequences that have at least 90% or 50% sequence similarity, respectively, to the representative sequence. The UniProt Nonredundant Reference (UniRef) databases combine closely related sequences into a single record where similar sequences are grouped together. TrEMBL consists of computationally analyzed records that await full manual annotation.",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,5e909230edb651ce77cbb6eac829ab5d465c9fc5,Clustering of highly homologous sequences to reduce the size of large protein databases,2001,Weizhong Li; L. Jaroszewski; A. Godzik
1039,W05-0709,External_87918,[0],,Arabic has two kinds of plurals : broken plurals and sound plurals <TARGET_CITATION/> .,"he first token  is a mention that refers to an organization, whereas the second token  is also a mention, but one that may refer to a person. Also, the prepositions (i.e.,  and ) not be considered a part of the mention. Arabic has two kinds of plurals : broken plurals and sound plurals <TARGET_CITATION/> . Arabic has two kinds of plurals: broken plurals and sound plurals <CITATION/>. Also, the prepositions (i.e.,  and ) not be considered a part of the mention. he first token  is a mention that refers to an organization, whereas the second token  is also a mention, but one that may refer to a person.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,13990315c6b2bc75361d674395eb01a07ec7cc4e,Arabic Verbs and Essentials of Grammar: A Practical Guide to the Mastery of Arabic,1997,Jane Wightwick; M. Gaafar
1040,J91-2003,External_4320,[4],introduction,"Although there are other discussions of the paragraph as a central element of discourse <TARGET_CITATION/> , all of them share a certain limitation in their formal techniques for analyzing paragraph structure ."," Although there are other discussions of the paragraph as a central element of discourse <TARGET_CITATION/> , all of them share a certain limitation in their formal techniques for analyzing paragraph structure . Although there are other discussions of the paragraph as a central element of discourse <CITATION/>, all of them share a certain limitation in their formal techniques for analyzing paragraph structure.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,6201c3bea46137ce18d4141eda1f9c2adf15d4e1,The Paragraph as a Grammatical Unit,1979,R. Longacre
1043,W10-1758,D08-1024,[5],conclusion,Our plan is to implement a windowed or movingaverage version of BLEU as in <TARGET_CITATION/> .,"When the final evaluation metric incorporates global statistics, however, an objective function which takes them into account is desirable. For example, when using BLEU, it makes a big difference whether individual sentences are both longer and shorter than the reference or systematically shorter than the reference, but these two cases can not be distinguished by singlesentence objective functions. Our plan is to implement a windowed or movingaverage version of BLEU as in <TARGET_CITATION/> . Our plan is to implement a windowed or movingaverage version of BLEU as in <CITATION/>. For example, when using BLEU, it makes a big difference whether individual sentences are both longer and shorter than the reference or systematically shorter than the reference, but these two cases can not be distinguished by singlesentence objective functions. When the final evaluation metric incorporates global statistics, however, an objective function which takes them into account is desirable.",75ff8457e6b6b587a2e4483f0df250e2ca205a7f,Taming Structured Perceptrons on Wild Feature Vectors,2010,Ralf D. Brown,7fdbb9f2a0caaa0813d26756a2d071959b3dd5a5,Online Large-Margin Training of Syntactic and Structural Translation Features,2008,David Chiang; Yuval Marton; P. Resnik
1057,J07-1005,External_37369,[2],,"The extraction of each PICO element relies to a different extent on an annotated corpus of MEDLINE abstracts , created through an effort led by the first author at the National Library of Medicine <TARGET_CITATION/> .","In addition, abstracts of much highquality work remain unstructured. For these reasons, explicit section markers are not entirely reliable indicators for the various semantic elements we seek to extract, but must be considered along with other sources of evidence. The extraction of each PICO element relies to a different extent on an annotated corpus of MEDLINE abstracts , created through an effort led by the first author at the National Library of Medicine <TARGET_CITATION/> . The extraction of each PICO element relies to a different extent on an annotated corpus of MEDLINE abstracts, created through an effort led by the first author at the National Library of Medicine <CITATION/>. For these reasons, explicit section markers are not entirely reliable indicators for the various semantic elements we seek to extract, but must be considered along with other sources of evidence. In addition, abstracts of much highquality work remain unstructured.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,41caea2054d5d2e80fe5bc1aefc2ea2056ab63f4,Automatically identifying health outcome information in MEDLINE records.,2006,Dina Demner-Fushman; B. Few; S. Hauser; G. Thoma
1065,N01-1003,External_24304,[0],related work,Previous work in sentence planning in the natural language generation ( NLG ) community uses handwritten rules to approximate the distribution of linguistic phenomena in a corpus ( see <TARGET_CITATION/> for a recent example with further references ) ., Previous work in sentence planning in the natural language generation ( NLG ) community uses handwritten rules to approximate the distribution of linguistic phenomena in a corpus ( see <TARGET_CITATION/> for a recent example with further references ) . Previous work in sentence planning in the natural language generation (NLG) community uses handwritten rules to approximate the distribution of linguistic phenomena in a corpus (see <CITATION/> for a recent example with further references).,ee6892b9c7f1a491e0925b913b66281c48408f74,SPoT: A Trainable Sentence Planner,2001,M. Walker; Owen Rambow; Monica Rogati,e5ba636047b974b8f99e840df097caa38f1f1d96,Clause Aggregation Using Linguistic Knowledge,1998,James Shaw
1072,P05-3005,External_95865,[2],,"Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <TARGET_CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> .","The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META. The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <TARGET_CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> . Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary, i.e., mouse Mouse Genome Database (MGD) <CITATION/>, fly <CITATION/>, yeast Saccharomyces Genome Database (SGD) <CITATION/>, rat  Rat Genome Database (RGD) <CITATION/>, worm  <CITATION/>, Human Nomenclature Database (HUGO) <CITATION/>, Online Mendelian Inheritance in Man (OMIM) <CITATION/>, and Enzyme Nomenclature Database (ECNUM) <CITATION/>.The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META.",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,,kwitek a et al rat genome database rgd mapping disease onto the genome nucleic acids res,2002,S Twigger; J Lu; M Shimoyama; D Chen; D Pasko; H Long; J Ginster; Chen CF; R Nigam
1077,J13-1008,External_1438,[2],experiments,"The following are the various tag sets we use in this article : ( a ) the core POS tag sets CORE44 and the newly introduced CORE12 ; ( b ) CATiB Treebank tag set ( CATIB6 ) <CITATION/> and its newly introduced extension of CATIBEX created using simple regular expressions on word form , indicating particular morphemes such as the prefix JI Al + or the suffix v ' + wn ; this tag set is the bestperforming tag set for Arabic on predicted values as reported in Section 4 ; ( c ) the PATB full tag set with complete morphological tag ( BW ) <TARGET_CITATION/> ; and two extensions of the PATB reduced tag set ( PENN POS , a.k.a. RTS , size 24 [ Diab , Hacioglu , and Jurafsky 2004 ] ) , both outperforming it : ( d ) <CITATION/> 's tag set ( KULICK ) , size 43 , one of whose most important extensions is the marking of the definite article clitic , and ( e ) Diab and Benajiba 's ( in preparation ) EXTENDED RTS tag set ( ERTS ) , which marks gender , number , and definiteness , size 134 .","These tag sets are hybrids in the sense that they are neither simply the core POS, nor the complete morphologically enriched tag set, but instead they selectively enrich the core POS tag set with only certain morphological features. A more detailed discussion of the various available Arabic tag sets can be found in <CITATION/>. The following are the various tag sets we use in this article : ( a ) the core POS tag sets CORE44 and the newly introduced CORE12 ; ( b ) CATiB Treebank tag set ( CATIB6 ) <CITATION/> and its newly introduced extension of CATIBEX created using simple regular expressions on word form , indicating particular morphemes such as the prefix JI Al + or the suffix v ' + wn ; this tag set is the bestperforming tag set for Arabic on predicted values as reported in Section 4 ; ( c ) the PATB full tag set with complete morphological tag ( BW ) <TARGET_CITATION/> ; and two extensions of the PATB reduced tag set ( PENN POS , a.k.a. RTS , size 24 [ Diab , Hacioglu , and Jurafsky 2004 ] ) , both outperforming it : ( d ) <CITATION/> 's tag set ( KULICK ) , size 43 , one of whose most important extensions is the marking of the definite article clitic , and ( e ) Diab and Benajiba 's ( in preparation ) EXTENDED RTS tag set ( ERTS ) , which marks gender , number , and definiteness , size 134 . The following are the various tag sets we use in this article: (a) the core POS tag sets CORE44 and the newly introduced CORE12; (b) CATiB Treebank tag set (CATIB6) <CITATION/> and its newly introduced extension of CATIBEX created using simple regular expressions on word form, indicating particular morphemes such as the prefix JI Al+ or the suffix v' +wn; this tag set is the bestperforming tag set for Arabic on predicted values as reported in Section 4; (c) the PATB full tag set with complete morphological tag (BW) <CITATION/>; and two extensions of the PATB reduced tag set (PENN POS, a.k.a. RTS, size 24 [Diab, Hacioglu, and Jurafsky 2004]), both outperforming it: (d) <CITATION/>'s tag set (KULICK), size 43, one of whose most important extensions is the marking of the definite article clitic, and (e) Diab and Benajiba's (in preparation) EXTENDED RTS tag set (ERTS), which marks gender, number, and definiteness, size 134.A more detailed discussion of the various available Arabic tag sets can be found in <CITATION/>. These tag sets are hybrids in the sense that they are neither simply the core POS, nor the complete morphologically enriched tag set, but instead they selectively enrich the core POS tag set with only certain morphological features.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,,buckwalter arabic morphological analyzer version 20 linguistic data consortium,2004,Timothy A Buckwalter
1083,E12-1068,C04-1024,[2],introduction,"The key linguistic knowledge sources that we use are morphological analysis and generation of German based on SMOR , a morphological analyzer/generator of German <CITATION/> and the BitPar parser , which is a stateoftheart parser of German <TARGET_CITATION/> .","Later, after performing an extensive analysis of this system, we will extend itto model compounds, a highly productive phenomenon in German (see Section 8). The key linguistic knowledge sources that we use are morphological analysis and generation of German based on SMOR , a morphological analyzer/generator of German <CITATION/> and the BitPar parser , which is a stateoftheart parser of German <TARGET_CITATION/> . The key linguistic knowledge sources that we use are morphological analysis and generation of German based on SMOR, a morphological analyzer/generator of German <CITATION/> and the BitPar parser, which is a stateoftheart parser of German <CITATION/>.to model compounds, a highly productive phenomenon in German (see Section 8). Later, after performing an extensive analysis of this system, we will extend it",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,8abb1cbb1b701140e247070a47625f42d91f0615,Efficient Parsing of Highly Ambiguous Context-Free Grammars with Bit Vectors,2004,Helmut Schmid
1094,J13-1008,P99-1065,[0],related work,<TARGET_CITATION/> report that an optimal tag set for parsing Czech consists of a basic POS tag plus a CASE feature ( when applicable ) .,Much work has been done on the use of morphological features for parsing of morphologically rich languages. <TARGET_CITATION/> report that an optimal tag set for parsing Czech consists of a basic POS tag plus a CASE feature ( when applicable ) . <CITATION/> report that an optimal tag set for parsing Czech consists of a basic POS tag plus a CASE feature (when applicable). Much work has been done on the use of morphological features for parsing of morphologically rich languages.,4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,0cb912b4a208b217c45d57e28fc0f59599f92330,A Statistical Parser for Czech,1999,M. Collins; Jan Hajic; L. Ramshaw; Christoph Tillmann
1097,J13-1008,N12-1032,[4],related work,"9 We do not relate to specific results in their study because it has been brought to our attention that <TARGET_CITATION/> are in the process of rechecking their code for errors , and rerunning their experiments ( personal communication ) .","We examined a large space of settings. In all our experiments, we contrasted the results obtained using machinepredicted input with the results obtained using gold input (the 9 We do not relate to specific results in their study because it has been brought to our attention that <TARGET_CITATION/> are in the process of rechecking their code for errors , and rerunning their experiments ( personal communication ) . 9 We do not relate to specific results in their study because it has been brought to our attention that <CITATION/> are in the process of rechecking their code for errors, and rerunning their experiments (personal communication).In all our experiments, we contrasted the results obtained using machinepredicted input with the results obtained using gold input (theWe examined a large space of settings.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,50c0d8b36fc516b4fc04aa636a62a9f2aee2240e,Getting More from Morphology in Multilingual Dependency Parsing,2012,Matthew Hohensee; Emily M. Bender
1102,E12-1068,W10-1734,[2],experiments,"We prepare the training data by splitting compounds in two steps , following the technique of <TARGET_CITATION/> ."," We prepare the training data by splitting compounds in two steps , following the technique of <TARGET_CITATION/> . We prepare the training data by splitting compounds in two steps, following the technique of <CITATION/>.",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,389cae0f6fac08fc9cfddcb8703fe98e95bf8ced,How to Avoid Burning Ducks: Combining Linguistic Analysis and Corpus Statistics for German Compound Processing,2010,Fabienne Fritzinger; Alexander M. Fraser
1109,J91-2003,External_83406,[0],introduction,"As a logical postulate it is not very radical ; it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX <TARGET_CITATION/> ) .","The issues of control are not so important for us at this point; we restrict ourselves to describing the logic. This Principle of Finitism is also assumed by <CITATION/>, and implicitly or explicitly by almost all researchers in computational linguistics. As a logical postulate it is not very radical ; it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX <TARGET_CITATION/> ) . As a logical postulate it is not very radical; it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science, such as mathematical analysis (cfXXX Mycielski 1981). This Principle of Finitism is also assumed by <CITATION/>, and implicitly or explicitly by almost all researchers in computational linguistics. The issues of control are not so important for us at this point; we restrict ourselves to describing the logic.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,analysis without actual infinityquot,1981,J Mycielski
1115,J07-1005,External_89593,[0],introduction,"Furthermore , the need to answer questions related to patient care at the point of service has been well studied and documented <TARGET_CITATION/> .","The PICO framework <CITATION/> for capturing wellformulated clinical queries (described in Section 2) can serve as the basis of a knowledge representation that bridges the needs of clinicians and analytical capabilities of a system. The confluence of these many factors makes clinical question answering a very exciting area of research. Furthermore , the need to answer questions related to patient care at the point of service has been well studied and documented <TARGET_CITATION/> . Furthermore, the need to answer questions related to patient care at the point of service has been well studied and documented (Covell, Uman, and Manning 1985; Gorman, Ash, and Wykoff 1994; Ely et al. 1999, 2005). The confluence of these many factors makes clinical question answering a very exciting area of research. The PICO framework <CITATION/> for capturing wellformulated clinical queries (described in Section 2) can serve as the basis of a knowledge representation that bridges the needs of clinicians and analytical capabilities of a system.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,5b5fb785f70eb049e463c09d1e4c24b0a0d57d51,Analysis of questions asked by family doctors regarding patient care,1999,J. W. Ely; J. Osheroff; M. Ebell; G. Bergus; B. Levy; M. Chambliss; E. Evans
1120,E12-1068,P11-1004,[4],related work,"<TARGET_CITATION/> , and others are primarily concerned with using morpheme segmentation in SMT , which is a useful approach for dealing with issues of wordformation .","This is a striking result considering stateoftheart performance of German parsing is poor compared with the best performance on English parsing. As parsing performance improves, the performance of linguisticfeaturebased approaches will increase. <TARGET_CITATION/> , and others are primarily concerned with using morpheme segmentation in SMT , which is a useful approach for dealing with issues of wordformation . <CITATION/>, and others are primarily concerned with using morpheme segmentation in SMT, which is a useful approach for dealing with issues of wordformation. As parsing performance improves, the performance of linguisticfeaturebased approaches will increase. This is a striking result considering stateoftheart performance of German parsing is poor compared with the best performance on English parsing.",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,8c9f1596773390d4088d6d5b8aa68a66d6c8f39b,Combining Morpheme-based Machine Translation with Post-processing Morpheme Prediction,2011,Ann Clifton; Anoop Sarkar
1123,J13-1008,N10-1115,[2],introduction,The result holds for both the MaltParser <CITATION/> and the EasyFirst Parser <TARGET_CITATION/> .,"In contrast with previous results, we show agreement features are quite helpful in both gold and predicted conditions. This is likely a result of MSA having a rich agreement system, covering both verbsubject and nounadjective relations. The result holds for both the MaltParser <CITATION/> and the EasyFirst Parser <TARGET_CITATION/> . The result holds for both the MaltParser <CITATION/> and the EasyFirst Parser <CITATION/>. This is likely a result of MSA having a rich agreement system, covering both verbsubject and nounadjective relations. In contrast with previous results, we show agreement features are quite helpful in both gold and predicted conditions.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,3ce0f00d6c949192107f1bd6a167c03e1fb7393a,An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing,2010,Yoav Goldberg; Michael Elhadad
1135,W01-0706,External_2081,[2],experiments,The shallow parser used is the SNoWbased CSCL parser <TARGET_CITATION/> .,The experiments use the version that was trained (by Collins) on sections 0221 of the Penn Treebank. The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 <CITATION/>. The shallow parser used is the SNoWbased CSCL parser <TARGET_CITATION/> . The shallow parser used is the SNoWbased CSCL parser <CITATION/>. The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 <CITATION/>. The experiments use the version that was trained (by Collins) on sections 0221 of the Penn Treebank.,cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,3fab92869cfab684b3ffb1c16a771e9c3b774acd,The Use of Classifiers in Sequential Inference,2001,Vasin Punyakanok; D. Roth
1137,W01-0706,W00-0726,[2],experiments,Table 2 shows the results on identifying all phrases  chunking in CoNLL2000 ( Tjong Kim <TARGET_CITATION/> ) terminology .,We start by reporting the results in which we compare the full parser and the shallow parser on the clean'' WSJ data. Table 2 shows the results on identifying all phrases  chunking in CoNLL2000 ( Tjong Kim <TARGET_CITATION/> ) terminology . Table 2 shows the results on identifying all phrases  chunking in CoNLL2000 (Tjong Kim <CITATION/>) terminology. We start by reporting the results in which we compare the full parser and the shallow parser on the clean'' WSJ data.,cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,9e85832b04cc3700c2c26d6ba93fdeae39cac04a,Introduction to the CoNLL-2000 Shared Task Chunking,2000,E. Tjong Kim Sang; S. Buchholz
1139,J07-1005,P06-1106,[0],,"Perhaps some variation of multilevel bulleted lists , appropriately integrated with interface elements for expanding and hiding items , might provide physicians a better overview of the information landscape ; see , for example , <TARGET_CITATION/> .","Furthermore, it is unclear if textual strings make good answers.'' Perhaps a graphical rendering of the semantic predicates present in relevant abstracts might more effectively convey the desired information; see, for example, <CITATION/>. Perhaps some variation of multilevel bulleted lists , appropriately integrated with interface elements for expanding and hiding items , might provide physicians a better overview of the information landscape ; see , for example , <TARGET_CITATION/> . Perhaps some variation of multilevel bulleted lists, appropriately integrated with interface elements for expanding and hiding items, might provide physicians a better overview of the information landscape; see, for example, <CITATION/>. Perhaps a graphical rendering of the semantic predicates present in relevant abstracts might more effectively convey the desired information; see, for example, <CITATION/>. Furthermore, it is unclear if textual strings make good answers.''",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,216f2cbdcc4c06943f38f8d1bde99a5746171b62,"Answer Extraction, Semantic Clustering, and Extractive Summarization for Clinical Question Answering",2006,Dina Demner-Fushman; Jimmy J. Lin
1170,J10-3007,External_3667,[4],,"This is the approach taken by IBM Models 4 + <TARGET_CITATION/> , and more recently by the LEAF model <CITATION/> .","Word alignment models in general and the HMM in particular are very gross oversimplifications of the translation process and the optimal likelihood parameters learned often do not correspond to sensible alignments. One solution to this problem is to add more complexity to the model to better reflect the translation process. This is the approach taken by IBM Models 4 + <TARGET_CITATION/> , and more recently by the LEAF model <CITATION/> . This is the approach taken by IBM Models 4+ <CITATION/>, and more recently by the LEAF model <CITATION/>. One solution to this problem is to add more complexity to the model to better reflect the translation process. Word alignment models in general and the HMM in particular are very gross oversimplifications of the translation process and the optimal likelihood parameters learned often do not correspond to sensible alignments.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,de2df29b0a0312de7270c3f5a0af6af5645cf91a,A Systematic Comparison of Various Statistical Alignment Models,2003,F. Och; H. Ney
1180,J91-2003,J87-3005,[3],introduction,"We have shown elsewhere ( <TARGET_CITATION/> ; Zadrozny 1987a , 1987b ) that natural language programs , such as online grammars and dictionaries , can be used as referential levels for commonsense reasoning  for example , to disambiguate PP attachment .","Since not all logically permissible models are linguistically appropriate, one needs a place, namely the metalevel, to put constraints on types of models. Gricean maxims belong there; Section 6 will be devoted to a presentation of the metalevel rules corresponding to them. We have shown elsewhere ( <TARGET_CITATION/> ; Zadrozny 1987a , 1987b ) that natural language programs , such as online grammars and dictionaries , can be used as referential levels for commonsense reasoning  for example , to disambiguate PP attachment . We have shown elsewhere (Jensen and Binot 1988; Zadrozny 1987a, 1987b) that natural language programs, such as online grammars and dictionaries, can be used as referential levels for commonsense reasoningfor example, to disambiguate PP attachment. Gricean maxims belong there; Section 6 will be devoted to a presentation of the metalevel rules corresponding to them.Since not all logically permissible models are linguistically appropriate, one needs a place, namely the metalevel, to put constraints on types of models.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,43865ad56b3364b39ae3badf1fc212547292b335,Disambiguating Prepositional Phrase Attachments by Using On-Line Dictionary Definitions,1987,Karen Jensen; J. Binot
1193,W05-0709,N04-1001,[0],introduction,"The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks .","These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc.. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks . The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations <CITATION/>, and have been at the center of evaluations such as: MUC6, MUC7, and the CoNLL'02 and CoNLL'03 shared tasks. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc..",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,54c04d731368ad14ab3902c1abae46b8b62cb633,A Statistical Model for Multilingual Entity Detection and Tracking,2004,Radu Florian; Hany Hassan; Abraham Ittycheriah; Hongyan Jing; N. Kambhatla; Xiaoqiang Luo; Nicolas Nicolov; S. Roukos
1199,E99-1022,External_105,[0],introduction,Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar ( HPSG ; <TARGET_CITATION/> ) as discussed in <CITATION/> .,"magic is an interesting technique with respect to natural language processing as it incorporates filtering into the logic underlying the grammar and enables elegant control independent filtering improvements. In this paper we investigate the selective application of magic to typed feature grammars a type of constraintlogic grammar based on Typed Feature Logic (T r; G6tz, 1995). Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar ( HPSG ; <TARGET_CITATION/> ) as discussed in <CITATION/> . Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar (HPSG; <CITATION/>) as discussed in <CITATION/>. In this paper we investigate the selective application of magic to typed feature grammars a type of constraintlogic grammar based on Typed Feature Logic (T r; G6tz, 1995). magic is an interesting technique with respect to natural language processing as it incorporates filtering into the logic underlying the grammar and enables elegant control independent filtering improvements.",3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,,headdriven phrase structure grammar,1994,Carl Pollard; Ivan Sag
1208,W01-0706,External_4334,[0],introduction,"Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) .","to ] [NP only $ 1.8 billion ] [PP in ] [NP September] . While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) . Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,,text chunking using transformationbased learning,1995,L A Ramshaw; M P Marcus
1210,J07-1005,External_37369,[0],,"After much exploration , <TARGET_CITATION/> discovered that it was not practical to annotate PICO entities at the phrase level due to significant unresolvable disagreement and interannotator reliability issues .","These 100 abstracts were set aside as a heldout test set. Of the remaining citations, 275 were used for training and rule derivation, as described in the following sections. After much exploration , <TARGET_CITATION/> discovered that it was not practical to annotate PICO entities at the phrase level due to significant unresolvable disagreement and interannotator reliability issues . After much exploration, <CITATION/> discovered that it was not practical to annotate PICO entities at the phrase level due to significant unresolvable disagreement and interannotator reliability issues. Of the remaining citations, 275 were used for training and rule derivation, as described in the following sections. These 100 abstracts were set aside as a heldout test set.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,41caea2054d5d2e80fe5bc1aefc2ea2056ab63f4,Automatically identifying health outcome information in MEDLINE records.,2006,Dina Demner-Fushman; B. Few; S. Hauser; G. Thoma
1211,J91-2003,External_29514,[0],introduction,"The necessity of this kind of merging of arguments has been recognized before : <TARGET_CITATION/> call it abductive unification/matching , Hobbs ( 1978 , 1979 ) refers to such operations using the terms knitting or petty conversational implicature .","This relation would hold, for instance, between the object theory of our example paragraph and a formula expressing the equality of two constants, i and i', denoting (respectively) the infection'' in the sentence Within twentyfour hours of infection..., and the infection'' of the theory (d1)a disease is an illness caused by an infection. This equality i = i' cannot be proven, but it may be reasonably assumedwe know that in this case the infection i' caused the illness, which, in turn, caused the death. The necessity of this kind of merging of arguments has been recognized before : <TARGET_CITATION/> call it abductive unification/matching , Hobbs ( 1978 , 1979 ) refers to such operations using the terms knitting or petty conversational implicature . The necessity of this kind of merging of arguments has been recognized before: <CITATION/> call it abductive unification/matching, Hobbs (1978, 1979) refers to such operations using the terms knitting or petty conversational implicature. This equality i = i' cannot be proven, but it may be reasonably assumedwe know that in this case the infection i' caused the illness, which, in turn, caused the death. This relation would hold, for instance, between the object theory of our example paragraph and a formula expressing the equality of two constants, i and i', denoting (respectively) the infection'' in the sentence Within twentyfour hours of infection..., and the infection'' of the theory (d1)a disease is an illness caused by an infection.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,fb96bb367eddcdb8562dfb99f3e3b482afb4f76a,Introduction to Artificial Intelligence,2023,Nikhil Sharma
1235,E99-1022,External_105,[0],,Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar <TARGET_CITATION/> .3 <CITATION/> propose a compilation of lexical rules into TIT definite clauses,In general all boxed items indicate structure sharing. For expository reasons we represent the ARG n features of the append relation as separate arguments. Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar <TARGET_CITATION/> .3 <CITATION/> propose a compilation of lexical rules into TIT definite clauses Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar <CITATION/>.3 <CITATION/> propose a compilation of lexical rules into TIT definite clausesFor expository reasons we represent the ARG n features of the append relation as separate arguments. In general all boxed items indicate structure sharing.,3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,,headdriven phrase structure grammar,1994,Carl Pollard; Ivan Sag
1246,J91-2003,External_43653,[4],introduction,"notation of <TARGET_CITATION/> is more sophisticated , and may be considered another possibility .","But, obviously, there are other possibilitiesfor instance, the discourse representation structures (DRS's) of <CITATION/>, which have been used to translate a subset of English into logical formulas, to model text (identified with a list of sentences), to analyze a fragment of English, and to deal with anaphora. The logical notation of <TARGET_CITATION/> is more sophisticated , and may be considered another possibility . notation of <CITATION/> is more sophisticated, and may be considered another possibility. The logicalBut, obviously, there are other possibilitiesfor instance, the discourse representation structures (DRS's) of <CITATION/>, which have been used to translate a subset of English into logical formulas, to model text (identified with a list of sentences), to analyze a fragment of English, and to deal with anaphora.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,universal grammarquot,1970,R Montague
1250,J07-1005,External_53400,[2],,"We first identified the most informative unigrams and bigrams using the information gain measure <CITATION/> , and then selected only the positive outcome predictors using odds ratio <TARGET_CITATION/> .","The unigram bag of words'' classifier is a naive Bayes classifier implemented with the API provided by the MALLET toolkit.4 This classifier outputs the probability of a class assignment. The ngram based classifier is also a naive Bayes classifier, but it operates on a different set of features. We first identified the most informative unigrams and bigrams using the information gain measure <CITATION/> , and then selected only the positive outcome predictors using odds ratio <TARGET_CITATION/> . We first identified the most informative unigrams and bigrams using the information gain measure <CITATION/>, and then selected only the positive outcome predictors using odds ratio <CITATION/>. The ngram based classifier is also a naive Bayes classifier, but it operates on a different set of features. The unigram bag of words'' classifier is a naive Bayes classifier implemented with the API provided by the MALLET toolkit.4 This classifier outputs the probability of a class assignment.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,cf45af2b0b278257bd91c50cd60d5893d1385d52,Feature Selection for Unbalanced Class Distribution and Naive Bayes,1999,D. Mladenić; M. Grobelnik
1251,J07-1005,P06-1106,[5],,"Perhaps some variation of multilevel bulleted lists , appropriately integrated with interface elements for expanding and hiding items , might provide physicians a better overview of the information landscape ; see , for example , <TARGET_CITATION/> .","Furthermore, it is unclear if textual strings make good answers.'' Perhaps a graphical rendering of the semantic predicates present in relevant abstracts might more effectively convey the desired information; see, for example, <CITATION/>. Perhaps some variation of multilevel bulleted lists , appropriately integrated with interface elements for expanding and hiding items , might provide physicians a better overview of the information landscape ; see , for example , <TARGET_CITATION/> . Perhaps some variation of multilevel bulleted lists, appropriately integrated with interface elements for expanding and hiding items, might provide physicians a better overview of the information landscape; see, for example, <CITATION/>. Perhaps a graphical rendering of the semantic predicates present in relevant abstracts might more effectively convey the desired information; see, for example, <CITATION/>. Furthermore, it is unclear if textual strings make good answers.''",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,216f2cbdcc4c06943f38f8d1bde99a5746171b62,"Answer Extraction, Semantic Clustering, and Extractive Summarization for Clinical Question Answering",2006,Dina Demner-Fushman; Jimmy J. Lin
1254,J07-1005,External_2313,[0],related work,"Nugget Fscore has been employed as a metric in the TREC questionanswering track since 2003 , to evaluate socalled definition and  other '' questions <TARGET_CITATION/> .","In Sections 9 and 10, we have discussed many of these issues. Recently, there is a growing consensus that an evaluation methodology based on the notion of information nuggets'' may provide an appropriate framework for assessing the quality of answers to complex questions. Nugget Fscore has been employed as a metric in the TREC questionanswering track since 2003 , to evaluate socalled definition and  other '' questions <TARGET_CITATION/> . Nugget Fscore has been employed as a metric in the TREC questionanswering track since 2003, to evaluate socalled definition and other'' questions <CITATION/>. Recently, there is a growing consensus that an evaluation methodology based on the notion of information nuggets'' may provide an appropriate framework for assessing the quality of answers to complex questions. In Sections 9 and 10, we have discussed many of these issues.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,e50dd4321a0e51013f8259021b1d61154b45041c,Overview of the TREC 2006,2007,E. Voorhees
1257,J07-1005,External_44095,[0],related work,"In addition , there has been much work on the application of linguistic and semantic knowledge to information retrieval ; see <TARGET_CITATION/> ) for a brief overview .","In this section, however, we will attempt to draw connections to other clinical information systems (although not necessarily for question answering) and related domainspecific questionanswering systems. For an overview of systems designed to answer opendomain factoid questions, the TREC QA track overview papers are a good place to start <CITATION/>. In addition , there has been much work on the application of linguistic and semantic knowledge to information retrieval ; see <TARGET_CITATION/> ) for a brief overview . In addition, there has been much work on the application of linguistic and semantic knowledge to information retrieval; see <CITATION/> for a brief overview. For an overview of systems designed to answer opendomain factoid questions, the TREC QA track overview papers are a good place to start <CITATION/>. In this section, however, we will attempt to draw connections to other clinical information systems (although not necessarily for question answering) and related domainspecific questionanswering systems.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,a97f3440ec7b6ab5d8faad61c339f21b404e3e24,The role of knowledge in conceptual retrieval: a study in the domain of clinical medicine,2006,Jimmy J. Lin; Dina Demner-Fushman
1258,N01-1013,External_6119,[1],,"However , <TARGET_CITATION/> claims that the loglikelihood chisquared statistic ( G2 ) is more appropriate for corpusbased NLP .","There is a choice of which statistic to use in conjunction with the test. The usual statistic encountered in text books is the Pearson chisquared statistic, denoted X2. However , <TARGET_CITATION/> claims that the loglikelihood chisquared statistic ( G2 ) is more appropriate for corpusbased NLP . <CITATION/> claims that the loglikelihood chisquared statistic (G2) is more appropriate for corpusbased NLP. The usual statistic encountered in text books is the Pearson chisquared statistic, denoted X2. There is a choice of which statistic to use in conjunction with the test.",636a9580ca9a2554a2a388696ec12f5c3181dd52,Class-Based Probability Estimation Using a Semantic Hierarchy,2001,S. Clark; David J. Weir,025464b73f805e76689a7a20a48a9e9c0f4ff3ef,Accurate Methods for the Statistics of Surprise and Coincidence,1993,T. Dunning
1261,W01-0706,W99-0621,[3],experiments,"Since earlier versions of the SNoW based CSCL were used only to identify single phrases <TARGET_CITATION/> and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL2000 ( Tjong Kim <CITATION/> ) to compare it to other shallow parsers .","Indeed, in CSCL (constraint satisfaction with classifiers), SNoW is used to learn several different classifiers  each detects the beginning or end of a phrase of some type (noun phrase, verb phrase, etc.). The outcomes of these classifiers are then combined in a way that satisfies some constraints  nonoverlapping constraints in this case  using an efficient constraint satisfaction mechanism that makes use of the confidence in the classifier's outcomes. Since earlier versions of the SNoW based CSCL were used only to identify single phrases <TARGET_CITATION/> and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL2000 ( Tjong Kim <CITATION/> ) to compare it to other shallow parsers . Since earlier versions of the SNoW based CSCL were used only to identify single phrases <CITATION/> and never to identify a collection of several phrases at the same time, as we do here, we also trained and tested it under the exact conditions of CoNLL2000 (Tjong Kim <CITATION/>) to compare it to other shallow parsers. The outcomes of these classifiers are then combined in a way that satisfies some constraints  nonoverlapping constraints in this case  using an efficient constraint satisfaction mechanism that makes use of the confidence in the classifier's outcomes. Indeed, in CSCL (constraint satisfaction with classifiers), SNoW is used to learn several different classifiers  each detects the beginning or end of a phrase of some type (noun phrase, verb phrase, etc.).",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,a31d6f597f78599c6df66dedf64cd5bc05c5327a,A Learning Approach to Shallow Parsing,1999,Marcia Muñoz; Vasin Punyakanok; D. Roth; Dav Zimak
1262,J13-1008,External_4464,[0],experiments,A more detailed discussion of the various available Arabic tag sets can be found in <TARGET_CITATION/> .,"Therefore, researchers have proposed tag sets for MSA whose size is similar to that of the English PTB tag set, as this has proven to be a useful size computationally. These tag sets are hybrids in the sense that they are neither simply the core POS, nor the complete morphologically enriched tag set, but instead they selectively enrich the core POS tag set with only certain morphological features. A more detailed discussion of the various available Arabic tag sets can be found in <TARGET_CITATION/> . A more detailed discussion of the various available Arabic tag sets can be found in <CITATION/>. These tag sets are hybrids in the sense that they are neither simply the core POS, nor the complete morphologically enriched tag set, but instead they selectively enrich the core POS tag set with only certain morphological features. Therefore, researchers have proposed tag sets for MSA whose size is similar to that of the English PTB tag set, as this has proven to be a useful size computationally.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,2a733deaa7c55e427337860c7643e6b5f8b750fc,Book Reviews: Introduction to Arabic Natural Language Processing by Nizar Y. Habash,2010,Nizar Habash
1285,J07-1005,H05-1117,[0],related work,"A number of studies <CITATION/> have pointed out shortcomings of the original nugget scoring model , although a number of these issues have been recently addressed ( <TARGET_CITATION/> , 2006b ) .","Recently, there is a growing consensus that an evaluation methodology based on the notion of information nuggets'' may provide an appropriate framework for assessing the quality of answers to complex questions. Nugget Fscore has been employed as a metric in the TREC questionanswering track since 2003, to evaluate socalled definition and other'' questions <CITATION/>. A number of studies <CITATION/> have pointed out shortcomings of the original nugget scoring model , although a number of these issues have been recently addressed <TARGET_CITATION/> . A number of studies <CITATION/> have pointed out shortcomings of the original nugget scoring model, although a number of these issues have been recently addressed (Lin and DemnerFushman 2005a, 2006b). Nugget Fscore has been employed as a metric in the TREC questionanswering track since 2003, to evaluate socalled definition and other'' questions <CITATION/>. Recently, there is a growing consensus that an evaluation methodology based on the notion of information nuggets'' may provide an appropriate framework for assessing the quality of answers to complex questions.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,570bfcb94270e1d565450fb6029a9f6e7c8749a2,Automatically Evaluating Answers to Definition Questions,2005,Jimmy J. Lin; Dina Demner-Fushman
1290,W05-0709,External_3692,[0],,"The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model ) <TARGET_CITATION/> .","We assign to each token in the text a label indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions. We use a maximum entropy Markov model (MEMM) classifier. The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model ) <TARGET_CITATION/> . The principle of maximum entropy states that when one searches among probability distributions that model the observed data (evidence), the preferred one is the one that maximizes the entropy (a measure of the uncertainty of the model) <CITATION/>. We use a maximum entropy Markov model (MEMM) classifier. We assign to each token in the text a label indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,fb486e03369a64de2d5b0df86ec0a7b55d3907db,A Maximum Entropy Approach to Natural Language Processing,1996,Adam L. Berger; S. D. Pietra; V. D. Pietra
1291,J10-3007,External_27540,[0],related work,"In the context of word alignment , <TARGET_CITATION/> use a stateduration HMM in order to model wordtophrase translations .","The idea of introducing constraints over a model to better guide the learning process has appeared before. In the context of word alignment , <TARGET_CITATION/> use a stateduration HMM in order to model wordtophrase translations . In the context of word alignment, <CITATION/> use a stateduration HMM in order to model wordtophrase translations. The idea of introducing constraints over a model to better guide the learning process has appeared before.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,e59cd429d043802ad0d83b2770518a07b3eb1d2c,HMM Word and Phrase Alignment for Statistical Machine Translation,2005,Yonggang Deng; W. Byrne
1293,D08-1016,P05-1010,[5],conclusion,"We could also introduce new variables , e.g. , nonterminal refinements <TARGET_CITATION/> , or secondary links Mid ( not constrained by TREE/PTREE ) that augment the parse with representations of control , binding , etc. <CITATION/> .","Belief propagation improves nonprojective dependency parsing with features that would make exact inference intractable. For projective parsing, it is significantly faster than exact dynamic programming, at the cost of small amounts of search error, We are interested in extending these ideas to phrasestructure and lattice parsing, and in trying other higherorder features, such as those used in parse reranking <CITATION/> and historybased parsing <CITATION/>. We could also introduce new variables , e.g. , nonterminal refinements <TARGET_CITATION/> , or secondary links Mid ( not constrained by TREE/PTREE ) that augment the parse with representations of control , binding , etc. <CITATION/> . We could also introduce new variables, e.g., nonterminal refinements <CITATION/>, or secondary links Mid (not constrained by TREE/PTREE) that augment the parse with representations of control, binding, etc. <CITATION/>. For projective parsing, it is significantly faster than exact dynamic programming, at the cost of small amounts of search error, We are interested in extending these ideas to phrasestructure and lattice parsing, and in trying other higherorder features, such as those used in parse reranking <CITATION/> and historybased parsing <CITATION/>. Belief propagation improves nonprojective dependency parsing with features that would make exact inference intractable.",ebbb58b2e616435b6ededbc103acfef6dc79bd51,Dependency Parsing by Belief Propagation,2008,David A. Smith; Jason Eisner,713a4825ea09801ebc24ce207ca9ae5fbc97ac65,Probabilistic CFG with Latent Annotations,2005,Takuya Matsuzaki; Yusuke Miyao; Junichi Tsujii
1299,P05-3005,External_35214,[2],,"The system utilizes several large size biological databases including three NCBI databases ( <CITATION/> , and Entrez GENE <CITATION/> ) , PSD database from Protein Information Resources ( PIR ) <TARGET_CITATION/> , and"," The system utilizes several large size biological databases including three NCBI databases ( <CITATION/> , and Entrez GENE <CITATION/> ) , PSD database from Protein Information Resources ( PIR ) <TARGET_CITATION/> , and The system utilizes several large size biological databases including three NCBI databases (<CITATION/>, and Entrez GENE <CITATION/>), PSD database from Protein Information Resources (PIR) <CITATION/>, and",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,,suzek be et al the protein information resource nucleic acids res,2003,Wu CH; Yeh LS; H Huang; L Arminski; J Castro-Alvear; Y Chen; Z Hu; P Kourtesis; Ledley RS
1309,P05-3005,External_95868,[2],,"Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly FlyBase <TARGET_CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> .","The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META. The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly FlyBase <TARGET_CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <CITATION/> . Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary, i.e., mouse Mouse Genome Database (MGD) <CITATION/>, fly <CITATION/>, yeast Saccharomyces Genome Database (SGD) <CITATION/>, rat  Rat Genome Database (RGD) <CITATION/>, worm  <CITATION/>, Human Nomenclature Database (HUGO) <CITATION/>, Online Mendelian Inheritance in Man (OMIM) <CITATION/>, and Enzyme Nomenclature Database (ECNUM) <CITATION/>.The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META.",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,,the flybase database of the drosophila genome projects and community literature nucleic acids res,2003,F Consortium
1317,J91-2003,External_3166,[4],introduction,"This Principle of Finitism is also assumed by <TARGET_CITATION/> , and implicitly or explicitly by almost all researchers in computational linguistics .","Therefore these notions, and all other constructs we are going to define (axioms, metarules, definitions etc.) are computational, although usually we will not provide explicit algorithms for computing them. The issues of control are not so important for us at this point; we restrict ourselves to describing the logic. This Principle of Finitism is also assumed by <TARGET_CITATION/> , and implicitly or explicitly by almost all researchers in computational linguistics . This Principle of Finitism is also assumed by <CITATION/>, and implicitly or explicitly by almost all researchers in computational linguistics. The issues of control are not so important for us at this point; we restrict ourselves to describing the logic. Therefore these notions, and all other constructs we are going to define (axioms, metarules, definitions etc.) are computational, although usually we will not provide explicit algorithms for computing them.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,c414875a916a05f6490aac594cf08f8cee7fb227,Semantics and Cognition,1991,R. Jackendoff
1318,J13-1008,P09-2056,[0],experiments,"For more information on CATiB , see <TARGET_CITATION/> .","An example CATiB dependency tree is shown in Figure 1. For the corpus statistics, see Table 1. For more information on CATiB , see <TARGET_CITATION/> . For more information on CATiB, see <CITATION/>.For the corpus statistics, see Table 1. An example CATiB dependency tree is shown in Figure 1.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,25f60908cc3613ddca64638bc9aa119f4c55e78a,CATiB: The Columbia Arabic Treebank,2009,Nizar Habash; Ryan Roth
1325,J07-1005,External_37367,[2],,Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy <TARGET_CITATION/> .,Metadata associated with most MEDLINE citations (MeSH terms) are extensively used to determine the strength of evidence and in our EBM citation scoring algorithm (Section 6). The potential highest level of the strength of evidence for a given citation can be identified using the Publication Type (a metadata field) and MeSH terms pertaining to the type of the clinical study. Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy <TARGET_CITATION/> . Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy <CITATION/>.The potential highest level of the strength of evidence for a given citation can be identified using the Publication Type (a metadata field) and MeSH terms pertaining to the type of the clinical study. Metadata associated with most MEDLINE citations (MeSH terms) are extensively used to determine the strength of evidence and in our EBM citation scoring algorithm (Section 6).,9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,79fd37bf64e4ae8b2a44965bf4c90e8fa616049c,Strength of recommendation taxonomy (SORT): a patient-centered approach to grading evidence in the medical literature.,2004,M. Ebell; J. Siwek; B. Weiss; S. Woolf; J. Susman; B. Ewigman; Marjorie A. Bowman
1329,J07-1005,External_89591,[0],introduction,"MEDLINE , the authoritative repository of abstracts from the medical and biomedical primary literature maintained by the National Library of Medicine , provides the clinically relevant sources for answering physicians ' questions , and is commonly used in that capacity ( <TARGET_CITATION/> ; De Groote and Dorsch 2003 ) .","The confluence of these many factors makes clinical question answering a very exciting area of research. Furthermore, the need to answer questions related to patient care at the point of service has been well studied and documented (Covell, Uman, and Manning 1985; Gorman, Ash, and Wykoff 1994; Ely et al. 1999, 2005). MEDLINE , the authoritative repository of abstracts from the medical and biomedical primary literature maintained by the National Library of Medicine , provides the clinically relevant sources for answering physicians ' questions , and is commonly used in that capacity ( <TARGET_CITATION/> ; De Groote and Dorsch 2003 ) . MEDLINE, the authoritative repository of abstracts from the medical and biomedical primary literature maintained by the National Library of Medicine, provides the clinically relevant sources for answering physicians' questions, and is commonly used in that capacity (Cogdill and Moore 1997; De Groote and Dorsch 2003). Furthermore, the need to answer questions related to patient care at the point of service has been well studied and documented (Covell, Uman, and Manning 1985; Gorman, Ash, and Wykoff 1994; Ely et al. 1999, 2005). The confluence of these many factors makes clinical question answering a very exciting area of research.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,daebd0d30ff94ac8feb2f5995ba4e65f45222a41,First-year medical students' information needs and resource selection: responses to a clinical scenario.,1997,K. Cogdill; M. E. Moore
1331,J91-2003,External_44423,[0],introduction,"He lists , classifies , and discusses various types of inference , by which he means , generally ,  the linguisticlogical notions of consequent and presupposition '' <TARGET_CITATION/>:112 ) have collected convincing evidence of the existence of language chunks  real structures , not just orthographic conventions  that are smaller than a discourse , larger than a sentence , generally composed of sentences , and recursive in nature ( like sentences ) .","The textualist approach to paragraph analysis is exemplified by E. J. Crothers. His work is taxonomic, in that he performs detailed descriptive analyses of paragraphs. He lists , classifies , and discusses various types of inference , by which he means , generally ,  the linguisticlogical notions of consequent and presupposition '' <TARGET_CITATION/>:112 ) have collected convincing evidence of the existence of language chunks  real structures , not just orthographic conventions  that are smaller than a discourse , larger than a sentence , generally composed of sentences , and recursive in nature ( like sentences ) . He lists, classifies, and discusses various types of inference, by which he means, generally, the linguisticlogical notions of consequent and presupposition'' Crothers (1979:112) have collected convincing evidence of the existence of language chunksreal structures, not just orthographic conventionsthat are smaller than a discourse, larger than a sentence, generally composed of sentences, and recursive in nature (like sentences). His work is taxonomic, in that he performs detailed descriptive analyses of paragraphs. The textualist approach to paragraph analysis is exemplified by E. J. Crothers.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,d99f3a684977faef51822bed1dd1eafced8f26c0,Paragraph Structure Inference,1979,E. Crothers
1335,E12-1068,W09-0420,[4],related work,<TARGET_CITATION/> tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms .,<CITATION/> introduced factored SMT. We use more complex context features. <TARGET_CITATION/> tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms . <CITATION/> tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms. We use more complex context features. <CITATION/> introduced factored SMT.,d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,5a6f330c3a320831e5cf64f9b69c3d8595dcb3d9,Experiments in Morphosyntactic Processing for Translating to and from German,2009,Alexander M. Fraser
1346,J14-2004,P10-1143,[3],related work,This article represents an extension of our previous work on unsupervised event coreference resolution <TARGET_CITATION/> ., This article represents an extension of our previous work on unsupervised event coreference resolution <TARGET_CITATION/> . This article represents an extension of our previous work on unsupervised event coreference resolution <CITATION/>.,f1a02d840f732f85942de4892c79ccc80d5123a5,Unsupervised Event Coreference Resolution,2014,C. Bejan; S. Harabagiu,791198ab24bea86944265887136843e00352e13f,Unsupervised Event Coreference Resolution with Rich Linguistic Features,2010,C. Bejan; S. Harabagiu
1348,E99-1022,External_51664,[0],introduction,"See , among others , <TARGET_CITATION/> .","State of the art topdown processing techniques are used to deal with the remaining constraints. Magic is a compilation technique originally developed for goaldirected bottomup processing of logic programs. See , among others , <TARGET_CITATION/> . See, among others, <CITATION/>. Magic is a compilation technique originally developed for goaldirected bottomup processing of logic programs. State of the art topdown processing techniques are used to deal with the remaining constraints.",3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,,efficient bottomup evaluation of logic programs,1992,Raghu Ramakrishnan; Divesh Srivastava; S Sudarshan
1361,W01-0706,External_24319,[0],introduction,"Research on shallow parsing was inspired by psycholinguistics arguments <TARGET_CITATION/> that suggest that in many scenarios ( e.g. , conversational ) full parsing is not a realistic strategy for sentence processing and analysis , and was further motivated by several arguments from a natural language engineering viewpoint .","While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). Research on shallow parsing was inspired by psycholinguistics arguments <TARGET_CITATION/> that suggest that in many scenarios ( e.g. , conversational ) full parsing is not a realistic strategy for sentence processing and analysis , and was further motivated by several arguments from a natural language engineering viewpoint . Research on shallow parsing was inspired by psycholinguistics arguments <CITATION/> that suggest that in many scenarios (e.g., conversational) full parsing is not a realistic strategy for sentence processing and analysis, and was further motivated by several arguments from a natural language engineering viewpoint. Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,3185f75000efa42a0ce91fecf9e03de3d5c66bcf,Performance structures: A psycholinguistic and linguistic appraisal,1983,J. Gee; F. Grosjean
1363,J10-3007,External_527,[2],,"results are based on a corpus of movie subtitles <CITATION/> , and are consequently shorter sentences , whereas the En  Es results are based on a corpus of parliamentary proceedings <TARGET_CITATION/> .","Vertical axis: percentage of transferred edges that are correct. Horizontal axis: average number of transferred edges per sentence. results are based on a corpus of movie subtitles <CITATION/> , and are consequently shorter sentences , whereas the En  Es results are based on a corpus of parliamentary proceedings <TARGET_CITATION/> . results are based on a corpus of movie subtitles <CITATION/>, and are consequently shorter sentences, whereas the EnEs results are based on a corpus of parliamentary proceedings <CITATION/>. Horizontal axis: average number of transferred edges per sentence. Vertical axis: percentage of transferred edges that are correct.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,694b3c58712deefb59502847ba1b52b192c413e5,Europarl: A Parallel Corpus for Statistical Machine Translation,2005,Philipp Koehn
1377,W05-0709,External_42603,[2],,"the mention subtype , which is a subcategory of the mention type <TARGET_CITATION/> ( e.g. OrgGovernmental , FacilityPath , etc. ) .","the mention level (named, nominal, pronominal, or premodifier) 3. the mention class (generic, specific, negatively quantified, etc.) 4. the mention subtype , which is a subcategory of the mention type <TARGET_CITATION/> ( e.g. OrgGovernmental , FacilityPath , etc. ) . the mention subtype, which is a subcategory of the mention type (ACE, 2004) (e.g. OrgGovernmental, FacilityPath, etc.).the mention class (generic, specific, negatively quantified, etc.) 4. the mention level (named, nominal, pronominal, or premodifier) 3.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,99757327b6169ce8d037de1ef9a20ba3f760f829,Automatic Content Extraction for Designing a French Clinical Corpus,2014,Louise Deléger; Cyril Grouin; Aurélie Névéol
1410,W05-0709,External_3322,[0],introduction,"The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks .","These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc.. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks . The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations <CITATION/>, and have been at the center of evaluations such as: MUC6, MUC7, and the CoNLL'02 and CoNLL'03 shared tasks. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc..",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,149f5137d1c7e34764e1f4d4d7b97b8e6bdeda2a,A Maximum Entropy Approach to Named Entity Recognition,1999,R. Grishman; Andrew Borthwick
1414,J07-1005,External_2531,[0],related work,"For an overview of systems designed to answer opendomain factoid questions , the TREC QA track overview papers are a good place to start <TARGET_CITATION/> .","As a result, there exist relatively few points of comparison to our own work, as the research space is sparsely populated. In this section, however, we will attempt to draw connections to other clinical information systems (although not necessarily for question answering) and related domainspecific questionanswering systems. For an overview of systems designed to answer opendomain factoid questions , the TREC QA track overview papers are a good place to start <TARGET_CITATION/> . For an overview of systems designed to answer opendomain factoid questions, the TREC QA track overview papers are a good place to start <CITATION/>. In this section, however, we will attempt to draw connections to other clinical information systems (although not necessarily for question answering) and related domainspecific questionanswering systems. As a result, there exist relatively few points of comparison to our own work, as the research space is sparsely populated.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,,the trec8 question answering track evaluation,1999,Ellen M Voorhees; Dawn M Tice
1424,J11-1005,P08-1101,[4],introduction,"For the joint segmentation and POStagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work <TARGET_CITATION/> , while being more than an order of magnitude faster .","We give an updated set of results, plus a number of additional experiments which probe further into the advantages and disadvantages of our framework. For the segmentation task, we also compare our beamsearch framework with alternative decoding algorithms including an exact dynamicprogramming method, showing that the beamsearch method is significantly faster with comparable accuracy. For the joint segmentation and POStagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work <TARGET_CITATION/> , while being more than an order of magnitude faster . For the joint segmentation and POStagging task, we present a novel solution using the framework in this article, and show that it gives comparable accuracies to our previous work <CITATION/>, while being more than an order of magnitude faster. For the segmentation task, we also compare our beamsearch framework with alternative decoding algorithms including an exact dynamicprogramming method, showing that the beamsearch method is significantly faster with comparable accuracy. We give an updated set of results, plus a number of additional experiments which probe further into the advantages and disadvantages of our framework.",f24fb33e739b0181fc171b515f957190e3bb6430,Syntactic Processing Using the Generalized Perceptron and Beam Search,2011,Yue Zhang; S. Clark,3594af2ebf510609651bf282dfea65c8e837b1a7,Joint Word Segmentation and POS Tagging Using a Single Perceptron,2008,Yue Zhang; S. Clark
1450,D08-1002,W07-1431,[1],experiments,"Although this is only true in cases where y occurs in an upward monotone context <TARGET_CITATION/> , in practice genuine contradictions between yvalues sharing a meronym relationship are extremely rare .","Meronyms: For some relations, there is no contradiction when y1 and y2 share a meronym, i.e. part of'' relation. For example, in the set born in(Mozart,) there is no contradiction between the y values Salzburg'' and Austria'', but Salzburg'' conflicts with Vienna''. Although this is only true in cases where y occurs in an upward monotone context <TARGET_CITATION/> , in practice genuine contradictions between yvalues sharing a meronym relationship are extremely rare . Although this is only true in cases where y occurs in an upward monotone context <CITATION/>, in practice genuine contradictions between yvalues sharing a meronym relationship are extremely rare. For example, in the set born in(Mozart,) there is no contradiction between the y values Salzburg'' and Austria'', but Salzburg'' conflicts with Vienna''. Meronyms: For some relations, there is no contradiction when y1 and y2 share a meronym, i.e. part of'' relation.",6fb0fe906c6d90f8111f5026770e1bbf12975241,"It’s a Contradiction – no, it’s not: A Case Study using Functional Relations",2008,Alan Ritter; S. Soderland; Doug Downey; Oren Etzioni,4639cb3718e4eb698a0285548ed2bf23ad9908a9,Natural Logic for Textual Inference,2007,Bill MacCartney; Christopher D. Manning
1458,E99-1022,P97-1001,[0],,The ConTroll grammar development system as described in <TARGET_CITATION/> implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars .,which are used to restrict lexical entries. <CITATION/> describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.4 Because of space limitations we have to refrain from an example. The ConTroll grammar development system as described in <TARGET_CITATION/> implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars . The ConTroll grammar development system as described in <CITATION/> implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars.<CITATION/> describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.4 Because of space limitations we have to refrain from an example. which are used to restrict lexical entries.,3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,32baa67816a9f4357e0ff675994724ad6e0876cb,Interleaving Universal Principles and Relational Constraints over Typed Feature Logic,1997,Thilo Götz; Walt Detmar Meurers
1462,J08-2002,External_63,[2],,"Therefore , in order to be able to incorporate longrange dependencies in our models , we chose to adopt a reranking approach <TARGET_CITATION/> , which selects from likely assignments generated by a model which makes stronger independence assumptions .","For argument labeling, the number of possible assignments is  20m, if m is the number of arguments of a verb (typically between 2 and 5), and 20 is the approximate number of possible labels if considering both core and modifying arguments. Training a model which has such a huge number of classes is infeasible if the model does not factorize due to strong independence assumptions. Therefore , in order to be able to incorporate longrange dependencies in our models , we chose to adopt a reranking approach <TARGET_CITATION/> , which selects from likely assignments generated by a model which makes stronger independence assumptions . Therefore, in order to be able to incorporate longrange dependencies in our models, we chose to adopt a reranking approach <CITATION/>, which selects from likely assignments generated by a model which makes stronger independence assumptions. Training a model which has such a huge number of classes is infeasible if the model does not factorize due to strong independence assumptions. For argument labeling, the number of possible assignments is  20m, if m is the number of arguments of a verb (typically between 2 and 5), and 20 is the approximate number of possible labels if considering both core and modifying arguments.",7ed7a41c275f2870b840a5e6c3eaec8888c9480c,A Global Joint Model for Semantic Role Labeling,2008,Kristina Toutanova; A. Haghighi; Christopher D. Manning,844db702be4bc149b06b822b47247e15f5894cc3,Discriminative Reranking for Natural Language Parsing,2000,M. Collins; Terry Koo
1463,J91-2003,External_38475,[0],introduction,"However , it is possible to think about constraining linguistic or logical predicates by simulating physical experiences ( cfXXX <TARGET_CITATION/> ) .","It is precisely this grounding'' of logical predicates in other conceptual structures that we would like to capture. We investigate here only the grounding'' in logical theories. However , it is possible to think about constraining linguistic or logical predicates by simulating physical experiences ( cfXXX <TARGET_CITATION/> ) . However, it is possible to think about constraining linguistic or logical predicates by simulating physical experiences (cfXXX Woods 1987). We investigate here only the grounding'' in logical theories. It is precisely this grounding'' of logical predicates in other conceptual structures that we would like to capture.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,dont blame the toolquot,1987,W Woods
1468,J91-2003,External_3166,[4],introduction,<TARGET_CITATION/> ) writes  it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . '',"notation of <CITATION/> is more sophisticated, and may be considered another possibility. Jackendoff's (1983) formalism is richer and resembles more closely an English grammar. <TARGET_CITATION/> ) writes  it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . '' <CITATION/> writes it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys.'' Jackendoff's (1983) formalism is richer and resembles more closely an English grammar. notation of <CITATION/> is more sophisticated, and may be considered another possibility.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,c414875a916a05f6490aac594cf08f8cee7fb227,Semantics and Cognition,1991,R. Jackendoff
1469,E99-1022,External_43334,[0],,See also <TARGET_CITATION/> .,"Finally, the used topdown interpreter implements a powerful coroutining mechanism:12 At run time the processing of a goal is postponed in case it is insufficiently instantiated. Whether or not a goal is sufficiently instantiated is determined on the basis of socalled delay patterns.13 These are specifications provided by the user that 12Coroutining appears under many different guises, like for example, suspension, residuation, (goal) freezing, and blocking. See also <TARGET_CITATION/> . See also <CITATION/>. Whether or not a goal is sufficiently instantiated is determined on the basis of socalled delay patterns.13 These are specifications provided by the user that 12Coroutining appears under many different guises, like for example, suspension, residuation, (goal) freezing, and blocking. Finally, the used topdown interpreter implements a powerful coroutining mechanism:12 At run time the processing of a goal is postponed in case it is insufficiently instantiated.",3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,,prologii manuel de reference et modele theorique,1982,Alain Colmerauer
1487,W05-0709,P03-1051,[2],,<TARGET_CITATION/> demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation ., <TARGET_CITATION/> demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation . <CITATION/> demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation.,0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,e493205bc5151b02fe2712d813dd38f5f9ea9ba2,Language Model Based Arabic Word Segmentation,2003,Young-suk Lee; K. Papineni; S. Roukos; O. Emam; Hany Hassan
1495,J07-1005,External_53397,[0],introduction,"Third , the paradigm of evidencebased medicine <TARGET_CITATION/> provides a taskbased model of the clinical informationseeking process .","The 2004 version of the UMLS Metathesaurus (used in this work) contains information about over 1 million biomedical concepts and 5 million concept names from more than 100 controlled vocabularies. The Semantic Network provides a consistent categorization of all concepts represented in the UMLS Metathesaurus. Third , the paradigm of evidencebased medicine <TARGET_CITATION/> provides a taskbased model of the clinical informationseeking process . Third, the paradigm of evidencebased medicine <CITATION/> provides a taskbased model of the clinical informationseeking process. The Semantic Network provides a consistent categorization of all concepts represented in the UMLS Metathesaurus. The 2004 version of the UMLS Metathesaurus (used in this work) contains information about over 1 million biomedical concepts and 5 million concept names from more than 100 controlled vocabularies.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,,evidencebased medicine how to practice and teach ebm second edition churchill livingstone,2000,David L Sackett; Sharon E Straus; W Scott Richardson; William Rosenberg; R Brian Haynes
1496,E12-1068,D07-1091,[4],related work,<TARGET_CITATION/> introduced factored SMT .,"The only work that we are aware of which deals with both issues is the work of de <CITATION/>, which deals with verbal morphology and attached pronouns. There has been other work on solving inflection. <TARGET_CITATION/> introduced factored SMT . <CITATION/> introduced factored SMT. There has been other work on solving inflection. The only work that we are aware of which deals with both issues is the work of de <CITATION/>, which deals with verbal morphology and attached pronouns.",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,659f1f754954d093e684ead4842832052f7bf748,Factored Translation Models,2007,Philipp Koehn; Hieu D. Hoang
1497,W05-0709,External_3692,[2],introduction,Both systems are built around from the maximumentropy technique <TARGET_CITATION/> .,It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <CITATION/>. Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in <CITATION/> and the coreference resolution system is similar to the one described in <CITATION/>. Both systems are built around from the maximumentropy technique <TARGET_CITATION/> . Both systems are built around from the maximumentropy technique <CITATION/>. Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in <CITATION/> and the coreference resolution system is similar to the one described in <CITATION/>. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <CITATION/>.,0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,fb486e03369a64de2d5b0df86ec0a7b55d3907db,A Maximum Entropy Approach to Natural Language Processing,1996,Adam L. Berger; S. D. Pietra; V. D. Pietra
1498,N01-1009,External_1172,[2],experiments,We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature <TARGET_CITATION/> .,3.1.1 Materials and DesignWe chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly selected from the BNC. We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature <TARGET_CITATION/> . We chose the adjectives as follows: we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature <CITATION/>. We chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly selected from the BNC. 3.1.1 Materials and Design,3d4226a01208653d3598685cfa571390e193791d,A Corpus-based Account of Regular Polysemy: The Case of Context-sensitive Adjectives,2001,Maria Lapata,259d0304adcb49e40436137684b78a80c9ef097b,The Generative Lexicon,1991,J. Pustejovsky
1501,W01-0706,External_6640,[2],experiments,"For the full parser , we use the one developed by Michael Collins <TARGET_CITATION/>  one of the most accurate full parsers around .","We perform our comparison using two stateoftheart parsers. For the full parser , we use the one developed by Michael Collins <TARGET_CITATION/>  one of the most accurate full parsers around . For the full parser, we use the one developed by Michael Collins <CITATION/>  one of the most accurate full parsers around. We perform our comparison using two stateoftheart parsers.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,3764baa7465201f054083d02b58fa75f883c4461,A New Statistical Parser Based on Bigram Lexical Dependencies,1996,M. Collins
1502,J13-1008,N10-1115,[4],experiments,"Some researchers , however , including <TARGET_CITATION/> , train on predicted feature values instead .","Combined Gold and Predicted Features for TrainingSo far, we have only evaluated models trained on gold POS tag set and morphological feature values. Some researchers , however , including <TARGET_CITATION/> , train on predicted feature values instead . Some researchers, however, including <CITATION/>, train on predicted feature values instead. So far, we have only evaluated models trained on gold POS tag set and morphological feature values. Combined Gold and Predicted Features for Training",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,3ce0f00d6c949192107f1bd6a167c03e1fb7393a,An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing,2010,Yoav Goldberg; Michael Elhadad
1513,E12-1068,P10-1047,[4],related work,"Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of <TARGET_CITATION/> and others .","In German these linguistic features are marked very irregularly and there is widespread syncretism, making it difficult to split off morphemes specifying these features. So it is questionable as to whether morpheme segmentation techniques are sufficient to solve the inflectional problem we are addressing. Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of <TARGET_CITATION/> and others . Much previous work looks at the impact of using source side information (i.e., feature functions on the aligned English), such as those of <CITATION/> and others. So it is questionable as to whether morpheme segmentation techniques are sufficient to solve the inflectional problem we are addressing. In German these linguistic features are marked very irregularly and there is widespread syncretism, making it difficult to split off morphemes specifying these features.",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,5d4735f21d572796b3ad643a6dbe585db90d0a07,Syntax-to-Morphology Mapping in Factored Phrase-Based Statistical Machine Translation from English to Turkish,2010,Reyyan Yeniterzi; Kemal Oflazer
1517,W05-0709,N04-1001,[4],introduction,Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in <TARGET_CITATION/> and the coreference resolution system is similar to the one described in <CITATION/> .,"derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <CITATION/>. Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in <TARGET_CITATION/> and the coreference resolution system is similar to the one described in <CITATION/> . Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in <CITATION/> and the coreference resolution system is similar to the one described in <CITATION/>. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging <CITATION/>. derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,54c04d731368ad14ab3902c1abae46b8b62cb633,A Statistical Model for Multilingual Entity Detection and Tracking,2004,Radu Florian; Hany Hassan; Abraham Ittycheriah; Hongyan Jing; N. Kambhatla; Xiaoqiang Luo; Nicolas Nicolov; S. Roukos
1534,W05-0709,N04-1001,[0],,The context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not <TARGET_CITATION/> .,"This set can be partitioned into 4 categories: lexical, syntactic, gazetteerbased, and those obtained by running other namedentity classifiers (with different tag sets). We use features such as the shallow parsing information associated with the tokens in a window of 3 tokens, POS, etc.. The context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not <TARGET_CITATION/> . The context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not <CITATION/>. We use features such as the shallow parsing information associated with the tokens in a window of 3 tokens, POS, etc.. This set can be partitioned into 4 categories: lexical, syntactic, gazetteerbased, and those obtained by running other namedentity classifiers (with different tag sets).",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,54c04d731368ad14ab3902c1abae46b8b62cb633,A Statistical Model for Multilingual Entity Detection and Tracking,2004,Radu Florian; Hany Hassan; Abraham Ittycheriah; Hongyan Jing; N. Kambhatla; Xiaoqiang Luo; Nicolas Nicolov; S. Roukos
1535,W05-0709,P04-1018,[2],,Features using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution <TARGET_CITATION/> ., Features using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution <TARGET_CITATION/> . Features using the word context (left and right tokens) have been shown to be very helpful in coreference resolution <CITATION/>.,0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,4f8dd94c1a1454cc34475a4f533e137c7e4afd8d,A Mention-Synchronous Coreference Resolution Algorithm Based On the Bell Tree,2004,Xiaoqiang Luo; Abraham Ittycheriah; Hongyan Jing; N. Kambhatla; S. Roukos
1548,N01-1003,External_63,[4],introduction,"The SPR uses rules automatically learned from training data , using techniques similar to <TARGET_CITATION/> .","In the second phase, the sentenceplanranker (SPR) ranks the sample sentence plans, and then selects the topranked output to input to the surface realizer. Our primary contribution is a method for training the SPR. The SPR uses rules automatically learned from training data , using techniques similar to <TARGET_CITATION/> . The SPR uses rules automatically learned from training data, using techniques similar to <CITATION/>. Our primary contribution is a method for training the SPR. In the second phase, the sentenceplanranker (SPR) ranks the sample sentence plans, and then selects the topranked output to input to the surface realizer.",ee6892b9c7f1a491e0925b913b66281c48408f74,SPoT: A Trainable Sentence Planner,2001,M. Walker; Owen Rambow; Monica Rogati,844db702be4bc149b06b822b47247e15f5894cc3,Discriminative Reranking for Natural Language Parsing,2000,M. Collins; Terry Koo
1551,N01-1003,External_24304,[0],,"These operations are not domainspecific and are similar to those of previous aggregation components <TARGET_CITATION/> , although the various MERGE operations are , to our knowledge , novel in this form .","PERIOD. Joins two complete clauses with a period. These operations are not domainspecific and are similar to those of previous aggregation components <TARGET_CITATION/> , although the various MERGE operations are , to our knowledge , novel in this form . These operations are not domainspecific and are similar to those of previous aggregation components <CITATION/>, although the various MERGE operations are, to our knowledge, novel in this form. Joins two complete clauses with a period. PERIOD.",ee6892b9c7f1a491e0925b913b66281c48408f74,SPoT: A Trainable Sentence Planner,2001,M. Walker; Owen Rambow; Monica Rogati,e5ba636047b974b8f99e840df097caa38f1f1d96,Clause Aggregation Using Linguistic Knowledge,1998,James Shaw
1569,E99-1022,External_24317,[4],introduction,As such it resembles the parser of the grammar development system Attribute Language Engine ( ALE ) of <TARGET_CITATION/> .,"The proposed parser is related to the socalled Lemma Table deduction system (Johnson and D6rre, 1995) which allows the user to specify whether topdown subcomputations are to be tabled. In contrast to Johnson and D6rre's deduction system, though, the selective magic parsing approach combines topdown and bottomup control strategies. As such it resembles the parser of the grammar development system Attribute Language Engine ( ALE ) of <TARGET_CITATION/> . As such it resembles the parser of the grammar development system Attribute Language Engine (ALE) of <CITATION/>. In contrast to Johnson and D6rre's deduction system, though, the selective magic parsing approach combines topdown and bottomup control strategies. The proposed parser is related to the socalled Lemma Table deduction system (Johnson and D6rre, 1995) which allows the user to specify whether topdown subcomputations are to be tabled.",3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,a3179ab83aaf84c8147fc24a3357c595d10687fb,"ALE : the attribute logic engine user's guide, version 2.0.1",1992,Bob Carpenter; Gerald Penn
1573,J07-1005,External_37367,[2],,Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy <TARGET_CITATION/> .,Metadata associated with most MEDLINE citations (MeSH terms) are extensively used to determine the strength of evidence and in our EBM citation scoring algorithm (Section 6). The potential highest level of the strength of evidence for a given citation can be identified using the Publication Type (a metadata field) and MeSH terms pertaining to the type of the clinical study. Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy <TARGET_CITATION/> . Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy <CITATION/>.The potential highest level of the strength of evidence for a given citation can be identified using the Publication Type (a metadata field) and MeSH terms pertaining to the type of the clinical study. Metadata associated with most MEDLINE citations (MeSH terms) are extensively used to determine the strength of evidence and in our EBM citation scoring algorithm (Section 6).,9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,79fd37bf64e4ae8b2a44965bf4c90e8fa616049c,Strength of recommendation taxonomy (SORT): a patient-centered approach to grading evidence in the medical literature.,2004,M. Ebell; J. Siwek; B. Weiss; S. Woolf; J. Susman; B. Ewigman; Marjorie A. Bowman
1574,J00-3001,External_244,[2],conclusion,"While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure <TARGET_CITATION/> :","Note that this technique is optimal for the extraction of the lowestfrequency words, leading to identical performance for G2 and Fisher's exact test for these words. For the higherfrequency words, Fisher's exact test leads to a slightly better recall with the same precision scores (0.31 for both tests). While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure <TARGET_CITATION/> : While we have observed reasonable results with both G2 and Fisher's exact test, we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information (MI) measure <CITATION/>:For the higherfrequency words, Fisher's exact test leads to a slightly better recall with the same precision scores (0.31 for both tests). Note that this technique is optimal for the extraction of the lowestfrequency words, leading to identical performance for G2 and Fisher's exact test for these words.",886dffd5b9d41c77365fb3893dd05f2067862d13,Extracting the lowest-frequency words: pitfalls and possibilities,2000,M. Weeber; R. Vos; R. Baayen,9e2caa39ac534744a180972a30a320ad0ae41ea3,"Word Association Norms, Mutual Information, and Lexicography",1989,Kenneth Ward Church; Patrick Hanks
1578,W01-0706,External_34197,[0],introduction,"Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) .","to ] [NP only $ 1.8 billion ] [PP in ] [NP September] . While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) . Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,f5bb34e38e3403054d4396fc48882f02eae1ffcc,Error-Driven Pruning of Treebank Grammars for Base Noun Phrase Identification,1998,Claire Cardie; D. Pierce
1589,J91-2003,External_65798,[0],introduction,An example of psycholinguistically oriented research work can be found in <TARGET_CITATION/> .,"In these sources, a paragraph is notionally defined as something like a series of sentences that develop one single topic, and rules are laid down for the construction of an ideal (or at least an acceptable) paragraph. Although these dictates are fairly clear, the underlying notion of topic is not. An example of psycholinguistically oriented research work can be found in <TARGET_CITATION/> . An example of psycholinguistically oriented research work can be found in <CITATION/>. Although these dictates are fairly clear, the underlying notion of topic is not. In these sources, a paragraph is notionally defined as something like a series of sentences that develop one single topic, and rules are laid down for the construction of an ideal (or at least an acceptable) paragraph.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,f937a643326ef161bacf882f65ab353bd1d45f75,Cues People Use to Paragraph Text,1984,S. Bond; J. Hayes
1591,J91-2003,External_44423,[0],introduction,"<TARGET_CITATION/> ) , for example , bemoans the fact that his  theory lacks a world knowledge component , a mental  encyclopedia , ' which could be invoked to generate inferences ... '' .","This type of consultation uses existing natural language texts as a referential level for processing purposes. It is the lack of exactly this notion of referential level that has stood in the way of other linguists who have been interested in the paragraph as a unit. <TARGET_CITATION/> ) , for example , bemoans the fact that his  theory lacks a world knowledge component , a mental  encyclopedia , ' which could be invoked to generate inferences ... '' . <CITATION/>, for example, bemoans the fact that his theory lacks a world knowledge component, a mental encyclopedia,' which could be invoked to generate inferences... ''. It is the lack of exactly this notion of referential level that has stood in the way of other linguists who have been interested in the paragraph as a unit. This type of consultation uses existing natural language texts as a referential level for processing purposes.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,d99f3a684977faef51822bed1dd1eafced8f26c0,Paragraph Structure Inference,1979,E. Crothers
1603,J91-2003,External_5163,[0],introduction," petty conversational implicature '' <TARGET_CITATION/> , or the metarules of Section 5.2 ?","6.1.1 Was the Use of a Gricean Maxim Necessary? Can one deal effectively with the problem of reference without axiomatized Gricean maxims, for instance by using only petty conversational implicature '' <TARGET_CITATION/> , or the metarules of Section 5.2 ? petty conversational implicature'' <CITATION/>, or the metarules of Section 5.2? Can one deal effectively with the problem of reference without axiomatized Gricean maxims, for instance by using only6.1.1 Was the Use of a Gricean Maxim Necessary?",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,coherence and coreferencequot,1979,J R Hobbs
1618,P05-3005,External_24086,[2],,"Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <TARGET_CITATION/> .","The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META. The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) <CITATION/> , fly <CITATION/> , yeast Saccharomyces Genome Database ( SGD ) <CITATION/> , rat  Rat Genome Database ( RGD ) <CITATION/> , worm  <CITATION/> , Human Nomenclature Database ( HUGO ) <CITATION/> , Online Mendelian Inheritance in Man ( OMIM ) <CITATION/> , and Enzyme Nomenclature Database ( ECNUM ) <TARGET_CITATION/> . Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary, i.e., mouse Mouse Genome Database (MGD) <CITATION/>, fly <CITATION/>, yeast Saccharomyces Genome Database (SGD) <CITATION/>, rat  Rat Genome Database (RGD) <CITATION/>, worm  <CITATION/>, Human Nomenclature Database (HUGO) <CITATION/>, Online Mendelian Inheritance in Man (OMIM) <CITATION/>, and Enzyme Nomenclature Database (ECNUM) <CITATION/>.The Semantic Network contains information about the types or categories (e.g., Disease or Syndrome'', Virus'') to which all META concepts have been assigned. The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META.",5e16986346ba5362ae3947dc59cee74a247f2902,Dynamically Generating a Protein Entity Dictionary Using Online Resources,2005,Hongfang Liu; Zhang-Zhi Hu; Cathy H. Wu,,enzyme nomenclature functional or structural rna,2000,P Gegenheimer
1628,E12-1068,P08-1087,[4],related work,"Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of <TARGET_CITATION/> and others .","In German these linguistic features are marked very irregularly and there is widespread syncretism, making it difficult to split off morphemes specifying these features. So it is questionable as to whether morpheme segmentation techniques are sufficient to solve the inflectional problem we are addressing. Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of <TARGET_CITATION/> and others . Much previous work looks at the impact of using source side information (i.e., feature functions on the aligned English), such as those of <CITATION/> and others. So it is questionable as to whether morpheme segmentation techniques are sufficient to solve the inflectional problem we are addressing. In German these linguistic features are marked very irregularly and there is widespread syncretism, making it difficult to split off morphemes specifying these features.",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,71bd8077b00cf418df80057e404f778b468c8c52,Enriching Morphologically Poor Languages for Statistical Machine Translation,2008,Eleftherios Avramidis; Philipp Koehn
1633,W01-0706,W99-0621,[2],experiments,The shallow parser used is the SNoWbased CSCL parser <TARGET_CITATION/> .,The experiments use the version that was trained (by Collins) on sections 0221 of the Penn Treebank. The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 <CITATION/>. The shallow parser used is the SNoWbased CSCL parser <TARGET_CITATION/> . The shallow parser used is the SNoWbased CSCL parser <CITATION/>. The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 <CITATION/>. The experiments use the version that was trained (by Collins) on sections 0221 of the Penn Treebank.,cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,a31d6f597f78599c6df66dedf64cd5bc05c5327a,A Learning Approach to Shallow Parsing,1999,Marcia Muñoz; Vasin Punyakanok; D. Roth; Dav Zimak
1634,E12-1068,External_7548,[4],related work,"Other approaches use less deep linguistic resources ( e.g. , POStags <TARGET_CITATION/> ) or are ( almost ) knowledgefree ( e.g. , <CITATION/> ) .","Using additional source side information beyond the markup did not produce a gain in performance. For compound splitting, we follow <CITATION/>, using linguistic knowledge encoded in a rulebased morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies. Other approaches use less deep linguistic resources ( e.g. , POStags <TARGET_CITATION/> ) or are ( almost ) knowledgefree ( e.g. , <CITATION/> ) . Other approaches use less deep linguistic resources (e.g., POStags <CITATION/>) or are (almost) knowledgefree (e.g., <CITATION/>). For compound splitting, we follow <CITATION/>, using linguistic knowledge encoded in a rulebased morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies. Using additional source side information beyond the markup did not produce a gain in performance.",d0013135c1adfe2f18031f70efd3b023a20f4a21,Modeling Inflection and Word-Formation in SMT,2012,Alexander M. Fraser; Marion Weller; A. Cahill; Fabienne Cap,d90a4f8fc424909e9fb40ffd5a9088d7a6b8e937,German Compounds in Factored Statistical Machine Translation,2008,Sara Stymne
1642,W05-0709,J01-4004,[0],introduction,"The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks .","These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc.. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks . The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations <CITATION/>, and have been at the center of evaluations such as: MUC6, MUC7, and the CoNLL'02 and CoNLL'03 shared tasks. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc..",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,a20bfec3c95aad003dcb45a21a220c19cca8bb66,A Machine Learning Approach to Coreference Resolution of Noun Phrases,2001,Wee Meng Soon; H. Ng; Chung Yong Lim
1658,W05-0709,P03-1051,[2],,"As in <TARGET_CITATION/> , we used unsupervised training data which is automatically segmented to discover previously unseen stems .","However, an analysis of the errors indicated that the character based model is more effective at segmenting words that do not appear in the training data. We seeked to exploit this ability to generalize to improve the dictionary based model. As in <TARGET_CITATION/> , we used unsupervised training data which is automatically segmented to discover previously unseen stems . As in <CITATION/>, we used unsupervised training data which is automatically segmented to discover previously unseen stems. We seeked to exploit this ability to generalize to improve the dictionary based model. However, an analysis of the errors indicated that the character based model is more effective at segmenting words that do not appear in the training data.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,e493205bc5151b02fe2712d813dd38f5f9ea9ba2,Language Model Based Arabic Word Segmentation,2003,Young-suk Lee; K. Papineni; S. Roukos; O. Emam; Hany Hassan
1663,J10-3007,P07-1003,[2],,This heuristic is called soft union <TARGET_CITATION/> .,the knowledge about the posterior distributions of each directional model. We include a point in the final alignment if the average of the posteriors under the two models for that point is above a threshold. This heuristic is called soft union <TARGET_CITATION/> . This heuristic is called soft union <CITATION/>. We include a point in the final alignment if the average of the posteriors under the two models for that point is above a threshold. the knowledge about the posterior distributions of each directional model.,270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,3629b977c9675a51476fdfd59795178b6b29fafb,Tailoring Word Alignments to Syntactic Machine Translation,2007,John DeNero; D. Klein
1667,J91-2003,External_76184,[2],introduction,"This semantics was constructed ( <TARGET_CITATION/> , 1987b ) as a formal framework for default and commonsense reasoning .","where s, m, d, are constants. We adopt the threelevel semantics as a formal tool for the analysis of paragraphs. This semantics was constructed <TARGET_CITATION/> as a formal framework for default and commonsense reasoning . This semantics was constructed (Zadrozny 1987a, 1987b) as a formal framework for default and commonsense reasoning. We adopt the threelevel semantics as a formal tool for the analysis of paragraphs. where s, m, d, are constants.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,intended models circumscription and commonsense reasoningquot,1987,W Zadrozny
1669,J91-2003,External_34289,[4],introduction,"Similarly , the notion of R + Mabduction is spiritually related to the  abductive inference '' of <CITATION/> , the  diagnosis from first principles '' of <CITATION/> ,  explainability '' of <CITATION/> , and the subset principle of <TARGET_CITATION/> .","Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of uniquename assumption'' <CITATION/>, domain closure assumption'' (ibid.), domain circumscription'' (cfXXX Etherington and Mercer 1987), and their kin. Similarly , the notion of R + Mabduction is spiritually related to the  abductive inference '' of <CITATION/> , the  diagnosis from first principles '' of <CITATION/> ,  explainability '' of <CITATION/> , and the subset principle of <TARGET_CITATION/> . Similarly, the notion of R + Mabduction is spiritually related to the abductive inference'' of <CITATION/>, the diagnosis from first principles'' of <CITATION/>, explainability'' of <CITATION/>, and the subset principle of <CITATION/>. , domain circumscription'' (cfXXX Etherington and Mercer 1987), and their kin. Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of uniquename assumption'' <CITATION/>, domain closure assumption'' (ibid.)",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,learning from positiveonly examples the subset principle and three case studiesquot,1986,R C Berwick
1670,W05-0709,E99-1001,[0],introduction,"The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks .","These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc.. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks . The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations <CITATION/>, and have been at the center of evaluations such as: MUC6, MUC7, and the CoNLL'02 and CoNLL'03 shared tasks. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc..",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,aa8c4d7b07e1b03dfe214b247e62c27de33b63b6,Named Entity Recognition without Gazetteers,1999,Andrei Mikheev; M. Moens; Claire Grover
1672,A00-2004,External_30123,[3],,"R98 ( , , , ,  ) uses a variant of Kozima 's semantic similarity measure <TARGET_CITATION/> to compute block similarity .","in section 3.4. R98(,,d0t) is the modularised version of R98 for experimenting with different similarity measures. R98 ( , , , ,  ) uses a variant of Kozima 's semantic similarity measure <TARGET_CITATION/> to compute block similarity . R98(,,) uses a variant of Kozima's semantic similarity measure <CITATION/> to compute block similarity. R98(,,d0t) is the modularised version of R98 for experimenting with different similarity measures. in section 3.4.",448aa9b04905e421a8ef6e864c183f7ca6a7bb45,Advances in domain independent linear text segmentation,2000,Freddy Y. Y. Choi,6fc74be27e660130014129c03d5961f974499fcb,Text Segmentation Based on Similarity between Words,1993,H. Kozima
1679,J10-3007,External_38,[1],introduction,"But their importance has grown far beyond machine translation : for instance , transferring annotations between languages <TARGET_CITATION/> ; discovery of paraphrases <CITATION/> ; and joint unsupervised POS and parser induction across languages <CITATION/> .","Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as forMT system combination <CITATION/>. But their importance has grown far beyond machine translation : for instance , transferring annotations between languages <TARGET_CITATION/> ; discovery of paraphrases <CITATION/> ; and joint unsupervised POS and parser induction across languages <CITATION/> . But their importance has grown far beyond machine translation: for instance, transferring annotations between languages <CITATION/>; discovery of paraphrases <CITATION/>; and joint unsupervised POS and parser induction across languages <CITATION/>. MT system combination <CITATION/>. Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as for",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,,bootstrapping parsers via syntactic projection across parallel texts natural language engineering,2005,Rebecca Hwa; Philip Resnik; Amy Weinberg; Clara Cabezas; Okan Kolak
1688,J13-1008,E12-1069,[4],related work,"19 The paper by <TARGET_CITATION/> presents additional , more sophisticated models that we do not use in this article .","17 We also applied the manipulations described in Section A.3 to FNNUM, giving us the variants FNNUMDGT and FNNUMDGTBIN, which we tested similarly. 18 In this article, we use a newer version of the corpus by <CITATION/> than the one we used in <CITATION/>. 19 The paper by <TARGET_CITATION/> presents additional , more sophisticated models that we do not use in this article . 19 The paper by <CITATION/> presents additional, more sophisticated models that we do not use in this article.18 In this article, we use a newer version of the corpus by <CITATION/> than the one we used in <CITATION/>. 17 We also applied the manipulations described in Section A.3 to FNNUM, giving us the variants FNNUMDGT and FNNUMDGTBIN, which we tested similarly.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,58fdacf0d40ddcb304536992a04fa2000022d8de,"Identifying Broken Plurals, Irregular Gender, and Rationality in Arabic Text",2012,Sarah Alkuhlani; Nizar Habash
1690,J91-2003,External_44421,[4],introduction,"Although there are other discussions of the paragraph as a central element of discourse <TARGET_CITATION/> , all of them share a certain limitation in their formal techniques for analyzing paragraph structure ."," Although there are other discussions of the paragraph as a central element of discourse <TARGET_CITATION/> , all of them share a certain limitation in their formal techniques for analyzing paragraph structure . Although there are other discussions of the paragraph as a central element of discourse <CITATION/>, all of them share a certain limitation in their formal techniques for analyzing paragraph structure.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,the episode schema in story processingquot,1980,K Haberlandt; C Berian; J Sandson
1693,W05-0709,External_42603,[2],experiments,"We introduce here a clearly defined and replicable split of the <TARGET_CITATION/> data , so that future investigations can accurately and correctly compare against the results presented here .","The system is trained on the Arabic ACE 2003 and part of the 2004 data. We introduce here a clearly defined and replicable split of the <TARGET_CITATION/> data , so that future investigations can accurately and correctly compare against the results presented here . We introduce here a clearly defined and replicable split of the ACE 2004 data, so that future investigations can accurately and correctly compare against the results presented here. The system is trained on the Arabic ACE 2003 and part of the 2004 data.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,99757327b6169ce8d037de1ef9a20ba3f760f829,Automatic Content Extraction for Designing a French Clinical Corpus,2014,Louise Deléger; Cyril Grouin; Aurélie Névéol
1707,J91-2003,External_1447,[0],introduction,"Other factors , such as the role of focus ( Grosz 1977 , 1978 ; <TARGET_CITATION/> ) or quantifier scoping <CITATION/> must play a role , too .","We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution. They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it). Other factors , such as the role of focus ( Grosz 1977 , 1978 ; <TARGET_CITATION/> ) or quantifier scoping <CITATION/> must play a role , too . Other factors, such as the role of focus (Grosz 1977, 1978; Sidner 1983) or quantifier scoping <CITATION/> must play a role, too. They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it). We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,focusing in the comprehension of definite anaphoraquot,1983,C Sidner
1730,W01-0706,External_4604,[2],experiments,"SNoW <TARGET_CITATION/> is a multiclass classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .","The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 <CITATION/>. The shallow parser used is the SNoWbased CSCL parser <CITATION/>. SNoW <TARGET_CITATION/> is a multiclass classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example . SNoW <CITATION/> is a multiclass classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example. The shallow parser used is the SNoWbased CSCL parser <CITATION/>. The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 <CITATION/>.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,3ed17a1114e2dc48597ab17cc8d5234006f525c9,Learning to Resolve Natural Language Ambiguities: A Unified Approach,1998,D. Roth
1742,J13-1008,External_8755,[0],related work,"As for work on Arabic ( MSA ) , results have been reported on the PATB <TARGET_CITATION/> , the Prague Dependency Treebank ( PADT ) <CITATION/> and the CATiB <CITATION/> .","We also find that the number feature helps for Arabic. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima'an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. As for work on Arabic ( MSA ) , results have been reported on the PATB <TARGET_CITATION/> , the Prague Dependency Treebank ( PADT ) <CITATION/> and the CATiB <CITATION/> . As for work on Arabic (MSA), results have been reported on the PATB <CITATION/>, the Prague Dependency Treebank (PADT) <CITATION/> and the CATiB <CITATION/>. Looking at Hebrew, a Semitic language related to Arabic, Tsarfaty and Sima'an (2007) report that extending POS and phrase structure tags with definiteness information helps unlexicalized PCFG parsing. We also find that the number feature helps for Arabic.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,,towards an optimal pos tag set for modern standard arabic processing,2007,Mona Diab
1762,W05-0709,External_87915,[2],,"The final machine is a trigram language model , specifically a KneserNey <TARGET_CITATION/> based backoff language model .","The first machine, illustrated in Figure 1 encodes the prefix and suffix expansion rules, producing a lattice of possible segmentations. The second machine is a dictionary that accepts characters and produces identifiers corresponding to dictionary entries. The final machine is a trigram language model , specifically a KneserNey <TARGET_CITATION/> based backoff language model . The final machine is a trigram language model, specifically a KneserNey <CITATION/> based backoff language model. The second machine is a dictionary that accepts characters and produces identifiers corresponding to dictionary entries. The first machine, illustrated in Figure 1 encodes the prefix and suffix expansion rules, producing a lattice of possible segmentations.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,,an empirical study of smoothing techinques for language modeling,1998,S F Chen; J Goodman
1767,J07-1005,External_16632,[4],experiments,"As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail  this is the standard pipeline architecture commonly employed in other questionanswering systems <TARGET_CITATION/> .","Ideally, we would like to match structured representations derived from the question with those derived from MEDLINE citations (taking into consideration other EBMrelevant factors). However, we do not have access to the computational resources necessary to apply knowledge extractors to the 15 million plus citations in the MEDLINE database and directly index their results. As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail  this is the standard pipeline architecture commonly employed in other questionanswering systems <TARGET_CITATION/> . As an alternative, we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detailthis is the standard pipeline architecture commonly employed in other questionanswering systems <CITATION/>. However, we do not have access to the computational resources necessary to apply knowledge extractors to the 15 million plus citations in the MEDLINE database and directly index their results. Ideally, we would like to match structured representations derived from the question with those derived from MEDLINE citations (taking into consideration other EBMrelevant factors).",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,4fcc00570dcf797c3f18fbc5df926edd79ffb3b3,Natural language question answering: the view from here,2001,L. Hirschman; R. Gaizauskas
1779,N01-1013,External_19410,[4],experiments,The task we used to compare different generalisation techniques is similar to that used by <TARGET_CITATION/> ., The task we used to compare different generalisation techniques is similar to that used by <TARGET_CITATION/> . The task we used to compare different generalisation techniques is similar to that used by <CITATION/>.,636a9580ca9a2554a2a388696ec12f5c3181dd52,Class-Based Probability Estimation Using a Semantic Hierarchy,2001,S. Clark; David J. Weir,,inducing a semantically annotated lexicon via embased clustering,1999,M Rooth; S Riezler; D Prescher; G Carroll; F Beil
1784,J10-3007,External_3667,[0],introduction,"Due to this inherent ambiguity , manual annotations usually distinguish between sure correspondences for unambiguous translations , and possible , for ambiguous translations <TARGET_CITATION/> .","A word alignment for a parallel sentence pair represents the correspondence between words in a source language and their translations in a target language <CITATION/>. There are many reasons why a simple wordtoword (1to1) correspondence is not possible for every sentence pair: for instance, auxiliary verbs used in one language but not the other (e.g., English He walked and French Il est alle), articles required in one language but optional in the other (e.g., English Cars use gas and Portuguese Os carros usam gasolina), cases where the content is expressed using multiple words in one language and a single word in the other language (e.g., agglutination such as English weapons of mass destruction and German Massenvernichtungswaffen), and expressions translated indirectly. Due to this inherent ambiguity , manual annotations usually distinguish between sure correspondences for unambiguous translations , and possible , for ambiguous translations <TARGET_CITATION/> . Due to this inherent ambiguity, manual annotations usually distinguish between sure correspondences for unambiguous translations, and possible, for ambiguous translations <CITATION/>. There are many reasons why a simple wordtoword (1to1) correspondence is not possible for every sentence pair: for instance, auxiliary verbs used in one language but not the other (e.g., English He walked and French Il est alle), articles required in one language but optional in the other (e.g., English Cars use gas and Portuguese Os carros usam gasolina), cases where the content is expressed using multiple words in one language and a single word in the other language (e.g., agglutination such as English weapons of mass destruction and German Massenvernichtungswaffen), and expressions translated indirectly. A word alignment for a parallel sentence pair represents the correspondence between words in a source language and their translations in a target language <CITATION/>.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,de2df29b0a0312de7270c3f5a0af6af5645cf91a,A Systematic Comparison of Various Statistical Alignment Models,2003,F. Och; H. Ney
1791,W01-0706,W00-0726,[0],introduction,would be chunked as follows ( Tjong Kim <TARGET_CITATION/> ) : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP,"A lot of recent work on shallow parsing has been influenced by Abney's work <CITATION/>, who has suggested to chunk'' sentences to base level phrases. For example, the sentence He reckons the current account deficit will narrow to only $ 1.8 billion in September .'' would be chunked as follows ( Tjong Kim <TARGET_CITATION/> ) : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP would be chunked as follows (Tjong Kim <CITATION/>): [NP He ] [VP reckons ] [NP the current account deficit ] [VP will narrow ] [PPFor example, the sentence He reckons the current account deficit will narrow to only $ 1.8 billion in September .'' A lot of recent work on shallow parsing has been influenced by Abney's work <CITATION/>, who has suggested to chunk'' sentences to base level phrases.",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,9e85832b04cc3700c2c26d6ba93fdeae39cac04a,Introduction to the CoNLL-2000 Shared Task Chunking,2000,E. Tjong Kim Sang; S. Buchholz
1795,E99-1022,P97-1001,[3],introduction,Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar ( HPSG ; <CITATION/> ) as discussed in <TARGET_CITATION/> .,"magic is an interesting technique with respect to natural language processing as it incorporates filtering into the logic underlying the grammar and enables elegant control independent filtering improvements. In this paper we investigate the selective application of magic to typed feature grammars a type of constraintlogic grammar based on Typed Feature Logic (T r; G6tz, 1995). Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar ( HPSG ; <CITATION/> ) as discussed in <TARGET_CITATION/> . Typed feature grammars can be used as the basis for implementations of Headdriven Phrase Structure Grammar (HPSG; <CITATION/>) as discussed in <CITATION/>. In this paper we investigate the selective application of magic to typed feature grammars a type of constraintlogic grammar based on Typed Feature Logic (T r; G6tz, 1995). magic is an interesting technique with respect to natural language processing as it incorporates filtering into the logic underlying the grammar and enables elegant control independent filtering improvements.",3dcdcb15a3da453b154870453151e92b94e82920,Selective Magic HPSG Parsing,1999,Guido Minnen,32baa67816a9f4357e0ff675994724ad6e0876cb,Interleaving Universal Principles and Relational Constraints over Typed Feature Logic,1997,Thilo Götz; Walt Detmar Meurers
1804,J91-2003,External_76181,[0],introduction,"Some of the intuitions we associate with this notion have been very well expressed by <TARGET_CITATION/> , pp. 78 ) : ... Semantics is constrained by our models of ourselves and our worlds .","This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an objectlevel theory. The referential structures we are going to use are collections of logical theories, but the concept of reference is more general. Some of the intuitions we associate with this notion have been very well expressed by <TARGET_CITATION/> , pp. 78 ) : ... Semantics is constrained by our models of ourselves and our worlds . Some of the intuitions we associate with this notion have been very well expressed by Turner (1987, pp. 78): ... Semantics is constrained by our models of ourselves and our worlds. The referential structures we are going to use are collections of logical theories, but the concept of reference is more general. This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an objectlevel theory.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,05322560ac122561fad8d4fecc5b35f2edc9dde7,Death Is the Mother of Beauty,1987,M. Turner
1816,J91-2003,External_34285,[4],introduction," Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing <TARGET_CITATION/> , with one difference : the activation spreads to theories that share a predicate , not through the ISA hierarchy , and is limited to elementary facts about predicates appearing in the text .","Moreover, in addition to proposing this structure of R, we have described the two mechanisms for exploiting it, coherence'' and dominance,'' which are not variants of the standard first order entailment, but abduction. The idea of using preferences among theories is new, hence it was described in more detail. Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing <TARGET_CITATION/> , with one difference : the activation spreads to theories that share a predicate , not through the ISA hierarchy , and is limited to elementary facts about predicates appearing in the text . Coherence,'' as outlined above, can be understood as a declarative (or static) version of marker passing <CITATION/>, with one difference: the activation spreads to theories that share a predicate, not through the ISA hierarchy, and is limited to elementary facts about predicates appearing in the text. The idea of using preferences among theories is new, hence it was described in more detail. Moreover, in addition to proposing this structure of R, we have described the two mechanisms for exploiting it, coherence'' and dominance,'' which are not variants of the standard first order entailment, but abduction.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,passing markers a theory of contextual influence in language comprehensionquot,1983,E Charniak
1818,W01-0706,External_56408,[0],introduction,"First , it has been noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many largescale language processing applications including information extraction and text summarization <TARGET_CITATION/> .","Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). Research on shallow parsing was inspired by psycholinguistics arguments <CITATION/> that suggest that in many scenarios (e.g., conversational) full parsing is not a realistic strategy for sentence processing and analysis, and was further motivated by several arguments from a natural language engineering viewpoint. First , it has been noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many largescale language processing applications including information extraction and text summarization <TARGET_CITATION/> . First, it has been noted that in many natural language applications it is sufficient to use shallow parsing information; information such as noun phrases (NPs) and other syntactic sequences have been found useful in many largescale language processing applications including information extraction and text summarization <CITATION/>. Research on shallow parsing was inspired by psycholinguistics arguments <CITATION/> that suggest that in many scenarios (e.g., conversational) full parsing is not a realistic strategy for sentence processing and analysis, and was further motivated by several arguments from a natural language engineering viewpoint. Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>).",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,,the nyu system for muc6 or where’s syntax in,1995,R Grishman
1827,W05-0709,External_36918,[0],introduction,"The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks .","These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc.. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks . The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations <CITATION/>, and have been at the center of evaluations such as: MUC6, MUC7, and the CoNLL'02 and CoNLL'03 shared tasks. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc..",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,,bbn description of the sift system as used for muc7,1998,S Miller; M Crystal; H Fox; L Ramshaw; R Schwarz; R Stone; R Weischedel
1847,J07-1005,External_2531,[4],experiments,"As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail  this is the standard pipeline architecture commonly employed in other questionanswering systems <TARGET_CITATION/> .","Ideally, we would like to match structured representations derived from the question with those derived from MEDLINE citations (taking into consideration other EBMrelevant factors). However, we do not have access to the computational resources necessary to apply knowledge extractors to the 15 million plus citations in the MEDLINE database and directly index their results. As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail  this is the standard pipeline architecture commonly employed in other questionanswering systems <TARGET_CITATION/> . As an alternative, we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detailthis is the standard pipeline architecture commonly employed in other questionanswering systems <CITATION/>. However, we do not have access to the computational resources necessary to apply knowledge extractors to the 15 million plus citations in the MEDLINE database and directly index their results. Ideally, we would like to match structured representations derived from the question with those derived from MEDLINE citations (taking into consideration other EBMrelevant factors).",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,,the trec8 question answering track evaluation,1999,Ellen M Voorhees; Dawn M Tice
1849,J91-2003,External_80366,[4],introduction,"Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX <TARGET_CITATION/> ; Frisch 1987 ; PatelSchneider 1985 ) .","Form(F). 0 is a ground instance of a formula 0, if 0 contains no variables, and 0 = 00, for some substitution O. Thus, we do not require Th(T) to be closed under substitution instances of tautologies. Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX <TARGET_CITATION/> ; Frisch 1987 ; PatelSchneider 1985 ) . Although in this paper we take modus ponens as the main rule of inference, in general one can consider deductive closures with respect to weaker, nonstandard logics, (cfXXX Levesque 1984; Frisch 1987; PatelSchneider 1985). 0 is a ground instance of a formula 0, if 0 contains no variables, and 0 = 00, for some substitution O. Thus, we do not require Th(T) to be closed under substitution instances of tautologies. Form(F).",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,a logic of implicit and explicit beliefsquot,1984,H J Levesque
1851,J91-2003,External_1497,[0],introduction,"Other factors , such as the role of focus <TARGET_CITATION/> or quantifier scoping <CITATION/> must play a role , too .","We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution. They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it). Other factors , such as the role of focus <TARGET_CITATION/> or quantifier scoping <CITATION/> must play a role , too . Other factors, such as the role of focus (Grosz 1977, 1978; Sidner 1983) or quantifier scoping <CITATION/> must play a role, too. They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it). We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,the representation and use of focus in a system for understanding dialogsquot,1977,B J Grosz
1856,W05-0709,External_4380,[0],introduction,"The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks .","These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc.. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations <TARGET_CITATION/> , and have been at the center of evaluations such as : MUC6 , MUC7 , and the CoNLL '02 and CoNLL '03 shared tasks . The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations <CITATION/>, and have been at the center of evaluations such as: MUC6, MUC7, and the CoNLL'02 and CoNLL'03 shared tasks. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc..",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,,nymble a highperformance learning namefinder,1997,D M Bikel; S Miller; R Schwartz; R Weischedel
1863,J91-2003,External_65798,[0],introduction,An example of psycholinguistically oriented research work can be found in <TARGET_CITATION/> .,"In these sources, a paragraph is notionally defined as something like a series of sentences that develop one single topic, and rules are laid down for the construction of an ideal (or at least an acceptable) paragraph. Although these dictates are fairly clear, the underlying notion of topic is not. An example of psycholinguistically oriented research work can be found in <TARGET_CITATION/> . An example of psycholinguistically oriented research work can be found in <CITATION/>. Although these dictates are fairly clear, the underlying notion of topic is not. In these sources, a paragraph is notionally defined as something like a series of sentences that develop one single topic, and rules are laid down for the construction of an ideal (or at least an acceptable) paragraph.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,f937a643326ef161bacf882f65ab353bd1d45f75,Cues People Use to Paragraph Text,1984,S. Bond; J. Hayes
1873,W01-0706,P98-1010,[0],introduction,"Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) .","to ] [NP only $ 1.8 billion ] [PP in ] [NP September] . While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/> , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( <TARGET_CITATION/> ; Tjong Kim <CITATION/> ) . Thus, over the past few years, along with advances in the use of learning and statistical methods for acquisition of full parsers <CITATION/>, significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship (<CITATION/>; Tjong Kim <CITATION/>). While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local partofspeech information. to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .",cb352f6df85ada5f90ab0301e3bdbf37c93b3190,Exploring evidence for shallow parsing,2001,Xin Li; Dan Roth,7fad831935254c9c9ec39ffb03752a3f736c3f76,A Memory-Based Approach to Learning Shallow Natural Language Patterns,1998,S. Argamon; Ido Dagan; Yuval Krymolowski
1875,J13-1008,J08-4003,[4],related work,"11 <TARGET_CITATION/> reports that nonprojective and pseudoprojective algorithms outperform the  eager '' projective algorithm in MaltParser , but our training data did not contain any nonprojective dependencies .","All experiments reported here were conducted using this new configuration. To recap, it has the following MaltParser attributes (machine learning features): 4 wordform attributes, 7 POS tag attributes, and 5 deprel attributes (some of which are not useful for the Nivre eager'' algorithm), totaling 16 attributes and two more for every new feature described in Section 4.3 and on (e.g., CASE). 11 <TARGET_CITATION/> reports that nonprojective and pseudoprojective algorithms outperform the  eager '' projective algorithm in MaltParser , but our training data did not contain any nonprojective dependencies . 11 <CITATION/> reports that nonprojective and pseudoprojective algorithms outperform the eager'' projective algorithm in MaltParser, but our training data did not contain any nonprojective dependencies. To recap, it has the following MaltParser attributes (machine learning features): 4 wordform attributes, 7 POS tag attributes, and 5 deprel attributes (some of which are not useful for the Nivre eager'' algorithm), totaling 16 attributes and two more for every new feature described in Section 4.3 and on (e.g., CASE). All experiments reported here were conducted using this new configuration.",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,053f1cf10ced2321c1853f307075f0a6a83b6840,Algorithms for Deterministic Incremental Dependency Parsing,2008,Joakim Nivre
1877,J10-3007,External_3667,[4],,For MT the most commonly used heuristic is called grow diagonal final <TARGET_CITATION/> .,Typically this is achieved by a symmetrization heuristic that takes two directional alignments and produces a singlealignment. For MT the most commonly used heuristic is called grow diagonal final <TARGET_CITATION/> . For MT the most commonly used heuristic is called grow diagonal final <CITATION/>. alignment. Typically this is achieved by a symmetrization heuristic that takes two directional alignments and produces a single,270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,de2df29b0a0312de7270c3f5a0af6af5645cf91a,A Systematic Comparison of Various Statistical Alignment Models,2003,F. Och; H. Ney
1878,W05-0709,P04-1018,[2],experiments,"ECMF is an entityconstrained mention Fmeasure ( cfXXX <TARGET_CITATION/> for how ECMF is computed ) , and ACEValue is the official ACE evaluation metric .","True'' mentions mean that input to the coreference system are mentions marked by human, while system mentions are output from the mention detection system. We report results with two metrics: ECMF and ACEValue. ECMF is an entityconstrained mention Fmeasure ( cfXXX <TARGET_CITATION/> for how ECMF is computed ) , and ACEValue is the official ACE evaluation metric . ECMF is an entityconstrained mention Fmeasure (cfXXX <CITATION/> for how ECMF is computed), and ACEValue is the official ACE evaluation metric. We report results with two metrics: ECMF and ACEValue. True'' mentions mean that input to the coreference system are mentions marked by human, while system mentions are output from the mention detection system.",0f84b5e9a2781c4128f705059d5825f91bd6c05c,The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution,2005,I. Zitouni; Jeffrey Scott Sorensen; Xiaoqiang Luo; Radu Florian,4f8dd94c1a1454cc34475a4f533e137c7e4afd8d,A Mention-Synchronous Coreference Resolution Algorithm Based On the Bell Tree,2004,Xiaoqiang Luo; Abraham Ittycheriah; Hongyan Jing; N. Kambhatla; S. Roukos
1886,J10-3007,External_2514,[0],related work,"PR is closely related to the work of <TARGET_CITATION/> ) , who concurrently developed the idea of using penalties based on posterior expectations of features to guide semisupervised learning .","By contrast the statements we can make in PR are of the form there should be more short edges than long edges''. Such a statement is datadependent in the sense that if the model satisfies the constraints then we do not need to change it; if it is far from satisfying it we might need to make very dramatic changes. PR is closely related to the work of <TARGET_CITATION/> ) , who concurrently developed the idea of using penalties based on posterior expectations of features to guide semisupervised learning . PR is closely related to the work of Mann and McCallum (2007, 2008), who concurrently developed the idea of using penalties based on posterior expectations of features to guide semisupervised learning. Such a statement is datadependent in the sense that if the model satisfies the constraints then we do not need to change it; if it is far from satisfying it we might need to make very dramatic changes.By contrast the statements we can make in PR are of the form there should be more short edges than long edges''.",270f0ef0f96ccb6a8c628f923372727b8d8a135b,Learning Tractable Word Alignment Models with Complex Constraints,2010,João Graça; Kuzman Ganchev; B. Taskar,,simple robust scalable semisupervised learning via expectation regularization,2007,G Mann; A McCallum
1899,J91-2003,External_504,[1],introduction,"This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose <TARGET_CITATION/> .","Note: In our translation from English to logic we are assuming that it'' is anaphoric (with the pronoun following the element that it refers to), not cataphoric (the other way around). This means that the it'' that brought the disease in P1 will not be considered to refer to the infection i'' or the death d'' in P3. This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose <TARGET_CITATION/> . This strategy is certainly the right one to start out with, since anaphora is always the more typical direction of reference in English prose <CITATION/>. This means that the it'' that brought the disease in P1 will not be considered to refer to the infection i'' or the death d'' in P3. Note: In our translation from English to logic we are assuming that it'' is anaphoric (with the pronoun following the element that it refers to), not cataphoric (the other way around).",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,b4d5633b96ea5e0f9e90e03df58e8ad0f6f3dee7,Cohesion in English,1976,M. Halliday; R. Hasan
1909,J13-1008,External_4979,[2],related work,"KUbler , McDonald , and <TARGET_CITATION/> describe a  typical '' MaltParser model configuration of attributes and features .13 Starting with it , in a series of initial controlled experiments , we settled on using buf <CITATION/> + stk <CITATION/> for wordforms , and buf <CITATION/> + stk <CITATION/> for POS tags .","The most commonly used feature functions are the top of the input buffer (next word to process, denoted buf<CITATION/>), or top of the stack (denoted stk<CITATION/>); following items on buffer or stack are also accessible (buf<CITATION/>, buf<CITATION/>, stk<CITATION/>, etc.). Hence MaltParser features are defined as POS tag at stk<CITATION/>, wordform at buf<CITATION/>, and so on. KUbler , McDonald , and <TARGET_CITATION/> describe a  typical '' MaltParser model configuration of attributes and features .13 Starting with it , in a series of initial controlled experiments , we settled on using buf <CITATION/> + stk <CITATION/> for wordforms , and buf <CITATION/> + stk <CITATION/> for POS tags . K<CITATION/> describe a typical'' MaltParser model configuration of attributes and features.13 Starting with it, in a series of initial controlled experiments, we settled on using buf<CITATION/> + stk<CITATION/> for wordforms, and buf<CITATION/> + stk<CITATION/> for POS tags. Hence MaltParser features are defined as POS tag at stk<CITATION/>, wordform at buf<CITATION/>, and so on. The most commonly used feature functions are the top of the input buffer (next word to process, denoted buf<CITATION/>), or top of the stack (denoted stk<CITATION/>); following items on buffer or stack are also accessible (buf<CITATION/>, buf<CITATION/>, stk<CITATION/>, etc.).",4a8b56e3e4f695e21e4dc839747049a5a389336f,Dependency Parsing of Modern Standard Arabic with Lexical and Inflectional Features,2013,Yuval Marton; Nizar Habash; Owen Rambow,60dad30438b1543c20ab67cf02107b4ed7250dc1,Parsing Indian Languages with MaltParser,2009,Joakim Nivre
1910,J07-1005,External_53398,[2],,"For this evaluation , we randomly selected 50 abstracts with disorders indexed as the main topic from abstracts retrieved using PubMed on the five clinical questions described in <TARGET_CITATION/> .","Although our problem extractor returns a list of clinical problems, we only evaluate performance on identification of the primary problem. For some abstracts, MeSH headings can be used as ground truth, because one of the human indexers' tasks in assigning terms is to identify the main topic of the article (sometimes a disorder). For this evaluation , we randomly selected 50 abstracts with disorders indexed as the main topic from abstracts retrieved using PubMed on the five clinical questions described in <TARGET_CITATION/> . For this evaluation, we randomly selected 50 abstracts with disorders indexed as the main topic from abstracts retrieved using PubMed on the five clinical questions described in <CITATION/>. For some abstracts, MeSH headings can be used as ground truth, because one of the human indexers' tasks in assigning terms is to identify the main topic of the article (sometimes a disorder). Although our problem extractor returns a list of clinical problems, we only evaluate performance on identification of the primary problem.",9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,2007,Dina Demner-Fushman; Jimmy J. Lin,,semantic characteristics of medline citations useful for therapeutic decisionmaking,2005,Charles Sneiderman; Dina Demner-Fushman; Marcelo Fiszman; Thomas C Rindflesch
1912,J91-2003,External_41326,[0],introduction,"This approach is taken in computational syntactic grammars <TARGET_CITATION/> ; the number of unlikely parses is severely reduced whenever possible , but no attempt is made to define only the socalled grammatical strings of a language .","In our case the concept black + death,'' which does not refer to any normal experiences, would be discarded as useless, although the collection of sentences would be recognized as a strange, even if coherent, paragraph. We can also hope for some finetuning of the notion of topic, which would prevent many offensive examples. This approach is taken in computational syntactic grammars <TARGET_CITATION/> ; the number of unlikely parses is severely reduced whenever possible , but no attempt is made to define only the socalled grammatical strings of a language . This approach is taken in computational syntactic grammars <CITATION/>; the number of unlikely parses is severely reduced whenever possible, but no attempt is made to define only the socalled grammatical strings of a language. We can also hope for some finetuning of the notion of topic, which would prevent many offensive examples. In our case the concept black + death,'' which does not refer to any normal experiences, would be discarded as useless, although the collection of sentences would be recognized as a strange, even if coherent, paragraph.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,parsing strategies in a broadcoverage grammar of english research report rc 12147 ibm tj watson research center,1986,K Jensen
1915,J91-2003,External_6974,[4],introduction," Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing <TARGET_CITATION/> , with one difference : the activation spreads to theories that share a predicate , not through the ISA hierarchy , and is limited to elementary facts about predicates appearing in the text .","Moreover, in addition to proposing this structure of R, we have described the two mechanisms for exploiting it, coherence'' and dominance,'' which are not variants of the standard first order entailment, but abduction. The idea of using preferences among theories is new, hence it was described in more detail. Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing <TARGET_CITATION/> , with one difference : the activation spreads to theories that share a predicate , not through the ISA hierarchy , and is limited to elementary facts about predicates appearing in the text . Coherence,'' as outlined above, can be understood as a declarative (or static) version of marker passing <CITATION/>, with one difference: the activation spreads to theories that share a predicate, not through the ISA hierarchy, and is limited to elementary facts about predicates appearing in the text. The idea of using preferences among theories is new, hence it was described in more detail. Moreover, in addition to proposing this structure of R, we have described the two mechanisms for exploiting it, coherence'' and dominance,'' which are not variants of the standard first order entailment, but abduction.",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,e31b8ff1107d312005028a8daaab7e88612c9855,Semantic interpretation and the resolution of ambiguity,1989,S. Bonzi
1930,J91-2003,External_5163,[3],introduction,"We shall see this in the next example : two sentences , regarded as a fragment of paragraph , are a variation on a theme by <TARGET_CITATION/> .","We do not claim that Gla is the best or unique way of expressing the rule assume that the writer did not say too much.'' Rather, we stress the possibility that one can axiomatize and productively use such a rule. We shall see this in the next example : two sentences , regarded as a fragment of paragraph , are a variation on a theme by <TARGET_CITATION/> . We shall see this in the next example: two sentences, regarded as a fragment of paragraph, are a variation on a theme by <CITATION/>.Rather, we stress the possibility that one can axiomatize and productively use such a rule. We do not claim that Gla is the best or unique way of expressing the rule assume that the writer did not say too much.''",c5e51bfbe4b33ffd3dd12e240d6146ab7e7b7eeb,Semantics of Paragraphs,1991,Wlodek Zadrozny; Karen Jensen,,coherence and coreferencequot,1979,J R Hobbs

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from unidecode import unidecode\n",
    "from collections import OrderedDict\n",
    "import argparse\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnContext(prev, target, next, prev_nr, next_nr):\n",
    "    if (prev_nr == 0):\n",
    "        prev = []\n",
    "    elif (prev_nr < len(prev)):\n",
    "        prev = prev[-prev_nr:]\n",
    "    if (next_nr == 0):\n",
    "        next = []\n",
    "    elif (next_nr < len(next)):\n",
    "        next = next[:next_nr]\n",
    "    return list(itertools.chain(prev, target, next))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "DATA_DIR = '../data'\n",
    "DATA_SET = 'multicite'\n",
    "OUTPUT_CAT = ['t','bt','tn','btn','bbt','tnn']\n",
    "\n",
    "DATASET_DIR = DATA_DIR + f'/{DATA_SET}'\n",
    "\n",
    "for cat in OUTPUT_CAT:\n",
    "    if not os.path.exists(os.path.join(DATASET_DIR, f'{DATA_SET}_fc_{cat}')):\n",
    "        os.makedirs(os.path.join(DATASET_DIR, f'{DATA_SET}_fc_{cat}'))\n",
    "\n",
    "for dataset in [\"train\", \"test\"]:\n",
    "    data_df = pd.read_csv(DATASET_DIR + f\"/{dataset}_raw.txt\", sep=\"\\t\", engine=\"python\", dtype=object)\n",
    "    data_df['cite_context_paragraph'] = data_df['cite_context_paragraph'].apply(eval)\n",
    "    result_t = pd.DataFrame(columns=['CC','label'])\n",
    "    result_bt = pd.DataFrame(columns=['CC','label'])\n",
    "    result_tn = pd.DataFrame(columns=['CC','label'])\n",
    "    result_btn = pd.DataFrame(columns=['CC','label'])\n",
    "    result_bbt = pd.DataFrame(columns=['CC','label'])\n",
    "    result_tnn = pd.DataFrame(columns=['CC','label'])\n",
    "    for idx, row in data_df.iterrows():\n",
    "        paragraph = row['cite_context_paragraph']\n",
    "        citation_context = [row['citation_context']]\n",
    "        \n",
    "        try:\n",
    "            citing_sent_index = paragraph.index(citation_context[0])\n",
    "            context_prev = paragraph[:citing_sent_index]\n",
    "            context_next =  paragraph[citing_sent_index +1:]      \n",
    "        except (IndexError, ValueError) as e:\n",
    "            print(idx)\n",
    "            print(citation_context)\n",
    "            print('Index not found!')\n",
    "        result_t.loc[len(result_t)] = [returnContext(context_prev, citation_context, context_next, 0, 0), row['citation_class_label']]\n",
    "        result_bt.loc[len(result_bt)] = [returnContext(context_prev, citation_context, context_next, 1, 0), row['citation_class_label']]\n",
    "        result_tn.loc[len(result_tn)] = [returnContext(context_prev, citation_context, context_next, 0, 1), row['citation_class_label']]\n",
    "        result_btn.loc[len(result_btn)] = [returnContext(context_prev, citation_context, context_next, 1, 1), row['citation_class_label']]\n",
    "        result_bbt.loc[len(result_bbt)] = [returnContext(context_prev, citation_context, context_next, 2, 0), row['citation_class_label']]\n",
    "        result_tnn.loc[len(result_tnn)] = [returnContext(context_prev, citation_context, context_next, 0, 2), row['citation_class_label']]\n",
    "    result_t.to_csv(f'{DATASET_DIR}/{DATA_SET}_fc_t/{dataset}.csv', index=False)\n",
    "    result_bt.to_csv(f'{DATASET_DIR}/{DATA_SET}_fc_bt/{dataset}.csv', index=False)\n",
    "    result_tn.to_csv(f'{DATASET_DIR}/{DATA_SET}_fc_tn/{dataset}.csv', index=False)\n",
    "    result_btn.to_csv(f'{DATASET_DIR}/{DATA_SET}_fc_btn/{dataset}.csv', index=False)\n",
    "    result_bbt.to_csv(f'{DATASET_DIR}/{DATA_SET}_fc_bbt/{dataset}.csv', index=False)\n",
    "    result_tnn.to_csv(f'{DATASET_DIR}/{DATA_SET}_fc_tnn/{dataset}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

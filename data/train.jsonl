{"id": "00bcb525-6b6f-48be-8bd6-60852038c995", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["Neural", "Machine", "Translation", "(NMT)", "has", "opened", "several", "research", "directions", "to", "exploit", "as", "many", "and", "diverse", "data", "as", "possible.", "Massive", "multilingual", "NMT", "models,", "for", "instance,", "take", "advantage", "of", "several", "language-pair", "datasets", "in", "a", "single", "system", "(Johnson et al., 2017).", "This", "offers", "several", "advantages,", "such", "as", "a", "simple", "training", "process", "and", "enhanced", "performance", "of", "the", "language-pairs", "with", "little", "data", "(although", "sometimes", "detrimental", "to", "the", "high-resource", "language-pairs).", "However,", "massive", "models", "of", "dozens", "of", "languages", "are", "not", "necessarily", "the", "best", "outcome,", "as", "it", "is", "demonstrated", "that", "smaller", "clusters", "still", "offer", "the", "same", "benefits", "(Tan et al., 2019, Oncevay et al., 2020)."], "cited_papers": [{"title": "Google's multilingual neural machine translation system: Enabling zero-shot translation", "year": "2017", "authors": ["Melvin Johnson", "Mike Schuster", "Quoc Le", "Maxim Krikun", "Yonghui Wu", "Zhifeng Chen", "Nikhil Thorat", "Fernanda Vi\u00e9gas", "Martin Wattenberg", "Greg Corrado", "Macduff Hughes", "Jeffrey Dean"]}], "target_citation_location": 34, "citation_locations": [34, 86], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "010f860b-24d4-4e94-b0d2-593693d657e6", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["As", "shown", "in", "Table", "1,", "the", "size", "of", "the", "'in-domain'", "TED", "training", "data", "is", "much", "smaller", "than", "the", "'out-of-domain'", "Multi-UN", "training", "data.", "Since", "adding", "a", "significant", "amount", "of", "out-ofdomain", "data", "to", "an", "in-domain", "corpus", "reduces", "the", "quality", "of", "translation", "for", "in-domain", "sentences", "[23],", "we", "decided", "to", "use", "only", "a", "part", "of", "the", "out-of-domain", "data", "to", "enhance", "the", "translation", "quality.", "In", "order", "to", "achieve", "this,", "we", "constructed", "a", "language", "model", "on", "the", "TED", "monolingual", "data", "and", "computed", "sentence-level", "perplexity", "score", "for", "all", "the", "sentences", "in", "Multi-UN,", "with", "respect", "to", "the", "TED", "language", "model.", "After", "sorting", "the", "sentences", "in", "the", "ascending", "order", "of", "the", "perplexity", "values,", "only", "sentences", "below", "a", "specific", "threshold", "were", "selected.", "This", "method", "provided", "us", "with", "the", "most", "'TED-like'", "sentences", "from", "the", "Multi-UN", "corpora."], "cited_papers": [{"title": "Experiments on Domain Adaptation for English-Hindi SMT", "year": "2009", "authors": ["R Haque", "S Naskar", "J Van Genabith", "A Way"]}], "target_citation_location": 42, "citation_locations": [42], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "014223dd-b870-48b7-9281-c9fbacf18f6f", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["Automatic", "extraction", "of", "events", "has", "gained", "sizable", "attention", "in", "subfields", "of", "NLP", "and", "information", "retrieval", "such", "as", "automatic", "summarization,", "question", "answering", "and", "knowledge", "graph", "embeddings", "(Chieu and Lee, 2004, Glava\u0161 and \u0160najder, 2014),", "as", "events", "are", "a", "representation", "of", "temporal", "information", "and", "sequences", "in", "text.", "Various", "developments", "in", "guidelines", "and", "datasets", "for", "event", "detection", "have", "been", "met", "with", "equally", "fast", "paced", "evolution", "of", "automatic", "event", "annotation", "and", "detection", "methodologies", "in", "the", "last", "few", "years", "(Doddington et al., 2004, Pustejovsky et al., 2010, O'Gorman et al., 2016).", "On", "a", "larger", "scale,", "event", "extraction", "has", "extended", "to", "many", "languages", "beyond", "English,", "including", "French", "(Bittar et al., 2011),", "Spanish", "(Saur\u0131, 2010),", "Italian", "(Caselli et al., 2011a)", "and", "very", "recently,", "Hindi", "(Goud et al., 2019b).", "Event", "detection", "architectures", "have", "their", "origins", "in", "statistical", "models", "such", "as", "K-means", "and", "hierarchical", "clustering", "methods", "(Arnulphy et al., 2015),", "which", "have", "more", "recently", "given", "way", "to", "neural", "models.", "Deep", "neural", "architectures", "on", "event", "annotation", "vary", "based", "on", "the", "approach", "taken", "to", "identifying", "and", "handling", "the", "data."], "cited_papers": [{"title": "Query based event extraction along a timeline", "year": "2004", "authors": ["Hai Leong Chieu", "Yoong Keok Lee"]}, {"title": "Event graphs for information retrieval and multi-document summarization. Expert systems with applications", "year": "2014", "authors": ["Goran Glava\u0161"]}], "target_citation_location": 25, "citation_locations": [25, 67, 83, 85, 87, 92, 109], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0157b9a7-b148-4d34-8d56-a4d827539085", "citing_paper": {"title": "A Parameter-Based Message-Passing Parser for MT of Korean and English", "year": 1994, "authors": ["Bonnie Dorr", "Jye-Hoon Lee", "Sungki Suh"]}, "text": ["The", "subject", "NP", "'Bill'", "is", "coindexed", "with", "the", "trace", "in", "the", "more", "deeply", "embedded", "relative", "clause.", "If", "we", "assume,", "following", "Chomsky (1986a),", "that", "relative", "clause", "formation", "involves", "movement", "from", "an", "inner", "clause", "into", "an", "outer", "subject", "position,", "then", "the", "grammaticality", "of", "the", "above", "example", "suggests", "that", "the", "Trace", "theory", "must", "be", "parameterized", "so", "that", "crossing", "more", "than", "one", "barrier", "is", "allowed", "in", "Korean.", "Our", "formulation", "of", "this", "parametric", "distinction", "is", "as", "follows:"], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "01b0446b-330d-4218-b91f-5a0e9e702d81", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["Self-training", "(He et al., 2019, Chen et al., 2020)", "uses", "a", "source-to-target", "model", "to", "generate", "synthetic", "pairs", "from", "source-side", "monolingual", "data", "to", "augment", "the", "original", "parallel", "corpus.", "We", "combined", "2M", "Chinese", "monolingual", "data", "with", "2M", "Chinese", "sentences", "randomly", "sampled", "from", "the", "CWMT", "parallel", "corpus,", "yielding", "a", "total", "of", "4M", "monolingual", "for", "forward", "translation."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 1, "citation_locations": [1], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "01d94d2b-6f78-4845-8d3c-2fb8077bdbad", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["Results.", "Figure", "2", "(top", "rows", "of", "A,", "B,", "C)", "shows", "butterfly", "plots", "for", "the", "effects", "of", "word", "length,", "frequency", "and", "class", "across", "64", "electrodes.", "Our", "linear", "SVM", "decoding", "analysis", "replicates", "the", "temporal", "cascade", "of", "word", "length,", "frequency", "and", "class", "effects", "previously", "reported", "for", "EEG", "responses", "averaged", "across", "a", "large", "number", "of", "trials.", "The", "word", "length", "effect", "arises", "early", "at", "about", "100", "ms,", "previously", "associated", "with", "visual", "word", "processing", "in", "occipitotemporal", "cortices", "(Hauk and Pulverm\u00fcller, 2004, Pulverm\u00fcller et al., 2009, Schuster et al., 2016).", "Word", "frequency", "influenced", "neural", "processing", "later", "from", "200", "ms", "onwards", "with", "a", "slight", "left-hemispheric", "predominance", "(Griffiths et al., 2012).", "The", "word", "class", "effect", "emerged", "in", "early", "and", "late", "time", "windows", "with", "the", "effect", "at", "about", "550", "ms", "in", "line", "with", "the", "wellknown", "P600", "as", "an", "ERP", "indicator", "for", "syntactic", "processing", "(Osterhout and Holcomb, 1992, Hagoort et al., 1993, ter Keurs et al., 1999).", "Word", "length", "and", "frequency", "effects", "were", "stronger", "than", "the", "word", "class", "effect,", "see", "King et al. (2020).", "As", "expected,", "decoding", "accuracy", "increased", "when", "EEG", "signals", "were", "averaged", "across", "trials.", "Thus,", "carefully", "controlling", "each", "comparison", "of", "interest", "(e.g.", "word", "class)", "for", "the", "effects", "of", "no", "interest", "(e.g.", "word", "length", "and", "gressively", "generates", "dependencies", "amongst", "training", "samples", "thereby", "limiting", "their", "additional", "benefit", "beyond", "250k.", "We", "formally", "assessed", "whether", "the", "Transformer", "that", "scored", "best", "on", "the", "dev", "set", "obtained", "better", "decoding", "accuracy", "for", "250K", "than", "for", "the", "original", "20k", "training", "set", "(n.b.", "we", "performed", "this", "statistical", "test", "on", "the", "test", "set,", "because", "the", "3", "and", "10", "trial", "averages", "within", "the", "dev", "set", "were", "not", "independent", "from", "one", "another", "as", "a", "result", "of", "boostrapping).", "Indeed,", "for", "both", "3", "and", "10", "trial", "averages", "the", "Transformer's", "(but", "not", "the", "SVM's)", "decoding", "accuracy", "was", "significantly", "better", "for", "250k", "than", "the", "original", "20k", "training", "set", "(p", "&lt,", "0.01,", "Wilcoxon", "signed-rank", "test)."], "cited_papers": [{"title": "Understanding in an instant: Neurophysiological evidence for mechanistic language circuits in the brain", "year": "2009", "authors": ["Friedemann Pulverm\u00fcller", "Yury Shtyrov", "Olaf Hauk"]}, {"title": "Words in Context: The Effects of Length, Frequency, and Predictability on Brain Responses During Natural Reading", "year": "2016", "authors": ["Sarah Schuster", "Stefan Hawelka", "Florian Hutzler"]}, {"title": "Effects of word length and frequency on the human event-related potential", "year": "2004", "authors": ["Olaf Hauk", "Friedemann Pulverm\u00fcller"]}], "target_citation_location": 71, "citation_locations": [71, 87, 119, 133], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "01e43ee9-7f60-43b5-bce5-82282dbb981d", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["For", "the", "dynamic", "programming", "algorithm,", "costs", "are", "taken", "into", "account.", "In", "compilers,", "this", "value", "is", "related", "to", "the", "cost", "of", "the", "instructions", "corresponding", "to", "the", "pattern", "tree.", "For", "this", "example,", "the", "costs", "are", "not", "a", "function", "of", "anything", "external,", "they", "do,", "however,", "capture", "the", "preference", "of", "larger", "pattern", "trees", "over", "combinations", "of", "smaller", "trees,", "which", "is", "desireable,", "see", "Estival et al. (1990).", "Tracing", "through", "the", "example", "again,", "then,", "this", "time", "with", "costs,", "at", "the", "lowest", "node", "the", "annotation", "\u00ab", "has", "cost", "3,", "the", "other", "two", "annotations", "\u00ab", "\u00bd", "\u00bd", "and", "\u00ab", "\u00bd,", "being", "partial", "pattern", "trees,", "have", "no", "cost.", "At", "the", "next", "higher", "node,", "the", "annotations", "\u00ac", "\u00bd", "\u00ab", "\u00bd", "\u00bd", "and", "\u00ac", "\u00bd", "\u00ab", "\u00bd", "have", "cost", "3,", "\u00ab", "\u00bf", "has", "cost", "6", "(3", "for", "the", "pattern", "tree", "\u00ab", "\u00bf,", "and", "3", "for", "the", "left", "child", "as", "annotated", "in", "the", "previous", "step),", "\u00ab", "has", "cost", "5.", "As", "both", "\u00ab", "alternatives", "span", "the", "same", "subtree", "from", "this", "node", "down,", "and", "have", "the", "same", "return", "type", "(sub),", "it", "is", "possible", "to", "discard", "the", "annotation", "\u00ab", "\u00bf,", "as", "it", "will", "always", "be", "cheaper", "to", "use", "\u00ab", "at", "this", "point,", "regardless", "of", "what", "happens", "further", "up", "the", "tree.", "At", "the", "next", "higher", "node,", "the", "annotations", "\u00ac", "\u00bd", "\u00ab", "\u00bd", "\u00bd", "and", "\u00ac", "\u00bd", "\u00ab", "\u00bd", "have", "cost", "6,", "and", "\u00ab", "\u00bf", "has", "cost", "8.", "Finally,", "at", "the", "top", "\u00cb", "node,", "\u00ab", "\u00be", "has", "cost", "13", "(5", "for", "the", "pattern", "tree,", "8", "for", "the", "left", "child:", "as", "the", "pattern", "tree", "can", "only", "accept", "an", "initial", "tree", "as", "the", "left", "child,", "only", "\u00ab", "\u00bf", "is", "a", "suitable", "candidate),", "but", "\u00ab", "\u00bd", "has", "cost", "10", "(4", "for", "the", "pattern", "tree,", "6", "for", "the", "intervening", "auxiliary", "trees).", "The", "algorithm", "in", "Figure", "8", "is", "modified", "so", "that", "any", "annotation", "in", "an", "annotation", "set", "with", "the", "same", "type", "but", "non-minimal", "cost", "is", "discarded.", "Thus", "the", "derivation", "of", "the", "optimal", "tree", "parse,", "top-down,", "would", "be", "\u00ab", "\u00bd", "with", "an", "adjunction", "of", "\u00ac", "\u00bd", "which", "in", "turn", "has", "an", "adjunction", "of", "\u00ac", "\u00bd."], "cited_papers": [{"title": "A syntax and semantics for feature-structure transfer", "year": "1990", "authors": ["D Estival", "A Ballim", "G Russell", "S Warwick"]}], "target_citation_location": 58, "citation_locations": [58], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "02756584-bfba-49b7-bcf4-76fd4668c044", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["Our", "training", "data", "include", "four", "datasets", "about", "causal", "and", "temporal", "relations", "between", "event", "texts.", "PDTB", "3.0", "(Webber et al., 2006)", "is", "WSJ", "articles", "annotated", "with", "four", "high-level", "discourse", "relations,", "and", "we", "map", "the", "sub-relations", "of", "'Temporal'", "to", "our", "classes.", "5", "BECauSE", "2.0", "(Dunietz et al., 2017)", "is", "news", "articles", "annotated", "with", "linguistically", "marked", "causality.", "WIQA", "(Tandon et al., 2019)", "is", "scientific", "event", "texts", "annotated", "with", "causality", "between", "events.", "ConceptNet", "(Speer et al., 2017)", "is", "a", "knowledge", "graph", "between", "phrases,", "and", "relations", "about", "causality", "are", "mapped", "to", "our", "classes.", "To", "prevent", "overfitting", "to", "corpus-specific", "characteristics,", "we", "add", "adversarial", "data", "by", "swapping", "two", "input", "texts", "(PDTB-R,", "BECauSE-R,", "ConceptNet-R)", "or", "pairing", "random", "texts", "(WIQA-P).", "The", "mapping", "between", "corpus-specific", "labels", "and", "ours", "is", "in", "Table", "3,", "and", "the", "module", "accuracy", "in", "Table", "2", "rows", "11-19.", "5", "We", "use", "explicit", "relations", "only", "for", "pretraining,", "since", "they", "often", "capture", "linguistically", "marked,", "rather", "than", "true,", "relations", "between", "events.", "We", "also", "exclude", "the", "Contingency", "relations", "as", "causal", "and", "non-causal", "relations", "(e.g.,", "justification)", "are", "mixed."], "cited_papers": [{"title": "The BECauSE Corpus 2.0: Annotating causality and overlapping relations", "year": "2017", "authors": ["Jesse Dunietz", "Lori Levin", "Jaime Carbonell"]}], "target_citation_location": 39, "citation_locations": [16, 39, 49, 60], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "03121d9f-4dc3-46bf-8926-94c2ba0c29df", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["The", "four", "languages", "are", "highly", "agglutinative", "or", "polysynthetic,", "meaning", "that", "they", "usually", "express", "a", "large", "amount", "of", "information", "in", "just", "one", "word", "with", "several", "joint", "morphemes.", "This", "is", "a", "real", "challenge", "for", "MT", "and", "subword", "segmentation", "methods,", "given", "the", "high", "probability", "of", "addressing", "a", "\"rare", "word\"", "for", "the", "system.", "We", "also", "note", "that", "each", "language", "belongs", "to", "a", "different", "language", "family,", "but", "that", "is", "not", "a", "problem", "for", "multilingual", "models,", "as", "usually", "the", "family-based", "clusters", "are", "not", "the", "most", "effective", "ones", "(Oncevay et al., 2020", "Pre-processing", "The", "datasets", "were", "noisy", "and", "not", "cleaned.", "Lines", "are", "reduced", "according", "to", "several", "heuristics:", "Arabic", "numbers", "or", "punctuation", "do", "not", "match", "in", "the", "parallel", "sentences,", "there", "are", "more", "symbols", "or", "numbers", "than", "words", "in", "a", "sentence,", "the", "ratio", "of", "words", "from", "one", "side", "is", "five", "times", "larger", "or", "shorter", "than", "the", "other,", "among", "others.", "Table", "5", "in", "the", "Appendix", "includes", "the", "original", "and", "cleaned", "data", "size", "per", "language-pair,", "whereas", "Table", "1", "presents", "the", "final", "sizes."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 81, "citation_locations": [81], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0374ebac-b7a0-4cda-a62a-ff2965a7e9fc", "citing_paper": {"title": "Entity Attribute Relation Extraction with Attribute-Aware Embeddings", "year": 2020, "authors": ["Dan Iter", "Xiao Yu", "Fangtao Li"]}, "text": ["We", "sample", "sentences", "from", "a", "subset", "of", "online", "news", "articles", "and", "label", "them", "with", "our", "distant", "supervision", "knowledge", "base", "(Mintz et al., 2009)", "using", "a", "query", "streams", "as", "the", "source", "of", "supervision,", "as", "in", "(Pas \u00b8ca et al., 2007).", "We", "sample", "12.6", "million", "entityattribute", "pairs", "from", "a", "knowledge", "base,", "finding", "6", "million", "unique", "entities", "and", "788", "thousand", "unique", "attributes.", "Each", "sentence", "that", "contains", "an", "entityattribute", "pair", "from", "our", "knowledge", "base", "is", "used", "as", "the", "support", "set", "for", "that", "pair."], "cited_papers": [{"title": "The role of documents vs. queries in extracting class attributes from text", "year": "2007", "authors": ["Marius Pas", "Benjamin Van Durme", "Nikesh Garera"]}], "target_citation_location": 31, "citation_locations": [19, 31], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "038bcd81-56ab-48fc-abe3-b99741f587c0", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["10", "An", "example", "of", "this", "type", "of", "work", "is", "Kiraz (2001).", "In", "Arabic", "a", "root", "such", "as", "ktb", "is", "combined", "with", "a", "vowel", "pattern", "to", "produce", "words", "such", "as", "kitaab", "('book')", "and", "kutub", "('books').", "It", "is", "interesting", "to", "note", "that", "the", "traditional", "approach", "to", "Arabic", "roots", "results", "in", "approximately", "10,000", "different", "items.", "This", "number", "corresponds", "more", "closely", "to", "the", "number", "of", "simple", "lexemes", "to", "be", "expected", "in", "the", "lexicon", "of", "a", "language", "than", "to", "the", "number", "of", "lexemes.", "It", "is", "then", "not", "surprising", "to", "find", "items", "such", "as", "kaatib", "('writer'),", "kutib", "('be", "written')", "with", "the", "same", "root.", "11", "In", "principle", "we", "could", "of", "course", "reverse", "the", "entire", "system.", "Thus,", "languages", "such", "as", "Navajo,", "which", "use", "only", "prefixation,", "are", "not", "a", "major", "problem.", "12", "There", "is", "of", "course", "a", "different", "prefixation", "process", "attaching", "un-to", "a", "verb", "as", "in", "undo,", "but", "it", "would", "yield", "the", "wrong", "analysis", "for", "unacceptable.", "The", "word", "means", "'which", "cannot", "be", "accepted',", "not", "'which", "can", "be", "unaccepted'."], "cited_papers": [{"title": null, "year": "2001", "authors": ["George Kiraz"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0398aae2-5054-4ed3-b12f-25f38be79e3e", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["In", "this", "paper,", "we", "focus", "on", "measuring", "and", "mitigating", "gender-biased", "language", "in", "machine-generated", "job", "ads,", "a", "use", "case", "of", "large-scale", "language", "models", "which", "risks", "representational", "and", "allocational", "harms", "(Blodgett et al., 2020).", "Representational", "harms", "come", "from", "the", "conditioning", "of", "a", "job's", "suitability", "to", "a", "given", "individual", "based", "on", "their", "gender.", "When", "jobs", "are", "valued", "unequally", "(either", "by", "financial,", "social", "or", "intellectual", "status),", "this,", "in", "turn,", "can", "reinforce", "gendered", "power", "hierarchies", "and", "negative", "societal", "divisions.", "Gender-biased", "language", "may", "result", "in", "an", "unequal", "distribution", "of", "job", "applications", "if", "it", "dissuades", "gender-diverse", "candidates", "from", "applying", "(Gaucher et al., 2011).", "Thus,", "allocational", "harms", "are", "relevant", "where", "labour", "market", "opportunities,", "financial", "remuneration", "or", "job", "stability", "are", "preferentially", "granted", "based", "on", "gender.", "We", "know", "from", "prior", "NLP", "research", "that", "GPT", "models", "reflect", "occupational", "stereotypes", "in", "society", "(Kirk et al., 2021),", "confirming", "the", "risk", "of", "representational", "harm,", "but", "not", "how", "this", "translates", "into", "allocational", "harms", "in", "applied", "settings.", "To", "measure", "bias,", "our", "experiment", "employs", "lists", "of", "gender-coded", "words.", "These", "lists", "are", "potentially", "in", "themselves", "biased,", "having", "been", "defined", "by", "a", "research", "group", "under", "a", "particular", "cultural", "bias", "or", "as", "the", "result", "of", "biased", "data.", "To", "mitigate", "this", "concern,", "we", "use", "multiple", "measures", "to", "cover", "the", "blind", "spots", "or", "specific", "biases", "present", "in", "any", "single", "list.", "However,", "our", "proposed", "metric", "may", "better", "capture", "the", "most", "obvious,", "text-level", "aspects", "of", "gender-biased", "language", "and", "will", "be", "less", "effective", "to", "find", "covert,", "but", "equally", "as", "damaging,", "forms", "of", "gender", "bias", "in", "job", "ads,", "or", "job", "search", "more", "broadly."], "cited_papers": [{"title": "Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models", "year": "2021", "authors": ["Hannah Kirk", "Yennie Jun", "Haider Iqbal", "Elias Benussi", "Filippo Volpin", "Frederic Dreyer", "Aleksandar Shtedritski", "Yuki Asano"]}], "target_citation_location": 124, "citation_locations": [28, 89, 124], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "04391904-fa5d-4403-be75-ab490e07b577", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["Leveraging", "sparsity", "of", "matrices", "We", "considered", "the", "option", "of", "performing", "matrix", "products", "involving", "large", "sparse", "matrices", "(Lines", "8,", "15,", "21,", "25", "in", "our", "pseudo-code", "(\u00a72.2))", "by", "representing", "them", "in", "PyTorch's", "torch.sparse_coo_tensor", "format", "and", "using", "the", "torch.sparse", "framework", "to", "explicitly", "leverage", "their", "sparsity", "for", "saving", "compute.", "Unfortunately,", "the", "results", "were", "not", "encour-", "aging", "even", "for", "k", "=", "1%", "of", "number", "of", "keys", "(Figure", "4).", "While", "future", "devices", "might", "allow", "faster", "sparsedense", "products,", "in", "the", "immediate", "future,", "one", "can", "leverage", "block-sparse", "kernels", "(Child et al., 2019, Tillet et al., 2019)", "which", "have", "been", "successfully", "used", "for", "such", "products", "(Rasley et al., 2020)."], "cited_papers": [{"title": "Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters", "year": "2020", "authors": ["Jeff Rasley", "Samyam Rajbhandari", "Olatunji Ruwase", "Yuxiong He"]}], "target_citation_location": 89, "citation_locations": [80, 89], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "049f1ee0-c587-4ac0-aba1-fc75f686f73a", "citing_paper": {"title": "A User-Based Usability Assessment of Raw Machine Translated Technical Instructions", "year": 2012, "authors": ["Stephen Doherty", "Sharon O'brien"]}, "text": ["We", "have", "also", "collated", "eye", "tracking", "measurements", "such", "as", "total", "fixation", "counts,", "average", "fixation", "duration", "and", "percentage", "change", "in", "pupil", "dilation,", "all", "of", "which", "are", "shown", "to", "be", "indicators", "of", "cognitive", "load", "(Duchowski, 2007)."], "cited_papers": [{"title": "Eye Tracking Methodology: Theory and Practice", "year": "2007", "authors": ["A Duchowski"]}], "target_citation_location": 32, "citation_locations": [32], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "04c5b379-d47b-4491-adde-3ad18bcfbb2c", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["The", "Symlink", "track", "at", "SemEval-2022", "received", "4", "system", "description", "paper", "submissions", "presented", "in", "Table", "2.", "Overall,", "all", "submitted", "systems", "are", "based", "on", "BERT", "architecture", "(Devlin et al., 2019).", "Among", "those,", "two", "out", "of", "four", "systems", "use", "SciBERT", "(Beltagy et al., 2019),", "while", "two", "remaining", "systems", "use", "other", "variants", "of", "BERT", "such", "as", "original", "BERT", "(Devlin et al., 2019)", "and", "mBERT", "(Devlin et al., 2019)."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 48, "citation_locations": [24, 34, 48, 51], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3]]}
{"id": "05134017-3dff-4d67-8ef1-9385c1586b3b", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["We", "perform", "pretraining", "on", "two", "widely-used", "indomain", "datasets:", "MSCOCO", "Caption", "(Lin et al., 2014)", "and", "Visual", "Genome", "(Krishna et al., 2016),", "and", "validate", "the", "learned", "multi-modal", "representations", "on", "five", "well-known", "visual-language", "tasks:", "Visual", "Question", "Answering", "(VQA),", "Imagetext", "retrieval,", "Nature", "Language", "Visual", "Reasoning", "(NLVR", "2", "),", "Visual", "Entailment", "(VE)", "and", "Visual", "Commonsense", "Reasoning", "(VCR).", "Empirical", "results", "show", "that", "our", "method", "outperforms", "the", "state-of-theart", "end-to-end", "approaches", "by", "a", "sizeable", "margin.", "To", "better", "understand", "our", "method,", "we", "also", "provide", "a", "detailed", "ablation", "study", "and", "visualization."], "cited_papers": [{"title": "Microsoft coco: Common objects in context", "year": "2014", "authors": ["Tsung-Yi Lin", "Michael Maire", "Serge Belongie", "James Hays", "Pietro Perona", "Deva Ramanan", "Piotr Doll\u00e1r", "C Lawrence Zitnick"]}], "target_citation_location": 10, "citation_locations": [10, 14], "citation_type": "single", "annotations": [[3, 3, 3, 2, 2, 2, 3, 3, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "05404c91-fa18-4f54-aae7-192d87bbccfa", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["Binary", "refers", "to", "positive", "and", "negative,", "and", "ternary", "refers", "to", "positive,", "negativeand", "neutral.", "For", "binary", "evaluations", "we", "categorized", "anger,", "disgust,", "fear,", "and", "sadness", "as", "negative,", "and", "anticipation,", "joy,", "and", "trust", "as", "positive.", "Surprise", "was", "either", "discarded", "or", "included", "as", "a", "separate", "category", "(see", "table", "7).", "For", "this", "classification", "task", "BERT", "achieved", "macro", "f1", "scores", "of", "0.536", "and", "accuracies", "of", "0.544.", "This", "is", "comparable", "to", "other", "similar", "datasets", "when", "classes", "are", "merged", "(e.g.", "Demszky et al. (2020)", ")."], "cited_papers": [{"title": null, "year": "2020", "authors": ["Dorottya Demszky", "Dana Movshovitz-Attias", "Jeongwoo Ko", "Alan Cowen", "Gaurav Nemade", "Sujith Ravi"]}], "target_citation_location": 72, "citation_locations": [72], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1]]}
{"id": "062d7b40-3fc9-45ea-8dca-b119795c3c0e", "citing_paper": {"title": "Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure", "year": 1999, "authors": ["Nicoletta Calzolari", "Antonio Zampolli"]}, "text": ["Model:", "The", "PAROLE", "Lexicon", "model", "for", "Morphosyntax", "and", "Syntax", "is", "based", "on", "the", "results", "of", "EAGLES", "(Sanfilippo et al. 1996)", "and", "EUREKA", "GENELEX", "(Antoni-Lay et al. 1994),", "further", "developed", "within", "the", "PAROLE", "project", "(Calzolari, Montemagni, Pirrelli 1996).", "Thanks", "to", "that", "all", "the", "lexical", "resources", "are", "declarative,", "theory", "and", "application", "independent,", "harmonised,", "multifunctional,", "and", "able", "to", "evolve", "easily,", "for", "example", "to", "incorporate", "other", "levels", "of", "information", "or", "to", "become", "multilingual.", "This", "approach,", "which", "answers", "to", "the", "requisites", "of", "generality,", "explicitness,", "and", "variability", "of", "granularity,", "guarantees", "a", "large", "scale", "reusability."], "cited_papers": [{"title": "A Generic Model for Reusable Lexicons: The Genelex Project", "year": "1994", "authors": ["M Antoni-Lay", "G Francopoulo", "L Zaysser"]}], "target_citation_location": 20, "citation_locations": [16, 20, 27], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "06567b6e-2654-4f02-a8fe-3aebf9bcc855", "citing_paper": {"title": "On the weak link between importance and prunability of attention heads", "year": 2020, "authors": ["Aakriti Budhraja", "Madhura Pande", "Preksha Nema", "Pratyush Kumar", "Mitesh Khapra"]}, "text": ["The", "acclaimed", "success", "of", "Transformer-based", "models", "across", "NLP", "tasks", "has", "been", "followed", "by", "two", "important", "directions", "of", "research.", "In", "the", "first", "direction,", "interpretability", "studies", "aim", "to", "understand", "how", "these", "models", "work.", "Given", "that", "multi-headed", "attention", "is", "an", "important", "feature", "of", "these", "models,", "researchers", "have", "focused", "on", "attention", "heads", "as", "the", "units", "of", "interpretation.", "These", "studies", "comment", "on", "the", "role", "of", "each", "attention", "head", "and", "the", "relation", "between", "a", "head's", "position", "and", "its", "significance", "(Clark et al., 2019, Michel et al., 2019, Voita et al., 2019b,a, Liu et al., 2019, Belinkov et al., 2017).", "These", "studies", "show", "that", "certain", "heads", "are", "more", "important", "based", "on", "(i)", "their", "position", "in", "the", "network", "(top,", "middle,", "bottom),", "or", "(ii)", "the", "component", "to", "which", "they", "belong", "(encoder", "self-attention,", "decoder", "self-attention,", "encoder-decoder", "cross", "attention),", "or", "(iii)", "the", "functional", "role", "they", "play", "(e.g.,", "syntactic/semantic)."], "cited_papers": [{"title": "Are sixteen heads really better than one?", "year": "2019", "authors": ["Paul Michel", "Omer Levy", "Graham Neubig"]}, {"title": "What does bert look at? an analysis of bert's attention", "year": "2019", "authors": ["Kevin Clark", "Urvashi Khandelwal", "Omer Levy", "Christopher D Manning"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "What do neural machine translation models learn about morphology?", "year": "2017", "authors": ["Yonatan Belinkov", "Nadir Durrani", "Fahim Dalvi", "Hassan Sajjad", "James Glass"]}], "target_citation_location": 73, "citation_locations": [73], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3]]}
{"id": "0712b528-4adf-40ef-9cae-d4de17a6825f", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Curriculum", "Diversity.", "The", "variations", "in", "the", "combinations", "of", "quests", "and", "worlds", "themselves", "seen", "at", "training", "time", "has", "potential", "to", "effect", "zero-shot", "performance", "(Samvelyan et al., 2021).", "We", "introduce", "two", "baselines", "that", "change", "the", "relative", "diversities", "of", "resulting", "quests", "in", "the", "curriculums,", "to", "contrast", "with", "our", "proposed", "procedural", "generation", "pipeline.", "Generated", "quest", "details", "are", "found", "in", "Appendix", "A.5."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 22, "citation_locations": [22], "citation_type": "single", "annotations": [[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "07e1efd0-b4a4-4d31-9e70-2c4af8b833f0", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["In", "table", "1", "we", "have", "gathered", "some", "of", "the", "most", "significant", "emotion", "datasets", "in", "relation", "to", "this", "study.", "The", "table", "lists", "the", "paper", "in", "which", "the", "dataset", "was", "released", "(study),", "what", "the", "source", "data", "that", "was", "used", "was", "(source),", "what", "model", "was", "used", "to", "obtain", "the", "best", "evaluation", "scores", "(model),", "the", "number", "of", "categories", "used", "for", "annotation", "(cat),", "whether", "the", "system", "was", "multilabel", "or", "not", "(multi),", "and", "the", "macro", "f1", "scores", "and", "accuracy", "score", "as", "reported", "by", "the", "paper", "(macro", "f1", "and", "accuracy", "respectively).", "Some", "papers", "only", "reported", "a", "micro", "f1", "and", "no", "macro", "f1", "score.", "These", "scores", "have", "been", "marked", "with", "a", "\u00b5.", "The", "datasets", "in", "table", "1", "differ", "from", "each", "so", "much", "in", "content,", "structure,", "and", "manner", "of", "annotation", "that", "direct", "comparisons", "are", "hard", "to", "make.", "Typically,", "the", "fewer", "the", "number", "of", "categories,", "the", "easier", "the", "classification", "task", "and", "the", "higher", "the", "evaluation", "scores.", "It", "stands", "to", "reason", "that", "the", "easier", "it", "is", "to", "detect", "emotions", "in", "the", "source", "data,", "the", "easier", "it", "is", "for", "annotators", "to", "identify", "and", "agree", "upon", "annotation", "labels", "and", "therefore", "it", "becomes", "easier", "for", "the", "system", "or", "model", "to", "correctly", "classify", "the", "test", "data", "as", "well.", "The", "outlier", "in", "these", "datasets", "is", "EmoNet", "(Abdul-Mageed and Ungar, 2017)", "which", "achieved", "astonishing", "accuracies", "by", "using", "665", "different", "hashtags", "to", "automatically", "categorize", "1.6", "million", "tweets", "into", "24", "categories", "(Plutchik's", "8", "at", "3", "different", "intensities),", "unfortunately", "neither", "the", "dataset", "or", "their", "model", "has", "been", "made", "available", "for", "closer", "inspection."], "cited_papers": [{"title": "Emonet: Fine-grained emotion detection with gated recurrent neural networks", "year": "2017", "authors": ["Muhammad Abdul", "-Mageed unk", "Lyle Ungar"]}], "target_citation_location": 200, "citation_locations": [200], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "0882b8fb-ec05-44b9-bc00-4b7078c2e368", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["ChrF", "(Popovi\u0107, 2015)", "a", "character", "n-gram", "precision", "and", "recall", "enhanced", "with", "word", "n-grams.", "Since", "answers", "are", "largely", "made", "up", "of", "entities,", "ChrF", "score", "integration", "is", "only", "performed", "when", "the", "answer", "span", "is", "not", "present", "in", "the", "related", "context.", "In", "order", "to", "evaluate", "the", "quality", "of", "the", "translation,", "we", "manually", "corrected", "the", "translation", "errors", "in", "the", "output", "of", "a", "subset", "of", "the", "corpus", "composed", "of", "890", "QA", "pairs", "and", "107", "contexts.", "We", "obtain", "a", "BLEU", "score", "(Papineni et al., 2002)", "We", "also", "explore", "mixed", "datasets", "training", "strategy", "with", "SQuAD-en", "train", "+", "FQuAD", "train", "for", "training", "models", "on", "a", "concatenation", "of", "the", "training", "data", "covering", "French-English", "language", "pairs", "to", "test", "the", "crosslingual", "transfer", "ability", "of", "multilingual", "models."], "cited_papers": [{"title": "chrF: character n-gram F-score for automatic MT evaluation", "year": "2015", "authors": ["Maja Popovi\u0107"]}], "target_citation_location": 1, "citation_locations": [1, 74], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0918f617-140a-46b7-99fc-e9e4b2634017", "citing_paper": {"title": "SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering", "year": 2020, "authors": ["Aishwarya Ashok", "Ganapathy Natarajan", "Ramez Elmasri", "Laurel Smith-Stvan"]}, "text": ["The", "correct", "answer", "and", "at", "least", "50%", "were", "inspired", "by", "the", "accuracy", "@", "x%", "approach", "used", "by", "different", "authors", "working", "with", "the", "Amazon", "dataset", "and", "performing", "similar", "tasks", "(Fan et al., 2019, McAuley and Yang, 2016, Yu and Lam, 2018).", "In", "accuracy", "@", "x%", "the", "commonly", "used", "measure", "is", "accuracy", "@", "50%.", "This", "approach", "helps", "in", "identifying", "the", "top", "answers", "crossing", "a", "threshold", "and", "has", "better", "relationship", "in", "real", "world", "applications", "(Fan et al., 2019)."], "cited_papers": [{"title": "Addressing complex and subjective product-related queries with customer reviews", "year": "2016", "authors": ["Julian Mcauley", "Alex Yang"]}, {"title": "Aware answer prediction for product-related questions incorporating aspects", "year": "2018", "authors": ["Qian Yu", "Wai Lam"]}, {"title": "Reading customer reviews to answer product-related questions", "year": "2019", "authors": ["Chao Miao Fan", "Mingming Feng", "Ping Sun", "Haifeng Li", "unk Wang"]}], "target_citation_location": 28, "citation_locations": [28, 60], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "092339e6-33e1-4333-99e6-223e745a4b19", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["In", "recent", "years", "there", "has", "been", "some", "revival", "of", "interest", "in", "computational", "lexicography", "that", "has", "fulfilled", "some", "of", "MMB's", "hopes", "and", "dreams.", "It", "has", "been", "driven", "to", "some", "extent", "by", "the", "availability", "from", "publishers", "of", "machine-readable", "English", "dictionaries,", "such", "as", "Longman's", "dictionary", "of", "contemporary", "English", "(LDOCE)", "and", "Collins-Birmingham", "University", "International", "Language", "Database", "(COBUILD),", "with", "definitions", "written", "in", "a", "semi-formal", "way.", "This", "makes", "it", "much", "easier", "for", "a", "computational", "parser", "to", "extract", "information", "from", "them.", "But", "the", "initial", "work", "in", "the", "current", "wave", "was", "done", "by", "Amsler (1980)", "at", "Texas", "using", "Webster's,", "an", "oldfashioned", "dinosaur", "of", "a", "dictionary.", "He", "developed", "a", "notion", "of", "'tangled", "hierarchies'", "which", "captures", "the", "notion", "MMB", "promoted", "so", "as", "to", "get", "away", "from", "straightforward", "tree-like", "hierarchies."], "cited_papers": [{"title": "Bar-Hillel, Y. The present state of research on mechanical translation", "year": "1953", "authors": ["R Amsler"]}], "target_citation_location": 85, "citation_locations": [85], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "09242a6b-0b17-4069-be28-ada153a96937", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["Random", "named", "entity:", "the", "majority", "of", "answers", "in", "Quoref", "are", "person", "names.", "To", "evaluate", "this", "artifact,", "we", "randomly", "select", "a", "PERSON", "named", "entity", "from", "the", "context", "as", "the", "answer.", "3", "Wh-word", "(Weissenborn et al., 2017):", "to", "recognize", "the", "QA", "pairs", "that", "can", "be", "answered", "by", "only", "using", "the", "interrogative", "adverbs", "from", "the", "question,", "we", "train", "a", "model", "on", "a", "variation", "of", "the", "training", "dataset", "in", "which", "questions", "only", "contain", "interrogative", "adverbs.", "Empty", "question", "(Sugawara et al., 2020):", "to", "recognize", "QA", "pairs", "that", "are", "answerable", "without", "considering", "the", "question,", "4", "we", "train", "a", "QA", "model", "only", "on", "the", "contexts", "and", "without", "questions.", "Semantic", "overlap", "(Jia and Liang, 2017):", "for", "this", "artifact,", "we", "report", "the", "ratio", "of", "the", "QA", "pairs", "whose", "answers", "lie", "in", "the", "sentence", "of", "the", "context", "that", "has", "the", "highest", "semantic", "similarity", "to", "the", "question.", "We", "use", "sentence-BERT", "(Reimers and Gurevych, 2019)", "to", "find", "the", "most", "similar", "sentence.", "Short", "distance", "reasoning:", "for", "this", "bias,", "we", "train", "a", "model", "only", "using", "the", "sentence", "of", "the", "context", "that", "is", "the", "most", "similar", "to", "the", "question,", "instead", "of", "the", "whole", "context.", "We", "exclude", "the", "question-answer", "pairs", "in", "which", "the", "most", "similar", "sentence", "does", "not", "contain", "the", "answer.", "This", "model", "will", "not", "learn", "to", "perform", "coreference", "reasoning", "when", "the", "related", "coreferring", "pairs", "are", "not", "in", "the", "same", "sentence."], "cited_papers": [{"title": "Assessing the benchmarking capacity of machine reading comprehension datasets", "year": "2020", "authors": ["Saku Sugawara", "Pontus Stenetorp", "Kentaro Inui", "Akiko Aizawa"]}], "target_citation_location": 70, "citation_locations": [31, 70, 97, 130], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "092bd072-8d20-4162-aea7-1fdb9fbe8e1a", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["In", "order", "to", "generate", "character", "embeddings", "from", "the", "input", "sentence,", "we", "first", "use", "a", "CharCNN", "(Kim et al., 2016).", "Let", "C", "be", "the", "dictionary", "of", "all", "the", "characters", "in", "the", "language", "and", "V", "be", "all", "the", "words", "in", "the", "language.", "We", "first", "define", "the", "character", "embeddings", "matrix", "E", "\u2208", "R", "d\u00d7|C", "|,", "where", "d", "is", "the", "dimensionality", "of", "the", "character", "embeddings,", "with", "the", "constraint", "that", "d", "&lt,", "|C", "|.", "Let", "word", "w", "i", "\u2208", "V", "c", "w", "i", "=", "[c", "w", "i", "1,", "c", "w", "i", "2", ",...,", "c", "w", "i", "n", "].", "The", "character", "representation", "of", "w", "i", "is", "therefore", "given", "by", "E", "w", "i", "\u2208", "R", "d\u00d7n."], "cited_papers": [{"title": "Character-aware neural language models", "year": "2016", "authors": ["Yoon Kim", "Yacine Jernite", "David Sontag", "Alexander M Rush"]}], "target_citation_location": 15, "citation_locations": [15], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "095a1d93-99b1-47e4-90d8-a93c40b0daf4", "citing_paper": {"title": "A Parameter-Based Message-Passing Parser for MT of Korean and English", "year": 1994, "authors": ["Bonnie Dorr", "Jye-Hoon Lee", "Sungki Suh"]}, "text": ["We", "have", "just", "seen", "that", "certain", "types", "of", "syntactic", "parameterization", "may", "be", "captured", "in", "the", "grammar", "network", "(e.g.,", "Xbar", "parameters", "such", "as", "constituent", "order).", "In", "addition", "to", "these,", "there", "are", "syntactic", "parameters", "that", "must", "be", "programmed", "into", "the", "message-passing", "mechanism", "itself,", "not", "just", "into", "the", "grammar", "network.", "Figure", "2", "shows", "the", "syntactic", "parameter", "settings", "for", "English", "and", "Korean.", "The", "English", "settings", "are", "drawn", "from", "Dorr (1993b).", "The", "same", "paradigm", "was", "followed", "in", "our", "analysis", "of", "Korean", "parameters.", "The", "remainder", "of", "this", "paper", "will", "focus", "on", "how", "we", "automatically", "precompile", "the", "English", "and", "Korean", "parameter", "settings", "concerning", "Xbar", "theory", "into", "the", "grammar", "network", "(i.e.,", "Basic", "Categories,", "Pre-tenninals,", "Constituent", "Order,", "Specifiers,", "and", "Adjunction)."], "cited_papers": [{"title": "Interlingual machine translation: a parameterized approach", "year": "1993", "authors": ["B Dorr"]}], "target_citation_location": 64, "citation_locations": [64], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "09946730-d0ff-4972-8910-70cdbe86d9b0", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["language", "features,", "which", "can", "be", "fine-tuned", "for", "applications", "like", "semantic", "analysis", "and", "question", "answering.", "Multi-lingual-BERT", "(mBERT)", "is", "a", "BERT", "model", "pre-trained", "using", "the", "Wikipedia", "text", "corpus", "(Merity et al., 2016)", "in", "more", "than", "100", "languages", "around", "the", "world.", "XLM-RoBERTa", "(Conneau et al., 2020)", "scaled", "this", "idea", "with", "more", "than", "2", "terabytes", "of", "common", "crawl", "data."], "cited_papers": [{"title": "Pointer sentinel mixture models", "year": "2016", "authors": ["Stephen Merity", "Caiming Xiong", "James Bradbury", "Richard Socher"]}], "target_citation_location": 26, "citation_locations": [26, 36], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "099c645b-10b7-47e1-963f-1a9aaa776bc1", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["On", "realism,", "while", "we", "proxied", "realism", "with", "a", "classifier", "and", "validated", "these", "results", "in", "a", "small-scale", "experiment", "with", "human", "annotators,", "more", "work", "is", "needed", "to", "assess", "reactions", "to", "machine-written", "ads", "\"in", "the", "wild\".", "Furthermore,", "while", "fine-tuning", "and", "prompt-engineering", "increased", "realism", "in", "the", "aggregate,", "some", "job", "ads", "were", "still", "nonsensical", "or", "simply", "parroted", "the", "prompt", "text,", "e.g.,", "\"The", "job", "ad", "should", "not", "have", "any", "biases", "in", "it.\".", "We", "briefly", "assess", "some", "outputs", "qualitatively", "in", "Appendix", "F", "but", "make", "our", "bias", "measure", "generation", "process", "publicly", "available", "to", "encourage", "more", "human-directed", "assessments", "of", "bias", "and", "realism.", "9", "It", "remains", "to", "be", "seen", "whether", "realism", "(as", "measured", "by", "similarity", "to", "human-authored", "ads)", "is", "a", "necessary", "characteristic", "for", "success", "(as", "measured", "by", "the", "number", "of", "applications).", "Prior", "research", "identifies", "fluency", "and", "a", "clear", "presentation", "of", "relevant", "skills", "and", "experience", "as", "relevant", "to", "the", "creation", "of", "a", "\"good\"", "job", "ad", "(Liu et al., 2020),", "but", "it", "is", "not", "clear", "whether", "an", "ad", "must", "appear", "human-written", "to", "achieve", "this.", "Our", "assumption", "for", "this", "project", "is", "that", "human-written", "job", "ads", "follow", "styles,", "conventions", "and", "a", "level", "of", "detail", "that", "effectively", "encourage", "prospective", "employees", "to", "apply,", "but", "further", "research", "is", "required", "to", "understand", "whether", "ads", "clearly", "identified", "as", "machine-written", "can", "be", "equally", "or", "more", "effective", "in", "this", "regard."], "cited_papers": [{"title": "Hiring now: A skill-aware multi-attention model for job posting generation", "year": "2020", "authors": ["Liting Liu", "Jie Liu", "Wenzheng Zhang", "Ziming Chi", "Wenxuan Shi", "Yalou Huang"]}], "target_citation_location": 144, "citation_locations": [144], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "09b50114-c9a9-4583-9ed6-9798d995ae7e", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Inference", "In", "our", "implementation,", "we", "use", "FAISS", "(Johnson et al., 2019)", "to", "index", "the", "dense", "representations", "of", "all", "passages.", "Specifically,", "we", "use", "IndexFlatIP", "for", "indexing", "and", "the", "exact", "maximum", "inner", "product", "search", "for", "querying."], "cited_papers": [{"title": "Billion-scale similarity search with gpus", "year": "2019", "authors": ["Jeff Johnson", "Matthijs Douze", "Herv\u00e9 J\u00e9gou"]}], "target_citation_location": 7, "citation_locations": [7], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0a1bada6-98d3-461f-9ac1-1e41c2d641f8", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["We", "train", "two", "BART", "(Lewis et al., 2020)", "models", "that", "encodes", "input", "information", "via", "a", "bidirectional", "transformer", "encoder", "and", "decodes", "autoregressively:", "the", "first", "takes", "as", "input", "character", "and", "location", "information", "and", "produces", "a", "short", "motivation", "(Section", "2),", "the", "second", "takes", "as", "input", "character,", "location", "information,", "short", "motivation", "and", "produces", "the", "sequence", "of", "LIGHT", "game", "engine", "executable", "actions", "needed", "to", "achieve", "the", "motivation.", "This", "sequence", "of", "actions", "is", "provided", "by", "the", "human", "expert", "demonstrations", "as", "mentioned", "in", "Section", "2."], "cited_papers": [{"title": "BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension", "year": "2020", "authors": ["Mike Lewis", "Yinhan Liu", "Naman Goyal ", " Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer"]}], "target_citation_location": 4, "citation_locations": [4], "citation_type": "single", "annotations": [[2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0a41bef5-c4ec-45b4-bb27-eb0391a40b4a", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["There", "have", "been", "a", "series", "of", "attempts", "to", "utilize", "phonetic", "representations", "of", "language", "to", "improve", "or", "extend", "automatic", "speech", "recognition", "(ASR)", "models.", "Some", "of", "these", "jointly", "model", "text", "and", "audio", "data", "using", "sequences", "of", "phonemes", "combined", "with", "sequences", "of", "text", "characters.", "Sundararaman et al. (2021),", "for", "example,", "uses", "a", "joint", "transformer", "architecture", "that", "encodes", "sequences", "of", "phonemes", "and", "sequences", "of", "text", "simultaneously.", "However,", "this", "joint", "model", "is", "utilized", "to", "learn", "representations", "that", "are", "more", "robust", "to", "transcription", "errors.", "The", "architecture", "still", "requires", "text", "inputs", "(from", "ASR", "transcriptions)", "and", "generates", "outputs", "in", "both", "text", "and", "phoneme", "representations.", "In", "contrast,", "our", "approach", "allows", "for", "text", "input,", "audio", "input,", "or", "text", "plus", "audio", "input", "to", "language", "models.", "Similarly,", "in", "(Chaudhary et al., 2018)", "and", "(Bharadwaj et al., 2016)", "investigate", "the", "potential", "of", "phoneme-based", "or", "phoneme", "aware", "representations", "and", "models,", "showing", "gains", "in", "performance,", "language", "transfer,", "and", "flexibility", "across", "written", "scripts.", "These", "works", "conduct", "training", "on", "text-based", "data", "only,", "using", "Epitran", "to", "convert", "to", "phonemes.", "Baevski et al. (2021)", "transforms", "unlabeled", "text", "(i.e.,", "not", "aligned", "with", "corresponding", "audio", "files)", "into", "phonemes", "in", "a", "scheme", "to", "train", "speech", "recognition", "models", "without", "any", "labeled", "data.", "This", "scheme", "involves", "a", "generator", "model", "trained", "jointly", "with", "a", "discriminator", "model.", "The", "generator", "model", "converts", "audio,", "segmented", "into", "phonetic", "units", "into", "predicted", "phonemes,", "and", "the", "discriminator", "model", "attempts", "to", "discriminate", "between", "these", "predicted", "phonemes", "and", "the", "phonemes", "transliterated", "from", "unlabeled", "text.", "Although", "both", "text", "and", "audio", "are", "utilized", "in", "this", "work,", "they", "are", "not", "input", "to", "the", "same", "model", "and", "the", "primary", "output", "of", "the", "training", "scheme", "is", "a", "model", "that", "creates", "good", "phonetic", "speech", "representations", "from", "input", "audio."], "cited_papers": [{"title": "Phonologically aware neural model for named entity recognition in low resource transfer settings", "year": "2016", "authors": ["Akash Bharadwaj", "David Mortensen", "Chris Dyer", "Jaime Carbonell"]}], "target_citation_location": 115, "citation_locations": [41, 113, 115, 152], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0a580572-1242-490a-8010-9c7d91226b8f", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Generating", "multiple", "valid", "outputs", "given", "a", "source", "sequence", "has", "a", "wide", "range", "of", "applications,", "such", "as", "machine", "translation", "(Shen et al., 2019),", "paraphrase", "generation", "(Gupta et al., 2018),", "question", "generation", "(Cho et al., 2019),", "dialogue", "system", "(Dou et al., 2021),", "and", "story", "generation", "(Yu et al., 2021).", "For", "example,", "in", "machine", "translation,", "there", "are", "often", "many", "plausible", "and", "semantically", "equivalent", "translations", "due", "to", "information", "asymmetry", "between", "different", "languages", "(Lachaux et al., 2020)."], "cited_papers": [{"title": "Mixture content selection for diverse sequence generation", "year": "2019", "authors": ["Jaemin Cho", "Minjoon Seo", "Hannaneh Hajishirzi"]}], "target_citation_location": 24, "citation_locations": [18, 21, 24, 27, 31, 53], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0a5fef3d-0b6d-425f-8c6b-861799eab3dd", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["We", "use", "the", "OPUS", "(Lison and Tiedemann, 2016)", "parallel", "movie", "subtitle", "corpus", "of", "subtitles", "collected", "from", "opensubtitles.org", "as", "a", "multi-domain", "proxy.", "As", "the", "movies", "we", "use", "for", "source", "data", "cover", "several", "different", "genres", "and,", "although", "scripted,", "represents", "real", "human", "language", "used", "in", "a", "multitude", "of", "situations", "similar", "to", "many", "social", "media", "platforms."], "cited_papers": [{"title": "Opensubtitles2016: Extracting large parallel corpora from movie and tv subtitles", "year": "2016", "authors": ["Pierre Lison", "J\u00f6rg Tiedemann ", " Khalid", "Thierry Choukri", "Sara Declerck", "Marko Goggi", "Bente Grobelnik", "Joseph Maegaard", "unk Mariani"]}], "target_citation_location": 4, "citation_locations": [4], "citation_type": "single", "annotations": [[2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0a82e811-90c7-4744-a503-ce6c5d21efb6", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["The", "DeKo", "rules", "can", "only", "work", "if", "they", "can", "refer", "to", "detailed", "information", "on", "lexical", "items", "-therefore", "the", "DeKo", "team", "and", "other", "researchers", "at", "the", "IMS", "in", "Stuttgart", "developed", "a", "highly", "flexible", "lexicon", "concept", "where", "different", "kinds", "of", "information", "are", "stored", "together", "with", "morphological", "elements", "(see", "L\u00fcdeling &amp, Fitschen 2002", "for", "more", "details).", "At", "the", "moment", "the", "relevant", "information", "is", "still", "being", "collected", "and", "encoded", "into", "the", "IMSLex.", "Therefore,", "the", "DeKo", "rules", "as", "they", "stand", "now", "are", "much", "less", "specific", "than", "they", "should", "be."], "cited_papers": [{"title": "An integrated lexicon for the analysis of complex words' to appear in Proceedings of EURALEX", "year": "2002", "authors": ["Anke L\u00fcdeling", "Arne Fitschen"]}], "target_citation_location": 46, "citation_locations": [46], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "0b198d64-13db-4486-b9b4-d45c5ad6a9e3", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["The", "O2O", "model", "trained", "with", "a", "conditional", "chain", "mapping", "(Fujita et al., 2020a, Shi et al., 2020)", "can", "also", "be", "used", "to", "maximize", "Eq.", "(3).", "4))", "used", "in", "the", "O2M", "model,", "the", "O2O", "conditional", "chain", "mapping", "model", "is", "trained", "to", "maximize", "the", "joint", "log-likelihood", "(Eq.", "(3))", "via", "a", "recursive", "expansion", "of", "the", "probabilistic", "chain", "rule.", "This", "model", "does", "not", "require", "or", "assume", "conditional", "independence", "between", "sequence", "types.", "Formally,", "the", "O2O", "model", "is", "trained", "to", "maximize", "the", "following", "loss", "function:"], "cited_papers": [{"title": "Neural speaker diarization with speaker-wise chain rule", "year": "2020", "authors": ["Y Fujita", "S Watanabe", "S Horiguchi", "Y Xue", "J Shi", "K Nagamatsu"]}, {"title": "Sequence to multisequence learning via conditional chain mapping for mixture signals", "year": "2020", "authors": ["J Shi", "X Chang", "P Guo", "S Watanabe", "Y Fujita", "J Xu", "B Xu", "L Xie"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0b22cdf6-04f8-4985-9145-1c7bf750ddb1", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["The", "Champollion", "system", "was", "developed", "by", "Smadja et al. (1996)", "to", "specifically", "address", "translation", "of", "collocations,", "including", "non-compositional", "expressions.", "They", "used", "aligned", "sentences", "from", "the", "Canadian", "Hansards", "corpus", "(as", "did", "Kupiec).", "They", "used", "a", "tool", "they", "had", "previously", "developed", "(XTRACT)", "to", "identify", "collocations", "and", "they", "translated", "approximately", "900", "medium", "frequency", "English", "phrases", "to", "French.", "Manual", "evaluation", "by", "bilingual", "speakers", "revealed", "accuracies", "between", "65", "and", "78%.", "Champollion", "works", "by", "iteratively", "fusing", "together", "target", "language", "words", "that", "are", "strongly", "correlated", "to", "the", "source", "language", "collocation", "for", "which", "translation", "is", "attempted.", "Dice", "scores", "are", "used", "to", "filter", "out", "unlikely", "word", "combinations.", "Munteanu and Marcu (2002)", "ambitiously", "produce", "alignments", "from", "comparable", "corpora,", "corpora", "where", "exact", "translations", "may", "not", "be", "available,", "but", "in", "which", "the", "same", "topics", "or", "entities", "are", "being", "discussed", "such", "as", "contemporaneous", "newswire.", "They", "use", "suffix", "trees", "in", "both", "languages", "and", "a", "bilingual", "lexicon", "to", "provide", "points", "of", "correspondence", "between", "the", "two", "languages.", "Not", "only", "to", "they", "successfully", "create", "alignments", "in", "the", "comparable", "data,", "thus", "creating", "a", "parallel", "corpus,", "they", "create", "phrasal", "alignments", "of", "a", "restricted", "sort.", "Namely,", "their", "parallel", "phrases", "have", "the", "same", "number", "of", "tokens", "(i.e.,", "words)", "in", "each", "language", "and", "the", "word", "order", "of", "the", "source", "and", "target", "languages", "must", "be", "the", "same.", "Some", "examples", "of", "English/French", "alignments", "that", "they", "identified", "are:"], "cited_papers": [{"title": "Processing Comparable Corpora with Bilingual Suffix Trees", "year": "2002", "authors": ["D Munteanu", "D Marcu"]}], "target_citation_location": 95, "citation_locations": [6, 27, 95], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "0b3356f7-23c9-4807-ba1d-cc52b114f09d", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["From", "our", "source", "data", "we", "can", "extract", "parallel", "sentences", "for", "43", "languages.", "For", "12", "of", "these", "languages", "we", "have", "over", "10,000", "sentences", "available", "for", "projection", "as", "per", "table", "4.", "We", "removed", "some", "of", "these", "languages", "for", "having", "fewer", "than", "950", "lines,", "resulting", "in", "a", "total", "of", "32", "languages", "5", "including", "the", "annotated", "English", "and", "Finnish", "data.", "We", "have", "made", "all", "32", "datasets", "available", "on", "GitHub", "plus", "the", "raw", "data", "for", "all", "43", "languages", "including", "the", "11", "datasets", "that", "had", "fewer", "than", "950", "lines.", "10,582 11,128 11,503 11,885 12,559 12,836 14,831 15,712 15,713 16,217 16,608 22,194", "Table", "4:", "Languages", "(ISO", "code)", "with", "over", "10k", "parallel", "sentences", "with", "our", "annotated", "English", "data."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 83, "citation_locations": [83], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "0b435777-180b-4e1c-8990-2be845a1c199", "citing_paper": {"title": "Comparison of post-editing productivity between professional translators and lay users", "year": 2014, "authors": ["Nora Aranberri", "Gorka Labaka"]}, "text": ["Even", "when", "we", "are", "aware", "that", "many", "other", "factors", "are", "involved", "in", "the", "process,", "we", "turned", "to", "a", "readability", "-reading", "difficulty", "-measurement", "as", "a", "proxy", "for", "translation", "difficulty.", "We", "calculated", "the", "number", "of", "hard", "words", "9,", "lexical", "density", "10", "and", "Gunning", "Fog", "Index", "(Gunning, 1952)", "(see", "Table", "7).", "11", "When", "comparing", "both", "texts,", "we", "see", "that", "Text", "A", "has", "a", "slightly", "lower", "number", "of", "hard", "words,", "11.94%", "as", "opposed", "to", "13.64%", "for", "Text", "B.", "Lexical", "density", "is", "considerably", "higher", "for", "Text", "B,", "which", "means", "that", "repetitions", "are", "lower.", "Given", "that", "both", "Text", "A", "and", "Text", "B", "have", "very", "similar", "number", "of", "words,", "we", "conclude,", "therefore,", "that", "Text", "B", "has", "a", "higher", "number", "of", "different", "words,", "making", "it", "more", "complex.", "Finally,", "the", "Fog", "Index", "confirms", "that", "more", "years", "of", "education", "are", "necessary", "to", "read", "Text", "B.", "Overall,", "readability", "features", "suggest", "that", "Text", "B", "is", "more", "difficult", "to", "read.", "Understanding", "the", "source", "text", "is", "a", "vital", "step", "in", "translation,", "but", "other", "factors", "such", "as", "the", "mapping", "of", "the", "concepts", "and", "grammatical", "features", "pay", "an", "important", "role.", "In", "an", "attempt", "to", "measure", "both", "sides", "of", "the", "translation", "process", "in", "terms", "of", "complexity,", "we", "have", "also", "analysed", "the", "linguistic", "complexity", "of", "the", "translations", "produced", "by", "the", "participants.", "Based", "on", "the", "linguistic", "analysis", "presented", "in", "Gonzalez-Dios, et al. (2014),", "we", "have", "calculated", "the", "average", "occurrences", "of", "a", "number", "of", "linguistic", "features", "(including", "lexical,", "morphological,", "syntactic", "and", "pragmatic", "features)", "present", "in", "the", "translations", "and", "post-edited", "versions", "of", "Texts", "A", "and", "B", "(see", "Table", "8).", "We", "observe", "that", "out", "of", "the", "96", "features", "studied,", "Text", "B", "has", "a", "higher", "number", "of", "occurrences", "for", "63", "for", "both", "translators", "and", "users,", "and", "Text", "A", "for", "25", "and", "17,", "for", "translators", "and", "users,", "respectively,", "having", "no", "occurrences", "for", "8", "and", "6", "features.", "Additioanlly,", "we", "have", "considered", "the", "10", "most", "predictive", "features", "for", "complexity", "according", "to", "the", "same", "authors,", "which", "include", "a", "number", "of", "the", "most", "predictive", "features", "according", "to", "Feng et al. (2010),", "namely,", "partof-speech", "ratios", "for", "nouns.", "We", "see", "that", "Text", "B", "appears", "to", "be", "more", "complex,", "scoring", "higher", "in", "7", "out", "of", "the", "10", "features.", "A", "final", "aspect", "that", "is", "worth", "noting", "is", "text", "expansion", "rates.", "English", "is", "an", "analytic", "language", "and", "Basque", "is", "an", "agglutinative", "language,", "which", "usually", "means", "that", "word-counts", "contract", "when", "translating", "into", "Basque.", "For", "translators,", "on", "average,", "Text", "A", "has", "contracted", "to", "90.25%", "and", "Text", "B", "has", "expanded", "to", "103.85%", "with", "respect", "to", "the", "English", "source.", "For", "users,", "both", "texts", "contract", "but", "whereas", "Text", "A", "goes", "down", "to", "85.21%,", "Text", "B", "still", "remains", "at", "a", "high", "98.21%.", "The", "fact", "that", "an", "expansion", "has", "occurred", "in", "Text", "B", "might", "be", "due", "to", "participants", "tending", "to", "over-explain", "or", "paraphrase.", "This", "might", "be", "a", "result", "of", "the", "complexity", "of", "the", "content."], "cited_papers": [{"title": "Simple or Complex? Assessing the readability of Basque texts", "year": "2014", "authors": ["I Gonzalez-Dios", "M Aranzabe", "A Diaz De Ilarraza", "H Salaberri"]}], "target_citation_location": 209, "citation_locations": [43, 209, 315], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0b4ab0af-e084-4f4d-af0f-3ee6a8305a17", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["Phrase-based", "SMT", "systems", "[2]", "are", "the", "most", "commonly", "used", "technique", "in", "statistical", "machine", "translation", "nowadays.", "In", "this", "approach,", "source", "and", "target", "phrase", "pairs", "consistent", "with", "the", "word", "alignment", "are", "extracted", "from", "the", "parallel", "training", "data.", "Phrases", "in", "PBSMT", "are", "just", "contiguous", "chunks", "of", "text,", "and", "are", "not", "linguistically", "motivated.", "The", "extracted", "source-target", "phrase", "pairs", "along", "with", "their", "translation", "probabilities", "(computed", "from", "the", "same", "training", "data)", "are", "stored", "in", "a", "structure", "known", "as", "the", "'phrase", "table'.", "During", "translation,", "an", "input", "sentence", "is", "split", "up", "into", "phrases", "and", "their", "corresponding", "translations", "are", "looked", "up", "from", "the", "phrase", "table", "to", "create", "a", "set", "of", "translated", "sentences", "in", "the", "target", "language.", "The", "target", "phrases", "in", "each", "such", "translation", "are", "subsequently", "reordered", "using", "a", "statistical", "re-ordering", "model", "that", "assigns", "a", "probability", "based", "on", "the", "orientation", "between", "a", "phrase", "and", "the", "previously", "translated", "phrase.", "A", "language", "model", "is", "further", "used", "for", "better", "fluency", "and", "grammaticality", "of", "the", "translation.", "The", "phrase", "translation", "probabilities", "along", "with", "reordering", "and", "language", "model", "probabilities", "are", "combined", "in", "a", "log-linear", "fashion", "to", "assign", "a", "score", "to", "each", "possible", "translation", "of", "an", "input", "sentence.", "Finally", "the", "best", "scoring", "translation", "is", "searched", "for", "by", "the", "decoding", "algorithm", "and", "is", "presented", "as", "the", "best", "translation", "for", "the", "corresponding", "input", "sentence.", "Formally", "this", "task", "can", "be", "expressed", "as", "in", "(1):"], "cited_papers": [{"title": "Overview of the iwslt 2011 evaluation campaign", "year": "2011", "authors": ["M Federico", "L Bentivogli", "M Paul", "S Stueker"]}], "target_citation_location": 213, "citation_locations": [3, 213], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "0b96aa48-744b-4f0e-9270-d9fb54f797c1", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["WorldTree.", "A", "number", "of", "approaches", "have", "been", "proposed", "for", "the", "explanation", "regeneration", "task", "on", "WorldTree,", "including", "those", "from", "previous", "iterations", "of", "this", "shared", "task.", "These", "approaches", "adopt", "a", "set", "of", "diverse", "techniques", "ranging", "from", "graph-based", "learning", "(Li et al., 2020),", "to", "Transformer-based", "language", "models", "(Cartuyvels et al., 2020, Das et al., 2019, Pawate et al., 2020, Chia et al., 2019),", "Integer", "Linear", "Programming", "(Gupta and Srinivasaraghavan, 2020),", "and", "sparse", "retrieval", "models", "(Valentino et al., 2021, Chia et al., 2019)."], "cited_papers": [{"title": "ChiSquareX at TextGraphs 2020 Shared Task: Leveraging Pretrained Language Models for Explanation Regeneration", "year": "2020", "authors": ["Aditya Girish Pawate", "Varun Madhavan", "Devansh Chandak"]}, {"title": "Red Dragon AI at TextGraphs 2019 Shared Task: Language Model Assisted Explanation Generation", "year": "2019", "authors": ["Ken Yew", "Sam Chia", "Martin Witteveen", "unk Andrews"]}, {"title": "Chains-of-Reasoning at TextGraphs 2019 Shared Task: Reasoning over Chains of Facts for Explainable Multi-hop Inference", "year": "2019", "authors": ["Rajarshi Das", "Ameya Godbole", "Manzil Zaheer", "Shehzaad Dhuliawala", "Andrew Mccallum"]}, {"title": "Autoregressive Reasoning over Chains of Facts with Transformers", "year": "2020", "authors": ["Ruben Cartuyvels", "Graham Spinks", "Marie-Francine Moens"]}], "target_citation_location": 41, "citation_locations": [36, 41, 45, 50], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "0be697c9-cd46-492b-b300-dbc475d020dd", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["The", "vast", "majority", "of", "the", "dataset", "was", "annotated", "by", "university", "students", "learning", "about", "sentiment", "analysis", "with", "some", "annotations", "provided", "by", "expert", "annotators", "for", "reliability", "measurements", "( \u00d6hman et al., 2018).", "The", "students'", "annotation", "process", "was", "monitored", "and", "evaluated.", "They", "received", "only", "minimal", "instructions.", "These", "instructions", "included", "that", "they", "were", "to", "focus", "on", "the", "quality", "of", "annotations", "rather", "than", "quantity,", "and", "to", "annotate", "from", "the", "point", "of", "view", "of", "the", "speaker.", "We", "also", "asked", "for", "feedback", "on", "the", "annotation", "process", "to", "improve", "the", "user-friendliness", "of", "the", "platform", "for", "future", "use.", "In", "tables", "2", "and", "5", "the", "number", "of", "active", "annotators", "have", "been", "included.", "All", "in", "all", "over", "100", "students", "annotated", "at", "least", "some", "sentences", "with", "around", "60", "active", "annotators,", "meaning", "students", "who", "annotated", "more", "than", "300", "sentences", "( \u00d6hman, 2020)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 25, "citation_locations": [25, 122], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0cafbd9d-be24-4e57-9f5b-13b44699c005", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["A", "set", "of", "30", "high-level", "instructions", "specific", "to", "semantic", "network", "processing", "are", "implemented", "directly", "in", "hardware.", "These", "include", "associative", "search,", "marker", "setting", "and", "propagation,", "logical/arithmetic", "operations", "involving", "markers,", "create", "and", "delete", "nodes", "and", "relations,", "and", "collect", "a", "list", "of", "nodes", "with", "a", "certain", "marker", "set.", "Currently,", "the", "instruction", "set", "can", "be", "called", "from", "C", "language", "so", "that", "users", "can", "develop", "applications", "with", "an", "extended", "version", "of", "C", "language.", "From", "the", "programming", "level,", "SNAP", "provides", "data-parallel", "programming", "environment", "similar", "to", "C*", "of", "the", "Connection", "Machine", "[Thinking Machine Corp., 1989", "],", "but", "specialized", "for", "semantic", "network", "processing", "with", "marker", "passing."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 84, "citation_locations": [84], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "0d047316-e1bc-4506-a374-2fe99e460436", "citing_paper": {"title": "Situation-Specific Multimodal Feature Adaptation", "year": 2021, "authors": ["\u00d6zge Alac"]}, "text": ["MS", "COCO", "(Lin et al., 2014", "):", "an", "object", "detection", "and", "captioning", "dataset", "with", "&gt,200", "K", "labeled", "images", "and", "5", "captions", "in", "a", "sentence", "form", "for", "each", "image", "Flicker30k", "(Plummer et al., 2015):", "31", "K", "images", "collected", "from", "Flickr,", "together", "with", "5", "reference", "sentences", "ImageNET", "(Deng et al., 2009):", "14", "M", "annotated", "images,", "hierarchically", "organized", "(w.r.t.", "WordNet)", "MVSO", "(Jou et al., 2015):", "15", "K", "visual", "concepts", "across", "12", "languages,", "7.36", "M", "images", "Additionally,", "there", "are", "multimodal", "datasets", "that", "were", "created", "for", "a", "specific", "task:"], "cited_papers": [{"title": "Microsoft coco: Common objects in context", "year": "2014", "authors": ["Tsung-Yi Lin", "Michael Maire", "Serge Belongie", "James Hays", "Pietro Perona", "Deva Ramanan", "Piotr Doll\u00e1r", "C Lawrence Zitnick"]}], "target_citation_location": 2, "citation_locations": [2, 26, 39, 49], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0d890a23-237e-4930-bb69-bbeb550f6369", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["n", "positive", "signifiers", "n", "words", "NCR", "VAD", "Lexicon", "This", "measure", "is", "based", "on", "a", "list", "of", "words", "rated", "on", "the", "emotional", "dimensions", "of", "valence,", "arousal,", "and", "dominance", "which", "has", "been", "used", "in", "gender", "bias", "research.", "In", "particular,", "weakness", "(low", "dominance),", "passiveness", "(low", "arousal", "or", "agency),", "and", "badness", "(valence)", "may", "be", "associated", "with", "a", "female", "stereotype", "(Stanczak and Augenstein, 2021).", "Given", "the", "size", "of", "the", "lexicon", "and", "its", "overlap", "of", "up", "to", "100%", "with", "other", "word", "lists,", "we", "only", "counted", "words", "with", "either", "a", "valence,", "arousal,", "or", "dominance", "rating", "&gt,", "0.75", "on", "a", "scale", "from", "0", "to", "1.", "The", "calculation", "is:"], "cited_papers": [{"title": null, "year": "2021", "authors": ["Karolina Stanczak", "Isabelle Augenstein"]}], "target_citation_location": 55, "citation_locations": [55], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0db63059-0925-4372-9de0-76e410bd9af4", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["Naturally,", "the", "WMT", "Metrics", "task,", "most", "recently", "run", "in", "2020", "(Mathur et al., 2020b)", "is", "one", "such", "forum", "for", "the", "evaluation", "of", "metrics.", "In", "this", "last", "iteration,", "metrics", "were", "evaluated", "based", "on", "their", "correlation", "with", "human", "judgment", "scores", "on", "the", "sentence,", "paragraph,", "and", "document", "level.", "BERTScore", "was", "not", "included", "even", "in", "the", "most", "recent", "iteration", "of", "the", "metrics", "task."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 10, "citation_locations": [10], "citation_type": "single", "annotations": [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "0dfa5468-9f66-4fb6-810b-5a93b0d01d71", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["Intended", "use.", "One", "primary", "goal", "of", "NLP", "models", "is", "the", "generalization", "to", "real-world", "inputs.", "However,", "existing", "test", "datasets", "and", "templates", "are", "often", "not", "comprehensive,", "and", "thus", "it", "is", "difficult", "to", "evaluate", "real-world", "performance", "(Recht et al., 2019, Ribeiro et al., 2020).", "Our", "work", "sheds", "a", "light", "on", "quantifying", "performance", "for", "inputs", "beyond", "the", "test", "dataset", "and", "help", "uncover", "model", "weaknesses", "prior", "to", "the", "realworld", "deployment.", "Misuse", "potential.", "Similar", "to", "other", "existing", "adversarial", "attack", "methods", "(Ebrahimi et al., 2018, Jin et al., 2019, Zhao et al., 2018b),", "our", "second-order", "attacks", "can", "be", "used", "for", "finding", "vulnerable", "examples", "to", "a", "NLP", "system.", "Therefore,", "it", "is", "essential", "to", "study", "how", "to", "improve", "the", "robustness", "of", "NLP", "models", "second-order", "attacks.", "Limitations.", "While", "the", "core", "idea", "about", "the", "double", "perturbation", "framework", "is", "general,", "in", "\u00a74,", "we", "consider", "only", "binary", "gender", "in", "the", "analysis", "of", "counterfactual", "fairness", "due", "to", "the", "restriction", "of", "the", "English", "corpus", "we", "used,", "which", "only", "have", "words", "associated", "with", "binary", "gender", "such", "as", "he/she,", "waiter/waitress,", "etc."], "cited_papers": [{"title": "Beyond accuracy: Behavioral testing of nlp models with checklist", "year": "2020", "authors": ["Tongshuang Marco Tulio Ribeiro", "Carlos Wu", "Sameer Guestrin", "unk Singh"]}, {"title": "Do ImageNet classifiers generalize to ImageNet?", "year": "2019", "authors": ["Benjamin Recht", "Rebecca Roelofs", "Ludwig Schmidt", "Vaishaal Shankar"]}], "target_citation_location": 33, "citation_locations": [33, 67], "citation_type": "group", "annotations": [[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0e8baf19-6c22-46b3-9161-54951d0ed82c", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["We", "use", "MultiWOZ", "(Budzianowski et al., 2018),", "a", "multi-domain", "human-human", "conversational", "dataset", "in", "our", "experiments.", "It", "contains", "in", "total", "8438", "dialogues", "spanning", "over", "seven", "domains,", "and", "each", "dialogue", "has", "13.7", "turns", "on", "average.", "We", "use", "the", "separation", "of", "training,", "validation", "and", "testing", "data", "as", "original", "MultiWOZ", "dataset.", "We", "use", "the", "evaluation", "metrics", "as", "Budzianowski et al. (2018)", "to", "measure", "dialogue", "task", "completion,", "which", "are", "how", "often", "the", "system", "provides", "a", "correct", "entity", "(Inform)", "and", "answers", "all", "the", "requested", "information", "(Success).", "We", "use", "BLEU", "(Papineni et al., 2002)", "to", "measure", "the", "language", "quality", "of", "generated", "responses."], "cited_papers": [{"title": "Bleu: a method for automatic evaluation of machine translation", "year": "2002", "authors": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu"]}], "target_citation_location": 77, "citation_locations": [3, 50, 77], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "0ef6e06f-b63a-4660-95c1-7806810db828", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["We", "utilize", "a", "standard", "Transformer", "(Vaswani et al., 2017)", "as", "our", "generation", "model.", "It", "takes", "the", "concatenation", "of", "the", "sequence", "x", "and", "all", "the", "selected", "concepts", "v", "1,", "...,", "v", "N", "as", "input", "and", "auto-regressively", "generates", "the", "outputs", "y.", "We", "adopt", "the", "cross-entropy", "loss,", "which", "can", "be", "written", "as:L", "generation", "=", "\u2212", "log", "p(y|x,", "v", "1,", "\u2022,", "v", "N)", "(5)", "=", "\u2212", "|y|", "t=1", "log", "p(y", "t", "|x,", "v", "1,", "\u2022,", "v", "N,", "y", "&lt,t", ").Note", "that", "since", "the", "selected", "concepts", "do", "not", "have", "a", "rigorous", "order,", "we", "only", "apply", "positional", "encodings", "(used", "in", "Transformer)", "to", "the", "input", "sequence", "x."], "cited_papers": [{"title": "Attention is all you need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0f11c20d-d5f7-438f-82a3-bd4c687a251a", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["Visual", "Embedding", "We", "adopt", "a", "CNN", "backbone", "to", "extract", "image", "features", "V", "=", "{v", "i}", "L", "i=1", "for", "each", "image", "I", "where", "L", "is", "the", "size", "of", "feature", "grids", "and", "v", "i", "\u2208", "R", "dv", "is", "a", "feature", "vector", "with", "dimension", "d", "v.", "In", "addition,", "each", "feature", "is", "further", "concatenated", "with", "its", "2-D", "sine", "position", "embedding", "(Carion et al., 2020).", "Following", "SOHO,", "we", "use", "a", "ResNet-101", "(He et al., 2016)", "as", "the", "visual", "backbone,", "followed", "by", "additional", "1x1", "Conv", "and", "2x2", "strides", "Max-pooling", "to", "reduce", "the", "memory", "footprint."], "cited_papers": [{"title": "Deep residual learning for image recognition", "year": "2016", "authors": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"]}], "target_citation_location": 63, "citation_locations": [56, 63], "citation_type": "single", "annotations": [[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "0f50a73d-e74d-4342-bfe0-1d768b2cb02b", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["To", "explore", "the", "generality", "of", "our", "LTR", "approach,", "we", "also", "conduct", "experiments", "on", "the", "MS", "MARCO", "document", "ranking", "task.", "We", "emphasize", "here", "that", "all", "experiments", "are", "conducted", "in", "a", "zero-shot", "manner,", "over", "paragraph", "extracts", "from", "the", "collection,", "what", "is", "commonly", "known", "as", "the", "MaxP", "approach", "(Bendersky and Kurland, 2009, Dai and Callan, 2019, Akkalyoncu Yilmaz et al., 2019, Sheetrit et al., 2020).", "Both", "the", "final-stage", "neural", "reranker", "and", "our", "LTR", "module", "are", "trained", "on", "MS", "MARCO", "passage", "data", "only.", "However,", "comparing", "our", "effectiveness", "results", "with", "the", "official", "leaderboard", "reveals", "that", "our", "configurations", "are", "competitive", "compared", "to", "other", "single-stage", "rerankers."], "cited_papers": [{"title": "A passage-based approach to learning to rank documents", "year": "2020", "authors": ["Eilon Sheetrit", "Anna Shtok", "Oren Kurland"]}, {"title": "Utilizing passage-based language models for ad hoc document retrieval", "year": "2009", "authors": ["Michael Bendersky", "Oren Kurland"]}, {"title": "Deeper text understanding for IR with contextual neural language modeling", "year": "2019", "authors": ["Zhuyun Dai", "Jamie Callan"]}, {"title": "Cross-domain modeling of sentence-level evidence for document retrieval", "year": "2019", "authors": ["Wei Zeynep Akkalyoncu Yilmaz", "Haotian Yang", "Jimmy Zhang", "unk Lin"]}], "target_citation_location": 45, "citation_locations": [45], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "0f9aaecd-1e0c-422f-93f6-b6cb4c82770b", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["POS", "tagger", "from", "Totale", "(Erjavec 2006)", "was", "also", "used", "as", "the", "disambiguation", "module", "instead", "of", "the", "original", "apertium", "tagger."], "cited_papers": [{"title": "Multilingual tokenisation, tagging, and lemmatisation with totale", "year": "2006", "authors": ["Erjavec Toma\u017e"]}], "target_citation_location": 4, "citation_locations": [4], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "101a11cc-ec0c-46ae-b594-8d3f64391c51", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["In", "general,", "for", "linguistic", "representation", "it", "is", "the", "derived", "tree", "that", "is", "used", "as", "the", "primary", "structure", "of", "representation,", "so", "the", "labels", "would", "represent", "words", "in", "a", "typical", "lexicalised", "grammar", "and", "the", "trees", "\u00ab", "\u00bd,", "\u00ab", "\u00be", "and", "\u00ac", "\u00bd", "would", "represent", "argument", "structure", "of", "these", "words.", "However,", "we", "will", "use", "a", "TAG", "grammar", "as", "a", "way", "of", "characterising", "other", "sorts", "of", "trees,", "such", "as", "TAG", "derivation", "trees", "or", "dependency", "trees,", "this", "is", "thus", "in", "a", "sense", "an", "extension", "of", "the", "notion", "of", "the", "meta-level", "grammar", "of", "Dras (1999).", "The", "idea", "is", "then", "to", "use", "a", "TAG", "grammar", "to", "break", "down", "some", "tree", "representation-which", "may", "be", "a", "dependency", "tree,", "a", "TAG", "derivation", "tree,", "6", "or", "other-into", "component", "trees", "possibly", "representing", "non-contiguous", "groupings.", "The", "aim", "is", "not", "to", "describe", "every", "decomposition", "into", "non-contiguous", "groupings,", "only", "those", "such", "as", "the", "language-related", "cases", "presented", "in", "Section", "2,", "and", "the", "use", "of", "TAG", "as", "representation", "allows", "for", "the", "complexity", "results", "below.", "We", "now", "present", "an", "algorithm", "for", "the", "decomposition", "in", "Section", "4."], "cited_papers": [{"title": "A meta-level grammar: redefining Synchronous TAG for translation and paraphrase", "year": "1999", "authors": ["M Dras"]}], "target_citation_location": 87, "citation_locations": [87], "citation_type": "single", "annotations": [[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1057e173-d360-4717-bcc5-b56b512b79b7", "citing_paper": {"title": "Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model", "year": 2022, "authors": ["Richard Futrell"]}, "text": ["Proposed", "model", "I", "propose", "a", "log-bilinear", "model", "(Mnih and Hinton, 2007, 2008)", "using", "word", "embeddings", "as", "input:", "1"], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 7, "citation_locations": [7], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 0]]}
{"id": "107e482a-318a-4905-8f58-73c1e8d3b206", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["The", "system", "is", "based", "on", "the", "Moses", "SMT", "toolkit", "[3]", "and", "constructed", "as", "follows.", "First,", "Giza++", "is", "used", "to", "perform", "word", "alignments", "in", "both", "directions.", "Second,", "phrases", "and", "lexical", "reorderings", "are", "extracted.", "Both", "steps", "use", "the", "default", "settings", "of", "the", "Moses", "SMT", "toolkit.", "A", "4-gram", "back-off", "target", "LM", "is", "then", "constructed", "as", "detailed", "in", "section", "3.2.", "The", "translation", "itself", "is", "performed", "in", "two", "passes:", "first,", "Moses", "is", "run", "and", "a", "1000-best", "list", "is", "generated", "for", "each", "sentence.", "The", "parameters", "of", "this", "first", "pass", "are", "tuned", "on", "development", "data", "using", "the", "cmert", "tool.", "These", "1000-best", "lists", "are", "then", "rescored", "with", "a", "continuous", "space", "4-gram", "LM", "and", "the", "weights", "of", "the", "feature", "functions", "are", "again", "optimized", "using", "the", "open", "source", "numerical", "optimization", "toolkit", "Condor", "[7].", "The", "details", "of", "this", "optimization", "procedure", "are", "as", "follows:"], "cited_papers": [{"title": "CONDOR, a new parallel, constrained extension of powell's UOBYQA algorithm: Experimental results and comparison with the DFO algorithm", "year": "2005", "authors": ["F Berghen", "H Bersini"]}], "target_citation_location": 122, "citation_locations": [9, 122], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "10897b03-b4e3-4f89-8b0f-01134949268a", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["For", "the", "training", "of", "Transformer+CTC,", "we", "applied", "joint", "CTC", "training", "to", "improve", "performance", "(Karita et al., 2019).", "For", "CTC-based", "decoding,", "we", "used", "the", "greedy", "search", "algorithm.", "For", "Transformer", "decoding,", "we", "used", "the", "beam", "search", "algorithm", "and", "tuned", "search", "parameters", "using", "the", "development", "set.", "For", "the", "Transformer+CTC", "model,", "we", "applied", "Transformer/CTC", "joint", "decoding", "(Karita et al., 2019).", "and", "tuned", "the", "weights", "of", "the", "objective", "using", "the", "development", "set.", "Note", "that", "the", "language", "model", "shallow", "fusion", "(Hori et al., 2018)", "is", "not", "applied", "since", "we", "could", "not", "find", "effectiveness", "in", "our", "preliminary", "experiment."], "cited_papers": [{"title": "Improving Transformer-based end-to-end speech recognition with connectionist temporal classification and language model integration", "year": "2019", "authors": ["S Karita", "N Soplin", "S Watanabe", "M Delcroix", "A Ogawa", "T Nakatani"]}], "target_citation_location": 49, "citation_locations": [13, 49, 68], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "10db6e79-23e4-4e1d-b0e7-9be761293266", "citing_paper": {"title": "A Parameter-Based Message-Passing Parser for MT of Korean and English", "year": 1994, "authors": ["Bonnie Dorr", "Jye-Hoon Lee", "Sungki Suh"]}, "text": ["Our", "GB", "parser", "is", "an", "extension", "of", "the", "message-passing", "approach", "proposed", "by", "Lin (1993)", "and", "Lin and Goebel (1993),", "which", "uses", "a", "network", "to", "encode", "the", "grammar.", "The", "nodes", "in", "the", "grammar", "network", "represent", "grammatical", "categories", "(e.g.,", "NP,", "Nbar,", "N)", "or", "subcategories,", "such", "as", "V:NP", "(i.e.,", "a", "transitive", "verb", "that", "takes", "an", "NP", "as", "complement).", "Figure", "l.a", "depicts", "a", "portion", "of", "the", "grammar", "network", "for", "English."], "cited_papers": [{"title": "Context-free grammar parsing by message passing", "year": "1993", "authors": ["D Lin", "R Goebel"]}], "target_citation_location": 14, "citation_locations": [12, 14], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "113cce68-b4e5-4758-b8c1-caaf1d4ba83a", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["By", "contrast,", "engineering", "applications", "mainly", "aim", "to", "maximise", "performance", "accuracy,", "utilising", "all", "available", "information", "and", "more", "powerful", "nonlinear", "classifiers.", "Intriguingly,", "recent", "studies", "have", "shown", "that", "adding", "human", "eye", "tracking", "data", "(Barrett et al., 2016)", "or", "morphosyntactic", "information", "extracted", "from", "human", "functional", "magnetic", "resonance", "imaging", "(fMRI)", "signals", "during", "sentence", "reading,", "can", "substantially", "improve", "PoS", "induction", "(Bingel et al., 2016", ").", "Yet,", "morphosynactic", "information", "obtained", "from", "fMRI", "is", "limited,", "because", "fMRI", "measures", "only", "the", "slow", "changes", "in", "blood", "oxygenation,", "peaking", "5-6", "s", "after", "stimulus", "onset,", "rather", "than", "the", "rapid", "neural", "activity", "during", "language", "processing."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 30, "citation_locations": [30, 51], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "117b6024-d843-43e4-96f2-7b3ac02c7f4c", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["Task", "Definition", "The", "Text-based", "NP", "Enrichment", "task", "is", "deceptively", "simple:", "For", "each", "ordered", "pair", "(n", "1,", "n", "2)", "of", "non-pronominal", "base-NP", "3", "spans", "in", "an", "input", "text,", "determine", "if", "there", "exists", "a", "preposition-mediated", "relation", "between", "n", "1", "and", "n", "2,", "and", "if", "there", "is", "one,", "determine", "the", "preposition", "that", "best", "describes", "their", "relation.", "4", "The", "output", "is", "a", "list", "3", "We", "follow", "the", "definition", "of", "Base-NPs", "as", "defined", "by", "Ramshaw and Marcus (1995):", "initial", "portions", "of", "non-recursive", "noun-phrases,", "including", "pre-modifiers", "such", "as", "determiners,", "adjectives", "and", "noun-compounds,", "but", "not", "including", "post-modifiers", "such", "as", "prepositional", "phrases", "and", "clauses.", "These", "are", "also", "known", "in", "the", "NLP", "literature", "as", "''NP", "Chunks''.", "4", "During", "annotation,", "we", "noticed", "that", "annotators", "often", "tried", "to", "express", "set-membership", "using", "prepositions,", "which", "resulted", "in", "awkward", "and", "unclear", "annotations.", "To", "remedy", "this,", "we", "found", "it", "effective", "to", "add", "an", "explicit", "''member-of''", "relation", "as", "an", "allowed", "annotation", "option.", "This", "significantly", "reduced", "of", "tuples", "of", "the", "form", "(n", "i,", "prep,", "n", "j", "),", "where", "n", "i", "is", "called", "the", "anchor", "and", "n", "j", "is", "called", "the", "complement", "of", "the", "relation.", "Figure", "2", "shows", "an", "example", "of", "text", "where", "each", "NP", "n", "1", "is", "annotated", "with", "its", "(prep,", "n", "2)", "NP-enrichments."], "cited_papers": [{"title": "Text chunking using transformation-based learning", "year": "1995", "authors": ["Lance Ramshaw", "Mitch Marcus"]}], "target_citation_location": 69, "citation_locations": [69], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1248a723-2831-4842-92fc-41a26a73a61b", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["We", "would", "also", "like", "to", "validate", "our", "methods", "on", "a", "variety", "of", "other", "data", "sets", "and", "tasks.", "We", "selected", "the", "MasakhaNER", "dataset", "for", "evaluation", "because", "we", "specifically", "wished", "to", "evaluate", "results", "on", "ac-tual", "low-resource", "languages", "supported", "by", "both", "Allosaurus", "and", "Epitran.", "While", "there", "are", "still,", "we", "argue,", "detectable", "improvements", "in", "downstream", "results", "with", "our", "method,", "further", "work", "would", "benefit", "from", "additional", "evaluations", "on", "other", "data", "sets", "or", "tasks.", "In", "particular,", "the", "Swahili", "News", "Classification", "corpus", "(David, 2020)", "corpus", "may", "provide", "a", "useful", "evaluation."], "cited_papers": [{"title": "Swahili : News classification dataset. The news version contains both train and test sets", "year": "2020", "authors": ["Davis David"]}], "target_citation_location": 75, "citation_locations": [75], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "1257587a-a31a-46fa-8886-03d847259ec8", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["GLOVE", "(Chen et al., 2019)", "71.9", "ELMO", "(Chen et al., 2019)", "80.2", "BERT", "BASE", "\u2192", "LR", "(Chen et al., 2019)", "80.6", "BERT", "LARGE", "\u2192", "LR", "(Chen et al., 2019)", "79", "BERT-base", "by", "adding", "an", "internal", "entity", "linker."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 4, "citation_locations": [1, 4, 10, 16], "citation_type": "single", "annotations": [[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1298f98c-416a-45fd-9f28-27d136dfec11", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["The", "Baseline", "method", "only", "takes", "image", "feature", "as", "input", "while", "the", "+Trace", "model", "take", "image", "feature", "and", "trace", "both", "as", "input.", "They", "employ", "the", "architecture", "in", "Changpinyo et al. (2019)", "with", "a", "few", "minor", "differences.", "First,", "they", "set", "the", "number", "of", "Transformers'", "layers", "for", "both", "the", "encoder", "and", "the", "decoder", "to", "2", "instead", "of", "6.", "Second,", "their", "projection", "layers", "also", "consist", "of", "layer", "normalization", "(Ba et al., 2016).", "Third,", "they", "set", "the", "maximum", "number", "of", "iterations", "to", "150k.", "Finally,", "they", "allow", "the", "maximum", "number", "of", "target", "captions", "to", "be", "as", "long", "as", "225", "to", "account", "for", "the", "narration's", "longer", "nature.", "LoopCAG", "methods", "Our", "model", "comprises", "of", "four", "components:", "1)", "the", "transformer", "encoderdecoder", "framework,", "2)", "the", "trace", "input,", "3)", "Attention", "Guidance(+AG", "for", "short)", "grounding", "loss,", "4)", "Contrastive", "constraints(+C", "for", "short)."], "cited_papers": [{"title": "Decoupled box proposal and featurization with ultrafine-grained semantic labels improve image captioning and visual question answering", "year": "1909", "authors": ["Soravit Changpinyo", "Bo Pang", "Piyush Sharma", "Radu Soricut"]}], "target_citation_location": 26, "citation_locations": [26, 61], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "12c93147-f4cd-4f50-aa3c-78621dfef731", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["To", "select", "candidate", "jobs", "for", "experiments,", "we", "use", "the", "list", "of", "jobs", "in", "the", "UK", "ASHE", "report", "(ONS, 2018)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 17, "citation_locations": [17], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "1329336a-81f5-49ec-8285-8fe1d21ade8e", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["One", "main", "challenge", "of", "directly", "optimizing", "a", "Seq2Seq", "model", "with", "quality", "scores", "of", "the", "output", "is", "that", "the", "discrete", "sampling", "process", "makes", "the", "loss", "non-differentiable.", "To", "circumvent", "this", "problem,", "reinforcement", "learning", "has", "been", "used", "to", "reformulate", "the", "conditional", "text", "generation", "tasks", "(Ranzato et al., 2016, Bahdanau et al., 2016, Li et al., 2016, Paulus et al., 2018, Li et al., 2019).", "Compared", "to", "this", "school", "of", "methods,", "our", "method", "is", "based", "on", "supervised", "learning,", "and", "it", "is", "more", "stable", "and", "less", "sensitive", "to", "the", "design", "choices", "(e.g.", "reward", "shaping),", "which", "are", "well-known", "challenges", "of", "reinforcement", "learning", "methods.", "Minimum", "risk", "training", "(Shen et al., 2016, Wieting et al., 2019)", "and", "other", "online", "sampling", "based", "methods", "(Bengio et al., 2015, Norouzi et al., 2016, Zhang et al., 2019)", "belong", "to", "another", "school", "of", "methods", "used", "to", "circumvent", "the", "problem", "of", "non-differentiability.", "However,", "they", "also", "exhibit", "similar", "problems", "of", "stability", "as", "reinforcement", "learning.", "Contrastive", "Learning", "Recently,", "contrastive", "learning", "(Hadsell et al., 2006)", "has", "been", "introduced", "into", "several", "conditional", "text", "generation", "tasks,", "such", "as", "machine", "translation", "(Yang et al., 2019, Pan et al., 2021),", "text", "summarization", "(Cao and Wang, 2021, Xu et al., 2021, Sun and Li, 2021),", "and", "other", "tasks", "(Uehara et al., 2020, Cho et al., 2021, Lee et al., 2021b).", "Among", "these", "application", "scenarios,", "most", "work", "deployed", "contrastive", "learning", "in", "the", "latent", "representation", "space,", "following", "the", "framework", "proposed", "in", "Chen et al. (2020).", "However,", "in", "this", "work", "we", "adopt", "contrastive", "learning", "over", "the", "discrete", "space", "of", "the", "generated", "texts.", "Besides,", "instead", "of", "constructing", "the", "contrastive", "learning", "examples", "by", "rule-based", "methods", "(e.g.", "perturbing", "the", "reference", "output),", "we", "use", "the", "generation", "models", "to", "construct", "the", "examples,", "which", "makes", "the", "contrastive", "learning", "task", "closer", "to", "the", "generation", "task.", "Sun", "and", "Li", "(2021)", "also", "adopted", "contrastive", "learning", "on", "the", "generated", "texts.", "However,", "their", "formulation", "belongs", "to", "the", "margin-based", "losses.", "We", "have", "discussed", "the", "difference", "between", "our", "method", "and", "the", "margin-based", "losses", "in", "the", "previous", "paragraphs.", "Discriminative", "Reranking", "Discriminative", "reranking", "has", "been", "widely", "studied", "for", "conditional", "generation", "tasks", "(Shen et al., 2004, Och et al., 2004, Wan et al., 2015, Mizumoto and Matsumoto, 2016).", "Some", "recent", "works", "(Liu and Liu, 2021, Lee et al., 2021a)", "have", "also", "explored", "discriminative", "reranking", "of", "candidates", "from", "neural", "natural", "language", "generation", "models,", "which", "adopt", "large", "pre-trained", "language", "models", "(e.g.", "BERT", "(Devlin et al., 2019))", "as", "the", "reranker.", "In", "this", "work,", "we", "factorize", "the", "Seq2Seq", "model", "(e.g.,", "BART)", "trained", "on", "the", "same", "dataset", "as", "the", "reranking", "model,", "which", "maximizes", "the", "parameter", "sharing", "across", "two", "stages.", "Besides,", "our", "approach", "contributes", "an", "instance", "of", "leveraging", "large", "pre-trained", "Seq2Seq", "models", "as", "a", "quality", "estimation", "model", "(Yuan et al., 2021)."], "cited_papers": [{"title": "Discriminative reranking for grammatical error correction with statistical machine translation", "year": "2016", "authors": ["Tomoya Mizumoto", "Yuji Matsumoto"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "Multi-document summarization via discriminative summary reranking", "year": "2015", "authors": ["Xiaojun Wan", "Ziqiang Cao", "Furu Wei", "Sujian Li", "M Zhou"]}], "target_citation_location": 260, "citation_locations": [41, 81, 88, 118, 132, 135, 139, 159, 260, 264, 286, 334], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "13953d36-f056-42de-885e-ab1722e0651c", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["This", "generation", "task", "adopts", "the", "traditional", "image", "captioning", "evaluation", "metric", "using", "the", "open-source", "tool", "2", "with", "a", "minor", "modification", "3", "to", "suit", "with", "LN-COCO,", "including", "BLEU", "(Papineni et al., 2002),", "METEOR", "(Banerjee and Lavie, 2005),", "ROUGE-L", "(Lin and Och, 2004),", "ROUGE-1-F1(Pont-Tuset", "et", "al.,", "2020),", "and", "CIDEr-D", "(Vedantam et al., 2015)."], "cited_papers": [{"title": "Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics", "year": "2004", "authors": ["Chin-Yew Lin", "Franz Josef Och"]}], "target_citation_location": 30, "citation_locations": [26, 28, 30, 37], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "147acd2a-9cb4-416b-8eca-8f76b2e3e2fc", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["For", "each", "potential", "shortcut", "token,", "we", "extract", "N", "synonyms", "by", "leveraging", "the", "word", "embeddings", "curated", "for", "synonym", "extraction", "(Mrk\u0161i\u0107 et al., 2016),", "plus", "WordNet", "(Miller, 1995)", "and", "DBpedia", "(Auer et al., 2007).", "More", "specifically,", "for", "each", "top", "token", "t", "in", "the", "list", "generated", "by", "the", "previous", "step,", "we", "first", "search", "counter-fitting", "word", "vectors", "to", "find", "synonyms", "with", "cosine", "similarity", "larger", "than", "a", "threshold", "4", "\u03c4.", "Additionally", "we", "search", "in", "WordNet", "and", "DBpedia", "to", "obtain", "a", "maximum", "of", "N", "synonyms", "for", "each", "token", "t.", "Then", "we", "extract", "a", "subset", "S", "t", "from", "D,", "which", "consists", "of", "sentences", "containing", "t.", "We", "perturb", "all", "sentences", "in", "S", "t", "by", "replacing", "t", "with", "its", "synonyms.", "The", "resulted", "perturbed", "set", "S", "\u2032", "t", "is", "N", "times", "of", "the", "original", "set", "S", "t.", "We", "apply", "model", "f", "on", "S", "t", "and", "S", "\u2032", "t", "and", "obtain", "accuracy", "acc", "t", "and", "acc", "\u2032", "t.", "Since", "we", "only", "perturb", "S", "t", "with", "t's", "synonyms,", "the", "semantic", "meaning", "of", "perturbed", "sentences", "should", "stay", "close", "to", "the", "original", "sentences.", "Thus,", "if", "t", "is", "a", "genuine", "token,", "acc", "\u2032", "t", "is", "expected", "to", "be", "close", "to", "acc", "t.", "On", "the", "other", "hand,", "if", "t", "is", "a", "shortcut,", "model", "prediction", "can", "be", "different", "even", "the", "semantic", "meaning", "of", "the", "sentence", "does", "not", "change", "a", "lot", "(see", "examples", "in", "Table", "2).", "Thus,", "we", "assume", "tokens", "with", "larger", "differences", "between", "acc", "t", "and", "acc", "\u2032", "t", "are", "more", "likely", "to", "be", "shortcuts", "and", "tokens", "with", "smaller", "differences", "are", "more", "likely", "to", "be", "domain", "specific", "\"genuine\"", "words.", "From", "the", "potential", "shortcut", "token", "list", "computed", "in", "Sec", "3.2,", "we", "remove", "tokens", "with", "performance", "difference", "smaller", "than", "\u03b4", "to", "further", "filter", "domain", "specific", "\"geniue\"", "tokens."], "cited_papers": [{"title": "Counter-fitting word vectors to linguistic constraints", "year": "2016", "authors": ["Nikola Mrk\u0161i\u0107", "\u00d3 Diarmuid", "Blaise S\u00e9aghdha", "Milica Thomson", "Lina Ga\u0161i\u0107", "Pei-Hao Rojas-Barahona", "David Su", "Tsung-Hsien Vandyke", "Steve Wen", "unk Young"]}], "target_citation_location": 18, "citation_locations": [18, 21, 24], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1497c2f8-c428-4304-93bc-091abc79d71c", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["In", "this", "work,", "we", "explore", "a", "set", "of", "interpretable", "entity", "representations", "that", "are", "simultaneously", "human", "and", "machine", "readable.", "The", "key", "idea", "of", "this", "approach", "is", "to", "use", "fine-grained", "entity", "typing", "models", "with", "large", "type", "inventories", "(Ling and Weld, 2012, Gillick et al., 2014, Choi et al., 2018, Onoe and Durrett, 2020).", "Given", "an", "entity", "mention", "and", "context", "words,", "our", "typing", "model", "outputs", "a", "highdimensional", "vector", "whose", "values", "are", "associated", "with", "predefined", "fine-grained", "entity", "types.", "Each", "value", "ranges", "between", "0", "and", "1,", "corresponding", "to", "the", "confidence", "of", "the", "model's", "decision", "that", "the", "entity", "has", "the", "property", "given", "by", "the", "corresponding", "type.", "We", "use", "pre-trained", "Transformer-based", "entity", "typing", "models,", "trained", "either", "on", "a", "supervised", "entity", "typing", "dataset", "(Choi et al., 2018)", "or", "on", "a", "distantlysupervised", "dataset", "derived", "from", "Wikipedia", "categories", "(Onoe and Durrett, 2020).", "The", "type", "vectors", "from", "these", "models,", "which", "contain", "tens", "of", "thousands", "of", "types,", "are", "then", "used", "as", "contextualized", "entity", "embeddings", "in", "downstream", "tasks."], "cited_papers": [{"title": "Ultra-Fine Entity Typing", "year": "2018", "authors": ["Eunsol Choi", "Omer Levy", "Yejin Choi", "Luke Zettlemoyer"]}], "target_citation_location": 100, "citation_locations": [35, 100, 110], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "14a9cca7-b623-4bb7-a3c3-cbad2ce4b2b1", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["Therefore,", "we", "additionally", "use", "two", "distantly", "labeled", "entity", "typing", "datasets", "derived", "from", "Wikipedia.", "We", "leverage", "past", "work", "in", "using", "types", "derived", "from", "Wikipedia", "categories", "(Suchanek et al., 2007, Onoe and Durrett, 2020, inter alia),", "which", "contain", "type", "information", "and", "are", "widely", "annotated", "across", "Wikipedia", "articles.", "We", "select", "the", "appropriate", "dataset", "for", "each", "setting", "depending", "on", "task-specific", "requirements", "(see", "Section", "6).", "For", "all", "datasets,", "we", "compute", "entity", "typing", "macro", "F1", "using", "development", "examples", "(1k)", "to", "check", "model", "convergence."], "cited_papers": [{"title": "YAGO: A Core of Semantic Knowledge", "year": "2007", "authors": ["Fabian Suchanek", "Gjergji Kasneci", "Gerhard Weikum"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "group", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "14be9216-7fea-41d6-b7b8-19b04b0bf143", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["We", "have", "started", "working", "on", "these", "issues,", "but", "none", "of", "it", "was", "finally", "used", "in", "our", "system,", "mainly", "due", "to", "the", "fact", "that", "no", "native", "speaker", "of", "the", "Arabic", "language", "was", "available.", "The", "submitted", "system", "was", "only", "retuned", "on", "the", "ASR", "1-best", "development", "data.", "Table", "5", "compares", "the", "BLEU", "score", "on", "various", "data", "sets", "of", "the", "text", "and", "ASR", "condition.", "We", "observe", "a", "degradation", "of", "about", "11%", "relative", "when", "translating", "the", "ASR", "output", "of", "Dev5", "and", "of", "16%", "for", "Dev6", "respectively.", "Unfortunately,", "translation", "of", "the", "ASR", "output", "did", "not", "work", "very", "well", "on", "this", "year's", "test", "data.", "High", "word", "error", "rates", "of", "the", "speech", "recognition", "module", "favor", "the", "translation", "of", "consensus", "networks", "[18]", "since", "the", "oracle", "error", "rate", "of", "such", "data", "structures", "is", "usually", "two", "to", "three", "times", "smaller.", "However,", "this", "data", "structure", "is", "incompatible", "with", "SYSTRAN's", "tokenization", "that", "operates", "at", "the", "sentence", "level."], "cited_papers": [{"title": "A new decoder for spoken language translation based on confusion networks", "year": "2005", "authors": ["N Bertoldi", "M Federico"]}], "target_citation_location": 112, "citation_locations": [112], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "15037448-2238-4f79-8267-bcb1abef3dc5", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["In", "our", "system,", "we", "train", "a", "Transformer", "(Vaswani et al., 2017)", "with", "a", "deep", "encoder", "(Meng et al., 2020)", "as", "baseline", "for", "abtaining", "rich", "source", "representations,", "besides", "we", "initialize", "the", "model", "with", "the", "method", "mentioned", "in", "DeepNet", "(Wang et al., 2022)", "in", "order", "to", "stabilize", "the", "training", "of", "the", "deeper", "model.", "At", "the", "pre-training", "stage,", "we", "firstly", "pretrain", "our", "model", "on", "a", "large", "general", "corpus,", "then", "we", "utilize", "data", "synthesis", "methods", "such", "as", "self-training", "and", "back-translation", "to", "improve", "model", "quality."], "cited_papers": [{"title": "Attention is all you need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 7, "citation_locations": [7, 12, 31], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "153e8912-59e4-4ced-8602-cdc6dd3dab44", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["From", "a", "technical", "point", "of", "view,", "the", "domain", "of", "inflectional", "morphology", "is", "a", "rather", "well-explored", "area,", "in", "which", "most", "efforts", "are", "devoted", "to", "development", "rather", "than", "research.", "Techniques", "used", "are", "based", "on", "finite-state", "transducers", "as", "used", "originally", "in", "two-level", "morphology,", "cf.", "Sproat (1992)", "for", "an", "overview.", "Research", "concentrates", "to", "a", "large", "extent", "on", "complicated", "phenomena", "such", "as", "Arabic", "nonlinear", "morphology.", "10", "Transferring", "the", "finite-state", "approach", "from", "inflection", "to", "word", "formation", "does", "not", "by", "itself", "cause", "many", "additional", "problems,", "but", "it", "does", "exacerbate", "a", "number", "of", "well-known", "problems", "of", "finite-state", "mechanisms:"], "cited_papers": [{"title": "Morphology and Computation", "year": "1992", "authors": ["Richard Sproat"]}], "target_citation_location": 41, "citation_locations": [41], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "155fb05a-0c93-4a0d-adb3-22bc696201c8", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["In", "Peru,", "before", "NMT,", "there", "were", "studies", "in", "rulebased", "MT,", "based", "on", "the", "Apertium", "platform", "(Forcada et al., 2011),", "for", "Quechua", "Eastern", "Apurimac", "(qve)", "and", "Quechua", "Cuzco", "(quz)", "(Cavero and Madariaga, 2007).", "Furthermore,", "Ortega and Pillaipakkamnatt (2018)", "improved", "alignments", "for", "quz", "by", "using", "an", "agglutinative", "language", "as", "Finnish", "as", "a", "pivot.", "Apart", "from", "the", "Quechua", "variants,", "only", "Aymara", "(Coler and Homola, 2014)", "and", "Shipibo-Konibo", "(Galarreta et al., 2017)", "have", "been", "addressed", "with", "rule-based", "and", "statistical", "MT,", "respectively.", "Ortega et al. (2020b)", "for", "Southern", "Quechua,", "and", "G\u00f3mez", "Montoya et al. (2019)", "for", "Shipibo-Konibo,", "are", "the", "only", "studies", "that", "employed", "sequence-tosequence", "NMT", "models.", "They", "also", "performed", "transfer", "learning", "experiments", "with", "potentially", "related", "language", "pairs", "(e.g.", "Finnish", "or", "Turkish,", "which", "are", "agglutinative", "languages).", "However,", "as", "far", "as", "we", "know,", "this", "is", "the", "first", "study", "that", "trains", "a", "multilingual", "model", "for", "some", "language", "spoken", "in", "Peru.", "For", "related", "work", "on", "multilingual", "NMT,", "we", "refer", "the", "readers", "to", "the", "survey", "of", "Dabre et al. (2020)."], "cited_papers": [{"title": "Corpus creation and initial SMT experiments between Spanish and Shipibo-konibo", "year": "2017", "authors": ["Ana-Paula Galarreta", "Andr\u00e9s Melgar", "Arturo Oncevay"]}], "target_citation_location": 52, "citation_locations": [15, 25, 27, 49, 52, 62, 68, 135], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "15939aaa-3347-4f7d-bffb-c274a2df767c", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["We", "demonstrate", "our", "phonetic", "approach", "by", "training", "Named", "Entity", "Recognition", "(NER)", "models", "for", "Swahili", "[swh]", "3", "using", "various", "combinations", "of", "Swahili", "text", "data,", "Swahili", "audio", "data,", "Kinyarwanda", "[kin]", "text", "data,", "and", "Kinyarwanda", "audio", "data.", "These", "two", "languages", "both", "originate", "from", "from", "the", "same", "language", "family,", "Bantu,", "and", "are", "spoken", "by", "millions", "of", "people", "in", "Eastern", "Africa,", "often", "within", "the", "same", "country,", "resulting", "in", "some", "overlap", "in", "loan", "words,", "etc.", "4", "However,", "they", "are", "both", "considered", "low-resource", "languages.", "Kinyarwanda", "in", "particular,", "though", "spoken", "by", "approximately", "13-22", "million", "people", "5,", "has", "very", "little", "text", "data", "available", "in", "that", "language,", "with", "fewer", "than", "3,000", "articles", "on", "the", "Kinyarwanda-language", "Wikipedia,", "and", "Swahili", "comparatively", "ahead", "but", "still", "poorly", "resourced", "at", "approximately", "68,000", "articles,", "far", "less", "than", "many", "European", "languages.", "6,", "though", "some", "datasets", "have", "been", "created", "such", "as", "KINNEWS", "(Niyongabo et al., 2020).", "On", "the", "other", "hand,", "Kinyarwanda", "is", "uniquely", "placed", "as", "a", "language", "to", "leverage", "speech-based", "technologies,", "due", "to", "well-organized", "efforts", "7", "to", "collect", "voice", "data", "for", "that", "language.", "It", "is", "in", "fact", "one", "of", "the", "largest", "subsets", "available", "on", "the", "Common", "Voice", "Dataset", "(Ardila et al., 2019),", "with", "1,183", "hours", "of", "voice", "clips", "collected", "and", "validated.", "Choosing", "these", "two", "languages", "allowed", "us", "to", "test", "the", "use", "of", "the", "technique", "on", "legitimately", "low-resourced", "languages", "that", "could", "benefit", "from", "improved", "NLP", "technology,", "and", "which", "as", "part", "of", "the", "same", "family", "of", "languages", "5", "Sources", "vary:", "Ethnologue", "cites", "\"Total", "users", "in", "all", "countries:", "13,133,980\",", "but", "there", "are", "22", "million", "according", "to", "WorldData.info", "(https://www.worlddata.info/languages/kinyarwanda.php)."], "cited_papers": [{"title": "Common voice: A massivelymultilingual speech corpus", "year": "2019", "authors": ["Rosana Ardila", "Megan Branson", "Kelly Davis", "Michael Henretty", "Michael Kohler", "Josh Meyer", "Reuben Morais", "Lindsay Saunders", "Francis Tyers", "Gregor Weber"]}], "target_citation_location": 177, "citation_locations": [134, 177], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "15ee468b-068d-4575-9a5b-3ba33853b428", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["MMB", "believed", "30", "years", "ago", "that", "constructed", "entities", "such", "as", "dictionaries", "and", "thesauri", "(especially", "the", "latter)", "constituted", "real", "resources", "for", "computational", "language", "processing", "(Masterman, 1956 (Masterman, , 1959b)).", "That", "was", "at", "a", "time", "when", "any", "computational", "operations", "on", "such", "entities", "were", "often", "dismissed", "by", "those", "working", "in", "other", "areas", "of", "computational", "linguistics", "as", "low-grade", "concordance", "work.", "Betty", "May", "compacted", "the", "whole", "of", "Roget's", "thesaurus", "for", "MMB,", "from", "1,000", "'heads'", "to", "800,", "and", "had", "them", "cardpunched.", "That", "formed", "the", "basis", "for", "a", "range", "of", "experiments", "on", "Hollerith", "sorting", "machines", "which", "contributed", "to", "Karen", "Sparck", "Jones'", "seminal", "thesis", "work", "Synonymy", "and", "semantics", "classification", "(1964, 1986).", "MMB", "believed", "that", "thesauri", "such", "as", "Roget's", "were", "not", "just", "fallible", "human", "constructs", "but", "real", "resources", "with", "some", "mathematical", "structure", "that", "was", "also", "a", "guide", "to", "the", "structures", "which", "humans", "use", "to", "process", "language.", "She", "would", "often", "refer", "to", "'Roget's", "unconscious'", "by", "which", "she", "meant", "that", "the", "patterns", "of", "cross-references", "from", "word", "to", "word", "across", "the", "thesaurus", "had", "underlying", "generalisations", "and", "patterns."], "cited_papers": [{"title": null, "year": "1956", "authors": ["M Masterman", "unk Words"]}, {"title": "Classification, concept formation and language", "year": "1959", "authors": ["M Masterman"]}], "target_citation_location": 23, "citation_locations": [23, 97], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "15feb3c0-b1f8-4266-9edf-e422b9203b33", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["Prior", "to", "this", "shared", "task,", "some", "studies", "have", "created", "datasets", "for", "similar", "tasks", "(Yokoi et al., 2011, Schubotz et al., 2016, Alexeeva et al., 2020).", "However,", "one", "of", "them", "is", "created", "for", "publications", "written", "in", "Japanese", "(Yokoi et al., 2011),", "making", "it", "nearly", "impossible", "to", "transfer", "to", "English", "literature.", "While", "two", "other", "datasets", "(Schubotz et al., 2016, Alexeeva et al., 2020)", "only", "annotate", "small-scale", "golden", "datasets", "for", "evaluation", "purposes.", "As", "the", "result,", "no", "training", "data", "is", "available", "for", "training", "deep", "neural", "network", "models.", "In", "this", "shared", "task,", "we", "provide", "a", "large-scale", "dataset", "for", "English", "literature", "that", "we", "believe", "will", "provide", "enough", "supervision", "for", "the", "promising", "deep", "neural", "network-based", "models."], "cited_papers": [{"title": "Contextual analysis of mathematical expressions for advanced mathematical search", "year": "2011", "authors": ["Keisuke Yokoi", "Minh-Quoc Nghiem"]}], "target_citation_location": 25, "citation_locations": [13, 25, 39], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "164b3859-e683-4b0a-a2c0-7b1cc67d9281", "citing_paper": {"title": "Corpora and Machine Translation", "year": 1993, "authors": ["Yorick Wilks"]}, "text": ["There", "remain,", "too,", "crucial", "classes", "of", "cases", "that", "seem", "to", "need", "symbolic", "inference:", "an", "old,", "self-serving,", "one", "will", "do", "such", "as", "\"The", "soldiers", "fired", "at", "the", "women", "and", "I", "saw", "several", "fall\"", "(Wilks 1975)."], "cited_papers": [{"title": "A preferential pattern-matching semantics for natural language understanding", "year": "1975", "authors": ["Y Wilks"]}], "target_citation_location": 32, "citation_locations": [32], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "165dd43a-f4c3-4940-a4bd-ddd39c037009", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["The", "organizers", "of", "IWSLT", "provide", "several", "task", "specific", "corpora", "that", "can", "be", "used", "to", "train", "and", "optimize", "the", "translation", "system.", "The", "characteristics", "of", "these", "corpora", "are", "summarized", "in", "Table", "1.", "It", "is", "known", "that", "the", "choice", "of", "the", "development", "and", "internal", "test", "data", "may", "have", "an", "important", "impact", "on", "the", "quality", "of", "the", "system,", "in", "particular", "when", "the", "available", "corpora", "have", "different", "characteristics", "(for", "instance", "what", "concerns", "the", "average", "sentence", "length).", "We", "decided", "to", "develop.", "Therefore,", "we", "decided", "to", "add", "the", "last", "two", "corpora", "to", "the", "training", "material", "after", "optimizing", "the", "system", "and", "to", "retrain", "the", "full", "system", "keeping", "all", "settings", "unmodified.", "This", "idea", "was", "already", "successfully", "proposed", "in", "previous", "IWSLT", "evaluations", "[12]."], "cited_papers": [{"title": "The RWTH statistical machine translation system for the IWSLT 2006 evaluation", "year": "2007", "authors": ["A Mauser", "R Zens", "E Matusov", "S Hasan", "H Ney"]}], "target_citation_location": 112, "citation_locations": [112], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]]}
{"id": "16d50365-841a-4bc8-9391-187a3ebb45d2", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["A", "dataset", "for", "classification", "tasks", "is", "useful", "only", "if", "the", "accuracy", "of", "its", "annotations", "can", "be", "confirmed.", "To", "this", "end", "we", "use", "BERT", "to", "evaluate", "our", "annotations", "as", "it", "has", "consistently", "outperformed", "other", "models", "in", "recent", "classification", "tasks", "(see", "e.g", "Zampieri et al. (2020)", "),", "and", "Support", "Vector", "Machines", "for", "its", "simplicity", "and", "effectiveness.", "We", "use", "a", "stratified", "split", "of", "70:20:10", "for", "training,", "dev,", "and", "test", "data."], "cited_papers": [{"title": "Zeses Pitenis, and C \u00b8agr\u0131 C \u00b8\u00f6ltekin. 2020. SemEval-2020 Task 12: Multilingual Offensive Language Identification in Social Media", "year": "2020", "authors": ["Marcos Zampieri", "Preslav Nakov", "Sara Rosenthal", "Pepa Atanasova", "Georgi Karadzhov", "Hamdy Mubarak", "Leon Derczynski"]}], "target_citation_location": 40, "citation_locations": [40], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "171a7909-05ca-4ac8-8908-7620837b8a97", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Prevailing", "stereotypes.", "Previous", "research", "has", "shown", "that", "prevailing", "stereotypes", "often", "form", "the", "basis", "and", "justification", "of", "abuse.", "For", "example,", "many", "twitter", "accounts", "were", "open", "about", "their", "anger", "and", "hatred", "for", "Muslims", "in", "the", "wake", "of", "the", "Rochdale", "scandal", "that", "involved", "several", "British-Asian", "men", "getting", "convicted", "for", "child", "grooming", "(Awan, 2014).", "Stereotypes", "are", "not", "only", "explicit", "but", "implicit", "too", "(Hinton, 2017),", "which", "often", "show", "up", "as", "implicit", "and", "subtle", "abuse", "in", "the", "form", "of", "sarcasm,", "racist", "jokes,", "or", "unnecessary", "associations.", "While", "explicit", "stereotypes", "are", "consciously", "endorsed,", "and", "may", "be", "controllable,", "implicit", "stereotypes", "are", "thought", "to", "be", "shaped", "by", "experience", "and", "based", "on", "learned", "associations", "(Byrd, 2019).", "User", "and", "community", "information", "plays", "an", "important", "role", "in", "the", "identification", "of", "such", "stereotypes.", "For", "example,", "if", "the", "location", "of", "users", "is", "available", "alongside", "linguistic", "features", "of", "the", "comments", "they", "post,", "one", "can", "quickly", "discover", "the", "presence", "(or", "absence)", "of", "correlations", "between", "specific", "regions", "and", "specific", "kinds", "of", "abuse.", "Moreover,", "shared", "stereotypes", "may", "unconsciously", "bring", "users", "together", "on", "online", "platforms", "to", "form", "communities.", "Hence,", "having", "linguistic", "information", "of", "a", "community,", "such", "as", "the", "topics", "users", "in", "that", "community", "interact", "with", "and", "the", "stance", "of", "users", "towards", "different", "pieces", "of", "news,", "can", "help", "capture", "the", "prevailing", "stereotypes", "that", "form", "the", "motivation", "behind", "abusive", "comments", "from", "such", "users."], "cited_papers": [{"title": "Islamophobia and twitter: A typology of online hate against muslims on social media", "year": "2014", "authors": ["I Awan"]}], "target_citation_location": 48, "citation_locations": [48, 57, 101], "citation_type": "single", "annotations": [[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "175538a3-b824-4a11-8608-cc7b82bb193d", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["Linguistic", "Embedding", "For", "the", "language", "D,", "we", "first", "tokenize", "the", "sentence", "into", "a", "sequence", "of", "word", "tokens", "using", "WordPiece", "(Wu et al., 2016),", "then", "encode", "them", "into", "word", "embeddings", "W", "=", "{w", "j}", "T", "j=1", "where", "w", "j", "\u2208", "R", "dw", "is", "the", "feature", "vector.", "Similarly,", "an", "index", "position", "(Devlin et al., 2018)", "embedding", "is", "supplemented", "to", "each", "word", "embedding."], "cited_papers": [{"title": "Google's neural machine translation system", "year": "2016", "authors": ["Yonghui Wu", "Mike Schuster", "Zhifeng Chen", "V Quoc", "Mohammad Le", "Wolfgang Norouzi", "Maxim Macherey", "Yuan Krikun", "Qin Cao", "Klaus Gao", "unk Macherey"]}], "target_citation_location": 19, "citation_locations": [19, 46], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "17e76819-95a3-4afc-a60c-5b02acadec0e", "citing_paper": {"title": "Can Semantic Role Labeling Improve SMT?", "year": 2009, "authors": ["Dekai Wu", "Pascale Fung"]}, "text": ["We", "use", "the", "Chinese", "sentences", "as", "system", "input", "and", "their", "corresponding", "English", "translations", "as", "the", "reference", "translations.", "We", "use", "the", "open", "source", "statistical", "machine", "translation", "decoder", "Moses", "(?)", "for", "the", "experiments,", "translating", "the", "PropBank", "Chinese", "sentences", "into", "English", "with", "the", "same", "model", "trained", "for", "our", "participation", "in", "the", "IWSLT", "2007", "evaluation", "campaign", "(Shen et al., 2007)", ".The", "English", "translations", "generated", "by", "the", "decoder", "are", "the", "system", "output.", "Based", "on", "the", "system", "input", "and", "the", "reference", "We", "first", "randomly", "select", "50", "bi-sentences,", "without", "any", "constraint", "on", "the", "translation", "accuracy", "of", "the", "predicate", "verbs,", "to", "form", "the", "first", "observation", "data", "set", "(data", "set", "A)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 52, "citation_locations": [52], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "18048577-d84c-4db3-a351-c956d072c53c", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["The", "backbone", "of", "our", "PyTorch", "(Paszke et al., 2019)", "implementation", "is", "the", "Transformer", "and", "WordpieceTokenizer", "classes", "offered", "by", "Hugging", "Face", "(Wolf et al., 2019).", "We", "use", "pre-trained", "BERT", "models", "provided", "on", "huggingface.co:", "bert-base-cased,", "dbmz/bert-base-german-cased,", "dbmz/bert-base-italian-cased,", "and", "Geotrend/BERT-base-nl-cased", "(Abdaoui et al., 2020),", "keeping", "their", "default", "configuration.", "The", "only", "hyperparameters", "we", "choose", "ourselves", "are", "the", "batch", "size", "(24),", "the", "learning", "rate,", "and", "the", "number", "of", "epochs.", "We", "used", "the", "Adam", "optimizer", "to", "train", "all", "the", "parameters", "in", "our", "model", "including", "the", "pretrained", "BERT.", "To", "ensure", "stability", "and", "avoid", "overfitting,", "we", "used", "a", "linear", "scheduler", "with", "no", "warm-up", "step,", "which", "gradually", "reduces", "the", "learning", "rate", "from", "0.0015", "to", "0", "for", "each", "training", "iteration.", "During", "preliminary", "experiments", "on", "the", "development", "set,", "we", "found", "that", "training", "loss", "barely", "changed", "after", "five", "epochs."], "cited_papers": [{"title": "Pytorch: An imperative style, high-performance deep learning library", "year": "2019", "authors": ["Adam Paszke", "Sam Gross", "Francisco Massa", "Adam Lerer", "James Bradbury", "Gregory Chanan", "Trevor Killeen", "Zeming Lin", "Natalia Gimelshein", "Luca Antiga", "Alban Desmaison", "Andreas Kopf", "Edward Yang", "Zachary Devito", "Martin Raison", "Alykhan Tejani", "Sasank Chilamkurthy", "Benoit Steiner", "Lu Fang", "Junjie Bai", "Soumith Chintala"]}], "target_citation_location": 5, "citation_locations": [5, 17, 31], "citation_type": "single", "annotations": [[2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "182f4102-6abc-49aa-8deb-db6ebb7dbe3c", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["Since", "the", "removal", "of", "diacritics", "also", "clearly", "leads", "to", "a", "potential", "ambiguity", "as", "explained", "in", "Section", "(2.1)", "there", "has", "been", "some", "work", "on", "automatic", "diacritization", "of", "partially", "diacritized", "or", "undiacritized", "text", "(Mubarak et al., 2019a, Mubarak et al., 2019b, Abdelali et al., 2016)."], "cited_papers": [{"title": "A system for diacritizing four varieties of arabic", "year": "2019", "authors": ["Hamdy Mubarak", "Ahmed Abdelali", "Kareem Darwish", "Mohamed Eldesouki", "Younes Samih", "Hassan Sajjad"]}, {"title": "Farasa: A fast and furious segmenter for arabic", "year": "2016", "authors": ["Ahmed Abdelali", "Kareem Darwish", "Nadir Durrani", "Hamdy Mubarak"]}, {"title": "Highly effective arabic diacritization using sequence to sequence modeling", "year": "2019", "authors": ["Hamdy Mubarak", "Ahmed Abdelali", "Hassan Sajjad", "Younes Samih", "Kareem Darwish"]}], "target_citation_location": 31, "citation_locations": [31], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "186beee9-b17d-4dbc-aed1-a3bb6178283b", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["In", "the", "last", "years,", "there", "is", "increasing", "interest", "in", "the", "interaction", "between", "rule-based", "and", "statistical", "machine", "translation.", "A", "popular", "and", "successful", "idea", "is", "statistical", "post", "editing", "[16, 17].", "The", "principle", "idea", "is", "to", "train", "an", "SMT", "system", "to", "correct", "the", "outputs", "of", "a", "rule-based", "translation", "system."], "cited_papers": [{"title": "Rule-based translation with statistical phrase-based post-editing", "year": "2007", "authors": ["M Simard", "N Ueffing", "P Isabelle", "R Kuhn"]}, {"title": "Statistical post-editing on SYSTRAN's rule-based translation system", "year": "2007", "authors": ["L Dugast", "J Senellart", "P Koehn"]}], "target_citation_location": 26, "citation_locations": [26], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "186ee4a3-16c0-40c4-b697-5664050234e0", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["Data", "acquisition", "in", "DeKo", "was", "done", "on", "the", "basis", "of", "a", "corpus:", "we", "used", "German", "newspaper", "corpora,", "which", "were", "tagged", "with", "the", "TreeTagger", "(Schmid 1994)", "and", "lemmatized", "with", "DMOR", "(Schiller 1996),", "for", "searching", "and", "pre-processing", "we", "used", "the", "Corpus", "Query", "Processor", "(Schiller 1996)", "and", "a", "number", "of", "Perl", "scripts.", "In", "acquiring", "and", "systematizing", "the", "data", "we", "made", "a", "distinction", "between", "word", "formation", "involving", "selecting", "elements", "(roughly", "derivation)", "and", "word", "formation", "involving", "only", "categories", "(compounding).", "For", "expository", "purposes", "we", "concentrate", "on", "a", "derivation", "process", "here", "and", "only", "briefly", "describe", "a", "compounding", "process", "below."], "cited_papers": [{"title": "Probabilistic part-of-speech tagging using decision trees", "year": "1994", "authors": ["Helmut Schmid"]}], "target_citation_location": 23, "citation_locations": [23, 28, 39], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "187c22eb-00e5-42d7-af86-7de8fb679b7f", "citing_paper": {"title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables", "year": 2022, "authors": ["Nan Hu", "Zirui Wu", "Yuxuan Lai", "Xiao Liu", "Yansong Feng"]}, "text": ["The", "task", "of", "fact", "extraction", "and", "verification", "aims", "to", "extract", "evidence", "and", "verify", "a", "given", "claim.", "Previous", "efforts", "focus", "on", "dealing", "with", "text", "format", "evidence", "from", "unstructured", "documents", "(Nie et al., 2019, Zhong et al., 2020, Kruengkrai et al., 2021)", "or", "evidence", "from", "a", "single", "given", "table", "(Chen et al., 2020, Yang et al., 2020, Eisenschlos et al., 2020).", "Recently,", "Aly et al. (2021)", "propose", "a", "new", "realistic", "setting,", "FEVEROUS,", "i.e.,", "fact", "extraction", "and", "verification", "over", "unstructured", "and", "structured", "information.", "In", "FEVEROUS,", "models", "should", "not", "only", "extract", "evidence", "sentences/table", "cells", "from", "millions", "of", "passages,", "but", "also", "combine", "the", "evidence", "in", "different", "formats", "to", "verify", "a", "given", "claim."], "cited_papers": [{"title": "Feverous: Fact extraction and verification over unstructured and structured information", "year": "2021", "authors": ["Rami Aly", "Zhijiang Guo", "M Schlichtkrull", "James Thorne"]}], "target_citation_location": 38, "citation_locations": [28, 36, 38], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "18ec840a-47c6-47fd-b385-576cc8e93bab", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["The", "process", "of", "breaking", "down", "an", "input", "abstract", "syntax", "tree", "(AST)", "into", "component", "pattern", "trees,", "in", "order", "to", "generate", "an", "instruction", "set,", "is", "a", "standard", "one", "in", "compilers.", "The", "standard", "technique", "involves", "a", "bottom-up", "rewriting", "system", "(BURS),", "with", "the", "optimal", "instruction", "set", "constructed", "by", "the", "dynamic", "programming", "algorithm", "of", "Proebsting (1995),", "see", "for", "example", "Grune et al. (2000).", "Because", "of", "the", "natureA", "(\u00ac\u00bd", "\u2022\u00ab\u00bd", "\u00bd", "\u00ac", "\u00bd", "\u00ab", "\u00bd,", "\u00ab", "\u00bf)", "A", "(\u00ac\u00bd", "\u2022\u00ab\u00bd", "\u00bd", "\u00ac", "\u00bd", "\u00ab", "\u00bd,", "\u00ab", "\u00bf,", "\u00ab)", "A", "(\u00ab\u00bd", "\u00bd,\u00ab,", "\u00ab", "\u00bd)", "a", "b", "b", "b", "c", "\u00ab", "\u00bd", "\u00b4", "\u00b5:", "S", "A", "a", "b", "c", "\u00ab", "\u00b4", "\u00b5:", "A", "NA", "A", "a", "b", "b", "\u00ab", "\u00be", "\u00b4", "\u00bf\u00b5:", "S", "A", "c", "\u00ac", "\u00bd", "\u00b4", "\u00bf\u00b5:", "A", "A", "\u00a3", "NA", "b", "\u00ab", "\u00bf", "\u00b4", "\u00bf\u00b5:", "A", "A", "b", "\u00ab", "\u00b4", "\u00bf\u00b5:", "A", "NA", "a", "bFigure", "7:", "Abstract", "Syntax", "Tree", "and", "pattern", "trees", "of", "programming", "languages,", "the", "sort", "of", "pattern", "trees", "that", "are", "allowed", "are", "only", "groupings", "of", "contiguous", "nodes,", "in", "effect,", "tree", "parsing", "is", "allowed", "with", "a", "tree", "grammar", "consisting", "of", "trees", "of", "possibly", "multiple", "levels", "and", "allowing", "only", "concatenation:", "this", "is", "equivalent", "to", "a", "TSG.", "Consider", "an", "AST", "in", "Figure", "7", "(ignoring", "the", "annotations", "on", "the", "nodes,", "in", "parentheses),", "and", "take", "for", "pattern", "trees", "only", "those", "initial", "trees", "of", "Figure", "7", "(\u00ab", "\u00bd", "\u00ab", ").", "It", "can", "be", "seen", "that", "the", "AST", "can", "be", "decomposed", "in", "several", "ways,", "for", "example", "by", "the", "set", "of", "pattern", "trees", "\u00ab", "\u00be", "\u00ab", "\u00bf", "\u00ab", "\u00bf", "\u00ab", "or", "the", "set", "\u00ab", "\u00be", "\u00ab", "\u00bf", "\u00ab.", "If", "the", "numbers", "in", "parentheses", "after", "the", "labels", "()", "are", "considered", "as", "costs,", "an", "optimal", "decomposition", "can", "be", "determined", "(here,", "\u00ab", "\u00be", "\u00ab", "\u00bf", "\u00ab", ").", "Now", "in", "Section", "4.2", "we", "develop", "an", "algorithm", "based", "on", "this", "which", "allows", "an", "input", "AST", "(for", "us,", "a", "derivation", "or", "dependency", "structure,", "for", "example)", "to", "be", "broken", "into", "component", "non-contiguous", "'trees'", "efficiently.", "From", "a", "theoretical", "point", "of", "view", "this", "is", "interesting,", "as", "the", "expectation", "would", "be", "that", "some", "more", "complex", "mechanism", "would", "be", "necessary,", "in", "much", "the", "same", "way", "that", "allowing", "stretching", "of", "paired", "characters", "in", "strings", "(say,", "in", "the", "language", "of", "nested", "strings", "\u00d2", "\u00d2", "\u00d2", "\u00bc,", "where", "the", "th", "is", "matched", "with", "the", "\u00b4\u00d2", "\u00bd", "\u00b5", "th)", "cannot", "be", "performed", "by", "a", "finite", "state", "automaton", "but", "requires", "a", "pushdown", "automaton", "through", "the", "addition", "of", "a", "stack,", "here,", "it", "might", "be", "expected", "that", "a", "stack", "is", "similarly", "necessary", "to", "keep", "track", "of", "the", "unbounded", "elements."], "cited_papers": [{"title": "BURS automata generation", "year": "1995", "authors": ["T Proebsting"]}], "target_citation_location": 49, "citation_locations": [49, 53], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1902a247-750a-45de-b0c7-6108890e3149", "citing_paper": {"title": "Diverse dialogue generation with context dependent dynamic loss function", "year": 2020, "authors": ["Ayaka Ueyama", "Yoshinobu Kano"]}, "text": ["The", "SCE", "loss,", "which", "is", "often", "used", "to", "train", "a", "sequence-to-sequence", "(Seq2Seq)", "model", "(Sutskever et al., 2014),", "is", "expressed", "as", "\ud835\udc3f", "\ud835\udc46\ud835\udc36\ud835\udc38", "=", "\u2212\ud835\udc59\ud835\udc5c\ud835\udc54{\ud835\udc60\ud835\udc5c\ud835\udc53\ud835\udc61\ud835\udc5a\ud835\udc4e\ud835\udc65", "\ud835\udc50", "},", "where\ud835\udc60\ud835\udc5c\ud835\udc53\ud835\udc61\ud835\udc5a\ud835\udc4e\ud835\udc65", "\ud835\udc50", "=", "\ud835\udc52", "\ud835\udc51", "\ud835\udc50", "\u2211", "\ud835\udc52", "\ud835\udc51", "\ud835\udc58", "|\ud835\udc49|", "\ud835\udc58.", "Therein,", "\ud835\udc49", "represents", "the", "lexicon,", "\ud835\udc51", "\ud835\udc58", "denotes", "the", "\ud835\udc58-th", "element", "of", "the", "output", "\ud835\udc51", "\u2208", "\u211d", "|\ud835\udc49|.", "Nakamura et al. (2018)", "defined", "Inverse", "Token", "Frequency", "(ITF)", "loss", "as", "shown", "below."], "cited_papers": [{"title": "Another diversity promoting objective function for neural dialogue generation", "year": "2018", "authors": ["Ryo Nakamura", "Katsuhito Sudoh", "Koichiro Yoshino", "Satoshi Nakamura"]}], "target_citation_location": 53, "citation_locations": [13, 53], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3]]}
{"id": "19382018-a2fd-48e3-b36f-13e9d9199fcf", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Across", "the", "three", "categories", "of", "methods,", "we", "note", "that", "the", "general", "setup", "is", "to", "create", "representations,", "called", "profiles,", "for", "users", "or", "communities", "and", "utilize", "them", "alongside", "linguistic", "features.", "In", "social", "feature", "engineering", "based", "methods,", "these", "profiles", "are", "manually", "constructed", "vectors", "of", "features", "that", "capture", "the", "relevant", "traits,", "such", "as", "age", "in", "the", "case", "of", "cyber-bullying", "and", "gender", "in", "the", "case", "of", "sexism.", "In", "user", "embeddings", "and", "social", "graph", "based", "methods,", "the", "profiles", "are", "instead", "generated", "by", "neural", "network", "architectures", "to", "capture", "the", "linguistic", "behavior", "or", "community", "traits", "of", "users.", "That", "said,", "across", "all", "three", "categories,", "the", "profiles", "essentially", "provide", "a", "wider", "context", "to", "the", "comment", "being", "classified", "for", "abuse.", "For", "example,", "having", "the", "gender", "of", "the", "user", "who", "produces", "a", "comment", "such", "as", "\"Had", "an", "accident,", "women", "can't", "drive", "it", "seems!\"", "can", "help", "to", "classify", "the", "comment", "as", "sexist", "or", "not", "by", "differentiating", "benign", "self-deprecating", "humor", "from", "intent", "to", "degrade.", "The", "context", "that", "the", "profiles", "encode", "increases", "as", "we", "go", "from", "social", "feature", "engineering", "based", "methods", "to", "user", "embeddings", "based", "methods", "and", "further", "to", "social", "graph", "based", "methods.", "This", "is", "also", "evident", "from", "the", "magnitude", "of", "gains", "that", "the", "profiles", "provide", "on", "top", "of", "linguistic", "features.", "For", "example,", "the", "gender", "feature", "only", "increases", "the", "F", "1", "from", "73.89%", "to", "73.93%", "over", "character", "n-gram", "counts", "on", "the", "dataset", "by", "Waseem and Hovy (2016),", "while", "the", "social", "graph", "based", "method", "of", "Mishra et al. (2019)", "increases", "the", "F", "1", "to", "above", "80%.", "The", "example", "aside,", "it", "makes", "intuitive", "sense", "that", "profiles", "from", "social", "graph", "based", "methods", "encode", "the", "most", "amount", "of", "context,", "since", "these", "profiles", "are", "able", "to", "capture", "the", "various", "phenomena", "that", "occur", "in", "social", "networks,", "the", "most", "prominent", "ones", "of", "which", "are:"], "cited_papers": [{"title": "Abusive language detection with graph convolutional networks", "year": "2019", "authors": ["Pushkar Mishra", "Marco Tredici", "Helen Yannakoudakis", "Ekaterina Shutova"]}], "target_citation_location": 226, "citation_locations": [218, 226], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "193db12c-e687-499f-9de0-83449c1a483d", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["Results.", "For", "the", "SVM,", "the", "3-1", "pretraining", "without", "data", "augmentation", "resulted", "in", "the", "highest", "dev", "set", "accuracy", "(32.03%),", "though", "accuracy", "was", "only", "slightly", "better", "than", "for", "direct", "single-trial", "training", "(31.93%).", "For", "the", "Transformer,", "the", "3-1", "pretraining", "scheme", "with", "250k", "data", "augmentation", "obtained", "the", "highest", "single-trial", "decoding", "accuracy", "(39.41%)", "on", "the", "dev", "set.", "Indeed,", "Wilcoxon", "signed-rank", "test", "(Pereira et al., 2009)", "confirmed", "that", "the", "best", "dev", "set", "Transformer", "performed", "significantly", "better", "on", "the", "test", "set", "after", "3-1", "pretraining", "than", "after", "direct", "single-trial", "training", "(p", "&lt,", "0.01)."], "cited_papers": [{"title": "Machine learning classifiers and fMRI: A tutorial overview", "year": "2009", "authors": ["Francisco Pereira", "Tom Mitchell", "Matthew Botvinick"]}], "target_citation_location": 56, "citation_locations": [56], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "1951dc93-f7c0-446e-8515-967145633a58", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["Second,", "we", "propose", "to", "directly", "use", "coreference", "resolution", "datasets", "for", "training", "MRC", "models", "to", "improve", "their", "coreference", "reasoning.", "We", "automatically", "create", "a", "question", "whose", "answer", "is", "a", "coreferring", "expression", "m", "1", "using", "the", "BART", "model", "(Lewis et al., 2020).", "We", "then", "consider", "this", "question,", "m", "1", "'s", "antecedent,", "and", "the", "corresponding", "document", "as", "a", "new", "(question, answer, context)", "tuple.", "This", "data", "helps", "the", "model", "learning", "to", "resolve", "the", "coreference", "relation", "between", "m", "1", "and", "its", "antecedent", "to", "answer", "the", "question.", "We", "show", "that", "incorporating", "these", "additional", "data", "improves", "the", "performance", "of", "the", "state-of-the-art", "models", "on", "our", "new", "evaluation", "set."], "cited_papers": [{"title": "BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension", "year": "2020", "authors": ["Mike Lewis", "Yinhan Liu", "Naman Goyal ", " Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer"]}], "target_citation_location": 35, "citation_locations": [35, 52], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "19b3727e-4dd0-412a-bdaf-7edd2fab4b56", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["To", "deal", "with", "the", "absence", "of", "action", "annotations,", "latent", "action", "learning", "has", "been", "introduced", "(Zhao et al., 2018, Yarats and Lewis, 2018).", "System", "utterances", "are", "represented", "as", "low-dimensional", "latent", "variables", "by", "an", "auto-encoding", "task", "(Zhao et al., 2019),", "and", "utterances", "with", "the", "same", "representations", "are", "considered", "to", "convey", "similar", "meanings.", "Such", "action", "representations", "might", "be", "prone", "to", "overdependence", "on", "the", "training", "data,", "which", "restricts", "the", "model", "generalization", "capability,", "especially", "when", "multiple", "domains", "are", "considered.", "This", "is", "because,", "without", "explicit", "supervision,", "the", "desired", "property", "of", "capturing", "the", "intentions", "of", "system", "utterances", "in", "the", "latent", "space", "cannot", "be", "enforced", "(Locatello et al., 2019),", "which", "in", "turn", "is", "due", "to", "the", "implicit", "nature", "of", "latent", "variables.", "For", "example,", "variational", "auto-encoder", "(VAE),", "which", "is", "often", "used", "for", "latent", "action", "learning,", "tends", "to", "produce", "a", "balanced", "distribution", "over", "the", "latent", "variables", "(Zhao et al., 2018),", "while", "the", "true", "distribution", "of", "system", "actions", "is", "highly", "imbalanced", "(Budzianowski et al., 2018).", "The", "resulting", "misaligned", "action", "representations", "would", "confuse", "the", "model", "of", "both", "steps", "and", "degenerate", "the", "sample", "efficiency", "in", "training."], "cited_papers": [{"title": "Rethinking action spaces for reinforcement learning in end-to-end dialog agents with latent variable models", "year": "2019", "authors": ["Tiancheng Zhao", "Kaige Xie", "Maxine Eskenazi"]}], "target_citation_location": 27, "citation_locations": [14, 27, 87, 123, 134], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "19bbf577-3280-4bdb-89c7-ceed7f892fc4", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["To", "address", "the", "above", "issues,", "we", "propose", "to", "learn", "natural", "language", "actions", "that", "represent", "system", "utterances", "as", "a", "span", "of", "words,", "which", "explicitly", "reveal", "the", "underlying", "intentions.", "Natural", "language", "provides", "unique", "compositional", "structure", "while", "retaining", "the", "representation", "flexibility.", "These", "properties", "promote", "model", "generalization", "and", "thus", "make", "natural", "language", "a", "flexible", "representation", "for", "capturing", "characteristics", "with", "minimal", "assumptions", "(Jiang et al., 2019).", "Motivated", "by", "these", "advantages,", "we", "learn", "natural", "language", "actions", "by", "identifying", "salient", "words", "of", "system", "utterances.", "Salient", "refers", "to", "indicative", "for", "a", "prediction", "task", "(e.g.,", "sentiment", "analysis)", "that", "takes", "as", "input", "the", "original", "utterance.", "The", "main", "rationale", "is", "that", "the", "principal", "information", "that", "the", "task", "concerns", "can", "be", "preserved", "by", "just", "the", "salient", "words.", "For", "example,", "the", "sentiment", "of", "sentence", "\"The", "movie", "starts", "out", "as", "competent", "but", "turn", "bland\"", "can", "be", "revealed", "by", "the", "word", "\"bland\"", "when", "it", "is", "identified", "salient", "by", "considering", "the", "complete", "context.", "In", "our", "scenarios,", "we", "consider", "measuring", "word", "saliency", "in", "terms", "of", "state", "transitions.", "This", "is", "because", "state", "transitions", "reflect", "how", "the", "intentions", "of", "a", "system", "utterance", "influence", "the", "dialogue", "progress,", "and", "action", "representations", "that", "capture", "such", "influences", "can", "well", "reveal", "the", "intentions", "(Chandak et al., 2019, Tennenholtz and Mannor, 2019, Huang et al., 2020b).", "By", "considering", "salient", "words", "for", "state", "tracking", "tasks", "as", "actions,", "we", "obtain", "action", "representations", "that", "enjoy", "the", "merits", "of", "natural", "language", "and", "indeed", "capture", "the", "characteristics", "of", "interest,", "i.e.,", "intentions", "of", "system", "utterances."], "cited_papers": [{"title": "Language as an abstraction for hierarchical deep reinforcement learning", "year": "2019", "authors": ["Yiding Jiang", "Shixiang Gu", "Kevin Murphy", "Chelsea Finn"]}], "target_citation_location": 57, "citation_locations": [57, 186], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "19ebd7e7-e109-4438-868c-40e52ad2b8b4", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["of", "features", "not", "incorporated", "into", "the", "backbone", "is", "performed", "at", "parse", "time", "in", "conjunction", "with", "reduce", "operations.", "Unification", "failure", "results", "in", "the", "associated", "derivation", "being", "assigned", "a", "probability", "of", "zero.", "Probabilities", "are", "assigned", "to", "transitions", "in", "the", "LALR(", "1)", "action", "table", "via", "a", "proc\ufffd", "of", "supervised", "training", "based", "on", "computing", "the", "frequency", "with", "which", "transitions", "are", "traversed", "in", "a", "corpus", "of", "parse", "histories.", "The", "result", "is", "a", "probabilistic", "parser", "which,", "unlike", "a", "PCFG,", "is", "capable", "of", "probabilistically", "discriminating", "derivations", "which", "differ", "only", "in", "terms", "of", "order", "of", "application", "of", "the", "same", "set", "of", "CF", "backbone", "rules,", "due", "to", "the", "parse", "context", "defined", "by", "the", "LR", "table.", "Experiments", "with", "this", "s", "ys", "tem", "revealed", "three", "major", "problems", "which", "our", "current", "research", "is", "addressing.", "Firstly,", "although", "the", "system", "is", "able", "to", "rank", "parses", "with", "a", "75%", "chance", "that", "the", "correct", "anal", "ys", "is", "will", "be", "the", "most", "highly", "ranked,", "further", "improvement", "will", "require", "a", "'lexicalised'", "system", "in", "which", "(minimally)", "probabilities", "are", "associated", "with", "alternative", "subcategorisation", "possibilities", "of", "individual", "lexical", "items.", "Currently,", "the", "relative", "frequency", "of", "subcategorisation", "possibilities", "for", "individual", "lexical", "items", "is", "not", "recorded", "in", "wide-coverage", "lexicons,", "such", "as", "ANLT", "or", "COMLEX", "(Grishman et al., 1994).", "Secondly,", "removal", "of", "punctuation", "from", "the", "input", "(after", "segmentation", "int.o", "text", "sentences)", "worsens", "performance", "as", "punctuation", "both", "reduces", "syntactic", "ambiguity", "(Jones, 1994) and signals non-syntactic (discourse)", "relations", "between", "text", "units", "(Nun berg, 1990).", "Thirdly,", "the", "largest", "source", "of", "error", "on", "unseen", "input", "is", "the", "omission", "of", "appropriate", "subcategorisation", "values", "for", "lexical", "items", "(mostly", "verbs),", "preventing", "the", "system", "from", "finding", "the", "correct", "analysis.", "The", "current", "coverage", "of", "this", "system", "on", "a", "general", "corpus", "(e.g.", "Brown", "or", "LOB)", "is", "estimated", "to", "be", "around", "20%", "by", "Briscoe (1994).", "We", "have", "developed", "a", "variant", "probabilistic", "LR", "parser", "which", "does", "not", "rely", "on", "subcategorisation", "and", "uses", "punctuation", "to", "reduce", "ambiguity.", "The", "anal", "ys", "es", "produced", "by", "this", "parser", "could", "be", "utilised", "for", "phrase-finding", "applications,", "recovery", "of", "subcategorisation", "frames,", "and", "other", "'intermediate'", "level", "parsing", "problems."], "cited_papers": [{"title": "Prospects for practical parsing of unrestricted text: robust statistical parsing techniques", "year": "1994", "authors": ["E Briscoe"]}], "target_citation_location": 267, "citation_locations": [190, 211, 216, 267], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1a23249c-0aa3-465b-abce-3f2e916d145f", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Effect", "of", "hyperparameter", "tuning", "A", "generally", "unstated", "assumption", "is", "that", "pre-trained", "linguistic", "models", "are", "under-optimized", "and", "that", "practices", "commonly", "adopted", "for", "the", "fine-tuning", "stage", "can", "be", "detrimental", "to", "performance", "(Zhang et al., 2021, Mosbach et al., 2021).", "This", "is", "quite", "apparent", "in", "all", "settings,", "with", "better", "gains", "through", "hyperparameter", "optimization", "stages.", "Fine-tuning", "CamemBERT", "large", "on", "the", "French", "dataset", "yields", "90.2", "/", "75.5", "F1", "/", "EM", "on", "the", "FQuAD", "dev", "set.", "By", "means", "of", "comparison,", "CamemBERT", "large", "scores", "were", "81.2", "/", "55.9", "F1", "/", "EM", "on", "the", "same", "set", "with", "no", "hyperparameter", "tuning."], "cited_papers": [{"title": "Revisiting fewsample {bert} fine-tuning", "year": "2021", "authors": ["Tianyi Zhang", "Felix Wu", "Arzoo Katiyar", "Q Kilian", "Yoav Weinberger", "unk Artzi"]}, {"title": "On the stability of fine-tuning {bert}: Misconceptions, explanations, and strong baselines", "year": "2021", "authors": ["Marius Mosbach", "Maksym Andriushchenko", "Dietrich Klakow"]}], "target_citation_location": 29, "citation_locations": [29], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1a6f5495-0c9d-4a62-be81-5fc89bfa65f2", "citing_paper": {"title": "Entity Attribute Relation Extraction with Attribute-Aware Embeddings", "year": 2020, "authors": ["Dan Iter", "Xiao Yu", "Fangtao Li"]}, "text": ["Our", "baseline", "model", "is", "inspired", "by", "a", "hypernym", "classification", "model", "proposed", "by", "Shwartz et al. (2016),", "also", "using", "a", "pair", "of", "terms", "with", "a", "set", "of", "support", "sentences", "where", "the", "terms", "co-occur."], "cited_papers": [{"title": "Improving hypernymy detection with an integrated path-based and distributional method", "year": "2016", "authors": ["Vered Shwartz", "Yoav Goldberg", "Ido Dagan"]}], "target_citation_location": 12, "citation_locations": [12], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "1a85e328-bf4d-4134-9493-6f62561499fe", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Although", "many", "NLP", "methods", "have", "already", "been", "used", "to", "generate", "distance", "matrices,", "others", "are", "worth", "trying.", "Examples", "include", "graph", "embedding", "of", "associations", "(Bel-Enguix, 2014)", "and", "GraphGlove", "(Ryabinin et al., 2020)."], "cited_papers": [{"title": "Retrieving word associations with a simple neighborhood algorithm in a graph-based resource", "year": "2014", "authors": ["Gemma Bel-Enguix"]}], "target_citation_location": 22, "citation_locations": [22, 25], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3]]}
{"id": "1a8a5992-3076-4f52-b309-b97eb133c793", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["To", "reduce", "the", "deviation", "caused", "by", "different", "implementation", "details,", "we", "first", "present", "our", "implementations'", "performance", "(with", "*),", "which", "have", "a", "higher", "score", "than", "Pont-Tuset et al. (2020)", "reported.", "Thus,", "we", "have", "a", "more", "strict", "baseline", "to", "evaluate", "the", "improvement", "purely", "coming", "from", "our", "innovative", "method.", "Compared", "to", "Baseline*", "method,", "the", "performance", "on", "all", "metrics", "improves", "significantly", "when", "controlling", "captioning", "using", "the", "mouse", "trace", "(+Trace*),", "it", "indicates", "that", "using", "the", "mouse", "trace", "enables", "the", "system", "to", "describe", "better", "those", "user", "intended", "parts", "of", "the", "image."], "cited_papers": [{"title": "Connecting vision and language with localized narratives", "year": "2020", "authors": ["Jordi Pont-Tuset", "Jasper Uijlings", "Beer Changpinyo", "Radu Soricut", "Vittorio Ferrari"]}], "target_citation_location": 23, "citation_locations": [23], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1acae304-83c2-423e-b81d-2e3d4d36d8a6", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["GPT-3", "displays", "strong", "zero-shot", "abilities", "(Brown et al., 2020),", "i.e.,", "using", "a", "simple", "instruction", "or", "\"prompt\"", "as", "input,", "the", "model", "will", "extend", "or", "complete", "the", "text", "accordingly", "without", "any", "pre-defined", "examples.", "Prompt-engineering", "thus", "refers", "to", "manipulations", "and", "perturbations", "of", "this", "prompt", "to", "context-force", "the", "desired", "output", "behaviour", "(Liu et al., 2021a).", "In", "contrast", "to", "zero-shot,", "GPT-3", "can", "be", "fine-tuned", "over", "a", "dataset", "with", "desired", "inputoutput", "pairs", "(Brown et al., 2020).", "To", "conduct", "the", "experiment", "to", "compare", "neutral", "and", "diversityencouraging", "prompts,", "we", "compile", "a", "list", "of", "18", "prompts.", "Nine", "of", "them", "are", "designated", "\"neutral\"", "and", "used", "as", "our", "\"zero-shot\"", "prompts.", "These", "simply", "specify", "a", "task", "of", "generating", "an", "ad", "for", "a", "given", "job", "but", "are", "syntactically", "varied.", "The", "other", "nine", "prompts", "are", "\"equality", "and", "diversity", "prompts\",", "which", "we", "call", "\"engineered\"", "prompts.", "Tab.", "3", "displays", "all", "18", "prompts", "with", "their", "respective", "bias", "and", "realism", "scores."], "cited_papers": [{"title": "Language models are few-shot learners", "year": "2020", "authors": ["Tom Brown", "Benjamin Mann", "Nick Ryder", "Melanie Subbiah", "Jared Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell"]}], "target_citation_location": 60, "citation_locations": [5, 44, 60], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1b55a66f-4e55-4132-b9f9-1a9d957d53c8", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["(b)", "One-to-one", "model", "with", "a", "conditional", "chain", "mapping.\"", "!\"#", "#", "\"", "#\"#", "#", "$", "#", "\"", "$", "\"#", "!!", "\"", "!\"!", "#", "\"", "#\"!", "#", "\"", "!\"#", "#", "\"", "#\"#", "#", "$", "#", "\"", "$", "\"", "\"!", "#", "\"", "$!", "\"#!", "!\"+##',*", "!\"#$%#&amp,'#(-(.()*!", "\"", "#", "\"", "#", "$", "#", "\"(c)", "One-to-one", "model", "with", "a", "single", "sequence.", "data,", "including", "spoken", "dialogue", "systems", "(Jurafsky and Martin, 2008).", "This", "study", "aims", "to", "endow", "existing", "E2E", "ASR", "models", "with", "the", "ability", "to", "produce", "such", "linguistic", "annotations.", "Prior", "work", "explored", "using", "E2E", "ASR", "systems", "to", "predict", "multiple", "kinds", "of", "labels.", "Fig.", "1", "shows", "a", "diagram", "of", "these", "systems.", "These", "approaches", "use", "one", "of", "the", "following", "models:", "a", "one-to-many", "(O2M)", "model", "(Kubo and Bacchiani, 2020, Ueno et al., 2018, Gowda et al., 2019, Sanabria and Metze, 2018, Adams et al., 2019),", "a", "one-to-one", "(O2O)", "model", "with", "a", "conditional", "chain", "mapping", "(Shi et al., 2020),", "or", "an", "O2O", "model", "with", "a", "single", "sequence", "(Audhkhasi et al., 2018, Ghannay et al., 2018, Shafey et al., 2019, Yadav et al., 2020)."], "cited_papers": [{"title": "End-to-End Named Entity Recognition from English Speech", "year": "2020", "authors": ["H Yadav", "S Ghosh", "Y Yu", "R Shah"]}, {"title": "Joint Speech Recognition and Speaker Diarization via Sequence Transduction", "year": "2019", "authors": ["Laurent Shafey", "Hagen Soltau", "Izhak Shafran"]}, {"title": "Endto-end named entity and semantic concept extraction from speech", "year": "2018", "authors": ["S Ghannay", "A Caubri\u00e8re", "Y Est\u00e8ve", "N Camelin", "E Simonnet", "A Laurent", "E Morin"]}, {"title": "Building competitive direct acoustics-to-word models for english conversational speech recognition", "year": "2018", "authors": ["K Audhkhasi", "B Kingsbury", "B Ramabhadran", "G Saon", "M Picheny"]}], "target_citation_location": 131, "citation_locations": [61, 112, 122, 131], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "1b9301b6-96c4-4071-a5dd-1e9552cf4de3", "citing_paper": {"title": "A Parameter-Based Message-Passing Parser for MT of Korean and English", "year": 1994, "authors": ["Bonnie Dorr", "Jye-Hoon Lee", "Sungki Suh"]}, "text": ["The", "parameterized", "framework", "described", "above", "has", "been", "implemented", "in", "C++", "and", "successfully", "tested", "on", "well", "known,", "translationally", "divergent", "sentences.", "Dorr (1990)", "We", "ran", "the", "parameterized", "parser", "on", "both", "the", "English", "and", "Korean", "sentences", "shown", "here.", "The", "results", "shown", "in", "Figure", "5", "which", "were", "obtained", "from", "running", "the", "program", "on", "a", "Sparcstation", "ELC.", "3", "In", "general,", "the", "times", "demonstrate", "a", "speedup", "of", "2", "to", "3", "orders", "of", "magnitude", "over", "previous", "principlebased", "parsers", "on", "analogous", "examples", "such", "as", "those", "given", "in", "Dorr (1993a).", "Even", "more", "significant", "is", "the", "negligible", "difference", "in", "processing", "time", "between", "the", "two", "languages,", "despite", "radical", "differences", "in", "structure,", "particularly", "with", "respect", "to", "head-complement", "positioning.", "This", "is", "an", "improvement", "over", "previous", "parameterized", "approaches", "in", "which", "cross-linguistic", "divergences", "frequently", "induced", "timing", "discrepancies", "of", "1-2", "orders", "of", "magnitude", "due", "to", "the", "head-initial", "bias", "that", "underlies", "most", "parsing", "designs."], "cited_papers": [{"title": "Solving thematic divergences in machine translation", "year": "1990", "authors": ["B Dorr"]}], "target_citation_location": 19, "citation_locations": [19, 78], "citation_type": "single", "annotations": [[1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1b9cde1c-a609-407d-806f-b65a4057b188", "citing_paper": {"title": "A User-Based Usability Assessment of Raw Machine Translated Technical Instructions", "year": 2012, "authors": ["Stephen Doherty", "Sharon O'brien"]}, "text": ["To", "ensure", "the", "task", "was", "as", "realistic", "as", "possible,", "we", "selected", "English", "documentation", "for", "a", "well-known", "online", "file", "storage", "and", "sharing", "service.", "We", "made", "an", "initial", "assumption", "that", "the", "original", "English", "instructions", "published", "by", "the", "developer", "were", "reasonably", "usable,", "given", "that", "the", "service", "has", "over", "50", "million", "users", "(Barret, 2011).", "As", "native", "speakers", "of", "English,", "both", "authors", "judged", "the", "documentation", "to", "be", "of", "reasonable", "quality", "and", "well-formed.", "These", "were", "initial", "assumptions", "which", "would", "be", "tested", "in", "the", "project."], "cited_papers": [{"title": "Dropbox: The Inside Story of Tech's Hottest Startup", "year": "2011", "authors": ["V Barret"]}], "target_citation_location": 48, "citation_locations": [48], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1bbb6cfd-319a-43d9-8f55-a439b681dd76", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["In", "CWI", "2016", "(Paetzold and Specia, 2016a),", "complexity", "was", "defined", "as", "whether", "or", "not", "a", "word", "is", "difficult", "to", "understand", "for", "non-native", "English", "speakers", "and", "the", "words", "in", "the", "dataset", "are", "tagged", "as", "complex", "or", "non-complex", "by", "400", "non-native", "English", "speakers.", "The", "results", "highlight", "the", "effectiveness", "of", "Decision", "Trees", "(Quijada and Medero, 2016, Mukherjee et al., 2016)", "and", "Ensemble", "methods", "(Paetzold and Specia, 2016b, Malmasi et al., 2016)", "for", "the", "task."], "cited_papers": [{"title": "Sv000gg at semeval-2016 task 11: Heavy gauge complex word identification with system voting", "year": "2016", "authors": ["Gustavo Paetzold", "Lucia Specia"]}, {"title": "Ltg at semeval-2016 task 11: Complex word identification with classifier ensembles", "year": "2016", "authors": ["Shervin Malmasi", "Mark Dras", "Marcos Zampieri"]}], "target_citation_location": 50, "citation_locations": [3, 46, 50], "citation_type": "group", "annotations": [[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 2, 2, 2]]}
{"id": "1c180aca-79f4-4dbb-84f8-917f98c78227", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["In", "the", "domain", "of", "multi-lingual", "and", "cross", "lingual", "event", "detection,", "Feng et al. (2018)", "uses", "a", "combination", "of", "both", "LSTMs", "and", "CNNs", "for", "creating", "a", "language", "independent", "architecture", "for", "capturing", "events,", "while", "Goud et al. (2019a)", "used", "stacked", "RNNs", "for", "sequence", "labeling", "and", "a", "language", "discriminator", "to", "learn", "language", "features.", "The", "latter", "architecture", "implements", "the", "use", "of", "the", "character", "embeddings,", "but", "does", "not", "identify", "the", "relevant", "features", "independent", "of", "the", "word", "embeddings."], "cited_papers": [{"title": "Leveraging multilingual resources for open-domain event detection", "year": "2019", "authors": ["Jaipal Goud", "Pranav Goel", "Allen Antony", "Manish Shrivastava"]}], "target_citation_location": 29, "citation_locations": [10, 29], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "1c8c9753-497d-4cf6-a3a9-1a7eebadf756", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["We", "use", "KnowBert-W+W,", "which", "has", "been", "trained", "on", "Wikipedia", "and", "WordNet", "(Fellbaum, 1998)", "as", "an", "embedding", "model", "that", "incorporates", "external", "information,", "note", "that", "we", "are", "not", "using", "this", "as", "an", "entity", "linking", "system,", "even", "for", "NED.", "Similar", "to", "other", "BERT", "baselines,", "we", "feed", "a", "mention", "span", "m", "and", "context", "s,", "and", "we", "use", "the", "weighted", "sum", "of", "the", "[CLS]", "vectors", "from", "all", "15", "layers."], "cited_papers": [{"title": "WordNet: An Electronic Lexical Database", "year": "1998", "authors": ["Christiane Fellbaum"]}], "target_citation_location": 11, "citation_locations": [11], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1c9cba91-b9c6-49da-af45-bb0ebd4dc58f", "citing_paper": {"title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation", "year": 2021, "authors": ["Hansi Hettiarachchi", "Tharindu Ranasinghe"]}, "text": ["Other", "Monolingual", "Since", "there", "were", "less", "training", "data", "available", "for", "non-English", "monolingual", "datasets,", "we", "followed", "a", "few-shot", "learning", "approach", "mentioned", "in", "Ranasinghe et al. (2020c,b).", "When", "we", "are", "starting", "the", "training", "for", "non-English", "monolingual", "language", "pairs,", "rather", "than", "training", "a", "model", "from", "scratch,", "we", "initialised", "the", "weights", "saved", "from", "the", "English-English", "experiment.", "Then", "we", "performed", "training", "on", "the", "dev", "data", "for", "each", "language", "pair", "separately.", "Similar", "to", "English-English", "experiments,", "during", "the", "training", "process,", "the", "parameters", "of", "the", "transformer", "model,", "as", "well", "as", "the", "parameters", "of", "the", "subsequent", "layers,", "were", "updated."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 21, "citation_locations": [21], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1ce8175c-9e3e-42a6-b80a-6b5f64dd8327", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["The", "marginal", "position", "of", "word", "formation", "is", "illustrated", "by", "the", "treatment", "in", "general", "surveys", "of", "computational", "linguistics.", "Surveys", "such", "as", "Karlsson &amp, Karttunen (1997)", "and", "9", "Stem", "changes", "have", "been", "analysed", "in", "a", "number", "of", "different", "ways", "in", "the", "literature.", "Since", "many", "forms", "look", "like", "inflected", "forms", "(the", "so-called", "paradigmic", "forms)", "it", "is", "sometimes", "argued", "that", "these", "are", "inflected", "forms", "in", "word", "formation.", "There", "are", "good", "arguments", "against", "this", "view:", "(a)", "there", "are", "many", "stems", "that", "do", "not", "change", "in", "word", "formation,", "(b)", "changed", "stems", "do", "not", "necessarily", "have", "the", "semantics", "of", "the", "corresponding", "plural", "form", "and", "unchanged", "stems", "do", "not", "necessarily", "have", "the", "semantics", "of", "the", "singular,", "and", "(c)", "there", "are", "also", "non-paradigmic", "forms.", "See", "the", "discussions", "in", "Fuhrhop (1998)", "and", "Eisenberg (1998).", "The", "existence", "of", "stem", "changes", "is", "often", "used", "as", "an", "argument", "against", "the", "IA", "model,", "e.g.", "by", "Anderson (1992).", "An", "analysis", "in", "terms", "of", "\"stem", "formation\"", "is", "elaborated", "by", "ten", "Hacken", "(1994).", "Sproat (2000a)", "do", "not", "even", "mention", "inflection", "and", "word", "formation", "as", "terms,", "let", "alone", "make", "the", "conceptual", "distinction.", "The", "starting", "point", "of", "the", "approaches", "they", "describe", "is", "clearly", "inflection.", "As", "far", "as", "word", "formation", "phenomena", "are", "treated,", "e.g.", "Sproat (2000a:50),", "they", "are", "not", "considered", "from", "the", "perspective", "of", "the", "creation", "of", "new", "lexemes,", "but", "as", "examples", "of", "more", "difficult", "combinations", "of", "formatives."], "cited_papers": [{"title": "Lexical Analysis", "year": "2000", "authors": ["Richard Sproat"]}], "target_citation_location": 150, "citation_locations": [20, 116, 118, 136, 150, 187], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1d106a89-f31a-45de-a844-945400bff185", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["Suffix", "arrays", "were", "introduced", "by", "Manber", "and", "Myers", "who", "gave", "a", "\u0398(N", "log", "N)", "construction", "algorithm", "(1991).", "While", "several", "linear", "time", "suffix", "array", "construction", "algorithms", "have", "now", "been", "introduced", "(K\u00e4rkk\u00e4inen and Sanders, 2003, Ko and Aluru. 2003)", "it", "is", "not", "clear", "that", "their", "asymptotic", "gains", "make", "them", "a", "better", "choice", "than", "well-tuned", "supralinear", "methods", "on", "corpora", "of", "interest", "(Puglisi et al., 2005)."], "cited_papers": [{"title": "Space efficient linear time construction of suffix arrays", "year": "2003", "authors": ["P Ko", "S Aluru"]}, {"title": "Simple linear work suffix array construction", "year": "2003", "authors": ["J K\u00e4rkk\u00e4inen", "P Sanders"]}], "target_citation_location": 29, "citation_locations": [16, 29, 51], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "1d2f6ee9-a1f1-406f-bf6c-6995a99d75ae", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["To", "understand", "whether", "existing", "models", "can", "accurately", "perform", "such", "relative", "comparisons,", "we", "conducted", "a", "preliminary", "study", "on", "pre-trained", "BART", "(Lewis et al., 2020),", "first", "generating", "two", "candidate", "summaries", "from", "the", "model", "and", "observing", "whether", "a", "higher", "probability", "is", "assigned", "to", "the", "candidate", "with", "a", "higher", "ROUGE", "(Lin, 2004)", "score.", "As", "Tab.", "1", "shows,", "the", "accuracy", "is", "far", "from", "ideal.", "This", "is", "likely", "due", "to", "the", "fact", "that", "MLE", "training", "only", "encourages", "the", "model", "to", "assign", "high", "probability", "to", "the", "reference", "summary,", "and", "is", "agnostic", "about", "any", "relative", "comparison", "between", "non-reference", "summaries.", "However,", "we", "argue", "that", "it", "is", "also", "important", "for", "the", "order", "of", "model", "scores", "to", "be", "coordinated", "with", "the", "actual", "quality", "metrics", "by", "which", "the", "summaries", "will", "be", "evaluated", "-higher", "model", "scores", "should", "indicate", "better", "quality", "summaries.", "In", "the", "following", "we", "will", "refer", "to", "models", "that", "have", "such", "scores", "as", "\"coordinated\"", "for", "conciseness."], "cited_papers": [{"title": "BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension", "year": "2020", "authors": ["Mike Lewis", "Yinhan Liu", "Naman Goyal ", " Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer"]}], "target_citation_location": 19, "citation_locations": [19, 43], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1dc7049b-53e5-4467-9863-815b7437495d", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["We", "follow", "the", "setup", "from", "the", "robust", "training", "literature", "(Jia et al., 2019, Xu et al., 2020)", "and", "experiment", "with", "both", "the", "base", "(non-robust)", "and", "robustly", "trained", "models.", "We", "train", "the", "binary", "sentiment", "classifiers", "on", "the", "SST-2", "dataset", "with", "bag-ofwords", "(BoW),", "CNN,", "LSTM,", "and", "attention-basedOriginal:", "70%", "Negative", "Input", "Example:in", "its", "best", "moments,", "resembles", "a", "bad", "high", "school", "production", "of", "grease,", "without", "benefit", "of", "song."], "cited_papers": [{"title": "Certified robustness to adversarial word substitutions", "year": "2019", "authors": ["Robin Jia", "Aditi Raghunathan", "Kerem G\u00f6ksel", "Percy Liang"]}, {"title": "Automatic perturbation analysis for scalable certified robustness and beyond", "year": "2020", "authors": ["Kaidi Xu", "Zhouxing Shi", "Huan Zhang", "Yihan Wang", "Kai-Wei Chang", "Minlie Huang", "Bhavya Kailkhura", "Xue Lin", "Cho-Jui Hsieh"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1dc82b73-3fe3-451f-bb98-af9ce11a33cb", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["Gendered", "Word", "Lists", "We", "develop", "our", "bias", "measure", "using", "dimensionality-reduction", "over", "six", "existing", "lists", "of", "gender-laden", "words:", "(1,", "2)", "Gender-Coded", "Word", "Prevalence:", "Gaucher et al. (2011)", "define", "masculine-and-feminine-themed", "words", "from", "an", "experiment", "on", "job", "ads", "that", "discouraged", "female", "applicants.", "(3)", "Superlative", "Prevalence", ": Schmader et al. (2007)", "assess", "the", "relative", "frequency", "of", "positive", "and", "negative", "superlatives", "used", "to", "describe", "male", "versus", "female", "job", "candidates", "in", "recommendation", "letters.", "We", "use", "an", "established", "set", "of", "superlative", "words", "(Veale, 2016).", "(4)", "Gender-Laden", "Scoring:", "Sap et al. (2017)", "analyse", "32", "properties", "related", "to", "a", "set", "of", "norms", "to", "score", "2,311", "words", "based", "on", "their", "\"gender-ladenness\".", "(5)", "Connotation", "Frames:", "Sap", "et", "al.", "(2017)", "define", "linguistic", "markers", "of", "power", "and", "agency", "associated", "with", "female", "versus", "male", "characters", "in", "modern", "films.", "(6)", "NRC", "VAD", "Lexicon:", "Mohammad", "(2018)", "presents", "a", "lexicon", "of", "words", "coded", "by", "valence,", "arousal,", "and", "dominance", "whose", "interpretation", "may", "interact", "with", "gender.", "5", "Dimensionality", "Reduction", "We", "employ", "principal", "component", "analysis", "(PCA)", "on", "the", "six", "bias", "measures", "on", "real-world", "job", "ads", "to", "collapse", "them", "into", "interpretable", "components.", "We", "then", "replicate", "the", "PCA", "on", "synthetic", "job", "ads", "(zero-shot)", "and", "project", "all", "data", "points", "onto", "the", "first", "two", "principal", "components", "of", "real", "job", "ads", "and", "vice", "versa."], "cited_papers": [{"title": "Connotation frames of power and agency in modern films", "year": "2017", "authors": ["Maarten Sap", "Marcella Prasettio", "Ari Holtzman", "Hannah Rashkin", "Yejin Choi"]}], "target_citation_location": 72, "citation_locations": [22, 39, 68, 72], "citation_type": "single", "annotations": [[3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1e298cd5-80bc-4cd8-8c68-4a5c715c5474", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Natural", "Questions", "Test", "MRR@10", "R@50", "R@1000", "R@5", "R@20", "R@100", "BM25", "(anserini)", "(Yang et al., 2017", "(Karpukhin et al., 2020)", "BERTbase", "----78.4", "85.4", "ANCE", "(single)", "(Xiong et al., 2020)", "RoBERTabase", "33.0", "-95.9", "-81.9", "87.5", "ME-BERT", "(Luan et al., 2020)", "BERTlarge", "33.8", "-----RocketQA", "ERNIEbase", "37.0", "85.5", "97.9", "74.0", "82.7", "88.5"], "cited_papers": [{"title": "Sparse, dense, and attentional representations for text retrieval. CoRR, abs", "year": null, "authors": ["Yi Luan", "Jacob Eisenstein", "Kristina Toutanova", "Michael Collins"]}], "target_citation_location": 25, "citation_locations": [11, 12, 18, 25], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1e61ceab-5f51-41fc-b045-59c9a8c3941c", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["Dagan", "and", "Church", "developed,", "Termight,", "a", "tool", "that", "was", "meant", "assist", "professional", "translators", "and", "terminologists", "develop", "bilingual", "term", "lists", "and", "technical", "terminology", "in", "particular", "(1997).", "Like", "Kupiec's", "work,", "they", "also", "presume", "the", "availability", "of", "POS-tagging", "and", "work", "with", "noun", "phrases", "extracted", "from", "sentence-aligned", "corpora.", "A", "distinctive", "feature", "of", "their", "approach", "is", "using", "word-level", "alignments", "to", "score", "translations,", "this", "enables", "identification", "of", "correct", "translations", "even", "with", "the", "correct", "source", "term", "/", "target", "term", "correspondence", "is", "observed", "once", "or", "twice", "in", "the", "bilingual", "data.", "(This", "scenario,", "when", "term", "frequency", "is", "small,", "makes", "translation", "using", "contingency", "table", "methods", "such", "as", "Dice", "coefficients", "problematic.)", "They", "report", "finding", "a", "correct", "translation", "at", "rank", "1", "40%", "of", "the", "time", "and", "at", "rank", "2", "an", "additional", "7%", "of", "the", "time", "for", "a", "list", "of", "192", "English/German", "technical", "terms."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "1e61d4e1-95d3-46e9-8926-99de93556cdd", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["Quoref", "(Dasigi et al., 2019)", "is", "a", "dataset", "that", "is", "particularly", "designed", "for", "evaluating", "coreference", "understanding", "of", "MRC", "models.", "Figure", "1", "shows", "a", "QA", "sample", "from", "Quoref", "in", "which", "the", "model", "needs", "to", "resolve", "the", "coreference", "relation", "between", "\"his\"", "and", "\"John", "Motteux\"", "to", "answer", "the", "question.", "Recent", "large", "pre-trained", "language", "models", "reached", "high", "performance", "on", "Quoref.", "However,", "our", "results", "and", "analyses", "suggest", "that", "this", "dataset", "contains", "artifacts", "and", "does", "not", "reflect", "the", "natural", "distribution", "and,", "therefore,", "the", "challenges", "of", "coreference", "reasoning.", "As", "a", "result,", "high", "performances", "on", "Quoref", "do", "not", "necessarily", "reflect", "the", "coreference", "reasoning", "capabilities", "of", "the", "examined", "models", "and", "answering", "questions", "that", "require", "coreference", "reasoning", "might", "be", "a", "greater", "challenge", "than", "current", "scores", "suggest."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 1, "citation_locations": [1], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1e9494c5-fae9-44d6-b944-39945b7597c7", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["We", "compute", "our", "embeddings", "from", "an", "entity", "typing", "model", "trained", "on", "the", "UFET", "dataset", "(Choi et al., 2018)", "for", "CAP", "(10k", "types).", "We", "choose", "this", "dataset", "because", "many", "of", "mention", "spans", "in", "the", "CAP", "examples", "are", "nominal", "expressions", "or", "pronouns,", "and", "the", "Wiki-Context", "dataset", "includes", "almost", "entirely", "mentions", "of", "proper", "nouns.", "To", "make", "a", "prediction", "if", "two", "mentions", "are", "coreferent,", "we", "compute", "sim", "cos", "(t", "1,", "t", "2)", "over", "the", "type", "vectors", "for", "each", "mention", "and", "check", "if", "this", "is", "greater", "than", "a", "threshold,", "which", "we", "set", "to", "0.5.", "Only", "our", "baselines", "use", "the", "CAP", "training", "set,", "our", "model", "does", "not", "train", "on", "this", "data.", "We", "compare", "our", "approach", "with", "the", "baselines", "described", "above", "as", "reported", "in", "Chen et al. (2019).", "Note", "that", "they", "use", "two", "different", "types", "of", "entity", "representations:", "one", "based", "on", "entity", "descriptions", "and", "another", "based", "on", "entity", "names", "only."], "cited_papers": [{"title": "Ultra-Fine Entity Typing", "year": "2018", "authors": ["Eunsol Choi", "Omer Levy", "Yejin Choi", "Luke Zettlemoyer"]}], "target_citation_location": 14, "citation_locations": [14, 114], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1e9681fd-8281-4cc7-9195-a0145b17ae5e", "citing_paper": {"title": "Effects of Word Alignment Visualization on Post-Editing Quality & Speed \u2020", "year": 2015, "authors": ["Lane Schwartz", "Isabel Lacruz", "Tatyana Bystrova"]}, "text": ["For", "this", "study,", "we", "developed", "a", "novel", "post-editing", "interface,", "based", "on", "the", "open", "source", "software", "used", "and", "released", "by", "Schwartz et al. (2014).", "Our", "software", "is", "written", "using", "Scala", "(Odersky, 2014),", "and", "is", "released", "as", "open", "source", "(see", "the", "software", "supplement", "that", "accompanies", "this", "work).", "This", "code", "constitutes", "a", "ground-up", "rewrite", "of", "the", "Java-based", "post-editing", "interface", "of", "Schwartz et al. (2014),", "written", "using", "a", "strict", "model-view-controller", "software", "design", "pattern", "to", "be", "easy", "for", "other", "researchers", "to", "use", "and", "extend."], "cited_papers": [{"title": "Machine translation and monolingual postediting: The AFRL WMT-14 system", "year": "2014", "authors": ["L Schwartz", "T Anderson", "J Gwinnup", "K Young"]}], "target_citation_location": 53, "citation_locations": [19, 26, 53], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1ed3d3de-5136-4286-a12e-bc5857ed6e7a", "citing_paper": {"title": "SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering", "year": 2020, "authors": ["Aishwarya Ashok", "Ganapathy Natarajan", "Ramez Elmasri", "Laurel Smith-Stvan"]}, "text": ["Our", "system", "outperforms", "the", "R-Net", "baseline", "(Rouge-L:", "40.22)", "used", "by", "Gupta et al. (2019).", "Our", "system", "is", "supposed", "to", "be", "applied", "at", "the", "sentence", "level", "and", "the", "results", "indicate", "that", "a", "unsupervised", "system", "such", "as", "ours", "could", "outperform", "more", "complicated", "deep", "learning", "models.", "If", "there", "is", "a", "trade-off", "sought", "between", "computing", "time", "and", "accuracy,", "our", "system", "performs", "similar", "to", "or", "better", "than", "the", "baseline", "used", "by", "Gupta et al. (2019)", "ROUGE", "score", "is", "not", "the", "best", "metric", "for", "tasks", "such", "as", "opinion", "question", "answering.", "We", "believe", "the", "cosine", "similarity", "is", "a", "better", "metric", "to", "measure", "how", "close", "the", "retrieved", "answer", "is", "to", "the", "gold", "standard.", "Overall", "the", "sim", "method", "is", "able", "to", "provide", "an", "answer", "more", "than", "70%", "similar", "to", "the", "gold", "standard", "answer", "91.5%", "of", "the", "time.", "From", "the", "sentences", "returned", "by", "our", "system", "as", "candidate", "answers,", "72%", "of", "the", "time", "at", "least", "half", "the", "candidate", "sentences", "are", "good", "answers.", "This", "shows", "that", "our", "system", "is", "consistent", "and", "accurate", "at", "providing", "good", "answers."], "cited_papers": [{"title": "Amazonqa: A review-based question answering task", "year": "2019", "authors": ["Mansi Gupta", "Nitish Kulkarni", "Raghuveer Chanda", "Anirudha Rayasam", "Zachary Lipton"]}], "target_citation_location": 63, "citation_locations": [10, 63], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1efebe1a-5098-4d62-8c8c-4a01a029d3ad", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["For", "future", "work,", "we", "would", "like", "to", "include", "linguistic", "features", "at", "the", "source", "language.", "It", "is", "known", "that", "this", "can", "be", "helpful", "for", "NMT", "[15].", "Extending", "the", "approach", "with", "input", "factors", "could", "make", "the", "target", "language", "factors", "generation", "better.", "Furthermore,", "different", "attention", "mechanisms", "for", "each", "output", "will", "be", "explored", "because", "they", "could", "be", "aligned", "to", "different", "source", "words.", "The", "proposed", "FNMT", "architecture", "could", "even", "show", "better", "performance", "if", "applied", "when", "we", "translate", "to", "highly", "inflected", "languages", "like", "German,", "Arabic,", "Czech", "or", "Russian.", "Finally,", "FNMT", "approach", "will", "be", "explored", "in", "multimodal", "and", "multilingual", "tasks."], "cited_papers": [{"title": "Linguistic input features improve neural machine translation", "year": "2016", "authors": ["R Sennrich", "B Haddow"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "1fa4a02f-8ee1-41c5-8218-3ae1a7d07225", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["Following", "the", "previous", "editions", "of", "the", "shared", "task,", "we", "frame", "explanation", "generation", "as", "a", "ranking", "problem.", "Specifically,", "for", "a", "given", "science", "question,", "a", "model", "is", "supplied", "both", "the", "question", "and", "correct", "answer", "text,", "and", "must", "then", "selectively", "rank", "all", "the", "atomic", "scientific", "and", "world", "knowledge", "facts", "in", "the", "knowledge", "base", "such", "that", "those", "that", "were", "labelled", "as", "most", "relevant", "to", "building", "an", "explanation", "by", "a", "human", "annotator", "are", "ranked", "the", "highest.", "Additional", "details", "on", "the", "ranking", "problem", "are", "described", "in", "the", "2019", "shared", "task", "summary", "paper", "(Jansen and Ustalov, 2019)."], "cited_papers": [{"title": "TextGraphs 2019 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": "2019", "authors": ["Peter Jansen", "Dmitry Ustalov"]}], "target_citation_location": 86, "citation_locations": [86], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]]}
{"id": "1ff103d3-0ce4-48bc-935d-64b2c93f9170", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Comparing", "this", "relatedness", "measure", "to", "data", "obtained", "from", "humans", "(MEN, Bruni et al., 2012 and WS-353 relatedness, Agirre et al., 2009),", "we", "found", "that", "taking", "the", "square", "root", "of", "PMI", "norm", "increases", "the", "Pearson", "correlation", "coefficient", "between", "human", "annotations", "and", "our", "calculated", "relatedness", "from", "0.72", "to", "0.76", "for", "MEN,", "and", "from", "0.57", "to", "0.63", "for", "WS-353.", "Additionally,", "in", "our", "following", "methods,", "it", "is", "beneficial", "if", "the", "values", "do", "not", "concentrate", "around", "zero,", "therefore", "we", "use", "the", "square", "root", "of", "normalized", "PMI", "hereinafter:", "NPMI(x,", "y)", "=", "PMI", "norm", "(x,", "y)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "20034b01-748e-433e-affb-82158149430c", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["This", "work", "is", "part", "of", "an", "effort", "to", "develop", "a", "robust,", "domain-independent", "syntactic", "parser", "capable", "of", "yielding", "the", "one", "correct", "analysis", "for", "unrestricted", "naturally-occurring", "input.", "Our", "goal", "is", "to", "develop", "a", "system", "with", "performance", "comparable", "to", "extant", "part-of-speech", "taggers,", "returning", "a", "syntactic", "analysis", "from", "which", "predicate-argument", "structure", "can", "be", "recovered,", "and", "which", "can", "support", "semantic", "interpretation.", "The", "requirement", "for", "a", "domain-independent", "analyser", "favours", "statistical", "techniques", "to", "resolve", "ambiguities,", "whilst", "the", "latter", "goal", "favours", "a", "more", "sophisticated", "grammatical", "formalism", "than", "is", "typical", "in", "statistical", "approaches", "to", "robust", "analysis", "of", "corpus", "material.", "Briscoe and Carroll (1993)", "describe", "a", "probablistic", "parser", "using", "a", "wide-coverage", "unification", "based", "grammar", "of", "English", "written", "in", "the", "Alvey", "Natural", "Language", "To", "ols", "(ANLT)", "meta", "g", "rammat", "ical", "formalism", "(Briscoe et al. , 1987),", "generating", "around", "800", "rules", "in", "a", "syntactic", "variant", "of", "the", "Definite", "Clause", "Grammar", "formalism", "(DCG,", "Pereira &amp, Warren, 1980)", "extended", "with", "iterative", "(Kleene)", "operators.", "The", "ANLT", "grammar", "is", "linked", "to", "a", "lexicon", "containing", "about", "64K", "entries", "for", "40K", "lexemes,", "including", "detailed", "subcategorisation", "information", "appropriate", "for", "the", "grammar,", "built", "semi-automatically", "from", "a", "learners'", "dictionary", "(Carroll &amp, Grover, 1989).", "The", "resulting", "parser", "is", "efficient,", "capable", "of", "constructing", "a", "parse", "forest", "in", "what", "seems", "to", "be", "roughly", "quadratic", "time,", "and", "efficiently", "returning", "the", "ranked", "n-most", "likely", "analyses", "(Carroll, 1993 (Carroll, , 1994)).", "The", "probabilistic", "model", "is", "a", "refinement", "of", "probabilistic", "context-free", "grammar", "(PCFG)", "conditioning", "CF", "'backbone'", "rule", "application", "on", "LR", "state", "and", "lookahead", "item.", "Unification", "of", "the", "'residue'"], "cited_papers": [{"title": "Practical unification-based parsing of natural language", "year": "1993", "authors": ["J Carroll"]}, {"title": "Relating complexity to practical performance in parsing with wide-coverage unification grammars", "year": "1994", "authors": ["J Carroll"]}], "target_citation_location": 196, "citation_locations": [90, 117, 133, 168, 196], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "20b3310d-e84a-43ab-9182-130203a09788", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["State-of-the-art", "DRS", "parsers", "follow", "the", "encoderdecoder", "paradigm", "pioneered", "for", "machine", "translation", "by", "Sutskever et al. (2014):", "the", "input", "sequence", "is", "encoded", "by", "a", "neural", "network", "into", "a", "vector,", "then", "another", "network", "predicts", "the", "output", "sequence", "(or", "in", "this", "case:", "output", "DRS)", "from", "that", "vector.", "Rather", "than", "improve", "upon", "the", "accuracy", "of", "such", "parsers", "on", "standard", "benchmarks,", "our", "aim", "in", "this", "paper", "is", "to", "achieve", "some", "of", "their", "benefits", "(ability", "to", "learn", "from", "examples,", "high", "accuracy,", "low", "computational", "complexity,", "robustness", "to", "atypical", "input,", "utilization", "of", "off-the-shelf", "language", "models,", "conceptual", "simplicity)", "while", "also", "having", "a", "degree", "of", "compositionality,", "traditionally", "a", "property", "of", "grammar-based", "systems.", "Specifically,", "our", "system", "learns", "to", "assign", "each", "token", "of", "an", "utterance", "one", "of", "a", "finite", "set", "of", "abstract", "meaning", "fragments", "that", "are", "deterministically", "combined", "to", "give", "the", "meaning", "of", "the", "whole", "utterance.", "While", "our", "system", "may", "not", "fulfill", "all", "criteria", "of", "compositionality", "according", "to", "some", "definitions,", "it", "can", "arguably", "reap", "some", "of", "compositionality's", "benefits,", "which", "make", "it", "suitable", "for", "use", "in", "semi-automatic", "annotation", "workflows.", "We", "discuss", "this", "further", "in", "Section", "5.", "Previous", "work", "has", "introduced", "trainable", "compositional", "semantic", "parsers", "for", "AMR", "(Lindemann et al., 2020)", "and", "DRS", "(Evang, 2019, Bladier et al., 2021).", "In", "this", "paper,", "we", "improve", "upon", "the", "latter", "parser", "using", "a", "novel", "way", "to", "encode", "anchored", "DRSs", "as", "sequences,", "and", "thereby", "cast", "DRS", "parsing", "simply", "as", "a", "sequence", "labeling", "task", "(\u00a72).", "We", "use", "a", "standard", "transformer-based", "model", "to", "learn", "this", "task,", "followed", "by", "post-processing", "to", "ensure", "well-formed", "DRSs", "(\u00a73).", "We", "use", "training", "data", "from", "the", "Parallel", "Meaning", "Bank", "(\u00a74).", "The", "accuracy", "of", "our", "model", "approaches", "the", "state", "of", "the", "art", "with", "the", "additional", "benefit", "of", "being,", "to", "a", "degree,", "compositional", "(\u00a75).", "We", "give", "an", "error", "analysis", "in", "\u00a76", "and", "conclude", "in", "\u00a77."], "cited_papers": [{"title": "Fast semantic parsing with welltypedness guarantees", "year": "2020", "authors": ["Matthias Lindemann", "Jonas Groschwitz", "Alexander Koller"]}], "target_citation_location": 180, "citation_locations": [12, 180, 183], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "20c46e4c-57b3-4519-b34f-342a903bd53f", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["Feed-forward", "as", "attention", "In", "the", "feed-forward", "layer,", "a", "1-hidden", "layer", "fully-connected", "network", "is", "applied", "identically", "to", "every", "input", "token.", "As", "observed", "in", "past", "work", "(Sukhbaatar et al., 2019, Shazeer, 2020, Geva et al., 2020),", "a", "feed-forward", "layer", "can", "be", "cast", "into", "the", "query-key-value", "framework", "as:"], "cited_papers": [{"title": "Augmenting self-attention with persistent memory", "year": "2019", "authors": ["Sainbayar Sukhbaatar", "Edouard Grave", "Guillaume Lample", "H J\u00e9gou", "Armand Joulin"]}, {"title": "GLU variants improve transformer. ArXiv, abs", "year": "2002", "authors": ["Noam Shazeer"]}, {"title": "Transformer feed-forward layers are key-value memories", "year": "2020", "authors": ["R Mor Geva", "Jonathan Schuster", "Omer Berant", "unk Levy"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "20e27eee-c89b-4d2f-8d0a-2fa6514c763c", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["We", "also", "study", "mitigating", "shortcuts", "by", "masking", "out", "the", "identified", "shortcuts.", "RM),", "and", "both", "(Train", "&amp,", "Test", "RM)", "as", "described", "in", "Sec", "3.4.", "We", "evaluate", "these", "three", "approaches", "in", "multiple", "settings:", "1)", "domain", "generalization,", "2)", "challenging", "datasets,", "3)", "gender", "bias.", "As", "shown", "in", "Table", "5,", "masking", "out", "shortcuts,", "especially", "in", "training", "data,", "can", "improve", "model's", "generalization", "to", "out-of-distribution", "data.", "Note", "in", "this", "setting,", "different", "from", "existing", "domain", "transfer", "work", "(Pan", "and", "Yang,", "2010),", "we", "do", "not", "assume", "access", "to", "labeled", "data", "in", "the", "target", "domain", "during", "training,", "instead", "we", "use", "our", "proposed", "approach", "to", "identify", "potential", "shortcuts", "that", "can", "generalize", "to", "unseen", "target", "domains.", "As", "a", "result,", "we", "also", "observe", "model's", "performance", "improvement", "on", "challenging", "datasets", "(Table", "7).", "fairer", "model.", "Note", "the", "original", "performance", "might", "degrade", "slightly", "due", "to", "models", "learning", "different", "but", "more", "robust", "feature", "representations,", "consistent", "with", "findings", "in", "existing", "work", "(Tsipras et al., 2019)."], "cited_papers": [{"title": "Robustness may be at odds with accuracy", "year": "2019", "authors": ["Dimitris Tsipras", "Shibani Santurkar", "Logan Engstrom", "Alexander Turner", "Aleksander Madry"]}], "target_citation_location": 143, "citation_locations": [143], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]]}
{"id": "2112b391-985d-4715-b911-035114f05a28", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["In", "addition,", "in", "order", "to", "have", "both", "the", "high", "performance", "of", "post-norm", "and", "the", "stable", "training", "of", "pre-norm", "(Nguyen", "and", "Salazar,", "2019),", "we", "use", "the", "methods", "mentioned", "in", "DeepNet", "(Wang et al., 2022)", "For", "training", "the", "full-sentence", "translation", "model,", "given", "the", "source", "sentence", "x,", "the", "probability", "of", "predicting", "the", "target", "sentence", "y", "is", "as", "shown", "in", "Eq.", "1,", "and", "the", "training", "objective", "is", "to", "minimize", "the", "negative", "log-likelihood", "as", "shown", "in", "Eq.", "2.p(y|x)", "=", "|y|", "t=1", "p(y", "t", "|x,", "y", "&lt,t,", "\u03b8)(1)loss", "f", "ull", "(\u03b8)", "=", "\u2212", "(x,y)\u2208D", "logp", "g", "(y|x,", "\u03b8)", "(2)The", "batch", "size", "for", "training", "is", "4,096", "tokens", "per", "GPU,", "and", "we", "trained", "our", "model", "for", "7", "epochs", "on", "4", "NVIDIA", "V100", "GPUs", "for", "about", "10", "hours."], "cited_papers": [{"title": null, "year": "2022", "authors": ["Hongyu Wang", "Shuming Ma", "Li Dong", "Shaohan Huang", "Dongdong Zhang", "Furu Wei"]}], "target_citation_location": 29, "citation_locations": [29], "citation_type": "single", "annotations": [[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2135c5db-4f7a-437c-b516-e86be15f86cb", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["Google-BERT.", "Xiang et al. (2021)", "propose", "a", "framework", "composed", "of", "three", "main", "steps.", "In", "the", "first", "step,", "the", "model", "adopts", "a", "simple", "tf.idf", "model", "with", "cosine", "similarity", "to", "retrieve", "the", "top-K", "relevant", "explanation", "sentences", "(K", "=", "50)", "for", "each", "question", "and", "correct", "answer", "pair.", "In", "the", "second", "step,", "the", "authors", "employ", "an", "autoregressive", "model", "which", "selects", "the", "most", "relevant", "facts", "in", "a", "iterative", "manner.", "Specifically,", "the", "authors", "propose", "the", "adoption", "of", "a", "BERT-based", "model", "(Devlin et al., 2019)", "that", "selects", "the", "facts", "at", "iteration", "n", "given", "the", "facts", "retrieved", "in", "the", "previous", "step.", "The", "model", "uses", "up", "to", "4", "iterations.", "Finally,", "the", "authors", "employ", "a", "re-ranking", "module", "to", "re-score", "the", "retrieved", "candidate", "explanations", "computing", "the", "relevance", "between", "each", "fact", "and", "the", "question-answer", "pairs.", "The", "re-ranking", "model", "is", "implemented", "using", "a", "BERT", "model", "for", "binary", "classification.", "The", "ablation", "study", "shows", "that", "the", "first", "two", "steps", "allow", "achieving", "a", "performance", "of", "0.679", "NDCG,", "that", "is", "improved", "up", "to", "0.700", "NDCG", "using", "the", "re-ranking", "model.", "Moreover,", "the", "experiments", "show", "that", "the", "best", "performance", "is", "achieved", "when", "the", "re-ranking", "model", "is", "adopted", "to", "re-score", "the", "top", "K", "=", "30", "facts."], "cited_papers": [{"title": "A Three-step Method for Multi-Hop Inference Explanation Regeneration", "year": "2021", "authors": ["Yuejia Xiang", "Yunyan Zhang", "Xiaoming Shi", "Bo Liu", "Wandi Xu", "Xi Chen"]}], "target_citation_location": 1, "citation_locations": [1, 71], "citation_type": "single", "annotations": [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "219ae21f-dc99-426c-83cf-dafa9e1e8484", "citing_paper": {"title": "Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model", "year": 2022, "authors": ["Richard Futrell"]}, "text": ["Recently", "Nikkarinen et al. (2021)", "introduced", "a", "neural-Bayesian", "nonparametric", "estimator", "for", "probability", "distributions", "on", "single", "words.", "Their", "setting", "has", "an", "unknown", "and", "generally", "infinite", "vocabulary", "V,", "and", "their", "model", "generalizes", "using", "a", "characterlevel", "LSTM.", "In", "contrast,", "the", "current", "model", "assumes", "a", "pre-existing", "known", "vocabulary", "V", "with", "embeddings,", "and", "generalizes", "based", "on", "those", "embeddings.", "A", "hybrid", "model", "may", "be", "possible", "in", "future", "work."], "cited_papers": [{"title": "Modeling the unigram distribution", "year": "2021", "authors": ["Irene Nikkarinen", "Tiago Pimentel", "Dami\u00e1n Blasi", "Ryan Cotterell"]}], "target_citation_location": 1, "citation_locations": [1], "citation_type": "single", "annotations": [[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "21d57dc0-c879-406c-9e3d-acf240c9c655", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["As", "shown", "in", "Figure", "3,", "we", "organize", "the", "above", "three", "training", "strategies", "into", "an", "effective", "training", "pipeline", "for", "the", "dual-encoder.", "It", "makes", "an", "analogy", "to", "a", "multi-stage", "rocket,", "where", "the", "performance", "of", "the", "dual-encoder", "is", "consecutively", "improved", "at", "three", "steps", "(STEP", "1,", "3", "and", "4).", "That", "is", "why", "we", "call", "our", "approach", "RocketQA.", "Next,", "we", "will", "describe", "the", "details", "of", "the", "whole", "training", "procedure", "of", "RocketQA.", "D", "from", "C", "for", "each", "question", "q", "\u2208", "Q", "L.", "This", "design", "is", "to", "let", "the", "cross-encoder", "adjust", "to", "the", "distribution", "of", "the", "results", "retrieved", "by", "the", "dualencoder,", "since", "the", "cross-encoder", "will", "be", "used", "in", "the", "following", "two", "steps", "for", "optimizing", "the", "dualencoder.", "This", "design", "is", "important,", "and", "there", "is", "similar", "observation", "in", "Facebook", "Search", "(Huang et al., 2020)."], "cited_papers": [{"title": "Embedding-based retrieval in facebook search", "year": "2020", "authors": ["Jui-Ting Huang", "Ashish Sharma", "Shuying Sun", "Li Xia", "David Zhang", "Philip Pronin", "Janani Padmanabhan", "Giuseppe Ottaviano", "Linjun Yang"]}], "target_citation_location": 121, "citation_locations": [121], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]]}
{"id": "21dd12bf-64e1-41f3-9197-3f8bf9648797", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["For", "wh-word,", "empty", "question,", "and", "short", "distance", "reasoning,", "we", "use", "the", "TASE", "model", "(Segal et al., 2020)", "We", "also", "investigate", "whether", "these", "biases", "have", "similar", "ratios", "in", "a", "coreference", "resolution", "dataset.", "We", "use", "the", "CoNLL-2012", "coreference", "resolution", "dataset", "(Pradhan et al., 2012a)", "and", "convert", "it", "to", "a", "reading", "comprehension", "format,", "i.e.,", "CoNLL", "bart", "in", "Section", "5.", "5", "This", "data", "contains", "question-answer", "pairs", "in", "which", "the", "question", "is", "created", "based", "on", "a", "coreferring", "expression", "in", "CoNLL-2012,", "and", "the", "answer", "is", "its", "closest", "antecedent.", "We", "split", "this", "data", "into", "training", "and", "test", "sets", "and", "train", "bias", "models", "on", "the", "training", "split.", "The", "CoNLL", "bart", "column", "in", "Table", "1", "shows", "the", "bias", "proportions", "on", "this", "data."], "cited_papers": [{"title": "A simple and effective model for answering multi-span questions", "year": "2020", "authors": ["Elad Segal", "Avia Efrat", "Mor Shoham", "Amir Globerson", "Jonathan Berant"]}], "target_citation_location": 13, "citation_locations": [13, 35], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "21f1f90b-71c6-4c9f-b7b0-761601806da1", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["Despite", "the", "inclusion", "of", "translations", "and", "contrastive", "loss,", "we", "observed", "that", "there", "is", "only", "a", "marginal", "improvement", "in", "the", "QA", "performance.", "This", "can", "be", "attributed", "to", "the", "smaller", "size", "of", "the", "ChAII", "dataset", "with", "1114", "instances", "(Tamil and Hindi combined, Train, Validation, and Test combined),", "which", "is", "clearly", "insufficient", "to", "fine-tune", "a", "177M", "parameter", "model.", "Hence,", "the", "proposed", "techniques", "have", "to", "be", "evaluated", "on", "other", "larger", "datasets", "as", "well", "as", "using", "other", "multilingual", "models", "like", "XLM-RoBERTa", "(Conneau et al., 2020),", "Distill-mBERT", "(Sanh et al., 2019),", "MURIL", "(Khanuja et al., 2021)", "and", "Indic-BERT", "(Kakwani et al., 2020).", "We", "hope", "that", "the", "proposed", "techniques", "will", "motivate", "further", "research", "in", "this", "field,", "including", "exploration", "of", "the", "same", "phenomenon", "of", "cross-lingual", "transfer", "in", "other", "language", "families", "and", "multilingual", "tasks."], "cited_papers": [{"title": "Indicnlpsuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for indian languages", "year": "2020", "authors": ["Divyanshu Kakwani", "Anoop Kunchukuttan", "Satish Golla", "N C Gokul", "Avik Bhattacharyya", "M Mitesh", "Pratyush Khapra", "unk Kumar"]}], "target_citation_location": 75, "citation_locations": [36, 68, 70, 72, 75], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "222decd8-6ae3-4271-84e1-64aecae3eda6", "citing_paper": {"title": "Situation-Specific Multimodal Feature Adaptation", "year": 2021, "authors": ["\u00d6zge Alac"]}, "text": ["In", "this", "research", "proposal,", "we", "focus", "on", "three", "factors", "that", "can", "enhance", "the", "communication", "between", "humans", "and", "assistive", "technologies.", "The", "first", "one", "is", "the", "encoding", "of", "the", "referential", "complexity", "of", "the", "situated", "settings", "while", "creating", "multimodal", "embeddings.", "As", "pointed", "out", "in", "(Singh et al., 2020),", "pre-trained", "models,", "that", "were", "created", "by", "fusing", "the", "modalities", "without", "constraints,", "are", "expected", "to", "be", "an", "out-of-the-box", "solution", "and", "work", "well", "for", "a", "variety", "of", "simpler", "tasks.", "In", "this", "research,", "we", "propose", "to", "encode", "referential", "complexity", "during", "the", "training", "phase", "to", "see", "whether", "the", "complexity-sensitive", "embeddings", "will", "improve", "the", "tasks", "of", "crossmodal", "mapping", "and", "meaning", "recovery.", "We", "believe", "that", "this", "will", "implicitly", "direct", "the", "model", "to", "focus", "on", "various", "textual", "and", "visual", "forms", "of", "the", "same", "concepts."], "cited_papers": [{"title": "Are we pretraining it right? Digging deeper into visio-linguistic pretraining", "year": "2020", "authors": ["Amanpreet Singh", "Vedanuj Goswami", "Devi Parikh"]}], "target_citation_location": 41, "citation_locations": [41], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "228facc6-1348-42cf-bb1c-f43c35d8694f", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["MMB", "was", "much", "associated", "with", "the", "use", "of", "interlinguas", "for", "MT", "(machine", "translation)", "and", "for", "meaning", "representation", "(Masterman, 1967),", "and", "her", "reply", "to", "Bar-Hillel's", "criticism", "of", "their", "use", "has", "been", "much", "quoted.", "The", "notion", "of", "a", "uniform", "and", "universal", "meaning", "representation", "for", "translating", "between", "languages", "has", "continued", "to", "be", "a", "strategy", "within", "the", "field:", "it", "had", "a", "significant", "role", "in", "AI", "(artificial", "intelligence)", "systems", "such", "as", "conceptual", "dependency", "(Schank, 1975)", "and", "preference", "semantics", "(Wilks, 1973),", "and", "is", "now", "to", "be", "found", "in", "recent", "attempts", "to", "use", "Esperanto", "as", "an", "interlingua", "for", "MT."], "cited_papers": [{"title": "Conceptual information processing", "year": "1975", "authors": ["R Schank"]}], "target_citation_location": 67, "citation_locations": [17, 67, 71], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "22903351-6d7b-4775-9a75-cba6c5340540", "citing_paper": {"title": "Situation-Specific Multimodal Feature Adaptation", "year": 2021, "authors": ["\u00d6zge Alac"]}, "text": ["In", "recent", "years,", "we", "have", "witnessed", "a", "considerable", "increase", "in", "the", "use", "of", "assistive", "technologies", "that", "can", "engage", "in", "communication", "and", "perform", "tasks.", "These", "can", "come", "in", "different", "forms", "like", "smart", "speakers", "and", "mobile", "devices", "that", "you", "can", "command", "with", "audio,", "or", "more", "specialized", "task-oriented", "robots", "that", "can", "actually", "realize", "users'", "command", "in", "3D", "environments.", "The", "steady", "increase", "in", "the", "use", "of", "collaborative", "robots", "(IFR, 2018)", "in", "daily", "life", "brings", "along", "another", "important", "Human-Computer", "Interaction", "theme:", "the", "capability", "of", "engaging", "in", "a", "natural", "and", "smooth", "spoken", "dialog", "with", "humans,", "which", "is", "a", "major", "scientific", "and", "technological", "challenge.", "Particularly,", "being", "able", "to", "follow", "a", "communication", "that", "conveys", "thoughts", "and", "intentions", "expressed", "in", "a", "flexible", "manner", "without", "the", "restrictions", "of", "a", "close-set", "of", "commands", "is", "a", "crucial", "component", "of", "assistive", "robots", "for", "the", "handicapped", "and", "elderly", "people", "and", "for", "the", "education", "/", "entertainment", "purposes."], "cited_papers": [{"title": "Executive summary world robotics 2019 service robots", "year": "2018", "authors": ["unk Ifr"]}], "target_citation_location": 64, "citation_locations": [64], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "22bd3af6-e828-404e-89b5-b8c365fef334", "citing_paper": {"title": "On the weak link between importance and prunability of attention heads", "year": 2020, "authors": ["Aakriti Budhraja", "Madhura Pande", "Preksha Nema", "Pratyush Kumar", "Mitesh Khapra"]}, "text": ["Pruning", "Based", "on", "Component.", "Some", "studies", "show", "that", "heads", "in", "the", "ED", "component", "are", "most", "important", "while", "those", "in", "the", "ES", "module", "are", "least", "important", "(Voita et al., 2019b).", "We", "choose", "4", "different", "pruning", "percentages", "and", "in", "each", "case", "consider", "three", "configurations", "where", "the", "number", "of", "attention", "heads", "is", "least", "in", "one", "chosen", "component", "(ES,", "ED,", "DS).", "The", "configurations", "and", "corresponding", "BLEU", "scores", "on", "the", "EN-RU", "dataset", "are", "shown", "in", "Table", "3.", "We", "identify", "no", "consistent", "preference", "in", "the", "pruning", "strategy:", "In", "the", "4", "cases", "considered,", "each", "of", "the", "3", "configurations", "has", "the", "highest", "BLEU", "score", "in", "at", "least", "one", "case.", "Note", "that", "we", "chose", "the", "number", "of", "heads", "in", "each", "layer", "(14, 31, etc)", "to", "be", "consistent", "with", "those", "used", "in", "(Voita et al., 2019b).", "Varying", "Pruning", "Percentage.", "We", "vary", "the", "pruning", "percentage", "from", "10", "to", "90%", "and", "report", "the", "accuracy", "on", "the", "4", "GLUE", "tasks:", "MNLI-M,", "QQP,", "QNLI,", "and", "SST-2", "(Table", "4).", "We", "observe", "that", "half", "of", "the", "attention", "heads", "can", "be", "pruned", "with", "an", "average", "accuracy", "drop", "of", "under", "1%.", "As", "shown", "in", "Figure", "1,", "beyond", "50%", "pruning,", "the", "accuracy", "drop", "is", "sharper."], "cited_papers": [{"title": "Analyzing multihead self-attention: Specialized heads do the heavy lifting, the rest can be pruned", "year": "2019", "authors": ["Elena Voita", "David Talbot", "Fedor Moiseev", "Rico Sennrich", "Ivan Titov"]}], "target_citation_location": 25, "citation_locations": [25, 109, 117], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "22f0478c-5eab-4828-975f-6eb106cb9094", "citing_paper": {"title": "ROI Analysis model for Language Service Providers", "year": 2013, "authors": ["Ekaterina Stambolieva"]}, "text": ["Not", "much", "relevant", "literature", "can", "be", "found", "on", "the", "specific", "topic", "of", "estimating", "ROI", "in", "a", "LSP", "context.", "Nonetheless,", "different", "language", "and", "translation", "technology", "professionals", "have", "invested", "time", "and", "effort", "into", "discussing", "business", "and", "pricing", "models,", "which", "shed", "more", "light", "on", "ROI", "calculation.", "Sojn\u00f3czky (2013)", "emphasizes", "on", "margin", "calculation", "and", "stakeholders'", "satisfaction", "in", "the", "case", "when", "MT", "output", "is", "post-edited", "and", "delivered", "to", "the", "clients.", "Sojn\u00f3czky,", "the", "managing", "director", "of", "Hunnect", "1,", "implements", "a", "business", "model,", "which", "concentrates", "on", "margin", "shrinking", "benefits", "and", "its", "results", "are", "directly", "projected", "to", "clients'", "and", "translators'", "satisfaction.", "Sojn\u00f3czky (2013)", "does", "not", "discuss", "LSP", "costs", "for", "internal", "MT", "development.", "He", "emphasizes", "on", "margin", "shrinking,", "which", "is", "directly", "linked", "to", "investment", "gain.", "Hunnect's", "translation", "provision", "process", "involves", "three", "tasks", "-translation,", "bilingual", "editing", "and", "proofing.", "The", "time", "estimation", "of", "these", "tasks", "per", "order,", "shown", "in", "percentage,", "is", "the", "following:", "translation", "requires", "50%", "of", "the", "time,", "editing", "-20%,", "proofing", "-5%,", "and", "the", "rest", "25%", "is", "the", "marginal", "buffer", "time.", "The", "time", "management", "planning", "for", "the", "post-edited", "MT", "output", "is", "as", "follows:", "20%", "of", "the", "time", "is", "devoted", "to", "translation,", "30%", "-for", "post-editing", "(PE),", "5%", "for", "proofing.", "The", "other", "45%", "of", "the", "time", "is", "the", "margin", "time", "until", "delivery.", "In", "reality,", "Sojn\u00f3czky", "(2013)", "observes", "the", "margin", "time", "left", "after", "translation,", "postediting", "and", "proofing", "for", "Hunnect's", "case", "is", "50%.", "Therefore,", "the", "use", "of", "MT", "in", "the", "translation", "process", "reduced", "the", "delivery", "time", "or", "35%", "savings", "of", "time.", "35%", "savings", "of", "time", "results", "in", "\u2026", "quicker", "potential", "ROI.", "The", "vendor", "pricing", "scheme", "implemented", "by", "Sojn\u00f3czky (2013)", "is", "that", "postedited", "MT", "is", "paid", "60%", "of", "the", "original", "price.", "Consequently,", "the", "company", "cost", "for", "delivering", "an", "order", "is", "reduced", "by", "40%", "and", "time", "to", "delivery", "is", "increased", "by", "35%.", "As", "mentioned", "in", "Section", "7,", "managers", "need", "to", "be", "careful", "when", "developing", "vendor", "pricing", "model", "strategies", "as", "it", "is", "a", "sensitive", "matter.", "Additionally,", "Sojn\u00f3czky", "(2013)", "observes", "68%", "increase", "of", "productivity", "among", "trained", "to", "post-edit", "translators,", "which", "reflects", "directly", "the", "translators'", "pay.", "The", "statistics", "Sojn\u00f3czky (2013)", "observes", "show", "that", "the", "translators'", "pay", "has", "increased", "with", "at", "least", "1%", "instead", "of", "decreasing", "as", "feared."], "cited_papers": [{"title": "Hunnect's Use Case. TAUS Machine Translation Showcase at Localization World", "year": "2013", "authors": ["Sa\u00e1ndor Sojn\u00f3czky"]}], "target_citation_location": 326, "citation_locations": [43, 92, 251, 326], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]]}
{"id": "23336cc2-a7d6-4382-ab4d-b572593325f3", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["Once", "the", "best", "performing", "adapted", "language", "models", "were", "identified,", "we", "tried", "to", "further", "boost", "the", "performance", "by", "providing", "the", "HPB", "SMT", "system", "with", "target-side", "syntactic", "information", "extracted", "using", "CCG", "resources", "[5].", "We", "used", "CCG", "categories", "to", "label", "non-terminals", "in", "hierarchical", "rules.", "Different", "CCG-based", "labeling", "approaches", "were", "explored,", "each", "focussing", "on", "a", "different", "aspect", "of", "information", "reflected", "in", "CCG", "categories.", "The", "best", "performing", "system", "was", "a", "CCGaugmented", "HPB", "system", "for", "both", "language", "pairs", "providing", "a", "statistically", "significant", "improvement", "of", "0.93", "absolute", "BLEU", "points", "(3.25%", "relative)", "and", "0.44", "absolute", "BLEU", "points", "(3.7%", "relative)", "over", "the", "Ar-En", "and", "Zh-En", "mixture-adapted", "PB-SMT", "baselines,", "respectively."], "cited_papers": [{"title": "The syntactic process", "year": "2000", "authors": ["M Steedman"]}], "target_citation_location": 30, "citation_locations": [30], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0]]}
{"id": "23972ba3-c07a-4163-8f5b-354926150014", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["Evaluation", "Metrics:", "Historically,", "performance", "on", "the", "explanation", "regeneration", "task", "was", "evaluated", "using", "Mean", "Average", "Precision", "(MAP),", "using", "the", "binary", "ratings", "(gold", "or", "not", "gold)", "associated", "with", "each", "fact", "for", "a", "given", "explanation.", "To", "leverage", "the", "new", "graded", "annotation", "schema,", "here", "we", "switch", "to", "evaluate", "system", "performance", "using", "Normalized", "Discounted", "Cumulative", "Gain", "(NDCG)", "(J\u00e4rvelin and Kek\u00e4l\u00e4inen, 2002, Wang et al., 2013)."], "cited_papers": [{"title": "A Theoretical Analysis of NDCG Type Ranking Measures", "year": "2013", "authors": ["Yining Wang", "Liwei Wang", "Yuanzhi Li", "Di He", "Tie-Yan Liu"]}, {"title": "Cumulated Gain-Based Evaluation of IR Techniques", "year": "2002", "authors": ["Kalervo J\u00e4rvelin", "Jaana Kek\u00e4l\u00e4inen"]}], "target_citation_location": 52, "citation_locations": [52], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]]}
{"id": "23ab0f96-aed1-42b9-b134-1d5bf34a6f80", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["The", "same", "approach", "is", "applied", "on", "diacritic", "model", "instead", "of", "using", "character", "information", "we", "use", "diacritics", "and", "instead", "of", "using", "C-Bi-LSTM", "we", "use", "D-Bi-LSTM.", "We", "extract", "the", "forward", "and", "backward", "outputs", "of", "the", "trained", "D-Bi-LSTM", "as", "individually-trained", "diacritic", "embeddings.", "It", "is", "worth", "noting", "that", "both", "of", "these", "models", "are", "trained", "on", "diacritized", "version", "of", "the", "datasets.", "Also", "it", "is", "important", "to", "mention", "that", "the", "output", "from", "this", "step", "are", "weights", "to", "initialize", "the", "character", "and", "diacritic", "embedding", "layers", "in", "the", "combination", "model", "and", "both", "of", "these", "sets", "of", "weights", "have", "been", "trained", "individually", "in", "separate", "models.", "The", "justification", "of", "this", "step", "can", "be", "found", "in", "Section", "(6)", "Table (2)", "where", "the", "experiments", "showed", "that", "training", "these", "embeddings", "separately", "and", "using", "them", "as", "individually-trained", "embedding", "in", "the", "final", "model", "improves", "the", "performance."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 107, "citation_locations": [107], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "23b51f34-ef91-454c-a447-138c67705d6a", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["In", "order", "to", "accomplish", "the", "high-performance", "natural", "language", "processing,", "we", "have", "designed", "a", "highly", "parallel", "machine", "called", "Semantic", "Network", "Array", "Processor", "(SNAP)", "[Moldovan", "and", "Lee, 1990]", "[Lee and Moldovan, 1990],", "and", "implemented", "an", "experimental", "machine", "translation", "system", "*This", "research", "is", "funded", "by", "the", "National", "Science", "Foundation", "Grant", "No..", "A", "version", "of", "this", "paper", "will", "appear", "in", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "(IJCAI-91)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 25, "citation_locations": [24, 25], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "23e34678-62e1-4d4e-8b44-1f5225221bd5", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["To", "this", "end,", "the", "alignment", "process", "involves", "training", "three", "BERT-based (Devlin et al., 2018)", "biencoder", "retrieval", "models", "to", "retrieve", "the", "most", "likely", "characters,", "locations,", "and", "objects", "required", "flesh", "the", "environment", "out", "and", "make", "the", "quest", "achievable.", "We", "use", "the", "same", "biencoder", "architecture", "proposed", "by", "Urbanek et al. (2019)", "which", "encodes", "context", "using", "one", "transformer", "and", "candidates", "with", "anotherscoring", "candidates", "via", "inner", "product", "between", "the", "two", "encoded", "vectors.", "The", "character", "retrieval", "model", "is", "conditioned", "on", "the", "initial", "character,", "quest,", "and", "location-producing", "additional", "characters", "required", "to", "complete", "the", "world."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 40, "citation_locations": [9, 40], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "24726e53-1586-4fb3-be5d-8b78739fa560", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["There", "is", "a", "growing", "trend", "in", "using", "adversarial", "models", "for", "data", "creation", "to", "make", "the", "dataset", "more", "challenging", "or", "discard", "examples", "that", "can", "be", "solved", "using", "surface", "cues", "(Bartolo et al., 2020, Nie et al., 2020, Yang et al., 2018a, Zellers et al., 2018, Yang et al., 2018b, Dua et al., 2019, Chen et al., 2019, Dasigi et al., 2019).", "Quoref", "is", "also", "created", "using", "an", "adversarial", "data", "collection", "method", "to", "discard", "examples", "that", "can", "be", "solved", "using", "simple", "lexical", "cues.", "The", "assumption", "is", "that", "it", "is", "hard", "to", "avoid", "simple", "lexical", "cues", "by", "which", "the", "model", "can", "answer", "questions", "without", "coreference", "reasoning.", "Therefore,", "an", "adversarial", "model", "(A)", "is", "used", "to", "discard", "examples", "that", "contain", "such", "lexical", "cues.", "While", "this", "adversarial", "filtering", "removes", "examples", "that", "are", "easy", "to", "solve", "by", "A,", "it", "does", "not", "ensure", "that", "the", "remaining", "examples", "do", "not", "contain", "shortcuts", "that", "are", "not", "explored", "by", "A.", "First,", "the", "adversarial", "model", "in", "Quoref", "is", "trained", "on", "another", "dataset,", "i.e.,", "SQuAD.", "Thus,", "the", "failure", "of", "A", "on", "Quoref", "examples", "may", "be", "due", "to", "(1)", "Quoref", "having", "different", "lexical", "cues", "than", "those", "in", "SQuAD,", "or", "(2)", "domain", "shift.", "Second,", "and", "more", "importantly,", "as", "argued", "by", "Dunietz et al. (2020),", "making", "the", "task", "challenging", "by", "focusing", "on", "examples", "that", "are", "more", "difficult", "for", "existing", "models", "is", "not", "a", "solution", "for", "more", "useful", "reading", "comprehension.", "7", "We", "instead", "propose", "a", "methodology", "for", "creating", "question-answer", "pairs", "as", "follows:"], "cited_papers": [{"title": "To test machine comprehension, start by defining comprehension", "year": "2020", "authors": ["Jesse Dunietz", "Greg Burnham", "Akash Bharadwaj", "Owen Rambow", "Jennifer Chu-Carroll", "Dave Ferrucci"]}], "target_citation_location": 164, "citation_locations": [28, 164], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0]]}
{"id": "24a9b5c3-fd63-4fbe-bda1-ea7fc5fd8565", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["Southern", "Quechua:", "with", "6+", "millions", "of", "speakers", "and", "several", "variants,", "it", "is", "the", "most", "widespread", "indigenous", "language", "in", "Peru.", "AmericasNLP", "provides", "evaluation", "sets", "in", "the", "standard", "Southern", "Quechua,", "which", "is", "based", "mostly", "on", "the", "Quechua", "Ayacucho", "(quy)", "variant.", "There", "is", "parallel", "data", "from", "dictionaries", "and", "Jehovah", "Witnesses", "(Agi\u0107 and Vuli\u0107, 2019).", "There", "is", "parallel", "corpus", "aligned", "with", "English", "too.", "We", "also", "include", "the", "close", "variant", "of", "Quechua", "Cusco", "(quz)", "to", "support", "the", "multilingual", "learning.", "Aymara", "(aym):", "with", "1.7", "million", "of", "speakers", "(mostly", "in", "Bolivia).", "The", "parallel", "and", "monolingual", "data", "is", "extracted", "from", "a", "news", "website", "(Global", "Voices)", "and", "distributed", "by", "OPUS", "(Tiedemann, 2012).", "There", "are", "aligned", "data", "with", "English", "too.", "Shipibo-Konibo", "(shp):", "a", "Panoan", "language", "with", "almost", "30,000", "speakers", "in", "the", "Amazonian", "region.", "There", "are", "parallel", "data", "from", "dictionaries,", "educational", "material", "(Galarreta et al., 2017),", "language", "learning", "flashcards", "(G\u00f3mez", "Montoya et al., 2019),", "plus", "monolingual", "data", "from", "educational", "books", "(Bustamante et al., 2020).", "Ashaninka", "(cni):", "an", "Arawakan", "language", "with", "45,000", "speakers", "in", "the", "Amazon.", "There", "is", "parallel", "data", "from", "dictionaries,", "laws", "and", "books", "(Ortega et al., 2020a),", "plus", "monolingual", "corpus", "(Bustamante et al., 2020)."], "cited_papers": [{"title": "No data to crawl? monolingual corpus creation from PDF files of truly low-resource languages in Peru", "year": "2020", "authors": ["Gina Bustamante", "Arturo Oncevay", "Roberto Zariquiey"]}], "target_citation_location": 139, "citation_locations": [47, 98, 127, 132, 139, 160, 164], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "24cd0192-3f54-469a-b77e-6ec41cb39232", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["Researchers", "usually", "regard", "the", "sentence", "simplification", "task", "as", "a", "monolingual", "variant", "of", "machine", "translation", "(MT)", "(Wubben et al., 2012).", "Benefiting", "from", "the", "advancement", "of", "neural", "machine", "translation,", "this", "task", "has", "also", "made", "great", "progress", "in", "recent", "years."], "cited_papers": [{"title": "Sentence simplification by monolingual machine translation", "year": "2012", "authors": ["Sander Wubben"]}], "target_citation_location": 15, "citation_locations": [15], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "255c1009-cf0c-4829-a40c-b2d42b11e384", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["Algorithm", "1", "Metric", "of", "Higgins et al. (2017)", "1:", "D", "=", "\u2205", "2:", "for", "f", "i", "\u2208", "F", "do", "3:", "for", "n", "=", "1,", "2,...,", "N", "do", "4:", "Sample", "s", "n", "from", "j", "S", "ij", "5:", "Find", "the", "value", "v", "ij", "on", "f", "i", "for", "s", "n", "6:", "Sample", "(z", "(1)", "1", ",...,", "z", "(1)", "L)", "from", "R", "ij", "7:", "Sample", "(z", "(2)", "1", ",...,", "z", "(2)", "L)", "from", "R", "ij", "8:", "z", "n", "=", "1", "L", "L", "l=1", "|z", "(1)", "l", "\u2212", "z", "(2)", "l", "|", "9:", "D", "=", "{(z", "n,", "f", "i", ")}", "D", "10:", "Split", "D", "into"], "cited_papers": [{"title": "beta-vae: Learning basic visual concepts with a constrained variational framework", "year": "2017", "authors": ["Irina Higgins", "Lo\u00efc Matthey", "Arka Pal", "Christopher Burgess", "Xavier Glorot", "Matthew Botvinick", "Shakir Mohamed", "Alexander Lerchner"]}], "target_citation_location": 4, "citation_locations": [4], "citation_type": "single", "annotations": [[3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "2579964a-617e-48a0-8847-28ad3107860f", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["Most", "of", "the", "previous", "studies", "have", "attempted", "to", "extract", "and", "link", "at", "formula", "level", "(Nghiem Quoc et al., 2010, Kristianto et al., 2014 Kristianto et al., , 2016)).", "In", "reality,", "understanding", "mathematical", "formulae", "requires", "details", "of", "atomic", "symbols", "e.g.", "superscript,", "subscript,", "function", "arguments.", "We", "believe", "that", "addressing", "the", "problem", "at", "this", "fine-grain", "level", "is", "crucial", "to", "drive", "future", "research", "toward", "a", "better", "understanding", "of", "the", "complex", "symbol-description", "extraction", "task."], "cited_papers": [{"title": "Entity linking for mathematical expressions in scientific documents", "year": "2016", "authors": ["Giovanni Kristianto", "Goran Topi\u0107", "Akiko Aizawa"]}, {"title": "Extracting textual descriptions of mathematical expressions in scientific papers. D-Lib Magazine", "year": "2014", "authors": ["Giovanni Kristianto", "Akiko Aizawa"]}, {"title": "Mining coreference relations between formulas and text using Wikipedia", "year": "2010", "authors": ["Minh Nghiem Quoc", "Keisuke Yokoi"]}], "target_citation_location": 14, "citation_locations": [14], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "25cb89b4-8d45-4a96-84ea-bd8fdeb7cf59", "citing_paper": {"title": "Entity Attribute Relation Extraction with Attribute-Aware Embeddings", "year": 2020, "authors": ["Dan Iter", "Xiao Yu", "Fangtao Li"]}, "text": ["Modern", "search", "engines", "often", "attempt", "to", "provide", "structured", "search", "results", "that", "reveal", "more", "facets", "of", "the", "search", "query", "than", "explicitly", "requested.", "These", "results", "rely", "on", "knowledge", "bases", "that", "contain", "tuples", "of", "the", "form", "(entity,", "attribute,", "value).", "However,", "the", "number", "of", "known", "entities", "and", "attributes", "in", "these", "knowledge", "bases", "is", "limited", "and", "there", "is", "a", "long", "tail", "of", "both", "entities", "and", "attributes", "that", "is", "too", "large", "to", "be", "manually", "curated.", "The", "goal", "of", "automatic", "entityattribute", "extraction", "is", "to", "replace", "manual", "knowledge", "acquisition", "which", "is", "expensive", "and", "biased", "towards", "popular", "entities", "(Bollacker et al., 2008, Dong et al., 2014).", "Previous", "studies", "have", "proposed", "model-based", "approaches", "that", "use", "various", "NLP", "features,", "distant", "supervision", "and", "traditional", "machine", "learning", "methods", "for", "entity-attribute", "extraction", "but", "*", "Work", "done", "during", "an", "internship", "at", "Google.", "their", "precision", "has", "not", "been", "high", "enough", "to", "replace", "manually", "curated", "knowledge", "bases", "(Auer et al., 2007, Carlson et al., 2010, Gupta et al., 2014)."], "cited_papers": [{"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "year": "2008", "authors": ["Kurt Bollacker", "Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"]}, {"title": "Knowledge vault: A web-scale approach to probabilistic knowledge fusion", "year": "2014", "authors": ["Xin Dong", "Evgeniy Gabrilovich", "Geremy Heitz", "Wilko Horn", "Ni Lao", "Kevin Murphy", "Thomas Strohmann", "Shaohua Sun", "Wei Zhang"]}], "target_citation_location": 89, "citation_locations": [89, 133], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "25e623a7-e342-49b6-a9fa-0cec1a3e85be", "citing_paper": {"title": "Situation-Specific Multimodal Feature Adaptation", "year": 2021, "authors": ["\u00d6zge Alac"]}, "text": ["Model.", "The", "proposed", "method", "will", "be", "able", "to", "process", "several", "modalities", "that", "play", "a", "crucial", "role", "in", "communication,", "(i)", "Linguistic", "Information", "(at", "syntactic", "and", "semantic", "level),", "(ii)", "Situational", "Information,", "(iii)", "Prototypical", "Knowledge", "and", "Relations,", "and", "(iv)", "Speech-accompanying", "eye-movements", "of", "the", "speaker.", "The", "initial", "base", "model", "will", "focus", "on", "the", "first", "three", "capabilities", "by", "utilizing", "data-driven", "language", "models", "such", "as", "fasttext", "(Bojanowski et al., 2017)", "and", "commonsense", "knowledge-bases", "like", "ConceptNet", "(Speer et al., 2017).", "At", "the", "same", "time,", "two", "modules", "that", "(i)", "incorporate", "eye-movements", "and", "(ii)", "perform", "situation-specific", "feature", "adaptation", "will", "be", "developed", "from", "scratch.", "In", "brief,", "vocabulary", "obtained", "from", "the", "pre-trained", "embeddings", "is", "used", "as", "a", "bridge", "between", "the", "modalities.", "For", "each", "vocabulary", "item,", "multimodal", "embeddings", "will", "be", "created", "by", "processing", "every", "input", "channel,", "see", "Figure", "2.", "For", "each", "modality", "and", "their", "joint", "training,", "we", "will", "utilize", "an", "appropriate", "encoder,", "such", "as", "Fast-R-CNN", "(Girshick, 2015)", "for", "images", "and", "attention-based", "bi-directional", "LSTMs", "(e.g.", "Song et al. (2019),", "for", "text", "and", "eye-movement", "data.", "A", "neural", "network", "ensemble", "model", "will", "be", "trained", "on", "the", "embeddings", "for", "the", "task", "of", "intended", "object", "or", "action", "prediction", "from", "situated", "settings", "with", "masked", "information."], "cited_papers": [{"title": "Abstractive text summarization using lstm-cnn based deep learning", "year": "2019", "authors": ["Shengli Song", "Haitao Huang", "Tongxiao Ruan"]}], "target_citation_location": 145, "citation_locations": [60, 66, 137, 145], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "265eed67-b084-427c-8fb3-15fb0366b114", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["In", "this", "section,", "we", "discuss", "individual", "modules", "for", "operationalizing", "the", "PSL", "rules.", "For", "each", "module,", "we", "fine-tune", "the", "pretrained", "uncased", "BERT-base", "(Devlin et al., 2019).", "We", "use", "the", "Transformers", "library", "v3.3.0", "(Wolf et al., 2020)", "for", "high", "reproducibility", "and", "low", "development", "costs.", "But", "any", "other", "models", "could", "be", "used", "instead.", "Each", "dataset", "used", "is", "randomly", "split", "with", "a", "ratio", "of", "9:1", "for", "training", "and", "test.", "Cross-entropy", "and", "Adam", "are", "used", "for", "optimization.", "To", "address", "the", "imbalance", "of", "classes", "and", "datasets,", "the", "loss", "for", "each", "training", "instance", "is", "scaled", "by", "a", "weight", "inversely", "proportional", "to", "the", "number", "of", "its", "class", "and", "dataset."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 21, "citation_locations": [21, 28], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "267a1732-5688-45ce-b1d5-f6aad2c0ecd4", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["We", "follow", "the", "mainstream", "method", "(Yang et al., 2020, Kong et al., 2020, Reid et al., 2020)", "to", "concatenate", "the", "word", "and", "context", "together", "with", "a", "special", "token", "[SEP]", "as", "x", "=", "(w", "*,", "[SEP],", "c).", "The", "entire", "sequence", "is", "then", "fed", "into", "SimpDefiner,", "and", "the", "definition", "is", "obtained", "by", "the", "following", "language", "model:"], "cited_papers": [{"title": "VCDM: Leveraging Variational Biencoding and Deep Contextualized Word Representations for Improved Definition Modeling", "year": "2020", "authors": ["Machel Reid", "Edison Marrese-Taylor", "Yutaka Matsuo"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "270898ca-bbc5-4d63-afef-c51e70da288c", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["End-to-end", "automatic", "speech", "recognition", "(E2E", "ASR),", "which", "transcribes", "speech", "using", "a", "single", "neural", "network", "(NN),", "has", "recently", "gained", "traction", "(Graves and Jaitly, 2014, Chorowski et al., 2015, Chan et al., 2016, Graves, 2012, Dong et al., 2018).", "Existing", "E2E", "ASR", "models", "generate", "audio", "transcripts", "by", "sequentially", "producing", "likely", "graphemes,", "or", "multi-graphemic", "units,", "from", "which", "lexical", "items", "of", "a", "language", "can", "be", "recovered.", "However,", "other", "linguistic", "annotations", "such", "as", "phonemic", "transcripts,", "part-of-speech", "(POS)", "tags,", "or", "word", "boundaries,", "help", "understand", "the", "underlying", "audio", "characteristics", "(Simonnet et al., 2017).", "Such", "linguistic", "annotations", "are", "especially", "important", "in", "natural", "language", "processing", "(NLP)", "tasks", "done", "on", "audio", "!!!", "\"", "!\"!", "#", "\"", "#\"!", "#", "$", "#", "\"", "$!", "\"!", "\"", "!\"#", "#", "\"", "#\"#", "#", "$", "#", "\"", "$", "\"", "\"#", "\"", "#", "\"", "#", "\"", "#", "\"", "#", "$", "#", "\"", "#", "\""], "cited_papers": [{"title": "Speech-Transformer: A no-recurrence sequence-to-sequence model for speech recognition", "year": "2018", "authors": ["L Dong", "S Xu", "B Xu"]}, {"title": null, "year": "2012", "authors": ["A Graves"]}, {"title": "Attention-based models for speech recognition", "year": "2015", "authors": ["J Chorowski", "D Bahdanau", "D Serdyuk", "K Cho", "Y Bengio"]}, {"title": "Listen, attend and spell: A neural network for large vocabulary conversational speech recognition", "year": "2016", "authors": ["W Chan", "N Jaitly", "Q Le", "O Vinyals"]}, {"title": "Towards end-to-end speech recognition with recurrent neural networks", "year": "2014", "authors": ["A Graves", "N Jaitly"]}], "target_citation_location": 19, "citation_locations": [19, 65], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "274a4ae9-80e8-43f8-b06f-c115bfbf88c8", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["For", "linear", "SVM,", "we", "used", "an", "online", "learning", "implementation", "of", "SCIKIT-LEARN", "(Pedregosa et al., 2011, Zhang, 2004),", "based", "on", "LIBSVM", "(Chang and Lin, 2011),", "with", "hinge", "loss", "and", "Stochastic", "Gradient", "Descent", "(SGD)", "optimiser.", "Hyperparameters", "were", "set", "to", "default", "except", "for", "the", "SGD", "regularisation", "parameter", "that", "was", "increased", "to", "\u03b1", "=", "0.75,", "which", "provided", "better", "classification", "accuracy", "on", "the", "dev", "set.", "The", "parameter", "\u03b1", "is", "inversely", "proportional", "to", "the", "C", "parameter", "in", "the", "standard", "SVM", "implementation.", "The", "online", "implementation", "also", "allowed", "us", "to", "select", "the", "best", "model", "using", "early", "stopping.", "The", "SVM", "was", "provided", "with", "EEG", "activity", "vectors", "as", "inputs,", "i.e.", "1", "x", "(EEG", "channels", "\u00d7", "time", "points)."], "cited_papers": [{"title": "LIBSVM: A library for support vector machines", "year": "2011", "authors": ["Chih-Chung Chang", "Chih-Jen Lin"]}], "target_citation_location": 15, "citation_locations": [11, 15], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "27ad00a2-aae6-411c-86df-5488f3606005", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["The", "downside", "of", "datasets", "trained", "on", "Twitter", "is", "that", "they", "are", "likely", "not", "that", "good", "at", "classifying", "anything", "other", "than", "tweets.", "It", "is", "plausible", "that", "datasets", "trained", "on", "less", "specific", "data", "such", "as", "XED", "and", "those", "created", "by", "Tokuhisa et al. (2008)", "and", "Demszky et al. (2020)", "are", "better", "at", "crossing", "domains", "at", "the", "cost", "of", "evaluation", "metrics."], "cited_papers": [{"title": "Emotion classification using massive examples extracted from the web", "year": "2008", "authors": ["Ryoko Tokuhisa", "Kentaro Inui", "Yuji Matsumoto"]}], "target_citation_location": 38, "citation_locations": [38, 40], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "27d7c260-35f9-4df8-a6ee-bd4554b8552f", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["If", "there", "is", "no", "source", "text,", "the", "focus", "obviously", "falls", "upon", "the", "generation", "of", "the", "target", "text(s),", "a", "problem", "in", "MT", "which", "was", "for", "a", "long", "time", "seriously", "underestimated", "(cf.", "[27]", ").", "Our", "present", "approach", "has", "been", "influenced", "by", "the", "'phrasebook'", "approach", "to", "speech", "translation", "[44],", "in", "which", "set", "phrases", "are", "stored,", "as", "in", "a", "holidaymaker's", "phrasebook,", "and", "retrieved", "by", "the", "fairly", "crude,", "though", "effective,", "technique", "of", "recognising", "keywords", "in", "a", "particular", "order", "in", "the", "input", "speech", "signal.", "It", "also", "builds", "on", "research", "on", "interactive", "generation", "of", "stereotypical", "texts", "([1, 19, 35]", "),", "where", "texts", "in", "certain", "restricted", "domains", "are", "stored", "and", "retrieved", "as", "appropriate", "through", "interaction", "with", "users,", "and", "are", "reformulated", "to", "fulfill", "the", "specific", "requirements", "expressed", "by", "them."], "cited_papers": [{"title": "Speech language translation", "year": "1989", "authors": ["M Steer", "F Stentiford"]}], "target_citation_location": 45, "citation_locations": [30, 45, 89], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "283ac499-5a7a-48da-933c-a376cb876cb3", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["All", "models", "are", "implemented", "based", "on", "the", "opensource", "transformers", "library", "of", "hugging", "face", "(Wolf et al., 2020),", "which", "provides", "thousands", "of", "pretrained", "models", "that", "can", "be", "quickly", "downloaded", "and", "fine-tuned", "on", "specific", "tasks.", "of", "doing", "this", "in", "Table", "3", "and", "we", "can", "find", "that", "it", "is", "very", "effective", "by", "increasing", "0.02", "from", "base", "models."], "cited_papers": [{"title": "Transformers: State-of-theart natural language processing", "year": "2020", "authors": ["Thomas Wolf"]}], "target_citation_location": 13, "citation_locations": [13], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "285e25e4-bd31-4b12-9fca-da525e631efb", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["word", "embeddings", "extracted", "from", "the", "first", "layer", "of", "the", "GPT2", "language", "model", "(Radford et al., 2019)."], "cited_papers": [{"title": "Language models are unsupervised multitask learners", "year": "2019", "authors": ["Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever"]}], "target_citation_location": 12, "citation_locations": [12], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1]]}
{"id": "287d6e36-dd61-4117-a089-af9e83bb375a", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["SNAP", "provides", "four", "knowledge", "representation", "elements:", "node,", "link,", "node", "color", "and", "link", "value.", ", 1985],", "Conceptual", "Graphs", "[Sowa, 1984],", "KODIAK", "[Wilensky, 1987],", "etc."], "cited_papers": [{"title": "Experiments and Prospects of Example-Based Machine Translation", "year": "1986", "authors": ["C Stanfill", "D Waltz", "E Sumita", "H Iida", "H Tomabechi", "R Wilensky"]}], "target_citation_location": 18, "citation_locations": [13, 16, 18], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3]]}
{"id": "29265126-45b5-4048-ac86-c26fd6284b64", "citing_paper": {"title": "ROI Analysis model for Language Service Providers", "year": 2013, "authors": ["Ekaterina Stambolieva"]}, "text": ["Opposed", "to", "Sojn\u00f3czky (2013 ), McMahon (2009)", "estimates", "the", "post-editing", "costs", "of", "a", "commercial", "business", "for", "instant", "communication", "messaging", "translation.", "Interestingly,", "his", "cost", "estimations", "cover", "corpus", "management", "and", "acquisition,", "5", "to", "200", "GBP", "per", "year,", "customization", "costs,", "human", "resources", "training,", "5", "to", "10", "GBP", "per", "year,", "among", "others.", "He", "measures", "investment", "cost", "of", "product", "licenses", "to", "100", "GBP", "per", "year.", "Overall,", "the", "total", "investment", "costs", "are", "estimated", "to", "180", "GBP", "per", "year.", "The", "predicted", "ROI", "for", "the", "first", "year", "after", "successful", "MT", "implementation", "equals", "to", "minus", "30000", "GBP,", "therefore", "is", "negative", "speaking", "in", "financial", "terms.", "The", "vendor", "pricing", "models", "is", "estimated", "to", "65-85%", "of", "the", "original", "pay", "per", "word.", "What", "is", "intriguing", "is", "the", "fact", "benefits", "are", "not", "only", "measured", "in", "money.", "McMahon (2009),", "as", "Sojn\u00f3czky (2013),", "measures", "the", "user", "satisfaction", "rate,", "which", "in", "the", "case", "of", "Lionbridge", "2", "has", "increased", "with", "30-50%.", "The", "success", "rate", "measured", "varies", "between", "5%", "and", "25%."], "cited_papers": [{"title": "Hunnect's Use Case. TAUS Machine Translation Showcase at Localization World", "year": "2013", "authors": ["Sa\u00e1ndor Sojn\u00f3czky"]}, {"title": "Lionbridge Technology Overview: Technology Best Practice. Paper presented online", "year": "2009", "authors": ["Nicholas Mcmahon"]}], "target_citation_location": 2, "citation_locations": [2, 118, 120], "citation_type": "group", "annotations": [[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "295ea4c7-e46c-44ac-9d95-0552c17e5085", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["To", "date,", "several", "approaches", "to", "automated", "detection", "of", "abusive", "language", "have", "been", "proposed,", "including", "rule-based", "(Spertus, 1997, Razavi et al., 2010, Wiegand et al., 2018),", "linguistic", "and", "social", "feature", "engineering", "(Yin et al., 2009, Sood et al., 2012, Warner and Hirschberg, 2012, Salminen et al., 2018),", "utilizing", "distributed", "representations", "from", "neural", "networks", "(Djuric et al., 2015, Mehdad and Tetreault, 2016, Nobata et al., 2016)", "or", "applying", "deep", "neural", "networks", "directly", "(Park and Fung, 2017, Pavlopoulos et al., 2017a, Mishra et al., 2018a).", "Researchers", "have", "also", "explored", "multi-task", "learning", "settings", "with", "objectives", "such", "as", "emotion", "detection", "(Rajamanickam et al., 2020, Samghabadi et al., 2019).", "We", "refer", "the", "reader", "to", "recent", "surveys", "of", "the", "field", "(Schmidt and Wiegand, 2017, Fortuna and Nunes, 2018)", "for", "a", "detailed", "literature", "review."], "cited_papers": [{"title": "A survey on automatic detection of hate speech in text", "year": "2018", "authors": ["Paula Fortuna", "S\u00e9rgio Nunes"]}, {"title": "A survey on hate speech detection using natural language processing", "year": "2017", "authors": ["Anna Schmidt", "Michael Wiegand"]}], "target_citation_location": 60, "citation_locations": [15, 21, 28, 35, 49, 60], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "2994f6b0-d299-4e8c-8a55-cde8f5ea8fff", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["The", "most", "common", "method", "of", "measuring", "the", "quality", "of", "a", "MT", "metric", "is", "correlation", "with", "human", "judgments", "(Fomicheva and Specia, 2019),", "however,", "these", "correlations", "provide", "little", "information", "regard-ing", "when", "and", "why", "an", "MT", "metric", "differs", "from", "human", "judgment.", "In", "this", "paper,", "we", "consider", "three", "ways", "of", "examining", "MT", "metric", "quality,", "with", "the", "aim", "of", "determining", "the", "failure", "cases", "of", "MT", "metrics."], "cited_papers": [{"title": "Taking MT Evaluation Metrics to Extremes: Beyond Correlation with Human Judgments", "year": "2019", "authors": ["Marina Fomicheva", "Lucia Specia"]}], "target_citation_location": 17, "citation_locations": [17], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "299dd97f-5bc0-4748-bc9c-a4c1737a5e69", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["To", "tackle", "those", "challenges,", "most", "existing", "approaches", "(Li et al., 2021, Gan et al., 2020, Chen et al., 2020, Lu et al., 2019)", "adopt", "a", "two-step", "pretraining", "strategy", "that", "firstly", "utilizes", "off-the-shelf", "detectors", "to", "parse", "images", "into", "a", "set", "of", "object", "tokens,", "and", "then", "builds", "a", "multi-layer", "Transformer", "to", "learn", "visual", "and", "language", "embeddings", "jointly.", "In", "order", "to", "facilitate", "the", "multi-modal", "learning,", "those", "networks", "are", "typically", "trained", "via", "a", "set", "of", "carefully", "designed", "BERT-like", "objectives", "(e.g.", "Image-Text", "Matching).", "Despite", "its", "promising", "performance,", "the", "two-step", "strategy", "suffers", "from", "several", "limitations:", "1)", "limited", "visual", "object", "concepts", "as", "the", "external", "detectors", "are", "trained", "on", "a", "predefined", "set", "of", "object", "categories,", "2)", "lack", "of", "context", "cues", "outside", "of", "the", "object", "regions,", "which", "are", "crucial", "for", "complex", "reasoning", "tasks,", "3)", "sub-optimal", "visual", "representation", "due", "to", "stage-wise", "training,", "and", "4)", "computational", "inefficiency", "caused", "by", "additional", "detection", "modules.", "To", "overcome", "those", "limitations,", "recent", "works", "attempt", "to", "learn", "a", "joint", "visual-linguistic", "representations", "in", "an", "end-to-end", "manner", "(Huang et al., 2021 (Huang et al., , 2020,, Xu et al., 2021, Kim et al., 2021).", "These", "methods", "directly", "take", "dense", "visual", "features", "from", "image", "grids", "as", "inputs", "to", "a", "multi-modal", "Transformer", "network,", "and", "hence", "do", "not", "rely", "on", "external", "object", "detectors", "in", "both", "pretraining", "and", "finetuning", "stages.", "Such", "model", "design", "significantly", "simplifies", "overall", "network", "architecture", "and", "allows", "deeper", "integration", "between", "visual", "and", "language", "features.", "However,", "using", "grid-level", "features", "makes", "it", "difficult", "to", "capture", "object-level", "visual", "concepts,", "which", "often", "results", "in", "less", "expressive", "multi-modal", "representations", "and", "inferior", "performances", "in", "downstream", "tasks."], "cited_papers": [{"title": "E2e-vlp: End-to-end vision-language pre-training enhanced by visual learning", "year": "2021", "authors": ["Haiyang Xu", "Ming Yan", "Chenliang Li", "Bin Bi", "Songfang Huang", "Wenming Xiao", "Fei Huang"]}, {"title": "Pixel-bert: Aligning image pixels with text by deep multi-modal transformers", "year": "2020", "authors": ["Zhicheng Huang", "Zhaoyang Zeng", "Bei Liu", "Dongmei Fu", "Jianlong Fu"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "Vilt: Vision-and-language transformer without convolution or region supervision", "year": "2021", "authors": ["Wonjae Kim", "Bokyung Son", "Ildoo Kim"]}], "target_citation_location": 143, "citation_locations": [7, 143], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "29b6cf93-1dbe-4640-91fe-e24ca237494a", "citing_paper": {"title": "SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering", "year": 2020, "authors": ["Aishwarya Ashok", "Ganapathy Natarajan", "Ramez Elmasri", "Laurel Smith-Stvan"]}, "text": ["The", "AmazonQA", "dataset", "was", "used", "in", "this", "study", "(Gupta et al., 2019).", "The", "dataset", "has", "both", "yes/no", "(binary)", "and", "open-ended", "questions.", "The", "fields", "we", "used", "are", "question", "id,", "question", "Type,", "question", "Text,", "answers,", "review", "snippets,", "asin/", "product", "id,", "and", "category.", "The", "dataset", "was", "built", "based", "on", "previous", "parallel", "datasets", "provided", "by", "Wan and McAuley (2016)."], "cited_papers": [{"title": "Modeling ambiguity, subjectivity, and diverging viewpoints in opinion question answering systems", "year": "2016", "authors": ["Mengting Wan", "Julian Mcauley"]}], "target_citation_location": 48, "citation_locations": [8, 48], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1]]}
{"id": "29cd8dea-e9d2-461a-865b-5a9ebb0ec8d8", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["The", "results", "in", "Table", "6", "show", "that", "our", "best", "model", "beats", "all", "available", "previous", "scores", "on", "the", "English", "PMB", "3.0.0", "test", "set", "except", "for", "Pro", "Boxer and van Noord et al. (2020)", "and", "is", "also", "very", "competitive", "on", "the", "dev", "set.", "Its", "difference", "with", "the", "state-of-theart", "model", "on", "the", "test", "set", "is", "within", "1%.", "Compared", "with", "the", "best", "previous", "fully", "trainable", "compositional", "model", "in", "Bladier et al. (2021)", "2020),", "shown", "in", "Table", "7."], "cited_papers": [{"title": "Improving DRS parsing with separately predicted semantic roles", "year": "2021", "authors": ["Tatiana Bladier", "Gosse Minnema", "Rik Van Noord", "Kilian Evang"]}], "target_citation_location": 58, "citation_locations": [25, 58], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3]]}
{"id": "2a09f227-33d0-4ecf-8d4e-032a3282485d", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["To", "illustrate", "the", "same", "point,", "Amsler (1984)", "carried", "out", "a", "comparison", "between", "the", "vocabulary", "found", "in", "a", "college", "dictionary", "(Webster's", "7th)", "and", "a", "text", "corpus", "(New", "York", "Times", "News", "Service)", "and", "noted", "that", "the", "overlap", "was", "only", "23%", "of", "the", "total", "vocabulary", "in", "either", "source.", "Three", "quarters", "of", "the", "41%", "which", "only", "occurred", "in", "the", "corpus", "could", "be", "accounted", "for", "in", "terms", "of", "inflection,", "hyphenation", "at", "the", "end", "of", "a", "line,", "proper", "nouns,", "and", "obvious", "misspellings.", "Assuming", "that", "inflection", "is", "accounted", "for", "by", "a", "rule", "system,", "hyphenation", "is", "covered", "in", "a", "trivial", "pre-processing", "step,", "and", "misspellings", "are", "treated", "separately,", "proper", "nouns", "constitute", "an", "important", "source", "of", "incompleteness.", "What", "happens", "with", "the", "remaining", "quarter?", "Amsler", "states", "that", "these", "cases", "cannot", "be", "classified", "without", "individual", "inspection."], "cited_papers": [{"title": "Machine-Readable Dictionaries", "year": "1984", "authors": ["Robert Amsler"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2a16d7cf-1da9-471f-a8a0-c9164228bbe6", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["Training", "Following", "Choi et al. (2018),", "the", "loss", "is", "a", "sum", "of", "binary", "cross-entropy", "losses", "over", "all", "entity", "types", "T", "over", "all", "training", "examples", "D.", "That", "is,", "we", "treat", "each", "type", "prediction", "for", "each", "example", "as", "an", "independent", "binary", "decision,", "with", "shared", "parameters", "in", "the", "BERT", "encoder."], "cited_papers": [{"title": "Ultra-Fine Entity Typing", "year": "2018", "authors": ["Eunsol Choi", "Omer Levy", "Yejin Choi", "Luke Zettlemoyer"]}], "target_citation_location": 2, "citation_locations": [2], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2a22931e-7729-4972-a40d-a700e59a65de", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Recently,", "Zhang et al. (2021)", "and", "Mosbach et al. (2021)", "have", "nevertheless", "shown", "that", "the", "commonly", "adopted", "practices", "(the", "number", "of", "iterations,", "the", "choice", "of", "model", "layers)", "when", "fine-tuning", "Transformers-based", "langage", "models", "are", "inappropriate", "under", "resource", "constrained", "conditions", "and", "adversely", "affect", "the", "stability", "of", "models", "performances", "as", "overfitting,", "label", "noise", "memorization", "or", "catastrophic", "forgetting.", "Added", "to", "this,", "because", "the", "pretraining", "process", "is", "particularly", "constraining,", "various", "works", "have", "been", "oriented", "towards", "the", "research", "and", "training", "of", "efficient", "models,", "both", "in", "terms", "of", "available", "capacities", "and", "resources", "and", "in", "terms", "of", "environmental", "footprint."], "cited_papers": [{"title": "Revisiting fewsample {bert} fine-tuning", "year": "2021", "authors": ["Tianyi Zhang", "Felix Wu", "Arzoo Katiyar", "Q Kilian", "Yoav Weinberger", "unk Artzi"]}], "target_citation_location": 1, "citation_locations": [1, 3], "citation_type": "single", "annotations": [[1, 1, 3, 3, 1, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2a29611e-2040-46a6-a452-9851be5af9aa", "citing_paper": {"title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables", "year": 2022, "authors": ["Nan Hu", "Zirui Wu", "Yuxuan Lai", "Xiao Liu", "Yansong Feng"]}, "text": ["We", "get", "an", "increase", "of", "5.77%", "on", "the", "FEVEROUS", "score", "and", "7.91%", "on", "the", "accuracy", "over", "the", "previous", "best", "model", "FaBULOUS", "(Bouziane et al., 2021)", "on", "the", "development", "set.", "For", "the", "test", "set,", "the", "increase", "is", "6.96%", "and", "7.14%", "in", "Feverous", "score", "and", "label", "accuracy,", "respectively.", "These", "results", "suggest", "the", "effectiveness", "of", "our", "proposed", "DCUF", "model.", "The", "evidence", "format", "of", "a", "global", "evidence", "table", "is", "consistent", "to", "the", "input", "of", "pre-trained", "table", "models.", "Thus,", "DCUF", "can", "make", "better", "use", "of", "the", "internal", "ability", "of", "pre-trained", "models", "than", "previous", "works", "which", "concatenate", "linearized", "tables", "or", "max-pool", "lots", "of", "claim-table", "pair", "encoding", "(Bouziane et al., 2021).", "Moreover,", "DCUF", "also", "performs", "better", "than", "another", "well-performing", "model,", "CARE", "(Kotonya et al., 2021b).", "DCUF", "converts", "cells", "to", "meaningful", "sentences", "that", "are", "similar", "to", "the", "inputs", "of", "PLMs", "pre-training", "stage,", "which", "makes", "better", "use", "of", "the", "PLMs", "ability."], "cited_papers": [{"title": "Fabulous: Fact-checking based on understanding of language over unstructured and structured information", "year": "2021", "authors": ["Mostafa Bouziane", "Hugo Perrin", "Amine Sadeq", "Thanh Nguyen", "Aur\u00e9lien Cluzeau", "Julien Mardas"]}], "target_citation_location": 97, "citation_locations": [21, 97, 108], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2a7a28a0-eb97-4ff3-b99a-4f3b8f8e9ce8", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["The", "task", "of", "neural", "event", "detection", "has", "been", "attempted", "using", "a", "combination", "of", "networks,", "but", "mostly", "revolving", "around", "the", "use", "of", "convolutional", "neural", "architectures.", "Work", "in", "this", "approach", "focused", "on", "various", "aspects", "such", "as", "max-pooling", "to", "retrieve", "the", "structure", "of", "event", "nugget", "information", "(Nguyen and Grishman, 2015),", "modeling", "the", "skipgram", "architecture", "to", "learn", "lexical", "feature", "representations", "(Chen et al., 2015)", "as", "well", "as", "using", "dynamic", "CNNs", "in", "order", "to", "extract", "lexical", "and", "syntactic", "features", "in", "parallel", "(Nguyen and Grishman, 2016).", "Recurrent", "neural", "architectures", "have", "also", "been", "employed", "for", "this", "task,", "which", "predict", "the", "location", "of", "the", "trigger", "based", "on", "combining", "the", "for-ward", "and", "backward", "features", "of", "sentences", "in", "which", "events", "occur", "(Nguyen et al., 2016, Ghaeini et al., 2016).", "Note", "that", "in", "both", "cases", "architectures", "focused", "on", "dealing", "with", "structural,", "lexical", "and", "contextual", "features."], "cited_papers": [{"title": "Event detection and domain adaptation with convolutional neural networks", "year": "2015", "authors": ["Huu Thien", "Ralph Nguyen", "unk Grishman"]}], "target_citation_location": 43, "citation_locations": [43, 53, 70, 102], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2ad0305e-be82-4196-85bd-91618eba21a6", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["Post-processing", "After", "the", "neural", "model", "predicts", "a", "fragment", "and", "a", "word", "sense", "for", "each", "token,", "we", "assemble", "these", "predictions", "into", "a", "complete", "clause", "list", "by", "choosing", "unique", "new", "names", "for", "discourse", "referents", "with", "index", "0", "and", "unifying", "other", "discourse", "referents", "with", "them", "according", "to", "their", "relative", "indices.", "We", "also", "replace", "DUMMY", "strings", "in", "clauses", "by", "the", "predicted", "word", "senses", "and", "by", "symbols", "for", "names,", "cardinalities,", "and", "date/time", "expressions,", "which", "are", "predicted", "from", "the", "tokens", "by", "a", "rule-based", "system", "similar", "to", "that", "of", "Evang (2019).", "For", "example,", "for", "the", "proper", "name", "Tom", "it", "predicts", "the", "symbol", "\"tom\",", "for", "the", "numeral", "two", "it", "predicts", "\"2\",", "and", "for", "the", "time", "expression", "five", "o'clock,", "it", "predicts", "\"17:00\".", "Special", "clauses", "like", "b1", "\"speaker\"", "x1", "and", "b1", "\"hearer\"", "x1", "are", "removed", "and", "the", "corresponding", "referent", "(x1", "in", "the", "example)", "replaced", "by", "the", "symbols", "\"speaker\"", "and", "\"hearer\".", "Finally,", "we", "use", "a", "set", "of", "postprocessing", "rules", "similar", "to", "that", "of", "van Noord et al. (2020)", "to", "ensure", "the", "validity", "of", "the", "resulting", "DRS:", "if", "there", "is", "a", "loop", "in", "the", "subordination", "relation", "among", "boxes,", "an", "arbitrary", "box", "in", "the", "loop", "is", "chosen,", "and", "all", "its", "clauses", "are", "removed", "to", "break", "the", "loop", "(cf.", "Figure", "9"], "cited_papers": [{"title": "Character-level representations improve DRS-based semantic parsing even in the age of BERT", "year": "2020", "authors": ["Rik Van Noord", "Antonio Toral", "Johan Bos"]}], "target_citation_location": 151, "citation_locations": [82, 151], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "2b29e08f-e1e8-4e9c-a863-52f3156329f4", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["We", "use", "pre-trained", "BERT-large", "uncased", "(24-layer,", "1024-hidden,", "16-heads,", "340M", "parameters,", "whole", "word", "masking)", "(Devlin et al., 2019)", "for", "our", "mention", "and", "context", "encoder.", "All", "BERT", "hyperparameters", "are", "unchanged.", "The", "entity", "embedding", "matrix", "contains", "10M", "(UFET", "type", "set)", "or", "60M", "(Wiki", "type", "set)", "parameters.", "We", "train", "our", "models", "with", "batch", "size", "32", "(8", "\u00d7", "4", "gradient", "accumulation", "steps)", "using", "one", "NVIDIA", "V100", "GPU", "for", "a", "week.", "We", "use", "the", "AdamW", "optimizer", "(Kingma and Ba, 2014, Loshchilov and Hutter, 2018)", "with", "learning", "rate", "2e-5", "for", "BERT", "parameters", "and", "learning", "rate", "1e-3", "for", "the", "type", "embedding", "matrix.", "We", "use", "Hugging-Face's", "Transformers", "library", "(Wolf et al., 2019)", "Table", "2:", "\"Out-of-the-box\"", "accuracy", "on", "the", "CAP", "development", "set.", "We", "compare", "performance", "of", "BERT-base,", "BERT-large,", "and", "the", "mention", "and", "context", "representation", "of", "the", "embedding", "model", "with", "ours,", "using", "just", "cosine", "similarity", "and", "no", "classifier."], "cited_papers": [{"title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing", "year": "2019", "authors": ["Thomas Wolf", "Lysandre Debut", "Victor Sanh", "Julien Chaumond", "Clement Delangue", "Anthony Moi", "Pierric Cistac", "Tim Rault", "R'emi Louf", "Morgan Funtowicz", "Jamie Brew"]}], "target_citation_location": 89, "citation_locations": [13, 67, 89], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "2bce80a0-ce4f-421d-9c7a-1bc5f1eee206", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["In", "this", "work,", "we", "aim", "to", "design", "an", "E2E", "pretraining", "strategy", "for", "the", "VLP", "problem.", "To", "this", "end,", "we", "adopt", "a", "modular", "representation", "network,", "which", "takes", "image", "grid", "features", "from", "a", "CNN-based", "visual", "network", "and", "the", "corresponding", "text", "embeddings", "into", "a", "multi-modal", "Transformer", "(Huang et al., 2020 (Huang et al., , 2021)).", "Our", "goal", "is", "to", "learn", "the", "visual", "network", "and", "the", "Transformer", "jointly,", "and", "yet", "to", "effectively", "encode", "object-level", "visual", "concepts", "in", "the", "multimodal", "representations.", "This", "enables", "us", "to", "capture", "rich", "cross-modal", "alignment", "between", "linguistic", "entities", "and", "visual", "semantic", "concepts", "for", "the", "downstream", "tasks,", "and", "meanwhile", "to", "enjoy", "the", "benefits", "of", "an", "efficient", "E2E", "network", "design", "without", "relying", "on", "detectors", "during", "fine-tuning", "and", "inference."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Pixel-bert: Aligning image pixels with text by deep multi-modal transformers", "year": "2020", "authors": ["Zhicheng Huang", "Zhaoyang Zeng", "Bei Liu", "Dongmei Fu", "Jianlong Fu"]}], "target_citation_location": 43, "citation_locations": [43], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2bd7d37b-6aef-4821-8996-02294cd1f425", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["Lexical", "complexity", "is", "one", "of", "the", "main", "reasons", "leading", "to", "overall", "text", "complexity", "and", "thus", "result", "in", "poor", "reading", "comprehension", "for", "readers", "(DuBay, 2004).", "Different", "from", "the", "Complex", "Word", "Identification", "(CWI)", "(Shardlow, 2014)", "task,", "which", "aims", "to", "predict", "whether", "a", "given", "word", "is", "complex", "or", "not,", "the", "goal", "of", "lexical", "complexity", "prediction", "(LCP)", "is", "to", "predict", "the", "complexity", "value", "of", "the", "given", "parts", "from", "contexts", "as", "shown", "in", "Figure", "1.", "The", "underlined", "parts", "of", "the", "sentence", "are", "the", "words", "that", "need", "to", "be", "predicted", "and", "the", "same", "words", "in", "different", "contexts", "may", "have", "different", "complexity", "scores.", "LCP", "plays", "an", "important", "role", "in", "the", "usual", "Lexical", "Simplification", "(LS)", "(Bott et al., 2012)", "pipeline", "since", "it", "can", "help", "simplifiers", "find", "the", "challenging", "words", "and", "replace", "them", "with", "appropriate", "alternatives", "that", "easy", "to", "understand.", "Either", "LCP", "or", "CWI", "can", "not", "only", "be", "used", "as", "a", "component", "of", "LS", "systems", "but", "also", "as", "a", "stand-alone", "application", "within", "intelligent", "tutoring", "systems", "for", "second", "language", "learners", "or", "in", "reading", "devices", "for", "people", "with", "low", "literacy", "skills", "(Gooding and Kochmar, 2018)."], "cited_papers": [{"title": "Can spanish be simpler? lexsis: Lexical simplification for spanish", "year": "2012", "authors": ["Stefan Bott", "Luz Rello"]}], "target_citation_location": 105, "citation_locations": [22, 30, 105, 165], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "2bd8caf1-dd8a-4b9e-9a50-8ef1ab909059", "citing_paper": {"title": "A User-Based Usability Assessment of Raw Machine Translated Technical Instructions", "year": 2012, "authors": ["Stephen Doherty", "Sharon O'brien"]}, "text": ["This", "paper", "reports", "on", "a", "project", "whose", "aims", "are", "to", "investigate", "the", "usability", "of", "raw", "machine", "translated", "technical", "support", "documentation", "for", "a", "commercial", "online", "service.", "It", "builds", "on", "previous", "work", "which", "investigates", "the", "use", "of", "eye", "tracking", "as", "a", "machine", "translation", "evaluation", "mechanism", "(Doherty and O'Brien, 2009, Doherty et al., 2010,", "which", "focused", "on", "the", "readability", "and", "comprehension", "of", "machine-translated", "technical", "support", "documentation", "(Doherty, 2012),", "and", "on", "the", "impact", "of", "controlled", "authoring", "on", "the", "readability", "of", "MT", "output", "(O'Brien, 2010)."], "cited_papers": [{"title": "Can MT output be evaluated through eye tracking? MT Summit XII: Proceedings of the Twelfth Machine Translation Summit", "year": "2009", "authors": ["S Doherty", "S O'brien"]}, {"title": "Eye tracking as an MT evaluation technique", "year": "2010", "authors": ["S Doherty", "S O'brien", "M Carl"]}], "target_citation_location": 43, "citation_locations": [43, 56, 70], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "2c07bdb5-1e42-4a09-a0b1-f43429b10bf5", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Besides,", "leveraging", "knowledge", "graph", "is", "not", "the", "only", "way", "to", "promote", "content", "diversity", "as", "it", "is", "a", "highly", "knowledge-intensive", "task.", "Many", "existing", "knowledge-enhanced", "methods", "(Yu et al., 2022c)", "can", "be", "used", "to", "acquire", "different", "external", "knowledge", "for", "producing", "diverse", "outputs,", "e.g.,", "taking", "different", "retrieved", "documents", "as", "conditions", "for", "generator."], "cited_papers": [{"title": "A survey of knowledge-enhanced text generation", "year": "2022", "authors": ["Wenhao Yu", "Chenguang Zhu", "Zaitang Li", "Zhiting Hu", "Qingyun Wang", "Ji Heng", "Meng Jiang"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "2c19138d-a200-48bb-8511-f539581a3bf0", "citing_paper": {"title": "Comparison of post-editing productivity between professional translators and lay users", "year": 2014, "authors": ["Nora Aranberri", "Gorka Labaka"]}, "text": ["The", "post-editing", "environment", "used", "in", "the", "experiment", "was", "the", "Bologna", "Translation", "Service", "(BTS),", "the", "product", "of", "an", "EU-funded", "ICT", "PSP", "4", "th", "Call,", "Theme", "6:", "Multilingual", "Web", "project", "(ID", "270915).", "1", "It", "is", "an", "end-to-end", "web-based", "translation", "management", "tool", "in", "which", "users", "with", "different", "roles", "(manager,", "requester,", "reviewer,", "etc.)", "participate", "on-line", "at", "different", "stages", "of", "the", "translation", "workflow.", "It", "couples", "translation", "memory", "(TM)", "and", "machine", "translation", "(MT)", "capabilities", "within", "a", "simple", "work", "environment.", "BTS", "was", "designed", "with", "lay", "users", "in", "mind.", "The", "work", "environment", "offers", "a", "simple", "layout", "with", "a", "top", "bar", "with", "the", "main", "action", "buttons", "and", "job", "information", "(see", "Figure", "1).", "Below,", "the", "source", "text", "is", "split", "into", "segments", "and", "the", "target", "side", "is", "filled", "with", "either", "TM", "(fuzzy-)matches", "or", "MT", "candidates", "for", "the", "reviewer", "to", "work", "on.", "It", "is", "a", "plain", "tool", "as", "opposed", "to", "more", "sophisticated", "software", "developed", "in", "the", "CASCAMAT", "2", "and", "Ma-teCat", "3", "projects", "(Alabau et al. 2013, Federico et al., 2012),", "which", "include", "interactive", "translation", "prediction", "and", "track", "post-editing", "operations.", "For", "the", "current", "experiment,", "the", "BTS", "platform", "was", "enhanced", "with", "an", "English", "to", "Basque", "MT", "system.", "A", "standard", "phrase-based", "statistical", "machine", "translation", "system", "was", "built", "based", "on", "Moses", "using", "a", "parallel", "corpus", "of", "14.58", "million", "English", "tokens", "and", "12.50", "million", "Basque", "tokens", "(1.3", "million", "parallel", "sentences)", "which", "includes", "localization", "texts", "(graphic", "user", "interface", "strings", "and", "user", "documention),", "academic", "books", "and", "web", "entertainment", "data.", "To", "address", "the", "token", "mismatch", "between", "English", "(analytic", "language)", "and", "Basque", "(agglutinative", "language)", "tokens,", "the", "aligner", "was", "fed", "with", "segmented", "words", "for", "the", "agglutinative", "language.", "Several", "segmentation", "options", "exist:", "we", "can", "isolate", "each", "morpheme,", "or", "break", "each", "word", "into", "lemma", "and", "a", "bag", "of", "suffixes,", "we", "can", "establish", "hand-written", "rules", "for", "segmentation,", "or", "let", "an", "automatic", "tool", "define", "and", "process", "the", "words", "unsupervised.", "Based", "on", "the", "results", "from", "Labaka", "(2010),", "we", "opted", "for", "the", "second", "option", "and", "joined", "together", "all", "the", "suffixes", "attached", "to", "a", "particular", "lemma", "in", "one", "separate", "token.", "Thus,", "on", "splitting", "a", "word,", "we", "generated,", "at", "most,", "three", "tokens", "(prefixes,", "lemma", "and", "suffixes).", "Moses", "was", "trained", "and", "optimized", "on", "segmented", "text.", "Note", "that", "when", "using", "segmented", "text", "for", "training,", "the", "output", "of", "the", "system", "is", "also", "segmented", "text.", "Real", "words", "are", "not", "available", "to", "the", "statistical", "decoder.", "This", "means", "that", "a", "generation", "postprocess", "(unsegmentation", "step)", "is", "needed", "to", "obtain", "real", "word", "forms.", "We", "incorporated", "a", "second", "language", "model", "(LM)", "based", "on", "real", "word", "forms", "to", "be", "used", "after", "the", "morphological", "postprocess.", "We", "implemented", "the", "word", "form-based", "LM", "by", "using", "an", "n-best", "list,", "as", "was", "done", "in", "Oflazer and El-Kahlout (2007).", "We", "first", "asked", "Moses", "to", "generate", "a", "translation", "candidate", "ranking", "based", "on", "the", "segmented", "training", "explained", "above.", "Next,", "these", "candidates", "were", "postprocessed.", "We", "then", "recalculated", "the", "total", "cost", "of", "each", "candidate", "by", "including", "the", "cost", "assigned", "by", "the", "new", "word", "form-based", "LM", "in", "the", "models", "used", "during", "decoding.", "Finally,", "the", "candidate", "list", "was", "re-ranked", "according", "to", "this", "new", "total", "cost.", "This", "somehow", "revises", "the", "candidate", "list", "to", "promote", "the", "ones", "that", "are", "more", "likely", "to", "be", "real", "word-form", "sequences.", "The", "weight", "for", "the", "word", "formbased", "LM", "was", "optimized", "at", "Minimum", "Error", "Rate", "Training", "(Och, 2003)", "together", "with", "the", "weights", "for", "the", "rest", "of", "the", "models."], "cited_papers": [{"title": "Minimum Error Rate Training in Statistical Machine Translation", "year": "2003", "authors": ["F Och"]}], "target_citation_location": 506, "citation_locations": [150, 412, 506], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "2c3e1a1f-3abf-47a5-8c27-751cba524f67", "citing_paper": {"title": "Associating semantic components with intersective Levin classes", "year": 1997, "authors": ["Hoa Dang", "Joseph Rosenzweig", "Martha Palmer"]}, "text": ["The", "new", "lexico-structural", "transfer", "approach", "is", "more", "similar", "to", "the", "interlingua", "approach", "in", "that", "they", "both", "have", "a", "predicate-argument", "structure", "representation", "of", "the", "meaning", "of", "the", "sentence,", "which", "gives", "them", "roughly", "equivalent", "semantic", "depth.", "Another", "similarity", "is", "that", "the", "new", "transfer", "approach", "can", "also", "combine", "lexical", "items", "from", "several", "languages", "together", "into", "a", "single", "transfer", "lexicon", "entry,", "greatly", "simplifying", "the", "task", "of", "adding", "the", "mapping", "to", "a", "new", "language", "[10].", "An", "important", "remaining", "difference", "is", "that", "the", "interlingua", "approach", "would", "claim", "that", "a", "single", "predicate-argument", "structure", "can", "serve", "as", "a", "common", "representation", "for", "many", "languages,", "whereas", "the", "transfer", "approach", "allows", "for", "language-specific", "predicate-argument", "structures..", "A", "fundamental", "assumption", "of", "either", "approach,", "and", "the", "most", "important", "similarity,", "is", "that", "these", "classifications", "can", "be", "made", "based", "on", "distinguished", "semantic", "features,", "and", "that", "these", "semantic", "features", "will", "be", "relevant", "to", "classification", "schemes", "in", "other", "languages.", "Whether", "the", "classification", "schemes", "serve", "as", "a", "means", "of", "associating", "a", "single", "logical", "form", "composed", "of", "semantic", "primitives", "with", "many", "lexical", "items,", "as", "in", "the", "LCS", "approach,", "or", "as", "a", "means", "of", "enriching", "a", "set", "of", "logical", "forms", "with", "a", "collection", "of", "semantic", "features,", "the", "classifications", "still", "have", "to", "be", "determined,", "and", "the", "associations", "with", "semantic", "features", "have", "to", "be", "made.", "The", "rest", "of", "this", "paper", "discusses", "specific", "issues", "with", "respect", "to", "the", "association", "of", "semantic", "features", "with", "the", "classifications", "in", "English", "verbs."], "cited_papers": [{"title": "Enriching lexical transfer with cross-linguistic semantic features", "year": "1997", "authors": ["Alexis Nasr", "Owen Rambow", "Martha Palmer", "Joseph Rosenzweig"]}], "target_citation_location": 69, "citation_locations": [69], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2c41be4b-0d14-4315-a327-47045c4f5ed7", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["The", "work", "of", "Bornea et al. (2020)", "showed", "that", "large", "pre-trained", "multilingual", "models", "are", "not", "enough", "for", "question-answering", "in", "underrepresented", "languages", "and", "presented", "several", "novel", "strategies", "to", "improve", "the", "performance", "of", "mBERT", "with", "translations.", "This", "work", "achieved", "languageindependent", "embeddings,", "which", "improved", "the", "cross-lingual", "transfer", "performance", "with", "additional", "pre-training", "on", "adversarial", "tasks.", "It", "also", "introduced", "a", "Language", "Arbitration", "Framework", "(LAF),", "which", "consolidated", "the", "embedding", "representations", "across", "languages", "using", "properties", "of", "translation.", "Crosslingual", "manifold", "mixup", "(X-Mixup)", "(Yang et al., 2021)", "achieved", "better", "cross-lingual", "transfer", "by", "calibrating", "the", "representation", "discrepancy,", "which", "resulted", "in", "a", "compromised", "representation", "for", "target", "languages.", "It", "was", "shown", "that", "the", "multilingual", "pretraining", "process", "can", "be", "improved", "by", "implementing", "X-Mixup", "on", "parallel", "data.", "Contrastive", "Language-Image", "pre-training", "(CLIP)", "(Radford et al., 2021)", "introduced", "an", "efficient", "way", "to", "learn", "scalable", "image", "representations", "with", "natural", "language", "supervision.", "Drawing", "inspiration", "from", "ConVIRT", "(Zhang et al., 2020),", "CLIP", "used", "a", "contrastive", "objective", "that", "maximizes", "the", "cosine", "similarity", "of", "the", "correct", "pairs", "of", "images", "and", "text,", "while", "minimizing", "the", "same", "for", "incorrect", "pairs.", "Building", "upon", "the", "work", "of", "(Bornea et al., 2020),", "we", "show", "that", "translations", "of", "a", "small-scale", "dataset", "into", "cross-family", "languages", "could", "degrade", "the", "QA", "performance.", "To", "overcome", "this", "problem,", "we", "propose", "multilingual", "contrastive", "training", "to", "encourage", "cross-lingual", "invariance.", "Our", "approach", "is", "relatively", "simpler", "compared", "to", "adversarial", "training", "and", "LAF", "used", "in", "Bornea et al. (2020).", "Though", "the", "proposed", "contrastive", "loss", "has", "a", "similar", "objective", "to", "the", "pretraining", "loss", "in", "(Guo et al., 2018),", "there", "are", "subtle", "differences", "because", "we", "use", "it", "in", "multi-task", "learning", "setup", "along", "with", "the", "original", "task", "loss", "for", "finetuning."], "cited_papers": [{"title": "Learning transferable visual models from natural language supervision", "year": "2021", "authors": ["Alec Radford", "Jong Kim", "Chris Hallacy", "Aditya Ramesh", "Gabriel Goh", "Sandhini Agarwal", "Girish Sastry", "Amanda Askell", "Pamela Mishkin", "Jack Clark"]}], "target_citation_location": 111, "citation_locations": [3, 71, 111, 129, 160, 203, 218], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2c486aba-d2d2-4ca3-94df-362382d80fc8", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["Peru", "offers", "a", "rich", "diversity", "context", "for", "machine", "translation", "research", "with", "47", "native", "languages", "(Simons and Fenning, 2019).", "All", "of", "them", "are", "highly", "distinguishing", "from", "Castilian", "Spanish,", "the", "primary", "1", "Available", "in:", "https://github.com/aoncevay/mt-peru", "official", "language", "in", "the", "country", "and", "the", "one", "spoken", "by", "the", "majority", "of", "the", "population.", "However,", "from", "the", "computational", "perspective,", "all", "of", "these", "languages", "do", "not", "have", "enough", "resources,", "such", "as", "monolingual", "or", "parallel", "texts,", "and", "most", "of", "them", "are", "considered", "endangered", "(Zariquiey et al., 2019)."], "cited_papers": [{"title": "Obsolescencia ling\u00fc\u00edstica, descripci\u00f3n gramatical y documentaci\u00f3n de lenguas en el per\u00fa: hacia un estado de la cuesti\u00f3n", "year": "2019", "authors": ["Roberto Zariquiey", "Harald Hammarstr\u00f6m", "M\u00f3nica Arakaki", "Arturo Oncevay", "John Miller"]}], "target_citation_location": 72, "citation_locations": [14, 72], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1]]}
{"id": "2c8b4633-0992-4b6f-acd1-ea557f40e934", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["The", "originality", "of", "WM", "lies", "in", "its", "approach", "to", "reusability.", "Ten", "Hacken &amp, Domenig (1996)", "present", "this", "approach", "in", "terms", "of", "the", "diagram", "in", "Fig.", "1."], "cited_papers": [{"title": "Reusable Dictionaries for NLP: The Word Manager Approach", "year": "1996", "authors": ["unk Ten Hacken", "& Pius", "Marc Domenig"]}], "target_citation_location": 11, "citation_locations": [11], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "2c970549-0f45-4e89-9c6e-5cc92bda999d", "citing_paper": {"title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation", "year": 2021, "authors": ["Hansi Hettiarachchi", "Tharindu Ranasinghe"]}, "text": ["Word", "Sense", "Disambiguation", "(WSD)-based", "approaches", "were", "widely", "used", "by", "previous", "research", "to", "tackle", "this", "problem", "(Loureiro and Jorge, 2019, Scarlini et al., 2020).", "WSD", "associates", "the", "word", "in", "a", "text", "with", "its", "correct", "meaning", "from", "a", "predefined", "sense", "inventory", "(Navigli, 2009).", "As", "such", "inventories,", "WordNet", "(Miller, 1995)", "and", "Babel-Net", "(Navigli and Ponzetto, 2012)", "were", "commonly", "used.", "However,", "these", "approaches", "fail", "to", "generalise", "into", "different", "languages", "as", "these", "inventories", "are", "often", "limited", "to", "high", "resource", "languages.", "Targeting", "this", "gap,", "SemEval-2021", "Task", "2:", "Multilingual", "and", "Cross-lingual", "Word-in-Context", "Disambiguation", "is", "designed", "to", "capture", "the", "word", "sense", "without", "relying", "on", "fixed", "sense", "inventories", "in", "both", "monolingual", "and", "cross-lingual", "setting.", "In", "summary,", "this", "task", "is", "designed", "as", "a", "binary", "classification", "problem", "which", "predicts", "whether", "the", "target", "word", "has", "the", "same", "meaning", "or", "different", "meaning", "in", "different", "contexts", "of", "the", "same", "language", "(monolingual", "setting)", "or", "different", "languages", "(cross-lingual", "setting)."], "cited_papers": [{"title": "Babelnet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network", "year": "2012", "authors": ["Roberto Navigli", "Simone Ponzetto"]}], "target_citation_location": 40, "citation_locations": [15, 32, 37, 40], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2cc6cf73-1941-4dd2-abaf-4addf7c29cc4", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["Eq.", "6", "implies", "that", "the", "abstractive", "model", "g", "should", "be", "able", "to", "assign", "higher", "estimated", "probability", "to", "the", "better", "candidate", "summary", "during", "inference.", "However,", "this", "intuition", "is", "not", "directly", "captured", "in", "the", "standard", "MLE", "objective", "used", "in", "training", "-a", "model", "obtaining", "zero", "MLE", "loss", "would", "assign", "zero", "probability", "to", "any", "candidate", "summary", "different", "from", "the", "reference.", "This", "is", "obviously", "improper", "for", "any", "task", "where", "multiple", "reasonable", "generations", "may", "exist", "(Khayrallah et al., 2020),", "and", "also", "does", "not", "say", "anything", "about", "the", "ordering", "of", "two", "imperfect", "references.", "We", "therefore", "advocate", "for", "making", "the", "alternative", "assumption", "that", "the", "probability", "of", "one", "candidate", "should", "be", "well-correlated", "with", "its", "quality", "as", "evaluated", "by", "an", "automatic", "metric", "M.", "Since", "it", "is", "intractable", "to", "enumerate", "all", "the", "possible", "candidate", "outputs,", "we", "only", "require", "our", "model", "to", "be", "able", "to", "accurately", "predict", "the", "ranking", "order", "of", "a", "set", "of", "the", "most", "probable", "candidate", "summaries", "\u015c,", "which", "are", "its", "own", "beam", "search", "results.", "In", "order", "to", "achieve", "this", "objective,", "we", "slightly", "modify", "the", "conditions", "of", "Eq.", "5,", "maintaining", "the", "general", "functional", "form,", "but", "instead", "specifying", "the", "marginal", "probability", "of", "the", "non-reference", "candidates", "S", "to", "be", "\u03b2,", "and", "encouraging", "coordination", "of", "probabilities", "and", "qualities", "among", "non-reference", "candidates", "as", "follows:"], "cited_papers": [{"title": "Simulated multiple reference training improves low-resource machine translation", "year": "2020", "authors": ["Huda Khayrallah", "Brian Thompson", "Matt Post", "Philipp Koehn"]}], "target_citation_location": 69, "citation_locations": [69], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2ce468d7-7610-4425-964c-6d2995e87250", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["In", "this", "paper,", "we", "developed", "a", "semi-supervised", "strategy", "to", "detect", "toxic", "comments", "in", "the", "Brazilian", "Portuguese", "language.", "Semi-supervision", "is", "the", "problem", "of", "learning", "from", "labeled", "and", "unlabeled", "data", "(Abney, 2007, Subramanya and Talukdar, 2014),", "in", "which", "given", "a", "point", "set", "X", "=", "{x", "1,", "...,", "x", "l,", "x", "l+1,", "...,", "x", "n}", "and", "a", "label", "set", "L", "=", "{1,", "...,", "c},", "the", "first", "l", "points", "have", "labels", "{y", "1,", "...,", "y", "l}", "\u2208", "L", "and", "the", "remaining", "points", "are", "unlabeled", "(Zhou et al., 2004)."], "cited_papers": [{"title": null, "year": "2007", "authors": ["Steven Abney"]}, {"title": "Graph-based semi-supervised learning", "year": "2014", "authors": ["Amarnag Subramanya", "Partha Talukdar"]}], "target_citation_location": 28, "citation_locations": [28, 75], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "2d654ce0-5b9f-45bd-86e6-04629c556dec", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["The", "feature", "functions", "h", "i", "are", "the", "system", "models", "and", "the", "\u03bb", "i", "weights", "are", "typically", "optimized", "to", "maximize", "a", "scoring", "function", "on", "a", "development", "set", "[6].", "In", "our", "system", "fourteen", "features", "functions", "were", "used,", "namely", "phrase", "and", "lexical", "translation", "probabilities", "in", "both", "directions,", "seven", "features", "for", "the", "lexicalized", "distortion", "model,", "a", "word", "and", "a", "phrase", "penalty", "and", "a", "target", "language", "model", "(LM)."], "cited_papers": [{"title": "Discriminative training and maximum entropy models for statistical machine translation", "year": "2002", "authors": ["unknown"]}], "target_citation_location": 26, "citation_locations": [26], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2d6bcd78-598e-40ce-9ce1-be0921b6c0fe", "citing_paper": {"title": "Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure", "year": 1999, "authors": ["Nicoletta Calzolari", "Antonio Zampolli"]}, "text": ["In", "the", "specification", "phase", "of", "the", "project", "the", "formal", "representation", "of", "the", "\"conceptual", "core\"", "of", "the", "lexicons", "was", "designed,", "and", "the", "basic", "structured", "set", "of", "\"meaning-types\"", "-i.e.", "the", "core", "ontology", "-to", "be", "used", "as", "a", "common", "starting", "point", "and", "a", "shared", "device", "to", "build", "the", "harmonised", "language", "specific", "semantic", "lexicons", "was", "defined", "(see", "Busa et al. 1999).", "Such", "a", "task", "has", "tackled", "questions", "that", "are", "at", "the", "core", "of", "lexical", "semantics", "research.", "The", "development", "of", "twelve", "harmonised", "semantic", "lexicons", "requires", "strong", "mechanisms", "for", "guaranteeing", "uniformity", "and", "consistency", "of", "the", "representations.", "These", "mechanisms,", "in", "turn,", "guarantee", "that", "within", "the", "same", "language", "consistent", "formal", "devices", "apply", "cross-domain", "and", "cross-categorially.", "Finally,", "the", "multilingual", "component", "translates", "into", "the", "requirement", "of", "identifying", "elements", "of", "the", "semantic", "vocabulary", "for", "structuring", "word", "meaning", "which", "are", "at", "the", "same", "time", "independent", "from", "any", "individual", "language", "but", "able", "to", "capture", "linguistically", "useful", "generalisations", "for", "different", "NLP", "tasks."], "cited_papers": [{"title": "Building a semantic lexicon: structuring and generating concepts", "year": "1999", "authors": ["F Busa", "N Calzolari", "A Lenci", "J Pustejovsky"]}], "target_citation_location": 53, "citation_locations": [53], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2dab37b8-1a52-4114-a467-86ceb48c6d61", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["Compositionality", "and", "Its", "Benefits", "Is", "our", "semantic", "parser", "compositional?", "Bender et al. (2015)", "provide", "a", "definition", "of", "compositionality", "in", "meaning", "systems,", "which", "we", "summarize", "as", "follows:", "(1)", "there", "is", "a", "finite", "set", "of", "atomic", "word-meaning", "pairings,", "(2)", "there", "is", "a", "finite", "number", "of", "rules", "combining", "constituent-meaning", "pairings", "into", "larger", "constituent-meaning", "pairings,", "and", "any", "non-atomic", "constituent-meaning", "pairing", "is", "a", "function", "of", "the", "constituent-meaning", "pairings", "from", "which", "it", "is", "created", "and", "of", "the", "rule", "that", "creates", "it,", "(3)", "meaning", "representations", "are", "not", "changed", "destructively.", "They", "argue", "that", "compositional", "aspects", "of", "meaning", "such", "as", "predicate-argument", "structure", "should", "be", "processed", "by", "compositional", "systems,", "whereas", "noncompositional", "aspects", "such", "as", "anaphora", "or", "word", "senses", "should", "be", "handled", "by", "different", "mechanisms."], "cited_papers": [{"title": "Layers of interpretation: On grammar and compositionality", "year": "2015", "authors": ["Emily Bender", "Dan Flickinger", "Stephan Oepen", "Woodley Packard", "Ann Copestake"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "2daf23fa-88d4-41bf-88b5-fcfb500b54db", "citing_paper": {"title": "Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model", "year": 2022, "authors": ["Richard Futrell"]}, "text": ["Data", "I", "use", "Universal", "Dependencies", "(UD)", "2.8", "2", "(Nivre et al., 2020)", "and", "the", "automatically-parsed", "Wikipedia", "datasets", "released", "as", "part", "of", "the", "CoNLL", "2017", "Shared", "Task", "(Zeman et al., 2017)", "as", "a", "source", "of", "attributive", "adjective-noun", "pairs.", "I", "extract", "all", "pairs", "of", "words", "linked", "by", "a", "dependency", "of", "type", "amod", "where", "the", "head", "has", "universal", "part-of-speech", "(UPOS)", "NOUN", "and", "the", "dependent", "has", "UPOS", "ADJ.", "I", "represent", "the", "pair", "using", "the", "downcased", "wordforms", "of", "the", "adjective", "and", "noun."], "cited_papers": [{"title": "Universal Dependencies v2: An evergrowing multilingual treebank collection", "year": "2020", "authors": ["Joakim Nivre", "Marie-Catherine De Marneffe", "Filip Ginter", "Jan Haji\u010d", "Christopher Manning", "Sampo Pyysalo", "Sebastian Schuster", "Francis Tyers", "Daniel Zeman"]}], "target_citation_location": 8, "citation_locations": [8, 23], "citation_type": "single", "annotations": [[0, 2, 2, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2e9ca574-0f76-4315-8c1d-fae6e354893e", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Explainability", "is", "an", "important", "concept", "within", "abusive", "language", "detection.", "Jurgens et al. (2019)", "noted", "in", "their", "work", "that", "explainable", "ML", "techniques", "can", "promote", "restorative", "and", "procedural", "justice", "by", "surfacing", "the", "norms", "that", "have", "been", "violated", "and", "clarifying", "how", "they", "have", "been", "violated.", "That", "said,", "there", "has", "been", "limited", "discussion", "of", "the", "issue", "within", "the", "domain", "of", "abusive", "language", "detection.", "In", "this", "section,", "we", "first", "formalize", "the", "properties", "that", "an", "explainable", "detection", "method", "should", "aim", "to", "exhibit", "in", "order", "to", "thoroughly", "substantiate", "its", "decisions.", "We", "then", "describe", "how", "user", "and", "community", "information", "play", "an", "important", "role", "in", "the", "realization", "of", "each", "of", "the", "properties.", "Finally,", "we", "discuss", "what", "it", "means", "to", "operationalize", "explainability", "within", "abusive", "language", "detection", "in", "an", "effective", "manner."], "cited_papers": [{"title": "A just and comprehensive strategy for using NLP to address online abuse", "year": "2019", "authors": ["David Jurgens", "Libby Hemphill", "Eshwar Chandrasekharan"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2ed89cb6-f9ee-44d4-b04a-d3d6f9111080", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["Another", "line", "of", "past", "work", "tests", "if", "type", "information", "or", "other", "knowledge", "is", "captured", "by", "pre-trained", "LMs.", "Peters et al. (2018)", "report", "that", "ELMo", "performs", "well", "on", "word", "sense", "disambiguation", "and", "POS", "tagging.", "Some", "other", "work", "also", "investigates", "models'", "ability", "to", "induce", "syntactic", "information", "by", "measuring", "accuracy", "of", "a", "probe", "(Zhang and Bowman, 2018, Hewitt and Manning, 2019, Hewitt and Liang, 2019).", "However,", "there", "is", "significant", "uncertainty", "about", "how", "to", "calibrate", "such", "probing", "results", "(Voita and Titov, 2020),", "our", "model's", "representations", "are", "more", "directly", "interpretable", "and", "don't", "require", "posthoc", "probing."], "cited_papers": [{"title": "Deep Contextualized Word Representations", "year": "2018", "authors": ["Matthew Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer"]}], "target_citation_location": 17, "citation_locations": [17, 47, 60], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "2f0ac087-9978-4157-87d9-1bd6d35e6cb6", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["We", "built", "a", "Transformer-based", "ASR", "system", "using", "the", "ESPnet", "toolkit", "(Watanabe et al., 2018).", "The", "Transformer", "architecture", "and", "hyper-parameters", "for", "training/decoding", "are", "based", "on", "existing", "recipes", "in", "ESPnet.", "We", "investigated", "three", "models:", "selfattention-based", "CTC", "(Pham et al., 2019),", "the", "Transformer", "(Dong et al., 2018),", "and", "a", "hybrid", "Transformer", "trained", "with", "an", "auxiliary", "CTC", "objective", "(Transformer+CTC)", "(Karita et al., 2019).", "The", "CTC", "model", "was", "used", "in", "prior", "studies", "based", "on", "O2O", "models,", "e.g.,", "(Audhkhasi et al., 2018, Yadav et al., 2020).", "During", "training,", "the", "CTC", "model", "was", "regularized", "with", "the", "Transformer", "decoder", "in", "the", "multitask", "learning", "fashion", "similar", "to", "Transformer+CTC.", "Such", "regularization", "techniques", "yield", "a", "significant", "improvement", "over", "a", "pure", "CTC", "baseline", "(Fujita et al., 2020b)."], "cited_papers": [{"title": "Very deep self-attention networks for end-to-end speech recognition", "year": "2019", "authors": ["N.-Q Pham", "T.-S Nguyen", "J Niehues", "M M\u00fcller", "A Waibel"]}], "target_citation_location": 31, "citation_locations": [10, 31, 34, 46, 60, 92], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "2f18ce3d-4522-401a-911d-daf9d52e09d1", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["The", "memory-based", "approach", "is", "expected", "to", "offer", "solutions", "to", "these", "problems", "by", "allowing", "large", "numbers", "of", "cases", "to", "be", "stored", "in", "the", "memory,", "and", "make", "translation", "by", "using", "these", "cases.", "The", "memory-based", "translation", "essentially", "convert", "lime-complexity", "of", "rule", "application", "into", "space-complexity", "by", "preparing", "large", "examples", "of", "translation", "pairs.", "Since", "each", "case", "can", "be", "represented", "in", "a", "fairly", "context-sensitive", "manner", "with", "full", "semantic", "restrictions", "incorporated,", "the", "memorybased", "translation", "avoids", "expensive", "computations", "generally", "takes", "place", "in", "the", "rule-based", "translation", "system.", "In", "addition,", "the", "memory-based", "approach", "is", "expected", "to", "produce", "high", "quality", "translation", "due", "to", "its", "capability", "to", "reuse", "stylistic", "translation", "in", "the", "past.", "Since,", "detailed", "mechanisms", "and", "rationale", "for", "the", "memory-based", "translation", "approach", "has", "been", "discussed", "by", "relevant", "literatures", "(see", "[Nagao, 1984],", "[Riesbeck and Martin, 1985],", "[Kitano, 1990a],", "[Sumita and Iida, 1991],", "[Kitano and Higuchi, 199la],", "and", "[Kitano and Higuchi, 199lb]", "),", "we", "will", "simply", "focus", "on", "its", "massively", "parallel", "implementation", "and", "its", "performance."], "cited_papers": [{"title": "A Framework of a Mechanical Trans lation between Japanese and English by Analogy Principle", "year": "1968", "authors": ["C Moldovan ", " Lin", "D Moldovan", "\" Snap: Simulator Results ", " Moldovan", "D Lee", "W Lin", "C Nagao", "M Pollard", "C Sag", "I Quillian", "M Riesbeck", "C Martin", "C Riesbeck", "C Schank", "R Sato", "S Nagao", "M unk"]}], "target_citation_location": 119, "citation_locations": [118, 119, 120, 121, 122, 124], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "2f65b053-600b-493e-a70b-342c7fc9f861", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["CoNLL", "bart:", "we", "use", "a", "fine-tuned", "BART", "model", "(Lewis et al., 2020)"], "cited_papers": [{"title": "BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension", "year": "2020", "authors": ["Mike Lewis", "Yinhan Liu", "Naman Goyal ", " Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[3, 3, 2, 2, 2, 2, 1, 1, 1]]}
{"id": "2f7eb327-c396-4c72-8235-f310342400cd", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["To", "observe", "the", "effect", "of", "disentanglement", "in", "homotopy", "(Bowman et al., 2016)", "Additionally,", "to", "highlight", "the", "role", "of", "generative", "factor", "in", "generation,", "we", "conduct", "a", "dimensionwise", "homotopy,", "transitioning", "from", "the", "first", "to", "the", "last", "sentence", "by", "interpolating", "between", "the", "dimensions", "one-by-one.", "This", "is", "implemented", "as", "follows:", "(i)", "using", "prior", "distribution", "7", "we", "sample", "two", "latent", "codes", "denoted", "by", "z", "1", "=", "(z", "1,1,", "z", "1,2", ",...,", "z", "1,n", "),", "z", "2", "=", "(z", "2,1,", "z", "2,2", ",...,", "z", "2,n", "),", "(ii)", "for", "i-th", "dimension,", "using", "z", "1,i", "=", "(z", "2,1", ",...,", "z", "2,i\u22121,", "z", "1,i", ",...,", "z", "1,n)", "as", "the", "start,", "we", "interpolate", "along", "the", "i-th", "dimension", "towards", "z", "2,i", "=", "(z", "2,1", ",...,", "z", "2,i,", "z", "1,i+1", ",...,", "z", "1,n", ").", "Table", "6", "illustrates", "this", "for", "a", "3D", "latent", "code", "example."], "cited_papers": [{"title": "Generating sentences from a continuous space", "year": "2016", "authors": ["R Samuel", "Luke Bowman", "Oriol Vilnis", "Andrew Vinyals", "Rafal Dai", "Samy J\u00f3zefowicz", "unk Bengio"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "302e8762-1a72-4c43-824b-1cdfb4a14091", "citing_paper": {"title": "Corpora and Machine Translation", "year": 1993, "authors": ["Yorick Wilks"]}, "text": ["We", "need", "to", "establish", "a", "ground", "zero", "on", "what", "the", "IBM", "system", "is:", "their", "rhetorical", "claim", "is", "(or", "perhaps", "was)", "that", "they", "are", "a", "pure", "statistical", "system,", "different", "from", "their", "competitors,", "glorying", "in", "the", "fact", "that", "they", "did", "not", "even", "need", "French", "speakers.", "By", "analogy", "with", "Searle's", "Chinese", "Room,", "one", "could", "call", "this", "theirs", "a", "French", "Room", "position:", "MT", "without", "a", "glimmering", "of", "understanding", "or", "even", "knowing", "that", "French", "was", "the", "language", "they", "were", "working", "on!", "There", "is", "no", "space", "here", "for", "a", "detailed", "description", "of", "IBM's", "claims", "(see", "Brown et al. 1990 Brown et al. , 1991a Brown et al. , 1991b)).", "In", "essence,", "the", "method", "is", "an", "adaptation", "of", "one", "that", "worked", "well", "for", "speech", "decoding", "(Jelinek and Mercer 1980)."], "cited_papers": [{"title": "Interpolated estimation of Markov source parameters from sparse data", "year": "1980", "authors": ["F Jelinek", "R Mercer"]}], "target_citation_location": 105, "citation_locations": [89, 105], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]]}
{"id": "308797a4-1d80-4ac3-bb56-93527f52723d", "citing_paper": {"title": "Effects of Word Alignment Visualization on Post-Editing Quality & Speed \u2020", "year": 2015, "authors": ["Lane Schwartz", "Isabel Lacruz", "Tatyana Bystrova"]}, "text": ["Professional", "translations", "of", "Doc", "A", "into", "English", "and", "Doc", "B", "into", "Russian", "were", "commissioned", "as", "part", "of", "the", "WMT-14", "shared", "translation", "task", "(Bojar et al., 2014).", "The", "Russian", "version", "of", "each", "text", "was", "translated", "automatically", "using", "Moses", "(Koehn et al., 2007)", "by", "Schwartz et al. (2014)", "as", "part", "of", "their", "WMT14", "shared", "task", "submission.", "As", "a", "side", "effect", "of", "the", "phrase-based", "MT", "process,", "Moses", "can", "be", "configured", "to", "produce", "alignment", "links,", "indicating", "which", "target", "language", "words", "were", "produced", "from", "which", "source", "language", "words.", "To", "enable", "maximal", "comparability", "with", "the", "post-editing", "results", "of", "Schwartz et al. (2014),", "we", "make", "use", "of", "Russian-English", "machine", "translation", "results", "and", "alignments", "from", "that", "work", "here."], "cited_papers": [{"title": "Machine translation and monolingual postediting: The AFRL WMT-14 system", "year": "2014", "authors": ["L Schwartz", "T Anderson", "J Gwinnup", "K Young"]}], "target_citation_location": 36, "citation_locations": [22, 34, 36, 83], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "30a10754-99c4-4706-9652-5962e6001094", "citing_paper": {"title": "ROI Analysis model for Language Service Providers", "year": 2013, "authors": ["Ekaterina Stambolieva"]}, "text": ["Table", "2.", "expands", "the", "overview", "of", "costs", "to", "cover", "the", "whole", "translation", "process", "depending", "on", "the", "different", "services", "a", "LSP", "offers", "to", "its", "clients.", "Scenario", "2", "and", "3", "share", "some", "of", "the", "listed", "costs", "in", "Table", "2,", "but", "include", "additional", "ones.", "The", "total", "cost", "of", "resources,", "for", "instance,", "includes", "human", "resources", "costs,", "hardware", "and", "software", "license", "costs,", "among", "others.", "As", "LSPs", "rely", "on", "technology,", "the", "minimal", "requirements", "in", "place", "are", "the", "presence", "of", "a", "CAT", "tool", "system,", "and", "a", "project", "coordination", "framework.", "Personnel", "training", "on", "CAT", "tool", "usage", "as", "well", "as", "project", "coordination", "usage", "induction", "are", "not", "regarded", "as", "costs", "in", "the", "current", "scenarios,", "as", "they", "are", "expected", "to", "have", "been", "completed.", "However,", "post-editing", "training", "and", "MT", "development", "training,", "among", "others,", "are", "considered", "as", "investment", "costs", "since", "they", "depend", "on", "the", "new", "involvement", "of", "MT", "technology", "in", "the", "business", "processes.", "Therefore,", "the", "total", "LSP", "investment", "cost", "for", "providing", "pure", "human", "translation", "services", "is", "presented", "in", "Figure", "2:", "3.", "aims", "to", "provide", "cost", "overview", "of", "translation", "within", "the", "context", "of", "Scenario", "2,", "namely", "when", "a", "LSP", "incorporates", "in-house", "developed", "MT", "solution's", "output", "in", "the", "translation", "delivery", "process.", "The", "emphasis", "comes", "down", "to", "the", "cost", "of", "the", "number", "of", "translated", "segments,", "which", "is", "marked", "with", "Comtsegm", "instead", "of", "Cosegm", "as", "in", "Table", "1.", "For", "good", "language", "and", "translation", "models,", "when", "overall", "MT", "output", "BLEU", "score", "(Koehn 2010)", "is", "higher", "than", "65%,", "a", "MT", "pre-translated", "segment", "translation", "is", "paid", "50%", "of", "the", "human", "translation", "rate", "per", "segment.", "Consequently,", "Comtsegm", "=", "50%", "*Cosegm.", "To", "our", "knowledge,", "our", "internal", "proofing", "costs", "do", "not", "change", "according", "to", "recent", "statistics.", "With", "time,", "these", "statistics", "can", "change", "and", "guide", "better", "pricing", "model", "development.", "Table", "4.", "shows", "the", "translation", "process", "investment", "costs", "when", "MT", "is", "developed", "internally", "on", "LSP", "premises.", "The", "document", "conversion,", "project", "coordination,", "additional", "services", "costs,", "along", "with", "the", "cost", "of", "terminology", "management,", "and", "resources,", "are", "identical", "and", "the", "same", "as", "in", "Scenario", "1.", "It", "is", "interesting", "to", "note", "the", "costs", "that", "accompany", "internal", "MT", "development.", "These", "costs", "include", "but", "are", "not", "restricted", "to", "customization,", "6", "equal", "to", "50%", "*Cosegm", "automation,", "software", "and", "hardware", "costs.", "A", "cost", "for", "trainings", "is", "introduced.", "It", "covers", "project", "coordinators", "MT", "training", "expenses.", "Additionally", "it", "includes", "MT", "specialist", "new", "methodology", "and", "approach", "trainings.", "These", "costs", "can", "be", "roughly", "estimated", "to", "the", "expenses", "incurred", "for", "the", "number", "of", "employees", "required", "per", "day.", "Depending", "of", "the", "scale", "of", "the", "MT", "projects,", "hardware", "costs", "for", "two", "servers", "allowing", "simultaneous", "translation", "requests", "can", "easily", "reach", "60K", "euros.", "The", "hardware", "cost", "is", "repetitive", "every", "year", "as", "more", "projects", "and", "users", "are", "expected", "to", "benefit", "from", "MT.", "The", "cost", "of", "customization", "and", "optimization", "include", "human", "development", "effort", "and", "is", "measured", "in", "man-hours.", "This", "cost", "is", "directly", "linked", "to", "the", "software", "licensing", "expenses", "as", "licensed", "tools", "are", "used", "to", "accelerate", "the", "MT", "specialists'", "development", "effort.", "More", "managerial", "tasks", "by", "human", "resources", "are", "required", "such", "as", "risk", "management", "monitoring", "and", "development", "of", "prevention", "plan", "strategies."], "cited_papers": [{"title": "Automatic Evaluation. Statistical Machine Translation", "year": "2010", "authors": ["Phillip Koehn"]}], "target_citation_location": 223, "citation_locations": [223], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "30b1d408-effb-4de7-a0c7-e4d723f1134b", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["Until", "recently,", "the", "interactive", "approach", "to", "MT", "almost", "inevitably", "came", "in", "the", "form", "of", "the", "widely", "promoted", "Translator's", "Workbench'", "idea", "[21, 29],", "the", "main", "aims", "of", "which", "are", "to", "help", "translators", "to", "translate", "texts.", "Now", "it", "has", "been", "acknowledged", "that", "there", "is", "a", "drawback", "in", "this", "approach,", "which", "is", "that", "it", "is", "sometimes", "difficult", "to", "see", "where", "the", "most", "appropriate", "division", "of", "labour", "between", "the", "computer", "and", "the", "human", "should", "occur,", "and", "there", "is", "sometimes", "even", "a", "conflict", "between", "what", "the", "system", "offers", "the", "translator-user,", "and", "what", "the", "user", "already", "knows,", "or", "between", "the", "extent", "to", "which", "the", "system", "or", "the", "user", "should", "take", "the", "initiative,", "which", "might", "differ", "from", "occasion", "to", "occasion."], "cited_papers": [{"title": "Multi-level translation aids in a distributed system", "year": "1982", "authors": ["A Melby"]}, {"title": "The proper place of men and machines in language translation", "year": "1980", "authors": ["M Kay"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3120671c-c0ee-44fc-8cdb-a4b651e265cc", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["Model", "stacking", "is", "an", "efficient", "ensemble", "method", "to", "improve", "model", "accuracy.", "The", "main", "procedure", "of", "stacking", "trained", "models", "in", "our", "method", "including", "five", "steps.", "First,", "we", "use", "heterogeneous", "PLMs", "including", "BERT,", "RoBERTa,", "ALBERT,", "and", "ERNIE", "as", "base", "models.", "Second,", "we", "generate", "multiple", "hyperparameter", "sets", "by", "setting", "different", "values", "of", "dropout,", "selecting", "different", "numbers", "of", "last", "hidden", "layers,", "and", "using", "different", "loss", "functions.", "Since", "our", "purpose", "here", "is", "not", "only", "to", "find", "the", "best", "hyperparameter", "sets", "but", "also", "to", "collect", "diverse", "sets", "with", "reasonable", "performances,", "we", "keep", "all", "the", "training", "results", "from", "different", "sets.", "Third,", "we", "perform", "7fold", "cross-validation", "during", "the", "whole", "training", "process", "to", "avoid", "overfitting", "or", "selection", "bias.", "Fourth,", "we", "adopt", "several", "training", "strategies", "including", "using", "pseudo-labelling", "(Iscen et al., 2019)", "and", "data", "augmentation", "to", "further", "improve", "the", "diversity", "of", "trained", "models."], "cited_papers": [{"title": "Label propagation for deep semi-supervised learning", "year": "2019", "authors": ["Ahmet Iscen", "Giorgos Tolias"]}], "target_citation_location": 118, "citation_locations": [118], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "31d55e62-e326-4da3-895e-38ed14d2f98d", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["Formal", "Dataset", "Description", "An", "input", "text", "is", "composed", "of", "tokens", "w", "1", ",...,", "w", "t,", "and", "an", "ordered", "set", "N", "=", "n", "1", ",...,", "n", "k", "of", "base-NP", "mentions.", "The", "underlying", "text", "is", "often", "arranged", "into", "paragraphs,", "and", "may", "also", "include", "a", "title.", "A", "base-NP", "mention,", "7", "Note", "that", "the", "converse", "does", "not", "hold:", "prep(n", "1,", "n", "2", "),", "coref-to(n", "1,", "n", "3)", "does", "not", "necessarily", "entail", "prep(n", "3,", "n", "2", ").", "Consider", "for", "example:", "''The", "race", "began.", "John,", "the", "organizer,", "pleased''.", "While", "John", "and", "the", "organizer", "are", "coreferring,", "the", "relation", "organizer", "of", "the", "race", "holds,", "while", "John", "of", "the", "race", "does", "not.", "This", "is", "because", "John", "and", "the", "organizer", "are", "two", "different", "senses", "for", "the", "same", "reference,", "and", "the", "relation", "holds", "only", "for", "one", "of", "the", "senses", "(cf.", "Frege, 1960).", "Putting", "it", "differently,", "when", "John", "and", "organizer", "serve", "as", "predicates,", "their", "selectional", "preferences", "are", "different", "despite", "them", "coreferring.", "Such", "examples", "are", "common,", "consider", "also", "''John", "is", "Jenny's", "father,", "Mary's", "husband''", "where", "father", "of", "Jenny", "holds,", "while", "husband", "of", "Jenny", "doesn't.", "Similarly,", "husband", "of", "Mary", "holds,", "while", "father", "of", "Mary", "doesn't.", "also", "known", "as", "NP", "chunk,", "is", "the", "smallest", "noun", "phrase", "unit", "that", "does", "not", "contain", "other", "NPs,", "prepositional", "phrases,", "or", "relative", "clauses.", "8", "It", "is", "defined", "as", "a", "contiguous", "span", "over", "the", "text,", "indicated", "by", "start-token", "and", "end-token", "positions", "(e.g.,", "(3,", "5)", "''the", "young", "boy'').", "The", "output", "is", "a", "set", "R", "of", "relations", "of", "the", "form", "(n", "i,", "prep,", "n", "j", "),", "where", "i", "=", "j", "and", "prep", "is", "a", "preposition", "(or", "a", "set-membership", "symbol).", "Each", "text", "is", "also", "associated", "with", "a", "set", "C", "of", "non-overlapping", "coreference", "clusters,", "where", "each", "cluster", "c", "\u2286", "N", "is", "a", "non-empty", "list", "of", "NP", "mentions.", "The", "set", "of", "clusters", "is", "not", "provided", "as", "input,", "but", "for", "correct", "sets", "R", "it", "holds", "that", "\u2200n", "j", "\u2208", "c(n", "j", "),(n", "i,", "prep,", "n", "j)", "\u2208", "R", "\u21d2", "(n", "i,", "prep,", "n", "j)", "\u2208", "R,", "where", "c(n", "j)", "\u2208", "C", "is", "the", "cluster", "containing", "n", "j", ".Completeness", "and", "Uniformity", "The", "kinds", "of", "preposition-mediated", "relations", "we", "cover", "originate", "from", "different", "linguistic", "or", "cognitive", "phenomena,", "and", "some", "of", "them", "can", "be", "resolved", "by", "employing", "different", "linguistic", "constructs.", "For", "example,", "some", "within-sentence", "relations", "can", "be", "extracted", "deterministically", "from", "dependency", "trees,", "for", "example,", "by", "following", "syntactic", "prepositional", "attachment.", "Other", "relations", "can", "be", "inferred", "based", "on", "pronominal", "coreference", "(e.g.,", "''his", "school", "[of", "Adam]''", "above", "can", "be", "resolved", "by", "first", "resolving", "''his''", "to", "''Adam's''", "via", "a", "coreference", "engine,", "and", "then", "normalizing", "''Adam's", "school''", "\u2192", "''school", "of", "Adam'').", "Many", "others", "are", "substantially", "more", "involved.", "We", "deliberately", "chose", "not", "to", "distinguish", "between", "the", "different", "cases,", "and", "expose", "all", "the", "relations", "to", "the", "user", "(and", "to", "the", "annotators)", "via", "the", "same", "uniform", "interface.", "This", "approach", "also", "contributes", "to", "the", "practical", "usefulness", "of", "the", "task:", "Instead", "of", "running", "several", "different", "processes", "to", "recover", "different", "kinds", "of", "links,", "the", "end-user", "will", "have", "to", "run", "only", "one", "process", "to", "obtain", "them", "all."], "cited_papers": [{"title": "On sense and reference", "year": "1960", "authors": ["Gottlob Frege"]}], "target_citation_location": 129, "citation_locations": [129], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "31dfabd8-f1e7-41f9-9e3c-a0ee072551e9", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["Recent", "read-write", "policies", "can", "be", "divided", "into", "two", "categories:", "fixed", "policies", "such", "as", "wait-k", "(Ma et al., 2018),", "wait-if*", "(Cho and Esipova, 2016),", "and", "adaptive", "policies", "such", "as", "MoChA", "(Chiu and Raffel, 2017),", "MILk", "(Arivazhagan et al., 2019)", "and", "MU", "(Zhang et al., 2020).", "Fixed", "policies", "are", "simple", "to", "implement,", "but", "they", "neglect", "contextual", "information,", "which", "might", "result", "in", "quality", "reduction.", "Dynamic", "policies", "are", "more", "flexible,", "they", "can", "learn", "from", "data", "to", "achieve", "better", "quality/latency", "trade-offs,", "but", "accordingly", "difficult", "to", "train."], "cited_papers": [{"title": "Monotonic infinite lookback attention for simultaneous machine translation", "year": "2019", "authors": ["Naveen Arivazhagan", "Colin Cherry", "Wolfgang Macherey", "Chung-Cheng Chiu", "Semih Yavuz", "Ruoming Pang", "Wei Li", "Colin Raffel"]}], "target_citation_location": 25, "citation_locations": [14, 16, 23, 25, 28], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3211c3e4-6fda-4fde-a4ab-963cbb6b4dda", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["Similar", "to", "(Ng et al., 2019, Meng et al., 2020),", "we", "preprocess", "the", "data", "as", "follows:"], "cited_papers": [{"title": null, "year": "2020", "authors": ["Fandong Meng", "Jianhao Yan", "Yijin Liu", "Yuan Gao", "Xianfeng Zeng", "Qinsong Zeng", "Peng Li", "Ming Chen", "Jie Zhou", "Sifan Liu"]}, {"title": "Facebook fair's wmt19 news translation task submission", "year": "2019", "authors": ["Nathan Ng", "Kyra Yee", "Alexei Baevski", "Myle Ott", "Michael Auli", "Sergey Edunov"]}], "target_citation_location": 2, "citation_locations": [2], "citation_type": "group", "annotations": [[2, 2, 1, 2, 2, 2, 2, 2, 2]]}
{"id": "322ad6ee-c78a-425a-94cf-5b7629a993c0", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["Since", "PLMs", "can", "process", "multiple", "input", "sentences,", "we", "add", "a", "query", "sentence", "before", "the", "context", "to", "emphasize", "the", "words", "(e.g.", "river)", "that", "need", "to", "be", "predicted", "and", "the", "corpus", "(e.g.", "Bible)", "they", "come", "from.", "We", "add", "special", "tokens", "[CLS]", "and", "[SEP]", "to", "separate", "the", "query", "and", "the", "context", "as", "shown", "in", "Figure", "2.", "BERT", "first", "tokenizes", "the", "input", "contents", "and", "then", "generates", "contextualized", "vector", "representations", "for", "each", "token", "in", "multiple", "hidden", "layers.", "We", "focus", "on", "the", "output", "of", "only", "the", "first", "position", "that", "we", "passed", "the", "special", "[CLS]", "token", "to.", "The", "last", "k", "hidden", "layers", "are", "selected", "to", "get", "the", "final", "representation", "of", "token", "[CLS]", "through", "a", "weighted", "calculation", "function", "as", "below,x", "[CLS]", "=", "k", "i=1", "W", "i", "x", "[CLS]iwhere", "W", "i", "is", "the", "learning", "weight", "for", "each", "hidden", "layer.", "The", "calculated", "representation", "is", "then", "fed", "into", "a", "dense", "layer,", "and", "the", "technique", "of", "multi-sample", "dropout", "(Inoue, 2019)", "is", "utilized", "to", "accelerate", "training", "and", "finally", "obtain", "the", "predicted", "complexity", "scores.", "The", "loss", "function", "can", "be", "chosen", "among", "several", "options", "including", "Mean", "Square", "Error", "(MSE),", "Root", "Mean", "Square", "Error", "(RMSE),", "and", "Mean", "Absolute", "Error", "(MAE)."], "cited_papers": [{"title": "Multi-sample dropout for accelerated training and better generalization", "year": "2019", "authors": ["Hiroshi Inoue"]}], "target_citation_location": 146, "citation_locations": [146], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "326dc2a7-b307-4739-95de-336b862fc960", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["1", "https://parl.ai/projects/light", "Quests", "in", "LIGHT", "(Ammanabrolu et al., 2021)", "take", "the", "form", "of", "a", "short", "motivation", "and", "goal", "action", "that", "is", "required", "reach", "the", "world", "state", "required", "to", "finish", "the", "game.", "For", "example,", "if", "the", "short", "motivation", "is", "\"Your", "motivation", "is", "to", "acquire", "a", "sword\",", "then", "the", "corresponding", "goal", "state", "would", "be", "for", "the", "character", "to", "have", "a", "sword", "in", "their", "inventory", "and", "goal", "action", "would", "be", "get", "sword.", "This", "environment", "also", "contains", "a", "set", "of", "human", "expert", "demonstration", "of", "people", "speaking", "and", "acting", "in", "character", "while", "playing", "the", "quests", "mentioned", "above.", "Further", "details", "are", "found", "in", "Appendix", "A.1."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "330b46ff-b24d-41ae-bae1-1c17b29b1ef3", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["The", "Factored", "neural", "machine", "translation", "is", "an", "extension", "of", "the", "standard", "NMT", "architecture", "which", "allows", "us", "generating", "several", "output", "symbols", "simultaneously", "as", "presented", "in", "For", "simplicity", "reasons,", "only", "two", "symbols", "are", "generated:", "the", "lemma", "and", "the", "concatenation", "of", "the", "different", "factors", "that", "we", "consider.", "For", "example,", "from", "the", "French", "word", "devient,", "we", "obtain", "the", "lemma", "devenir", "and", "the", "factors", "VP3#S,", "meaning", "that", "it", "is", "a", "Verb,", "in", "Present,", "3rd", "person,", "irrelevant", "gender", "(#)", "and", "Singular.", "The", "morphological", "and", "grammatical", "analysis", "is", "performed", "with", "the", "MACAON", "toolkit", "[17].", "MACAON", "POS-tagger", "outputs", "the", "lemma", "and", "factors", "for", "each", "word", "taking", "into", "account", "its", "context.", "For", "the", "very", "few", "cases", "when", "MACAON", "proposes", "multiple", "factors,", "the", "first", "proposition", "is", "taken.", "The", "decoder", "of", "the", "FNMT", "architecture", "presented", "in", "Figure", "3", "may", "lead", "to", "sequences", "with", "different", "length", "since", "lemmas", "and", "factors", "are", "generated", "in", "a", "synchronous", "stream,", "but", "in", "separate", "outputs.", "Indeed,", "each", "sequence", "of", "symbols", "ends", "when", "the", "end-of-sequence", "(&lt,eos&gt,)", "symbol", "is", "generated", "with", "this", "architecture,", "and", "nothing", "prevents", "the", "lemma", "generator", "to", "output", "the", "&lt,eos&gt,", "symbol", "before", "or", "after", "the", "factors", "generator.", "To", "avoid", "this", "scenario,", "the", "length", "of", "the", "factors", "sequence", "is", "constricted", "to", "be", "equal", "to", "the", "length", "of", "the", "lemma", "sequence.", "This", "implies", "that", "to", "ignore", "the", "&lt,eos&gt,", "symbol", "for", "factors", "(to", "avoid", "shorter", "factors", "sequence)", "and", "stop", "the", "generation", "of", "factors", "when", "the", "lemma", "sequence", "has", "ended", "(to", "avoid", "longer", "factors", "sequence).", "This", "is", "motivated", "by", "the", "fact", "that", "the", "lemmas", "are", "closer", "to", "the", "final", "objective", "(a", "sequence", "of", "words)", "and", "that", "they", "are", "the", "symbols", "carrying", "most", "of", "the", "meaning."], "cited_papers": [{"title": "Macaon, an nlp tool suite for processing word lattices", "year": "2011", "authors": ["A Nasr", "F B\u00e9chet", "J.-F Rey", "B Favre", "J Roux"]}], "target_citation_location": 86, "citation_locations": [86], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "336c85b7-081b-4404-8779-d3c630934907", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["der", "Goot", "(2022)", "(MaChAmp)", "proposed", "to", "pretrain", "a", "language", "model", "and", "re-finetune", "after", "multitask", "learning", "for", "a", "pre-defined", "set", "of", "semantically", "focused", "NLP", "tasks.", "They", "trained", "a", "multi-task", "model", "for", "all", "text-based", "SemEval", "tasks", "that", "include", "annotation", "on", "the", "word,", "sentence,", "or", "paragraph", "level.", "They", "compared", "the", "performance", "with", "models", "using", "mBERT", "(Devlin et al., 2019).", "The", "pretrained", "multi-task", "embedding", "showed", "a", "consistent", "improvement", "across", "many", "tasks", "against", "the", "mBERT", "embedding."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 52, "citation_locations": [52], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "3406cd9e-89bb-4365-a856-bb42f4dc5c7a", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Data", "Augmentation", "The", "third", "strategy", "aims", "to", "alleviate", "the", "issue", "of", "limited", "training", "data.", "Since", "the", "cross-encoder", "is", "more", "powerful", "in", "measuring", "the", "similarity", "between", "questions", "and", "passages,", "we", "utilize", "it", "to", "annotate", "unlabeled", "questions", "for", "data", "augmentation.", "Specifically,", "we", "incorporate", "a", "new", "collection", "of", "unlabeled", "questions,", "while", "reuse", "the", "passage", "collection.", "Then,", "we", "use", "the", "learned", "crossencoder", "to", "predict", "the", "passage", "labels", "for", "the", "new", "questions.", "To", "ensure", "the", "quality", "of", "the", "automatically", "labeled", "data,", "we", "only", "select", "the", "predicted", "positive", "and", "negative", "passages", "with", "high", "confidence", "scores", "estimated", "by", "the", "cross-encoder.", "Finally,", "the", "automatically", "labeled", "data", "is", "used", "as", "augmented", "training", "data", "to", "learn", "the", "dual", "encoder.", "Another", "view", "of", "the", "data", "augmentation", "is", "knowledge", "distillation", "(Hinton et al., 2015),", "where", "the", "cross-encoder", "is", "the", "teacher", "and", "the", "dual-encoder", "is", "the", "student."], "cited_papers": [{"title": "Distilling the knowledge in a neural network", "year": "2015", "authors": ["Geoffrey Hinton", "Oriol Vinyals", "Jeffrey Dean"]}], "target_citation_location": 118, "citation_locations": [118], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "34c603da-dfc3-47d1-bd9d-31afa18dc65c", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["Moreover,", "we", "also", "compared", "the", "FNMT", "system", "to", "the", "multiway,", "multilingual", "NMT", "system", "[16].", "This", "method", "can", "train", "several", "encoder", "and", "decoders", "sharing", "only", "the", "attention", "mechanism", "between", "them.", "In", "order", "to", "reproduce", "our", "experiments", "using", "the", "multilingual", "architecture,", "we", "used", "one", "input", "encoder", "(at", "word-level)", "for", "English", "and", "two", "separate", "decoders:", "French", "lemmas", "and", "French", "factors.", "The", "final", "word", "is", "obtained", "by", "the", "factors-to-word", "process", "as", "used", "with", "our", "FNMT", "system.", "As", "presented", "in", "Table", "1,", "Multilingual", "approach", "performs", "better", "than", "all", "other", "systems", "at", "lemma", "and", "factors", "level.", "However,", "the", "performance", "at", "word", "level", "is", "the", "lowest", "due", "to", "the", "desyncronization", "of", "the", "two", "outputs", "which", "are", "trained", "independently."], "cited_papers": [{"title": "Multi-way, multilingual neural machine translation with a shared attention mechanism", "year": "2016", "authors": ["O Firat", "K Cho", "Y Bengio"]}], "target_citation_location": 13, "citation_locations": [13], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "34ef890c-ecf7-49af-af6f-b493b2f656d3", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["These", "methods", "directly", "incorporate", "handengineered", "features", "and", "personal", "traits", "of", "users", "or", "their", "communities", "in", "order", "to", "model", "the", "likelihood", "of", "abusive", "language", "in", "the", "users'", "comments,", "a", "process", "known", "as", "profiling", "(Zhang et al., 2018).", "Dadvar et al. (2013)", "included", "the", "age", "of", "users", "alongside", "other", "traditional", "lexicon-based", "features", "to", "detect", "cyber-bullying,", "while", "Gal\u00e1n-Garc\u00eda", "et", "al.", "(2016)", "utilized", "the", "time", "of", "publication,", "geo-position,", "and", "language", "in", "the", "profile", "of", "Twitter", "users.", "Waseem and Hovy (2016)", "exploited", "gender", "of", "Twitter", "users", "on", "top", "of", "character", "n-gram", "counts", "to", "improve", "detection", "of", "sexism", "and", "racism", "in", "a", "dataset", "comprising", "racist,", "sexist", "and", "benign", "tweets", "-they", "noted", "that", "the", "F", "1", "increased", "slightly", "from", "73.89%", "to", "73.93%", "when", "the", "gender", "feature", "was", "included.", "Using", "the", "same", "setup,", "Unsv\u00e5g", "and", "Gamb\u00e4ck", "(2018)", "showed", "that", "the", "inclusion", "of", "social", "community", "(i.e.,", "number", "of", "followers", "and", "friends)", "and", "activity", "(i.e.,", "number", "of", "status", "updates", "and", "favorites)", "features", "of", "users", "alongside", "their", "gender", "further", "enhanced", "performance", "by", "3", "F", "1", "points", "over", "the", "n-gram", "baseline."], "cited_papers": [{"title": "Improving cyberbullying detection with user context", "year": "2013", "authors": ["Maral Dadvar", "Dolf Trieschnigg", "Roeland Ordelman", "Franciska De", "Jong unk"]}], "target_citation_location": 33, "citation_locations": [32, 33, 66], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "35921b7e-a1c6-4818-88ea-d9a8e51636ac", "citing_paper": {"title": "Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets", "year": 2021, "authors": ["George-Andrei Dima", "Dumitru-Clementin Cercel", "Mihai Dascalu"]}, "text": ["Our", "model", "achieved", "the", "highest", "score", "for", "subtask", "1b", "(i.e.,", "adverse", "effect", "span", "detection)", "with", "an", "F", "1", "-score", "of", "51%,", "arguing", "that", "MTL", "can", "enhance", "adverse", "effect", "extraction", "from", "social", "media", "posts.", "In", "terms", "of", "future", "work,", "adversarial", "training", "(Miyato et al., 2018, Chen et al., 2020a)", "will", "be", "considered", "to", "improve", "the", "robustness", "of", "our", "approach."], "cited_papers": [{"title": "Self-supervised adversarial training", "year": "2020", "authors": ["Kejiang Chen", "Yuefeng Chen", "Hang Zhou", "Xiaofeng Mao", "Yuhong Li", "Yuan He", "Hui Xue", "Weiming Zhang", "Nenghai Yu"]}, {"title": "Virtual adversarial training: a regularization method for supervised and semisupervised learning", "year": "2018", "authors": ["Takeru Miyato", "Masanori Shin-Ichi Maeda", "Shin Koyama", "unk Ishii"]}], "target_citation_location": 40, "citation_locations": [40], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "35b7ad85-897b-44cf-8860-5f7bb3cf3394", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["CNN-Text", "(Kim, 2014)", "is", "the", "use", "of", "CNN (LeCun et al., 1989)", "network", "on", "word", "embeddings", "to", "perform", "the", "classification", "tasks."], "cited_papers": [{"title": "Convolutional neural networks for sentence classification", "year": "2014", "authors": ["Yoon Kim"]}], "target_citation_location": 1, "citation_locations": [1, 6], "citation_type": "single", "annotations": [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "3603c3c4-dd33-4485-a60a-3d694f77b949", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["(1)", "(2)", "the", "integration", "label", "[b-1", "e0", "n0", "p0", "s0", "t0", "x0]", "indicates", "that", "1", "should", "be", "subtracted", "from", "that", "to", "get", "to", "the", "actual", "relative", "index.", "This", "allows", "was", "in", "our", "example", "to", "have", "the", "same", "fragment", "as", "in", "Someone", "was", "tricked,", "where", "the", "subject", "does", "not", "introduce", "a", "presupposition", "and", "the", "actual", "index", "is", "thus", "-1", "rather", "than", "-2", "because", "there", "is", "one", "less", "box", "intervening.", "2", "Another", "important", "factorization", "concerns", "largeclass", "and", "open-class", "symbols,", "viz.", "(content-word)", "word", "senses,", "names,", "numbers,", "and", "time", "expressions.", "We", "follow", "Evang (2019)", "in", "replacing", "these", "with", "dummy", "expressions", "in", "the", "fragments", "and", "predicting", "them", "separately,", "as", "explained", "below", "in", "Section", "3.", "We", "also", "follow", "them", "in", "heuristically", "changing", "the", "representation", "of", "first", "and", "second", "person", "pronouns,", "which", "introduce", "\"speaker\"", "and", "\"hearer\"", "constants", "instead", "of", "discourse", "referents", "in", "the", "PMB,", "for", "more", "consistent", "representation", "of", "predicates.b0", "REF", "x0", "b-1", "Name", "x-1", "\"tom\"", "b-1", "PRESUPPOSITION", "b0", "b-2", "male", "\"n.02\"", "x-1", "b-2", "REF", "t0", "b-1", "TPR", "t-1", "\"now\"", "b-1", "Time", "e-1", "t-1", "b-1", "time", "\"n.08\"", "t-1", "b-1", "REF", "e-1", "b-1", "Patient", "e-1", "x-1", "b-1", "trick", "\"v.01\"", "e-1", "(3)", "b0", "REF", "x0", "b-1", "Name", "x-1", "\"DUMMY\"", "b-1", "PRESUPPOSITION", "b0", "b-2", "male", "\"n.02\"", "x-1", "b-1", "REF", "t0", "b-1", "TPR", "t-1", "\"now\"", "b-1", "Time", "e-1", "t-1", "b-1", "time", "\"n.08\"", "t-1", "b-1", "REF", "e-1", "b-1", "Patient", "e-1", "x-1", "b-1", "DUMMY", "\"v.00\"", "e-1", "[b0", "e0", "n0", "p0", "s0", "t0", "x0]", "[b-1", "e0", "n0", "p0", "s0", "t0", "x0]", "[b0", "e0", "n0", "p0", "s0", "t0", "x0]", "tom", "-", "trick", "\"v.01\""], "cited_papers": [{"title": "Transition-based DRS parsing using stack-LSTMs", "year": "2019", "authors": ["Kilian Evang"]}], "target_citation_location": 88, "citation_locations": [88], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "361123f3-238b-4b33-892d-4d3b3338b91e", "citing_paper": {"title": "NEW TABULAR ALGORITHMS FOR LIG PARSING", "year": 2000, "authors": ["Mi G Uel Alonso Jor G E Grana", "Manuel Vilares"]}, "text": ["Several", "parsing", "algorithms", "have", "been", "proposed", "for", "TAG,", "ranging", "from", "simple", "bottom-up", "algorithms,", "like", "CYK", "(17],", "to", "sophisticated", "extensions", "of", "the", "Earley", "'s", "algorithm", "[9].", "In", "order", "to", "improve", "efficiency,", "it", "is", "usual", "to", "translate", "the", "source", "tree", "adjoining", "grammar", "into", "a", "linear", "indexed", "grammar", "[1 6, 12, 13, 17].", "However,", "in", "some", "cases", "is", "not", "possible", "to", "translate", "the", "parsing", "strategy", "from", "TAG", "to", "LIG,", "as", "there", "are", "parsing", "strategies", "for", "TAG", "which", "are", "not", "incorporated", "in", "any", "parsing", "algorithm", "for", "LIG.", "To", "eliminate", "this", "drawback,", "we", "present", "in", "this", "paper", "several", "parsing", "algorithms", "for", "LIG", "which", "mimic", "the", "most", "popular", "parsing", "strategies", "for", "TAG", "[1]."], "cited_papers": [{"title": "Solving the correct-prefix property for TAGs", "year": "1997", "authors": ["M-J Nederhof"]}], "target_citation_location": 24, "citation_locations": [15, 24, 45, 102], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3645ec53-03ca-4891-b947-3fb94e761633", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["In", "addition", "to", "calculating", "the", "relatedness", "between", "words,", "the", "above", "works", "also", "differ", "in", "the", "scoring", "functions", "of", "the", "possible", "clues.", "Without", "limiting", "the", "generality,", "we", "assume", "that", "our", "agent", "plays", "in", "the", "blue", "team,", "that", "is,", "our", "clues", "refer", "to", "the", "blue", "words.", "Using", "the", "notations", "of", "Koyyalagunta et al. (2021),", "let", "c", "be", "a", "possible", "clue", "word,", "I", "n", "a", "set", "of", "targeted", "(intended)", "words,", "that", "is,", "the", "n", "closest", "blue", "words", "to", "c,", "R", "the", "set", "of", "all", "bad", "words", "that", "do", "not", "belong", "to", "the", "team", "(red", "words),", "and", "s(\u2022,", "\u2022)", "a", "function", "that", "calculates", "the", "similarity", "or", "relatedness", "of", "two", "words.", "The", "scoring", "function", "of", "Kim et al. (2019)", "is", "thengKim(c,", "n)", "=", "\uf8f1", "\uf8f2", "\uf8f3", "min", "b\u2208In", "s(c,", "b),", "if", "min", "b\u2208In", "s(c,", "b)", "&gt,", "maxr\u2208R", "s(c,", "r)", "0,", "otherwise.(1)", "Jaramillo et al. (2020)", "takes", "the", "same", "function,", "but", "adds", "penalties", "based", "on", "the", "color", "of", "the", "cards.", "Koyyalagunta et al. (2021),", "on", "the", "other", "hand,", "define", "another", "scoring", "function:"], "cited_papers": [{"title": "Playing codenames with language graphs and word embeddings", "year": "2021", "authors": ["Divya Koyyalagunta", "Anna Sun", "Rachel Draelos", "Cynthia Rudin"]}], "target_citation_location": 145, "citation_locations": [48, 107, 130, 145], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 2, 2, 2, 1, 1, 1, 1]]}
{"id": "36748a8b-0998-4c74-bda5-2268b0e3d9cc", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["In", "this", "step,", "we", "will", "extract", "both", "genuine", "tokens", "and", "shortcut", "tokens", "because", "they", "are", "both", "likely", "to", "affect", "a", "model's", "prediction.", "We", "rely", "on", "interpretability", "techniques", "to", "collect", "information", "on", "whether", "a", "certain", "input", "token", "is", "important", "to", "model's", "decision", "making.", "In", "this", "paper,", "we", "use", "the", "attention", "score", "in", "BERT-based", "models", "as", "an", "explanation", "of", "model", "predictions", "(Clark et al., 2019b, Kovaleva et al., 2019),", "due", "to", "its", "simplicity", "and", "fast", "computation.", "Recent", "work", "(Jiaao et al., 2021)", "also", "reveals", "that", "attention", "scores", "outperform", "other", "explanation", "techniques", "in", "regularizing", "redundant", "information.", "Other", "techniques", "(Ribeiro et al., 2016, Sundararajan et al., 2017, Chen et al., 2020, Jacovi et al., 2021)", "can", "also", "be", "used", "in", "this", "step.", "As", "an", "example,", "given", "a", "sentence", "\"Spielberg", "is", "a", "good", "director.\",", "assuming", "\"good\"", "is", "a", "genuine", "token", "and", "\"Spielberg\"", "is", "a", "shortcut", "token,", "we", "expect", "that", "in", "a", "BERT-based", "sentiment", "classification", "model,", "the", "attention", "scores", "for", "\"good\"", "and", "\"Spielberg\"", "are", "higher", "and", "thus", "will", "be", "extracted", "as", "important", "tokens.", "On", "the", "other", "hand,", "for", "\"is\",", "\"a\"", "and", "\"director\"", "the", "attention", "scores", "would", "be", "lower", "as", "they", "are", "relatively", "less", "useful", "to", "the", "model", "decision."], "cited_papers": [{"title": "Hiddencut: Simple data augmentation for natural language understanding with better generalizability", "year": "2021", "authors": ["Chen Jiaao", "Chen Shen Dinghan", "Yang Weizhu", "unk Diyi"]}], "target_citation_location": 69, "citation_locations": [59, 69, 85], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "368cb02f-87bf-462d-a7f7-446cc1937185", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["We", "compare", "the", "output", "of", "Epitran", "and", "Allosaurus", "on", "the", "ALFFA", "dataset.", "Following", "the", "practice", "of", "(Li et al., 2020),", "we", "used", "the", "editdistance", "10", "library", "to", "calculate", "the", "Phone", "Error", "Rate", "(PER).", "Having", "no", "ground", "truth", "phone", "annotations,", "we", "instead", "take", "Epitran's", "outputs", "as", "\"ground", "truth\"", "for", "comparison.", "The", "mean", "PER", "between", "the", "outputs", "is", "23.7%.", "This", "result", "is", "consistent", "with", "Siminyu et al. (2021),", "which", "finds", "PERs", "as", "high", "as", "72.8%", "when", "testing", "on", "on", "the", "Bukusu", "(bxk),", "Saamia", "(lsm)", "and", "East", "Tusom", "languages", "(an", "endangered", "subdialect", "of", "the", "Tungkhulic", "language", "family).", "However,", "by", "training", "the", "phone", "recognizer", "on", "even", "minimal", "amounts", "of", "data", "in", "these", "languages,", "PERs", "were", "improved", "significantly."], "cited_papers": [{"title": "Phoneme recognition through fine tuning of phonetic representations: a case study on luhya language varieties", "year": "2021", "authors": ["Kathleen Siminyu", "Xinjian Li", "Antonios Anastasopoulos", "David Mortensen", "Michael Marlo", "Graham Neubig"]}], "target_citation_location": 59, "citation_locations": [16, 59], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "369c7783-f682-47bc-8f2f-dd86bfaa2af6", "citing_paper": {"title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection", "year": 2021, "authors": ["Henry Weld", "Guanghao Huang", "Jean Lee", "Tongshu Zhang", "Kunze Wang", "Xinghong Guo", "Siqu Long", "Josiah Soyeon", "Caren Han"]}, "text": ["Capsule", "NN", "(Zhang et al., 2019a)", "is", "a", "capsule-based", "neural", "network", "that", "explicitly", "captures", "the", "semantic", "hierarchical", "relationship", "among", "words,", "slots", "and", "intents", "via", "a", "dynamic", "routing-by-agreement", "schema."], "cited_papers": [{"title": "Joint slot filling and intent detection via capsule neural networks", "year": "2019", "authors": ["Chenwei Zhang", "Yaliang Li", "Nan Du", "Wei Fan", "S Yu Philip"]}], "target_citation_location": 2, "citation_locations": [2], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "36b34d59-a34c-4929-b1f4-2410a7617864", "citing_paper": {"title": "Can Semantic Role Labeling Improve SMT?", "year": 2009, "authors": ["Dekai Wu", "Pascale Fung"]}, "text": ["In", "experiments", "carried", "out", "on", "PropBank", "data", "using", "gold", "standard", "syntactic", "parse", "trees,", "extended", "syntactic", "features", "such", "as", "Path", "Trigram", "and", "Path", "Abbreviations", "were", "found", "to", "have", "the", "highest", "contribution", "to", "system", "performance", "(Fung et al., 2006).", "Another", "feature,", "Verb", "Cluster,", "was", "also", "found", "to", "be", "most", "useful", "by", "Xue and Palmer (2005)."], "cited_papers": [{"title": "Automatic learning of chinese-english semantic structure mapping", "year": "2006", "authors": ["Pascale Fung", "Zhaojun Wu", "Yongsheng Yang", "Dekai Wu"]}], "target_citation_location": 33, "citation_locations": [33, 46], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "36b8160b-cdb9-4bfa-969f-16e3469adcee", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Once", "an", "agent", "acts", "or", "talks,", "the", "partner", "agent-in", "this", "case", "also", "a", "polyencoder", "(Humeau et al., 2020)", "trained", "to", "react", "to", "agents", "with", "motivations-also", "acts", "or", "talks", "and", "this", "information", "is", "processed", "by", "the", "environment.", "As", "recommended", "by", "Prabhumoye", "et", "al.", "(2020),", "Ammanabrolu et al. (2021),", "we", "keep", "the", "partner", "model", "fixed", "during", "the", "episodes", "where", "the", "LIGHT", "agent", "trains", "to", "ensure", "that", "it", "retains", "natural", "English", "semantics-avoiding", "the", "problem", "of", "language", "drift", "by", "learning", "an", "emergent", "language", "with", "that", "must", "agree", "with", "the", "partner's", "usage", "(Lee et al., 2019)."], "cited_papers": [{"title": "Countering language drift via visual grounding", "year": "2019", "authors": ["Jason Lee", "Kyunghyun Cho", "Douwe Kiela"]}], "target_citation_location": 81, "citation_locations": [14, 40, 81], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "372c85ac-7fc8-4c5d-a812-2299205075ae", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["Generalisability", "While", "we", "have", "established", "methods", "for", "measuring", "and", "mitigating", "binary", "gender", "bias,", "we", "have", "not", "achieved", "the", "same", "for", "nonbinary", "genders", "nor", "for", "any", "other", "protected", "characteristics", "defined", "in", "the", "Equality", "Act", "2010", "(Fell and Dyban, 2017).", "Practitioners", "tackling", "more", "varied", "presentations", "of", "identity-directed", "bias", "may", "be", "less", "able", "to", "find", "pre-existing", "lists", "of", "biased", "words", "to", "define", "bias", "measurements."], "cited_papers": [{"title": "Against discrimination: equality act 2010 (UK)", "year": "2017", "authors": ["Elena Vladimirovna Fell", "Maria Dyban"]}], "target_citation_location": 34, "citation_locations": [34], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "37685f01-9521-424c-a055-5cfdde38cc50", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["The", "Semantic", "Network", "Array", "Processor", "(SNAP)", "is", "a", "highly", "parallel", "array", "processor", "fully", "optimized", "for", "semantic", "network", "processing", "with", "marker-passing", "mechanism.", "In", "order", "to", "facilitate", "efficient", "propagation", "of", "markers", "and", "to", "ease", "development", "of", "applications,", "a", "set", "of", "marker", "propagation", "instructions", "has", "been", "microcoded.", "SNAP", "supports", "propagation", "of", "markers", "containing", "(1)", "bit-vectors.", "(2)", "address,", "and", "(3)", "numeric", "value.", "By", "limiting", "content", "of", "markers,", "significant", "reduction", "in", "cost", "and", "resource", "has", "been", "attained", "without", "undermining", "performance", "requirements", "for", "knowledge", "processing.", "Several", "AI", "applications", "such", "as", "natural", "language", "processing", "system,", "classification", "system", "[Kim and Moldovan, 1990],", "and", "rule-based", "system", "has", "been", "developed", "on", "SNAP."], "cited_papers": [{"title": null, "year": "1990", "authors": ["J Kim", "D Moldovan"]}], "target_citation_location": 90, "citation_locations": [90], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "376ebc0e-173a-486f-affa-6468067738d0", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["In", "this", "section", "we", "provide", "a", "short", "overview", "of", "six", "widely", "used", "disentanglement", "metrics,", "highlighting", "their", "key", "differences", "and", "commonalities,", "and", "refer", "the", "readers", "to", "the", "corresponding", "papers", "for", "exact", "details", "of", "computations.", "Eastwood and Williams (2018)", "define", "three", "criteria", "for", "disentangled", "representations:", "disentanglement,", "which", "measures", "the", "degree", "of", "one", "dimension", "only", "encoding", "information", "about", "no", "more", "than", "one", "generative", "factor,", "completeness,", "which", "measures", "whether", "a", "generative", "factor", "is", "only", "captured", "by", "one", "latent", "variable,", "informativeness,", "which", "measures", "the", "degree", "by", "which", "representations", "capture", "exact", "values", "of", "the", "generative", "factors.", "2", "They", "design", "a", "series", "of", "classification", "tasks", "to", "predict", "the", "value", "of", "a", "generative", "factor", "based", "on", "the", "latent", "code,", "and", "extract", "the", "relative", "importance", "of", "each", "latent", "code", "for", "each", "task", "to", "calculate", "disentanglement", "and", "completeness", "scores.", "Informativeness", "score", "is", "measured", "by", "the", "accuracy", "of", "the", "classifier", "directly.", "Other", "existing", "metrics", "reflect", "at", "least", "one", "of", "these", "three", "criteria,", "as", "summarised", "in", "Table", "1", "Higgins et al. (2017)", "focus", "on", "disentanglement", "and", "propose", "to", "use", "the", "absolute", "difference", "of", "two", "groups", "of", "representations", "with", "the", "same", "value", "on", "one", "generative", "factor", "to", "predict", "this", "generative", "factor.", "For", "perfectly", "disentangled", "representations,", "latent", "dimensions", "not", "encoding", "information", "about", "this", "generative", "factor", "would", "have", "zero", "difference.", "Hence,", "even", "simple", "linear", "classifiers", "could", "easily", "identify", "the", "generative", "factors", "based", "on", "the", "changes", "of", "values.", "Kim and Mnih (2018)", "consider", "both", "disentanglement", "and", "completeness", "by", "first", "finding", "the", "dimension", "which", "has", "the", "largest", "variance", "when", "fixing", "the", "value", "on", "one", "generative", "factor,", "and", "then", "using", "the", "found", "dimension", "to", "predict", "that", "generative", "factor.", "Kumar et al. (2018)", "propose", "a", "series", "of", "classification", "tasks", "each", "of", "which", "uses", "a", "single", "latent", "variable", "to", "predict", "the", "value", "of", "a", "generative", "factor", "and", "treat", "the", "average", "of", "the", "difference", "between", "the", "top", "two", "accuracy", "scores", "for", "each", "generative", "factor", "as", "the", "final", "disentanglement", "score."], "cited_papers": [{"title": "A framework for the quantitative evaluation of disentangled representations", "year": "2018", "authors": ["Cian Eastwood", "K Christopher", "unk Williams"]}], "target_citation_location": 33, "citation_locations": [33, 153, 216, 251], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "37a1935c-b17a-475e-ae29-cf1cf00d3eac", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["Moreover,", "these", "LLMs", "are", "known", "to", "have", "flaws.", "BERT", "in", "particular", "has", "been", "shown", "to", "be,", "in", "certain", "scenarios,", "insensitive", "to", "negation", "(Ettinger, 2020)", "and", "word", "order", "(Pham et al., 2020).", "BERT", "also", "has", "inexact", "representations", "of", "numbers", "(Wallace et al., 2019)", "and", "fails", "to", "be", "robust", "to", "named", "entities", "(Balasubramanian et al., 2020).", "All", "of", "these", "phenomena", "could", "result", "in", "poor-quality", "scores", "from", "BERTScore.", "However,", "it", "is", "difficult", "to", "say", "for", "certain", "how", "these", "issues", "might", "manifest", "in", "BERTScore,", "as", "it", "employs", "BERT", "in", "an", "unsupervised", "scenario", "distinct", "from", "that", "of", "these", "analyses."], "cited_papers": [{"title": "What's in a name? are BERT named entity representations just as good for any other name?", "year": "2020", "authors": ["Sriram Balasubramanian", "Naman Jain", "Gaurav Jindal", "Abhijeet Awasthi", "Sunita Sarawagi"]}], "target_citation_location": 43, "citation_locations": [22, 26, 34, 43], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0]]}
{"id": "37ae9613-35f6-485c-8f11-97dc211149f4", "citing_paper": {"title": "NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques", "year": 2021, "authors": ["Gunjan Chhablani", "Abheesht Sharma", "Harshit Pandey", "Yash Bhartia", "Shan Suthaharan"]}, "text": ["Hanu", "and", "Unitary", "team", "(2020)", "introduced", "Detoxify,", "a", "comment", "detection", "library", "modeled", "using", "HuggingFace's", "transformers", "(Wolf et al., 2020)", "to", "identify", "inappropriate", "or", "harmful", "text", "online", "as", "a", "result", "of", "participation", "in", "three", "such", "challenges.", "In", "a", "contemporary", "work,", "Pavlopoulos et al. (2020)", "discuss", "context", "requirement", "for", "toxicity", "detection."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 15, "citation_locations": [15, 36], "citation_type": "single", "annotations": [[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3834abf2-9ea1-4f00-abdb-899a98fd422b", "citing_paper": {"title": "Controlled Text Generation with Adversarial Learning", "year": 2020, "authors": ["Federico Betti", "Giorgia Ramponi", "Massimo Piccardi"]}, "text": ["The", "syntax", "discriminator", "takes", "as", "input", "either", "a", "real", "sentence,", "r", "=", "(r", "1", ",...,", "r", "n", "),", "or", "a", "generated", "one,g", "=", "(g", "1", ",...,", "g", "n", ").Similarly", "to", "many", "other", "works", "(e.g.,", "[9, 23]", "),", "the", "discriminator", "first", "transforms", "its", "input", "into", "an", "embedding", "matrix.", "This", "embedding", "allows", "learning", "a", "transformation", "that", "condenses", "the", "information", "brought", "in", "by", "each", "word", "optimally", "for", "any", "given", "task.", "The", "syntax", "discriminator", "is", "then", "built", "using", "two", "convolutional", "layers", "with", "ReLU", "activation", "functions,", "followed", "by", "a", "self-attention", "layer,", "again", "followed", "by", "two", "other", "convolutional", "layers", "with", "ReLU", "activation", "functions.", "The", "selfattention", "layer", "is", "used", "to", "attend", "to", "the", "output", "of", "the", "previous", "convolutional", "layer", "and", "select", "the", "most", "useful", "features.", "The", "final", "layers", "generate", "the", "decision."], "cited_papers": [{"title": null, "year": "2016", "authors": ["Lantao Yu", "Weinan Zhang", "Jun Wang", "Yong Yu", "unk Seqgan"]}, {"title": "Long text generation via adversarial training with leaked information", "year": "2018", "authors": ["Jiaxian Guo", "Sidi Lu", "Han Cai", "Weinan Zhang", "Yong Yu", "Jun Wang"]}], "target_citation_location": 34, "citation_locations": [34], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3848be40-d7f3-4bbe-a519-21144af097b2", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["To", "address", "our", "considerations", "related", "to", "resource", "constraints", "we", "perform", "a", "hyperparameter", "optimization,", "that", "has", "proven", "to", "lead", "to", "better", "solutions", "in", "less", "time.", "It", "is", "based", "on", "a", "population-based", "learning", "(Jaderberg et al., 2017)", "in", "which", "a", "population", "of", "models", "and", "their", "hyperparameters", "are", "jointly", "optimized.", "To", "this", "end,", "we", "build", "a", "validation", "set", "by", "randomly", "extracting", "10%", "of", "the", "training", "data."], "cited_papers": [{"title": null, "year": "2017", "authors": ["Max Jaderberg", "Valentin Dalibard", "Simon Osindero", "Wojciech Czarnecki", "Jeff Donahue", "Ali Razavi", "Oriol Vinyals", "Tim Green", "Iain Dunning", "Karen Simonyan"]}], "target_citation_location": 31, "citation_locations": [31], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "389ddc80-bad8-4408-bc36-7c03b84036a6", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["In", "[5],", "authors", "propose", "to", "carefully", "organise", "the", "batches", "so", "that", "only", "a", "subset", "K", "of", "the", "target", "vocabulary", "is", "possibly", "generated", "at", "training", "time.", "This", "allows", "the", "system", "to", "train", "a", "model", "with", "much", "larger", "target", "vocabulary", "without", "substantially", "increasing", "the", "computational", "complexity.", "Another", "alternative", "is", "proposed", "by", "[6]", "where", "a", "structured", "output", "layer", "(SOUL)", "is", "defined", "to", "handle", "the", "words", "not", "appearing", "in", "the", "shortlist.", "This", "allows", "the", "system", "to", "always", "apply", "the", "softmax", "normalization", "on", "a", "layer", "with", "reduced", "size."], "cited_papers": [{"title": "On using very large target vocabulary for neural machine translation", "year": null, "authors": ["S Jean", "K Cho", "R Memisevic", "Y Bengio"]}], "target_citation_location": 1, "citation_locations": [1, 49], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "39672bdb-ec13-4e13-9c09-f3a1bd75225f", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["BERT-based", "models", "have", "the", "advantage", "that", "we", "can", "directly", "use", "the", "attention", "scores", "as", "explanations", "of", "model", "decisions.", "For", "models", "with", "other", "architectures,", "we", "can", "use", "explanation", "techniques", "such", "as", "LIME", "(Ribeiro et al., 2016)", "or", "Path", "Integrated", "Gradient", "approaches", "(Sundararajan et al., 2017)", "to", "provide", "explanations."], "cited_papers": [{"title": "Axiomatic attribution for deep networks", "year": "2017", "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"]}], "target_citation_location": 37, "citation_locations": [31, 37], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2]]}
{"id": "3abeb9fd-3b54-4c2f-98bf-5359ac433eab", "citing_paper": {"title": "NEW TABULAR ALGORITHMS FOR LIG PARSING", "year": 2000, "authors": ["Mi G Uel Alonso Jor G E Grana", "Manuel Vilares"]}, "text": ["The", "space", "complexity", "of", "the", "algorithm", "with", "respect", "to", "the", "length", "n", "of", "the", "input", "string", "is", "O(n", "5", "),", "due", "to", "the", "five", "positions", "of", "the", "input", "string", "stored", "in", "each", "item.", "The", "time", "complexity", "is", "O(n", "7)", "due", "to", "deduction", "steps", "in", "the", "set", "v\ufffd::?:},", "0", "H", "00", "-Yl.", "To", "reduce", "the", "time", "complexity", "we", "will", "use", "a", "technique", "similar", "to", "that", "used", "in", "[5, 2]", "to", "reduce", "the", "complexity", "of", "the", "tabular", "interpretations", "of", "automata", "for", "tree", "adjoining", "languages.", "In", "this", "case,", "we", "split", "each", "deduction", "step", "in", "v\ufffd::?:},", "0", "H", "00", "-Yl", "into", "two", "different", "steps", "such", "that", "their", "final", "complexity", "is", "at", "most", "O(n", "6", ").", "The", "resulting", "parsing", "schema", "is", "defined", "by", "the", "following", "parsing", "system.", "6)", "for", "a", "linear", "indexed", "grammar", "g", "and", "a", "input", "string", "a", "1", "...", "an", "is", "defined", "as", "fo", "llows:,", "-,", "-],", "The", "LIG", "so", "generated", "does", "not", "satisfy", "our", "definition", "of", "shared", "forest", "because", "single", "parse", "trees", "can", "not", "be", "extracted", "in", "linear", "time.", "Vijay-Shanker", "and", "Weir", "[18]", "try", "to", "solve", "this", "problem", "by", "defining", "a", "non-deterministic", "finite", "state", "automaton", "that", "determines", "if", "a", "given", "LIGed", "forest", "symbol", "(A,", "i,", "j)[a:]", "derives", "a", "string", "of", "terminals.", "A", "similar", "finite-state", "automata", "is", "also", "defined", "by", "Nederhof", "in", "[11]."], "cited_papers": [{"title": "Models of tabulation for TAG parsing", "year": "1999", "authors": ["M-J Nederhof"]}], "target_citation_location": 208, "citation_locations": [66, 169, 208], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "3b1d9793-0def-436a-8d1f-213082f8a9a1", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["The", "system", "of", "Han et al. (2000)", "pairs", "two", "dependency", "trees", "based", "on", "a", "Deep", "Syntactic", "Structure", "(DSyntS)", "of", "Meaning", "Text", "Theory", "(MTT)", "(Mel'\u010duk, 1988),", "a", "dependency", "representation", "composed", "of", "nodes", "labeled", "by", "lexemes", "that", "correspond", "to", "meaning-bearing", "words", "(nouns,", "verbs,", "adjectives,", "adverbs)", "and", "directed", "arcs", "with", "dependency", "relation", "labels.", "Transfer", "rules", "are", "also", "represented", "by", "DSyntS", "trees,", "with", "variables.", "3", "The", "goal", "of", "this", "particular", "dependency", "representation", "is", "to", "minimise", "'spurious'", "structural", "divergences,", "such", "as", "when", "a", "preposition", "in", "one", "language", "is", "represented", "by", "a", "verbal", "inflection", "in", "the", "other.", "However,", "some", "divergences", "still", "occur,", "as", "in", "(1).", "The", "transfer", "rule", "then", "requires", "that", "the", "two", "nodes", "is", "and", "small", "pair", "with", "the", "single", "node", "cakayo:", "a", "transfer", "rule", "for", "Figure", "1,", "treating", "them", "as", "a", "gCN,", "would", "be", "as", "in", "the", "righthand", "side", "of", "that", "figure.", "4", "However,", "there", "are", "constructions", "which", "cannot", "be", "handled", "in", "such", "a", "way.", "Consider", "the", "translation", "pair", "in", "(3)."], "cited_papers": [{"title": "Handling Structural Divergences and Recovering Dropped Arguments in a Korean/English Machine Translation System", "year": "2000", "authors": ["H Grune", "C Bal", "K Jacobs", "unk Langendoen", "U Chichester", "B Han", "M Lavoie", "O Palmer", "R Rambow", "T Kittredge", "N Korelsky", "M Kim", "unk Kim"]}], "target_citation_location": 3, "citation_locations": [3, 20], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3b216670-843b-43f5-ab05-3fa73cc437f8", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["Hierarchical", "rules", "are", "extracted", "from", "the", "training", "corpus", "by", "subtracting", "continuous", "phrase-pairs", "attested", "in", "the", "translation", "table", "recursively", "from", "longer", "phrases", "and", "replacing", "them", "with", "the", "non-terminal", "symbol", "X.", "Non-terminals", "in", "hierarchical", "rules", "act", "as", "placeholders", "that", "are", "replaced", "with", "other", "phrases", "during", "translation", "in", "a", "bottom-up", "fashion.", "Hierarchical", "rules", "are", "extracted", "from", "the", "training", "corpus", "without", "using", "any", "syntactic", "information.", "As", "the", "resulting", "system", "is", "syntactically", "unaware,", "the", "HPB", "SMT", "system", "can", "produce", "ungrammatical", "translations.", "Therefore,", "several", "approaches", "have", "tried", "to", "provide", "the", "HPB", "SMT", "system", "with", "syntactic", "information.", "Syntax", "augmented", "Machine", "Translation", "(SAMT)", "[11]", "uses", "target-side", "phrase-structure", "grammar", "syntactic", "trees", "to", "label", "non-terminals", "in", "hierarchical", "rules.", "These", "non-terminal", "labels", "represent", "syntactic", "constraints", "imposed", "on", "target", "phrase", "replacements", "during", "translation", "aiming", "to", "produce", "more", "grammatical", "translations."], "cited_papers": [{"title": "Syntax augmented machine translation via chart parsing", "year": "2006", "authors": ["A Zollmann", "A Venugopal"]}], "target_citation_location": 95, "citation_locations": [95], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3beab6e0-900b-4032-a08f-7caf0f91cc74", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["A", "closely", "related", "linguistic", "concept", "and", "an", "established", "task", "in", "the", "last", "decade", "is", "bridging", "anaphora", "resolution", "(Clark, 1975, Loebner, 1998, Poesio and Vieira, 1998, Matsui, 2001, Gardent et al., 2003, Markert et al., 2012, Hou et al., 2013a,b, Nedoluzhko, 2013, Hou et al., 2014, Grishina, 2016, R\u00f6siger, 2018a, Hou et al., 2018, Hou, 2018a Hou, ,b, 2020,, Pagel and Roesiger, 2018, Roesiger et al., 2018a, R\u00f6siger, 2018b, Pandit and Hou, 2021, Kobayashi and Ng, 2021, Hou, 2021).", "Both", "bridging", "anaphora", "resolution", "and", "NP", "Enrichment", "relate", "entities", "mentioned", "in", "the", "text", "via", "non-identity", "relations.", "However,", "there", "are", "a", "number", "of", "major", "differences", "between", "bridging", "and", "NP", "Enrichment.", "These", "differences", "are", "summarized", "in", "Table", "8,", "and", "expanded", "upon", "in", "what", "follows."], "cited_papers": [{"title": "End-to-end neural information status classification", "year": "2021", "authors": ["Yufang Hou"]}, {"title": "Bridging", "year": "1975", "authors": ["H Herbert", "unk Clark"]}, {"title": "Collective classification for fine-grained information status", "year": "2012", "authors": ["Katja Markert", "Yufang Hou", "Michael Strube"]}, {"title": "Probing for bridging inference in transformer language models", "year": "2021", "authors": ["Yufang Onkar Arun Pandit", "unk Hou"]}, {"title": "Which bridges for bridging definite descriptions", "year": "2003", "authors": ["Claire Gardent", "H\u00e9l\u00e8ne Manu\u00e9lian", "Eric Kow"]}, {"title": "Bridging resolution: Making sense of the state of the art", "year": "2021", "authors": ["Hideo Kobayashi", "Vincent Ng"]}, {"title": "Experimental pragmatics: Towards testing relevance-based predictions about anaphoric bridging inferences", "year": "2001", "authors": ["Tomoko Matsui"]}, {"title": "A corpus-based investigation of definite description use", "year": "1998", "authors": ["Massimo Poesio", "Renata Vieira"]}, {"title": "Bashi: A corpus of Wall Street Journal articles annotated with bridging links", "year": "2018", "authors": ["Ina R\u00f6siger"]}, {"title": "Experiments on bridging across languages and genres", "year": "2016", "authors": ["Yulia Grishina"]}, {"title": "Towards bridging resolution in German: Data analysis and rule-based experiments", "year": "2018", "authors": ["Janis Pagel", "Ina Roesiger"]}, {"title": "A rule-based system for unrestricted bridging resolution: Recognizing bridging anaphora and finding links to antecedents", "year": "2014", "authors": ["Yufang Hou", "Katja Markert", "Michael Strube"]}, {"title": "Unrestricted bridging resolution", "year": "2018", "authors": ["Yufang Hou", "Katja Markert", "Michael Strube"]}, {"title": "Integrating predictions from neural-network relation classifiers into coreference and bridging resolution", "year": "2018", "authors": ["Ina Roesiger", "Maximilian K\u00f6per", "Kim Nguyen", "Sabine Schulte Im Walde"]}, {"title": "Rule-and learning-based methods for bridging resolution in the ARRAU corpus", "year": "2018", "authors": ["Ina R\u00f6siger"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "Generic noun phrases and annotation of coreference and bridging relations in the Prague dependency treebank", "year": "2013", "authors": ["Anna Nedoluzhko"]}, {"title": "A deterministic algorithm for bridging anaphora resolution", "year": "2018", "authors": ["Yufang Hou"]}, {"title": "Definite associative anaphora", "year": "1998", "authors": ["Sebastian Loebner"]}], "target_citation_location": 17, "citation_locations": [17], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3c6bcfd4-a6d0-48e8-8772-44e766b159b0", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["In", "this", "paper,", "we", "focus", "on", "addressing", "these", "challenges", "so", "as", "to", "effectively", "train", "a", "dual-encoder", "retriever", "for", "open-domain", "QA.", "We", "propose", "an", "optimized", "training", "approach,", "called", "RocketQA,", "to", "improving", "dense", "passage", "retrieval.", "Considering", "the", "above", "challenges,", "we", "make", "three", "major", "technical", "contributions", "in", "RocketQA.", "First,", "RocketQA", "introduces", "cross-batch", "negatives.", "Comparing", "to", "inbatch", "negatives,", "it", "increases", "the", "number", "of", "available", "negatives", "for", "each", "question", "during", "training,", "and", "alleviates", "the", "discrepancy", "between", "training", "and", "inference.", "Second,", "RocketQA", "introduces", "denoised", "hard", "negatives.", "It", "aims", "to", "remove", "false", "negatives", "from", "the", "top-ranked", "results", "retrieved", "by", "a", "retriever,", "and", "derive", "more", "reliable", "hard", "negatives.", "Third,", "RocketQA", "leverages", "large-scale", "unsupervised", "data", "\"labeled\"", "by", "a", "cross-encoder", "(as", "shown", "in", "Figure", "1b)", "for", "data", "augmentation.", "Though", "inefficient,", "the", "cross-encoder", "architecture", "has", "been", "found", "to", "be", "more", "capable", "than", "the", "dual-encoder", "architecture", "in", "both", "theory", "and", "practice", "(Luan et al., 2020).", "Therefore,", "we", "utilize", "a", "cross-encoder", "to", "generate", "highquality", "pseudo", "labels", "for", "unlabeled", "data", "which", "are", "used", "to", "train", "the", "dual-encoder", "retriever.", "The", "contributions", "of", "this", "paper", "are", "as", "follows:"], "cited_papers": [{"title": "Sparse, dense, and attentional representations for text retrieval. CoRR, abs", "year": null, "authors": ["Yi Luan", "Jacob Eisenstein", "Kristina Toutanova", "Michael Collins"]}], "target_citation_location": 139, "citation_locations": [139], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3cc60145-6873-48c5-844f-3009ebc4eec0", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["To", "examine", "the", "performance", "of", "these", "models", "on", "real-world", "downstream", "task", "setting,", "we", "consider", "the", "classification", "task.", "For", "our", "classification", "datasets,", "we", "use", "DBpedia", "(14", "classes)", "and", "Yahoo", "Question", "(10", "classes)", "(Zhang et al., 2015).", "Each", "class", "of", "these", "two", "datasets", "has", "(10k,", "1k,", "1k)", "randomly", "chosen", "sentences", "in", "(train,", "dev,", "test)", "sets.", "We", "train", "Vanilla-VAE,", "\u03b2-VAE", "(\u03b2", "=", "0.2),", "CCI-VAE", "(C", "=", "10),", "and", "MAT-VAE", "(\u03b2", "=", "0.01,", "\u03bb", "=", "0.1)", "from", "Table", "3", "on", "DBpedia", "and", "Yahoo", "(without", "the", "labels),", "then", "freeze", "the", "trained", "encoders", "and", "place", "a", "classifier", "on", "top", "to", "use", "the", "mean", "vector", "representations", "from", "the", "encoder", "as", "a", "feature", "to", "train", "a", "classifier."], "cited_papers": [{"title": "Character-level convolutional networks for text classification", "year": "2015", "authors": ["Xiang Zhang", "Junbo Zhao", "Yann Lecun"]}], "target_citation_location": 31, "citation_locations": [31], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3ce3908a-1b08-425b-bd5e-b04c41286e0b", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["In", "all", "configurations,", "the", "performance", "in", "terms", "of", "EM", "and", "F1", "on", "PIAF", "remains", "significantly", "lower", "than", "that", "obtained", "on", "FQuAD", "since", "the", "PIAF", "corpus", "does", "not", "include", "multiple", "responses", "as", "pointed", "out", "by", "d", "'Hoffschmidt et al. (2020).", "Unsurprisingly,", "PIAF", "dev", "offer", "a", "more", "challenging", "evaluation", "set,", "where", "the", "answer", "extraction", "performance", "are", "lower.", "Indeed,", "the", "corpus", "is", "more", "diversified", "with", "questions", "on", "191", "different", "Wikipedia", "articles,", "whereas", "on", "FQuAD", "dev", "it", "only", "covers", "18."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 35, "citation_locations": [35], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3d02c644-ec6c-4297-b63f-fe920f6be8b8", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["The", "latest", "article", "on", "the", "topic", "is", "(Koyyalagunta et al., 2021),", "in", "which,", "in", "addition", "to", "the", "previously", "used", "Skip-gram", "and", "GloVe", "word", "embeddings,", "to", "produce", "their", "similarity", "matrices", "they", "use", "FastText", "(Bojanowski et al., 2017),"], "cited_papers": [{"title": "Enriching word vectors with subword information", "year": "2017", "authors": ["Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov"]}], "target_citation_location": 29, "citation_locations": [7, 29], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1]]}
{"id": "3d8cf0cc-d078-44ae-b357-44e848ef41dc", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["sufficient", "to", "solve", "the", "task,", "as", "was", "also", "argued", "in", "Hou (2020)", "and", "Pandit and Hou (2021).", "Finally,", "we", "note", "an", "interesting", "trend", "that", "the", "decoupled", "variant", "favors", "recall", "whereas", "the", "coupled", "variant", "favors", "precision,", "across", "all", "models.", "In", "summary,", "all", "models", "perform", "substantially", "below", "human", "agreement,", "leaving", "a", "large", "room", "for", "improvement."], "cited_papers": [{"title": "Bridging anaphora resolution as question answering", "year": "2020", "authors": ["Yufang Hou"]}], "target_citation_location": 10, "citation_locations": [10, 12], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3dc66c6c-5524-4872-9248-093f0622d9dc", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["Our", "study", "is", "also", "related", "to", "attribution", "approaches,", "which", "aims", "to", "find", "features", "or", "regions", "of", "input", "that", "are", "important", "for", "tasks.", "Different", "types", "of", "techniques,", "including", "gradient-based", "(Selvaraju et al., 2017) and post-hoc (Ribeiro et al., 2018),", "are", "applied", "for", "reinforcement", "learning", "(Mott et al., 2019),", "computer", "vision", "(Adebayo et al., 2018),", "and", "text", "classification", "(Jin et al., 2020).", "While", "these", "works", "focus", "on", "interpreting", "model", "behaviors,", "we", "aim", "to", "find", "salient", "words", "beyond", "input", "and", "utilize", "them", "as", "action", "representations."], "cited_papers": [{"title": "Towards hierarchical importance attribution: Explaining compositional semantics for neural sequence models", "year": "2020", "authors": ["Xisen Jin", "Junyi Du", "Zhongyu Wei", "Xiangyang Xue", "Xiang Ren"]}], "target_citation_location": 41, "citation_locations": [28, 34, 37, 41], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "3e0006fc-3207-4693-934d-8b6ac029b963", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["All", "methods", "and", "materials", "discussed", "in", "this", "paper", "were", "tested", "on", "a", "fully", "functional", "machine", "translation", "system", "based", "on", "Apertium", "(Armentano-Oller et al., 2006)", "and", "(Corb\u00ed-Bellot et al., 2005),", "an", "opensource", "RBMT", "toolkit."], "cited_papers": [{"title": "An open-source shallow-transfer machine translation engine for the romance languages of Spain", "year": "2005", "authors": ["Corb\u00ed-Bellot Antonio", "M Mikel", "L Forcada", "Sergio Ortiz-Rojas", "Juan P\u00e9rez-Ortiz", "Gema S\u00e1nchez-Ramirez", "Felipe S\u00e1nchez-Mart\u00ednez", "I\u00f1aki Alegria", "Aingeru Mayor", "Kepa Sarasola"]}], "target_citation_location": 22, "citation_locations": [20, 22], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1]]}
{"id": "3e575477-fac5-45db-86c2-02f4fb005e5d", "citing_paper": {"title": "Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model", "year": 2022, "authors": ["Richard Futrell"]}, "text": ["The", "log-bilinear", "model", "for", "conditional", "word", "probabilities", "was", "introduced", "in", "a", "language", "modeling", "context", "by", "Mnih and Hinton (2007, 2008).", "Mikolov et al. (2013a)", "influentially", "proposed", "to", "use", "the", "vector", "representations", "output", "by", "the", "word", "encoder", "in", "such", "a", "model", "as", "general", "word", "embeddings.", "The", "current", "work", "aims", "to", "return", "log-bilinear", "models", "to", "their", "language", "modeling", "roots,", "evaluating", "the", "capabilities", "of", "these", "models", "to", "estimate", "co-occurrence", "probabilities", "using", "pretrained", "embeddings", "as", "input,", "with", "a", "focus", "on", "word", "distributions", "where", "training", "data", "is", "limited.", "Here", "the", "target", "word", "vocabulary", "is", "typically", "small", "enough", "that", "the", "partition", "function", "(Eq.", "2)", "can", "be", "computed", "directly", "on", "modern", "hardware,", "so", "that", "approximations", "such", "as", "noisecontrastive", "estimation", "(Mikolov et al., 2013b)", "are", "not", "necessary."], "cited_papers": [{"title": "Efficient estimation of word representations in vector space", "year": "2013", "authors": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"]}], "target_citation_location": 16, "citation_locations": [15, 16, 105], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3e8822c0-a9c5-4056-a38a-f8cc71d5dfd7", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["There", "has", "been", "active", "research", "in", "NLP", "to", "understand", "different", "mechanisms", "of", "argumentation", "computationally.", "Argumentative", "relations", "have", "been", "found", "to", "be", "associated", "with", "various", "statistics,", "such", "as", "discourse", "markers", "(Opitz and Frank, 2019),", "sentiment", "(Allaway and McKeown, 2020),", "and", "use", "of", "negating", "words", "(Niven and Kao, 2019).", "Further,", "as", "framing", "plays", "an", "important", "role", "in", "debates", "(Ajjour et al., 2019),", "different", "stances", "for", "a", "topic", "emphasize", "different", "points,", "resulting", "in", "strong", "thematic", "correlations", "(Lawrence and Reed, 2017).", "Such", "thematic", "associations", "have", "been", "exploited", "in", "stance", "detection", "and", "dis/agreement", "classification.", "Stance", "detection", "(Allaway and McKeown, 2020, Stab et al., 2018, Xu et al., 2018)", "aims", "to", "classify", "a", "statement", "as", "pro", "or", "con", "with", "respect", "to", "a", "topic,", "while", "dis/agreement", "classification", "(Chen et al., 2018, Hou and Jochim, 2017, Rosenthal and McKeown, 2015)", "aims", "to", "decide", "whether", "two", "statements", "are", "from", "the", "same", "or", "opposite", "stance(s)", "for", "a", "given", "topic.", "Topics", "are", "usually", "discrete,", "and", "models", "often", "learn", "thematic", "correlations", "between", "a", "topic", "and", "a", "stance", "(Xu et al., 2019).", "Our", "work", "is", "slightly", "different", "as", "we", "classify", "the", "direct", "support", "or", "attack", "relation", "between", "two", "natural", "statements."], "cited_papers": [{"title": "Modeling frames in argumentation", "year": "2019", "authors": ["Yamen Ajjour", "Milad Alshomary", "Henning Wachsmuth", "Benno Stein"]}], "target_citation_location": 47, "citation_locations": [29, 31, 37, 47, 61, 76, 94, 128], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "3ea81d3a-19f2-4906-9aa1-107466d3cc8c", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["The", "MOST", "FREQUENT", "baseline", "chooses", "the", "most", "frequently", "observed", "entity", "for", "a", "given", "mention", "as", "a", "prediction,", "based", "on", "a", "prior", "probability", "p", "prior", "computed", "from", "link", "counts", "on", "Wikipedia.", "All", "baselines", "except", "MOST", "FREQUENT", "combine", "the", "classifier", "output", "and", "the", "prior", "probability", "to", "make", "a", "prediction:", "arg", "max", "c", "p", "prior", "(c)", "+", "p", "classifier", "(c).", "10", "data.", "Our", "approach", "outperforms", "all", "baselines,", "indicating", "that", "our", "entity", "representations", "include", "useful", "information", "about", "entities", "out-of-the-box.", "Such", "a", "performance", "gap", "is", "expected", "since", "our", "entity", "representations", "can", "directly", "encode", "some", "factual", "knowledge", "from", "Wikipedia.", "However,", "these", "results", "also", "imply", "that", "pre-trained", "LMs", "do", "not", "have", "enough", "factual", "information", "out-of-the-box,", "they", "may", "rely", "on", "in-domain", "fine-tuning", "to", "achieve", "high", "performance", "in", "the", "target", "domain,", "and", "often", "fail", "to", "generalize", "to", "new", "settings.", "Note", "that", "while", "these", "accuracies", "are", "significantly", "below", "the", "supervised", "state-of-the-art", "(95%),", "they", "are", "competitive", "with", "the", "\"zero-shot\"", "entity", "results", "from", "recent", "past", "work", "(Gupta et al., 2017, Onoe and Durrett, 2020)."], "cited_papers": [{"title": "Entity Linking via Joint Encoding of Types, Descriptions, and Context", "year": "2017", "authors": ["Nitish Gupta", "Sameer Singh", "Dan Roth"]}, {"title": "Fine-Grained Entity Typing for Domain Independent Entity Linking", "year": "2020", "authors": ["Yasumasa Onoe", "Greg Durrett"]}], "target_citation_location": 154, "citation_locations": [154], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]]}
{"id": "3f17c099-54eb-4a33-94d2-128373dac908", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["For", "Kinyarwanda", "pre-training", "data,", "we", "use", "the", "Common", "Voice", "(CV)", "Kinyarwanda", "6.1", "subset", "(Ardila et al., 2019).", "Again,", "we", "utilize", "both", "the", "audio", "files", "and", "transcriptions.", "Due", "to", "the", "large", "size", "of", "the", "CV", "6.1", "Kinyarwanda", "subset,", "we", "processed", "only", "about", "80%", "of", "the", "audio", "files."], "cited_papers": [{"title": "Common voice: A massivelymultilingual speech corpus", "year": "2019", "authors": ["Rosana Ardila", "Megan Branson", "Kelly Davis", "Michael Henretty", "Michael Kohler", "Josh Meyer", "Reuben Morais", "Lindsay Saunders", "Francis Tyers", "Gregor Weber"]}], "target_citation_location": 13, "citation_locations": [13], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "3f4c2197-2e17-4119-af99-0f6219d9b681", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["(2)", "The", "BAE", "attack", "(Garg and Ramakrishnan, 2020)", "generates", "coherent", "adversarial", "examples", "by", "masking", "and", "replacing", "words", "using", "BERT.", "For", "both", "methods", "we", "use", "the", "implementation", "provided", "by", "TextAttack", "(Morris et al., 2020)."], "cited_papers": [{"title": "BAE: BERT-based adversarial examples for text classification", "year": "2020", "authors": ["Siddhant Garg", "Goutham Ramakrishnan"]}], "target_citation_location": 4, "citation_locations": [4, 26], "citation_type": "single", "annotations": [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "3f58355b-e8f5-44e9-b287-d200a83c0a2b", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["For", "the", "Transformer", "(Vaswani et al., 2017),", "we", "conducted", "a", "model", "architecture", "and", "hyperparameter", "search", "(layers,", "learning", "rate,", "MLP", "dimensions,", "dropout", "rate,", "Encoder", "vs.", "Encoder-Decoder)", "on", "the", "dev", "set.", "The", "selected", "model", "was", "composed", "of", "four", "encoder-blocks", "and", "a", "final", "dense", "layer", "that", "projects", "the", "output", "of", "the", "last", "encoder-block", "onto", "the", "PoS", "tags", "via", "a", "softmax", "function.", "We", "used", "the", "Adam", "optimiser", "and", "early", "stopping.", "The", "implementation", "is", "based", "on", "the", "WMT", "example", "2", "of", "Google's", "novel", "ML", "frameworks", "Flax/Jax.", "Table", "2", "lists", "the", "selected", "hyperparameters.", "The", "Transformer", "received", "EEG", "channels", "x", "time", "points", "as", "inputs", "and", "provided", "a", "classification", "response", "for", "the", "entire", "time", "window."], "cited_papers": [{"title": "Attention is all you need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 3, "citation_locations": [3], "citation_type": "single", "annotations": [[0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "3f63a9d7-2397-4cbf-b303-ae1b4eca420a", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["The", "relationship", "between", "productivity", "and", "regularity", "is", "discussed", "by", "Corbin (1987).", "In", "a", "computational", "context,", "the", "regularity", "of", "a", "word", "formation", "rule", "is", "what", "makes", "it", "possible", "to", "describe", "it", "in", "the", "form", "of", "a", "procedure", "which", "can", "be", "used", "to", "recognize", "new", "words."], "cited_papers": [{"title": null, "year": "1987", "authors": ["Danielle Corbin"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4094666a-afe7-4032-a908-5d7b626764de", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["To", "model", "the", "relational", "information", "in", "the", "commonsen", "KG,", "we", "employ", "the", "relational", "graph", "convolutional", "network", "(R-GCN)", "(Schlichtkrull et al., 2018)", "which", "generalizes", "GCN", "with", "relation", "specific", "weight", "matrices.", "We", "follow", "Vashishth et al. (2020)", "and", "Ji et al. (2020)", "to", "use", "a", "non-parametric", "compositional", "operation", "\u03d5(\u2022)", "to", "combine", "the", "concept", "node", "embedding", "and", "the", "relation", "embedding.", "Specifically,", "given", "the", "input", "subgraph", "G", "x", "=", "{V", "x,", "E", "x}", "and", "an", "R-GCN", "with", "L", "layers,", "we", "update", "the", "embedding", "of", "each", "node", "v", "\u2208", "V", "x", "at", "the", "(l+1)-th", "layer", "by", "aggregating", "information", "from", "the", "embeddings", "of", "its", "neighbours", "in", "N", "(v)", "at", "the", "l-th", "layer:"], "cited_papers": [{"title": "Modeling relational data with graph convolutional networks", "year": "2018", "authors": ["Michael Schlichtkrull", "N Thomas", "Peter Kipf", "Rianne Bloem", "unk Van Den", "Ivan Berg", "Max Titov", "unk Welling"]}], "target_citation_location": 17, "citation_locations": [17, 28, 30], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4120f023-8660-4b22-bd4d-ab0c1317e0b7", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["5.", "For", "Hindi,", "we", "use", "the", "gold-standard", "corpus", "of", "Goud et al. (2019b),", "which", "consists", "of", "810", "event", "annotated", "news", "articles", "based", "on", "modified", "TimeML", "rules.", "The", "dataset", "has", "242,201", "tokens", "and", "20,190", "event", "mentions."], "cited_papers": [{"title": "A semantico-syntactic approach to event-mention detection and extraction in hindi", "year": "2019", "authors": ["Jaipal Goud", "Pranav Goel", "Alok Debnath", "Suhan Prabhu", "Manish Shrivastava"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "413b4549-3b7a-464c-baac-1958bcb8bce9", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["BART", "movistar", "rider", "alejandro", "valverde", "won", "fleche", "wallonne", "on", "wednesday.", "team", "sky's", "chris", "froome", "fell", "in", "the", "final", "12km", "but", "finished", "the", "race.", "philippe", "gilbert", "pulled", "out", "of", "the", "race", "after", "a", "bad", "crash", "50km", "from", "the", "end.", "click", "here", "for", "more", "cycling", "news.", "2021,", "Fabbri et al., 2021)", "has", "shown", "that", "few-shot", "learning", "can", "be", "an", "effective", "fine-tuning", "method", "of", "pre-trained", "models", "for", "text", "generation", "tasks.", "Therefore,", "we", "investigate", "our", "model's", "performance", "in", "a", "few-shot", "setting.", "Specifically,", "we", "randomly", "sample", "100/1000", "examples", "from", "the", "training", "set", "of", "CNNDM/XSum,", "and", "fine-tune", "the", "models", "that", "are", "pre-trained", "using", "MLE", "loss", "on", "those", "examples.", "More", "training", "details", "can", "be", "found", "in", "Appendix", "C.", "The", "results", "are", "shown", "in", "Tab.", "11.", "All", "experiments", "are", "repeated", "three", "times,", "and", "the", "reported", "results", "are", "the", "average", "performance.", "The", "results", "indicate", "that", "our", "model", "can", "achieve", "improvement", "over", "the", "baseline", "model", "under", "the", "few-shot", "learning", "setting", "with", "a", "small", "computational", "overhead."], "cited_papers": [{"title": "Improving zero and few-shot abstractive summarization with intermediate fine-tuning and data augmentation", "year": "2021", "authors": ["Alexander Fabbri", "Simeng Han", "Haoyuan Li", "Haoran Li", "Marjan Ghazvininejad", "Shafiq Joty", "Dragomir Radev", "Yashar Mehdad"]}], "target_citation_location": 45, "citation_locations": [45], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "41648b62-3363-4ef4-ba4d-d705be2967ed", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["where", "S", "i", "and", "S", "j", "are", "two", "different", "candidate", "summaries", "and", "ROUGE(S", "i,", "S", "*)", "&gt,", "ROUGE(S", "j,", "S", "*", "),", "\u2200i,", "j,", "i", "&lt,", "j.", "\u03bb", "ij", "is", "the", "margin", "multiplied", "by", "the", "difference", "in", "rank", "between", "the", "candidates,", "i.e.,\u03bb", "ij", "=", "(j", "\u2212", "i)", "*", "\u03bb.", "f", "(S", "i)", "is", "the", "length-normalized", "estimated", "log-probability", "3", "f", "(S)", "=", "l", "t=1", "log", "p", "g", "\u03b8", "(s", "t", "|D,", "S", "&lt,t,", "\u03b8)", "|S|", "\u03b1", "(9)where", "\u03b1", "is", "the", "length", "penalty", "hyperparameter.", "This", "loss", "gives", "the", "abstractive", "model", "a", "dual", "purpose,", "first", "as", "a", "reference-free", "evaluation", "model,", "which", "can", "be", "used", "in", "a", "two-stage", "summarization", "pipeline,", "where", "it", "is", "used", "to", "score", "the", "candidates", "generated", "by", "a", "pre-trained", "generation", "model", "and", "select", "the", "final", "output", "from", "them.", "However,", "since", "the", "autoregressive", "generation", "depends", "on", "both", "the", "token-level", "prediction", "accuracy", "and", "sequencelevel", "coordination,", "the", "model", "fine-tuned", "with", "the", "contrastive", "loss", "alone", "can", "no", "longer", "be", "used", "as", "a", "generation", "model.", "Multi-task", "Fine-tuning", "Following", "Edunov et al. (2018),", "we", "combine", "the", "contrastive", "(Eq.", "8)", "and", "cross-entropy", "(Eq.", "3)", "losses", "to", "preserve", "the", "generation", "ability", "of", "the", "pre-trained", "abstractive", "model:"], "cited_papers": [{"title": "Classical structured prediction losses for sequence to sequence learning", "year": "2018", "authors": ["Sergey Edunov", "Myle Ott", "Michael Auli", "David Grangier", "Marc'aurelio Ranzato"]}], "target_citation_location": 162, "citation_locations": [162], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "426e4634-6cc5-4bcb-94bb-c4543837c3a7", "citing_paper": {"title": "Situation-Specific Multimodal Feature Adaptation", "year": 2021, "authors": ["\u00d6zge Alac"]}, "text": ["Furthermore,", "when", "the", "environment", "is", "noisy,", "or", "the", "communication", "partner", "suffers", "from", "a", "motor", "or", "cognitive", "impairment,", "multimodal", "integration", "plays", "a", "more", "critical", "role.", "Noise", "in", "communication", "can", "originate", "from", "various", "sources.", "It", "can", "be", "linguistic", "noise", "(e.g.", "spelling", "mistakes,", "complex", "attachments),", "visual", "ambiguities", "(e.g.", "clutter", "in", "the", "environment,", "occlusions)", "or", "an", "acoustic", "noise.", "Instead", "of", "waiting", "for", "clarification,", "combining", "the", "uncertain", "information", "from", "the", "linguistic", "channel", "with", "information", "from", "the", "other", "ones", "increases", "the", "fluency", "and", "the", "effectiveness", "of", "the", "communication", "(Garay-Vitoria and Abascal, 2004).", "One", "of", "the", "most", "well-known", "examples", "to", "this", "phenomenon", "is", "the", "cocktail", "party", "effect,", "that", "highlights", "the", "human", "ability", "to", "focus", "on", "one", "particular", "source", "while", "inhibiting", "the", "noisy", "ones.", "When", "the", "informativeness", "of", "one", "modality", "is", "reduced", "due", "to", "environmental", "conditions,", "the", "human", "language", "processing", "system", "can", "successfully", "adjust", "itself", "by", "relying", "less", "on", "the", "unclear", "modality", "and", "using", "other", "cues", "in", "the", "environment.", "In", "this", "specific", "scenario,", "other", "informative", "cues", "provide", "more", "reliable", "information", "compared", "to", "the", "noisy", "linguistic", "input.", "These", "cues", "can", "come", "from", "the", "surrounding", "environment", "and", "from", "the", "communicational", "partners,", "and", "include", "eye-gaze", "direction", "or", "representational", "gestures", "combined", "with", "their", "referential", "link", "to", "the", "entities", "in", "the", "environment.", "Eye-tracking", "is", "attracting", "considerable", "interest", "in", "many", "assistive", "technologies", "such", "as", "educational", "VR", "systems", "that", "provide", "embodied", "learning", "environments", "or", "driver", "monitoring", "systems.", "The", "use", "of", "eye-tracking", "in", "daily", "technological", "products", "such", "as", "mobile", "phones,", "laptops", "and", "virtual", "reality", "headsets", "is", "increasing", "day", "by", "day", "(Brousseau et al., 2020, Rogers, 2019, Khamis et al., 2018).", "Therefore,", "incorporating", "eye-movements", "in", "our", "language", "comprehension", "models", "is", "an", "inevitable", "outcome", "of", "these", "latest", "developments,", "and", "this", "makes", "the", "systematic", "research", "on", "the", "combination", "of", "this", "modality", "with", "others", "very", "crucial."], "cited_papers": [{"title": "Seven reasons why eyetracking will fundamentally change vr", "year": "2019", "authors": ["Sol unk"]}, {"title": "The past, present, and future of gaze-enabled handheld mobile devices: survey and lessons learned", "year": "2018", "authors": ["Mohamed Khamis", "Florian Alt", "Andreas Bulling"]}, {"title": "Hybrid eye-tracking on a smartphone with cnn feature extraction and an infrared 3d model", "year": "2020", "authors": ["Braiden Brousseau", "Jonathan Rose"]}], "target_citation_location": 241, "citation_locations": [82, 241], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "42c82e0b-5e6c-48d5-9986-3807c0d65425", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["Our", "main", "contribution", "is", "to", "change", "the", "target", "distribution", "of", "abstractive", "models", "from", "a", "one-point", "deterministic", "distribution", "assumed", "by", "MLE", "training", "to", "a", "non-deterministic", "distribution", "in", "which", "candidate", "summaries", "are", "also", "assigned", "probability", "mass", "according", "to", "their", "quality.", "The", "new", "SOTA", "performance", "on", "CNN/DailyMail (Hermann et al., 2015)", "and", "XSum", "(Narayan et al., 2018)", "datasets", "demonstrated", "the", "effectiveness", "of", "our", "method.", "Our", "in-depth", "analysis", "also", "found", "that", "the", "abstractive", "models", "trained", "using", "our", "method", "can", "estimate", "the", "candidate", "summary", "quality", "more", "accurately,", "in", "concert", "with", "the", "the", "objective", "of", "our", "training", "paradigm."], "cited_papers": [{"title": "Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization", "year": "2018", "authors": ["Shashi Narayan", "Shay Cohen", "Mirella Lapata"]}], "target_citation_location": 46, "citation_locations": [43, 46], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "43138f94-cd75-4327-a5f9-2ecc00e48d79", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["In", "argumentation", "theory,", "Walton's", "argumentation", "schemes", "specify", "common", "reasoning", "patterns", "used", "in", "arguments", "(Walton et al., 2008).", "We", "focus", "on", "two", "schemes", "related", "to", "normative", "arguments,", "whose", "claims", "suggest", "that", "an", "action", "or", "situation", "be", "brought", "about.", "Normative", "claims", "are", "one", "of", "the", "most", "common", "proposition", "types", "in", "argumentation", "(Jo et al., 2020)", "and", "have", "received", "much", "attention", "in", "the", "literature", "(Park and Cardie, 2018)."], "cited_papers": [{"title": "Argumentation schemes", "year": "2008", "authors": ["Douglas Walton", "Chris Reed", "Fabrizio Macagno"]}], "target_citation_location": 13, "citation_locations": [13, 46, 55], "citation_type": "single", "annotations": [[0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "434bf4fe-75df-4b04-905c-0ce4d5a8b71f", "citing_paper": {"title": "ROI Analysis model for Language Service Providers", "year": 2013, "authors": ["Ekaterina Stambolieva"]}, "text": ["A", "difficult", "challenge", "to", "face", "is", "designing", "a", "winning", "vendor", "pricing", "model.", "Even", "in", "the", "cases", "of", "google", "9", "-like", "machine", "translation", "output,", "it", "is", "arduous", "to", "benefit", "from", "vendor", "involvement", "with", "MT.", "The", "reason", "why", "originates", "from", "the", "fact", "that", "when", "incorporating", "MT", "output", "in", "the", "translation", "process", "workflow,", "per", "segment", "rates", "are", "directly", "affected", "and", "reduced", "(the", "reductions", "can", "reach", "50%", "of", "the", "normal", "price).", "From", "vendors'", "point", "of", "view,", "MT", "threatens", "to", "reduce", "per", "segment", "rates,", "which", "in", "return", "leads", "to", "hourly", "rate", "destabilization.", "Regardless", "of", "MT", "output", "quality,", "vendors", "tend", "to", "decline", "jobs", "due", "to", "the", "fact", "MT", "output", "is", "incorporated", "in", "pre-translated", "documents.", "This", "decrease", "of", "vendor", "involvement", "leads", "us", "to", "a", "conclusion", "that", "purely", "showing", "good", "MT", "results", "is", "not", "sufficient", "and", "more", "work", "is", "required", "to", "be", "done", "in", "order", "to", "start", "gaining", "investment", "back", "and", "increasing", "the", "ROI", "ratio.", "What", "we", "discovered", "on", "our", "own,", "stated", "additionally", "by", "Sojn\u00f3czky (2013),", "is", "that", "human", "translators'", "engagement", "is", "MT", "development", "is", "vital.", "People", "are", "the", "key", "factor", "of", "success", "of", "every", "business", "and", "winning", "strategies", "must", "actively", "involve", "employees", "on", "different", "organizational", "levels", "in", "technological", "(including", "MT)", "solution", "processes.", "In", "euroscript", "10,", "we", "regularly", "ask", "for", "in-house", "translators'", "MT", "evaluation", "feedback", "in", "terms", "of", "different", "categories", "of", "MT", "output", "errors.", "We", "devote", "time", "to", "correcting", "these", "mistakes,", "informing", "the", "in-house", "translators", "of", "the", "improvements", "made", "and", "engaging", "ourselves", "into", "increasing", "translators'", "satisfaction", "with", "working", "with", "MT.", "We", "consider", "different", "options", "of", "post-editing", "training", "focused", "on", "translators", "following", "the", "strategy", "of", "involving", "translators", "more", "with", "MT.", "This", "idea", "is", "also", "supported", "by:", "Hern\u00e1ndez-Lasa", "(2011)", "and", "Wiggins (2013).", "Our", "preliminary", "results", "show", "that", "roughly", "50%", "of", "our", "in-house", "translators,", "who", "work", "with", "MT,", "consider", "its", "understandability", "as", "good", "opposed", "to", "acceptable", "or", "bad", "(see", "Avramidis et al., 2012, Vilar et al., 2006", "for", "MT", "features", "that", "influence", "MT", "understandability)."], "cited_papers": [{"title": "Hunnect's Use Case. TAUS Machine Translation Showcase at Localization World", "year": "2013", "authors": ["Sa\u00e1ndor Sojn\u00f3czky"]}], "target_citation_location": 156, "citation_locations": [156, 269, 296], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "437b8748-98cc-4246-97fe-24e0a3233d49", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["Choice", "of", "BERT", "Output", "Layer", "and", "Wordpiece", "Embeddings", "We", "were", "interested", "in", "how", "the", "choice", "of", "BERT", "output", "layers", "and", "word", "piece", "embeddings", "impacts", "performance", "of", "our", "model.", "Hence,", "we", "did", "the", "following", "experiments", "with", "our", "base", "model,", "shown", "in", "Table", "4.", "First,", "we", "use", "BERT's", "middle", "(7", "th)", "output", "layer,", "using", "the", "embedding", "of", "the", "initial", "word", "piece", "for", "each", "word", "as", "input", "to", "the", "classifiers.", "Second,", "we", "used", "the", "middle", "layer,", "but", "with", "the", "mean", "vector", "of", "all", "word", "pieces", "(this", "is", "the", "method", "we", "used", "in", "all", "previous", "experiments).", "Third,", "we", "used", "the", "mean", "value", "of", "the", "final", "(12", "th)", "BERT", "output", "layer,", "which", "helped", "van", "Noord", "et", "al.", "(2020)", "build", "their", "best", "model,", "yet", "according", "to", "Chronis and Erk (2020)", "random", "errors,", "we", "did", "five", "trials", "on", "each", "of", "these", "embedding", "approaches", "and", "averaged", "the", "results.", "Although", "the", "differences", "are", "rather", "small,", "the", "mean", "vector", "of", "the", "middle", "layer", "seems", "to", "provide", "the", "best", "scores", "across", "the", "board.", "Therefore,", "we", "stuck", "to", "this", "setting", "for", "subsequent", "experiments."], "cited_papers": [{"title": "When is a bishop not like a rook? when it's like a rabbi! multiprototype BERT embeddings for estimating semantic relationships", "year": "2020", "authors": ["Gabriella Chronis", "Katrin Erk"]}], "target_citation_location": 120, "citation_locations": [120], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4393edb8-65e2-4821-a762-64d6a9cff0e8", "citing_paper": {"title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection", "year": 2021, "authors": ["Henry Weld", "Guanghao Huang", "Jean Lee", "Tongshu Zhang", "Kunze Wang", "Xinghong Guo", "Siqu Long", "Josiah Soyeon", "Caren Han"]}, "text": ["Slot-gated", "(Goo et al., 2018)", "is", "an", "attentionbased", "BiLSTM", "model", "which", "builds", "on", "sepa-", "rate", "attended", "context", "for", "slot", "filling", "and", "intent", "classification", "while", "explicitly", "feeding", "the", "intent", "context", "into", "the", "process", "of", "slot", "filling", "via", "a", "gating", "mechanism.Metrics", "Model", "UCA", "U-F1(E)", "U-F1(I)", "U-F1(A)", "U-F1(O)", "T-F1", "T-F1(T)", "T-F1(S)", "T-F1(C)", "T-F1(D)", "T-F1(P)", "T-F1(O)", "JSA", "RNN-NLU", "(Liu\u2022", "Inter-BiLSTM", "(Wang et al., 2018)", "combines", "two", "inter-connected", "BiLSTMs", "performing", "slot", "filling", "and", "intent", "classification", "respectively.", "The", "information", "flow", "between", "the", "two", "tasks", "occurs", "by", "passing", "the", "hidden", "states", "at", "each", "time", "step", "from", "each", "side", "to", "the", "other", "to", "support", "the", "decoding", "process."], "cited_papers": [{"title": "Slot-gated modeling for joint slot filling and intent prediction", "year": "2018", "authors": ["Guang Chih-Wen Goo", "Yun-Kai Gao", "Chih-Li Hsu", "Tsung-Chieh Huo", "Keng-Wei Chen", "Yun-Nung Hsu", "unk Chen"]}], "target_citation_location": 1, "citation_locations": [1, 53], "citation_type": "single", "annotations": [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "43dfab3c-7cfd-4284-b1f5-3226b128db99", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Say", "that", "the", "agent", "plays", "in", "the", "blue", "team,", "i.e.", "we", "want", "to", "generate", "clues", "associated", "to", "the", "blue", "words,", "based", "on", "the", "distance", "functions", "above.", "The", "functions", "of", "Kim et al. (2019)", "(see", "(1))", "determined", "the", "score", "of", "a", "possible", "reference", "based", "on", "relatedness", "of", "the", "clue", "word", "to", "the", "least", "related", "blue", "word", "targeted.", "The", "shortcoming", "of", "this,", "however,", "is", "that", "in", "addition", "to", "blue", "(good)", "words", "that", "are", "similar", "to", "the", "clue", "word,", "there", "may", "be", "bad", "words", "of", "a", "different", "color", "that", "are", "only", "very", "slightly", "less", "similar", "to", "the", "clue.", "We", "can", "assume", "that", "in", "this", "case,", "agents", "are", "less", "likely", "to", "choose", "the", "targeted", "words,", "or", "in", "general,", "the", "smaller", "the", "difference", "between", "the", "distances", "of", "two", "words", "from", "the", "clue", "according", "to", "our", "distance", "function,", "the", "more", "likely", "the", "human", "player", "will", "perceive", "the", "order", "of", "the", "two", "words", "reversed."], "cited_papers": [{"title": "Cooperation and codenames: Understanding natural language processing via codenames", "year": "2019", "authors": ["Andrew Kim", "Maxim Ruzmaykin", "Aaron Truong", "Adam Summerville"]}], "target_citation_location": 29, "citation_locations": [29], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4474f252-18ed-4cb0-8e6d-5a13bf815809", "citing_paper": {"title": "On the weak link between importance and prunability of attention heads", "year": 2020, "authors": ["Aakriti Budhraja", "Madhura Pande", "Preksha Nema", "Pratyush Kumar", "Mitesh Khapra"]}, "text": ["Varying", "Pruning", "Percentage.", "We", "randomly", "prune", "attention", "heads", "across", "all", "components", "and", "layers", "varying", "the", "percentage", "of", "pruning", "from", "25%", "to", "87%", "(Table", "1).", "We", "observed", "that", "in", "the", "case", "of", "extreme", "pruning,", "i.e.,", "keeping", "just", "one", "head", "in", "each", "layer", "of", "each", "of", "the", "three", "components", "(which", "corresponds", "to", "a", "pruning", "percentage", "of", "87%),", "the", "drop", "in", "BLEU", "was", "1.62", "(EN-RU)", "and", "1.03", "(EN-DE)", "as", "can", "be", "seen", "from", "Table", "1.", "Across", "both", "EN-RU", "and", "EN-DE", "tasks,", "60%", "of", "the", "attention", "heads", "can", "be", "pruned", "with", "a", "maximum", "drop", "in", "BLEU", "score", "by", "only", "0.15.", "As", "can", "be", "observed", "from", "Figure", "1,", "the", "drop", "is", "sharper", "as", "we", "increase", "the", "pruning", "percentage", "beyond", "60%.", "three", "layers,", "3", "in", "the", "fourth", "layer", "and", "2", "each", "in", "the", "last", "two", "layers.", "For", "each", "pruning", "percentage,", "the", "first", "row", "corresponds", "to", "the", "configuration", "in", "which", "heads", "considered", "important", "(Voita et al., 2019b)", "were", "retained", "and", "the", "second", "row", "corresponds", "to", "the", "adversarial", "configuration", "in", "which", "heads", "considered", "important", "were", "pruned.", "We", "identify", "no", "preference", "in", "pruning", "as", "for", "each", "pruning", "percentage", "the", "performance", "of", "both", "configurations", "is", "very", "similar."], "cited_papers": [{"title": "Analyzing multihead self-attention: Specialized heads do the heavy lifting, the rest can be pruned", "year": "2019", "authors": ["Elena Voita", "David Talbot", "Fedor Moiseev", "Rico Sennrich", "Ivan Titov"]}], "target_citation_location": 146, "citation_locations": [146], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "44bf0888-2835-4627-8523-1d0371f11d87", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["Word2VecVN", "(Vu, 2016)", "x", "Trained", "on", "7GB", "texts", "of", "Vietnamese", "news", "FastText", "(Vietnamese", "version)", "(Joulin et al., 2016)", "x"], "cited_papers": [{"title": "Pre-trained word2vec models for vietnamese", "year": "2016", "authors": ["Xuan-Son Vu"]}], "target_citation_location": 1, "citation_locations": [1, 13], "citation_type": "single", "annotations": [[1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "44ec7730-9be1-42f7-89e6-27b1fa340499", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["As", "seen", "in", "Figure", "1,", "we", "focus", "on", "creating", "agents", "in", "LIGHT (Urbanek et al., 2019),", "a", "large-scale", "crowdsourced", "fantasy", "text-adventure", "game,", "consisting", "of", "rich", "textual", "worlds-locations,", "objects,", "and", "characters", "with", "personas,", "and", "quests-motivations", "for", "each", "character.", "To", "complete", "these", "quests,", "an", "agent", "must:", "(1)", "maintain", "character", "via", "its", "persona,", "and", "(2)", "reason", "in", "a", "partially", "observable", "world", "about", "potential", "actions", "and", "utterances", "based", "on", "incomplete", "descriptions", "of", "the", "locations,", "objects,", "and", "other", "characters.", "This", "requires", "several", "human", "like", "competencies", "such", "as", "commonsense", "reasoning,", "dynamic", "natural", "language", "understanding,", "and", "operating", "in", "combinatorially", "sized", "language-based", "stateaction", "spaces.", "Although", "recent", "work", "has", "provided", "evidence", "showing", "that", "interactive", "language", "learning", "via", "reinforcement", "learning", "(RL)", "in", "text", "games", "can", "be", "significantly", "more", "sample", "efficient", "than", "static", "supervised", "learning", "(Ammanabrolu et al., 2021)", "when", "creating", "goal-driven", "natural", "language", "agents,", "their", "ability", "to", "robustly", "generalize", "to", "novel", "scenarios", "is", "limited."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 11, "citation_locations": [11, 120], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "45078abb-8df9-4abb-b5d7-4224dee2258c", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["We", "propose", "a", "three-step", "approach", "to", "Arabic", "sequence", "labeling.", "The", "first", "step", "is", "to", "automatically", "diacritize", "the", "text", "using", "the", "state-of-the-art", "automatic", "diacritization", "system", "Shakkala", "(Barqawi, 2017).", "The", "second", "step", "is", "the", "individual", "training", "of", "character", "and", "diacritic", "embeddings", "using", "the", "architecture", "proposed", "by", "Gridach (2016).", "The", "third", "step", "is", "to", "train", "all", "embedding", "layers", "together", "using", "a", "combination", "model", "(see", "section", "4.3).", "There", "are", "two", "main", "advantages", "in", "adopting", "this", "architecture", "for", "EMIL.", "First,", "it", "is", "based", "on", "a", "standard", "approach", "in", "NER", "and", "sequence", "labeling", "in", "general,", "which", "remains", "very", "close", "to", "the", "state-ofthe-art.", "Second,", "it", "is", "a", "relatively", "light-weight", "architecture", "requiring", "less", "computational", "resources", "than", "other", "alternatives", "(see", "section", "5.3).", "We", "will", "discuss", "and", "justify", "our", "design", "choices", "and", "the", "computational", "aspects", "of", "the", "architecture", "further", "in", "Section", "(5.3)", "and", "Section", "(6)."], "cited_papers": [{"title": "Character-aware neural networks for arabic named entity recognition for social media", "year": "2016", "authors": ["Mourad Gridach"]}], "target_citation_location": 43, "citation_locations": [25, 43], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "457691b7-656e-4f4e-ab06-8fd0d3ab7b40", "citing_paper": {"title": "On the weak link between importance and prunability of attention heads", "year": 2020, "authors": ["Aakriti Budhraja", "Madhura Pande", "Preksha Nema", "Pratyush Kumar", "Mitesh Khapra"]}, "text": ["In", "all", "experiments", "involving", "BERT,", "we", "use", "the", "BERT", "Base-uncased", "model", "(Devlin et al., 2018).", "It", "has", "12", "layers", "and", "each", "layer", "contains", "12", "attention", "heads,", "summing", "to", "144", "attention", "heads.", "We", "fine-tune", "and", "evaluate", "the", "pre-trained", "model", "2", "on", "sentence", "entailment", "task", "MNLI-M,", "the", "question", "similarity", "task", "QQP,", "the", "question-answering", "task", "QNLI,", "and", "the", "movie", "review", "task", "SST-2", "from", "the", "GLUE", "Benchmark", "(Wang et al., 2018).", "We", "report", "accuracies", "on", "the", "official", "development", "sets", "of", "the", "considered", "GLUE", "tasks.", "For", "each", "of", "the", "four", "GLUE", "tasks,", "namely", "MNLI-M,", "QQP,", "QNLI", "and", "SST-2,", "we", "tried", "combinations", "of", "batch", "size", "and", "learning", "rate", "from", "{8,", "16,", "32,", "64,", "128}", "and", "{2,", "3,", "4,", "5}", "\u00d7", "10", "\u22125", "respectively", "and", "selected", "the", "best", "performing", "configuration.", "The", "exact", "hyperparameters", "used", "for", "each", "of", "the", "tasks", "have", "been", "made", "available", "with", "the", "code", "released", "3.", "Each", "BERT", "experiment", "was", "run", "on", "a", "single", "Cloud", "TPU", "(v2-8)."], "cited_papers": [{"title": "Glue: A multi-task benchmark and analysis platform for natural language understanding", "year": "2018", "authors": ["Alex Wang", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R Bowman"]}], "target_citation_location": 60, "citation_locations": [11, 60], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4580587a-8b18-4ee3-ab75-52d8ad70821e", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Diversity", "in", "NLG", "has", "been", "extensively", "studied", "for", "various", "tasks", "in", "the", "past", "few", "years,", "such", "as", "machine", "translation", "(Shen et al., 2019)", "and", "paraphrase", "\u00a7", "Codes", "of", "our", "model", "and", "baselines", "are", "available", "at", "https://github.com/DM2-ND/MoKGE."], "cited_papers": [{"title": "Mixture models for diverse machine translation: Tricks of the trade", "year": "2019", "authors": ["Tianxiao Shen", "Myle Ott", "Michael Auli", "Marc'aurelio Ranzato"]}], "target_citation_location": 19, "citation_locations": [19], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "45b7784f-553f-4d13-a26b-a316950d5180", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["After", "obtaining", "natural", "language", "actions,", "we", "enrich", "the", "dialogues", "as", "{(c", "t,", "l(x", "t", "),", "x", "t", ")|1", "\u2264", "t", "\u2264", "n", "d", "},", "where", "l(x", "t)", "is", "the", "natural", "language", "action", "of", "utterance", "x", "t.", "We", "could", "then", "run", "conditioned", "response", "generation", "to", "train", "content", "planning", "and", "language", "generation", "models", "as", "Eqn.", "1-3.", "The", "learning", "efficiency", "can", "be", "improved", "by", "the", "more", "compact", "and", "noise-free", "action", "space.", "Moreover,", "the", "natural", "language", "actions", "present", "abundant", "information", "of", "correlations", "among", "actions,", "which", "allows", "for", "better", "generalization", "over", "actions", "(Chandak et al., 2019, Hu et al., 2019)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Learning action representations for reinforcement learning", "year": "2019", "authors": ["Yash Chandak", "Georgios Theocharous", "James Kostas", "Scott Jordan", "Philip Thomas"]}], "target_citation_location": 87, "citation_locations": [87], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "45bfd403-bf49-4957-94da-5e0259a93d0d", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["When", "S", "attacks", "C,", "they", "may", "express", "opposite", "sentiments", "toward", "the", "same", "target,", "whereas", "they", "may", "express", "the", "same", "sentiment", "if", "S", "supports", "C", "(Gemechu and Reed, 2019)", "R4:", "SentiConflict(S,", "C)", "\u2192", "Attack(S,", "C),", "R5:", "SentiCoherent(S,", "C)", "\u2192", "Support(S,", "C)", "s.t.", "SentiConflict(S,", "C)", "=", "max", "i,j", "P", "(t", "S", "i", "=", "t", "C", "j)", "P", "(s", "S", "i", "=", "pos)P", "(s", "C", "j", "=", "neg)", "+P", "(s", "S", "i", "=", "neg)P", "(s", "C", "j", "=", "pos),", "SentiCoherent(S,", "C)", "=", "max", "i,j", "P", "(t", "S", "i", "=", "t", "C", "j)", "P", "(s", "S", "i", "=", "pos)P", "(s", "C", "j", "=", "pos)", "+P", "(s", "S", "i", "=", "neg)P", "(s", "C", "j", "=", "neg)", ".In", "this", "work,", "targets", "are", "all", "noun", "phrases", "and", "verb", "phrases", "in", "C", "and", "S.", "P", "(t", "S", "i", "=", "t", "C", "j)", "is", "computed", "by", "a", "textual", "entailment", "module", "(\u00a74.1),", "and", "P", "(s", "S", "i)", "and", "P", "(s", "C", "j)", "by", "a", "target-based", "sentiment", "classifier", "(\u00a74.2)."], "cited_papers": [{"title": "Decompositional argument mining: A general purpose approach for argument graph construction", "year": "2019", "authors": ["Debela Gemechu", "Chris Reed"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "45cdd009-6f69-480e-80b9-f6269ca55dd1", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["We", "require", "aligned", "parallel", "text", "to", "fuel", "our", "methods", "and", "we", "relied", "on", "the", "Europarl", "corpus", "(Koehn, 2003)", "which", "is", "comprised", "of", "EU", "parliamentary", "oration", "that", "has", "been", "manually", "translated", "into", "other", "EU", "languages.", "There", "is", "approximately", "160", "MB", "of", "text", "(about", "24", "million", "words)", "per", "language."], "cited_papers": [{"title": "Europarl: A Multilingual Corpus for Evaluation of Machine Translation", "year": "2003", "authors": ["P Koehn"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "45cdfbbd-e098-431b-b49c-56efc15fbe77", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["1", "https://commoncrawl.org/", "Local", "language", "communities", "that", "are", "working", "to", "develop", "and", "preserve", "their", "languages", "are", "producing", "diverse", "sets", "of", "data", "beyond", "pure", "text.", "The", "Bloom", "Library", "project,", "2", "for", "example,", "is", "being", "used", "by", "local", "language", "communities", "to", "create", "and", "translate", "\"shell\"", "or", "\"template\"", "books", "into", "many", "languages", "(426", "languages", "at", "the", "time", "this", "paper", "is", "being", "written).", "However,", "Bloom", "allows", "users", "to", "do", "more", "than", "just", "translate", "text.", "Users", "are", "also", "recording", "audio", "tracks", "and", "sign", "language", "videos,", "which", "has", "resulted", "in", "1600+", "oral", "translations.", "Other", "examples", "showing", "the", "multi-modal", "nature", "of", "data", "in", "local", "languages", "include:", "(i)", "the", "creation", "of", "ChoCo:", "a", "multimodal", "corpus", "of", "the", "Choctaw", "language", "(Brixey and Artstein, 2021),", "(ii)", "SIL", "International's", "50+", "year", "effort", "to", "document", "endangered", "Austronesian", "languages", "via", "text,", "audio,", "and", "video", "(Quakenbush, 2007),", "(iii)", "the", "grassroots", "Masakhane", "effort", "catalyzing", "the", "creation", "and", "use", "of", "diverse", "sets", "of", "African", "language", "data", "(\u2200 et al., 2020),", "and", "(iv)", "work", "with", "the", "Me'phaa", "language", "of", "western", "Mexico", "that", "is", "producing", "digital", "recordings", "(video", "and", "audio)", "along", "with", "vocabulary,", "grammar", "and", "texts", "(Marlett and Weathers, 2018).", "These", "diverse", "data", "sources", "are", "effectively", "unusable", "by", "traditional", "text-based", "NLP", "techniques.", "In", "the", "light", "of", "data", "scarcity", "on", "these", "languages,", "they", "offer", "significant", "untapped", "potential", "to", "unlock", "improved", "NLP", "technology,", "if", "text", "data", "can", "be", "leveraged", "along", "with", "audio,", "image", "and", "video", "data.", "Furthermore,", "flexible", "multi-modal", "technology", "such", "as", "this", "will", "make", "it", "easier", "to", "include", "diverse", "people", "and", "communities", "such", "as", "those", "described", "above", "within", "the", "NLP", "technology", "development", "process", "-audio-based", "technology", "reducing", "the", "need", "for", "literacy,", "for", "example."], "cited_papers": [{"title": "Choco: a multimodal corpus of the choctaw language. Language Resources and Evaluation", "year": "2021", "authors": ["Jacqueline Brixey", "Ron Artstein"]}], "target_citation_location": 110, "citation_locations": [110, 127, 145, 170], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "45d36906-8669-4594-b3de-8a1e2a1fd00c", "citing_paper": {"title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables", "year": 2022, "authors": ["Nan Hu", "Zirui Wu", "Yuxuan Lai", "Xiao Liu", "Yansong Feng"]}, "text": ["Benchmarks", "for", "fact", "verification", "on", "structured", "evidence", "are", "built", "on", "tables", "collected", "from", "Wikipedia", "(Chen et al., 2020)", "or", "scientific", "articles", "(Wang et al., 2021).", "Many", "previous", "works", "search", "latent", "programs", "as", "an", "intermediary", "to", "reason", "over", "the", "given", "table.", "They", "directly", "encode", "programs", "(Chen et al., 2020)", "or", "construct", "heterogeneous", "graphs", "(Shi et al., 2020, Yang et al., 2020)", "with", "the", "claim,", "the", "table", "and", "the", "programs.", "Another", "way", "is", "to", "linearize", "the", "input", "table", "and", "perform", "table", "pre-training", "(Chen et al., 2020)", "and", "add", "additional", "table-aware", "embeddings", "(Herzig et al., 2020, Eisenschlos et al., 2020)", "to", "enhance", "the", "table", "encoding.", "However,", "in", "these", "datasets,", "the", "evidence", "is", "only", "one", "given", "table,", "and", "models", "are", "not", "requested", "to", "find", "out", "the", "evidence", "cells", "explicitly."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Learn to combine linguistic and symbolic information for table-based fact verification", "year": "2020", "authors": ["Qi Shi", "Yu Zhang", "Qingyu Yin", "Ting Liu"]}], "target_citation_location": 43, "citation_locations": [14, 18, 38, 43, 64, 70], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "45df5ee0-94ec-4a96-b1ac-97fa3bb4ef5a", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["First,", "there", "exists", "the", "discrepancy", "between", "training", "and", "inference", "for", "the", "dual-encoder", "retriever.", "During", "inference,", "the", "retriever", "needs", "to", "identify", "positive", "(or", "relevant)", "passages", "for", "each", "question", "from", "a", "large", "collection", "containing", "millions", "of", "candidates.", "However,", "during", "training,", "the", "model", "is", "learned", "to", "estimate", "the", "probabilities", "of", "positive", "passages", "in", "a", "small", "candidate", "set", "for", "each", "question,", "due", "to", "the", "limited", "memory", "of", "a", "single", "GPU", "(or", "other", "device).", "To", "reduce", "such", "a", "discrepancy,", "previous", "work", "tried", "to", "design", "specific", "mechanisms", "for", "selecting", "a", "few", "hard", "negatives", "from", "the", "top-k", "retrieved", "candidates", "(Gillick et al., 2019, Wu et al., 2020, Karpukhin et al., 2020, Luan et al., 2020, Xiong et al., 2020).", "However,", "it", "suffers", "from", "the", "false", "negative", "issue", "due", "to", "the", "following", "challenge."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Learning dense representations for entity retrieval", "year": "2019", "authors": ["Daniel Gillick", "Sayali Kulkarni", "Larry Lansing", "Alessandro Presta", "Jason Baldridge", "Eugene Ie", "Diego Garc\u00eda-Olano"]}, {"title": "Sparse, dense, and attentional representations for text retrieval. CoRR, abs", "year": null, "authors": ["Yi Luan", "Jacob Eisenstein", "Kristina Toutanova", "Michael Collins"]}], "target_citation_location": 92, "citation_locations": [92], "citation_type": "group", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "46077b39-e131-42d2-8c22-a5c47c8cc0df", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["This", "2021", "instantiation", "of", "the", "Shared", "Task", "on", "Explanation", "Regeneration", "focuses", "on", "the", "theme", "of", "determining", "relevance", "in", "large", "multi-hop", "explanations.", "To", "this", "end,", "participants", "were", "given", "access", "to", "a", "large", "pre-release", "dataset", "of", "approximately", "250k", "explanatory", "relevancy", "ratings", "that", "augment", "the", "2020", "shared", "task", "data", "(Jansen and Ustalov, 2020),", "and", "were", "tasked", "with", "ranking", "the", "facts", "most", "critical", "to", "assembling", "large", "explanations", "for", "a", "given", "question", "highest.", "Similarly", "to", "the", "previous", "instances", "of", "our", "competition,", "the", "shared", "task", "has", "been", "organized", "on", "the", "CodaLab", "platform.", "1", "We", "released", "train", "and", "development", "datasets", "along", "with", "the", "baseline", "solution", "in", "advance", "to", "allow", "one", "to", "get", "to", "know", "the", "task", "specifics.", "2", "We", "ran", "the", "practice", "phase", "from", "February", "15", "till", "March", "9,", "2021.", "Then", "we", "released", "the", "test", "dataset", "without", "answers", "and", "ran", "the", "official", "evaluation", "phase", "from", "March", "10", "till", "March", "24,", "2021.", "After", "that", "we", "established", "postcompetition", "phase", "to", "enable", "long-term", "evaluation", "of", "the", "methods", "beyond", "our", "shared", "task.", "Participating", "systems", "substantially", "increased", "task", "performance", "compared", "to", "a", "supplied", "baseline", "system", "by", "32%,", "while", "achieving", "moderate", "overall", "absolute", "task", "performance", "-highlighting", "both", "the", "success", "of", "this", "shared", "task,", "as", "well", "as", "the", "continued", "challenge", "of", "determining", "relevancy", "in", "large", "multi-hop", "inference", "problems."], "cited_papers": [{"title": "TextGraphs 2020 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": "2020", "authors": ["Peter Jansen", "Dmitry Ustalov"]}], "target_citation_location": 46, "citation_locations": [46], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "460c7458-1992-4f54-a42c-c74e8923ef86", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["This", "challenge", "aims", "at", "identifying", "the", "reliability", "of", "information", "shared", "on", "social", "network", "sites", "(SNSs).", "With", "the", "blazing-fast", "spurt", "of", "SNSs", "(e.g.", "Facebook,", "Zalo", "and", "Lotus),", "there", "are", "approximately", "65", "million", "Vietnamese", "users", "on", "board", "with", "the", "annual", "growth", "of", "2.7", "million", "in", "the", "recent", "year,", "as", "reported", "by", "the", "Digital", "2020", "1.", "SNSs", "have", "become", "widely", "accessible", "for", "users", "to", "not", "only", "connect", "friends", "but", "also", "freely", "create", "and", "share", "diverse", "content", "(Shu et al., 2017, Zhou et al., 2019).", "A", "number", "of", "users,", "1", "https://wearesocial.com/digital-2020", "however,", "has", "exploited", "these", "social", "platforms", "to", "distribute", "fake", "news", "and", "unreliable", "information", "to", "fulfill", "their", "personal", "or", "political", "purposes", "(e.g.", "US", "election", "2016", "(Allcott and Gentzkow, 2017)", ").", "It", "is", "not", "easy", "for", "other", "ordinary", "users", "to", "realize", "the", "unreliability,", "hence,", "they", "keep", "spreading", "the", "fake", "content", "to", "their", "friends.", "The", "problem", "becomes", "more", "seriously", "once", "the", "unreliable", "post", "becomes", "popular", "and", "gains", "belief", "among", "the", "community.", "Therefore,", "it", "raises", "an", "urgent", "need", "for", "detecting", "whether", "a", "piece", "of", "news", "on", "SNSs", "is", "reliable", "or", "not.", "This", "task", "has", "gained", "significant", "attention", "recently", "(Ruchansky et al., 2017, Shu et al., 2019a,b, Yang et al., 2019)."], "cited_papers": [{"title": "Unsupervised fake news detection on social media: A generative approach", "year": "2019", "authors": ["Shuo Yang", "Kai Shu", "Suhang Wang", "Renjie Gu", "Fan Wu", "Huan Liu"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "Csi: A hybrid deep model for fake news detection", "year": "2017", "authors": ["Natali Ruchansky", "Sungyong Seo", "Yan Liu"]}], "target_citation_location": 171, "citation_locations": [73, 104, 171], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "46198fc2-5f06-42e3-b890-54d9fbda8de7", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["We", "used", "the", "learning", "with", "Local", "and", "Global", "Consistence", "(LGC)", "(Zhou et al., 2004)", "as", "a", "regularization", "method.", "The", "algorithm", "designs", "a", "classi-fying", "function", "that", "is", "sufficiently", "smooth", "concerning", "the", "intrinsic", "structure", "collectively", "revealed", "by", "known", "labeled", "and", "unlabeled", "points.", "Thus,", "the", "LGC", "lets", "every", "point", "iteratively", "spread", "its", "label", "information", "to", "its", "neighbors", "until", "a", "global", "stable", "state", "is", "achieved", "(Gui et al., 2014).", "Also,", "it", "allows", "the", "class", "information", "of", "the", "labeled", "objects", "to", "be", "changed", "during", "the", "classification", "as", "objects", "may", "be", "erroneously", "labeled", "and,", "consequently,", "decrease", "the", "performance", "of", "the", "classification.", "More", "than", "that,", "the", "algorithm", "diminished", "the", "influence", "of", "objects", "with", "a", "high", "degree", "(many", "neighboring", "objects),", "therefore,", "these", "objects", "do", "not", "have", "excessive", "influence", "in", "the", "classification."], "cited_papers": [{"title": "Semi-supervised learning with local and global consistency", "year": "2014", "authors": ["Jie Gui", "Rongxiang Hu", "Zhongqiu Zhao", "Wei Jia"]}], "target_citation_location": 58, "citation_locations": [10, 58], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4647c75c-7a0e-4575-a466-fa328037ed6c", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["Related", "work", "Our", "work", "follows", "a", "long", "line", "of", "works", "on", "efficient", "Transformers", "(see", "\u00a71).", "Our", "method", "employs", "three", "main", "ideas:", "(a)", "computing", "the", "top-k", "attention", "scores", "for", "each", "query", "(b)", "grouping", "the", "queries", "into", "chunks", "and", "processing", "these", "sequentially", "(c)", "caching", "only", "a", "part", "of", "the", "activations", "for", "the", "backward", "pass.", "Top-k", "operation", "was", "used", "at", "self-attention", "layers", "by", "(Zhao et al., 2019)", "to", "show", "improved", "model", "performance,", "attributed", "to", "the", "removal", "of", "irrelevant", "information", "in", "the", "context.", "We", "use", "it", "to", "reduce", "the", "resource", "usage", "of", "multi-head", "attention", "and", "feed-forward", "layers.", "Processing", "query", "chunks", "sequentially", "was", "also", "used", "in", "Reformer", "(Kitaev et al., 2020)", "as", "activations", "are", "not", "cached.", "But", "in", "that", "case,", "by", "replacing", "vanilla", "residual", "connections", "in", "the", "Transformer", "with", "reversible", "connections", "(Gomez et al., 2017).", "Similar", "to", "the", "explanation", "provided", "in", "\u00a72.2,", "these", "require", "an", "extra", "implicit", "forward", "pass", "during", "the", "backward", "pass", "and", "do", "not", "provide", "the", "compute", "and", "memory", "savings", "we", "get", "from", "our", "top-k", "specific", "backward", "pass", "(\u00a72.2).", "Secondly,", "replacing", "residual", "connections", "with", "reversible", "ones", "changes", "the", "function", "computed", "by", "the", "model", "and", "would", "require", "corrective", "pre-training", "to", "be", "used", "with", "BERT,", "T5,", "etc", "(\u00a74.3-", "\u00a74.5)."], "cited_papers": [{"title": "Reformer: The efficient transformer", "year": "2020", "authors": ["Nikita Kitaev", "Lukasz Kaiser", "Anselm Levskaya"]}], "target_citation_location": 99, "citation_locations": [60, 99, 120], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "46909607-aab1-4d54-b634-6922af8a2d68", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["They", "found", "that", "the", "behavior", "of", "human", "players", "is", "best", "modeled", "on", "the", "probabilities", "of", "bigrams,", "which", "is", "in", "line", "with", "the", "results", "of", "(Spence", "and", "Owens,", "1990)", "(although", "the", "latter", "calculated", "cooccurrences", "with", "much", "larger", "window", "size).", "Kim et al. (2019)", "were", "the", "first", "to", "build", "agents", "designed", "explicitly", "to", "play", "the", "game.", "As", "a", "background", "to", "their", "relatedness", "measure,", "they", "used", "CBOW,", "Skip-gram", "and", "GloVe", "word", "embeddings", "(in", "multiple", "configurations),"], "cited_papers": [{"title": "Cooperation and codenames: Understanding natural language processing via codenames", "year": "2019", "authors": ["Andrew Kim", "Maxim Ruzmaykin", "Aaron Truong", "Adam Summerville"]}], "target_citation_location": 38, "citation_locations": [38], "citation_type": "single", "annotations": [[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "46d36327-b7a1-4bab-acb6-5f6be12f4ae4", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["WM", "is", "a", "long-term,", "open-ended", "project", "which", "originated", "with", "Domenig (1989).", "Subsequently", "it", "was", "developed", "at", "Universities", "in", "Basel,", "Amsterdam", "(Vrije", "Universiteit),", "and", "Lugano", "(SUPSI", "and", "USI),", "funded", "in", "part", "by", "the", "Swiss", "federal", "government", "and", "by", "private", "companies."], "cited_papers": [{"title": "Word Manager: A system for the Specification, Use, and Maintenance of Morphological Knowledge, Habilitationsschrift", "year": "1989", "authors": ["Marc Domenig"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "476a6d41-38ef-4dd6-9087-3647860b4a6d", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Linguistic", "variations.", "Another", "aspect", "comes", "from", "looking", "at", "implicit", "abuse,", "whereby", "a", "user", "may", "utilize", "novel", "slangs", "or", "conventional", "words", "in", "unconventional", "ways,", "e.g.,", "as", "a", "racial", "slur", "or", "as", "a", "name", "for", "some", "specific", "demographic", "(Waseem et al., 2017).", "Information", "about", "how", "a", "term", "is", "being", "used", "by", "other", "members", "of", "a", "user's", "community,", "e.g.,", "in", "abusive", "contexts", "or", "otherwise,", "can", "help", "decipher", "linguistic", "variations", "that", "come", "up", "from", "time", "to", "time.", "In", "fact,", "it", "is", "usually", "the", "users", "with", "strong", "ties", "who", "are", "responsible", "for", "popularizing", "language", "variations", "as", "well", "as", "for", "spreading", "hate", "speech", "(Del Tredici and Fern\u00e1ndez, 2018, Ribeiro et al., 2018).", "Therefore,", "having", "user", "and", "community", "information", "alongside", "linguistic", "features", "helps", "capture", "linguistic", "variations", "and", "their", "diffusion."], "cited_papers": [{"title": "Characterizing and detecting hateful users on twitter", "year": "2018", "authors": ["Manoel Ribeiro", "Pedro Calais", "Yuri Santos", "Virg\u00edlio Almeida", "Wagner Meira"]}, {"title": "The road to success: Assessing the fate of linguistic innovations in online communities", "year": "2018", "authors": ["Marco Del Tredici", "Raquel Fern\u00e1ndez"]}], "target_citation_location": 94, "citation_locations": [36, 94], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "476aab87-c427-4ae9-81cf-09095a3cd302", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["If", "recombination", "or", "rephrasing", "is", "required", "during", "the", "composition", "process,", "this", "implies", "consultation", "with", "the", "user.", "Therefore,", "the", "system", "must", "be", "able", "to", "interact", "in", "an", "intelligent", "manner", "with", "the", "user", "and,", "consequently,", "an", "additional", "module", "in", "the", "form", "of", "a", "human-machine", "interaction", "dialogue", "model", "is", "required.", "In", "order", "for", "the", "system", "to", "interact", "'intelligently',", "it", "must", "understand", "the", "communicative", "intent", "of", "the", "user", "and", "therefore", "must", "have", "knowledge", "of", "the", "domain.", "We", "will", "not", "address", "here", "this", "aspect", "of", "the", "proposed", "system,", "which", "is", "essentially", "a", "typical", "problem", "of", "task-oriented", "dialogue", "([13]", ")."], "cited_papers": [{"title": "The structure of task oriented dialogs", "year": "1974", "authors": ["B Grosz"]}], "target_citation_location": 92, "citation_locations": [92], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "4831b3e6-53fd-4d49-8d96-3ea5e2100a9c", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Recent", "advances", "in", "the", "field", "of", "Natural", "Language", "Processing", "(NLP)", "have", "been", "made", "with", "the", "development", "of", "transfer", "learning", "and", "the", "availability", "of", "pre-trained", "language", "models", "based", "on", "Transformer", "architectures", "(Vaswani et al., 2017),", "such", "as", "BERT", "(Devlin et al., 2019).", "As", "they", "provide", "contextualized", "semantic", "representation", "they", "contribute", "both", "to", "advance", "the", "state-of-the-art", "on", "several", "NLP", "tasks", "and", "also", "to", "evolve", "training", "practices", "through", "the", "use", "of", "fine-tuning."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 34, "citation_locations": [30, 34], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "48e1a480-08a1-49a6-9997-7e7f8824d27b", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["4.", "For", "French,", "we", "did", "not", "find", "systems", "that", "did", "event", "extraction", "from", "the", "French", "TimeBank", "corpus.", "The", "existing", "literature", "either", "creates", "and", "evaluates", "on", "a", "modified", "corpus", "(Bittar, 2009)", "or", "provides", "annotations", "trained", "on", "the", "TimeML", "annotated", "data", "and", "tested", "on", "Fr-TempEval2)", "(Arnulphy et al., 2015).", "Therefore,", "we", "compare", "our", "performance", "to", "those,", "while", "also", "understanding", "that", "the", "comparison", "is", "not", "a", "strict", "metric.", "We", "hope", "to", "establish", "the", "scores", "here", "as", "baseline", "for", "further", "improvement", "over", "models", "in", "event", "detection", "in", "French."], "cited_papers": [{"title": "Annotation of events and temporal expressions in french texts", "year": "2009", "authors": ["Andr\u00e9 Bittar"]}], "target_citation_location": 28, "citation_locations": [28, 42], "citation_type": "single", "annotations": [[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4914a18a-e1e2-4855-a3d4-3da70ef6ca58", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["Experimental", "details", "For", "all", "models,", "we", "benchmark", "by", "running", "a", "forward", "and", "backward", "pass", "over", "random", "inputs.", "Each", "measurement", "is", "an", "average", "over", "3", "runs", "on", "an", "Nvidia", "A100", "GPU", "and", "is", "discarded", "if", "memory", "usage", "exceeds", "30GiB.", "We", "use", "causal", "masking", "for", "self-attention", "layers", "to", "highlight", "the", "simplicity", "of", "our", "approach", "that", "can", "seamlessly", "handle", "arbitrary", "attention", "masks,", "unlike", "other", "methods", "(Wang et al., 2020, Katharopoulos et al., 2020, Choromanski et al., 2021),", "where", "implementing", "causal", "masking", "requires", "customized", "CUDA", "implementations.", "For", "Performer,", "we", "use", "256", "random", "features,", "and", "the", "CUDA", "implementation", "from", "(Katharopoulos et al., 2020)."], "cited_papers": [{"title": "Rethinking attention with performers", "year": "2021", "authors": ["Valerii Krzysztof Marcin Choromanski", "David Likhosherstov", "Xingyou Dohan", "Andreea Song", "Tamas Gane", "Peter Sarlos", "Jared Hawkins", "Afroz Davis", "Lukasz Mohiuddin", "David Kaiser", "Lucy Belanger", "Adrian Colwell", "unk Weller"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 62, "citation_locations": [62, 83], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4a020263-16d2-4bea-a8d7-d0f44cf1a2d6", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["The", "rest", "of", "the", "article", "is", "organized", "according", "to", "(Day, 2007)", "as", "follows:"], "cited_papers": [{"title": null, "year": "2007", "authors": ["Day Robert", "A unk"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1]]}
{"id": "4a86c4ba-0e7b-4781-a1af-e8566830cac2", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["While", "we", "do", "not", "have", "access", "to", "many", "coreference", "annotations", "for", "the", "task", "of", "coreference-aware", "MRC,", "there", "are", "various", "datasets", "for", "the", "task", "of", "coreference", "resolution.", "Coreference", "resolution", "datasets", "contain", "the", "annotation", "of", "expressions", "that", "refer", "to", "the", "same", "entity.", "In", "this", "paper,", "we", "hypothesize", "that", "we", "can", "directly", "use", "coreference", "resolution", "corpora", "to", "improve", "the", "coreference", "reasoning", "of", "MRC", "models.", "We", "propose", "an", "effective", "approach", "to", "convert", "coreference", "annotations", "into", "QA", "pairs", "so", "that", "models", "learn", "to", "perform", "coreference", "resolution", "by", "answering", "those", "questions.", "In", "our", "experiments,", "we", "use", "the", "9", "We", "examine", "50", "randomly", "selected", "examples", "from", "our", "challenge", "set,", "and", "they", "were", "all", "answerable", "by", "a", "human.", "CoNLL-2012 dataset (Pradhan et al., 2012b)", "that", "is", "the", "largest", "annotated", "dataset", "with", "coreference", "information."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 110, "citation_locations": [110], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "4aa08dcc-af3f-4463-bfa6-9f5d8cc186bb", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["Apart", "from", "designing", "classification", "tasks", "for", "disentanglement", "evaluation,", "another", "method", "is", "based", "on", "estimating", "the", "mutual", "information", "(MI)", "between", "a", "single", "dimension", "of", "the", "latent", "variable", "and", "a", "single", "generative", "factor.", "Chen et al. (2018)", "propose", "to", "use", "the", "average", "of", "the", "gap", "(difference)", "between", "the", "largest", "normalised", "MI", "(by", "the", "information", "entropy", "of", "the", "generative", "factor)", "and", "the", "second", "largest", "normalised", "MI", "over", "all", "generative", "factors", "as", "the", "disentanglement", "score,", "whereas", "the", "modularity", "metric", "of", "Ridgeway and Mozer (2018)", "measures", "whether", "a", "single", "latent", "variable", "has", "the", "highest", "MI", "with", "only", "one", "generative", "factor", "and", "none", "with", "others."], "cited_papers": [{"title": "Learning deep disentangled embeddings with the f-statistic loss", "year": "2018", "authors": ["Karl Ridgeway", "C Michael", "unk Mozer"]}], "target_citation_location": 73, "citation_locations": [31, 73], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "4aee5d0f-e018-40c6-b19b-0bc664597528", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["The", "idea", "to", "develop", "this", "sort", "of", "interaction", "in", "the", "direction", "of", "a", "more", "sophisticated", "clarification", "dialogue", "is", "now", "gaining", "currency", "with", "the", "emergence", "of", "DBMT", "[3, 4, 47]", "and", "the", "notion", "of", "'MT", "without", "a", "source", "text'", "[43],", "where", "the", "dialogue", "aims", "not", "merely", "at", "disambiguating", "a", "given", "text,", "but", "in", "helping", "the", "user", "to", "compose", "it", "in", "the", "first", "place."], "cited_papers": [{"title": "Machine translation without a source text", "year": "1990", "authors": ["H Somers", "J Tsujii", "D Jones"]}], "target_citation_location": 36, "citation_locations": [26, 36], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "4b2f347e-656a-4a48-9135-ee6c18ba63bc", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["Besides,", "concept", "instance", "nodes", "(CI)", "and", "concept", "sequence", "instance", "structures", "(CSI)", "are", "dynamically", "created", "during", "parsing.", "Each", "CI", "or", "CSI", "is", "connected", "to", "the", "associated", "CC", "or", "CSC", "by", "INST", "link.", "CIs", "correspond", "to", "discourse", "entities", "proposed", "in", "[Webber, 1983).", "Three", "additional", "links", "are", "used", "to", "facilitate", "pragmatic", "inferences.", "They", "are", "CONTEXT", "links.", "CONSTRAINT", "links", "and", "EQROLE", "links.", "A", "CONTEXT", "link", "is", "a", "path", "of", "contextual", "priming", "which", "is", "crucial", "in", "word", "sense", "disambiguation.", "When", "a", "word", "is", "activated", "during", "processing,", "the", "activation", "spreads", "through", "CONTEXT", "links", "and", "impose", "contextual", "priming", "to", "relevant", "concepts.", "A", "CONSTRAINT", "link", "denotes", "an", "antecedent/consequence", "relationship", "between", "two", "events", "or", "states,", "which", "is", "created", "between", "two", "CSRs.", "An", "EQROLE", "link", "denotes", "the", "necessary", "argument", "matching", "condition", "for", "testing", "an", "antecedent/consequence", "relationship,", "which", "is", "created", "between", "two", "CSEs", "in", "different", "CSCs."], "cited_papers": [{"title": "So What Can We Talk About Now", "year": "1983", "authors": ["B Webber ", " Webber"]}], "target_citation_location": 38, "citation_locations": [38], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4b320c01-749f-433a-af8a-a42a0c56a628", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["We", "collect", "the", "data", "for", "two", "months", "from", "August", "to", "October", "2020.", "There", "are", "two", "main", "sources", "of", "the", "data:", "SNSs", "and", "Vietnamese", "newspapers.", "As", "for", "the", "former", "source,", "public", "social", "media", "posts", "are", "retrieved", "from", "news", "groups", "and", "key", "opinion", "leaders", "(KOLs).", "Many", "fake", "news,", "however,", "has", "been", "flagged", "and", "removed", "from", "the", "social", "networking", "sites", "since", "the", "enforcement", "of", "Vietnamese", "cybersecurity", "law", "in", "2019", "(Son, 2018).", "Therefore,", "to", "include", "the", "deleted", "fake", "news,", "we", "gather", "newspaper", "articles", "reporting", "these", "posts", "and", "recreate", "their", "content."], "cited_papers": [{"title": "Vietnam passes cyber security law", "year": "2018", "authors": ["Tuan Son"]}], "target_citation_location": 66, "citation_locations": [66], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "4b75a4b4-5c1d-424e-9b86-bf7360c6b43e", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["and", "the", "WordNet", "database", "(Miller, 1992)", "with", "a", "number", "of", "different", "distance", "functions."], "cited_papers": [{"title": "WordNet: A lexical database for English", "year": "1992", "authors": ["A George", "unk Miller"]}], "target_citation_location": 4, "citation_locations": [4], "citation_type": "single", "annotations": [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "4bc88726-244c-47c4-8d41-f4b0781e8efe", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["This", "section", "describes", "how", "we", "prepare", "the", "collapsed", "single", "sequence", "composed", "of", "s", "i", "in", "Eq.", "(8).", "We", "explain", "this", "data", "preparation", "with", "both", "English", "(TED-LIUM", "release", "2", "(TEDLIUM2)", "(Rousseau et al., 2014))", "and", "Japanese", "(corpus", "of", "spontaneous", "Japanese", "(CSJ)", "(Maekawa et al., 2000", "))", "data", "as", "an", "example.", "The", "sequence", "type", "includes", "the", "graphemic", "and", "phonemic", "transcripts", "1,", "as", "well", "as", "the", "POS", "tags."], "cited_papers": [{"title": "Enhancing the TED-LIUM corpus with selected data for language modeling and more TED talks", "year": "2014", "authors": ["A Rousseau", "P Del\u00e9glise", "Y Est\u00e8ve"]}], "target_citation_location": 29, "citation_locations": [29, 37], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "4bda6500-9ff1-4879-9a27-8caa19cc1dc0", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["The", "baseline", "system", "built", "for", "the", "task", "is", "a", "simple", "PBSMT", "system", "trained", "only", "on", "the", "'in-domain'", "training", "data", "released", "as", "a", "part", "of", "the", "evaluation", "campaign.", "This", "training", "data", "comprised", "of", "both", "parallel", "and", "monolingual", "data", "from", "the", "TED", "1", "http://iwslt2011.org", "Talks:", "2", "a", "collection", "of", "public", "speeches", "on", "a", "variety", "of", "topics.", "Out-of-domain", "data", "in", "the", "form", "of", "a", "parallel", "Multi-UN", "corpus", "3", "was", "also", "available", "to", "enrich", "the", "models", "trained", "on", "in-domain", "data.", "For", "domain-adaptation", "we", "enhanced", "the", "language", "models", "built", "on", "the", "TED", "corpus", "data", "with", "selected", "data", "from", "the", "UN", "corpus.", "Mixture", "adaptation", "[4]", "techniques", "were", "used", "to", "combine", "models", "from", "multiple", "sources", "weighted", "according", "to", "their", "fit", "with", "respect", "to", "the", "development", "set.", "The", "adapted", "language", "models", "provided", "an", "improvement", "of", "about", "5.16", "absolute", "(21.99%", "relative)", "BLEU", "points", "for", "Ar-En", "and", "1.25", "absolute", "(11.76%", "relative)", "BLEU", "points", "for", "Zh-En", "language", "pairs", "over", "the", "unadapted", "baseline."], "cited_papers": [{"title": "Broadcast news lm adaptation using contemporary texts", "year": "2001", "authors": ["M Federico", "N Bertoldi"]}], "target_citation_location": 98, "citation_locations": [98], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4c089e24-7287-4d9b-81fa-61b6d8f30c76", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Table", "2", "shows", "the", "main", "experimental", "results.", "We", "can", "see", "that", "RocketQA", "significantly", "outperforms", "all", "the", "baselines", "on", "both", "MSMARCO", "and", "NQ", "datasets.", "Another", "observation", "is", "that", "the", "dense", "retrievers", "are", "overall", "better", "than", "the", "sparse", "retrievers.", "Such", "a", "finding", "has", "also", "been", "reported", "in", "previous", "studies", "(Karpukhin et al., 2020, Luan et al., 2020, Xiong et al., 2020),", "which", "indicates", "the", "effectiveness", "of", "the", "dense", "retrieval", "approach."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Sparse, dense, and attentional representations for text retrieval. CoRR, abs", "year": null, "authors": ["Yi Luan", "Jacob Eisenstein", "Kristina Toutanova", "Michael Collins"]}], "target_citation_location": 47, "citation_locations": [47], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "4c760f4a-c274-4ee6-8e9d-05b4bd8c4be5", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["One", "of", "the", "central", "subjects", "of", "artificial", "intelligence", "research", "has", "long", "been", "the", "development", "of", "agents", "that", "play", "various", "games", "at", "the", "human", "level", "or", "better.", "Most", "studies", "in", "the", "field", "focus", "on", "combinatorial", "games,", "that", "can", "be", "easily", "formalized", "mathematically,", "such", "as", "chess", "and", "go", "(see,", "for", "example,", "Allis et al., 1994).", "The", "popular", "board", "game", "Codenames", "is", "different", "from", "these", "in", "many", "aspects", "and", "may", "provide", "an", "excellent", "experimental", "ground", "in", "areas", "such", "as", "predicting", "human", "behavior", "or", "implementing", "human-machine", "cooperation."], "cited_papers": [{"title": "Searching for solutions in games and artificial intelligence", "year": "1994", "authors": ["Louis Victor", "Allis unk"]}], "target_citation_location": 49, "citation_locations": [49], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4c791b07-9140-48f4-b5bb-29625a86c801", "citing_paper": {"title": "Can Semantic Role Labeling Improve SMT?", "year": 2009, "authors": ["Dekai Wu", "Pascale Fung"]}, "text": ["It", "has", "been", "widely", "observed", "that", "the", "negative", "impacts", "of", "such", "errors", "on", "the", "utility", "of", "the", "translation", "are", "inadequately", "reflected", "by", "evaluation", "metrics", "based", "on", "lexical", "criteria.", "The", "accuracy", "of", "translation", "lexical", "choice", "has", "reached", "increasingly", "satisfactory", "levels-at", "least", "for", "largely", "literal", "genres", "such", "as", "newswire", "-which", "helps", "boost", "lexically", "oriented", "scores", "such", "as", "BLEU", "(Papineni et al., 2002)", "or", "METEOR", "(Banerjee and Lavie, 2005)", "despite", "serious", "role", "confusion", "errors", "in", "the", "translations."], "cited_papers": [{"title": "METEOR: An automatic metric for MT evaluation with improved correlation with human judgement", "year": "2005", "authors": ["Satanjeev Banerjee", "Alon Lavie"]}], "target_citation_location": 59, "citation_locations": [56, 59], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "4c7e0b43-be66-4869-86c6-2061f17405d7", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["Another", "straightforward", "operation", "is", "to", "sum", "the", "embeddings", "(technique", "used", "in", "[23])", "of", "the", "previous", "lemma", "with", "the", "embedding", "of", "the", "previous", "factors,", "as", "described", "in", "equation", "7."], "cited_papers": [{"title": "Efficient Estimation of Word Representations in Vector Space", "year": "2013", "authors": ["T Mikolov", "K Chen", "G Corrado", "J Dean"]}], "target_citation_location": 11, "citation_locations": [11], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]]}
{"id": "4c821844-95b9-45e8-8264-36eb7f0a1459", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["Because", "OPUS", "open", "subtitles", "is", "a", "parallel", "corpus", "we", "are", "able", "to", "evaluate", "our", "annotated", "datasets", "across", "languages", "and", "at", "identical", "levels", "of", "granularity.", "Although", "the", "subtitles", "might", "be", "translated", "using", "different", "translation", "philosophies", "(favoring", "e.g.", "meaning,", "mood,", "or", "idiomatic", "language", "as", "the", "prime", "objective)", "(Carl et al., 2011),", "we", "expect", "the", "translations", "to", "have", "aimed", "at", "capturing", "the", "sentiments", "and", "emotions", "originally", "expressed", "in", "the", "film", "based", "on", "previous", "studies", "(e.g.", "Cowen et al. (2019),", "Scherer and Wallbott (1994),", "Creutz (2018),", "Scherrer (2020)", "and", "Kajava", "et", "al.", "(2020))."], "cited_papers": [{"title": "Evidence for universality and cultural variation of differential emotion response patterning", "year": "1994", "authors": ["Klaus Scherer", "Harald Wallbott"]}], "target_citation_location": 70, "citation_locations": [45, 69, 70, 71, 72], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "4cd4676a-2cf1-4053-9122-03b1bd4d14c7", "citing_paper": {"title": "Controlled Text Generation with Adversarial Learning", "year": 2020, "authors": ["Federico Betti", "Giorgia Ramponi", "Massimo Piccardi"]}, "text": ["Evaluation", "For", "this", "task,", "we", "have", "classified", "the", "generated", "sentences", "in", "terms", "of", "their", "sentiment", "using", "a", "Bidirectional-LSTM", "as", "classifier.", "In", "addition,", "we", "have", "evaluated", "two", "quality", "metrics:", "1)", "the", "novelty", "of", "each", "generated", "sentence", "(Eq.", "5)", "using", "the", "definition", "from", "[20],", "where", "JS", "is", "the", "Jaccard", "similarity", "and", "C", "j", "are", "the", "training", "set", "sentences.", "The", "novelty", "measures", "the", "diversity", "between", "the", "generated", "data", "and", "the", "training", "corpus,", "and", "2)", "the", "diversity", "metric", "(Eq.", "6),", "a", "measure", "of", "the", "model's", "ability", "to", "generate", "diverse", "sentences", "and", "avoid", "mode", "collapse."], "cited_papers": [{"title": "SentiGAN: Generating Sentimental Texts via Mixture Adversarial Networks", "year": "2018", "authors": ["Ke Wang", "Xiaojun Wan"]}], "target_citation_location": 41, "citation_locations": [41], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4ce2e6ce-71a4-47e9-9670-57d51dd869bf", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Table", "5:", "The", "experimental", "results", "of", "passage", "reading", "on", "NQ", "dataset.", "In", "this", "paper,", "we", "focus", "on", "extractive", "reader,", "while", "the", "recent", "generative", "readers", "(Lewis et al., 2020, Izacard and Grave, 2020)", "can", "also", "be", "applied", "here", "and", "may", "lead", "to", "better", "results."], "cited_papers": [{"title": "Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs", "year": null, "authors": ["Gautier Izacard", "Edouard Grave"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "4d21de9a-b471-4195-8d4f-a5027988598d", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["Each", "language", "part", "of", "the", "bilingual", "word", "list", "was", "treated", "independently", "using", "the", "same", "method,", "but", "obviously", "different", "corpus.", "Each", "word", "from", "bilingual", "word", "list", "was", "stemmed", "using", "a", "modified", "version", "of", "(Popovi\u010d, 1992)", "algorithm", "that", "takes", "into", "consideration", "only", "extensions", "that", "were", "present", "in", "paradigms.", "This", "means", "that", "each", "word", "is", "shortened", "of", "the", "longest", "possible", "extension", "producing", "word's", "stem.", "All", "extensions", "are", "attached", "to", "the", "stem", "producing", "a", "multiset", "of", "words.", "This", "multiset", "is", "searched", "in", "monolingual", "referential", "corpus,", "in", "our", "case", "(Erjavec et al., 1998) and (Serbian, 2007),", "all", "words", "that", "are", "found", "in", "corpus", "present", "a", "list", "of", "possible", "extensions,", "thus", "reducing", "the", "number", "of", "all", "extensions", "to", "a", "moderate", "number."], "cited_papers": [{"title": "The effectiveness of stemming for natural language access to Slovene textual data", "year": "1992", "authors": ["M Popovi\u010d", "P Willett"]}], "target_citation_location": 32, "citation_locations": [32, 83], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4de55fa4-1491-4963-bd30-6e33dff37202", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Passage", "re-ranking", "for", "open-domain", "QA", "Based", "on", "the", "retrieved", "passages", "from", "a", "first-stage", "retriever,", "BERT-based", "rerankers", "have", "recently", "been", "applied", "to", "retrieval-based", "question", "answering", "and", "search-related", "tasks", "(Wang et al., 2019, Nogueira and Cho, 2019, Nogueira et al., 2019b, Yan et al., 2019),", "and", "yield", "substantial", "improvements", "over", "the", "traditional", "methods.", "Although", "effective", "to", "some", "extent,", "these", "rankers", "employ", "the", "cross-encoder", "architecture", "(as", "shown", "in", "Figure", "1b)", "that", "is", "impractical", "to", "be", "applied", "to", "all", "passages", "in", "a", "corpus", "with", "respect", "to", "a", "question.", "The", "re-rankers", "(Khattab and Zaharia, 2020, Gao et al., 2020)", "with", "light", "weight", "interaction", "based", "on", "the", "representations", "of", "dense", "retrievers", "have", "been", "studied.", "However,", "these", "techniques", "still", "rely", "on", "a", "separate", "retriever", "which", "provides", "candidates", "and", "representations.", "As", "a", "comparison,", "we", "focus", "on", "developing", "dual-encoder", "based", "retrievers."], "cited_papers": [{"title": "Colbert: Efficient and effective passage search via contextualized late interaction over BERT", "year": "2020", "authors": ["Omar Khattab", "Matei Zaharia"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 71, "citation_locations": [27, 71], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "4e146b7b-4ec3-46ad-9d51-79e400819de8", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["\"", "!\"!", "#", "$%", "!\"!", "&amp,!", "\"", "#\"!", "#", "$%", "#\"!", "&amp,!", "\"", "$\"!", "#", "$%", "$\"!", "&amp,!", "\"", "!\"#", "#", "$%", "!\"#", "&amp,!", "\"", "#\"#", "#", "$%", "#\"#", "'", "%", "$\"#", "&amp,!", "\"", "$\"#", "#", "$%", "%\"#", "'", "%", "&amp,\"#", "'", "%", "'\"#", "&amp,", "(!", "#", "$!", "\"", "!\"!", "'!", "\"", "!\"#", "'!", "\"", "!\"$", "&amp,", "(#", "#", "$!", "\"", "#\"!", "'!", "\"", "#\"#", "'!", "\"", "#\"$", "&amp,", "($", "#", "$!", "\"", "$\"!", "'!", "\"", "$\"#", "'!", "\"", "$\"$", "&amp,!", "\"", "!\"$", "#", "$%", "!\"$", "&amp,!", "\"", "#\"$", "#", "$%", "#\"$", "&amp,!", "\"", "$\"$", "#", "$%", "$\"$", "&amp,For", "the", "Japanese", "data,", "we", "use", "the", "annotation", "labels", "provided", "in", "the", "corpus.", "Note", "that", "some", "of", "the", "POS", "tags", "are", "estimated", "using", "a", "morphological", "analysis", "model.", "For", "the", "English", "data,", "we", "obtain", "these", "sequences", "from", "the", "pronunciation", "dictionary", "provided", "in", "the", "corpus", "and", "WordNet", "(Miller, 1998),", "respectively.", "Some", "words", "in", "the", "vocabulary", "have", "two", "or", "more", "pronunciations", "in", "the", "pronunciation", "dictionary.", "To", "obtain", "phoneme", "sequences,", "we", "randomly", "selected", "a", "single", "pronunciation", "per", "word", "from", "the", "candidate", "pronunciations.", "Since", "in", "WordNet,", "57", "%", "of", "the", "words", "in", "the", "corpus", "are", "not", "annotated", "with", "the", "POS", "tags,", "we", "annotated", "these", "labels", "with", "the", "output", "of", "the", "POS", "tagging", "system", "(Loper and Bird, 2002).", "Next,", "we", "replaced", "these", "phonemes", "and", "POS", "tags", "with", "special", "symbols", "(Fig.", "2(c))", "to", "distinguish", "them", "from", "the", "grapheme", "symbols.", "Third,", "we", "split", "graphemic", "and", "linguistic", "annotation", "sequences", "at", "word", "boundaries", "and", "obtain", "sub-sequences", "(\u0233", "i,k", "in", "Eq.", "(8))", "(Fig.", "2(d)).", "Then", "sub-sequences", "are", "aggregated", "with", "the", "segments", "(s", "i", "in", "Eq.", "(8))", "and", "collapsed", "into", "the", "target", "sequence", "in", "the", "manner", "of", "Eq.", "(8)", "(Fig.", "2(e)).", "For", "the", "English", "data,", "we", "applied", "byte-pair", "encoding", "(BPE)", "(Kudo and Richardson, 2018)", "to", "the", "collapsed", "target", "sequence", "(Fig.", "2(f))."], "cited_papers": [{"title": "NLTK: the natural language toolkit", "year": "2002", "authors": ["E Loper", "S Bird"]}], "target_citation_location": 205, "citation_locations": [143, 205, 282], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4e8b6a77-d4be-4046-a02a-97f40d073544", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["A", "CSC", "captures", "ordering", "constraints", "of", "natural", "language,", "and", "it", "roughly", "corresponds", "to", "phrase", "structure", "rules.", "CSCs", "can", "be", "used", "to", "represent", "syntax", "and", "semantics", "of", "sentences", "at", "different", "levels", "of", "abstraction", "from", "instances", "of", "surface", "sequence", "to", "linguistically", "motivated", "grammar", "such", "as", "Lexical-Functional", "Grammar", "(LFG)", "[Kaplan and Bresnan, 1982].", "As", "shown", "in", "figure", "2,", "a", "CSC", "consists", "of", "a", "root", "node", "(CSR),", "element", "nodes", "(CSE),", "a", "FIRST", "link,", "a", "LAST", "link,", "NEXT", "link(s)", "and", "ROLE", "links.", "A", "CSR", "is", "a", "representative", "node", "for", "the", "meaning", "of", "the", "entire", "CSC", "structure,", "CSRs", "are", "connected", "to", "their", "designated", "interlingual", "concepts", "by", "ENG", "or", "JPN.", "Each", "CSC", "has", "one", "or", "more", "CSEs", "linked", "to", "a", "CSR", "by", "ROLE", "links.", "The", "ordering", "constraints", "between", "two", "concept", "sequence", "element", "nodes", "are", "represented", "by", "NEXT", "link.", "FIRST", "and", "LAST", "links", "in", "each", "CSC", "points", "to", "the", "first", "and", "last", "elements,", "respectively.", "Also,", "each", "CSE", "represents", "the", "relevant", "case", "role,", "and", "the", "case", "role", "has", "a", "selectional", "restriction.", "Since", "we", "want", "to", "avoid", "heavy", "symbolic", "operations", "during", "parsing,", "ROLE", "links", "and", "associated", "constraint", "links", "are", "used", "instead", "of", "performing", "type", "and", "value", "consistency", "check", "by", "unification.", "Therefore", "each", "CSE", "is", "used", "for", "both", "enforcing", "the", "ordering", "constraint", "and", "capturing", "semantic", "information."], "cited_papers": [{"title": "Lexical-Functional Grammar: A Formal System for Grammatical Representation", "year": "1982", "authors": ["R Bresnan ", " Kaplan", "J Bresnan", "J Bresnan", "R Kaplan", "A Zaenen"]}], "target_citation_location": 46, "citation_locations": [46], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4efe12ff-7f24-4f00-b753-ebd288c416e0", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Unlabeled", "questions", "We", "collect", "1.7", "million", "unlabeled", "questions", "from", "Yahoo!", "Answers", "5,", "ORCAS", "(Craswell et al., 2020)", "and", "MRQA", "(Fisch et al., 2019).", "We", "use", "the", "questions", "from", "Yahoo!", "Answers,", "ORCAS", "and", "NQ", "as", "new", "questions", "in", "the", "experiments", "of", "MSMARCO.", "We", "only", "use", "the", "questions", "from", "MRQA", "as", "the", "new", "questions", "in", "the", "experiments", "of", "NQ.", "Since", "both", "NQ", "and", "MRQA", "mainly", "contain", "factoid-questions,", "while", "other", "datasets", "contain", "both", "factoid", "and", "non-factoid", "questions."], "cited_papers": [{"title": "ORCAS: 20 million clicked query-document pairs for analyzing search", "year": "2020", "authors": ["Nick Craswell", "Daniel Campos", "Bhaskar Mitra", "Emine Yilmaz", "Bodo Billerbeck"]}], "target_citation_location": 13, "citation_locations": [13, 16], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4f36509e-1b50-49b4-8d26-e311e3198c69", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["There", "is", "a", "large", "body", "of", "work", "in", "the", "literature", "showing", "that", "a", "morphological", "decomposition", "of", "the", "Arabic", "words", "can", "improve", "the", "word", "coverage", "and", "by", "these", "means", "the", "translation", "quality,", "see", "for", "instance", "[10, 14, 15].", "This", "is", "in", "particular", "true", "for", "under-resourced", "tasks", "like", "this", "evaluation.", "Most", "of", "the", "published", "work", "is", "based", "on", "the", "freely", "available", "tools,", "like", "the", "Buckwalter", "transliterator", "and", "the", "MADA", "and", "TOKAN", "tools", "for", "morphological", "analysis", "from", "Columbia", "University."], "cited_papers": [{"title": "The TALP ngram-based SMT system for IWSLT", "year": "2007", "authors": ["P Lambert", "M Costa-Juss\u00e0", "J Crego", "M Khalilov", "J No", "R Banchs", "J Fonollosa", "H Schwenk"]}, {"title": "The university of washington machine translation system for the iwslt 2007 competition", "year": "2007", "authors": ["K Kirchhoff", "M Yang"]}, {"title": "Arabic preprocessing schemes for statistical machine translation", "year": "2006", "authors": ["N Habash", "F Sadat"]}], "target_citation_location": 34, "citation_locations": [34], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "4f6067c2-de52-4400-9a44-eb13b17ff731", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["Each", "annotated", "document", "consists", "of", "a", "title", "and", "3", "paragraphs", "of", "text,", "and", "contains", "a", "list", "of", "non-pronominal", "base-NPs", "(most", "identified", "by", "SpaCy", "[Honnibal et al., 2020]", "9", "but", "some", "added", "manually", "by", "the", "annotators),", "a", "list", "of", "coreference", "clusters", "over", "the", "NPs,", "and", "a", "list", "of", "NP-relations", "that", "hold", "in", "the", "text.", "Each", "relation", "is", "a", "triplet", "consisting", "of", "two", "NPs", "from", "the", "NP", "list,", "and", "a", "connecting", "element", "which", "is", "one", "of", "23", "prepositions", "(displayed", "in", "Table", "1)", "10", "or", "a", "''member(s)", "of''", "relation", "designating", "set-membership.", "The", "list", "of", "NP", "relations", "is", "exhaustive,", "and", "aims", "to", "cover", "all", "and", "only", "valid", "NP-NP", "relations", "in", "the", "document."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 23, "citation_locations": [23], "citation_type": "single", "annotations": [[3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4fa279b1-f81e-4b97-a92d-1eec7beaf4b9", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Third,", "it", "is", "expensive", "to", "acquire", "large-scale", "training", "data", "for", "open-domain", "QA.", "MSMARCO", "and", "Natural", "Questions", "(Kwiatkowski et al., 2019)", "are", "two", "largest", "datasets", "for", "open-domain", "QA.", "They", "are", "created", "from", "commercial", "search", "engines,", "and", "have", "516K", "and", "300K", "annotated", "questions,", "respectively.", "However,", "it", "is", "still", "insufficient", "to", "cover", "all", "the", "topics", "of", "questions", "issued", "by", "users", "to", "search", "engines."], "cited_papers": [{"title": "Natural questions: a benchmark for question answering research", "year": "2019", "authors": ["Tom Kwiatkowski", "Jennimaria Palomaki", "Olivia Redfield", "Michael Collins", "Ankur Parikh", "Chris Alberti", "Danielle Epstein", "Illia Polosukhin", "Jacob Devlin", "Kenton Lee", "Kristina Toutanova", "Llion Jones", "Matthew Kelcey", "Ming-Wei Chang", "Andrew Dai", "Jakob Uszkoreit", "Quoc Le", "Slav Petrov"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "4fc9994e-e039-4a13-8414-cdda4281fbd9", "citing_paper": {"title": "Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure", "year": 1999, "authors": ["Nicoletta Calzolari", "Antonio Zampolli"]}, "text": ["The", "1986", "Grosseto", "(Tuscany)", "Workshop", "\"On", "automating", "the", "lexicon\"", "(Walker et al. 1995)", "is", "usually", "recognised", "as", "the", "event", "marking", "an", "inversion", "of", "tendency", "and", "the", "starting", "point", "of", "the", "process", "which", "gradually", "brought", "the", "major", "actors", "of", "the", "NLP", "sector", "to", "pay", "more", "and", "more", "attention", "to", "reusable", "language", "resources.", "This", "process,", "which", "was", "fostered", "by", "a", "number", "of", "initiatives", "which", "followed", "directly", "from", "the", "Grosseto", "workshop,", "achieved", "a", "crucial", "step", "through", "the", "recognition,", "in", "the", "so-", "called Danzin Report (1992),", "of", "the", "infrastructural", "role", "of", "LR", "(see", "also", "Zampolli 1991).", "This", "was", "very", "influential", "in", "the", "formation", "of", "the", "strategy", "of", "the", "European", "Commission", "(EC).", "In", "fact,", "the", "issue", "of", "LR", "is", "now", "regularly", "present", "in", "the", "initiatives", "of", "the", "EC", "in", "the", "field", "of", "language", "processing."], "cited_papers": [{"title": "Preliminary Considerations on the Constitution of an ELTA (European Language Technology Agency). Pisa, Document prepared for DG XIII", "year": "1991", "authors": ["A Zampolli"]}], "target_citation_location": 84, "citation_locations": [9, 75, 84], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "502e9260-b205-4917-9dfc-ed0109b60e80", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Hope", "and", "Keller", "(2013),", "for", "example,", "use", "a", "graph", "of", "co-occurrences", "for", "word", "sense", "induction.", "Later", "Pelevina et al. (2016)", "use", "a", "similar", "method", "to", "disambiguate", "word", "embedding", "models."], "cited_papers": [{"title": "Making sense of word embeddings", "year": "2016", "authors": ["Maria Pelevina", "Nikolay Arefiev", "Chris Biemann", "Alexander Panchenko"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "5041b755-2716-48ea-91d9-f0d9d32880e5", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["Learning", "task-agnostic", "unsupervised", "representations", "of", "data", "has", "been", "the", "center", "of", "attention", "across", "various", "areas", "of", "Machine", "Learning", "and", "more", "specifically", "NLP.", "However,", "little", "is", "known", "about", "the", "way", "these", "continuous", "representations", "organise", "information", "about", "data.", "In", "recent", "years,", "the", "NLP", "community", "has", "focused", "on", "the", "question", "of", "design", "and", "selection", "of", "suitable", "linguistic", "tasks", "to", "probe", "the", "presence", "of", "syntactic", "or", "semantic", "phenomena", "in", "representations", "as", "a", "whole", "(Bosc and Vincent, 2020, Voita and Titov, 2020, Torroba Hennigen et al., 2020, Pimentel et al., 2020, Hewitt and Liang, 2019, Ettinger et al., 2018, Marvin and Linzen, 2018, Conneau et al., 2018).", "Nonetheless,", "a", "finegrain", "understanding", "of", "information", "organisation", "in", "coordinates", "of", "a", "continuous", "representation", "is", "yet", "to", "be", "achieved."], "cited_papers": [{"title": "Assessing composition in sentence vector representations", "year": "2018", "authors": ["Allyson Ettinger", "Ahmed Elgohary", "Colin Phillips", "Philip Resnik"]}, {"title": "Targeted syntactic evaluation of language models", "year": "2018", "authors": ["Rebecca Marvin", "Tal Linzen"]}, {"title": "What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties", "year": "2018", "authors": ["Alexis Conneau", "German Kruszewski", "Guillaume Lample", "Lo\u00efc Barrault", "Marco Baroni"]}, {"title": "Intrinsic probing through dimension selection", "year": "2020", "authors": ["Adina Lucas Torroba Hennigen", "Ryan Williams", "unk Cotterell"]}, {"title": "Informationtheoretic probing with minimum description length", "year": "2020", "authors": ["Elena Voita", "Ivan Titov"]}, {"title": "Do sequence-tosequence VAEs learn global features of sentences?", "year": "2020", "authors": ["Tom Bosc", "Pascal Vincent"]}, {"title": "Designing and interpreting probes with control tasks", "year": "2019", "authors": ["John Hewitt", "Percy Liang"]}, {"title": "Information-theoretic probing for linguistic structure", "year": "2020", "authors": ["Tiago Pimentel", "Josef Valvoda", "Rowan Hall Maudslay", "Ran Zmigrod", "Adina Williams", "Ryan Cotterell"]}], "target_citation_location": 69, "citation_locations": [69], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "508a12a1-fd09-42b9-8acc-c7f069798e9b", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["It", "is", "because", "solely", "relying", "on", "network", "homophily", "as", "the", "inductive", "bias", "for", "generating", "profiles", "caused", "the", "method", "of", "Mishra et al. (2018a)", "to", "make", "some", "faulty", "generalizations.", "Such", "observations", "have", "also", "been", "made", "by", "other", "works,", "a", "prominent", "one", "of", "which", "is", "the", "work", "of", "Bamman et al. (2014)", "who", "explored", "the", "relationships", "amongst", "gender,", "language,", "and", "social", "network", "connections.", "The", "researchers", "noted", "that", "even", "though", "there", "may", "exist", "many", "linguistic", "clusters", "that", "exhibit", "strong", "orientations", "to", "one", "gender,", "yet", "the", "characteristics", "of", "any", "particular", "cluster", "do", "not", "necessarily", "align", "with", "populationlevel", "statistics", "for", "that", "gender.", "Furthermore,", "they", "observed", "that", "there", "are", "individuals", "whose", "linguistic", "practices", "differ", "from", "population-level", "trends", "for", "their", "gender", "and", "that", "gender", "homophily", "does", "not", "capture", "their", "linguistic", "practices."], "cited_papers": [{"title": "Gender identity and lexical variation in social media", "year": "2014", "authors": ["David Bamman", "Jacob Eisenstein", "Tyler Schnoebelen"]}], "target_citation_location": 43, "citation_locations": [19, 43], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "50d87801-0834-4de7-ba8e-7ca053ec4521", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["Calibration", "requires", "that", "a", "model's", "confidence", "on", "its", "predictions", "is", "equal", "to", "the", "accuracy", "of", "these", "predictions", "(Guo et al., 2017).", "Previous", "work", "(M\u00fcller et al., 2019, Kumar and Sarawagi, 2019, Wang et al., 2020)", "has", "found", "that", "a", "more", "calibrated", "text", "generation", "model", "tends", "to", "have", "better", "performance,", "and", "techniques", "like", "label", "smoothing", "can", "improve", "both", "the", "token-level", "calibration", "and", "sequence-level", "accuracy", "(i.e.", "the", "ability", "of", "generating", "better", "results).", "One", "intuitive", "explanation", "of", "this", "phenomenon", "is", "to", "interpret", "the", "model's", "estimated", "probability", "of", "a", "generated", "summary", "as", "the", "product", "of", "the", "model's", "confidences", "on", "a", "series", "of", "tokenlevel", "predictions.", "Then,", "since", "a", "more", "calibrated", "model's", "confidence", "estimates", "better", "the", "accuracy", "of", "its", "predictions,", "the", "model's", "estimated", "probability", "of", "one", "sequence", "should", "be", "more", "indicative", "of", "the", "quality", "of", "this", "sequence,", "which", "is", "essential", "for", "the", "beam", "search", "during", "inference.", "However,", "the", "relation", "of", "token-level", "calibration", "and", "sequencelevel", "performance", "remains", "inconclusive", "(M\u00fcller et al., 2019).", "10", "For", "example,", "a", "generator", "that", "always", "predicts", "a", "uniform", "distribution", "over", "all", "tokens", "would", "be", "perfectly", "calibrated,", "however,", "such", "a", "model", "would", "not", "generate", "high-quality", "outputs."], "cited_papers": [{"title": "On calibration of modern neural networks", "year": "2017", "authors": ["Chuan Guo", "Geoff Pleiss", "Yu Sun", "Kilian Weinberger"]}], "target_citation_location": 17, "citation_locations": [17, 20, 137], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "50db6fee-0fc1-45e1-a03a-56e4f673d3d7", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Designing", "neural", "diversity", "metrics.", "In", "spite", "of", "growing", "interest", "in", "NLG", "models", "that", "produce", "diverse", "outputs,", "there", "is", "currently", "no", "principled", "neu-ral", "method", "for", "evaluating", "the", "diversity", "of", "an", "NLG", "system.", "As", "described", "in", "Tevet and Berant (2021),", "existing", "automatic", "diversity", "metrics", "(e.g.", "Self-BLEU)", "perform", "worse", "than", "humans", "on", "the", "task", "of", "estimating", "content", "diversity,", "indicating", "a", "low", "correlation", "between", "metrics", "and", "human", "judgments."], "cited_papers": [{"title": "Evaluating the evaluation of diversity in natural language generation", "year": "2021", "authors": ["Guy Tevet", "Jonathan Berant"]}], "target_citation_location": 34, "citation_locations": [34], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "5130579f-6987-43d4-8d91-92e4d163e732", "citing_paper": {"title": "NEW TABULAR ALGORITHMS FOR LIG PARSING", "year": 2000, "authors": ["Mi G Uel Alonso Jor G E Grana", "Manuel Vilares"]}, "text": ["These", "items", "are", "like", "those", "proposed", "for", "the", "tabulation", "of", "linear", "indexed", "automata", "[10]", "LCYK", "=", "{[A,", ",y,i,j", "I", "B,", "p,q]", "I", "A,", "B", "E", "VN,", "'Y", "E", "Vi,", "0", "::,", "i::,", "j,", "(p,q)", "::,", "(i,", "j)}", "11.cYK", "=", "{[a,", "i", "-1,", "i]", "I", "a", "=", "ai,", "lJ", "::,", "i", "::,", "n}", "v", "scan", "-", "[a,j,", "j", "+", "1]", "A[]", "\u2794", "a", "E", "p", "CYK", "-[A..", "1", "1", "],", "-,", "1,", "1+", "-,", "-,", "-I", "[B,-,", "i,", "k", "1", "-,", "-,", "-],", "1)[00-y](", "](oo]", "_", "[C,", "17", ",k,j", "I", "D,"], "cited_papers": [{"title": "Linear indexed automata and tabulation of TAG parsing", "year": "1998", "authors": ["M-J Nederhof"]}], "target_citation_location": 13, "citation_locations": [13], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "5143c579-3b3d-49b8-876d-4f9ff5f5c6fe", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["In", "practice,", "the", "separation", "of", "question", "encoding", "and", "passage", "encoding", "is", "desirable,", "so", "that", "the", "dense", "representations", "of", "all", "passages", "can", "be", "precomputed", "for", "efficient", "retrieval.", "Here,", "we", "adopt", "two", "independent", "neural", "networks", "initialized", "from", "pre-trained", "LMs", "for", "the", "two", "encoders", "E", "q", "(\u2022)", "and", "E", "p", "(\u2022)", "separately,", "and", "take", "the", "representations", "at", "the", "first", "token", "(e.g.,", "[CLS]", "symbol", "in", "BERT)", "as", "the", "output", "for", "encoding."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 58, "citation_locations": [58], "citation_type": "single", "annotations": [[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2]]}
{"id": "51ae962b-d5d2-4ebf-a02c-3eb127106cb7", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["cosine", "similarity", "in", "Skip-gram", "(Mikolov et al., 2013),"], "cited_papers": [{"title": "Distributed representations of words and phrases and their compositionality", "year": "2013", "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg Corrado", "Jeff Dean"]}], "target_citation_location": 4, "citation_locations": [4], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1]]}
{"id": "51f99389-855e-4869-b864-83335779ebb3", "citing_paper": {"title": "Comparison of post-editing productivity between professional translators and lay users", "year": 2014, "authors": ["Nora Aranberri", "Gorka Labaka"]}, "text": ["MT", "output", "quality", "is", "also", "essential", "in", "post-editing", "measurements,", "a", "factor", "that", "is", "often", "neglected", "when", "reporting", "productivity", "gain.", "An", "exception", "is", "a", "seminal", "work", "by", "Koehn and Germann (2014).", "They", "studied", "the", "relation", "between", "MT", "quality", "and", "post-editing,", "and", "concluded", "that", "differences", "in", "post-editing", "skills", "might", "be", "more", "decisive", "than", "MT", "quality", "to", "foresee", "productivity", "gain", "when", "comparing", "systems", "within", "the", "same", "quality", "range.", "Our", "findings", "show", "that", "the", "text", "for", "which", "a", "higher", "increase", "in", "productivity", "was", "obtained", "seems", "to", "be", "slightly", "easier", "and", "better", "suited", "for", "our", "MT", "system."], "cited_papers": [{"title": "The impact of machine translation quality on human post-editing", "year": "2014", "authors": ["P Koehn", "U Germann"]}], "target_citation_location": 26, "citation_locations": [26], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "5271dccb-0e35-481e-963e-999cb0e82b20", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["We", "evaluate", "on", "7", "sequence", "labelling", "benchmarks:", "4", "of", "which", "are", "NER", "datasets", "and", "3", "of", "which", "are", "POStagging", "datasets", "1.", "In", "brief,", "each", "dataset", "consists", "of", "a", "sequence", "of", "sentences,", "where", "each", "sentence", "has", "a", "sequence", "of", "(word:tag)", "pairs.", "For", "NER", "we", "use", "the", "BinAjeeba", "(Darwish, 2013),", "the", "ANERCorp", "developed", "by", "Benajiba et al. (2007),", "and", "the", "Wikipedia", "and", "Newswire", "datasets", "which", "are", "mapped", "2", "versions", "of", "the", "fine-grained", "WikiFANE", "and", "NewsFANE", "datasets", "(Alotaibi and Lee, 2014)", "respectively.", "For", "POStagging", "we", "are", "evaluating", "on", "3", "standard", "datasets:", "WikiNews", "(Abdelali et al., 2019),", "Al-Mushaf", "(Zeroual and Abdelhak, 2016),", "Prague", "Arabic", "Dependency", "Tree", "Bank", "(PADT)", "(Hajic et al., 2004)."], "cited_papers": [{"title": "Named entity recognition using cross-lingual resources: Arabic as an example", "year": "2013", "authors": ["Kareem Darwish"]}], "target_citation_location": 46, "citation_locations": [46, 51, 70, 82, 84, 91], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "52811710-c5e0-4a60-b6d3-6b78513ac43b", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["called", "DMSNAP", "using", "a", "parallel", "marker-passing", "scheme.", "DM-SNAP", "is", "a", "SNAP", "implementation", "of", "the", "\u03a6DMDIALOG", "speechto-speech", "dialogue", "translation", "system", "[Kitano, 1990a ] [Kitano, 1991a],", "but", "with", "some", "modifications", "to", "meet", "hardware", "constraints.", "Despite", "its", "high", "performance,", "our", "system", "carries", "out", "sound", "syntactic", "and", "semantic", "analysis", "including", "lexical", "ambiguity,", "structural", "ambiguity,", "pronoun", "reference,", "control,", "unbounded", "dependency,", "and", "others."], "cited_papers": [{"title": "Massively Parallel Memory-Based Parsing", "year": "1991", "authors": ["( Kitano", "H Higuchi ", " Kitano", "T Higuchi"]}, {"title": "Parallel Incremental Sentence Produclion for a Model of Simultaneous Interpretation", "year": "1989", "authors": ["H Kitano", "H Kitano", "H Kitano", "H Tomabechi", "Levin unk"]}], "target_citation_location": 19, "citation_locations": [19], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "5293abbf-b0a5-4258-a596-9192d4225de3", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["Some", "research", "adopted", "argumentation", "schemes", "as", "a", "framework,", "making", "comparisons", "with", "discourse", "relations", "(Cabrio et al., 2013)", "and", "collecting", "and", "leveraging", "data", "at", "varying", "degrees", "of", "granularity.", "At", "a", "coarse", "level,", "prior", "studies", "annotated", "the", "presence", "of", "particular", "argumentation", "schemes", "in", "text", "(Visser et al., 2020, Lawrence et al., 2019, Lindahl et al., 2019, Reed et al., 2008)", "and", "developed", "models", "to", "classify", "different", "schemes", "(Feng and Hirst, 2011).", "However,", "each", "scheme", "often", "accommodates", "both", "support", "and", "attack", "relations", "between", "statements,", "so", "classifying", "those", "relations", "requires", "semantically", "richer", "information", "within", "the", "scheme", "than", "just", "its", "presence.", "To", "that", "end,", "Reisert et al. (2018)", "annotated", "individual", "components", "within", "schemes,", "particularly", "emphasizing", "argument", "from", "consequences.", "Based", "on", "the", "logic", "behind", "this", "scheme,", "Kobbe et al. (2020)", "developed", "an", "unsupervised", "method", "to", "classify", "the", "support", "and", "attack", "relations", "using", "syntactic", "rules", "and", "lexicons.", "Our", "work", "extends", "these", "studies", "by", "including", "other", "normative", "schemes", "(practical", "reasoning", "and", "property-based", "reasoning)", "and", "annotating", "richer", "information."], "cited_papers": [{"title": "Classifying arguments by scheme", "year": "2011", "authors": ["Vanessa Wei Feng", "Graeme Hirst"]}], "target_citation_location": 47, "citation_locations": [13, 39, 47, 78, 96], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "533f8df9-6d1c-453c-8cd3-265fe8d10732", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["Job", "Selection", "Collecting", "and", "generating", "job", "ads", "for", "all", "possible", "jobs", "is", "prohibitively", "timely", "and", "costly.", "Hence,", "we", "restrict", "our", "experiments", "to", "a", "sample", "of", "15", "jobs", "selected", "via", "three", "criteria:", "(1)", "prevalence,", "jobs", "with", "a", "sufficiently", "large", "labour", "force", "in", "the", "UK", "(N", "\u2265", "40,000),", "(2)", "relevance,", "jobs", "which", "have", "a", "sufficiently", "large", "number", "of", "real-world", "job", "ads", "on", "a", "popular", "online", "forum", "(N", "\u2265", "1,000)", "and", "(3)", "bias,", "jobs", "which", "represent", "the", "most", "male-biased,", "female-biased", "and", "neutral", "parts", "of", "GPT-3's", "prior", "distribution", "in", "how", "frequently", "certain", "jobs", "are", "associated", "with", "a", "given", "gender.", "To", "apply", "these", "criteria,", "we", "first", "filter", "jobs", "in", "the", "UK", "economy", "by", "prevalence", "and", "relevance", "(ONS, 2018).", "Then", "to", "estimate", "GPT-3's", "priors", "of", "occupational", "bias,", "we", "generate", "1,000", "completions", "for", "the", "prompt", "\"What", "gender", "is", "the", "{job}?", "The", "{job}", "is", "a", "[token]\",", "where", "a", "completion", "could", "be:", "\"What", "gender", "is", "the", "plumber?"], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 111, "citation_locations": [111], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "535d0f79-ae06-49ad-9631-0759b8d98c7f", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["As", "shown", "in", "previous", "work", "(Wang et al., 2019, Sun et al., 2019, Meng et al., 2020),", "increasing", "the", "depth", "of", "the", "Transformer", "encoder", "can", "substantially", "improve", "model", "performance,", "therefore", "we", "train", "the", "Transformer", "with", "deep", "encoder", "to", "obtain", "a", "better", "source", "representation."], "cited_papers": [{"title": null, "year": "2020", "authors": ["Fandong Meng", "Jianhao Yan", "Yijin Liu", "Yuan Gao", "Xianfeng Zeng", "Qinsong Zeng", "Peng Li", "Ming Chen", "Jie Zhou", "Sifan Liu"]}, {"title": "Baidu neural machine translation systems for WMT19", "year": "2019", "authors": ["Meng Sun", "Bojian Jiang", "Hao Xiong", "Zhongjun He", "Hua Wu", "Haifeng Wang"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "5391071f-0afc-4232-951a-a73971c384a7", "citing_paper": {"title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation", "year": 2021, "authors": ["Hansi Hettiarachchi", "Tharindu Ranasinghe"]}, "text": ["The", "main", "motivation", "behind", "the", "TransWiC", "architecture", "is", "the", "success", "transformer-based", "architectures", "had", "in", "various", "natural", "language", "processing", "tasks", "like", "offensive", "language", "identification", "(Ranasinghe and Hettiarachchi, 2020, Ranasinghe et al., 2019c, Pitenis et al., 2020),", "offensive", "spans", "identification", "(Ranasinghe and Zampieri, 2021a, Ranasinghe et al., 2021),", "language", "detection", "(Jauhiainen et al.,", "Lang."], "cited_papers": [{"title": "BRUMS at SemEval-2020 task 12: Transformer based multilingual offensive language identification in social media", "year": "2020", "authors": ["Tharindu Ranasinghe", "Hansi Hettiarachchi"]}, {"title": "BRUMS at HASOC 2019: Deep learning models for multilingual hate speech and offensive language identification", "year": "2019", "authors": ["Tharindu Ranasinghe", "Marcos Zampieri", "Hansi Hettiarachchi"]}, {"title": "Offensive language identification in Greek", "year": "2020", "authors": ["Zesis Pitenis", "Marcos Zampieri", "Tharindu Ranasinghe"]}], "target_citation_location": 23, "citation_locations": [23, 27, 30], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "53f7484f-1cf2-4fc8-a26f-30cd0fbc5f22", "citing_paper": {"title": "drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM", "year": 2022, "authors": ["Dylan Phelps"]}, "text": ["SemEval-2022", "task", "2b", "(Tayyar Madabushi et al., 2022)", "encourages", "the", "creation", "of", "better", "representations", "of", "idiomatic", "expressions", "across", "multiple", "languages", "by", "presenting", "a", "Semantic", "Text", "Similarity", "(STS)", "task", "in", "which", "correct", "STS", "scores", "are", "required", "whether", "or", "not", "either", "sentence", "contains", "an", "idiomatic", "expression.", "The", "sub-task", "requires", "the", "creation", "of", "a", "self-consistent", "model", "in", "which", "a", "sentence", "including", "an", "idiomatic", "expression", "and", "one", "containing", "its", "literal", "meaning", "('swan", "song'", "and", "'final", "performance')", "are", "exactly", "similar", "to", "each", "other", "and", "equally", "similar", "to", "any", "other", "sentence."], "cited_papers": [{"title": "SemEval-2022 Task 2: Multilingual Idiomaticity Detection and Sentence Embedding", "year": "2022", "authors": ["Edward Harish Tayyar Madabushi", "Marcos Gow-Smith", "Carolina Garcia", "Marco Scarton", "Aline Idiart", "unk Villavicencio"]}], "target_citation_location": 3, "citation_locations": [3], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "5432b066-cfa4-4d54-936f-dbdacff11957", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["We", "apply", "the", "proposed", "framework", "and", "quantify", "second-order", "robustness", "through", "two", "second-order", "attacks", "(\u00a73).", "We", "experiment", "with", "English", "sentiment", "classification", "on", "the", "SST-2", "dataset", "(Socher et al., 2013)", "across", "various", "model", "architectures.", "Surprisingly,", "although", "robustly", "trained", "CNN", "(Jia et al., 2019)", "and", "Transformer", "(Xu et al., 2020)", "can", "achieve", "high", "robustness", "under", "strong", "attacks", "(Alzantot et al., 2018, Garg and Ramakrishnan, 2020)", "(23.0%-71.6%", "success", "rates),", "for", "around", "96.0%", "of", "the", "test", "examples", "our", "attacks", "can", "find", "a", "vulnerable", "example", "by", "perturbing", "1.3", "words", "on", "average.", "This", "finding", "indicates", "that", "these", "robustly", "trained", "models,", "despite", "being", "first-order", "robust,", "are", "not", "second-order", "robust."], "cited_papers": [{"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "year": "2013", "authors": ["Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "D Christopher", "Andrew Manning", "Christopher Ng", "unk Potts"]}], "target_citation_location": 24, "citation_locations": [24, 34, 37, 45], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5433acd7-1d0a-4387-bf37-243e6407e7df", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["and", "the", "BabelNet", "knowledge", "graph", "(Navigli and Ponzetto, 2010b),", "with", "a", "framework", "that", "associates", "words", "according", "to", "special", "rules,", "developed", "specifically", "for", "this", "purpose."], "cited_papers": [{"title": "Babelnet: Building a very large multilingual semantic network", "year": "2010", "authors": ["Roberto Navigli", "Simone Ponzetto"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[0, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "5435a7ff-18f8-4c4d-bf48-8ae6337450c5", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["At", "bottom,", "she", "believed", "that", "such", "interlinguas", "were", "in", "need", "of", "some", "form", "of", "empirical", "justification", "and", "could", "not", "be", "treated", "as", "unprovable", "and", "arbitrary", "assumptions", "for", "a", "system,", "in", "the", "way", "Katz (1972)", "has", "tried", "to", "do", "by", "arguing", "from", "the", "role", "of", "assumed", "entities", "in", "physics", "and", "mathematics.", "There", "was", "one", "weak", "form", "of", "empirical", "support", "available:", "statistics", "derived", "from", "dictionaries", "showed", "that", "the", "first", "100", "commonest", "defining", "words", "in", "English", "dictionaries", "(exempting", "'a'", "and", "'the')", "corresponded", "very", "closely", "indeed", "to", "the", "primitives", "of", "NUDE.", "But", "MMB", "wanted", "something", "more", "structural", "and", "spent", "some", "considerable", "time", "trying", "to", "associate", "the", "NUDE", "elements", "with", "the", "classifying", "principles", "of", "the", "thesaurus", "itself,", "which", "would", "then", "link", "back", "to", "the", "distributional", "facts", "about", "texts", "that", "the", "thesaurus", "itself", "represented.", "In", "this,", "as", "in", "other", "ways,", "MMB", "had", "more", "intuitive", "sympathy", "with", "earlier", "distributional", "or", "structural", "linguistics", "than", "with", "the", "more", "apparently", "mathematical", "and", "symbolic", "linguistics", "of", "Chomsky", "and", "his", "followers."], "cited_papers": [{"title": "Semantic theory", "year": "1972", "authors": ["Jerrold Katz"]}], "target_citation_location": 32, "citation_locations": [32], "citation_type": "single", "annotations": [[0, 0, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "546e7abb-9962-4e49-bfbc-2c9106ff7d2c", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["In", "this", "work,", "we", "introduce", "a", "framework", "to", "automatically", "identify", "spurious", "correlations", "exploited", "by", "the", "model,", "sometimes", "also", "denoted", "as", "\"shortcuts\"", "in", "prior", "work", "(Geirhos et al., 2020, Minderer et al., 2020)", "1,", "at", "a", "large", "scale.", "Our", "proposed", "framework", "differs", "from", "existing", "literature", "with", "a", "focus", "more", "on", "automatic", "shortcut", "identification,", "instead", "of", "pre-defining", "a", "limited", "set", "of", "shortcuts", "or", "learning", "from", "human", "annotations", "(Table", "1).", "Our", "framework", "works", "as", "follows:", "given", "a", "task", "and", "a", "trained", "model,", "we", "first", "utilize", "interpretability", "methods,", "e.g.,", "attention", "scores", "(Clark et al., 2019b, Kovaleva et al., 2019)", "and", "integrated", "gradient", "(Sundararajan et al., 2017)", "which", "are", "commonly", "used", "for", "interpreting", "model's", "decisions,", "to", "automatically", "extract", "tokens", "that", "the", "model", "deems", "as", "important", "for", "task", "label", "Objective", "Approach", "for", "shortcut", "identification", "He et al. (2019)", "Robustness", "against", "known", "shortcuts", "Pre-defined", "Clark et al. (2019a)", "Robustness", "against", "known", "shortcuts", "Pre-defined", "Clark et al. (2020)", "Robustness", "against", "unknown", "shortcuts", "A", "low-capacity", "model", "to", "specifically", "learn", "shortcuts", "Wang and Culotta (2020a)", "prediction.", "We", "then", "introduce", "two", "extra", "steps", "to", "further", "categorize", "the", "extracted", "tokens", "to", "be", "\"genuine\"", "or", "\"spurious\".", "We", "utilize", "a", "cross-dataset", "analysis", "to", "identify", "tokens", "that", "are", "more", "likely", "to", "be", "\"shortcut\"."], "cited_papers": [{"title": "Unlearn dataset bias in natural language inference by fitting the residual", "year": "2019", "authors": ["He He", "Sheng Zha", "Haohan Wang"]}], "target_citation_location": 111, "citation_locations": [24, 80, 84, 111, 117, 123, 135], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "54bf8c5b-756c-40b2-be3a-ebe0d8d78122", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["1.", "The", "TempEval-3", "TimeBank", "dataset", "was", "used", "for", "English", "(UzZaman et al., 2012).", "The", "corpus", "consists", "of", "61,418", "tokens", "for", "training", "and", "6,756", "event", "mentions.", "3.", "For", "Italian,", "we", "use", "Ita-TimeBank's", "ILC", "corpus", "(Caselli et al., 2011a)", "the", "Italian", "corpus", "annotated", "using", "ISO-TimeML", "rules", "for", "events", "and", "temporal", "information.", "The", "corpus", "consists", "of", "68,000", "tokens", "and", "10,591", "event", "mentions."], "cited_papers": [{"title": "Annotating events, temporal expressions and relations in italian: the it-timeml experience for the ita-timebank", "year": "2011", "authors": ["Tommaso Caselli", "Valentina Lenzi", "Rachele Sprugnoli"]}], "target_citation_location": 30, "citation_locations": [9, 30], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "55154692-1773-4be6-a947-641923ff7add", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["To", "empower", "the", "generation", "model", "to", "produce", "multiple", "reasonable", "outputs,", "we", "employ", "a", "mixture", "of", "expert", "(MoE)", "module", "to", "model", "uncertainty", "and", "generate", "diverse", "outputs.", "While", "the", "MoE", "models", "have", "primarily", "been", "explored", "as", "a", "means", "of", "increasing", "model", "capacity,", "they", "are", "also", "being", "used", "to", "boost", "diverse", "generation", "process", "(Shen et al., 2019, Cho et al., 2019).", "Formally,", "the", "MoE", "module", "introduces", "a", "multinomial", "latent", "variable", "z", "\u2208", "{1,", "\u2022,", "K},", "and", "decomposes", "the", "marginal", "likelihood", "as", "follows:p(y|x,", "G", "x)", "=", "K", "z=1", "p(z|x,", "G", "x", ")p(y|z,", "x,", "G", "x", ").", "(7)Training.", "We", "minimize", "the", "loss", "function", "(in", "Eq.(", "6))", "using", "the", "MoE", "decomposition,\u2207", "log", "p(y|x,", "G", "x)", "(8)", "=", "K", "z=1", "p(z|x,", "y,", "G", "x)", "\u2207", "log", "p(y,", "z|x,", "G", "x", "),and", "train", "the", "model", "with", "the", "EM", "algorithm", "(Dempster et al., 1977).", "Ideally,", "we", "would", "like", "different", "experts", "to", "specialize", "in", "different", "reasoning", "abilities", "so", "that", "they", "can", "generate", "diverse", "outputs.", "The", "specialization", "of", "experts", "means", "that", "given", "the", "input,", "only", "one", "element", "in", "{p(y,", "z|x,", "G", "x", ")}", "K", "z=1", "should", "dominate", "in", "value", "(Shen et al., 2019).", "To", "encourage", "this,", "we", "employ", "a", "hard", "mixture", "model", "to", "maximize", "max", "z", "p(y,", "z|x,", "G", "x)", "by", "assigning", "full", "responsibility", "to", "the", "expert", "with", "the", "largest", "joint", "probability.", "Training", "proceeds", "via", "hard-EM", "can", "be", "written", "as:"], "cited_papers": [{"title": "Mixture content selection for diverse sequence generation", "year": "2019", "authors": ["Jaemin Cho", "Minjoon Seo", "Hannaneh Hajishirzi"]}, {"title": "Mixture models for diverse machine translation: Tricks of the trade", "year": "2019", "authors": ["Tianxiao Shen", "Myle Ott", "Michael Auli", "Marc'aurelio Ranzato"]}], "target_citation_location": 50, "citation_locations": [50, 124, 168], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "554d25a1-b33a-468b-a977-010856197aab", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["Based", "on", "the", "learned", "state", "tracking", "model,", "a", "straightforward", "idea", "of", "obtaining", "salient", "words", "is", "to", "apply", "importance", "attribution", "approaches.", "Specifically,", "these", "approaches", "measure", "the", "importance", "of", "each", "word", "by", "observing", "the", "prediction", "difference", "caused", "by", "replacing", "it", "(Ribeiro et al., 2018, Jin et al., 2020).", "As", "discussed", "before,", "this", "would", "result", "in", "different", "action", "representations", "for", "utterances", "with", "the", "same", "action.", "To", "address", "this", "issue,", "we", "consider", "learning", "action", "representations", "from", "a", "broader", "vocabulary,", "which", "releases", "the", "constraint", "of", "selecting", "salient", "words", "only", "within", "utterances."], "cited_papers": [{"title": "Towards hierarchical importance attribution: Explaining compositional semantics for neural sequence models", "year": "2020", "authors": ["Xisen Jin", "Junyi Du", "Zhongyu Wei", "Xiangyang Xue", "Xiang Ren"]}, {"title": "Anchors: High-precision modelagnostic explanations", "year": "2018", "authors": ["Sameer Marco Tulio Ribeiro", "Carlos Singh", "unk Guestrin"]}], "target_citation_location": 38, "citation_locations": [38], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "561581b3-5e5d-4d16-ba0f-6bdf3e0e473c", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["We", "first", "review", "three", "efforts", "to", "translate", "multiword", "units", "by", "scoring", "POS-tagged", "phrases", "or", "by", "fusing", "individual", "target", "language", "words", "that", "appear", "correlated", "to", "a", "source", "language", "phrase.", "Kupiec (1993)", "examined", "translation", "of", "noun", "phrases", "between", "English", "and", "French", "and", "reported", "90%", "accuracy", "in", "an", "informal", "evaluation", "of", "the", "one", "hundred", "translations", "that", "had", "the", "highest", "confidence", "scores.", "His", "method", "requires", "POS-tagging", "each", "sentence", "in", "an", "aligned", "parallel", "text", "(i.e.,", "both", "sides", "are", "tagged).", "Then", "noun", "phrases", "are", "scored", "using", "an", "iterative", "estimation", "method.", "Kupiec", "notes", "several", "sources", "of", "error", "caused", "by", "problems", "using", "POS", "information", "instead", "of", "constituent", "parses,", "such", "as", "an", "inability", "to", "infer", "prepositional", "phrase", "attachment.", "The", "method", "relies", "on", "having", "POS", "tagging", "or", "parsing", "in", "both", "languages."], "cited_papers": [{"title": "An Algorithm for Finding Noun Phrase Correspondences in Bilingual Corpora", "year": "1993", "authors": ["J Kupiec"]}], "target_citation_location": 28, "citation_locations": [28], "citation_type": "single", "annotations": [[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "562bdaad-ce0b-4e37-89a6-42b1cdf5b3a1", "citing_paper": {"title": "Associating semantic components with intersective Levin classes", "year": 1997, "authors": ["Hoa Dang", "Joseph Rosenzweig", "Martha Palmer"]}, "text": ["Many", "of", "the", "lexical", "items", "classified", "into", "Levin's", "verb", "classes", "are", "listed", "as", "members", "of", "more", "than", "one", "semantic", "class", "[8].", "There", "are", "in", "fact", "3104", "verbs,", "but", "4194", "verb/class", "pairings,", "or", "verb", "senses,", "for", "an", "average", "of", "1.35", "senses", "per", "verb.", "Levin", "gives", "only", "a", "few", "informal", "indications", "about", "how", "to", "interpret", "a", "multiple", "listing", "for", "a", "verb.", "Sometimes", "the", "verb", "is", "listed", "in", "several", "classes", "because", "there", "is", "a", "systematic", "meaning", "relationship", "among", "them.", "Other", "times,", "the", "multiple", "categorization", "seems", "to", "be", "an", "idiosyncrasy", "involving", "two", "verbs", "that", "happen", "to", "have", "the", "same", "spelling,", "i.e.,", "homonyms.", "For", "example,", "the", "verb", "draw", "is", "listed", "as", "a", "remove", "verb", "(class", "10.1),", "as", "a", "scribble", "verb", "(class", "25.2)", "and", "as", "a", "performance", "verb", "(class", "26.7).", "While", "the", "latter", "two", "senses", "seem", "systematically", "related", "(both", "seem", "to", "be", "involved,", "for", "example,", "in", "a", "usage", "like", "draw", "a", "portrait)", "the", "remove", "sense", "(as", "in", "draw", "water", "from", "the", "well)", "is", "clearly", "distinct."], "cited_papers": [{"title": "English Verb Classes and Alternations", "year": "1993", "authors": ["B Levin"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "56d650b1-39f0-4190-9e3b-38a00e9d075a", "citing_paper": {"title": "Controlled Text Generation with Adversarial Learning", "year": 2020, "authors": ["Federico Betti", "Giorgia Ramponi", "Massimo Piccardi"]}, "text": ["Evaluation", "As", "evaluation", "measures,", "we", "have", "adopted", "corpus", "BLEU", "[17]", "to", "assess", "syntactic", "quality", "and", "the", "Kullback-Leibler", "(KL)", "divergence", "[12]", "between", "the", "topic", "used", "for", "conditioning", "and", "the", "topic", "extracted", "from", "the", "generated", "sentence", "to", "assess", "semantic", "coherence.", "A", "low", "KL", "value", "means", "that", "the", "distribution", "inferred", "from", "the", "output", "of", "the", "model", "is", "similar", "to", "the", "one", "extracted", "from", "the", "conditioning", "input", "sentence", "and", "used", "as", "conditioning", "vector", "c.", "This", "implies", "that", "the", "semantic", "conditioning", "has", "been", "carried", "out", "successfully."], "cited_papers": [{"title": "BLEU: a method for automatic evaluation of machine translation", "year": "2002", "authors": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu"]}], "target_citation_location": 9, "citation_locations": [9, 19], "citation_type": "single", "annotations": [[0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "576422ff-bf5e-43d7-8875-1be226be96ed", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["(3)", "Piano", "is", "a", "kind", "of", "art", "form.", "generation", "(Gupta et al., 2018).", "In", "these", "tasks,", "output", "spaces", "are", "constrained", "by", "input", "context,", "i.e.,", "the", "contents", "of", "multiple", "outputs", "should", "be", "similar,", "and", "globally,", "under", "the", "same", "topic.", "However,", "many", "NLG", "tasks,", "e.g.,", "generative", "commonsense", "reasoning,", "pose", "unique", "challenges", "for", "generating", "multiple", "reasonable", "outputs", "that", "are", "semantically", "different."], "cited_papers": [{"title": "A deep generative framework for paraphrase generation", "year": "2018", "authors": ["Ankush Gupta", "Arvind Agarwal", "Prawaan Singh", "Piyush Rai"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "576e6ebf-244e-4aef-9e88-d36961edf4a6", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["To", "disentangle", "dataset", "shift", "and", "evidence", "ambiguity", "of", "the", "data", "splitting", "strategy,", "we", "apply", "RDS", "stochastic", "choice", "reward", "mechanism", "(Nguyen et al., 2020)", "to", "create", "public", "training,", "public-and", "private", "testing", "sets.", "Figure", "3", "illustrates", "the", "learning", "dynamic", "towards", "the", "goal."], "cited_papers": [{"title": null, "year": "2020", "authors": ["unk Nguyen Van Nha"]}], "target_citation_location": 19, "citation_locations": [19], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "577d5c48-8b6e-4e10-a7d3-0c50daabc604", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Passage", "retrieval", "for", "open-domain", "QA", "For", "opendomain", "QA,", "a", "passage", "retriever", "is", "an", "important", "component", "to", "identify", "relevant", "passages", "for", "answer", "extraction.", "Traditional", "approaches", "(Chen et al., 2017)", "implemented", "term-based", "passage", "retrievers", "(e.g.", "TF-IDF", "and", "BM25),", "which", "have", "limited", "representation", "capabilities.", "Recently,", "researchers", "have", "utilized", "deep", "learning", "to", "improve", "traditional", "passage", "retrievers,", "including", "document", "expansions", "(Nogueira et al., 2019c),", "question", "expansions", "(Mao et al., 2020)", "and", "term", "weight", "estimation", "(Dai and Callan, 2019)."], "cited_papers": [{"title": "Document expansion by query prediction. CoRR, abs", "year": "1904", "authors": ["Rodrigo Nogueira", "Wei Yang", "Jimmy Lin", "Kyunghyun Cho"]}], "target_citation_location": 52, "citation_locations": [24, 52, 55, 60], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0]]}
{"id": "57da5cbf-a615-48d5-bc77-6839e555e174", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["Image-Text", "Retrieval:", "The", "image-text", "retrieval", "typically", "includes", "two", "sub-tasks:", "image-retrieval", "(IR)", "aims", "to", "retrieval", "an", "image", "when", "given", "a", "specific", "caption", "and", "text-retrieval", "(TR)", "is", "on", "the", "contrary.", "We", "perform", "experiments", "on", "both", "Flickr30k", "(Plummer et al., 2015)", "and", "MSCOCO", "dataset.", "As", "in", "UNITER,", "we", "construct", "a", "mini-batch", "for", "each", "GPU", "of", "a", "matched", "image-text", "pair,", "t-1", "negative", "images,", "and", "t-1", "negative", "texts", "where", "t", "is", "set", "as", "32.", "Besides,", "we", "take", "a", "fully-connected", "network", "on", "top", "of", "h", "cls", "and", "adopt", "the", "binary", "cross-entropy", "loss", "as", "supervision", "signal.", "The", "finetuning", "iterations", "are", "up", "to", "10K", "by", "following", "linear", "decay", "scheduling", "with", "initial", "lr", "7e-5", "for", "Transformer,", "1e-4", "for", "CNNs.", "Top-K", "(R@K,", "K", "\u2208", "{1,", "5,", "10})", "recall", "is", "the", "evaluation", "metric."], "cited_papers": [{"title": "Flickr30k entities: Collecting region-to-phrase correspondences for richer imageto-sentence models", "year": "2015", "authors": ["A Bryan", "Liwei Plummer", "Chris Wang", "Juan Cervantes", "Julia Caicedo", "Svetlana Hockenmaier", "unk Lazebnik"]}], "target_citation_location": 34, "citation_locations": [34], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "58266100-f96b-40a2-83a2-2a39cc9f720a", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["We", "further", "ascertain", "the", "findings", "of", "\u00a74.1", "via", "language", "modeling", "on", "WikiText-103", "(Merity et al., 2017)", "using", "a", "6-layer", "Transformer", "decoder", "with", "156M", "parameters.", "Using", "an", "input", "length", "of", "1024,", "we", "trained", "two", "models", "with", "vanilla", "and", "top-64", "attentions", "at", "the", "self-attention", "layers,", "obtaining", "test", "perplexity", "scores", "of", "30.96", "and", "30.51", "respectively,", "slightly", "better", "in", "case", "of", "top-64", "(details", "in", "\u00a7A.3)."], "cited_papers": [{"title": "Pointer sentinel mixture models", "year": "2017", "authors": ["Stephen Merity", "Caiming Xiong", "James Bradbury", "Richard Socher"]}], "target_citation_location": 12, "citation_locations": [12], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5827aba0-9772-4ef9-9f8b-59afbab29782", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Users.", "Besides", "being", "a", "mechanism", "for", "designers", "to", "interpret", "their", "methods,", "an", "effective", "operationalization", "of", "explainability", "should", "also", "serve", "as", "a", "means", "for", "users", "to", "receive", "explanations", "for", "the", "decisions", "made", "by", "a", "detection", "method.", "Jurgens et al. (2019)", "argue", "in", "their", "work", "that", "an", "online", "platform", "can", "build", "legitimacy", "and", "transparency", "by", "offering", "justifications", "to", "users", "when", "their", "comments", "are", "deemed", "abusive", "by", "the", "detection", "method", "of", "the", "platform,", "which", "can", "in", "turn", "lead", "to", "increase", "in", "compliance", "with", "the", "norms", "of", "the", "platform.", "That", "said,", "unlike", "in", "the", "case", "of", "designers", "of", "the", "method,", "offering", "feature", "attribution", "based", "explanations", "that", "simply", "highlight", "parts", "of", "a", "user's", "comment", "may", "not", "be", "effective", "at", "making", "the", "user", "agree", "with", "the", "decision", "of", "the", "detection", "method", "(Carton et al., 2020).", "Alternatively,", "providing", "a", "meaningful", "counterfactual", "paraphrase", "that", "is", "non-abusive", "is", "not", "only", "difficult", "(Laugel et al., 2019),", "but", "can", "also", "be", "seen", "as", "paternalism", "on", "the", "part", "of", "the", "platform", "(Barocas et al., 2020),", "i.e.,", "that", "the", "platform", "is", "trying", "to", "tell", "the", "user", "what", "to", "say", "or", "how", "to", "present", "their", "opinions.", "On", "the", "other", "hand,", "principal-reason", "explanations", "(Barocas et al., 2020),", "whereby", "the", "detection", "method", "selects", "the", "reason(s)", "for", "its", "decision", "from", "a", "curated", "list,", "can", "constitute", "an", "effective", "operationalization.", "Such", "a", "list", "can", "be", "prepared", "for", "each", "of", "the", "four", "properties", "of", "explainability,", "e.g.,", "by", "selecting", "the", "relevant", "norms", "from", "the", "terms", "of", "service", "of", "the", "platform,", "hence", "allowing", "for", "a", "principal", "reason", "to", "be", "offered", "per", "property", "or", "a", "combination", "thereof.", "When", "coupled", "with", "feature", "attribution,", "this", "approach", "to", "operationalization", "can", "clearly", "indicate", "to", "the", "user", "the", "norm(s)", "that", "their", "comment", "violates", "and,", "where", "possible,", "highlight", "parts", "that", "contribute", "to", "the", "violation(s).", "For", "example,", "given", "a", "comment", "like", "\"You", "f***,", "why", "do", "you", "have", "to", "support", "that", "team??\",", "the", "detection", "method", "can", "highlight", "the", "first", "part", "based", "on", "feature", "attribution", "and", "select", "the", "norm", "forbidding", "the", "use", "of", "expletives", "directed", "at", "others."], "cited_papers": [{"title": "The hidden assumptions behind counterfactual explanations and principal reasons", "year": "2020", "authors": ["Solon Barocas", "Andrew Selbst", "Manish Raghavan"]}], "target_citation_location": 150, "citation_locations": [35, 122, 136, 150, 176], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "582cfecc-f32b-4a0c-85ff-4d73fe80ae59", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["Trace", "Embedding:", "Each", "trace", "input", "item", "t", "i", "is", "projected", "into", "ti", "\u2208", "R", "d.", "We", "also", "generate", "Sinusoidal", "Positional", "Embeddings", "(Vaswani et al., 2017)", "o", "i", "to", "capture", "the", "temporal", "order", "of", "the", "traces.", "The", "final", "trace", "embedding", "T", "=", "{t1", ",...,", "tM", "},", "where", "ti", "=", "ti", "+", "o", "i."], "cited_papers": [{"title": "Attention is all you need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 21, "citation_locations": [21], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5861fdec-fd65-4b53-8a8d-9a596cf056c3", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["The", "exploitation", "of", "pre-trained", "models", "followed", "by", "task-specific", "fine-tuning", "haved", "pushed", "the", "state-ofthe-art", "forwards,", "while", "requiring", "much", "less", "computational", "and", "data", "resources.", "The", "idea", "behind", "pre-training", "is", "to", "reuse", "the", "weights", "parameters", "trained", "on", "a", "set", "of", "source", "tasks", "and", "continue", "to", "fine-tune", "them", "on", "under-resourced", "target", "tasks", "to", "achieve", "knowledge", "transfer.", "Dai", "and", "Le (2015)", "were", "the", "first", "to", "propose", "to", "pre-train", "RNNs", "using", "auto-encoders", "and", "language", "models", "as", "part", "of", "their", "QA", "encoding", "layer.", "Min et al. (2017)", "and", "Wiese et al. (2017)", "pre-trained", "QA", "models", "before", "applying", "the", "fine-tuning", "process", "between", "the", "source", "and", "the", "target", "domains.", "Other", "efforts", "focused", "on", "pretraining", "Transformer-based", "models", "multilingually", "such", "as", "the", "multilingual", "version", "of", "BERT", "(called", "mBERT)", "(Devlin et al., 2019)", "or", "XLM-R", "(Conneau et al., 2020)", "to", "learn", "cross-lingual", "representations", "which", "are", "transferable", "across", "languages."], "cited_papers": [{"title": "Neural domain adaptation for biomedical question answering", "year": "2017", "authors": ["Georg Wiese", "Dirk Weissenborn", "Mariana Neves"]}], "target_citation_location": 77, "citation_locations": [54, 75, 77, 110, 113], "citation_type": "single", "annotations": [[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "589f51be-7f4d-40e8-b266-cf7369826158", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["DMSNAP", "is", "capable", "of", "resolving", "this", "lexical", "ambiguity", "through", "use", "of", "contextual", "priming", "using", "the", "contextual", "marker", "(C-Marker)", "[Tomabechi, 1987]", "and", "the", "cost-based", "disambiguation", "[Kitano et al., 1989].", "Sentence", "s3", "contains", "a", "word", "sense", "ambiguity", "in", "the", "interpretation", "of", "the", "word", "'paper''", "as", "either", "a", "technical", "document", "or", "a", "sheet", "of", "paper.", "Upon", "reading", "'paper',", "C-THESIS", "and", "C-PAPER", "are", "activated.", "At", "this", "time,", "C-THESIS", "has", "a", "C-MARKER.", "The", "C-MARKER", "comes", "from", "activation", "of", "C-IJCAI-91", "and", "C-CONFERENCE,", "in", "previous", "sentences,", "which", "has", "contextual", "links", "connecting", "concepts", "relevant", "to", "academic", "conference", "such", "as", "C-THESIS.", "The", "meaning", "hypothesis", "containing", "C-THESIS", "costs", "less", "than", "the", "one", "with", "C-PAPER", "so", "that", "it", "is", "selected", "as", "the", "best", "hypothesis."], "cited_papers": [{"title": "Experiments and Prospects of Example-Based Machine Translation", "year": "1986", "authors": ["C Stanfill", "D Waltz", "E Sumita", "H Iida", "H Tomabechi", "R Wilensky"]}], "target_citation_location": 18, "citation_locations": [18, 23], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "58ce26ae-4270-4dad-8d7a-55e96e02daeb", "citing_paper": {"title": "NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques", "year": 2021, "authors": ["Gunjan Chhablani", "Abheesht Sharma", "Harshit Pandey", "Yash Bhartia", "Shan Suthaharan"]}, "text": ["Offensive", "language", "can", "include", "various", "categories", "such", "as", "threats,", "vilification,", "insults,", "calumniation,", "discrimination", "and", "swearing", "(Pavlopoulos et al., 2019).", "Detection", "of", "such", "language", "is", "necessary", "for", "ease", "of", "moderation", "of", "content", "on", "social", "media.", "Despite", "their", "popularity,", "toxicity", "detection", "tasks", "have", "focused", "majorly", "on", "sequence", "classification,", "rather", "than", "sequence", "tagging.", "Finding", "which", "spans", "make", "a", "comment", "or", "document", "toxic", "in", "nature", "is", "crucial", "in", "explaining", "the", "reasons", "behind", "their", "toxicity.", "Additionally,", "such", "attributions", "would", "allow", "for", "more", "efficient", "semi-automated", "quality-based", "moderation", "of", "content,", "especially", "for", "verbose", "documents,", "in", "comparison", "to", "quantitative", "toxicity", "scores."], "cited_papers": [{"title": "ConvAI at SemEval-2019 task 6: Offensive language identification and categorization with perspective and BERT", "year": "2019", "authors": ["John Pavlopoulos", "Nithum Thain", "Lucas Dixon", "Ion Androutsopoulos"]}], "target_citation_location": 15, "citation_locations": [15], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "59071786-a536-4f1d-9a18-505c0389ca20", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Pairwise", "diversity", "(\u21d3).", "Referred", "as", "\"self-\"", "(e.g.,", "self-BLEU)", "(Zhu et al., 2018),", "it", "measures", "the", "within-distribution", "similarity.", "This", "metric", "computes", "the", "average", "of", "sentence-level", "metrics", "between", "all", "pairwise", "combinations", "of", "hypotheses", "{Y", "(1),", "\u2022,", "Y", "(K)}", "generated", "from", "each", "source", "sequence", "X.", "Lower", "pairwise", "metric", "indicates", "high", "diversity", "between", "generated", "hypotheses."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "592d349b-96c1-4453-b563-d86e3284b01e", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["After", "the", "selection", "of", "documents", "for", "analysis,", "a", "list", "of", "keywords", "was", "prepared", "independently", "by", "the", "authors", "and", "then", "compiled.", "As", "traditionally", "held,", "an", "apology", "consists", "of", "five", "major", "parts", "(Cohen et al, 1981).", "These", "are", "the", "following:"], "cited_papers": [{"title": "Developing a measure of sociocultural competence: The case of apology", "year": "1981", "authors": ["A Cohen", "E Olshtain"]}], "target_citation_location": 30, "citation_locations": [30], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3]]}
{"id": "597e6134-ad19-48d2-9d76-46626ca4ec89", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["More", "recently,", "neural", "networks-based", "strategies", "and", "transformer-based", "architectures", "has", "been", "applied", "to", "hate", "speech", "detection", "due", "to", "the", "good", "results", "achieved", "in", "various", "tasks.", "Banerjee et al. (2020)", "2021)", "compared", "two", "pre-trained", "language", "models,", "such", "as", "BERT", "(Devlin et al., 2019)", "and", "XLM", "(CONNEAU", "and", "Lample,", "2019)", "trained", "to", "detect", "hate", "speech", "in", "the", "Spanish", "language."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 34, "citation_locations": [24, 34], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5980b50b-078f-4b7c-bd79-3c6e38536579", "citing_paper": {"title": "Effects of Word Alignment Visualization on Post-Editing Quality & Speed \u2020", "year": 2015, "authors": ["Lane Schwartz", "Isabel Lacruz", "Tatyana Bystrova"]}, "text": ["The", "mean", "adequacy", "score", "when", "bilingual", "participants", "were", "presented", "with", "alignments", "was", "8.35.", "When", "alignments", "were", "omitted", "from", "the", "post-editing", "tool,", "the", "mean", "adequacy", "score", "was", "7.85.", "A", "Wilcoxon", "signed-rank", "test", "(Wilcoxon, 1945)", "showed", "that", "when", "participants", "were", "presented", "with", "alignments", "the", "ratings", "of", "their", "translations", "were", "significantly", "higher", "than", "when", "participants", "post-edited", "without", "access", "to", "alignments", "(N", "=", "6,", "Z", "=", "-2.207,", "p", "=", "0.027)."], "cited_papers": [{"title": "Individual comparisons by ranking methods", "year": "1945", "authors": ["F Wilcoxon"]}], "target_citation_location": 31, "citation_locations": [31], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "59cf3d45-bcf2-4326-bd64-878e68f7e380", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["First,", "there", "is", "no", "agreed-upon", "definition", "of", "bridging", "(Roesiger et al., 2018b).", "Consequently,", "manual", "annotation", "of", "bridging", "relations,", "and", "the", "use", "of", "these", "annotations,", "requires", "substantial", "expertise", "and", "effort.", "In", "contrast,", "NP", "Enrichment", "is", "compactly", "defined,", "and", "is", "amenable", "to", "large-scale", "annotation", "after", "only", "a", "brief", "annotator", "training."], "cited_papers": [{"title": "Bridging resolution: Task definition, corpus resources and rule-based experiments", "year": "2018", "authors": ["Ina Roesiger", "Arndt Riester", "Jonas Kuhn"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "59f0a195-d9a8-435e-8097-5b2362c76c0e", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["The", "aforementioned", "correlations,", "however,", "are", "byproducts", "rather", "than", "core", "mechanisms", "of", "argumentative", "relations.", "In", "order", "to", "decide", "whether", "a", "statement", "supports", "or", "attacks", "another,", "we", "cannot", "ignore", "the", "logical", "relation", "between", "them.", "Textual", "entailment", "was", "found", "to", "inform", "argumentative", "relations", "(Choi and Lee, 2018)", "and", "used", "to", "detect", "arguments", "(Cabrio and Villata, 2012).", "Similarly,", "there", "is", "evidence", "that", "the", "opinions", "of", "two", "statements", "toward", "the", "same", "concept", "constitute", "their", "argumentative", "relations", "(Gemechu and Reed, 2019, Kobbe et al., 2020).", "Causality", "between", "events", "also", "received", "attention,", "and", "causality", "graph", "construction", "was", "proposed", "for", "argument", "analysis", "(Al-Khatib et al., 2020).", "Additionally,", "in", "argumentation", "theory,", "Walton's", "argumentation", "schemes", "(Walton et al., 2008)", "specify", "common", "reasoning", "patterns", "people", "use", "to", "form", "an", "argument.", "This", "motivates", "our", "work", "to", "investigate", "logical", "mechanisms", "in", "four", "categories:", "factual", "consistency,", "sentiment", "coherence,", "causal", "relation,", "and", "normative", "relation."], "cited_papers": [{"title": "Combining textual entailment and argumentation theory for supporting online debates interactions", "year": "2012", "authors": ["Elena Cabrio", "Serena Villata"]}], "target_citation_location": 46, "citation_locations": [40, 46, 65, 81, 89], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5a083832-f59f-4c4d-92a3-f79db6e5cbc7", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["The", "approach", "to", "text", "grammar", "taken", "here", "is", "in", "many", "ways", "similar", "to", "that", "of", "Jones (1994).", "However,", "he", "opts", "to", "treat", "punctuation", "marks", "as", "clitics", "on", "words", "which", "introduce", "additional", "featural", "information", "into", "standard", "syntactic", "rules.", "Thus,", "his", "grammar", "is", "thoroughly", "integrated", "and", "it", "would", "be", "harder", "to", "extract", "an", "independent", "text", "grammar", "or", "build", "a", "modular", "semantics.", "The", "coverage", "of", "the", "integrated", "version", "of", "the", "text", "grammar", "is", "described", "in", "more", "detail", "in", "Briscoe &amp, Carroll ( 1994).", "(Elworthy, 1993 (Elworthy, , 1994) )", "trained", "on", "text", "tagged", "with", "a", "slightly", "modified", "version", "of", "CLAWS-II", "labels", "(Garside et al. , 1987).", "Carroll (1994)", "that", "in", "practice", "NL", "grammars", "do", "not", "evince", "worst-case", "parsing", "complexity."], "cited_papers": [{"title": "Can punctuation help parsing", "year": "1994", "authors": ["B Jones"]}], "target_citation_location": 15, "citation_locations": [15, 74, 75, 88, 89], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5a737225-0c0b-44ba-b36a-d35ab91a1cd8", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["A2C", "Training.", "Each", "parallel", "A2C", "agent", "samples", "from", "the", "the", "current", "pool", "of", "available", "questsi.e.", "the", "curriculum-for", "a", "fixed", "number", "of", "steps", "k", "before", "switching", "to", "the", "quest", "pool", "corresponding", "to", "the", "next", "higher", "level", "difficulty", "curriculum.", "The", "initial", "pool", "of", "quests", "is", "the", "training", "set", "of", "LIGHT-Quests", "as", "seen", "in", "Ammanabrolu et al. (2021)", "and", "all", "pools", "after", "that", "correspond", "to", "decreasing", "values", "of", "n", "used", "when", "generating", "the", "curriculums", "(as", "seen", "in", "Figure", "6)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 51, "citation_locations": [51], "citation_type": "single", "annotations": [[3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "5aa08b2f-9742-44f6-a66b-3e6b52e03626", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["We", "then", "use", "the", "highway", "network", "(Srivastava et al., 2015)", "on", "the", "combined", "hidden", "state", "vector", "h.", "This", "network", "adaptively", "\"carries\"", "some", "dimensions", "of", "h", "to", "the", "output", "for", "predicting", "the", "correct", "label", "sequence.", "Therefore,", "the", "hidden", "states", "undergo", "the", "following", "transformation", "(Wen et al., 2016)", ":h", "i", "=", "\u03c1(h", "i)", "g(W", "H", "hi", "+b", "H", ")+(1\u2212\u03c1(h))", "hi", "(9)The", "function", "\u03c1(h", "w)", "=", "\u03c3(W", "\u03c1", "h", "i", "+", "b", "\u03c1", "),", "which", "is", "a", "simple", "activation", "function.", "g", "is", "any", "non-linear", "function,", "such", "as", "sigmoid", "or", "hyperbolic", "tangent.", "Following", "the", "highway", "network's", "output,", "we", "pass", "the", "hidden", "embeddings", "to", "a", "dropout", "layer,", "which", "effectively", "reduces", "the", "number", "of", "hidden", "units", "by", "a", "fraction", "d,", "so", "h", "drop", "\u2208", "R", "k/d\u00d7l,", "and", "a", "linear", "layer,", "which", "maps", "the", "h", "drop", "to", "a", "smaller", "embedding", "space.", "We", "label", "this", "space", "h", "\u2208", "R", "k/d\u00d7f", "(f", "being", "the", "dimensions", "of", "the", "feature", "space)", "for", "brevity."], "cited_papers": [{"title": "Learning text representation using recurrent convolutional neural network with highway layers", "year": "2016", "authors": ["Y Wen", "unk Luo", "unk Wang"]}], "target_citation_location": 39, "citation_locations": [6, 39], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5abf367a-a41a-4fbd-a432-78ec74fbed1a", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["Memory-based", "MT", "is", "an", "idea", "of", "viewing", "MT", "as", "a", "memory", "activity.", "For", "example,", "parsing", "is", "considered", "as", "a", "memory-search", "process", "which", "identifies", "similar", "cases", "in", "the", "past", "from", "the", "memory,", "and", "to", "provide", "interpretation", "based", "on", "the", "identified", "case.", "It", "can", "be", "considered", "as", "an", "application", "of", "Memory-Based", "Reasoning", "(MBR)", "[Stanfill and Waltz, 1986]", "and", "Case-Based", "Reasoning", "(CBR)", "[Riesbeck and Schank, 1989]", "to", "NLP.", "This", "view,", "however,", "counters", "to", "traditional", "idea", "to", "view", "NLP", "as", "an", "extensive", "rule", "application", "process", "to", "build", "up", "meaning", "representation.", "Some", "models", "has", "been", "proposed", "in", "this", "direction,", "such", "as", "Direct", "Memory", "Access", "Parsing", "(DMAP)", "[Riesbeck and Martin, 1985]", "and", "\u03a6DMDIALOG", "[Kitano, 1990a].", "Independently,", "the", "idea", "of", "using", "examples", "for", "translation", "has", "been", "proposed", "by", "[Nagao, 1984],", "and", "some", "experimental", "results", "has", "been", "reported", "recently", "[Sato and Nagao, 1990] [Sumita and Iida, 1991]", "and", "[Furuse et al., 1990].", "Recently,", "such", "an", "approach", "is", "gaining", "increasing", "attention", "due", "to", "the", "problems", "in", "the", "traditional", "machine", "translation", "approach:"], "cited_papers": [{"title": "A Framework of a Mechanical Trans lation between Japanese and English by Analogy Principle", "year": "1968", "authors": ["C Moldovan ", " Lin", "D Moldovan", "\" Snap: Simulator Results ", " Moldovan", "D Lee", "W Lin", "C Nagao", "M Pollard", "C Sag", "I Quillian", "M Riesbeck", "C Martin", "C Riesbeck", "C Schank", "R Sato", "S Nagao", "M unk"]}], "target_citation_location": 56, "citation_locations": [51, 56, 95, 98, 111, 120, 122], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5ad3a996-b937-4fc3-822f-ecfedb29b0c5", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["Joint:", "we", "concatenate", "the", "training", "examples", "from", "Quoref", "and", "CoNLL-to-QA", "converted", "11", "The", "only", "difference", "of", "TASE", "in", "our", "experiments", "and", "the", "reported", "results", "in", "Segal et al. (2020)", "is", "the", "number", "of", "training", "epochs.", "For", "a", "fair", "comparison,", "we", "train", "all", "models", "for", "the", "same", "number", "of", "iterations."], "cited_papers": [{"title": "A simple and effective model for answering multi-span questions", "year": "2020", "authors": ["Elad Segal", "Avia Efrat", "Mor Shoham", "Amir Globerson", "Jonathan Berant"]}], "target_citation_location": 25, "citation_locations": [25], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5ae1ad2e-846b-46bc-b3c8-922d349d96a6", "citing_paper": {"title": "drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM", "year": 2022, "authors": ["Dylan Phelps"]}, "text": ["To", "achieve", "this", "goal,", "we", "investigate", "whether", "due", "to", "the", "similarity", "between", "idioms", "and", "rare-words", "Schick", "and", "Sch\u00fctze's", "BERT", "for", "Attentive", "Mimicking", "(Schick and Sch\u00fctze, 2020)", "(BERTRAM)", "model,", "which", "was", "designed", "for", "use", "with", "rare-words,", "can", "be", "used", "to", "explicitly", "learn", "high-quality", "embeddings", "for", "idiomatic", "expressions.", "We", "also", "investigate", "how", "many", "examples", "of", "each", "idiom", "are", "required", "to", "create", "embeddings", "that", "perform", "well", "on", "the", "task,", "as", "well", "as", "how", "the", "quality", "of", "contexts", "fed", "to", "the", "BERTRAM", "model", "effects", "the", "representations", "and", "performance", "on", "the", "task."], "cited_papers": [{"title": "BERTRAM: Improved word embeddings have big impact on contextualized model performance", "year": "2020", "authors": ["Timo Schick", "Hinrich Sch\u00fctze"]}], "target_citation_location": 22, "citation_locations": [22], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5b03fcd7-8228-400f-b973-14450efc9a70", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["In", "this", "paper", "we", "describe", "the", "machine", "translation", "systems", "built", "for", "our", "participation", "in", "IWSLT", "2011", "evaluation", "campaign", "[1]", "for", "the", "Arabic-English", "(Ar-En)", "and", "Chinese-English", "(Zh-En)", "MT", "track", "translation", "tasks.", "We", "use", "different", "SMT", "models,", "ranging", "from", "standard", "phrase-based", "SMT", "models", "[2]", "to", "CCG-augmented", "hierarchical", "phrasebased", "models", "[3]", "to", "translate", "the", "test", "data", "provided.", "The", "open-domain", "nature", "of", "the", "data", "and", "the", "restricted", "size", "of", "the", "in-domain", "training", "corpora", "necessitated", "the", "use", "of", "domain", "adaptation", "techniques", "to", "improve", "translation", "quality."], "cited_papers": [{"title": "Overview of the iwslt 2011 evaluation campaign", "year": "2011", "authors": ["M Federico", "L Bentivogli", "M Paul", "S Stueker"]}], "target_citation_location": 18, "citation_locations": [18, 41, 47], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5b051aca-8dab-4531-91ca-a714c82fe22c", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["Before", "presenting", "the", "proposed", "action", "learning", "approach,", "we", "first", "briefly", "introduce", "dialogue", "state", "tracking", "tasks.", "For", "dialogues{(c", "t,", "x", "t", ")|1", "\u2264", "t", "\u2264", "n", "d", "},", "let", "{b", "t", "|1", "\u2264", "t", "\u2264", "n", "d", "}be", "the", "dialogue", "state", "for", "each", "turn,", "where", "b", "t", "\u2208", "{0,", "1}", "N", "b", "and", "N", "b", "is", "the", "number", "of", "all", "slot-value", "pairs.", "Dialogue", "state", "tracking", "is", "usually", "formulated", "as", "a", "multilabel", "learning", "problem", "where", "the", "state", "at", "turn", "t", "predicted", "by", "modeling", "the", "conditional", "distribution", "p(bt", "|c", "t)", "=", "p(b", "t", "|u", "t,", "x", "t\u22121,", "b", "t\u22121", "),", "where", "b", "t\u22121", "is", "the", "dialogue", "state", "in", "the", "previous", "turn.", "To", "model", "this", "conditional", "distribution,", "a", "state", "tracking", "model", "p", "B", "(u", "t,", "x", "t\u22121,", "b", "t\u22121)", "mainly", "employs", "an", "utterance", "en-coder,", "a", "context", "encoder", "to", "work", "with", "a", "slot-value", "predictor", "that", "estimates", "whether", "a", "slot-value", "pair", "should", "be", "included", "in", "the", "dialogue", "states", "(Lee et al., 2019).", "Specifically,", "the", "predictor", "takes", "as", "input", "a", "slot-value", "pair", "(s", "i,", "e", "i", "),", "and", "the", "encoded", "utterances", "h", "utt", "\u2208", "R", "D", "and", "context", "h", "ctx", "\u2208", "R", "D", "from", "the", "utterance", "encoder", "f", "utt", "(u", "t,", "x", "t\u22121)", "and", "context", "encoder", "f", "ctx", "(b", "t\u22121)", "respectively,", "and", "D", "is", "the", "hidden", "dimension.", "The", "prediction", "is", "then", "performed", "by", "aggregating", "the", "results", "of", "slot-value", "predictor", "f", "val", "(h", "utt,", "h", "ctx,", "(s", "i,", "e", "i", "))", "for", "the", "complete", "N", "b", "slotvalue", "pairs.", "We", "optimize", "the", "state", "tracking", "model", "using", "the", "cross-entropy", "loss:L", "=", "d", "i", "t=1:n", "d", "\u2212", "log(b", "t", "\u2022p", "B", "(u", "t,", "x", "t\u22121,", "c", "t\u22121", "))", "(4)where", "the", "parameters", "of", "p", "B,", "which", "include", "f", "utt,", "f", "ctx,", "and", "f", "val,", "are", "jointly", "trained."], "cited_papers": [{"title": "SUMBT: Slot-utterance matching for universal and scalable belief tracking", "year": "2019", "authors": ["Hwaran Lee", "Jinsik Lee", "Tae-Yoon Kim"]}], "target_citation_location": 152, "citation_locations": [152], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5b956b77-7cd7-4fdd-8e2d-fc6810a27231", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["To", "conclude,", "we", "argue", "that", "despite", "the", "ambiguities", "of", "prepositions,", "they", "allow", "us", "to", "obtain", "a", "meaningful", "set", "of", "typed", "semantic", "links", "between", "NPs,", "which", "are", "well", "understood", "by", "people", "and", "can", "be", "effectively", "processed", "by", "NLP", "models.", "While", "the", "annotation", "can", "be", "refined", "to", "include", "a", "fine-grained", "sense", "annotation", "for", "each", "link,", "for", "example,", "via", "a", "scheme", "as", "that", "of", "Schneider et al. (2018),", "we", "leave", "such", "an", "extension", "to", "future", "work."], "cited_papers": [{"title": "Comprehensive supersense disambiguation of English prepositions and possessives", "year": "2018", "authors": ["Nathan Schneider", "Jena Hwang", "Vivek Srikumar", "Jakob Prange", "Austin Blodgett", "Sarah Moeller", "Aviram Stern", "Adi Shalev", "Omri Abend"]}], "target_citation_location": 61, "citation_locations": [61], "citation_type": "single", "annotations": [[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "5bba977e-de97-4bec-946d-013bd4883f02", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["Data", "augmentation", "Data", "augmentation", "is", "the", "technique", "used", "to", "increase", "the", "amount", "of", "data", "by", "adding", "slightly", "modified", "copies", "of", "already", "existing", "data", "or", "newly", "created", "synthetic", "data", "from", "existing", "data.", "It", "acts", "as", "a", "regularizer", "and", "helps", "reduce", "overfitting", "when", "training", "a", "machine", "learning", "model.", "In", "this", "paper,", "data", "augmentation", "consists", "of", "two", "parts.", "We", "first", "add", "the", "dataset", "released", "by", "CWI", "2018", "into", "the", "training", "set.", "Besides,", "for", "subtask", "2,", "since", "its", "training", "dataset", "is", "small", "which", "only", "contains", "one", "thousand", "samples,", "we", "add", "the", "dataset", "of", "subtask", "1", "to", "train", "the", "model", "for", "subtask", "2.", "Then,", "for", "a", "given", "sentence", "in", "the", "training", "set,", "we", "perform", "the", "operations", "containing", "synonym", "replacement,", "random", "insertion,", "random", "swap,", "and", "random", "deletion", "introduced", "by", "Wei and Zou (2019)."], "cited_papers": [{"title": "Eda: Easy data augmentation techniques for boosting performance on text classification tasks", "year": "2019", "authors": ["Jason Wei", "Kai Zou"]}], "target_citation_location": 123, "citation_locations": [123], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "5be90da0-c7e0-4e70-a30d-58b3f31ed065", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["Generative", "language", "models", "are", "getting", "bigger:", "from", "ELMo's", "release", "in", "2018", "with", "94M", "parameters", "(Joshi et al., 2018)", "to", "Megatron-Turing", "NLG", "in", "2022", "with", "530Bn", "(Smith et al., 2022),", "there", "has", "been", "approximately", "a", "tenfold", "annual", "increase", "in", "parameters.", "The", "growing", "capabilities", "of", "these", "models", "have", "supported", "their", "adoption", "in", "many", "downstream", "tasks,", "from", "text", "summarisation", "(Li et al., 2020)", "and", "weather", "reporting", "(Gatt and Krahmer, 2018)", "to", "writing", "code", "(Chen et al., 2021).", "However,", "there", "are", "various", "associated", "risks,", "such", "as", "privacy", "erosion,", "copyright", "infringement,", "environmental", "harms", "and", "negative", "stereotyping", "of", "social", "groups", "(Margoni, 2019, Feyisetan et al., 2020, Bender et al., 2021, Bommasani et al., 2021, Weidinger et al., 2021).", "We", "focus", "on", "the", "latter", "of", "these", "risks,", "specifically", "the", "problem", "of", "gender", "bias", "with", "respect", "to", "occupation.", "*", "Equal", "contribution."], "cited_papers": [{"title": "Teaching natural language processing through big data text summarization with problem-based learning", "year": "2020", "authors": ["Liuqing Li", "Jack Geissinger", "William Ingram", "Edward Fox"]}], "target_citation_location": 50, "citation_locations": [14, 22, 50, 54, 58, 79], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5bf82317-b6ac-44db-b2c7-883ba93b90ec", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["Coreference", "We", "follow", "Cattan et al. (2021)", "and", "evaluate", "the", "coreference", "agreement", "scores", "after", "filtering", "singleton", "clusters.", "We", "report", "the", "standard", "CoNLL-2012", "score", "(Pradhan et al., 2012)", "that", "combines", "three", "coreference", "metric", "scores.", "The", "in-domain", "test", "score", "13", "is", "82.1,", "while", "in", "the", "OOD", "the", "score", "is", "77.1.", "For", "comparison", "with", "the", "most", "dominant", "coreference", "dataset,", "OntoNotes", "(Weischedel et al., 2013),", "which", "only", "reported", "the", "MUC", "agreement", "score", "(Grishman and Sundheim, 1996),", "we", "also", "measure", "the", "MUC", "score", "on", "our", "dataset.", "The", "MUC", "score", "on", "our", "dataset", "is", "83.6,", "compared", "to", "78.4-89.4", "in", "OntoNotes,", "depending", "on", "the", "domain", "(Pradhan et al., 2012).", "It", "is", "worth", "noting", "that", "on", "the", "Newswire", "domain", "of", "Onto-Notes", "(Weischedel et al., 2013)", "(the", "domain", "that", "is", "most", "similar", "to", "ours)", "the", "score", "is", "80.9,", "which", "indicates", "a", "high", "quality", "of", "annotation", "in", "our", "corpus.", "We", "expect", "the", "quality", "of", "our", "final", "coreference", "data", "to", "be", "even", "higher", "due", "to", "the", "consolidation", "step", "that", "was", "done", "by", "an", "expert", "on", "the", "test", "set", "and", "OOD", "splits."], "cited_papers": [{"title": "Realistic evaluation principles for cross-document coreference resolution", "year": "2021", "authors": ["Arie Cattan", "Alon Eirew", "Gabriel Stanovsky", "Mandar Joshi", "Ido Dagan"]}], "target_citation_location": 3, "citation_locations": [3, 20, 51, 59, 86, 98], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5c7cba84-7b32-4776-b1dc-093c51d4275f", "citing_paper": {"title": "NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques", "year": 2021, "authors": ["Gunjan Chhablani", "Abheesht Sharma", "Harshit Pandey", "Yash Bhartia", "Shan Suthaharan"]}, "text": ["A", "recently", "popular", "approach", "in", "Named-Entity", "Recognition", "tasks", "has", "been", "to", "use", "Conditional", "Random", "Fields", "(CRF)", "with", "BERT-based", "models.", "Inspired", "by", "the", "CRF-based", "approaches", "(Souza et al., 2019, Jurkiewicz et al., 2020),", "we", "use", "BERT-based", "models", "with", "a", "single", "BiLSTM", "layer", "and", "a", "CRF", "layer.", "During", "training,", "the", "CRF", "loss", "is", "used", "and", "during", "prediction,", "Viterbi", "Decoding", "is", "performed.", "Though", "CRF", "is", "generally", "used", "for", "word-level", "classification,", "we", "do", "not", "mask", "inner", "and", "end", "tokens", "for", "a", "word", "as", "it", "degrades", "dev", "set", "performance", "for", "our", "systems.", "Hence,", "all", "the", "tokens", "of", "a", "word", "are", "considered", "for", "classification."], "cited_papers": [{"title": "ApplicaAI at SemEval-2020 task 11: On RoBERTa-CRF, span CLS and whether self-training helps them", "year": "2020", "authors": ["Dawid Jurkiewicz", "\u0141ukasz Borchmann", "Izabela Kosmala", "Filip Grali\u0144ski"]}, {"title": "Portuguese named entity recognition using BERT-CRF. CoRR, abs", "year": "1909", "authors": ["F\u00e1bio Souza", "Rodrigo Nogueira", "Roberto De", "Alencar Lotufo"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5c96703e-96bd-434e-b7d6-b73130464d24", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["Research", "shows", "that", "affect", "categories", "are", "quite", "universal", "(Cowen et al., 2019, Scherer and Wallbott, 1994).", "Therefore,", "theoretically", "they", "should", "also", "to", "a", "large", "degree", "retain", "emotion", "categories", "when", "translated.", "Annotation", "projection", "has", "been", "shown", "to", "offer", "reliable", "results", "in", "different", "NLP", "and", "NLU", "tasks", "(Kajava et al., 2020, Yarowsky et al., 2001, Agi\u0107 et al., 2016, Rasooli and Tetreault, 2015).", "Projection", "is", "sometimes", "the", "only", "feasible", "way", "to", "produce", "resources", "for", "under-resourced", "languages.", "By", "taking", "datasets", "created", "for", "high-resource", "languages", "and", "projecting", "these", "results", "on", "the", "corresponding", "items", "in", "the", "underresourced", "language", "using", "parallel", "corpora,", "we", "can", "create", "datasets", "in", "as", "many", "languages", "as", "exist", "in", "the", "parallel", "corpus.", "A", "parallel", "corpus", "for", "multiple", "languages", "enables", "the", "simultaneous", "creation", "of", "resources", "for", "multiple", "languages", "at", "a", "low", "cost."], "cited_papers": [{"title": "Inducing multilingual text analysis tools via robust projection across aligned corpora", "year": "2001", "authors": ["David Yarowsky", "Grace Ngai", "Richard Wicentowski"]}, {"title": "Multilingual projection for parsing truly low-resource languages", "year": "2016", "authors": ["\u017deljko Agi\u0107", "Anders Johannsen", "Barbara Plank", "Natalie H\u00e9ctor Mart\u00ednez Alonso", "Anders Schluter", "unk S\u00f8gaard"]}, {"title": "Yara parser: A fast and accurate dependency parser", "year": "2015", "authors": ["Mohammad Sadegh Rasooli", "Joel Tetreault"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 38, "citation_locations": [8, 38], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5d07bd0a-8cec-418b-aa1a-bdb87eabd542", "citing_paper": {"title": "Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets", "year": 2021, "authors": ["George-Andrei Dima", "Dumitru-Clementin Cercel", "Mihai Dascalu"]}, "text": ["Class", "Weights:", "The", "class", "unbalance", "problem", "from", "subtask", "1a", "is", "addressed", "using", "the", "weighted", "version", "of", "the", "cross-entropy", "loss.", "The", "weights", "of", "the", "two", "classes", "were", "computed", "using", "the", "balanced", "heuristic", "(King and Zeng, 2001)", "from", "the", "scikitlearn", "library", "(Pedregosa et al., 2011)."], "cited_papers": [{"title": "Logistic regression in rare events data", "year": "2001", "authors": ["Gary King", "Langche Zeng"]}], "target_citation_location": 31, "citation_locations": [31, 36], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3]]}
{"id": "5d2e1885-fe31-4447-ba81-4146feddcd7a", "citing_paper": {"title": "Associating semantic components with intersective Levin classes", "year": 1997, "authors": ["Hoa Dang", "Joseph Rosenzweig", "Martha Palmer"]}, "text": ["With", "the", "recent", "lexico-structural", "approach", "to", "transfer", "lexicons,", "[10, 11, 1],", "these", "approaches", "are", "no", "longer", "as", "distinct", "as", "traditionally", "viewed,", "and", "are", "not", "necessarily", "antithetical,", "in", "that", "they", "are", "both", "concerned", "with", "cross-linguistic", "semantic", "components.", "The", "lexico-structural", "approach", "gains", "efficiency", "by", "recognizing", "that", "structural", "correspondences", "hold", "for", "entire", "classes", "of", "lexical", "items.", "For", "example,", "a", "classic", "problem", "is", "the", "translation", "of", "motion", "verbs", "from", "English", "to", "French.", "In", "English", "the", "manner", "of", "motion", "can", "be", "incorporated", "into", "the", "matrix", "verb,", "with", "the", "direction", "of", "the", "motion", "being", "adjoined", "on", "by", "a", "prepositional", "phrase,", "as", "in", "John", "swam", "across", "the", "lake.", "In", "many", "cases,", "this", "is", "not", "allowed", "in", "French,", "where", "the", "direction", "becomes", "incorporated", "into", "the", "matrix", "verb,", "and", "the", "manner", "is", "adjoined", "on", "as", "an", "adverbial", "or", "a", "prepositional", "phrase,", "as", "in", "Jean", "a", "travers\u00e9", "le", "lac", "\u00e0", "la", "nage,", "(Jean", "crosses", "the", "lake", "by", "swimming).", "This", "type", "of", "structural", "correspondence", "has", "been", "typically", "handled", "best", "by", "interlingua", "approaches,", "since", "traditional", "transfer", "approaches", "required", "that", "every", "possible", "combination", "of", "manner", "of", "motion", "verb", "and", "path", "prepositional", "phrase", "be", "listed", "explicitly,", "and", "paired", "with", "its", "target", "language", "equivalent.", "The", "lexico-structural", "approach", "allows", "the", "entire", "class", "of", "English", "manner", "of", "motion", "verbs", "that", "have", "adjoined", "path", "prepositional", "phrases,", "to", "be", "associated", "in", "a", "single", "transfer", "lexicon", "entry", "with", "the", "class", "of", "French", "directed", "motion", "verbs", "with", "adjoined", "manners", "of", "motion.", "This", "is", "effected", "by", "treating", "manner", "of", "motion,", "path", "and", "directed", "motion", "as", "cross-linguistic", "semantic", "features", "that", "occur", "in", "both", "languages,", "and", "serve", "to", "anchor", "the", "correspondences", "[11].", "These", "are", "the", "same", "basic", "components", "that", "Jackendoff", "ascribes", "to", "change-of-location", "verbs", "in", "his", "Lexical", "Conceptual", "Structures", "(LCS),", "GO,", "PATH", "and", "MANNER,", "[5].", "A", "similar", "interlingua", "treatment,", "also", "based", "on", "LCS,", "would", "decompose", "the", "English", "phrase", "swim", "across", "the", "lake", "into", "the", "same", "three", "separate", "components", "which", "would", "constitute", "the", "predicates", "of", "the", "predicate-argument", "structure.", "This", "predicate", "argument", "structure,", "the", "LCS,", "then", "also", "serves", "as", "the", "representation", "for", "the", "French", "translation", "[2]."], "cited_papers": [{"title": "Capturing motion verb generalizations with synchronous tags", "year": "1996", "authors": ["Martha Palmer", "Joseph Rosenzweig"]}], "target_citation_location": 255, "citation_locations": [8, 255, 278, 327], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5d3ddd80-fc67-4e17-a2b2-92d479c81d82", "citing_paper": {"title": "Effects of Word Alignment Visualization on Post-Editing Quality & Speed \u2020", "year": 2015, "authors": ["Lane Schwartz", "Isabel Lacruz", "Tatyana Bystrova"]}, "text": ["We", "hypothesize", "that", "texts", "with", "alignment", "are", "less", "cognitively", "demanding", "to", "process,", "and", "so", "less", "effortful", "to", "post-edit", "than", "texts", "without", "alignment.", "If", "this", "is", "the", "case,", "shorter", "post-editing", "times", "for", "texts", "with", "alignment", "are", "consistent", "with", "previous", "findings", "by", "Koponen et al. (2012),", "who", "found", "that", "per", "word", "post-editing", "times", "were", "shorter", "for", "segments", "that", "were", "less", "cognitively", "demanding", "because", "of", "the", "linguistic", "structure.", "Related", "work", "on", "cognitive", "effort", "in", "post-editing", "(Lacruz et al., 2014, Lacruz and Shreve, 2014)", "has", "also", "shown", "decreased", "densities", "of", "short", "pauses", "when", "less", "cognitively", "demanding", "segments", "are", "post-edited."], "cited_papers": [{"title": "Post-editing time as a measure of cognitive effort", "year": "2012", "authors": ["M Koponen", "W Aziz", "L Ramos", "L Specia"]}], "target_citation_location": 40, "citation_locations": [40, 69], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "5d42ab79-56dd-4911-a3f5-044a1ec75f08", "citing_paper": {"title": "Diverse dialogue generation with context dependent dynamic loss function", "year": 2020, "authors": ["Ayaka Ueyama", "Yoshinobu Kano"]}, "text": ["Table", "1", "and", "Table", "2", "respectively", "present", "evaluation", "results", "for", "Japanese", "and", "English", "datasets", "in", "perplexity,", "BLEU", "(Papineni et al., 2002),", "DIST-N", "(Li et al., 2016),", "ROUGE", "(Lin, 2004),", "also", "showing", "length,", "which", "is", "an", "average", "number", "of", "tokens", "generated", "in", "a", "sentence.", "*", "in", "these", "tables", "indicate", "significant", "differences", "between", "baseline", "models", "and", "INF", "model", "for", "each", "evaluation", "metric", "(p&lt,0.05).", "BLEU", "and", "ROUGE", "were", "used", "to", "assess", "the", "quality", "of", "the", "generated", "sentences,", "whereas", "DIST-N", "was", "used", "to", "calculate", "the", "proportion", "of", "different", "n-grams", "among", "the", "n-grams", "included", "in", "the", "generated", "sentences,", "and", "therefore", "to", "assess", "the", "diversity", "of", "the", "generated", "sentences."], "cited_papers": [{"title": "Rouge: A package for automatic evaluation of summaries", "year": "2004", "authors": ["Chin-Yew Lin"]}], "target_citation_location": 21, "citation_locations": [17, 19, 21], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5d9a3a01-f8dc-475f-84c0-2281b32dd064", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["A", "viable", "approach", "to", "sentiment", "analysis", "of", "newspaper", "headlines", "has", "been", "developed", "by", "using", "linguistic", "techniques", "and", "a", "broad-coverage", "lexicon", "(Chaumartin, 2007)."], "cited_papers": [{"title": "UPAR7: A knowledge-based system for headline sentiment tagging", "year": "2007", "authors": ["Fran\u00e7ois-R\u00e9gis Chaumartin"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "5daeac9e-9f8c-4380-97e2-397207335861", "citing_paper": {"title": "On the weak link between importance and prunability of attention heads", "year": 2020, "authors": ["Aakriti Budhraja", "Madhura Pande", "Preksha Nema", "Pratyush Kumar", "Mitesh Khapra"]}, "text": ["We", "use", "the", "Transformer-Base", "model", "(Vaswani et al., 2017)", "which", "has", "6", "layers", "each", "in", "the", "three", "components:", "encoder", "self-attention", "(ES),", "encoderdecoder", "cross-attention", "(ED),", "and", "decoder", "selfattention", "(DS).", "In", "each", "layer", "of", "each", "of", "the", "three", "components,", "we", "have", "8", "attention", "heads,", "totalling", "to", "3", "\u00d7", "6", "\u00d7", "8", "=", "144", "attention", "heads.", "We", "train", "the", "mod-els", "with", "2.5", "million", "sentence", "pairs", "each", "from", "the", "WMT'14", "English-Russian", "(EN-RU)", "and", "English-German", "(EN-DE)", "datasets.", "We", "report", "BLEU", "scores", "on", "WMT's", "newstest2014.", "We", "use", "Adam", "optimizer", "(Kingma", "and", "Ba,", "2014)", "with", "parameters", "\u03b2", "1", "=", "0.9,", "\u03b2", "2", "=", "0.997,", "and", "=", "10", "\u22129.", "We", "vary", "the", "learning", "rate", "according", "to", "the", "formula", "described", "in", "Vaswani et al. (2017)", "with", "warmup", "steps", "=", "16k.", "We", "use", "large", "batch", "sizes", "of", "32k", "and", "25k", "for", "EN-RU", "and", "EN-DE,", "respectively,", "as", "it", "has", "been", "established", "that", "large", "batch", "sizes", "are", "inherent", "to", "the", "performance", "of", "Transformers", "(Popel and Bojar, 2018, Voita et al., 2019b).", "We", "achieve", "effectively", "large", "batch", "sizes", "using", "the", "technique", "of", "gradient", "accumulation", "on", "single", "NVIDIA", "V100", "and", "1080Ti", "GPUs."], "cited_papers": [{"title": "Training tips for the transformer model", "year": "2018", "authors": ["Martin Popel", "Ond\u0159ej Bojar"]}, {"title": "Analyzing multihead self-attention: Specialized heads do the heavy lifting, the rest can be pruned", "year": "2019", "authors": ["Elena Voita", "David Talbot", "Fedor Moiseev", "Rico Sennrich", "Ivan Titov"]}], "target_citation_location": 145, "citation_locations": [5, 109, 145], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5dc63b1e-1cfd-4bd1-a12a-266b30fedb78", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["A", "major", "concern", "of", "MMB's", "was", "always", "how", "to", "parse", "written", "English", "into", "a", "machine", "representation", "for", "MT", "(Masterman, 1968).", "She", "believed", "that", "such", "a", "representation", "should", "be", "fundamentally", "semantic", "in", "nature", "(i.e.", "based", "on", "meaning", "rather", "than", "syntax)", "and", "that", "those", "semantic", "structures", "should", "be", "used", "in", "the", "parsing", "process", "itself.", "The", "latter", "view", "was", "highly", "original,", "since", "virtually", "no", "one", "has", "ever", "proposed", "such", "a", "thing", "-the", "doctrine", "is", "now", "known", "as", "semantic", "parsing,", "and", "is", "well", "known", "even", "if", "not", "as", "fashionable", "as", "it", "was", "ten", "years", "ago", "-and", "espousing", "it", "certainly", "set", "MMB", "apart", "from", "the", "prevailing", "syntactic", "approaches", "of", "her", "time.", "Some", "contemporary", "clarification", "will", "be", "needed", "in", "later", "commentary", "on", "this", "point,", "since", "the", "meaning", "of", "the", "word", "'semantics'", "as", "used", "by", "MMB", "in", "this", "connection,", "cannot", "be", "equated", "with", "either", "its", "use", "in", "'semantic", "grammar'", "(e.g.", "Burton, 1978)", "to", "mean", "parsing", "by", "the", "use", "of", "particular", "word-names", "as", "they", "occur", "in", "text", "(e.g.", "as", "in", "a", "program", "that", "knew", "what", "words", "would", "follow", "'electrical'),", "nor", "with", "its", "currently", "dominant", "use", "in", "formal,", "logical", "semantics,", "to", "which", "we", "shall", "return", "in", "a", "moment."], "cited_papers": [{"title": "Semantic grammar: an engineering technique for constructing natural language understanding systems. Bolt, Beranek and Newman", "year": "1978", "authors": ["R Burton"]}], "target_citation_location": 142, "citation_locations": [18, 142], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5dd0ea30-ae44-4baa-97cc-d94ef741f62a", "citing_paper": {"title": "Controlled Text Generation with Adversarial Learning", "year": 2020, "authors": ["Federico Betti", "Giorgia Ramponi", "Massimo Piccardi"]}, "text": ["In", "these", "experiments", "we", "have", "compared", "the", "conditioned", "text", "generation", "of", "CTERM-GAN", "with", "that", "of", "the", "state-of-the-art", "adversarial", "architectures", "-Se-qGAN", "[24],", "RelGAN", "[16],", "and", "TGVAE", "[22]", "-and", "a", "classic", "auto-regressive", "LSTM", "language", "model", "with", "an", "initial", "conditioning,", "in", "terms", "of", "both", "syntactic", "and", "semantic", "quality.", "The", "main", "goal", "is", "to", "ensure", "a", "good", "quality", "for", "the", "generation", "by", "introducing", "a", "conditioning", "on", "the", "semantic", "of", "the", "sentence.", "In", "this", "task,", "the", "conditioning", "consists", "of", "the", "word", "distribution", "for", "a", "topic", "extracted", "from", "a", "sentence,", "either", "provided", "by", "the", "user", "or,", "as", "in", "our", "case,", "sampled", "from", "the", "dataset.", "Any", "type", "of", "topic", "model", "can", "be", "adopted:", "in", "our", "case,", "an", "LDA", "model", "[2]", "has", "been", "trained", "on", "a", "starting", "dataset", "in", "order", "to", "have", "a", "distribution", "of", "the", "topics", "covered", "within", "the", "corpus.", "The", "LDA", "model,", "both", "in", "training", "and", "in", "inference,", "given", "an", "input", "sentence,", "builds", "a", "distribution", "on", "the", "vocabulary.", "In", "turn,", "this", "distribution", "influences", "the", "model's", "sentence", "generation", "thanks", "to", "its", "inclusion", "in", "the", "generation", "process.", "Most", "likely,", "improving", "the", "quality", "of", "the", "topic", "extraction", "is", "likely", "to", "improve", "the", "final", "results", "of", "the", "model.", "Eventually,", "the", "extracted", "distribution", "is", "used", "as", "the", "condition-", "ing", "input,", "c,", "for", "the", "relational", "memory", "during", "the", "generation,", "as", "described", "in", "Section", "3."], "cited_papers": [{"title": "RelGAN: Relational Generative Adversarial Networks for Text Generation", "year": "2019", "authors": ["Weili Nie", "Nina Narodytska", "Ankit Patel"]}], "target_citation_location": 22, "citation_locations": [20, 22, 25, 112], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5e0664f8-71b6-487a-a212-3d9ad391ea15", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["For", "the", "definition", "generation", "dataset,", "we", "directly", "use", "the", "OD", "dataset", "published", "by", "Gadetsky et al. (2018).", "The", "training", "set", "has", "33,128", "words", "and", "97,855", "entries.", "Each", "entry", "consists", "of", "a", "triplet", "of", "(w", "*,", "c,", "d", "com", ").", "For", "testing,", "we", "align", "the", "words", "and", "context", "in", "OD", "with", "the", "definitions", "in", "OALD", "through", "manual", "annotation.", "The", "annotated", "test", "set", "includes", "3,881", "words", "and", "5,111", "entries,", "which", "is", "used", "for", "automatic", "evaluation", "in", "experiments.", "Each", "entry", "in", "the", "test", "set", "has", "both", "golden", "complex", "and", "simple", "definitions", "from", "OD", "and", "OALD,", "respectively.", "Detailed", "statistics", "are", "listed", "in", "Table", "1."], "cited_papers": [{"title": "Conditional generators of words definitions", "year": "2018", "authors": ["Artyom Gadetsky", "Ilya Yakubovskiy", "Dmitry Vetrov"]}], "target_citation_location": 13, "citation_locations": [13], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5e35ec41-7a3a-415a-a917-df8046efb805", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["The", "wait-k", "policy", "(Ma et al., 2018)", "refers", "to", "write", "target", "word", "y", "t", "after", "reading", "source-side", "pre-fix", "(x", "1", "..x", "t+k\u22121", ").", "Let", "g(t)", "be", "a", "monotonic", "nondecreasing", "function", "of", "t", "that", "indicates", "the", "number", "of", "source", "words", "read", "by", "the", "encoder", "when", "writing", "the", "target", "word", "y", "t.", "Unlike", "full-sentence", "translation,", "the", "wait-k", "policy", "uses", "the", "source", "prefix", "(x", "1", ",...,", "x", "g(t))", "rather", "than", "the", "whole", "sentence", "x", "to", "generate", "y", "t:", "p(y", "t", "|x", "\u2264g(t),", "y", "&lt,t", ").", "Thus,", "the", "decoding", "probability", "is", "shown", "in", "Eq.", "7,", "and", "given", "training", "data", "D,", "the", "training", "objective", "is", "shown", "in", "Eq.", "8."], "cited_papers": [{"title": null, "year": "2018", "authors": ["Mingbo Ma", "Liang Huang", "Hao Xiong", "Renjie Zheng", "Kaibo Liu", "Baigong Zheng", "Chuanqiang Zhang", "Zhongjun He", "Hairong Liu", "Xing Li"]}], "target_citation_location": 3, "citation_locations": [3], "citation_type": "single", "annotations": [[1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5e3d562b-b98c-49ca-8bd4-131812b79e71", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["Although", "there", "are", "some", "efforts", "to", "detect", "nonacceptable", "language", "in", "Portuguese,", "they", "evaluate", "the", "developed", "approach", "in", "their", "own", "corpus,", "making", "a", "fair", "comparison", "among", "the", "models", "difficult.", "Moreover,", "these", "corpora", "are", "much", "smaller", "when", "compared", "to", "corpora", "of", "other", "languages", "(Poletto et al., 2020)", "and", "than", "the", "ToLD-Br", "corpus.", "This", "fact", "makes", "the", "development", "of", "robust", "strategies", "to", "handle", "toxic", "comments", "difficult,", "as", "they", "usually", "require", "a", "large", "corpus.", "As", "one", "can", "see", "in", "Table", "1,", "the", "corpus", "has", "a", "little", "more", "non-toxic", "than", "toxic", "tweets.", "In", "this", "paper,", "we", "adopted", "the", "binary", "version", "of", "the", "corpus,", "i.e.,", "our", "objective", "is", "to", "identify", "if", "a", "comment", "is", "toxic", "or", "non-toxic."], "cited_papers": [{"title": "Resources and benchmark corpora for hate speech detection: a systematic review", "year": "2020", "authors": ["Fabio Poletto", "Valerio Basile", "Manuela Sanguinetti", "Cristina Bosco", "Viviana Patti"]}], "target_citation_location": 41, "citation_locations": [41], "citation_type": "single", "annotations": [[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5e44b66f-ff23-4e08-98b4-7b31f36c8240", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["This", "task", "is", "highly", "related", "to", "word", "association", "modeling,", "which", "has", "been", "studied", "extensively", "in", "psycholinguistics", "for", "a", "long", "time", "(Palermo and Jenkins, 1964, McNeill, 1966),", "but", "is", "by", "no", "means", "equivalent", "to", "it.", "In", "word", "association", "experiments,", "subjects", "should", "name", "any", "word", "associated", "with", "a", "given", "word", "as", "quickly", "as", "possible,", "but", "in", "this", "case,", "the", "spymaster's", "task", "is", "to", "find", "a", "word", "that", "is", "related", "to", "as", "many", "words", "from", "a", "given", "set", "as", "possible,", "but", "not", "or", "significantly", "less", "closely", "to", "a", "set", "of", "other", "words.", "The", "time", "allotted", "for", "the", "task", "is", "also", "limited", "at", "most", "very", "loosely", "(by", "the", "patience", "of", "the", "other", "players),", "and", "based", "on", "personal", "experiences,", "spymasters", "often", "use", "several", "minutes", "of", "thinking", "time", "to", "come", "up", "with", "the", "right", "clue.", "For", "this", "reason,", "connected", "words", "are", "often", "related", "in", "a", "complex", "way,", "even", "indirectly.", "The", "task", "of", "agents", "-to", "find", "words", "in", "the", "table", "related", "to", "the", "clue", "word", "-is", "more", "like", "simple", "associations,", "but", "time", "is", "not", "dominant", "here", "either,", "and", "more", "complex,", "indirect", "relations", "also", "matter.", "In", "a", "game", "between", "people,", "the", "relationship", "and", "common", "knowledge", "between", "the", "players", "can", "also", "count,", "but", "this", "is", "not", "an", "influencing", "factor", "in", "a", "game", "with", "an", "agent."], "cited_papers": [{"title": "A study of word association", "year": "1966", "authors": ["David Mcneill"]}, {"title": "Word association norms: Grade school through college", "year": "1964", "authors": ["S David", "James J Palermo", "unk Jenkins"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5e47fe44-def1-4660-a210-98be9d59d0f1", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Specifically,", "we", "use", "a", "retrieval-based", "ranker", "model", "that", "checks", "for", "similarity", "of", "StarSpace (Wu et al., 2018)", "embeddings.", "Our", "choice", "of", "model", "is", "influenced", "by", "Fan et al. (2019)", "who", "report", "stateof-the-art", "retrieval", "performance", "for", "locations", "in", "LIGHT", "using", "this", "model.", "The", "overall", "ranker", "model", "first", "trains", "a", "randomly", "initialized", "StarSpace", "embedding", "model", "that", "is", "designed", "to", "correlate", "characters", "with", "the", "locations", "they", "are", "found", "in.", "It", "learns", "a", "single", "bag-of-words", "embedding", "that", "takes", "into", "account", "all", "the", "individual", "words", "contained", "within", "the", "input-encoding", "character", "and", "location", "information", "as", "well", "as", "the", "previously", "mentioned", "negative", "Quest", "Generation.", "The", "quest", "is", "now", "generated", "using", "the", "existing", "character", "and", "location", "information.", "The", "generation-based", "models", "used", "in", "this", "pipeline", "are", "trained", "to", "return", "the", "most", "likely", "output", "sequence", "given", "an", "input", "sequence.", "Given", "a", "target", "sequence", "Y", "=", "{y", "1,", "...,", "y", "M}", "and", "some", "input", "context", "vector", "via", "the", "encoders", "X.", "These", "models", "use", "autoregressive", "decoding", "techniques", "that", "factor", "the", "distribution", "over", "the", "target", "sequence", "into", "a", "chain", "of", "conditional", "probabilities", "with", "a", "causal", "left", "to", "right", "structure", "as", "P", "(Y", "|X,", "\u03b8)", "=", "M", "+1", "i=1", "p(y", "i", "|y", "0:i\u22121,", "X,", "\u03b8)", "where", "\u03b8", "represents", "the", "current", "network", "parameters.", "At", "test", "time,", "a", "special", "start-of-sequence", "token", "is", "provided", "to", "the", "model", "which", "then", "proceeds", "to", "decode", "the", "rest", "of", "the", "output", "sequence", "using", "beam", "search."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 21, "citation_locations": [12, 21], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5e48fe03-24b0-4525-8073-a75eb9aa0c01", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["(3)", "the", "subword", "field,", "which", "breaks", "tokens", "into", "subwords,", "and", "(4)", "the", "d2q", "field,", "which", "includes", "the", "stemmed", "tokens", "from", "the", "concatenated", "docTTTTTquery", "predictions", "(for", "the", "d2q", "variants).", "For", "each", "querydocument", "pair,", "feature", "extraction", "is", "repeated", "over", "all", "applicable", "fields.", "In", "total,", "there", "are", "83", "different", "features", "(per", "field)", "plus", "four", "translation-based", "features", "that", "are", "only", "available", "in", "the", "raw", "and", "subword", "fields.", "We", "additionally", "test", "on", "the", "MS", "MARCO", "document", "ranking", "task", "(Bajaj et al., 2018)", "in", "a", "zeroshot", "manner.", "For", "this,", "we", "segment", "each", "document", "into", "multiple", "passages", "as", "the", "neural", "models", "cannot", "process", "long", "documents.", "Specifically,", "we", "use", "the", "sliding", "window", "strategy", "of", "Pradeep et al. (2021),", "where", "the", "window", "length", "is", "ten", "sentences", "with", "a", "stride", "of", "five", "sentences.", "Retrieval", "is", "performed", "at", "the", "passage", "level,", "and", "the", "document", "score", "is", "computed", "based", "on", "the", "highest", "relevance", "score", "among", "its", "passages."], "cited_papers": [{"title": "Saurabh Tiwary, and Tong Wang", "year": "2018", "authors": ["Payal Bajaj", "Daniel Campos", "Nick Craswell", "Li Deng", "Jianfeng Gao", "Xiaodong Liu", "Rangan Majumder", "Andrew Mcnamara", "Bhaskar Mitra", "Tri Nguyen", "Mir Rosenberg", "Xia Song", "Alina Stoica"]}], "target_citation_location": 73, "citation_locations": [73, 103], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5e7b2a0f-2c5b-4085-b416-5a7e218b9f54", "citing_paper": {"title": "NEW TABULAR ALGORITHMS FOR LIG PARSING", "year": 2000, "authors": ["Mi G Uel Alonso Jor G E Grana", "Manuel Vilares"]}, "text": ["We", "will", "describe", "parsing", "algorithms", "using", "Parsing", "Schemata,", "a", "framework", "for", "high-level", "description", "of", "parsing", "algorithms", "(15].", "An", "interesting", "application", "of", "this", "framework", "is", "the", "analysis", "of", "the", "relations", "between", "different", "parsing", "algorithms", "by", "studying", "the", "formal", "relations", "between", "their", "underlying", "parsing", "schemata."], "cited_papers": [{"title": "Parsing Schemata -A Fra mework fo r Sp ecification and Analysis of Parsing Algorithms", "year": "1997", "authors": ["K Sikkel"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "5f554d4b-295e-4fd0-af6a-106e8ffe9c11", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["In", "prediction", "tasks,", "it", "is", "important", "that", "label", "predictions", "generalize", "to", "unseen", "data.", "In", "contrast", "to", "this,", "the", "numeric", "part", "of", "referent", "labels", "in", "clauses", "are", "not", "meaningful", "and", "depend", "on", "the", "number", "of", "referents", "that", "were", "introduced", "before", "in", "the", "same", "sentence,", "so", "they", "would", "generalize", "poorly.", "Thus,", "in", "row", "(2),", "we", "change", "the", "referents", "to", "be", "relative,", "inspired", "by", "Bos (2021):", "referents", "that", "have", "not", "occurred", "before", "get", "the", "index", "0", "and", "referents", "that", "have", "occurred", "get", "a", "negative", "index,", "indicating", "how", "long", "ago", "the", "same", "referent", "last", "occurred", "(counting", "back", "among", "all", "occurrences", "of", "referents", "of", "the", "same", "type)."], "cited_papers": [{"title": "Variable-free discourse representation structures", "year": "2021", "authors": ["Johan Bos"]}], "target_citation_location": 61, "citation_locations": [61], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "5fa87e7a-2f6b-4a54-a059-8981db5a6555", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["A", "simple", "yet", "effective", "method", "for", "improving", "translation", "quality", "on", "the", "downstream", "task", "is", "fine-tuning", "with", "domain", "data,which", "is", "known", "as", "domain", "adaption", "(Luong and Manning, 2015).", "We", "train", "for", "another", "2", "epochs", "on", "the", "BSTC", "dataset", "with", "pretrained", "model.", "Furthermore,", "we", "obverse", "that", "finetuning", "on", "limited", "spoken", "corpus", "lead", "to", "overfit", "quickly,", "as", "evidenced", "by", "the", "significant", "improvement", "on", "the", "BSTC", "development", "set", "while", "degrades", "rapidly", "on", "the", "CWMT", "development", "set."], "cited_papers": [{"title": "Stanford neural machine translation systems for spoken language domains", "year": "2015", "authors": ["Minh-Thang Luong", "Christopher D Manning"]}], "target_citation_location": 23, "citation_locations": [23], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "6010f581-a07e-4ccc-9ac2-63a7da590186", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["Pretrained", "transformers", "such", "as", "BERT", "(Devlin et al., 2019)", "have", "dramatically", "increased", "retrieval", "effectiveness", "in", "many", "tasks", "across", "a", "multitude", "of", "domains", "(Lin et al., 2020a).", "Nevertheless,", "in", "a", "standard", "\"retrieve-then-rerank\"", "setup,", "the", "application", "of", "pretrained", "transformer-based", "rerankers", "incurs", "large", "computational", "costs", "and", "long", "query", "latencies,", "making", "those", "rerankers", "unrealistic", "for", "many", "real-world", "applications.", "For", "example,", "according", "to", "the", "ColBERT", "paper", "(Khattab and Zaharia, 2020),", "reranking", "1000", "hits", "from", "the", "MS", "MARCO", "passage", "dataset", "takes", "32.9", "seconds", "per", "query.", "Other", "researchers", "have", "noted", "the", "computational", "costs", "of", "transformer-based", "rankers", "(Hofst\u00e4tter", "and", "Hanbury,", "*", "Equal", "contribution", "2019),", "and", "this", "realization", "has", "compelled", "the", "field", "to", "explore", "other", "approaches,", "for", "example,", "simplified", "models", "(Hofst\u00e4tter et al., 2020, Soldaini and Moschitti, 2020, Mitra et al., 2020, MacAvaney et al., 2020, Gao et al., 2020, Jiang et al., 2020)", "and", "learned", "dense", "representations", "(Xiong et al., 2020, Lin et al., 2020b)."], "cited_papers": [{"title": "ColBERT: Efficient and effective passage search via contextualized late interaction over BERT", "year": "2020", "authors": ["Omar Khattab", "Matei Zaharia"]}], "target_citation_location": 55, "citation_locations": [5, 19, 55, 102, 107], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "60874e59-fd7b-47f0-af98-01465bb9f859", "citing_paper": {"title": "Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets", "year": 2021, "authors": ["George-Andrei Dima", "Dumitru-Clementin Cercel", "Mihai Dascalu"]}, "text": ["Language", "Models:", "We", "experimented", "with", "BERTbase", "(Devlin et al., 2019)", "and", "with", "the", "domainspecific", "Transformers,", "namely", "BioBERT", "and", "Bio-ClinicalBERT", "(Alsentzer et al., 2019).", "After", "a", "preliminary", "fine-tuning", "on", "the", "subtask", "1a,", "the", "most", "promising", "results", "were", "obtained", "by", "BioBERT."], "cited_papers": [{"title": "Publicly available clinical bert embeddings", "year": "2019", "authors": ["Emily Alsentzer", "John Murphy", "William Boag", "Wei-Hung Weng", "Di Jindi", "Tristan Naumann", "Matthew Mcdermott"]}], "target_citation_location": 16, "citation_locations": [6, 16], "citation_type": "single", "annotations": [[3, 3, 2, 2, 2, 3, 3, 3, 2, 1, 1, 1, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "60b82cb4-eca3-4897-a522-ea8e3f9d0ec5", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["A", "standard", "buTPDA", "is", "not", "quite", "the", "right", "model.", "Schimpf and Gallier (1985)", "prove", "that", "TPDAs", "are", "necessary", "for", "operating", "on", "tree", "sets", "with", "context-free", "path", "languages.", "7", "But", "they", "also", "prove", "that", "the", "yield", "of", "the", "class", "of", "tree", "languages", "accepted", "by", "buTPDAs", "is", "the", "indexed", "languages.", "For", "the", "nature", "of", "gNCNs", "presented", "in", "this", "paper,", "the", "string", "language", "should", "be", "within", "the", "mildly", "context-sensitive", "languages", "(MCSLs),", "thus", "this", "type", "of", "TPDA", "is", "too", "powerful."], "cited_papers": [{"title": "Tree pushdown automata", "year": "1985", "authors": ["K Schimpf", "J Gallier"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "60f0865a-9431-4524-b181-8145a641fc5f", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["It", "can", "of", "course", "be", "argued", "that", "an", "alternative", "representation", "would", "be", "more", "appropriate", "for", "MT,", "where", "who", "depends", "from", "likes", "in", "the", "tree.", "We", "have", "used", "the", "system", "of", "Han et al. (2000)", "to", "illustrate", "this", "point", "because", "it", "is", "a", "system", "that", "has", "the", "goal", "of", "exploring", "the", "feasibility", "of", "a", "plug-and-play", "architecture:", "that", "is,", "necessary", "components", "such", "as", "a", "parser", "are", "obtained", "from", "elsewhere,", "with", "a", "given", "output", "structure", "that", "it", "is", "necessary", "to", "use.", "Given", "this,", "gNCNs", "are", "required", "either", "directly", "or", "indirectly.", "The", "case", "of", "the", "direct", "relation,", "using", "these", "structures", "as", "the", "basis", "for", "a", "transfer", "component,", "is", "illustrated", "already", "in", "the\u00abDXD[the]", "\u00acCOMPs[which]", "\u00abDXD[the]", "\u00acCOMPs[which]", "\u00abDXD[the]", "\u00abNXdxN[floor]", "\u00acN0nx0Vnx1[covered]", "\u00abNXdxN[dust]", "\u00acN0nx0Vnx1[collected]", "\u00abNXdxN[jacket]", "\u00acVvx[is]", "\u00abnx0Ax1[tweed]", "\u00abDXD[the]", "\u00acCOMPs[which]", "\u00abDXD[the]", "\u00abNXdxN[dust]", "\u00acN0nx0Vnx1[collected]", "\u00abNXdxN[jacket]", "\u00acVvx[is]", "\u00abNXN[it]", "\u00abDXD[the]", "\u00abNXdxN[floor]", "\u00abnx0Vnx1[covered]", "\u00acsPUs[.]", "\u00abnx0Ax1[tweed]Figure", "5:", "Derivation", "tree", "pair", "for", "example", "(4)", "lefthand", "pair", "of", "Figure", "4,", "a", "pairing", "indirectly", "involving", "gNCNs", "would", "be", "required", "in", "transforming", "the", "syntactic", "representation", "into", "a", "deeper", "semantic", "one", "(the", "one", "used", "in", "translation),", "as", "in", "the", "righthand", "pair", "of", "Figure", "4.", "This", "latter", "is", "the", "sort", "of", "relation", "that", "may", "need", "to", "be", "specified,", "then,", "in", "a", "formalism", "with", "multiple", "levels,", "such", "as", "MTT."], "cited_papers": [{"title": "Handling Structural Divergences and Recovering Dropped Arguments in a Korean/English Machine Translation System", "year": "2000", "authors": ["H Grune", "C Bal", "K Jacobs", "unk Langendoen", "U Chichester", "B Han", "M Lavoie", "O Palmer", "R Rambow", "T Kittredge", "N Korelsky", "M Kim", "unk Kim"]}], "target_citation_location": 30, "citation_locations": [30], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "60f3c57c-8b46-4e34-8e31-ec0c952459e9", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["Ortega", "et", "al.", "(2020b)", "used", "morphological", "information,", "such", "as", "affixes,", "to", "guide", "the", "Byte-Pair-Encoding", "(BPE)", "segmentation", "algorithm", "(Sennrich et al., 2016b)", "for", "Quechua.", "However,", "their", "improvement", "is", "not", "significant,", "and", "according", "to", "Bostrom and Durrett (2020),", "BPE", "tends", "to", "oversplit", "roots", "of", "infrequent", "words.", "They", "showed", "that", "a", "unigram", "language", "model", "(Kudo, 2018)", "seems", "like", "a", "better", "alternative", "to", "split", "affixes", "and", "preserve", "roots", "(in", "English", "and", "Japanese)."], "cited_papers": [{"title": "Subword regularization: Improving neural network translation models with multiple subword candidates", "year": "2018", "authors": ["Taku Kudo"]}], "target_citation_location": 45, "citation_locations": [17, 29, 45], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]]}
{"id": "6160a8c3-73ab-4eb0-91fb-9d8cdd72e26c", "citing_paper": {"title": "drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM", "year": 2022, "authors": ["Dylan Phelps"]}, "text": ["English", "and", "Portuguese", "are", "the", "primary", "languages", "and", "general", "STS", "data,", "from", "STSBenchmark", "(Cer et al., 2017)", "and", "ASSIN2", "(Real et al., 2020)", "for", "English", "and", "Portuguese", "respectively,", "and", "idiom", "STS", "data", "for", "both", "languages", "are", "included", "in", "the", "train,", "dev,", "eval", "and", "test", "sets.", "A", "very", "small", "amount", "(50", "examples)", "of", "Galician", "data,", "comprised", "of", "idiom", "STS", "data,", "is", "also", "included", "in", "the", "test", "set."], "cited_papers": [{"title": "SemEval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation", "year": "2017", "authors": ["Daniel Cer", "Mona Diab", "Eneko Agirre", "I\u00f1igo Lopez-Gazpio", "Lucia Specia"]}], "target_citation_location": 13, "citation_locations": [13, 16], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "620fb93f-2db9-4ded-95e3-6c13f871e499", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["Explicit", "vs.", "Implicit", "NP", "Relations", "Next,", "we", "analyze", "the", "composition", "of", "the", "relations", "in", "the", "dataset,", "as", "to", "whether", "these", "relations", "are", "implicit", "or", "explicit.", "While", "there", "is", "no", "accepted", "definition", "of", "explicit-implicit", "distinction", "in", "the", "literature", "(Carston, 2009, Jarrah, 2016),", "here", "we", "adapt", "a", "definition", "originally", "used", "by", "Cheng and Erk (2019)", "for", "another", "phenomenon,", "implicit", "arguments:", "14", "In", "an", "implicit", "relation", "the", "anchor", "and", "the", "complement", "are", "not", "syntactically", "connected", "to", "each", "other", "and", "might", "not", "even", "appear", "in", "the", "same", "sentence.", "This", "implies,", "for", "example,", "that", "any", "inter-sentential", "relations", "are", "implicit", "15,", "while", "relations", "within", "one", "sentence", "can", "be", "either", "implicit", "or", "explicit.", "We", "sample", "three", "documents", "from", "the", "test-set,", "containing", "590", "links", "in", "total,", "and", "count", "the", "number", "of", "relations", "of", "each", "type.", "Our", "manual", "analysis", "reveals", "that", "89.8%", "of", "the", "relations", "are", "implicit."], "cited_papers": [{"title": "Implicit argument prediction as reading comprehension", "year": "2019", "authors": ["Pengxiang Cheng", "Katrin Erk"]}], "target_citation_location": 46, "citation_locations": [37, 46], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "62d012ad-e4c0-46a2-9f76-fcd8985adb8b", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["where", "t", "i", "denotes", "the", "desired", "output,", "i.e.,", "the", "probability", "should", "be", "1.0", "for", "the", "next", "word", "in", "the", "training", "sentence", "and", "0.0", "for", "all", "the", "other", "ones.", "The", "first", "part", "of", "this", "equation", "is", "the", "cross-entropy", "between", "the", "output", "and", "the", "target", "probability", "distributions,", "and", "the", "second", "part", "is", "a", "regularization", "term", "that", "aims", "to", "prevent", "the", "neural", "network", "from", "over-fitting", "the", "training", "data", "(weight", "decay).", "The", "parameter", "\u03b2", "has", "to", "be", "determined", "experimentally.", "Training", "is", "done", "using", "a", "re-sampling", "algorithm", "as", "described", "in", "[11]."], "cited_papers": [{"title": "Continuous space language models", "year": "2007", "authors": ["H Schwenk"]}], "target_citation_location": 85, "citation_locations": [85], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1]]}
{"id": "62faf58f-8404-483d-b816-b49e7fa5e9c5", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["The", "current", "state-of-the-art", "on", "the", "explanation", "regeneration", "task", "is", "represented", "by", "a", "model", "that", "employs", "a", "combination", "of", "language", "models", "and", "Graph", "Neural", "Networks", "(GNN)", "(Li et al., 2020),", "with", "the", "bulk", "of", "performance", "contributed", "from", "the", "language", "model.", "Strong", "performance", "is", "also", "achieved", "by", "transformer", "models", "adapted", "to", "rank", "inference", "chains", "(Das et al., 2019)", "or", "operating", "in", "an", "iterative", "and", "recursive", "fashion", "(Cartuyvels et al., 2020).", "In", "contrast", "with", "neural-based", "models,", "recent", "works", "(Valentino et al., 2021)", "have", "shown", "that", "the", "explanatory", "patterns", "emerging", "in", "the", "WorldTree", "corpus", "can", "be", "leveraged", "to", "improve", "sparse", "retrieval", "models", "and", "provide", "a", "viable", "way", "to", "alleviate", "semantic", "drift."], "cited_papers": [{"title": "Unification-based Reconstruction of Multi-hop Explanations for Science Questions", "year": "2021", "authors": ["Marco Valentino", "Mokanarangan Thayaparan", "Andr\u00e9 Freitas"]}], "target_citation_location": 66, "citation_locations": [25, 49, 58, 66], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "63066805-2b93-4522-82d7-692f8f559fbe", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Commonsense", "explanation", "generation.", "It", "aims", "to", "generate", "an", "explanation", "given", "a", "counterfactual", "statement", "for", "sense-making", "(Wang et al., 2019).", "We", "use", "the", "benchmark", "dataset", "ComVE", "from", "SemEval-2020", "Task", "4", "(Wang et al., 2020).", "The", "dataset", "contains", "10,000", "/", "997", "/", "1,000", "examples", "for", "training", "/", "development", "/", "test", "sets,", "respectively.", "The", "average", "input/output", "length", "is", "7.7", "/", "9.0", "words.", "All", "examples", "in", "the", "dataset", "have", "3", "references.", "Abductive", "commonsense", "reasoning.", "It", "is", "also", "referred", "as", "\u03b1-NLG.", "It", "is", "the", "task", "of", "generating", "a", "valid", "hypothesis", "about", "the", "likely", "explanations", "to", "partially", "observable", "past", "and", "future.", "We", "use", "the", "ART", "benchmark", "dataset", "(Bhagavatula et al., 2020)", "that", "consists", "of", "50,481", "/", "1,779", "/", "3,560", "examples", "for", "training", "/", "development", "/", "test", "sets.", "The", "average", "input/output", "length", "is", "17.4", "/", "10.8", "words.", "Each", "example", "in", "the", "ART", "dataset", "has", "1", "to", "5", "references."], "cited_papers": [{"title": "Abductive commonsense reasoning", "year": "2020", "authors": ["Chandra Bhagavatula", "Chaitanya Ronan Le Bras", "Keisuke Malaviya", "Ari Sakaguchi", "Hannah Holtzman", "Doug Rashkin", "Scott Downey", "Yih Wen-Tau", "Yejin Choi"]}], "target_citation_location": 95, "citation_locations": [15, 26, 95], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "630e675d-2749-48be-9782-9dbd748a0ec7", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["Objective", "and", "subjective", "evaluation", "methods", "were", "used", "in", "final", "testing", "as", "only", "a", "correct", "mixture", "of", "methods", "minimizes", "evaluation", "bias.", "Translation", "quality", "evaluation", "was", "conducted", "using", "subjective", "evaluation", "methods,", "where", "a", "group", "of", "native", "and", "near-native", "speakers", "scored", "translations.", "Automatic", "objective", "measures", "NIST and BLEU (Papineni, 2001)", "were", "used", "to", "ensure", "wider", "coverage.", "Bilingual", "corpus", "(Erjavec, 2004)", "was", "use", "d", "in", "all", "evaluation", "processes."], "cited_papers": [{"title": "MULTEXT-East Version 3: Multilingual Morphosyntactic Specifications, Lexicons and Corpora", "year": "2004", "authors": ["Erjavec Toma\u017e"]}], "target_citation_location": 51, "citation_locations": [42, 51], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "6392db29-ec56-4bb4-94e3-cdfd5053ec88", "citing_paper": {"title": "Associating semantic components with intersective Levin classes", "year": 1997, "authors": ["Hoa Dang", "Joseph Rosenzweig", "Martha Palmer"]}, "text": ["It", "is", "not", "clear", "how", "much", "WordNet", "synsets", "should", "be", "expected", "to", "overlap", "with", "Levin", "classes,", "and", "preliminary", "indications", "are", "that", "there", "is", "a", "wide", "discrepancy", "[4],", "[6],", "[3].", "However,", "it", "would", "be", "useful", "for", "the", "WordNet", "synsets", "to", "have", "access", "to", "the", "detailed", "syntactic", "information", "that", "the", "Levin", "classes", "contain,", "and", "it", "would", "be", "equally", "useful", "to", "have", "more", "guidance", "as", "to", "when", "membership", "in", "a", "Levin", "class", "does", "in", "fact", "indicate", "shared", "semantic", "components.", "Identification", "of", "these", "components", "is", "critical", "to", "the", "use", "of", "classes", "and", "their", "semantic", "features", "for", "translation", "purposes,", "whether", "transfer-based", "or", "interlingua", "based.", "Although", "Levin", "classes", "group", "together", "verbs", "with", "similar", "argument", "structures,", "the", "meanings", "of", "the", "verbs", "are", "not", "necessarily", "synonymous.", "Some", "classes", "such", "as", "break", "(break,", "chip,", "crack,", "crash,", "crush,", "fracture,", "rip,", "shatter,", "smash,", "snap,", "splinter,", "tear)", "and", "cut", "(chip,", "clip,", "cut,", "hack,", "hew,", "saw,", "scrape,", "scratch,", "slash,", "snip)", "contain", "verbs", "that", "are", "quite", "synonymous,", "but", "others,", "such", "as", "braid", "(bob,", "braid,", "brush,", "clip,", "coldcream,", "comb,", "condition,", "crimp,", "crop,", "curl,", "etc.)", "do", "not,", "which", "at", "least", "partly", "explains", "the", "lack", "of", "overlap", "between", "Levin", "and", "WordNet."], "cited_papers": [{"title": "Comparisons of levin and wordnet. Presentation in working session of Semantic Tagging Workshop", "year": "1997", "authors": ["Doug Jones", "Boyan Onyshkevych"]}], "target_citation_location": 27, "citation_locations": [26, 27, 28], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "63b79a9e-9074-43bb-b665-7f52861e38cc", "citing_paper": {"title": "Corpora and Machine Translation", "year": 1993, "authors": ["Yorick Wilks"]}, "text": ["They", "are,", "as", "it", "were,", "wholly", "pragmatic", "statisticians:", "less", "pure", "than,", "say,", "the", "Gale", "group", "(e.g.", "Gale &amp, Church 1990)", "at", "AT&amp,T:", "this", "is", "easily", "seen", "by", "the", "IBM", "introduction", "of", "notions", "like", "the", "one", "they", "call", "\"informants\"", "where", "a", "noun", "phrase", "of", "some", "sort", "is", "sought", "before", "a", "particular", "text", "item", "of", "interest.", "This", "is", "an", "interpolation", "of", "a", "highly", "theoretically-loaded", "notion", "into", "a", "routine", "that,", "until", "then,", "had", "treated", "all", "text", "items", "as", "mere", "uninterpreted", "symbols."], "cited_papers": [{"title": "Poor estimates of context are worse than none", "year": "1990", "authors": ["W Gale", "K Church"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6443bfb8-2d12-4e0c-9612-db75a63bbbb0", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["In", "addition,", "they", "introduce", "another", "method", "to", "score", "clues", "not", "only", "on", "the", "basis", "of", "word", "similarities,", "but", "also", "on", "the", "basis", "of", "their", "frequency", "and", "the", "similarity", "of", "Dict2vec", "vectors", "(Tissier et al., 2017)", "-but", "this", "is", "actually", "a", "modification", "of", "the", "original", "distance", "matrix."], "cited_papers": [{"title": "Dict2vec: Learning word embeddings using lexical dictionaries", "year": "2017", "authors": ["Julien Tissier", "Christophe Gravier", "Amaury Habrard"]}], "target_citation_location": 31, "citation_locations": [31], "citation_type": "single", "annotations": [[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "645ef370-1fb3-4b24-bbb1-7b549ab531bc", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["The", "type", "of", "information", "recovered", "by", "the", "NP", "Enrichment", "task", "complements", "well-established", "core", "NLP", "tasks", "such", "as", "entity", "typing,", "entity", "linking,", "coreference", "resolution,", "and", "semantic-role", "labeling", "(Jurafsky and Martin, 2009).", "We", "believe", "it", "serves", "as", "an", "important", "and", "much-needed", "building", "block", "for", "downstream", "applications", "that", "require", "text", "understanding,", "including", "information", "retrieval,", "relation", "extraction", "and", "event", "extraction,", "question", "answering,", "and", "so", "on.", "In", "particular,", "the", "NP", "Enrichment", "task", "neatly", "encapsulates", "much", "of", "the", "long-range", "information", "that", "is", "often", "required", "by", "such", "applications.", "Take", "for", "example", "a", "system", "that", "attempts", "to", "extract", "reports", "on", "police", "shooting", "incidents", "(Keith et al., 2017),", "with", "the", "following", "challenging,", "but", "not", "uncommon,", "passage:", "2"], "cited_papers": [{"title": "Identifying civilians killed by police with distantly supervised entity-event extraction", "year": "2017", "authors": ["Katherine Keith", "Abram Handler", "Michael Pinkham", "Cara Magliozzi", "Joshua Mcduffie", "Brendan O' Connor"]}], "target_citation_location": 92, "citation_locations": [26, 92], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6484c43e-74d9-434d-8dd2-66e5389b31a5", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["The", "definition", "generation", "task", "is", "first", "introduced", "by", "Noraset et al. (2017).", "Although", "this", "task", "is", "proposed", "as", "a", "potentially", "useful", "tool", "for", "explainable", "AI,", "many", "subsequent", "works", "believe", "that", "it", "can", "assist", "language", "learning", "by", "giving", "definitions", "for", "words", "in", "the", "text", "(Ishiwatari et al., 2019, Mickus et al., 2019, Yang et al., 2020)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Mark my word: A sequence-to-sequence approach to definition modeling", "year": "2019", "authors": ["Timothee Mickus", "Denis Paperno", "Matthieu unk"]}, {"title": "Learning to describe unknown phrases with local and global contexts", "year": "2019", "authors": ["Shonosuke Ishiwatari", "Hiroaki Hayashi", "Naoki Yoshinaga", "Graham Neubig", "Shoetsu Sato", "Masashi Toyoda", "Masaru Kitsuregawa"]}], "target_citation_location": 40, "citation_locations": [8, 40], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "64eab2d0-0ea1-45c7-9d4d-46fb3093063c", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["With", "a", "slight", "abuse", "of", "notations,", "we", "use", "p", "B", "(x", "t\u22121)", "to", "denote", "p", "B", "(u", "t,", "x", "t\u22121,", "c", "t\u22121", ").", "We", "formulate", "the", "training", "loss", "for", "self-supervised", "task", "as:L", "mem", "=", "d", "i", "\u2212", "log(b", "t", "p", "B", "(l(x", "t\u22121", ")))", "\u2212", "KL(p", "B", "(x", "t\u22121", ")||p", "B", "(l(x", "t\u22121", "))", "(9)where", "KL", "is", "Kullback-Leibler", "divergence,", "and", "l(x", "t\u22121", "))", "is", "the", "natural", "language", "action", "obtained", "via", "the", "memory", "component.", "This", "loss", "enforces", "the", "learned", "action", "representations", "to", "restore", "both", "the", "ground", "truth", "and", "predicted", "state", "transitions.", "Note", "that", "the", "natural", "language", "actions", "are", "sampled", "from", "categorical", "distributions,", "which", "is", "nondifferentiable.", "To", "get", "gradients", "for", "the", "memory", "component", "during", "back-propagation,", "we", "apply", "a", "continuous", "approximation,", "i.e.,", "using", "gumbelsoftmax", "trick", "instead", "to", "conduct", "sampling", "(Jang et al., 2016),", "to", "enable", "end-to-end", "differentiability."], "cited_papers": [{"title": null, "year": "2016", "authors": ["Eric Jang", "Shixiang Gu", "Ben Poole"]}], "target_citation_location": 126, "citation_locations": [126], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3]]}
{"id": "66048f78-1f7d-4e50-8e9a-bfc7236302e2", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["Our", "training", "data", "include", "two", "public", "datasets:", "MNLI", "(Williams et al., 2018)"], "cited_papers": [{"title": "A broad-coverage challenge corpus for sentence understanding through inference", "year": "2018", "authors": ["Adina Williams", "Nikita Nangia", "Samuel Bowman"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 1, 1]]}
{"id": "660888a1-62b7-4896-93b8-2d3ff4d4e00b", "citing_paper": {"title": "Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets", "year": 2021, "authors": ["George-Andrei Dima", "Dumitru-Clementin Cercel", "Mihai Dascalu"]}, "text": ["Multi-Task", "Learning", "represents", "a", "training", "strategy", "where", "a", "shared", "model", "is", "simultaneously", "learning", "multiple", "tasks.", "Ruder (2017)", "analysed", "the", "techniques", "applied", "in", "MTL", "and", "compared", "the", "hard", "parameter", "sharing", "and", "soft", "parameter", "sharing", "paradigms,", "concluding", "that", "the", "former", "is", "still", "pervasive", "in", "nowadays", "approaches.", "MTL", "proved", "to", "fasten", "the", "convergence", "and", "to", "improve", "the", "model", "performance", "in", "a", "variety", "of", "NLP", "applications,", "including", "named", "entity", "recognition", "(Aguilar et al., 2018),", "fake", "news", "detection", "(Wu et al., 2019),", "multilingual", "offensive", "language", "identification", "(Chen et al., 2020b),", "sentiment", "analysis", "(Zaharia et al., 2020),", "humor", "classification", "(Vlad et al., 2020),", "recommender", "systems", "(Tang et al., 2020),", "and", "even", "question", "answering", "(Kongyoung et al., 2020).", "MTL", "also", "increases", "performance", "in", "conjunction", "with", "semi-supervised", "learning", "(Liu et al., 2007),", "curriculum", "learning", "(Dong et al., 2017),", "sequence-tosequence", "(Zaremoodi and Haffari, 2018),", "reinforcement", "learning", "(Gupta et al., 2020),", "and", "adversarial", "learning", "(Liu et al., 2017)."], "cited_papers": [{"title": "Adversarial multi-task learning for text classification", "year": "2017", "authors": ["Pengfei Liu", "Xipeng Qiu", "Xuan-Jing Huang"]}], "target_citation_location": 110, "citation_locations": [15, 65, 69, 74, 77, 80, 83, 88, 98, 101, 103, 106, 110], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1]]}
{"id": "663652af-e322-4541-bc4a-0f1a2af61af6", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["Second,", "we", "use", "the", "PE", "2", "rr", "dataset", "(Popovi\u0107 and Ar\u010dan, 2016),", "which", "is", "a", "manually", "annotated", "error", "analysis", "of", "MT", "output.", "Each", "example", "in", "the", "dataset", "consists", "of", "a", "source", "sentence,", "one", "MT", "output,", "and", "two", "correct", "translations,", "along", "with", "two", "error", "annotations.", "These", "annotations", "are", "word-level", "annotations", "into", "8", "broadly", "non-linguistic", "classes,", "such", "as", "German", "Source:", "Frauen,", "die", "in", "Burkina", "Faso", "zu", "Hexen", "abgestempelt", "werden,", "weisen", "in", "der", "Regel", "einige", "gemeinsame", "gesellschaftliche", "Merkmale", "auf.", "Original", "Translation", "(Annotated):", "Women", "in", "Burkina", "Faso", "[miss]", "are", "branded", "as", "witches,", "usually", "[miss]", "some", "common", "social", "features.", "Post-edit:", "Women", "in", "Burkina", "Faso", "who", "are", "branded", "as", "witches", "usually", "have", "some", "common", "social", "features.", "Original", "Reference:", "Women", "declared", "as", "witches", "in", "Burkina", "Faso", "usually", "have", "several", "common", "characteristics.", "\"addition\",", "\"lexical", "error\",", "or", "\"untranslated\".", "See", "Figure", "2", "for", "an", "example."], "cited_papers": [{"title": "PE2rr corpus: Manual error annotation of automatically preannotated MT post-edits", "year": "2016", "authors": ["Maja Popovi\u0107", "Mihael Ar\u010dan"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "664e5f37-13bf-479d-9f26-bfe1847af3d6", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["Simple", "definition", "in", "OALD", "a", "notice", "or", "announcement", "in", "a", "public", "medium", "promoting", "a", "product,", "service,", "or", "event", "or", "publicizing", "a", "job", "vacancy.", "current", "context", "because", "of", "the", "cognitively", "inaccurate", "nature", "of", "discrete", "sense", "boundaries", "(Rosch and Mervis, 1975, Kilgarriff, 1997, Tyler and Evans, 2001).", "Secondly,", "the", "predefined", "inventories", "need", "to", "be", "updated", "manually", "by", "lexicographers,", "which", "is", "time-consuming", "and", "causes", "dictionaries", "to", "lag", "behind", "the", "ever-changing", "language", "usage.", "Different", "from", "previous", "work", "(Noraset et al., 2017, Gadetsky et al., 2018, Mickus et al., 2019, Kong et al., 2020)", "that", "focused", "only", "on", "how", "to", "generate", "definitions,", "we", "further", "propose", "a", "novel", "task", "of", "Simple", "Definition", "Generation", "(SDG).", "Making", "the", "definitions", "easier", "to", "read", "and", "understand", "could", "benefit", "the", "language", "learners,", "low", "literacy", "readers,", "as", "well", "as", "helping", "people", "with", "aphasia", "or", "dyslexia.", "For", "example,", "compared", "with", "the", "Oxford", "Dictionary", "(OD),", "the", "Oxford", "Advanced", "Learner's", "Dictionary", "(OALD)", "has", "simpler", "definitions,", "which", "are", "specifically", "designed", "for", "language", "learners.", "As", "shown", "in", "Figure", "1,", "the", "definition", "of", "the", "word", "advertisement", "in", "OALD", "does", "not", "contain", "difficult", "words", "or", "phrases", "such", "as", "announcement", "and", "public", "medium."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Mark my word: A sequence-to-sequence approach to definition modeling", "year": "2019", "authors": ["Timothee Mickus", "Denis Paperno", "Matthieu unk"]}, {"title": "Conditional generators of words definitions", "year": "2018", "authors": ["Artyom Gadetsky", "Ilya Yakubovskiy", "Dmitry Vetrov"]}, {"title": "Definition modeling: Learning to define word embeddings in natural language", "year": "2017", "authors": ["Thanapon Noraset", "Chen Liang", "Larry Birnbaum", "Doug Downey"]}], "target_citation_location": 64, "citation_locations": [35, 64], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "66717a40-fad3-45f1-946c-b0f38aec2e71", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["We", "use", "diverse", "beam", "search", "(Vijayakumar et al., 2018)", "to", "generate", "16", "candidates", "for", "each", "data", "sample.", "On", "CNNDM", "and", "XSum,", "we", "use", "the", "pre-trained", "BART", "12", "and", "PEGASUS", "13", "models", "from", "the", "Transformers", "(Wolf et al., 2020)", "library", "as", "the", "base", "abstractive", "models", "for", "candidate", "summary", "generation", "and", "model", "finetuning", "respectively.", "On", "NYT,", "we", "first", "fine-tuned", "a", "BART", "model", "14", "with", "MLE", "training", "as", "the", "base", "abstractive", "model,", "since", "our", "data", "pre-processing", "is", "sightly", "different", "from", "the", "previous", "work", "and", "there", "are", "no", "available", "pre-trained", "checkpoints.", "We", "where", "warmup", "denotes", "the", "warmup", "steps,", "which", "is", "set", "to", "10000,", "step", "is", "the", "number", "of", "updating", "steps,", "lr", "is", "the", "learning", "rate.", "We", "set", "the", "length", "penalty", "factor", "\u03b1", "in", "the", "scoring", "function", "(Eq.", "9)", "to", "the", "same", "value", "as", "used", "in", "the", "original", "beam", "search.", "We", "search", "the", "value", "of", "the", "margin", "\u03bb", "in", "the", "contrastive", "loss", "(Eq.", "8)", "within", "the", "range", "[1", "\u00d7", "10", "\u22125,", "1],", "and", "decide", "the", "value", "based", "on", "the", "model", "performance", "on", "the", "validation", "set.", "We", "also", "performed", "extensive", "search", "for", "the", "coefficient", "\u03b3", "in", "Eq.", "10.", "The", "specific", "hyper-parameter", "setting", "is", "reported", "in", "Tab.", "13."], "cited_papers": [{"title": "Transformers: State-of-the-art natural language processing", "year": "2020", "authors": ["Thomas Wolf", "Lysandre Debut", "Victor Sanh", "Julien Chaumond", "Clement Delangue", "Anthony Moi", "Pierric Cistac", "Tim Rault", "Rmi Louf", "Morgan Funtowicz", "Joe Davison", "Sam Shleifer", "Clara Patrick Von Platen", "Yacine Ma", "Julien Jernite", "Canwen Plu", "Teven Xu", "Sylvain Scao", "Mariama Gugger", "Quentin Drame", "Alexander Lhoest", "unk Rush"]}], "target_citation_location": 31, "citation_locations": [5, 31], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "66bdf49d-3fb6-44de-8954-6458490f9a02", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Following", "Koyyalagunta et al. (2021),", "we", "use", "\u03bb", "=", "0.5", "for", "Koyyalagunta", "and", "KoyyRestrict", "scoring", "functions,", "but", "also", "for", "the", "Harmonic", "function.", "We", "pair", "all", "relatedness", "measures", "to", "all", "scoring", "functions,", "creating", "16", "agents", "in", "total,", "and", "generate", "clues", "for", "n", "=", "2", "and", "3", "targeted", "blue", "words", "using", "all", "of", "them.", "Differently", "from", "Koyyalagunta et al. (2021),", "we", "consider", "all", "of", "our", "vocabulary", "words", "as", "possible", "clue", "words.", "For", "each", "possible", "clue", "word,", "the", "best", "target", "words", "in", "the", "set", "I", "n", "are", "the", "n", "closest", "words", "to", "the", "clue", "word,", "so", "scoring", "a", "possible", "clue", "is", "computationally", "inexpensive."], "cited_papers": [{"title": "Playing codenames with language graphs and word embeddings", "year": "2021", "authors": ["Divya Koyyalagunta", "Anna Sun", "Rachel Draelos", "Cynthia Rudin"]}], "target_citation_location": 1, "citation_locations": [1, 51], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "66d4c5ca-46ac-4336-8c79-6242617388e2", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Producing", "K", "outputs", "during", "inference.", "In", "order", "to", "generate", "K", "different", "outputs", "on", "test", "set,", "we", "follow", "Shen et al. (2019)", "to", "enumerate", "all", "latent", "variables", "z", "and", "then", "greedily", "decoding", "each", "token", "by", "\u0177t", "=", "arg", "max", "p(y|\u0177", "1:t\u22121,", "z,", "x).", "In", "other", "words,", "we", "ask", "each", "expert", "to", "seek", "different", "sets", "of", "concepts", "on", "the", "knowledge", "graph,", "and", "use", "the", "selected", "concepts", "to", "generate", "K", "different", "outputs.", "Notably,", "this", "decoding", "procedure", "is", "efficient", "and", "easily", "parallelizable.", "Furthermore,", "to", "make", "fair", "comparisons", "with", "sampling-based", "methods,", "we", "use", "greedy", "decoding", "without", "any", "sampling", "strategy."], "cited_papers": [{"title": "Mixture models for diverse machine translation: Tricks of the trade", "year": "2019", "authors": ["Tianxiao Shen", "Myle Ott", "Michael Auli", "Marc'aurelio Ranzato"]}], "target_citation_location": 17, "citation_locations": [17], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "66f52dad-c5ae-4cb9-bbd5-615aee03fc09", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["The", "number", "of", "unique", "label", "combinations", "is", "147,", "including", "single-label.", "The", "most", "common", "label", "combinations", "beyond", "single-label", "are", "anger", "with", "disgust", "(2.4%)", "and", "joy", "with", "trust", "(2.1%)", "followed", "by", "different", "combinations", "of", "the", "positive", "emotions", "of", "anticipation,", "joy,", "and", "trust.", "These", "findings", "are", "in", "line", "with", "previous", "findings", "discussing", "overlapping", "categories", "(Banea et al., 2011, Demszky et al., 2020).", "However,", "these", "are", "followed", "by", "anger", "combined", "with", "anticipation", "and", "sadness", "with", "surprise.", "The", "first", "combination", "is", "possibly", "a", "reflection", "of", "the", "genre,", "as", "a", "common", "theme", "for", "anger", "with", "anticipation", "is", "threats.", "The", "combination", "of", "surprise", "with", "negative", "emotions", "(anger,", "disgust,", "fear,", "sadness)", "is", "much", "more", "common", "than", "a", "combination", "with", "positive", "emotions."], "cited_papers": [{"title": "Multilingual Sentiment and Subjectivity Analysis. Multilingual natural language processing", "year": "2011", "authors": ["Carmen Banea", "Rada Mihalcea", "Janyce Wiebe"]}, {"title": null, "year": "2020", "authors": ["Dorottya Demszky", "Dana Movshovitz-Attias", "Jeongwoo Ko", "Alan Cowen", "Gaurav Nemade", "Sujith Ravi"]}], "target_citation_location": 51, "citation_locations": [51], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6710cdc7-c0f2-4947-a93e-07f4fffb8a77", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["(2020)", "that", "focus", "on", "creating", "content", "especially", "for", "2D", "visual", "games", "via", "search", "or", "reinforcement", "learning", "based", "methods.", "Ammanabrolu et al. (2020b,a)", "use", "knowledge", "graphs", "to", "ground", "language", "and", "produce", "worlds", "and", "quests", "separately", "for", "text", "games", "from", "existing", "corpora", "such", "as", "stories.", "Fan et al. (2019)", "leverage", "LIGHT", "to", "learn", "to", "generate", "interactive", "fiction", "worlds", "on", "the", "basis", "of", "locations,", "characters,", "and", "objects-this", "work", "is", "closest", "in", "spirit", "to", "our", "own", "World", "Generation", "module", "later", "on.", "They", "all", "focus", "on", "either", "generating", "or", "playing", "games."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 40, "citation_locations": [18, 40], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "6758893f-9e3c-4740-8ed7-71eefd4502e6", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Incorporating", "external", "knowledge", "is", "essential", "for", "many", "NLG", "tasks", "to", "augment", "the", "limited", "textual", "information", "(Yu et al., 2022c, Dong et al., 2021, Yu et al., 2022b).", "Some", "recent", "work", "explored", "using", "graph", "neural", "networks", "(GNN)", "to", "reason", "over", "multihop", "relational", "knowledge", "graph", "(KG)", "paths", "(Zhou et al., 2018, Jiang et al., 2019, Zhang et al., 2020a, Wu et al., 2020, Yu et al., 2022a, Zeng et al., 2021).", "For", "example,", "Zhou et al. (2018)", "enriched", "the", "context", "representations", "of", "the", "input", "sequence", "with", "neighbouring", "concepts", "on", "ConceptNet", "using", "graph", "attention.", "Ji et al. (2020)", "performed", "dynamic", "multi-hop", "reasoning", "on", "multi-relational", "paths", "extracted", "from", "the", "external", "commonsense", "KG.", "Recently,", "some", "work", "attempted", "to", "integrate", "external", "commonsense", "knowledge", "into", "generative", "pretrained", "language", "models", "(Guan et al., 2020, Bhagavatula et al., 2020, Liu et al., 2021).", "For", "example,", "Guan et al. (2020)", "conducted", "post-training", "on", "sythetic", "data", "constructed", "from", "commonsense", "KG", "by", "translating", "triplets", "into", "natural", "language", "texts", "using", "templates.", "Yu et al. (2022c)", "wrote", "a", "comprehensive", "survey", "for", "more", "detailed", "comparisons", "of", "different", "knowledge", "graph", "enhanced", "NLG", "methods."], "cited_papers": [{"title": "Kg-bart: Knowledge graph-augmented bart for generative commonsense reasoning", "year": "2021", "authors": ["Ye Liu", "Yao Wan", "Lifang He", "Hao Peng", "Philip S Yu"]}, {"title": "Abductive commonsense reasoning", "year": "2020", "authors": ["Chandra Bhagavatula", "Chaitanya Ronan Le Bras", "Keisuke Malaviya", "Ari Sakaguchi", "Hannah Holtzman", "Doug Rashkin", "Scott Downey", "Yih Wen-Tau", "Yejin Choi"]}, {"title": "A knowledge-enhanced pretraining model for commonsense story generation", "year": "2020", "authors": ["Jian Guan", "Fei Huang", "Zhihao Zhao", "Xiaoyan Zhu", "Minlie Huang"]}], "target_citation_location": 82, "citation_locations": [15, 34, 37, 54, 82, 85, 104], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "67dd4d77-e980-4cb7-a675-507581b64431", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["We", "design", "a", "memory", "component", "to", "identify", "the", "salient", "words", "of", "system", "utterances", "in", "terms", "of", "modeling", "state", "transitions", "(Sec.", "3.2).", "To", "further", "boost", "the", "memory's", "capability", "in", "learning", "compact", "natural", "language", "actions,", "we", "propose", "a", "novel", "auxiliary", "task", "to", "identify", "salient", "words", "of", "dialogue", "context", "in", "a", "supervised", "setting", "(Sec. 3.3).", "Furthermore,we", "propose", "to", "take", "more", "advantage", "from", "the", "action", "learning", "phase", "by", "reusing", "the", "memory", "component", "for", "conditioned", "response", "generation", "(Sec.", "3.4)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 50, "citation_locations": [50], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "68f04c7e-9e20-4e7c-9540-71c2ecfbf957", "citing_paper": {"title": "ROI Analysis model for Language Service Providers", "year": 2013, "authors": ["Ekaterina Stambolieva"]}, "text": ["Wiggins", "(2013)", "gives", "yet", "another", "perspective", "of", "investment", "and", "MT", "implementation", "in", "Asia", "Online", "3", "business", "environment.", "Some", "of", "the", "advantages", "of", "providing", "MT-incorporated", "solutions", "Wiggins (2013)", "list", "are", "reduced", "translation", "costs,", "faster", "delivery", "time,", "expansion", "of", "existing", "relationships", "with", "clients,", "broadening", "offered", "functionality", "and", "opening", "new", "market", "possibilities."], "cited_papers": [{"title": "Business Strategies for Building Strategic Advantage and Revenue from Machine Translation", "year": "2013", "authors": ["Dion Wiggins"]}], "target_citation_location": 25, "citation_locations": [25], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "69213775-25ed-428d-939e-65cd1289c58d", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["In", "order", "to", "see", "the", "effectiveness", "of", "the", "representation", "learning", "method,", "the", "next", "two", "baselines", "incorporate", "logical", "mechanisms", "in", "different", "ways.", "BERT+LX", "uses", "latent", "cross", "(Beutel et al., 2018)", "to", "directly", "incorporate", "predicate", "values", "in", "R1-R13", "as", "features,", "we", "use", "an", "MLP", "to", "encode", "the", "predicate", "values,", "exploring", "(i)", "one", "hidden", "layer", "with", "D=768", "and", "(ii)", "no", "hidden", "layers.", "BERT+LX", "consistently", "outperforms", "a", "simple", "MLP", "without", "latent", "cross.", "BERT+MT", "uses", "multitask", "learning", "to", "train", "the", "main", "and", "logic", "tasks", "simultaneously."], "cited_papers": [{"title": "Latent cross: Making use of context in recurrent recommender systems", "year": "2018", "authors": ["Alex Beutel", "Paul Covington", "Sagar Jain", "Can Xu", "Jia Li", "Vince Gatto", "Ed Chi"]}], "target_citation_location": 25, "citation_locations": [25], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "695be529-8d0b-4f0f-993e-c684f25f15de", "citing_paper": {"title": "Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure", "year": 1999, "authors": ["Nicoletta Calzolari", "Antonio Zampolli"]}, "text": ["In", "the", "specification", "phase", "we", "have", "taken", "into", "account", "requirements", "of", "NLP", "applications", "and", "tasks", "(parsing,", "generation,", "machine", "translation,", "word", "sense", "disambiguation,", "cross-language", "information", "retrieval,", "etc.)", "-also", "as", "stated", "in", "the", "EAGLES", "report", "of", "the", "Lexicon/Semantics", "Working", "Group", "(Sanfilippo et al. 1999)", "-for", "the", "decisions", "on", "the", "basic", "semantic", "notions", "and", "the", "more", "specific", "types", "of", "semantic", "information", "to", "be", "encoded.", "This", "is", "of", "utmost", "importance", "given", "the", "applicative", "objectives", "of", "the", "PAROLE/SIMPLE", "lexicons.", "A", "dichotomy", "at", "stake", "here", "is", "the", "one", "between", "generality", "of", "a", "LR", "vs.", "usefulness", "for", "applications.", "In", "principle,", "only", "when", "we", "know", "the", "actual", "specific", "use", "we", "intend", "to", "do", "of", "a", "LR", "can", "we", "build", "the", "'very", "best'", "LR", "for", "that", "use,", "but", "this", "has", "proved", "to", "be", "too", "expensive", "and", "not", "realistic.", "In", "practice,", "however,", "there", "exists", "a", "large", "core", "of", "information", "that", "can", "be", "shared", "by", "many", "applicative", "uses,", "and", "this", "leads", "to", "the", "concept", "of", "\"generic\"", "LR,", "which", "is", "at", "the", "basis", "of", "the", "EAGLES", "initiative", "and", "of", "the", "PAROLE/SIMPLE", "projects.", "This", "generic", "shareable", "core", "of", "information", "must", "then", "be", "enhanced", "and", "tuned", "with", "other", "means", "(see", "sections", "3", "and", "4)."], "cited_papers": [{"title": "EAGLES Recommendations on Semantic Encoding", "year": "1999", "authors": ["A Sanfilippo"]}], "target_citation_location": 38, "citation_locations": [38], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "695ffeab-369c-457d-befe-ec349a3a461d", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["While", "researchers", "have", "started", "incorporating", "user", "and", "community", "information", "into", "detection", "of", "abusive", "language,", "there", "has", "been", "no", "discussion", "of", "the", "ethical", "guidelines", "for", "doing", "so.", "Therefore,", "taking", "a", "stand", "on", "the", "issue,", "we", "lay", "out", "five", "ethical", "considerations", "in", "the", "design", "and", "implementation", "of", "methods", "that", "incorporate", "user", "or", "community", "information:", "Personal", "vs.", "population-level", "trends.", "It", "is", "important", "to", "perform", "appropriate", "generalizations", "from", "personal", "traits", "to", "population-level", "behavioral", "trends.", "Methods", "should", "avoid", "relying", "on", "simple", "inductive", "biases", "such", "as", "personal", "traits", "of", "users,", "e.g.,", "gender,", "race,", "etc.,", "as", "this", "can", "easily", "lead", "to", "scenarios", "of", "faulty", "generalizations", "where", "comments", "from", "a", "particular", "gender", "or", "race", "are", "always", "labeled", "abusive/benign.", "Moreover,", "relying", "solely", "on", "personal", "traits", "of", "users", "also", "comes", "with", "the", "risk", "that", "such", "information", "may", "not", "always", "be", "present", "or", "may", "not", "be", "accurate", "even", "when", "present", "(Drouin et al., 2016).", "On", "the", "other", "hand,", "more", "complex", "inductive", "biases", "learned", "from", "data,", "as", "in", "the", "case", "of", "social", "graph", "based", "methods,", "provide", "a", "safer", "and", "more", "reliable", "generalization", "from", "personal", "behaviors", "of", "users", "or", "communities", "to", "population", "level", "trends.", "Bias", "in", "datasets.", "An", "obvious", "pitfall", "in", "working", "with", "methods", "that", "incorporate", "user", "and", "community", "information", "is", "having", "datasets", "where", "comments", "come", "from", "users", "belonging", "to", "some", "limited", "demographics", "only.", "We", "refer", "to", "this", "as", "demographic", "bias.", "Datasets", "with", "demographic", "bias", "will", "cause", "the", "methods", "to", "overfit", "to", "linguistic", "practices", "and", "dialects", "of", "users", "and", "communities", "belonging", "to", "specific", "demographics", "(Sap et al., 2020),", "hence", "diminishing", "the", "power", "of", "the", "methods", "to", "generalize.", "In", "fact,", "this", "bias", "is", "not", "only", "a", "problem", "for", "methods", "we", "discussed,", "but", "for", "any", "NLP", "method", "in", "general.", "When", "it", "comes", "to", "methods", "that", "incorporate", "user", "or", "community", "information", "specifically,", "there", "are", "two", "other", "biases", "that", "must", "be", "kept", "in", "mind", "when", "constructing", "datasets,", "we", "refer", "to", "them", "as", "comment", "distribution", "bias", "and", "label", "distribution", "bias.", "Comment", "distribution", "bias", "occurs", "when", "the", "majority", "of", "comments", "in", "the", "dataset", "come", "from", "a", "small", "number", "of", "unique", "users.", "Such", "datasets", "allow", "the", "methods", "to", "simply", "overfit", "to", "the", "linguistic", "or", "social", "behaviors", "and", "community", "roles", "of", "specific", "users", "(Wiegand et al., 2019).", "Label", "distribution", "bias", "occurs", "when", "only", "the", "abusive", "comments", "of", "a", "user", "are", "included", "in", "the", "dataset.", "Abuse", "is", "a", "relatively", "infrequent", "phenomenon,", "even", "at", "an", "individual", "level", "(Waseem and Hovy, 2016, Wulczyn et al., 2017).", "Only", "getting", "abusive", "comments", "of", "a", "user", "can", "make", "the", "methods", "simply", "associate", "the", "identity", "of", "the", "user", "to", "abusiveness", "when", "including", "user", "information.", "Moreover,", "datasets", "with", "this", "bias", "can", "also", "make", "phenomena", "like", "homophily", "appear", "overly", "effective", "in", "the", "detection", "of", "abuse", "by", "sampling", "only", "abusive", "comments", "from", "users", "who", "are", "close", "in", "the", "social", "network."], "cited_papers": [{"title": "Why do people lie online? because everyone lies on the internet", "year": "2016", "authors": ["Michelle Drouin", "Daniel Miller", "M Shaun", "Elisa Wehle", "unk Hernandez"]}], "target_citation_location": 139, "citation_locations": [139, 238, 346, 375], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6972d175-c33c-4bc3-84c5-ccd79ab9021d", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["We", "perform", "evaluations", "with", "fine-tuned", "cased", "multilingual", "and", "language", "specific", "BERT", "(Bidirectional", "Encoder", "Representations", "from", "Transformers)", "models", "(Devlin et al., 2019),", "as", "well", "as", "Suport", "Vector", "Machines", "(SVMs).", "Our", "evaluations", "show", "that", "the", "human-annotated", "datasets", "behave", "on", "par", "with", "comparable", "state-of-the-art", "datasets", "such", "as", "the", "GoEmotions", "dataset", "(Demszky et al., 2020).", "Furthermore,", "the", "projected", "datasets", "have", "accuracies", "that", "closely", "resemble", "human-annotated", "data", "with", "macro", "f1", "scores", "of", "0.51", "for", "the", "human", "annotated", "Finnish", "data", "and", "0.45", "for", "the", "projected", "Finnish", "data", "when", "evaluating", "with", "FinBERT", "(Virtanen et al., 2019)."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 17, "citation_locations": [17, 44, 79], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "69c72499-c385-4d1f-8852-b6c859a337c7", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["Figure", "2:", "Amount", "of", "data", "in", "GB", "(log-scale)", "for", "the", "88", "languages", "that", "appear", "in", "both", "the", "Wiki-100", "(Merity et al., 2016)", "corpus", "used", "for", "mBERT", "and", "XLM-100", "(Conneau et al., 2020).", "None", "of", "the", "Indian", "languages", "feature", "among", "top-25", "languages", "with", "the", "largest", "amount", "of", "data."], "cited_papers": [{"title": "Pointer sentinel mixture models", "year": "2016", "authors": ["Stephen Merity", "Caiming Xiong", "James Bradbury", "Richard Socher"]}], "target_citation_location": 18, "citation_locations": [18, 25], "citation_type": "single", "annotations": [[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "6a188eff-39ab-46f0-a10a-816fdab4ed62", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["In", "a", "Rapid", "Serial", "Visual", "Presentation", "(RSVP)", "paradigm,", "sentences", "were", "presented", "one", "word", "at", "a", "time,", "on", "average", "every", "\u2248", "240", "ms,", "in", "a", "white", "monospace", "font", "on", "a", "grey", "background", "approximately", "in", "the", "centre", "of", "the", "screen,", "at", "the", "optimal", "viewing", "position", "(Rayner et al., 2016).", "Each", "word", "subtended", "a", "horizontal", "angle", "0.76", "to", "the", "left", "and", "11.81", "to", "the", "right", "from", "the", "centre.", "Sentences", "were", "separated", "by", "500", "ms", "of", "a", "white", "central", "fixation", "cross", "(see", "Figure", "1).", "On", "approximately", "20%", "of", "the", "sentences", "in", "each", "session,", "the", "participant", "was", "prompted", "to", "verbalise", "the", "previous", "sentence", "back", "to", "the", "experimenter.", "An", "accuracy", "score", "of", "93%", "across", "all", "sessions", "confirmed", "that", "the", "participant", "successfully", "attended", "the", "sentences.", "Stimuli", "were", "presented", "using", "PsychoPy", "(Peirce et al., 2019)", "on", "an", "LCD", "monitor", "with", "a", "resolution", "of", "1920x1080", "pixels", "and", "60", "Hz", "refresh", "rate.", "The", "subject's", "head", "was", "stabilised", "with", "a", "chin-rest.", "Gilching,", "Germany).", "Channel", "impedances", "were", "kept", "below", "15", "k\u2126.", "Data", "were", "preprocessed", "using", "MNE-Python", "(Gramfort et al., 2013).", "Individual", "EEG", "sessions", "were", "band-pass", "filtered", "between", "1-40", "Hz,", "downsampled", "to", "250", "Hz", "and", "re-referenced", "to", "average", "reference.", "Noisy", "channels", "were", "determined", "based", "on", "visual", "inspection", "and", "interpolated.", "Non-neuronal", "components", "(e.g.", "ocular,", "muscular,", "electrical)", "were", "removed", "via", "Independent", "Component", "Analysis", "(ICA)", "individually", "for", "each", "recording", "session", "(an", "average", "of", "4", "components", "were", "removed", "per", "EEG", "session)."], "cited_papers": [{"title": "So much to read, so little time: How do we read, and can speed reading help?", "year": "2016", "authors": ["Keith Rayner", "Elizabeth Schotter", "E Michael", "Mary Masson", "Rebecca Potter", "unk Treiman"]}], "target_citation_location": 43, "citation_locations": [43, 120, 158], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6aab6bfa-e5e2-4db5-b17c-bbfba90fc609", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["The", "perplexities", "on", "the", "development", "data", "are", "summarized", "in", "Table", "2.", "It", "is", "not", "surprising", "to", "see", "that", "adding", "the", "development", "data", "of", "previous", "evaluations", "improves", "the", "perplexity", "since", "this", "more", "than", "doubles", "the", "amount", "of", "in-domain", "data.", "The", "small", "Gale", "as", "well", "as", "the", "large", "Gigaword", "corpus", "have", "also", "a", "noticeable", "effect.", "1", "The", "continuous", "space", "language", "model", "was", "trained", "on", "all", "the", "available", "data,", "including", "the", "large", "Gigaword", "corpus,", "using", "a", "resampling", "algorithm", "[11].", "This", "approach", "achieved", "a", "reduction", "in", "perplexity", "of", "more", "than", "15%", "in", "comparison", "to", "the", "large", "back-off", "language", "model.", "This", "is", "inline", "with", "results", "obtained", "in", "previous", "IWSLT", "evaluations", "[9],", "but", "here", "both", "language", "models", "are", "trained", "on", "substantially", "more", "data."], "cited_papers": [{"title": "Continuous space language models for the IWSLT 2006 task", "year": "2006", "authors": ["H Schwenk", "M Costa-Juss\u00e0", "J Fonollosa"]}], "target_citation_location": 105, "citation_locations": [75, 105], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "6afbd666-b6b3-45fa-82c7-5092ce3f3c74", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["Interpretability", "There", "has", "been", "a", "lot", "of", "work", "on", "better", "interpreting", "models'", "decision", "process,", "e.g.,", "understanding", "BERT", "(Clark et al., 2019b, Kovaleva et al., 2019)", "and", "attention", "in", "transformers", "(Hao et al., 2020),", "or", "through", "text", "generation", "models", "(Narang et al., 2020).", "In", "this", "paper", "we", "utilize", "the", "attention", "scores", "as", "a", "generic", "way", "to", "understand", "what", "features", "a", "model", "relies", "on", "for", "making", "its", "predictions.", "Other", "common", "model", "interpretation", "techniques", "(Sundararajan et al., 2017, Ribeiro et al., 2016),", "or", "more", "recent", "work", "on", "hierarchical", "attentions", "(Chen et al., 2020)", "and", "contrastive", "explanations", "(Jacovi et al., 2021),", "can", "be", "used", "as", "well.", "In", "Pruthi et al. (2020),", "the", "authors", "found", "that", "attention", "scores", "can", "be", "manipulated", "to", "deceive", "human", "decision", "makers.", "The", "reliability", "of", "existing", "interpretation", "methods", "is", "a", "research", "topic", "by", "itself,", "and", "extra", "care", "needs", "to", "be", "taken", "when", "using", "attention", "for", "auditing", "models", "on", "fairness", "and", "accountability", "(A\u00efvodji et al., 2019)."], "cited_papers": [{"title": "Fairwashing: the risk of rationalization", "year": "2019", "authors": ["Ulrich A\u00efvodji", "Hiromi Arai", "Olivier Fortineau", "S\u00e9bastien Gambs", "Satoshi Hara", "Alain Tapp"]}], "target_citation_location": 121, "citation_locations": [17, 22, 28, 58, 66, 70, 77, 121], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "6b9495ec-2822-4736-8dcb-4e5e7af64f8d", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["From", "the", "point", "of", "view", "of", "communication", "study,", "most", "of", "the", "research", "on", "public", "apologies", "is", "focused", "on", "apology", "as", "a", "speech", "act", "(e.g.", "Edmondson, 1981, Fraser, 1981, Holmes 1990, Blum-Kulka et al.1989, Olshtain and Cohen 1983, Owen, 1983, Trosborg, 1987).", "The", "studies", "are", "based", "on", "two", "perspectives.", "The", "first", "is", "from", "the", "point", "of", "view", "of", "the", "offended", "party", "(Lee &amp, Chung, 2012)", "and", "the", "second", "sees", "apology", "from", "the", "point", "of", "view", "of", "the", "offender", "(Darby &amp, Schlenker, 1989, Goffman, 1971, Hearit, 1994 Hearit, , 1996 Hearit, , 1997 Hearit, , 2010,, Schlenker &amp, Darby, 1981)."], "cited_papers": [{"title": "Crisis management by apology: corporate response to allegations of wrongdoing", "year": "2010", "authors": ["Keith Michael", "Hearit unk"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 58, "citation_locations": [24, 44, 58], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "6b94f8b7-856a-41ad-87b2-6bf427cf386d", "citing_paper": {"title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation", "year": 2021, "authors": ["Hansi Hettiarachchi", "Tharindu Ranasinghe"]}, "text": ["Unsupervised", "systems", "Majority", "of", "the", "unsupervised", "WSD", "systems", "use", "external", "knowledge", "bases", "like", "WordNet", "(Miller, 1995)", "and", "BabelNet", "(Navigli and Ponzetto, 2012).", "For", "each", "input", "word,", "its", "correct", "meaning", "according", "to", "the", "context", "can", "be", "found", "using", "graph-based", "techniques", "from", "those", "external", "knowledge", "bases.", "However,", "these", "approaches", "are", "only", "limited", "to", "the", "languages", "supported", "by", "used", "knowledge", "bases.", "More", "recent", "works", "like", "Hettiarachchi", "and", "Ranasinghe", "(2020a),", "Ranasinghe et al. (2019a)", "propose", "to", "use", "stacked", "word", "embeddings", "(Akbik et al., 2018)", "obtained", "by", "general", "purpose", "pretrained", "contextualised", "word", "embedding", "models", "such", "as", "BERT", "(Devlin et al., 2019)", "and", "Flair", "(Akbik et al., 2019)", "for", "unsupervised", "WSD.", "Despite", "their", "ability", "to", "scale", "over", "different", "languages,", "unsupervised", "approaches", "fall", "behind", "supervised", "systems", "in", "terms", "of", "accuracy."], "cited_papers": [{"title": "Pooled contextualized embeddings for named entity recognition", "year": "2019", "authors": ["Alan Akbik", "Tanja Bergmann", "Roland Vollgraf"]}], "target_citation_location": 85, "citation_locations": [14, 17, 62, 69, 82, 85], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6ba94104-a2d4-406c-b74c-256440e5d75d", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["In", "entity", "linking", "specifically,", "typing", "has", "been", "explored", "for", "cross-domain", "entity", "linking", "(Gupta et al., 2017, Onoe and Durrett, 2020).", "Past", "work", "by", "Raiman and Raiman (2018)", "has", "also", "explored", "learning", "a", "type", "system", "for", "this", "task.", "Our", "approach", "to", "learning", "types", "starts", "from", "a", "large", "set", "and", "filters", "it", "down,", "which", "is", "a", "simpler", "problem.", "A", "range", "of", "approaches", "have", "also", "considered", "augmenting", "pretrained", "models", "with", "type", "information", "(Peters et al., 2019),", "however,", "in", "these", "models,", "the", "types", "inform", "dense", "embeddings", "which", "are", "still", "uninterpretable."], "cited_papers": [{"title": "Deep-Type: Multilingual Entity Linking by Neural Type System Evolution", "year": "2018", "authors": ["Jonathan Raiman", "Olivier Raiman"]}], "target_citation_location": 16, "citation_locations": [12, 16, 59], "citation_type": "single", "annotations": [[1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1, 1, 1, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6beaf7b1-aa9b-4ebc-91b9-95d7e6924f03", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["ArXiv", "open-sources", "the", "LaTeX", "version", "of", "their", "articles,", "when", "available.", "In", "order", "to", "make", "our", "Symlink", "dataset", "open-access", "to", "the", "whole", "community,", "we", "crawled", "the", "metadata", "of", "these", "articles", "and", "only", "selected", "articles", "under", "the", "CC", "BY", "license.", "Once", "obtained", "the", "LaTeX", "project,", "we", "extracted", "all", "the", "paragraphs", "from", "the", ".tex", "files.", "We", "filtered", "out", "all", "short", "paragraphs", "with", "less", "than", "50", "words", "and", "paragraphs", "without", "symbols.", "Since", "a", "formula", "can", "be", "composed", "in", "multiple", "ways", "such", "as", "inline", "formulae", "(between", "$", "$),", "displayed", "formulae", "(between", "$$", "$$),", "or", "using", "commands", "e.g.", "array,", "to", "keep", "the", "original", "TeX", "format", "of", "the", "formulae,", "all", "of", "these", "math", "objects", "are", "masked", "before", "tokenization.", "Then,", "we", "used", "the", "SciBERT", "tokenizer", "(Beltagy et al., 2019)", "to", "tokenize", "the", "text.", "The", "original", "math", "object", "is", "then", "restored.", "As", "we", "observed", "that", "many", "papers", "have", "nested", "math", "objects,", "we", "deleted", "all", "the", "nested", "objects,", "hence,", "having", "non-nested", "LaTeX", "data.", "This", "is", "helpful", "as", "it", "makes", "the", "LaTeX", "documents", "more", "similar", "to", "the", "ones", "generated", "by", "the", "PDF-to-LaTeX", "tools,", "which", "do", "not", "contain", "nested", "objects."], "cited_papers": [{"title": "SciB-ERT: A pretrained language model for scientific text", "year": "2019", "authors": ["Iz Beltagy", "Kyle Lo", "Arman Cohan"]}], "target_citation_location": 117, "citation_locations": [117], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6c48fc67-68e6-4f23-bb85-80010de4050b", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["It", "is", "this", "very", "issue", "that", "the", "current", "wave", "of", "theories", "labelled", "'connectionist'", "(e.g.", "Sejnowski and Rosenberg, 1986)", "seeks", "to", "tackle:", "how", "underlying", "classifiers", "can", "emerge", "spontaneously", "from", "data", "by", "using", "no", "more", "than", "association", "and", "classification", "algorithms.", "MMB", "would", "have", "sympathised", "with", "its", "anti-logicism,", "but", "would", "have", "found", "its", "statistical", "basis", "only", "thin", "mathematics,", "and", "would", "have", "not", "been", "sympathetic", "to", "its", "anti-symbolic", "disposition."], "cited_papers": [{"title": "NETtalk: a parallel network that learns to read aloud", "year": "1986", "authors": ["T Sejnowski", "C Rosenberg"]}], "target_citation_location": 14, "citation_locations": [14], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6cb87225-e8a1-4675-88d5-9139231c0097", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["A", "majority", "of", "recent", "papers", "on", "multilabel", "emotion", "classification", "focus", "on", "the", "SemEval", "2018", "dataset", "which", "is", "based", "on", "tweets.", "Similarly,", "many", "of", "the", "non-multilabel", "classification", "papers", "use", "Twitter", "data.", "Twitter", "is", "a", "good", "base", "for", "emotion", "classification", "as", "tweets", "are", "limited", "in", "length", "and", "generally", "stand-alone,", "i.e.", "the", "reader", "or", "annotator", "does", "not", "need", "to", "guess", "the", "context", "in", "the", "majority", "of", "cases.", "Furthermore,", "hashtags", "and", "emojis", "are", "common,", "which", "further", "makes", "the", "emotion", "recognition", "easier", "for", "both", "human", "annotators", "and", "emotion", "detection", "and", "sentiment", "analysis", "models.", "Reddit", "data,", "as", "used", "by", "Demszky et al. (2020),", "and", "movie", "subtitles", "used", "by", "this", "paper,", "are", "slightly", "more", "problematic", "as", "they", "are", "not", "\"selfcontained\".", "Reddit", "comments", "are", "typically", "longer", "than", "one", "line", "and", "therefore", "provide", "some", "context", "for", "annotators", "to", "go", "by,", "but", "often", "lacks", "the", "hashtags", "and", "emojis", "of", "twitter", "and", "can", "be", "quite", "context-dependent", "as", "Reddit", "comments", "are", "by", "definition", "reactions", "to", "a", "post", "or", "another", "comment.", "Movie", "subtitles", "annotated", "out", "of", "sequence", "have", "virtually", "no", "context", "to", "aid", "the", "annotator", "and", "are", "supposed", "to", "be", "accompanied", "by", "visual", "cues", "as", "well.", "However,", "annotating", "with", "context", "can", "reduce", "the", "accuracy", "of", "one's", "model", "by", "doubly", "weighting", "surrounding", "units", "of", "granularity", "(roughly", "'sentences'", "in", "our", "case)", "(Boland et al., 2013).", "On", "the", "other", "hand,", "contextual", "annotations", "are", "less", "frustrating", "for", "the", "annotator", "and", "therefore,", "would", "likely", "provide", "more", "annotations", "in", "the", "same", "amount", "of", "time", "( \u00d6hman, 2020)."], "cited_papers": [{"title": "Creating an Annotated Corpus for Sentiment Analysis of German Product Reviews", "year": "2013", "authors": ["Katarina Boland", "Andias Wira-Alam", "Reinhard Messerschmidt"]}], "target_citation_location": 203, "citation_locations": [93, 203, 229], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "6cc5e33e-cf09-4b52-8b2b-8ba6d2e8bd49", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["Schabes", "et", "al.", "(1993)", "and", "Magerman (1995)", "report", "results", "using", "the", "GEIG", "evaluation", "scheme", "which", "are", "numerically", "superior", "to", "ours.", "However,", "their", "experiments", "are", "not", "strictly", "compati", "ble", "because", "they", "both", "utilise", "more", "homogeneous", "and", "probably", "simpler", "corpora.", "In", "addition,", "Schabes", "et", "al.", "do", "not", "recover", "tree", "labelling,,", "whilst", "Magerman", "has", "developed", "a", "parser", "designed", "to", "produce", "identical", "analyses", "to", "those", "used", "in", "the", "Penn", "'Ireebank,", "removing", "the", "problem", "of", "spurious", "errors", "due", "to", "grammatical", "incompatibility.", "Both", "these", "approaches", "achieve", "better", "cov", "erage", "by", "constructing", "the", "grammar", "fully", "automatically.", "No", "one", "has", "yet", "shown", "that", "any", "robust", "parser", "is", "practical", "and", "useful", "for", "some", "NLP", "task.", "However,", "it", "seems", "likely", "that", "say", "rule-to-rule", "semantic", "interpretation", "will", "be", "easier", "with", "hand-constructed", "grammars", "with", "an", "explicit,", "de", "terminate", "ruleset.", "A", "more", "meaningful", "comparison", "will", "require", "application", "of", "different", "parsers", "to", "an", "identical", "and", "extended", "test", "suite", "and", "utllisation", "of", "a", "more", "stringent", "standard", "evaluation", "procedure", "sensitive", "to", "node", "labellings."], "cited_papers": [{"title": "Statistical decision-tree models for parsing", "year": "1995", "authors": ["D Magerman"]}], "target_citation_location": 5, "citation_locations": [3, 5], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6ccf0eb0-1c70-4936-8fea-5d13208aca79", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["The", "term", "toxic", "comment", "is", "commonly", "found", "in", "literature", "as", "harmful", "speech,", "hate", "speech,", "or", "offensive", "language.", "Toxic", "comment", "may", "be", "viewed", "as", "negative", "online", "behaviors,", "i.e.,", "comments", "that", "are", "rude,", "disrespectful,", "may", "contain", "hate", "speech,", "or", "otherwise", "likely", "to", "make", "someone", "leave", "a", "discussion", "1.", "Schmidt and Wiegand (2017)", "define", "hate", "speech", "as", "any", "communication", "that", "disparages", "a", "person", "or", "a", "group", "based", "on", "some", "characteristic", "such", "as", "race,", "color,", "ethnicity,", "gender,", "sexual", "orientation,", "nationality,", "religion,", "or", "other", "characteristics.", "Also,", "it", "may", "occur", "with", "different", "linguistic", "styles,", "even", "in", "subtle", "forms", "or", "when", "humour", "is", "used", "(Fortuna and Nunes, 2018).", "It", "is", "important", "to", "highlight", "that", "fighting", "these", "types", "of", "comments", "is", "of", "utmost", "importance", "since", "they", "are", "a", "crime", "in", "several", "countries."], "cited_papers": [{"title": "A survey on hate speech detection using natural language processing", "year": "2017", "authors": ["Anna Schmidt", "Michael Wiegand"]}], "target_citation_location": 46, "citation_locations": [46, 94], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "6ce8151f-6aee-4e3a-ba96-a468e7972cd6", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["Reasoning", "based", "on", "causal", "relation", "between", "events", "is", "used", "in", "two", "types", "of", "argumentation:", "argument", "from", "cause", "to", "effect", "and", "argument", "from", "effect", "to", "cause", "(Walton et al., 2008)", "Effect-to-cause", "(E2C)", "reasoning", "has", "the", "reversed", "direction,", "S", "describes", "an", "observation", "and", "C", "is", "a", "reasonable", "explanation", "that", "may", "have", "caused", "it.", "If", "C", "causes", "(obstructs)", "S,", "then", "S", "is", "likely", "to", "support", "(attack)", "C,", "as", "in:", "The", "probabilities", "are", "computed", "by", "a", "causality", "module", "(\u00a74.3).Claim:", "St.", "Andrew"], "cited_papers": [{"title": "Argumentation schemes", "year": "2008", "authors": ["Douglas Walton", "Chris Reed", "Fabrizio Macagno"]}], "target_citation_location": 25, "citation_locations": [25], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6d26a458-cd8f-47ee-9745-7607c1849934", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["Task", "Definition", "There", "are", "two", "subtasks", "in", "the", "LCP", "task.", "For", "subtask", "1,", "the", "goal", "is", "to", "predict", "the", "complexity", "score", "for", "a", "single", "word", "from", "the", "given", "context.", "As", "an", "example", "shown", "in", "Figure", "1,", "the", "'refuge'", "is", "the", "word", "that", "needs", "to", "be", "predicted", "and", "since", "the", "meaning", "of", "it", "is", "harder", "to", "get", "in", "the", "first", "context,", "its", "complexity", "score", "in", "the", "first", "context", "is", "much", "higher.", "For", "subtask", "2,", "the", "goal", "is", "to", "predict", "the", "complexity", "score", "for", "a", "multi-word", "expression", "from", "the", "given", "context.", "An", "example", "is", "also", "shown", "in", "the", "right", "part", "of", "Figure", "1.", "a", "5-point", "Likert", "scale:", "one", "for", "very", "easy,", "two", "for", "easy,", "three", "for", "neutral,", "four", "for", "difficult,", "and", "five", "for", "very", "difficult.", "The", "numerical", "labels", "were", "transformed", "to", "a", "0-1", "range", "as", "shown", "in", "Figure", "1.", "To", "add", "further", "variation", "to", "the", "data,", "three", "corpora", "were", "selected", "including", "Bible,", "Europarl", "(Koehn, 2005)", "and", "Biomedical", "(Bada et al., 2012).", "Each", "corpus", "has", "its", "own", "unique", "language", "features", "and", "styles.", "In", "addition", "to", "single", "words,", "multi-word", "expressions", "were", "also", "selected", "for", "annotating.", "In", "the", "end,", "there", "were", "9476", "annotated", "contexts", "with", "5166", "unique", "words."], "cited_papers": [{"title": "Concept annotation in the craft corpus", "year": "2012", "authors": ["Michael Bada", "Miriam Eckert", "Donald Evans", "Kristin Garcia", "Krista Shipley", "Dmitry Sitnikov", "A William", "unk Baumgartner", "Karin Bretonnel Cohen", "Judith Verspoor", "unk Blake"]}], "target_citation_location": 154, "citation_locations": [151, 154], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6dc92787-8a95-41fa-a2fa-d67d724a8266", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["We", "use", "BLEU", "(Papineni et al., 2002)", "10", "and", "Average", "Lagging", "(AL)", "(Ma et al., 2018)", "11", "to", "evaluate", "translation", "quality", "and", "latency", "respectively.", "AL", "measures", "the", "degree", "the", "user", "is", "out", "of", "sync", "with", "the", "speaker.", "As", "shown", "in", "Eq.9-10,", "t", "is", "decoding", "step,", "\u03c4", "is", "cut-off", "decoding", "step", "where", "source", "sentence", "is", "finished,", "g(t)", "denotes", "the", "number", "of", "source", "words", "read", "by", "the", "encoder", "at", "decoding", "step", "t,", "and", "r", "=", "|x|/|y|", "is", "the", "target-to-source", "length", "ratio.", "The", "smaller", "the", "AL", "(roughly", "equivalent", "to", "k)", "is,", "the", "more", "real-time", "the", "simultaneous", "translation", "system", "is.AL", "g", "(x,", "y)", "=", "1", "\u03c4", "\u03c4", "t=1", "g(t)", "\u2212", "t", "\u2212", "1", "r", "(9)where", "\u03c4", "g", "(|x|)", "=", "min{t|g(t)", "=", "|x|}", "(10)"], "cited_papers": [{"title": "Bleu: a method for automatic evaluation of machine translation", "year": "2002", "authors": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu"]}], "target_citation_location": 3, "citation_locations": [3, 9], "citation_type": "single", "annotations": [[2, 2, 1, 1, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6e2ea89f-0670-4502-8223-ec7a8264960b", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["DeKo", "(for", "Derivation", "and", "Komposition,", "funded", "by", "the", "state", "of", "Baden-W\u00fcrttemberg", "from", "Jan", "2000", "-June", "2001)", "is", "designed", "as", "a", "German", "word", "formation", "component", "in", "a", "larger", "computational", "linguistic", "application.", "13", "It", "was", "done", "on", "a", "much", "smaller", "scale", "than", "Word", "Manager", "and", "is", "not", "used", "in", "any", "commercial", "products.", "In", "this", "tutorial", "we", "focus", "on", "some", "basic", "design", "features", "-especially", "where", "they", "differ", "from", "Word", "Manager's", "features.", "More", "details", "can", "be", "found", "in", "Heid 2001 , Schmid et al. 2001", "and", "at", "http://www.ims.uni-stuttgart.de/projekte/DeKo/.", "Here", "we", "want", "to", "concentrate", "on", "the", "corpus-based", "acquisition", "of", "data,", "the", "item-and-arrangement", "design,", "analysis", "and", "structure,", "and", "the", "interaction", "between", "DeKo", "and", "the", "lexicon.", "Although", "the", "DeKo", "project", "proper", "is", "finished,", "work", "is", "still", "being", "done", "to", "improve", "the", "program", "and", "especially", "to", "extend", "the", "lexicon."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "DeKo: Derivations-und Kompositionsmorphologie, Zwischenbericht", "year": "2001", "authors": ["Ulrich Heid"]}], "target_citation_location": 74, "citation_locations": [74], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6e465382-79c7-443c-bd7e-1ae16ff25a72", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["We", "analyzed", "the", "results", "related", "to", "the", "keywords", "in", "WordNet-Affect", "(Strapparava &amp, Valitutti, 2004, Strapparava et al., 2006)", "),", "a", "linguistic", "resource", "for", "the", "lexical", "representation", "of", "affective", "knowledge.", "In", "this", "the", "affective", "concepts", "representing", "emotional", "state", "are", "individuated", "by", "synsets", "marked", "with", "the", "alabel", "EMOTION.", "There", "are", "also", "other", "a-labels", "for", "those", "concepts", "representing", "moods,", "situations", "eliciting", "emotions,", "or", "emotional", "responses."], "cited_papers": [{"title": "The affective weight of lexicon", "year": "2006", "authors": ["Carlo Strapparava", "Allesandro Valitutti", "Oliviero Stock"]}, {"title": "WordNet Affect: an Affective Extension of WordNet", "year": "2004", "authors": ["Carlo Strapparava", "Allesandro Valitutti"]}], "target_citation_location": 10, "citation_locations": [10], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "6e472884-dc2e-4468-bae1-9ac167d34db4", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["3.", "Caselli et al. (2011b)", "establishes", "the", "current", "state", "of", "the", "art", "for", "data", "driven", "models", "in", "temporal", "and", "event", "extent", "information", "in", "Italian.", "The", "system", "is", "a", "modification", "of", "the", "TipSem", "system.", "We", "compares", "our", "models", "to", "their", "reported", "scores.", "However,", "the", "corpus", "used", "in", "Caselli et al. (2011b)", "is", "the", "Ita-TimeBank", "which", "has", "been", "augmented", "with", "further", "annotations", "and", "resources,", "while", "our", "system", "uses", "just", "the", "Ita-TimeBank", "for", "event", "extraction."], "cited_papers": [{"title": "Data-driven approach using semantics for recognizing and classifying timeml events in italian", "year": "2011", "authors": ["Tommaso Caselli", "Hector Llorens", "Borja Navarro-Colorado", "Estela Saquete"]}], "target_citation_location": 1, "citation_locations": [1, 43], "citation_type": "single", "annotations": [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6e918860-77a4-4a44-926b-9daf930711fd", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["Neural", "approaches", "to", "sequence", "tagging", "are", "common", "due", "to", "extensive", "developments", "in", "named", "entity", "recognition.", "Huang et al. (2015)", "introduced", "and", "cultivated", "the", "use", "of", "bidirectional", "LSTMs", "to", "incorporate", "features", "that", "could", "be", "used", "for", "sequence", "tagging", "using", "a", "CRF.", "Ma and Hovy (2016)", "'s", "architecture", "and", "the", "NeuroNER", "program", "(Dernoncourt et al., 2017)", "provided", "a", "basic", "architecture", "and", "influenced", "multiple", "developments", "to", "most", "sequence", "labeling", "tasks,", "including", "event", "detection and extraction (Araki, 2018).", "The", "task", "of", "event", "extraction", "in", "any", "language", "involves", "the", "identification", "of", "the", "event", "nugget", "(Ahn, 2006).", "Prominent", "work", "has", "been", "done", "to", "analyze", "the", "lexical", "and", "semantic", "features", "of", "event", "representation", "(Li et al., 2013),", "which", "served", "as", "a", "basis", "for", "neural", "event", "nugget", "detection", "(Liang et al., 2017)."], "cited_papers": [{"title": "The stages of event extraction", "year": "2006", "authors": ["David Ahn"]}], "target_citation_location": 76, "citation_locations": [15, 37, 44, 60, 76, 92, 103], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "6e966579-f5b0-45ec-bf3e-fab2639496de", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["We", "took", "all", "in-coverage", "sentences", "from", "Susanne", "of", "length", "8-40", "words", "inclusive", "containing", "internal", "punctuation,", "a", "total", "of", "2449", "sentences.", "The", "APB", "for", "this", "set", "was", "1.273,", "mean", "length", "22.5", "words,", "giving", "an", "expected", "number", "of", "analyses", "for", "an", "average", "sentence", "of", "225.", "We", "then", "re-moved", "all", "sentence-internal", "punctuation", "from", "this", "set", "and", "re-parsed", "it.", "Around", "8%", "of", "sentences", "now", "failed", "to", "receive", "an", "analysis.", "For", "those", "that", "did", "(mean", "length", "20.7", "words),", "the", "APB", "was", "now", "1", ".320,", "so", "an", "average", "sentence", "would", "be", "assigned", "310", "analyses,", "38%", "more", "than", "before.", "On", "closer", "inspection,", "the", "increase", "in", "ambiguity", "is", "due", "to", "two", "factors:", "a)", "a", "significant", "proportion", "of", "sentences", "that", "previously", "received", "1", "...:..", "9", "analyses", "now", "receive", "more,", "and", "b)", "there", "is", "a", "much", "more", "substantial", "tail", "in", "the", "distribution", "of", "sentence", "length", "vs.", "number", "of", "parses,", "due", "to", "some", "longer", "sentences", "being", "assigned", "many", "more", "parses.", "Manual", "examination", "of", "100", "depunctuated", "examples", "revealed", "that", "in", "around", "a", "third", "of", "cases,", "although", "the", "system", "returned", "global", "analyses,", "the", "correct", "one", "was", "not", "in", "this", "set", "(Briscoe &amp, Carroll, 1994).", "With", "a", "more", "constrained", "(sub", "categorised)", "syntactic", "grammar,", "many", "of", "these", "examples", "would", "not", "have", "received", "any", "global", "syntactic", "analysis."], "cited_papers": [{"title": "Parsing {with) Punctuation. Rank Xerox Research Centre", "year": "1994", "authors": ["E Briscoe", "J Carroll"]}], "target_citation_location": 177, "citation_locations": [177], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "6ea4b637-192a-4f93-8312-469f65c423ae", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Many", "works", "address", "the", "issue", "of", "model", "compression", "with", "quantization,", "pruning,", "knowledge", "distillation", "or", "a", "combination", "of", "these", "approaches.", "The", "idea", "of", "quantization", "(Shen et al., 2020)", "is", "to", "take", "advantage", "of", "the", "use", "of", "lower", "precision", "bit-width", "floats", "to", "reduce", "memory", "usage", "and", "increase", "computational", "density.", "Following", "the", "same", "objective,", "pruning", "(Michel et al., 2019)", "consists", "in", "removing", "parts", "of", "a", "model", "(weight", "bindings,", "attentional", "heads)", "with", "minimal", "precision", "losses.", "Finally,", "knowledge", "distillation", "(Sanh et al., 2019)", "enables", "the", "generation", "of", "models", "that", "mimic", "the", "performance", "of", "a", "large", "model", "(or", "set", "of", "models)", "while", "having", "fewer", "parameters."], "cited_papers": [{"title": "Q-BERT: hessian based ultra low precision quantization of BERT", "year": "2020", "authors": ["Sheng Shen", "Zhen Dong", "Jiayu Ye", "Linjian Ma", "Zhewei Yao", "Amir Gholami", "Michael Mahoney", "Kurt Keutzer"]}], "target_citation_location": 23, "citation_locations": [23, 49, 68], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6ed2d469-7806-45f4-8db7-f7d51cdb4766", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["For", "the", "visual", "feature,", "we", "adopt", "Faster-RCNN", "(Ren et al., 2015)", "to", "extract", "100", "bounding", "box", "proposals."], "cited_papers": [{"title": "Faster r-cnn: Towards real-time object detection with region proposal networks", "year": "2015", "authors": ["Kaiming Shaoqing Ren", "Ross He", "Jian Girshick", "unk Sun"]}], "target_citation_location": 7, "citation_locations": [7], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2]]}
{"id": "6ef16ef4-3bf6-4dc0-8c78-aca927b12321", "citing_paper": {"title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection", "year": 2021, "authors": ["Henry Weld", "Guanghao Huang", "Jean Lee", "Tongshu Zhang", "Kunze Wang", "Xinghong Guo", "Siqu Long", "Josiah Soyeon", "Caren Han"]}, "text": ["In", "the", "past", "few", "years,", "Natural", "Language", "Processing", "(NLP)", "researchers", "have", "proposed", "several", "online", "game/community", "toxicity", "analysis", "frameworks", "Figure", "1:", "An", "example", "intent/slot", "annotation", "from", "the", "CONDA", "(CONtextual", "Dual-Annotated)", "dataset.", "(Kwak et al., 2015, Murnion et al., 2018, Wang et al., 2020)", "and", "datasets", "(M\u00e4rtens et al., 2015, Stoop et al., 2019).", "However,", "existing", "datasets", "(1)", "focus", "only", "on", "the", "single", "utterance", "level", "without", "deeper", "understanding", "of", "context", "in", "the", "whole", "conversation/chat,", "and", "(2)", "do", "not", "explicitly", "use", "semantic", "clues", "from", "the", "words", "within", "the", "utterance."], "cited_papers": [{"title": "Detect all abuse! toward universal abusive language detection models", "year": "2020", "authors": ["Kunze Wang", "Dong Lu", "Caren Han", "Siqu Long", "Josiah Poon"]}, {"title": "Machine learning and semantic analysis of in-game chat for cyberbullying", "year": "2018", "authors": ["Shane Murnion", "J William", "Adrian Buchanan", "Gordon Smales", "unk Russell"]}, {"title": "Exploring cyberbullying and other toxic behavior in team competition online games", "year": "2015", "authors": ["Haewoon Kwak", "Jeremy Blackburn", "Seungyeop Han"]}], "target_citation_location": 30, "citation_locations": [30, 33], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "6fbfaf76-3c98-4c23-a15c-fcac6be5dd6a", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["The", "attention", "function", "(Eq.", "1)", "requires", "the", "computation", "of", "QK", "containing", "L", "Q", "L", "K", "entries", "and", "can", "be", "expensive", "for", "long", "sequences", "(L", "Q", "and", "L", "K", "are", "typically", "the", "sequence", "length).", "To", "alleviate", "this", "issue,", "sparse", "attention", "variants", "(Child et al., 2019, Qiu et al., 2020, Kitaev et al., 2020, Beltagy et al., 2020, Gupta and Berant, 2020)", "relax", "this", "requirement", "and", "compute", "only", "a", "few", "entries", "of", "QK,", "masking", "out", "the", "rest.", "For", "a", "binary", "mask"], "cited_papers": [{"title": null, "year": "2020", "authors": ["Ankit Gupta", "Jonathan Berant"]}, {"title": "Longformer: The long-document transformer", "year": "2020", "authors": ["Iz Beltagy", "E Matthew", "Arman Peters", "unk Cohan"]}, {"title": "Reformer: The efficient transformer", "year": "2020", "authors": ["Nikita Kitaev", "Lukasz Kaiser", "Anselm Levskaya"]}, {"title": "Blockwise selfattention for long document understanding", "year": "2020", "authors": ["Jiezhong Qiu", "Hao Ma", "Omer Levy", "Sinong Wen-Tau Yih", "Jie Wang", "unk Tang"]}, {"title": "Generating long sequences with sparse transformers", "year": "2019", "authors": ["Rewon Child", "Scott Gray", "Alec Radford", "Ilya Sutskever"]}], "target_citation_location": 40, "citation_locations": [40], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0]]}
{"id": "7033a2a3-1451-4cef-8b58-545a532c193b", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["to", "form", "reasoning", "chains", "that", "support", "the", "correct", "answer", "(see", "Figure", "1).", "As", "such,", "multi-hop", "inference", "represents", "a", "crucial", "step", "towards", "explainability", "in", "complex", "question", "answering,", "as", "the", "set", "of", "supporting", "facts", "can", "be", "interpreted", "as", "an", "explanation", "for", "the", "underlying", "inference", "process", "(Thayaparan et al., 2020)."], "cited_papers": [{"title": "A Survey on Explainability in Machine Reading Comprehension", "year": "2020", "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Andr\u00e9 Freitas"]}], "target_citation_location": 43, "citation_locations": [43], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1]]}
{"id": "7042aafd-f496-4ba3-b7a9-a072fd5d0af1", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["There", "are", "several", "reports", "in", "the", "literature", "showing", "that", "a", "careful", "design", "of", "the", "interface", "between", "automatic", "speech", "recognition", "(ASR)", "and", "machine", "translation", "can", "be", "important", "to", "limit", "the", "performance", "degradation", "observed", "when", "translating", "an", "automatic", "transcription", "(as", "opposed", "to", "a", "manual", "transcription).", "These", "works", "include", "the", "translation", "of", "richer", "data", "structures", "than", "the", "1-best", "ASR", "output,", "see", "for", "instance", "[18]", "or", "various", "aspects", "of", "case,", "punctuation", "and", "word", "normalization", "[19, 20]."], "cited_papers": [{"title": "A new decoder for spoken language translation based on confusion networks", "year": "2005", "authors": ["N Bertoldi", "M Federico"]}], "target_citation_location": 60, "citation_locations": [60, 70], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "70653da2-cfcc-475f-981a-6746923ba9d4", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["India", "has", "a", "population", "of", "1.4", "billion", "people", "speaking", "447", "languages", "and", "over", "10,000", "dialects,", "making", "it", "the", "country", "with", "the", "fourth-highest", "number", "of", "languages", "(Chakravarthi, 2020).", "However,", "Indian", "lan-guages", "are", "highly", "under-represented", "on", "the", "Internet", "and", "Natural", "Language", "Processing", "(NLP)", "systems", "for", "Indian", "languages", "are", "in", "their", "nascency", "(Bharathi et al., 2022, Priyadharshini et al., 2021)", ".Tamil", "is", "a", "member", "of", "the", "southern", "branch", "of", "the", "Dravidian", "languages,", "a", "group", "of", "about", "26", "languages", "indigenous", "to", "the", "Indian", "subcontinent.", "It", "is", "also", "classed", "as", "a", "member", "of", "the", "Tamil", "language", "family,", "which", "contains", "the", "languages", "of", "around", "35", "ethnolinguistic", "groups,", "including", "the", "Irula", "and", "Yerukula", "languages", "(Sakuntharaj and Mahesan, 2021 , 2017 , 2016, Thavareesan and Mahesan, 2019 , 2020a ,b, 2021).", "Malayalam", "is", "Tamil's", "closest", "significant", "cousin,", "the", "two", "began", "splitting", "during", "the", "9th", "century", "AD.", "Although", "several", "variations", "between", "Tamil", "and", "Malayalam", "indicate", "a", "pre-historic", "break", "of", "the", "western", "dialect,", "the", "process", "of", "separating", "into", "a", "different", "language,", "Malayalam,", "did", "not", "occur", "until", "the", "13th", "or", "14th", "century", "(Anita and Subalalitha, 2019b,a, Subalalitha and Poovammal, 2018, Subalalitha, 2019).", "Even", "state-of-the-art", "multilingual", "NLP", "systems", "perform", "sub-optimally", "on", "Dravidian", "languages", "(Google, 2021).", "This", "can", "be", "explained", "by", "the", "fact", "that", "multilingual", "language", "models", "are", "often", "jointly", "trained", "on", "100+", "languages", "and", "Indian", "languages", "constitute", "only", "a", "small", "fraction", "of", "their", "vocabulary", "and", "training", "data", "(as", "shown", "in", "Figure", "2).", "Machine", "learning", "models", "and", "tools", "have", "been", "proposed", "for", "many", "Natural", "Language", "Understanding", "tasks.", "In", "this", "work,", "we", "focus", "on", "Extractive", "Question-Answering", "(QA),", "where", "the", "goal", "is", "to", "localize", "the", "answer", "to", "a", "question", "within", "a", "large", "context", "(see", "Figure", "1).", "Specifically,", "we", "aim", "to", "develop", "a", "common", "multilingual", "question", "answering", "model", "for", "multiple", "Indian", "languages.", "A", "multilingual", "model", "has", "several", "advantages:", "(1)", "learning", "of", "cues", "across", "different", "languages,", "(2)", "a", "single", "model", "for", "many", "languages,", "and", "(3)", "avoiding", "dependency", "on", "English", "translation", "during", "inference.", "In", "this", "work,", "we", "start", "with", "a", "pre-trained", "multilingual", "Bidi-", "rectional", "Encoder", "Representations", "from", "Transformers", "(mBERT)", "model", "and", "further", "pre-train", "it", "with", "SQuAD", "(Rajpurkar et al., 2016),", "a", "large-scale", "question", "answering", "dataset", "in", "English.", "The", "resulting", "English-language", "mBERT-QA", "model", "is", "fine-tuned", "and", "evaluated", "for", "Indian", "languages", "Tamil", "and", "Hindi", "using", "the", "ChAII", "dataset", "(Google, 2021)."], "cited_papers": [{"title": "Automatic bilingual dictionary construction for Tirukural", "year": "2018", "authors": ["C Subalalitha"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "Information extraction framework for Kurunthogai", "year": "2019", "authors": ["C Subalalitha"]}], "target_citation_location": 148, "citation_locations": [25, 48, 99, 148, 159, 305, 332], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "70723d7e-0c6d-4990-ba18-c5aad43876a0", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["Compared", "to", "prior", "methods,", "top-k", "attention", "has", "multiple", "attractive", "properties:", "Top-k", "attention", "has", "the", "same", "memory", "footprint", "as", "Performer", "(Choromanski et al., 2021),", "a", "stateof-the-art", "attention", "variant", "with", "linear", "time", "and", "memory", "complexity,", "on", "very", "long", "inputs", "(orange", "curve,", "Fig.", "1,", "top-right),", "while", "being", "as", "fast", "as", "vanilla", "attention,", "and", "even", "faster", "than", "linear", "variants", "on", "inputs", "of", "length", "up", "to", "4K", "(Figure", "1,", "bottom-left).", "This", "allows", "us,", "e.g.,", "to", "train", "a", "typical", "12-layer", "Transformer", "decoder", "over", "32K-long", "inputs", "on", "a", "30GiB", "GPU", "(Figure", "3a)."], "cited_papers": [{"title": "Rethinking attention with performers", "year": "2021", "authors": ["Valerii Krzysztof Marcin Choromanski", "David Likhosherstov", "Xingyou Dohan", "Andreea Song", "Tamas Gane", "Peter Sarlos", "Jared Hawkins", "Afroz Davis", "Lukasz Mohiuddin", "David Kaiser", "Lucy Belanger", "Adrian Colwell", "unk Weller"]}], "target_citation_location": 19, "citation_locations": [19], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "70928c76-2d99-4f84-b005-c1b2b403ed66", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["There", "are", "two", "obvious", "approaches", "to", "try", "and", "answer", "this", "question.", "The", "first", "is", "to", "simply", "consider", "transformer-based", "features", "(e.g.,", "BERT", "score,", "ColBERT", "score,", "etc.)", "as", "yet", "another", "feature", "within", "a", "learning-to-rank", "framework-for", "example,", "with", "gradient", "boosted", "decision", "trees", "(Wang et al., 2020).", "This", "is", "not", "the", "route", "that", "we", "take,", "because", "this", "approach", "has", "less", "bearing", "on", "our", "desire", "to", "increase", "the", "efficiency", "of", "transformer-based", "models.", "Instead,", "we", "take", "the", "alternative", "approach", "of", "using", "learningto-rank", "techniques", "as", "a", "\"filtering\"", "stage", "in", "a", "multistage", "ranking", "architecture", "to", "reduce", "the", "number", "of", "candidates", "under", "consideration", "by", "BERT.", "More", "concretely,", "we", "find", "that", "a", "design", "based", "on", "this", "idea", "achieves", "the", "same", "level", "of", "effectiveness", "as", "a", "standard", "retrieve-and-rerank", "approach", "using", "BERT,", "but", "is", "up", "to", "18\u00d7", "faster.", "Other", "effectiveness-efficiency", "tradeoffs", "are", "possible,", "giving", "developers", "a", "rich", "design", "space", "to", "build", "systems", "tailored", "to", "different", "application", "scenarios."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 39, "citation_locations": [39], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "70e9b3a6-207f-4574-97fc-4a24ecd50ced", "citing_paper": {"title": "Can Semantic Role Labeling Improve SMT?", "year": 2009, "authors": ["Dekai Wu", "Pascale Fung"]}, "text": ["Gim\u00e9nez", "and", "M\u00e0rquez", "(2007b)", "and", "Gim\u00e9nez and M\u00e0rquez (2008)", "introduced", "and", "refined", "a", "set", "of", "new", "MT", "evaluation", "metrics", "employing", "rich", "assortments", "of", "features", "reflecting", "various", "kinds", "of", "similarity", "at", "lexical,", "shallow", "syntactic,", "deep", "syntactic,", "shallow", "semantic,", "and", "deep", "semantic", "levels."], "cited_papers": [{"title": "A smorgasbord of features for automatic mt evaluation", "year": "2008", "authors": ["Jes\u00fas Gim\u00e9nez", "Llu\u00eds M\u00e0rquez"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "717d08c1-01ef-42d8-aeb3-160e0bac9ea6", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["To", "answer", "these", "questions,", "we", "first", "establish", "in", "section", "2", "a", "state-of-the-art", "that", "is", "meant", "to", "be", "broad", "enough", "to", "have", "a", "shallow", "overview", "depicting", "the", "ins", "and", "outs", "and", "issues", "around", "the", "usability", "of", "Transformer-based", "models", "whose", "breadcrumb", "trail", "is", "the", "issue", "of", "resources.", "Then,", "we", "present", "in", "the", "section", "3", "the", "recent", "progress", "of", "the", "questionanswering", "task,", "through", "the", "use", "of", "these", "latest", "models.", "In", "sections", "4", "and", "5", "we", "introduce", "our", "model", "and", "present", "our", "experiments", "on", "the", "usability", "of", "Transformers", "models", "in", "a", "question-answering", "task", "for", "French, on FQuAD (d'Hoffschmidt et al., 2020)", "and", "PIAF", "(Keraron et al., 2020)", "corpora.", "We", "propose", "to", "address", "the", "instability", "relating", "to", "data", "scarcity", "by", "investigating", "various", "training", "strategies", "with", "data", "augmentation,", "hyperparameters", "optimization", "and", "cross-lingual", "transfer.", "Finally,", "we", "present", "a", "new", "compact", "model", "for", "French", "based", "on", "ALBERT", "(Lan et al., 2020)", "1,", "and", "compare", "it", "to", "existing", "monolingual", "and", "multilingual", "models,", "large", "and", "compact,", "under", "constrained", "conditions", "(notably", "on", "learning", "data)."], "cited_papers": [{"title": "ALBERT: A lite BERT for self-supervised learning of language representations", "year": "2020", "authors": ["Zhenzhong Lan", "Mingda Chen", "Sebastian Goodman", "Kevin Gimpel", "Piyush Sharma", "Radu Soricut"]}], "target_citation_location": 130, "citation_locations": [90, 93, 130], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]]}
{"id": "721760d5-4686-4d4d-a1f4-7affc9441ae2", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Therefore,", "neural-based", "diversity", "metrics", "are", "highly", "demanded.", "Intuitively,", "the", "metrics", "should", "include", "computational", "comparisons", "of", "multiple", "references", "and", "hypotheses", "by", "projecting", "them", "into", "the", "same", "semantic", "space,", "unlike", "metrics", "for", "evaluating", "the", "generation", "quality,", "e.g.,", "BERTScore", "(Zhang et al., 2020b)", "and", "BLEURT", "(Sellam et al., 2020),", "which", "only", "measures", "the", "correlation", "between", "a", "pair", "of", "reference", "and", "hypothesis."], "cited_papers": [{"title": "Bleurt: Learning robust metrics for text generation", "year": "2020", "authors": ["Thibault Sellam", "Dipanjan Das", "Ankur Parikh"]}], "target_citation_location": 39, "citation_locations": [36, 39], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "72c7a171-ef01-4b7b-bdbc-7334c37111ef", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["The", "connection", "of", "all", "this", "to", "ideograms", "had", "been", "noted", "by", "Richards,", "who", "was", "much", "preoccupied", "by", "Chinese,", "and", "who", "developed", "English", "through", "pictures", "(Richards and Gibson, 1952),", "a", "highly", "successful", "language", "teaching", "tool.", "MMB", "came", "to", "Chinese", "through", "Michael", "Halliday,", "then", "a", "Cambridge", "University", "lecturer", "in", "Chinese,", "and", "began", "to", "use", "stick-pictures", "as", "representations", "of", "situations", "but", "which", "could", "also", "provide", "a", "plausible", "referential", "underpinning", "for", "language:", "something", "universal,", "and", "outside", "the", "world", "of", "the", "language", "signs", "themselves,", "yet", "which", "did", "not", "fall", "back", "on", "the", "naive", "referentialism", "of", "those", "who", "said", "that", "the", "meanings", "of", "words", "were", "things", "or", "inexpressible", "concepts."], "cited_papers": [{"title": "English through pictures", "year": "1952", "authors": ["I Richards", "C Gibson"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "72ecc9df-5409-4c27-88a5-c77767f4723a", "citing_paper": {"title": "Effects of Word Alignment Visualization on Post-Editing Quality & Speed \u2020", "year": 2015, "authors": ["Lane Schwartz", "Isabel Lacruz", "Tatyana Bystrova"]}, "text": ["The", "Russian", "language", "news", "articles", "used", "in", "this", "study", "have", "corresponding", "reference", "translations.", "It", "is", "therefore", "possible", "(although", "given", "current", "machine", "translation", "quality,", "highly", "unlikely)", "that", "machine", "translation", "quality", "for", "any", "given", "segment", "could", "conceivably", "surpass", "the", "quality", "of", "the", "corresponding", "reference", "translation", "(if", "for", "example,", "the", "reference", "translator", "makes", "a", "mistake).", "For", "assessing", "the", "quality", "of", "the", "Russian-English", "machine", "translations,", "then,", "we", "follow", "the", "12-point", "adequacy", "scale", "of", "Schwartz et al. (2014).", "This", "adequacy", "scale", "is", "shown", "in", "Table", "1a", "on", "page", "2,", "this", "scale", "ranges", "from", "a", "low", "of", "2", "(the", "English", "translation", "makes", "no", "sense", "at", "all)", "to", "a", "high", "of", "12", "(the", "translation", "is", "superior", "to", "the", "reference)."], "cited_papers": [{"title": "Machine translation and monolingual postediting: The AFRL WMT-14 system", "year": "2014", "authors": ["L Schwartz", "T Anderson", "J Gwinnup", "K Young"]}], "target_citation_location": 69, "citation_locations": [69], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "73299666-4945-4570-9170-6db03f9b96aa", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Corpus", "diversity", "(\u21d1).", "Distinct-k", "(Li et al., 2016)", "measures", "the", "total", "number", "of", "unique", "k-grams", "normalized", "by", "the", "total", "number", "of", "generated", "k-gram", "tokens", "to", "avoid", "favoring", "long", "sentences.", "Entropyk", "(Zhang et al., 2018)", "reflects", "how", "evenly", "the", "empirical", "k-gram", "distribution", "is", "for", "a", "given", "sentence", "when", "word", "frequency", "is", "considered.", "Human", "6.62", "0.0", "12.43", "0.0", "10.36", "0.0", "6.04", "0.0", "53.57", "0.0", "10.84", "0.0", "100.0", "0.0", "100.0", "0.0", "*", "Metrics:", "SB-3/4:", "Self-BLEU-3/4", "(\u21d3),", "D-2:", "Distinct-2", "(\u21d1),", "E-4:", "Entropy-4", "(\u21d1),", "B-4:", "BLEU-4", "(\u21d1),", "R-L:", "ROUGE-L", "(\u21d1)#Uni.C(\u21d1)", "Jaccard", "(\u21d3)", "SB-3", "(\u21d3)", "SB-4", "(\u21d3)", "D-2(\u21d1)", "E-4(\u21d1)", "B-4", "(\u21d1)", "R-L", "(\u21d1)", "CVAE", "z", "="], "cited_papers": [{"title": "A diversity-promoting objective function for neural conversation models", "year": "2016", "authors": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan"]}], "target_citation_location": 4, "citation_locations": [4, 27], "citation_type": "single", "annotations": [[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "737635af-1e7c-4bc0-8b8f-20a6ede7212d", "citing_paper": {"title": "Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure", "year": 1999, "authors": ["Nicoletta Calzolari", "Antonio Zampolli"]}, "text": ["The", "SPARKLE", "project", "has", "shown", "(see", "Briscoe et al. 1999)", "how", "far", "simple", "robust", "phrasal", "parsing", "combined", "with", "classification", "techniques", "utilising", "limited", "and", "manageable", "linguistic", "knowledge", "and", "statistical", "data", "from", "substantial", "corpora", "can", "ameliorate", "this", "problem", "in", "the", "area", "of", "predicate", "subcategorisation,", "argument", "structure", "and", "semantic", "preferences,", "an", "area", "in", "which", "most", "extant", "conventional", "dictionaries,", "lexical", "databases", "and", "realistic", "lexicons", "are", "demonstrably", "weak", "or", "-when", "available", "-by", "necessity", "never", "complete."], "cited_papers": [{"title": "Syntactic and Semantic Type and Selection", "year": "1999", "authors": ["T Briscoe", "A Korhonen", "N Calzolari", "S Montemagni", "V Pirrelli", "S Federici", "G Carroll", "M Light", "D Mccarthy", "D Prescher", "S Riezler", "M Rooth"]}], "target_citation_location": 6, "citation_locations": [6], "citation_type": "single", "annotations": [[3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "738d20b9-cf59-4c7b-bb22-64cd614e4c1b", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["The", "first", "goal", "of", "this", "experiment", "is", "to", "see", "if", "the", "logical", "mechanisms", "improve", "the", "predictive", "power", "of", "a", "model", "trained", "without", "concerning", "them.", "Thus,", "our", "first", "baseline", "is", "BERT", "fine-tuned", "on", "the", "main", "task", "only.", "This", "method", "recently", "yielded", "the", "(near)", "best", "accuracy", "in", "argumentative", "relation", "classification", "(Durmus et al., 2019, Reimers et al., 2019)."], "cited_papers": [{"title": "Determining relative argument specificity and stance for complex argumentative structures", "year": "2019", "authors": ["Esin Durmus", "Faisal Ladhak", "Claire Cardie"]}, {"title": "Classification and clustering of arguments with contextualized word embeddings", "year": "2019", "authors": ["Nils Reimers", "Benjamin Schiller", "Tilman Beck", "Johannes Daxenberger", "Christian Stab", "Iryna Gurevych"]}], "target_citation_location": 48, "citation_locations": [48], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1]]}
{"id": "73f684be-f801-4360-ad31-dc9d3c2915cc", "citing_paper": {"title": "Controlled Text Generation with Adversarial Learning", "year": 2020, "authors": ["Federico Betti", "Giorgia Ramponi", "Massimo Piccardi"]}, "text": ["Natural", "language", "generation", "(NLG)", "is", "gaining", "increasing", "attention", "in", "the", "NLP", "community", "thanks", "to", "its", "intriguing", "complexity", "and", "central", "role", "in", "many", "tasks", "and", "applications.", "Recently,", "generative", "adversarial", "networks", "(GANs)", "[7]", "have", "started", "to", "display", "promising", "performance", "also", "in", "NLG.", "GANs", "leverage", "a", "form", "of", "adversarial", "learning", "where", "a", "generator", "incrementally", "learns", "to", "generate", "realistic", "samples,", "while", "a", "discriminator", "simultaneously", "learns", "to", "discriminate", "between", "real", "and", "generated", "data.", "They", "had", "originally", "been", "proposed", "as", "a", "generative", "approach", "for", "continuous", "data,", "such", "as", "images,", "but", "have", "later", "found", "application", "also", "for", "discrete", "data,", "despite", "their", "well-known", "\"non-differentiability", "issue\".", "In", "fact,", "several", "GANs", "have", "recently", "been", "proposed", "for", "text", "generation", "[24, 16, 25]", "and", "have", "achieved", "encouraging", "results", "in", "comparison", "to", "comparable", "maximum", "likelihood", "approaches,", "in", "particular,", "RelGAN", "[16]", "has", "outperformed", "state-of-theart", "(SOTA)", "results."], "cited_papers": [{"title": "RelGAN: Relational Generative Adversarial Networks for Text Generation", "year": "2019", "authors": ["Weili Nie", "Nina Narodytska", "Ankit Patel"]}], "target_citation_location": 124, "citation_locations": [30, 108, 124], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "747729fa-57f9-408d-ad79-c9207e05872a", "citing_paper": {"title": "Can Semantic Role Labeling Improve SMT?", "year": 2009, "authors": ["Dekai Wu", "Pascale Fung"]}, "text": ["This", "situation", "leads", "us", "to", "consider", "the", "potential", "application", "of", "shallow", "semantic", "parsing", "and", "semantic", "role", "labeling", "models", "to", "SMT,", "in", "ways", "that", "might", "reduce", "role", "confusion", "errors", "in", "the", "translation", "output.", "Within", "the", "lexical", "semantics", "community,", "increasingly", "sophisticated", "models", "for", "shallow", "semantic", "parsing", "are", "being", "developed.", "Such", "semantic", "parsers,", "which", "automatically", "label", "the", "predicates", "and", "arguments", "(roles)", "of", "the", "various", "semantic", "frames", "in", "a", "sentence,", "could", "automatically", "identify", "inconsistent", "semantic", "frame", "and", "role", "mappings", "between", "the", "input", "source", "sentences", "and", "their", "output", "translations.", "This", "approach", "is", "supported", "by", "the", "results", "of", "Fung et al. (2006),", "which", "reported", "that", "(for", "the", "Chinese-English", "language", "pair)", "approximately", "84%", "of", "semantic", "role", "mappings", "remained", "consistent", "cross-lingually", "across", "sentence", "translations."], "cited_papers": [{"title": "Automatic learning of chinese-english semantic structure mapping", "year": "2006", "authors": ["Pascale Fung", "Zhaojun Wu", "Yongsheng Yang", "Dekai Wu"]}], "target_citation_location": 92, "citation_locations": [92], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "7500307f-0aa9-4e7d-9bf9-8042bcf93dfd", "citing_paper": {"title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection", "year": 2021, "authors": ["Henry Weld", "Guanghao Huang", "Jean Lee", "Tongshu Zhang", "Kunze Wang", "Xinghong Guo", "Siqu Long", "Josiah Soyeon", "Caren Han"]}, "text": ["Joint", "BERT", "directly", "utilizes", "the", "merit", "of", "pretrained", "BERT", "(Devlin et al., 2019)", "and", "nonrecursively", "conducts", "the", "joint", "prediction", "over", "the", "[CLS]", "token", "embedding", "for", "intent", "and", "the", "sequence", "of", "token", "embeddings", "for", "slots."], "cited_papers": [{"title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 9, "citation_locations": [9, 18], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "7538ce02-6beb-41b3-8d93-b80978cc5def", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["MultiRC:", "Multi-Sentence", "Reading", "Comprehension", "set", "(Khashabi et al., 2018)", "is", "created", "in", "a", "way", "that", "answering", "questions", "requires", "a", "more", "complex", "understanding", "from", "multiple", "sentences.", "Therefore,", "coreference", "reasoning", "can", "be", "one", "of", "the", "sources", "for", "improving", "the", "performance", "on", "this", "dataset.", "The", "Contrast", "set", "and", "MultiRC", "datasets", "are", "not", "designed", "to", "explicitly", "evaluate", "coreference", "reasoning.", "However,", "we", "include", "them", "among", "our", "evaluation", "sets", "to", "have", "a", "broader", "view", "about", "the", "impact", "of", "using", "our", "coreference", "data", "in", "QA.", "6", "as", "we", "use", "it", "for", "investigating", "whether", "the", "resulting", "performance", "changes", "are", "due", "to", "using", "more", "training", "data", "or", "using", "coreference-aware", "additional", "data."], "cited_papers": [{"title": "Looking beyond the surface: A challenge set for reading comprehension over multiple sentences", "year": "2018", "authors": ["Daniel Khashabi", "Snigdha Chaturvedi", "Michael Roth", "Shyam Upadhyay", "Dan Roth"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "75f096d3-0d17-4996-937b-694b701d3784", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["CCG", "provides", "many", "advantages", "when", "using", "it", "in", "SMT", "in", "comparison", "with", "phrase-structure", "grammar.", "Firstly,", "CCG", "has", "more", "flexible", "structures", "in", "comparison", "with", "phrase-structure", "grammar.", "This", "flexibility", "results", "from", "the", "ability", "to", "combine", "CCG", "supertags", "using", "simple", "combinatory", "operators,", "which", "makes", "it", "possible", "to", "assign", "a", "CCG", "category", "to", "a", "phrase", "that", "does", "not", "represent", "a", "traditional", "constituent", "in", "phrasestructure", "grammar.", "This", "is", "very", "important", "for", "SMT", "systems", "as", "the", "power", "of", "SMT", "lies", "in", "using", "statistically", "extracted", "phrases", "which", "do", "not", "necessarily", "correspond", "to", "syntactic", "constituents.", "Secondly,", "CCG", "categories", "reflect", "rich", "information", "about", "the", "syntactic", "structure", "to", "which", "the", "word/phrase", "belongs", "at", "the", "lexical", "level", "without", "the", "need", "to", "build", "a", "full", "parse", "tree", "for", "the", "sentence.", "Thirdly,", "CCG", "parsing", "is", "more", "efficient", "in", "comparison", "to", "phrase-structure", "grammar", "parsing.", "Because", "most", "of", "the", "CCG", "grammar", "is", "contained", "in", "the", "lexicon,", "the", "process", "of", "supertagging,", "which", "is", "to", "assign", "supertags", "(i.e.", "complex", "CCG", "categories)", "to", "the", "words", "in", "a", "sentence,", "is", "considered", "\"almost", "parsing\"", "[13].", "After", "supertagging,", "the", "CCG", "parser", "is", "only", "required", "to", "combine", "the", "supertags", "using", "CCG", "simple", "combinatory", "operators.", "For", "the", "aforementioned", "reasons,", "CCG", "is", "considered", "more", "suitable", "to", "be", "used", "in", "SMT", "than", "phrase-structure", "grammar."], "cited_papers": [{"title": "Supertagging: An approach to almost parsing", "year": "1999", "authors": ["S Bangalore", "A Joshi"]}], "target_citation_location": 164, "citation_locations": [164], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7645d880-1c50-4bba-9f69-9a606188c28f", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["We", "modeled", "that", "problem", "as", "a", "heterogeneous", "network.", "The", "structure", "of", "our", "graph", "was", "inspired", "by", "de Sousa et al. (2020) and Anchi\u00eata et al. (2020).", "These", "authors", "modeled", "the", "tasks", "of", "helpfulness", "prediction", "and", "paraphrase", "identification", "as", "a", "heterogeneous", "network,", "respectively.", "For", "that,", "they", "defined", "an", "undirected", "unweighted", "graph", "with", "two", "node", "types:", "sentence", "and", "token.", "However,", "we", "have", "created", "a", "weighted", "graph", "based", "on", "pre-trained", "word", "embeddings.", "The", "weight", "between", "sentence", "and", "token", "nodes", "is", "the", "average", "of", "the", "embedding", "values", "for", "that", "token.", "Figure", "1", "depicts", "an", "example", "of", "a", "sentence", "modeled", "as", "a", "graph.", "From", "this", "figure,", "we", "may", "see", "two", "node", "types:", "token", "and", "sentence,", "and", "an", "undirected", "and", "weighted", "edges", "between", "the", "sentence", "and", "tokens", "nodes.", "To", "extract", "features", "from", "the", "graph", "structure,", "we", "used", "a", "regularization", "algorithm", "that", "propagates", "labels", "from", "a", "small", "set", "of", "labeled", "nodes", "to", "the", "entire", "graph.E(t)", "E(t)", "E(t)", "E(t)", "E(t)", "E(t)We", "evaluated", "the", "approach", "using", "the", "ToLD-Br", "corpus", "(Leite et al., 2020).", "It", "has", "twenty-one", "thousand", "annotated", "tweets", "as", "either", "toxic", "or", "non-toxic", "language.", "Also,", "we", "compared", "our", "strategy", "with", "different", "graph-based", "methods", "and", "with", "transformerbased", "methods.", "Our", "method", "outperformed", "all", "graph-based", "approaches", "and", "achieved", "competitive", "results", "compared", "to", "transformer-based", "methods,", "using", "only", "10%", "of", "labeled", "nodes."], "cited_papers": [{"title": "Modeling the paraphrase detection task over a heterogeneous graph network with data augmentation", "year": "2020", "authors": ["Rog\u00e9rio F De Rafael T Anchi\u00eata", "unk Sousa", "unk Thiago", "unk Pardo"]}], "target_citation_location": 16, "citation_locations": [16, 151], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "768a8d46-0f9b-4364-8651-3864888b9003", "citing_paper": {"title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection", "year": 2021, "authors": ["Henry Weld", "Guanghao Huang", "Jean Lee", "Tongshu Zhang", "Kunze Wang", "Xinghong Guo", "Siqu Long", "Josiah Soyeon", "Caren Han"]}, "text": ["In", "Figure", "4,", "we", "compare", "our", "dataset", "with", "other", "toxicity", "detection", "datasets", "using", "the", "metric", "of", "relative", "frequency", "of", "toxic", "utterances", "of", "each", "length.", "The", "datasets", "we", "compare", "with", "are", "1)", "Waseem", "(Waseem and Hovy, 2016)", "which", "consists", "of", "16.2k", "tweets", "binary", "classified", "as", "racism/sexism", "or", "other,", "2)", "FoxNews", "(Gao and Huang, 2017)", "which", "is", "1.5k", "sentences", "from", "Fox", "News", "discussion", "threads", "classified", "as", "hateful/non-", "The", "distribution", "in", "CONDA", "is", "different", "to", "the", "other", "datasets", "in", "that", "the", "toxic", "utterances", "are", "shorter.", "This", "is", "due", "to", "the", "terseness", "of", "in-game", "chat", "during", "playing,", "with", "longer", "utterances", "occurring", "in", "pregame", "and", "post-game", "discussion.", "Waseem", "has", "a", "particular", "distribution", "due", "to", "the", "character", "limit", "in", "Twitter", "(140", "characters", "at", "the", "time).", "FoxNews", "and", "StormfrontWS", "are", "forums", "which", "foster", "the", "use", "of", "longer", "sentences."], "cited_papers": [{"title": "Detecting online hate speech using context aware models", "year": "2017", "authors": ["Lei Gao", "Ruihong Huang"]}], "target_citation_location": 46, "citation_locations": [32, 46], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "769cf682-9464-4f37-8347-0b5be3235e57", "citing_paper": {"title": "Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model", "year": 2022, "authors": ["Richard Futrell"]}, "text": ["These", "co-occurrence", "probabilities", "are", "psycholinguistically", "relevant", "because", "they", "feed", "into", "information-theoretic", "measures", "of", "'thematic", "fit'", "and", "selectional", "restriction", "(Resnik, 1996, Lapata et al., 1999, Pad\u00f3 et al., 2007, Vecchi et al., 2017)", "which", "are", "relevant", "in", "predicting", "human", "online", "processing", "difficulty", "(e.g.", "McRae et al., 1998, Trueswell et al., 1994),", "and", "play", "a", "key", "role", "in", "language", "acquisition", "(Erickson and Thiessen, 2015).", "Most", "prominently,", "the", "widely-used", "pointwise", "mutual", "information", "(PMI)", "measure", "of", "association", "strength,", "PMI", "(w,", "c)", "=", "log", "p(w|c)", "p(w)", "(Fano, 1961, Church and Hanks, 1990),", "relies", "on", "these", "condi-tional", "probabilities", "as", "an", "input.", "PMI", "makes", "appearances", "in", "models", "of", "grammar", "induction", "from", "text", "(Magerman", "and", "Marcus, 1990, Yuret, 1998, Clark and Fijalkow, 2020, Hoover et al., 2021),", "online", "sentence", "comprehension", "and", "production", "(Futrell et al., 2020b, Ranjan et al., 2022),", "and", "quantitative", "theories", "of", "word", "order", "variation", "(Futrell et al., 2020a, Sharma et al., 2020)."], "cited_papers": [{"title": "Semantic influences on parsing: Use of thematic role information in syntactic ambiguity resolution", "year": "1994", "authors": ["C John", "unk Trueswell", "K Michael", "Susan Tanenhaus", "unk Garnsey"]}, {"title": "Modeling the influence of thematic fit (and other constraints) in on-line sentence comprehension", "year": "1998", "authors": ["Ken Mcrae", "J Michael", "Michael Spivey-Knowlton", "unk Tanenhaus"]}], "target_citation_location": 29, "citation_locations": [18, 29, 38, 58, 79, 85, 93], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "76a52b26-b465-484a-b1c5-87fa66db348f", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["Our", "departure", "point", "for", "this", "work", "has", "been", "the", "notion", "of", "an", "implicit", "argument", "of", "a", "noun,", "that", "is,", "nouns", "such", "as", "''brother''", "or", "''price''", "that", "are", "incomplete", "on", "their", "own,", "and", "require", "an", "argument", "to", "be", "complete.", "In", "linguistics,", "these", "are", "referred", "to", "as", "relational", "nouns", "(Partee, 1983 (Partee, /1997,, Loebner, 1985, Barker, 1995, De Bruin and Scha, 1988, Partee et al., 2000, L\u00f6bner, 2015, Newell and Cheung, 2018).", "In", "contrast,", "nouns", "like", "''plant'',", "or", "''sofa''", "are", "called", "sortal", "and", "are", "conceived", "as", "''complete'',", "their", "denotation", "need", "not", "rely", "on", "the", "relation", "to", "other", "nouns,", "and", "can", "be", "fully", "determined."], "cited_papers": [{"title": "Genitives, relational nouns, and the argument-modifier distinction", "year": "2000", "authors": ["Barbara Partee", "V Borschev"]}, {"title": "Possessive Descriptions, Dissertations in linguistics. Center for the Study of Language and Information", "year": "1995", "authors": ["Christian Barker"]}, {"title": "Functional concepts and frames", "year": "2015", "authors": ["Sebastian L\u00f6bner"]}, {"title": "Uniformity vs. versatility: The genitive, a case study", "year": "1983", "authors": ["Barbara Partee"]}, {"title": "The interpretation of relational nouns", "year": "1988", "authors": ["Jos De Bruin", "Remko Scha"]}, {"title": "Constructing a lexicon of relational nouns", "year": "2018", "authors": ["Edward Newell", "Jackie Cheung"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": null, "year": "1985", "authors": ["Sebastian Loebner"]}], "target_citation_location": 47, "citation_locations": [47], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "76e77210-dfaf-4e5d-8feb-b0a89dcbf609", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["The", "performance", "of", "QA", "models", "are", "evaluated", "using", "the", "Exact", "Match", "(EM)", "and", "F1", "scores.", "The", "EM", "score", "is", "the", "percentage", "of", "system", "outputs", "that", "match", "exactly", "with", "the", "ground", "truth", "answers.", "The", "F1", "score", "is", "a", "combined", "measure", "of", "precision", "and", "recall", "that", "is", "less", "strict", "than", "EM.", "The", "evaluation", "process", "3", "involves", "post-processing", "identical", "to", "that", "presented", "by", "d'Hoffschmidt", "et", "al.", "(2020)", "and", "inspired", "by", "that", "proposed", "for", "English", "by", "Rajpurkar et al. (2016),", "which", "consists", "of", "the", "removal", "of", "punctuation", "marks", "and", "determiners", "4", "as", "well", "as", "a", "down-casing", "of", "the", "answers", "(ground", "truths", "and", "predictions)."], "cited_papers": [{"title": "SQuAD: 100,000+ questions for machine comprehension of text", "year": "2016", "authors": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang"]}], "target_citation_location": 72, "citation_locations": [72], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "76fcdf32-b5e3-498e-b572-02d380e31df5", "citing_paper": {"title": "Entity Attribute Relation Extraction with Attribute-Aware Embeddings", "year": 2020, "authors": ["Dan Iter", "Xiao Yu", "Fangtao Li"]}, "text": ["The", "key", "insight", "of", "this", "paper", "is", "that", "entities", "that", "share", "many", "attributes", "are", "often", "similar.", "This", "is", "an", "extension", "of", "the", "distributional", "hypothesis,", "(Harris, 1954, Weeds and Weir, 2003),", "which", "states", "that", "words", "with", "similar", "semantic", "meanings", "tend", "to", "appear", "in", "similar", "contexts,", "and", "builds", "on", "work", "that", "use", "referential", "attributes", "to", "estimate", "semantic", "relatedness", "(Gupta et al., 2015, Freitas et al., 2013).", "For", "the", "attribute-aware", "embeddings,", "we", "argue", "that", "a", "good", "representation", "for", "an", "entity", "can", "be", "inferred", "from", "its", "most", "common", "attributes,", "which", "we", "may", "have", "access", "to", "from", "an", "external", "source", "of", "knowledge.", "In", "Figure", "1,", "we", "want", "to", "classify", "two", "candidate", "relations", "given", "the", "other", "known", "relations."], "cited_papers": [{"title": "The Structure of Language", "year": "1954", "authors": ["S Zellig", "unk Harris"]}, {"title": "A general framework for distributional similarity", "year": "2003", "authors": ["Julie Weeds", "David Weir"]}], "target_citation_location": 24, "citation_locations": [24, 51], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "776304f3-d01b-45e9-977c-70eaa7d7ad46", "citing_paper": {"title": "NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques", "year": 2021, "authors": ["Gunjan Chhablani", "Abheesht Sharma", "Harshit Pandey", "Yash Bhartia", "Shan Suthaharan"]}, "text": ["We", "use", "Integrated", "Gradients", "(Sundararajan et al., 2017)", "from", "the", "Captum", "(Kokhlikyan et al., 2020)", "library", "for", "qualitative", "analysis", "of", "predictions", "for", "the", "SpanBERT-SP,", "and", "the", "RoBERTa-TC", "models.", "We", "calculate", "Integrated", "Gradients", "of", "the", "targets", "with", "respect", "to", "the", "embedding", "layer", "outputs.", "The", "Riemann", "Right", "numerical", "approximation", "method", "is", "used,", "with", "n", "steps=50.", "Following", "Ramnath et al. (2020),", "we", "calculate", "token-wise", "importance", "distributions", "and", "word-wise", "distributions", "for", "a", "few", "examples.", "We", "refer", "the", "paper", "to", "the", "reader", "for", "more", "details."], "cited_papers": [{"title": "Captum: A unified and generic model interpretability library for pytorch", "year": "2020", "authors": ["Narine Kokhlikyan", "Vivek Miglani", "Miguel Martin", "Edward Wang", "Bilal Alsallakh", "Jonathan Reynolds", "Alexander Melnikov"]}], "target_citation_location": 8, "citation_locations": [4, 8, 48], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "77b7e195-be5d-4bc6-b8fd-5015586c56d4", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Another", "axis", "of", "development", "concerns", "the", "use", "of", "neural", "architecture", "search", "(Elsken et al., 2019)", "which", "allows", "to", "optimize", "a", "model", "by", "progressively", "modifying", "the", "design", "of", "the", "network", "through", "trial", "and", "error,", "eliminating", "insignificant", "operations.", "To", "avoid", "the", "unnecessary", "large", "number", "of", "parameters,", "adapters", "(Houlsby et al., 2019)", "were", "introduced", "to", "allow", "fine-tuning", "of", "the", "set", "of", "parameters", "specific", "to", "the", "task", "of", "interest", "rather", "than", "the", "entire", "model."], "cited_papers": [{"title": "Parameter-efficient transfer learning for nlp", "year": "2019", "authors": ["Neil Houlsby", "Andrei Giurgiu", "Stanislaw Jastrzebski", "Bruna Morrone", "Quentin De Laroussilhe", "Andrea Gesmundo", "Mona Attariyan", "Sylvain Gelly"]}], "target_citation_location": 42, "citation_locations": [11, 42], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "77edba3c-fd0d-4b9e-b680-d7246dc33749", "citing_paper": {"title": "On the weak link between importance and prunability of attention heads", "year": 2020, "authors": ["Aakriti Budhraja", "Madhura Pande", "Preksha Nema", "Pratyush Kumar", "Mitesh Khapra"]}, "text": ["We", "evaluate", "these", "experiments", "both", "on", "the", "Transformer", "and", "BERT", "models.", "Our", "results", "show", "that", "a", "large", "fraction", "of", "attention", "heads", "can", "be", "pruned", "randomly:", "75%", "of", "the", "attention", "heads", "of", "Transformer", "can", "be", "randomly", "pruned", "with", "a", "drop", "of", "less", "than", "1", "BLEU", "point", "on", "NMT", "tasks.", "Similarly,", "half", "of", "the", "attention", "heads", "of", "BERT", "can", "be", "randomly", "pruned", "with", "an", "average", "drop", "in", "accuracy", "of", "less", "than", "1%", "across", "a", "chosen", "set", "of", "GLUE", "tasks", "1.", "Significantly", "for", "Transformers,", "we", "find", "no", "evidence", "for", "pruning", "methods", "preferring", "specific", "attention", "heads", "based", "on", "their", "location,", "even", "when", "the", "locations", "are", "chosen", "to", "match", "attention", "heads", "identified", "to", "be", "more", "important", "in", "existing", "studies.", "Similarly", "on", "the", "BERT", "model,", "pruning", "top", "and", "bottom", "layers", "do", "not", "show", "significant", "difference,", "even", "though", "existing", "studies", "attribute", "higher", "importance", "to", "the", "latter", "(Sajjad et al., 2020).", "However,", "we", "identify", "a", "preference", "to", "avoid", "pruning", "the", "middle", "layers", "and", "consecutive", "layers.", "Lastly,", "we", "check", "if", "during", "fine-tuning", "certain", "heads", "compensate", "more", "for", "the", "pruned", "heads.", "If", "so,", "such", "heads", "would", "perhaps", "be", "more", "important.", "However,", "we", "find", "no", "such", "evidence.", "In", "particular,", "during", "fine-tuning,", "the", "un-pruned", "heads", "change", "similarly", "across", "most", "pruning", "configurations.", "Overall,", "our", "experiments", "suggest", "that", "interpretation", "of", "attention", "heads", "does", "not", "strongly", "inform", "pruning.", "The", "rest", "of", "the", "paper", "is", "organized", "as", "follows:", "Section", "2", "mentions", "about", "the", "models", "and", "the", "datasets", "used", "for", "this", "work", "followed", "by", "Section", "3", "which", "provides", "details", "of", "the", "experimental", "process.", "This", "section", "reports", "results", "on", "both", "Transformer", "and", "BERT", "models.", "We", "summarize", "our", "work", "in", "Section", "4."], "cited_papers": [{"title": "Poor man's bert: Smaller and faster transformer models", "year": "2020", "authors": ["Hassan Sajjad", "Fahim Dalvi", "Nadir Durrani", "Preslav Nakov"]}], "target_citation_location": 139, "citation_locations": [139], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "78664403-8a6d-4a13-9c4f-7cbc5bb63e6e", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Existing", "diversity-promoting", "methods", "only", "varied", "the", "language", "styles", "and", "failed", "to", "perform", "different", "knowledge", "reasoning", "to", "generate", "diverse", "contents", "(Cho et al., 2019, Shen et al., 2019, Holtzman et al., 2020).", "Here,", "incorporating", "commonsense", "KG", "is", "essential", "for", "the", "generative", "reasoning", "(GR)", "tasks", "because", "the", "KG", "cannot", "only", "augment", "the", "limited", "information", "in", "the", "input", "text,", "but", "also", "provide", "a", "rich", "searching", "space", "for", "knowledge", "reasoning.", "Therefore,", "we", "propose", "to", "employ", "commonsense", "KG", "to", "play", "the", "central", "role", "of", "performing", "diverse", "knowledge", "reasoning,", "then", "use", "different", "sets", "of", "selected", "concepts", "to", "produce", "diverse", "outputs."], "cited_papers": [{"title": "Mixture models for diverse machine translation: Tricks of the trade", "year": "2019", "authors": ["Tianxiao Shen", "Myle Ott", "Michael Auli", "Marc'aurelio Ranzato"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "Mixture content selection for diverse sequence generation", "year": "2019", "authors": ["Jaemin Cho", "Minjoon Seo", "Hannaneh Hajishirzi"]}], "target_citation_location": 19, "citation_locations": [19], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "78698375-e636-4cf9-9226-ea2d2ab57957", "citing_paper": {"title": "Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model", "year": 2022, "authors": ["Richard Futrell"]}, "text": ["Distributional", "similarity", "information", "has", "been", "used", "to", "improve", "modeling", "of", "word", "co-occurrence", "probabilities", "in", "previous", "work.", "Dagan et al. (1994 Dagan et al. ( , 1999) )", "defined", "a", "kernel-based", "interpolated", "language", "model", "where", "probability", "mass", "is", "explicitly", "spread", "over", "similar", "words,", "with", "variant", "models", "along", "these", "lines", "found", "in", "Wang et al. (2005)", "and", "Yarlett", "(2008).", "These", "models", "leverage", "similarity", "information", "about", "target", "words", "but", "not", "context", "words.", "In", "contrast,", "B\u00edr\u00f3 et al. (2007)", "proposed", "a", "method", "which", "uses", "similarity", "information", "about", "the", "context", "word", "but", "not", "the", "target", "word.", "Toutanova et al. (2004)", "developed", "a", "method", "that", "can", "exploit", "similarity", "information", "about", "both", "target", "and", "context,", "using", "a", "Markov", "Chain", "algorithm", "incorporating", "distributional", "and", "WordNet", "similarities.", "None", "of", "this", "previous", "work", "derived", "word", "similarity", "information", "from", "pretrained", "embeddings,", "because", "such", "embeddings", "did", "not", "exist", "at", "the", "time."], "cited_papers": [{"title": "Sequence prediction exploiting similarity information", "year": "2007", "authors": ["Istv\u00e1n B\u00edr\u00f3", "Zolt\u00e1n Szamonek", "Csaba Szepesv\u00e1ri"]}], "target_citation_location": 58, "citation_locations": [16, 40, 43, 58, 75], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "78a1cfaa-566e-4d7f-b70a-e8e30e6fa66d", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["Translation-based", "features", "Capturing", "semantic", "relationships", "between", "a", "query", "and", "a", "document", "is", "also", "crucial", "to", "improving", "retrieval", "accuracy.", "To", "incorporate", "such", "features,", "we", "can", "use", "a", "translation", "model", "(Boytsov and Nyberg, 2020, Boytsov and Kolter, 2021)", "to", "measure", "the", "log", "translation", "probability", "between", "queries", "and", "documents.", "The", "conditional", "probability", "we", "need", "p(q|d", "n)", "is", "generated", "by", "the", "IBM", "Model", "1", "translation", "model,", "and", "the", "final", "query-document", "feature", "is", "the", "sum", "of", "all", "individual", "conditional", "query", "probabilities."], "cited_papers": [{"title": "Exploring classic and neural lexical translation models for information retrieval: Interpretability, effectiveness, and efficiency benefits", "year": "2021", "authors": ["Leonid Boytsov", "Zico Kolter"]}, {"title": null, "year": "2020", "authors": ["Leonid Boytsov", "Eric Nyberg"]}], "target_citation_location": 28, "citation_locations": [28], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "78bf0a46-4a12-491a-833c-c17715bd0ea5", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["Another", "option", "for", "using", "O2O", "models", "is", "to", "output", "multiple", "sequences", "as", "a", "single", "sequence", "instead", "of", "using", "conditional", "chain", "mapping,", "as", "shown", "in", "Fig.", "1(c).", "For", "example,", "in", "(Audhkhasi et al., 2018),", "the", "O2O", "model", "produces", "word", "transcripts", "by", "first", "generating", "a", "word's", "constituent", "graphemes", "followed", "by", "the", "word", "itself.", "Another", "application,", "explored", "in", "(Shafey et al., 2019)", "used", "the", "O2O", "model", "to", "produce", "graphemes", "followed", "by", "speaker", "role.", "This", "approach", "is", "the", "simplest", "to", "implement", "because", "we", "can", "reuse", "the", "neural", "network", "architecture", "used", "to", "produce", "the", "primary", "sequence", "to", "sequence", "mapping", "to", "produce", "the", "secondary", "label", "sequence", "(e.g.,", "connectionist", "temporal", "classification", "(CTC)", "based", "systems).", "In", "contrast", "to", "the", "previous", "two", "approaches,", "the", "O2O", "model", "does", "not", "require", "postprocessing", "to", "align", "the", "label", "sequences", "during", "inference", "since", "the", "output", "sequence", "preserves", "the", "alignment", "between", "the", "word", "and", "corresponding", "annotation", "labels,", "alignment", "is", "only", "needed", "for", "the", "data", "preparation", "stage", "during", "training", "to", "produce", "the", "appropriate", "target", "sequences.", "For", "this", "reason,", "we", "used", "the", "O2O", "model", "in", "this", "study.", "This", "paper", "proposes", "to", "use", "a", "state-of-the-art", "Transformer-based", "E2E", "ASR", "system", "(Karita et al., 2019)", "for", "the", "O2O", "model", "with", "a", "single", "sequence,", "instead", "of", "CTC-based", "approaches", "which", "are", "frequently", "supported", "(Audhkhasi et al., 2018, Ghannay et al., 2018).", "Compared", "with", "the", "CTC-based", "systems,", "this", "approach", "can", "explicitly", "model", "the", "relationship", "between", "the", "output", "labels", "thanks", "to", "the", "autoregressive", "decoder", "network,", "similar", "to", "the", "conditional", "chain", "rule", "model", "in", "Fig.", "1(b).", "We", "also", "demonstrate", "improved", "performance", "compared", "to", "the", "CTC-based", "systems.", "Another", "contribution", "is", "that", "we", "conducted", "an", "extensive", "empirical", "evaluation", "to", "analyze", "and", "demonstrate", "the", "utility", "of", "our", "approach.", "For", "example,", "we", "applied", "the", "method", "to", "English", "and", "Japanese", "ASR", "tasks", "in", "which", "phonemic", "transcripts", "and", "POS", "tags", "are", "simultaneously", "produced.", "Our", "approach", "predicts", "linguistic", "annotations", "correctly", "even", "though", "corresponding", "graphemes", "are", "wrong,", "while", "the", "pipeline", "approach,", "in", "which", "NLP-based", "methods", "are", "applied", "to", "a", "hypothesized", "ASR", "transcript,", "fails.", "This", "feature", "is", "helpful", "for", "the", "downstream", "NLP", "system", "like", "slot", "filling", "or", "intent", "detection.", "Besides,", "our", "approach", "is", "suitable", "for", "on-device", "applications", "because", "the", "E2E", "model", "archives", "small-footprint", "prediction", "(Pang et al., 2018).", "Note", "that", "our", "primary", "goal", "is", "to", "provide", "aligned", "transcripts", "and", "linguistic", "annotations", "with", "minimal", "degradation", "in", "ASR", "performance.", "We", "are", "not", "aiming", "to", "improve", "ASR", "performance.", "The", "features", "of", "the", "proposed", "method", "are", "summarized", "as", "follows:"], "cited_papers": [{"title": "Building competitive direct acoustics-to-word models for english conversational speech recognition", "year": "2018", "authors": ["K Audhkhasi", "B Kingsbury", "B Ramabhadran", "G Saon", "M Picheny"]}, {"title": "Endto-end named entity and semantic concept extraction from speech", "year": "2018", "authors": ["S Ghannay", "A Caubri\u00e8re", "Y Est\u00e8ve", "N Camelin", "E Simonnet", "A Laurent", "E Morin"]}], "target_citation_location": 192, "citation_locations": [29, 52, 175, 192, 334], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "78e20995-f5d1-4e7c-b46f-a630a4e901e6", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["All", "models", "use", "the", "SHIBA", "implementation", "of", "CA-NINE", "(Tanner and Hagiwara, 2021).", "SHIBA", "was", "designed", "for", "use", "on", "the", "Japanese", "[jpn]", "language,", "which", "does", "not", "include", "spaces", "between", "its", "characters", "(similar", "to", "our", "phonetic", "representations", "without", "word", "boundaries).", "We", "used", "the", "default", "hyperparameter", "settings", "for", "SHIBA", "pre-training", "and", "finetuning,", "because", "we", "are", "primarily", "concerned", "with", "the", "relative", "impact", "of", "various", "combinations", "of", "pretraining", "data", "on", "the", "downstream", "NER", "tasks.", "We", "use", "the", "Hugging", "Face", "transformers", "library", "(Wolf et al., 2020)", "to", "train", "all", "models."], "cited_papers": [{"title": "Transformers: State-of-the-art natural language processing", "year": "2020", "authors": ["Thomas Wolf", "Lysandre Debut", "Victor Sanh", "Julien Chaumond", "Clement Delangue", "Anthony Moi", "Pierric Cistac", "Tim Rault", "Rmi Louf", "Morgan Funtowicz", "Joe Davison", "Sam Shleifer", "Clara Patrick Von Platen", "Yacine Ma", "Julien Jernite", "Canwen Plu", "Teven Xu", "Sylvain Scao", "Mariama Gugger", "Quentin Drame", "Alexander Lhoest", "unk Rush"]}], "target_citation_location": 73, "citation_locations": [8, 73], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2]]}
{"id": "7916c898-1260-4995-ba15-95fe15dc3ad6", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["We", "compare", "with", "the", "following", "baselines", "that", "do", "not", "consider", "conditioned", "generation:", "(1)", "Seqto-Seq", "(Budzianowski et al., 2018)", "implemented", "based", "on", "transformer", "(Vaswani et al., 2017),", "(2)", "TSCP", "(Lei et al., 2018),", "and", "two", "baselines", "that", "adopt", "latent", "action", "learning", "for", "conditioned", "generation:", "(3)", "LaRL", "(Zhao et al., 2019),", "(4)", "MALA", "(Huang et al., 2020a).", "Note", "that", "for", "these", "two", "approaches,", "we", "experiment", "with", "both", "discrete", "and", "continuous", "latent", "action", "representations.", "We", "also", "compare", "the", "full", "model", "MASP", "with", "its", "two", "variants:", "(1)", "Post-hoc", "Saliency", "obtains", "action", "representations", "via", "the", "importance", "attribution", "technique", "as", "Jin et al. (2020),", "(2)", "Memory-based", "Saliency", "employs", "the", "same", "memory", "component", "as", "MASP", "but", "trained", "without", "the", "pseudo", "parallel", "corpus."], "cited_papers": [{"title": "Towards hierarchical importance attribution: Explaining compositional semantics for neural sequence models", "year": "2020", "authors": ["Xisen Jin", "Junyi Du", "Zhongyu Wei", "Xiangyang Xue", "Xiang Ren"]}], "target_citation_location": 79, "citation_locations": [14, 19, 22, 36, 39, 79], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "794f8d7f-63d2-4134-8977-927b0e7ef557", "citing_paper": {"title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation", "year": 2021, "authors": ["Hansi Hettiarachchi", "Tharindu Ranasinghe"]}, "text": ["Words'", "semantics", "have", "a", "dynamic", "nature", "which", "depends", "on", "the", "surrounding", "context", "(Pilehvar and Camacho-Collados, 2019).", "Therefore,", "the", "majority", "of", "words", "tends", "to", "be", "polysemous", "(i.e.", "have", "multiple", "senses).", "For", "few", "examples,", "words", "such", "as", "\"cell\",", "\"bank\"", "and", "\"report\"", "can", "be", "mentioned.", "Due", "to", "this", "nature", "in", "natural", "language,", "it", "is", "important", "to", "focus", "on", "word-in-context", "sense", "while", "extracting", "the", "meaning", "of", "a", "word", "which", "appeared", "in", "a", "text", "segment.", "Also,", "this", "is", "a", "critical", "requirement", "to", "many", "applications", "such", "as", "question", "answering,", "document", "summarisation,", "information", "retrieval", "and", "information", "extraction."], "cited_papers": [{"title": "Wic: the word-in-context dataset for evaluating context-sensitive meaning representations", "year": "2019", "authors": ["Mohammad Taher Pilehvar", "Jose Camacho-Collados"]}], "target_citation_location": 12, "citation_locations": [12], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "796e9c48-ebb3-49bb-9cc7-a34a3d257a01", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["We", "experiment", "with", "the", "validation", "split", "on", "a", "single", "RTX", "3090,", "and", "measure", "the", "average", "running", "time", "per", "example.", "As", "shown", "in", "Table", "6,", "SO-Beam", "runs", "faster", "than", "SO-Enum", "since", "it", "utilizes", "the", "probability", "output.", "The", "running", "time", "may", "increase", "if", "the", "model", "has", "improved", "second-order", "robustness.", "A.4", "Additional", "Results", "on", "Protected", "Tokens", "Fig.", "7", "presents", "the", "experimental", "results", "with", "additional", "protected", "tokens", "such", "as", "nationality,", "religion,", "and", "sexual", "orientation", "(from", "Ribeiro", "et", "al.", "(2020)).", "We", "use", "the", "same", "base", "LSTM", "as", "described", "in", "\u00a74.2.", "One", "interesting", "observation", "is", "when", "p", "=", "(gay,", "straight)", "where", "the", "bias", "is", "negative,", "indicating", "that", "the", "sentiment", "classifier", "tends", "to", "give", "more", "negative", "prediction", "when", "substituting", "gay", "\u2192", "straight", "in", "the", "input.", "This", "phenomenon", "is", "opposite", "to", "the", "behavior", "of", "toxicity", "classifiers", "(Dixon et al., 2018),", "and", "we", "hypothesize", "that", "it", "may", "be", "caused", "by", "the", "different", "distribution", "of", "training", "data.", "To", "verify", "the", "hypothesis,", "we", "count", "the", "number", "of", "training", "examples", "containing", "each", "word,", "and", "observe", "that", "we", "have", "far", "more", "negative", "examples", "than", "positive", "examples", "among", "those", "containing", "straight", "(Table", "7).", "After", "looking", "into", "the", "training", "set,", "it", "turns", "out", "that", "straight", "to", "video", "is", "a", "common", "phrase", "to", "criticize", "a", "film,", "thus", "the", "classifier", "incorrectly", "correlates", "straight", "with", "negative", "sentiment.", "This", "also", "reveals", "the", "limitation", "of", "our", "method", "on", "polysemous", "words.", "In", "Fig.", "8,", "we", "measure", "the", "bias", "on", "X", "test", "and", "observe", "positive", "bias", "on", "most", "tokens", "for", "both", "k", "=", "0", "and", "k", "=", "3,", "which", "indicates", "that", "the", "model", "\"tends\"", "to", "make", "more", "positive", "predictions", "for", "examples", "containing", "certain", "female", "pronouns", "than", "male", "pro-", "nouns.", "Notice", "that", "even", "though", "gender", "swap", "mitigates", "the", "bias", "to", "some", "extent,", "it", "is", "still", "difficult", "to", "fully", "eliminate", "the", "bias.", "This", "is", "probably", "caused", "by", "tuples", "like", "(him,", "his,", "her)", "which", "cannot", "be", "swapped", "perfectly,", "and", "requires", "additional", "processing", "such", "as", "part-of-speech", "resolving", "(Zhao et al., 2018a).", "To", "help", "evaluate", "the", "naturalness", "of", "our", "constructed", "examples", "used", "in", "\u00a74,", "we", "provide", "sample", "sentences", "in", "Table", "9", "and", "Table", "10.", "Bold", "words", "are", "the", "corresponding", "patch", "words", "p,", "taken", "from", "the", "predefined", "list", "of", "gendered", "pronouns."], "cited_papers": [{"title": "Measuring and mitigating unintended bias in text classification", "year": "2018", "authors": ["Lucas Dixon", "John Li", "Jeffrey Sorensen", "Nithum Thain", "Lucy Vasserman"]}], "target_citation_location": 128, "citation_locations": [128, 308], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7996be5b-46a4-4a39-9ed3-603f91d7b8f9", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["Paraphrase", "Here", "we", "use", "an", "example,", "(4),", "from", "Dras (1999),", "where", "paraphrases", "are", "represented", "by", "pairing", "TAG", "derivation", "trees", "(Figure", "5).", "This", "is", "again", "similar", "to", "the", "previous", "MT", "examples:", "in", "order", "to", "define", "a", "paraphrase", "where", "the", "most", "embedded", "clause", "becomes", "a", "separate", "sentence,", "it", "is", "necessary", "to", "form", "a", "gNCN", "(those", "nodes", "in", "bold", "in", "Figure", "5)."], "cited_papers": [{"title": "A meta-level grammar: redefining Synchronous TAG for translation and paraphrase", "year": "1999", "authors": ["M Dras"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "79a2f9e8-9b64-4e34-b4a4-7668862dc5c5", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["Lee", "and", "Na", "(2022)", "(JBNU-CCLab)", "achieved", "their", "state-of-the-art", "performance", "using", "SciBERT", "(Beltagy et al., 2019).", "Their", "entity", "model", "consists", "of", "an", "MRC-based", "model", "(Li et al., 2020),", "simplifying", "the", "tasks", "as", "binary", "classification", "problems", "whether", "span", "is", "valid", "using", "entity", "type", "information", "as", "input", "features.", "They", "proposed", "a", "simple", "rule-based", "Symbol", "Tokenizer", "to", "predict", "accurately", "the", "complex", "symbols", "appearing", "in", "scientific", "documents.", "The", "relation", "model", "exploits", "entity", "span", "information", "and", "entity", "type", "information", "as", "input", "features", "using", "typed", "entity", "marker.", "Additionally,", "the", "paper", "ex-ploited", "many", "regularization", "techniques", "to", "improve", "the", "model", "performance", "such", "as", "regularized", "dropout", "(Wu et al., 2021)", "and", "representational", "collapse", "prevention", "(Aghajanyan et al., 2020)", "and", "traditional", "ensemble", "techniques."], "cited_papers": [{"title": "A unified MRC framework for named entity recognition", "year": "2020", "authors": ["Xiaoya Li", "Jingrong Feng", "Yuxian Meng", "Qinghong Han", "Fei Wu", "Jiwei Li"]}], "target_citation_location": 20, "citation_locations": [11, 20, 90, 95], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "79d3482f-d9d9-47a5-814f-532bd4ab19c5", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["After", "the", "annotations", "were", "extracted", "from", "the", "database,", "the", "data", "needed", "to", "be", "cleaned", "up.", "The", "different", "evaluations", "required", "different", "pre-processing", "steps.", "Most", "commonly,", "this", "included", "the", "removal", "of", "superfluous", "characters", "containing", "no", "information.", "We", "tried", "to", "keep", "as", "much", "of", "the", "original", "information", "as", "possible,", "including", "keeping", "offensive,", "racist,", "and", "sexist", "language", "as", "is.", "If", "such", "information", "is", "removed,", "the", "usefulness", "of", "the", "data", "is", "at", "risk", "of", "being", "reduced,", "particularly", "when", "used", "for", "e.g.", "offensive", "language", "detection", "(P\u00e0mies et al., 2020)."], "cited_papers": [{"title": "LT@Helsinki at SemEval-2020 Task 12: Multilingual or language-specific BERT?", "year": "2020", "authors": ["Marc P\u00e0mies", "Emily \u00d6hman", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}], "target_citation_location": 79, "citation_locations": [79], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1]]}
{"id": "79d402b3-1249-4691-a298-1d59bee993c4", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["Accurate", "enough", "parse", "selection", "for", "practical", "applications", "will", "require", "a", "more", "lexic.", "alised", "system.", "Magerman's ( 1995)", "parser", "is", "an", "extension", "of", "the", "history-based", "parsing", "approach", "devel", "oped", "at", "IBM", "(e.g.", "Black, 1993)", "in", "which", "rules", "are", "conditioned", "on", "lexical", "and", "other", "(essentially", "arbitrary)", "information", "available", "in", "the", "parse", "history.", "In", "future", "work,", "we", "intend", "to", "explore", "a", "more", "restricted", "and", "semantically-driven", "version", "of", "this", "approach", "in", "which,", "firstly,", "probabilities", "are", "associated", "with", "different", "subcategorisation", "possibilities,", "and", "secondly,", "alternative", "predicate", "argument", "structures", "derived", "from", "the", "grammar", "are", "ranked", "probabilistically.", "However,", "the", "mas", "sively", "increased", "coverage", "obtained", "here", "by", "relaxing", "subcategorisation", "constraints", "underlines", "the", "need", "to", "acquire", "accurate", "and", "complet\ufffd", "subcategorisation", "frames", "in", "a", "corpus-driven", "fas", "hion,", "before", "such", "constraints", "can", "be", "exploited", "robustly", "and", "effectively", "with", "free", "text."], "cited_papers": [{"title": "Statistically-Driven Computer Grammars of English: The IBM/ Lancaster Approach", "year": "1993", "authors": ["E Black", "R Garside", "G Leech"]}], "target_citation_location": 29, "citation_locations": [14, 29], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7a50d6ed-fbff-4e1b-b5db-cb53f68fd79f", "citing_paper": {"title": "Associating semantic components with intersective Levin classes", "year": 1997, "authors": ["Hoa Dang", "Joseph Rosenzweig", "Martha Palmer"]}, "text": ["In", "this", "paper", "we", "have", "presented", "a", "more", "fine-grained", "analysis", "of", "the", "Levin", "classes", "which", "highlights", "the", "semantic", "components", "entailed", "by", "certain", "syntactic", "frames,", "and", "hence", "the", "semantic", "components", "of", "entire", "classes", "of", "verbs.", "We", "hypothesize", "that", "the", "semantic", "components", "we", "are", "identifying", "will", "be", "useful", "for", "cross-linguistic", "generalizations.", "An", "important", "avenue", "of", "future", "research", "which", "we", "intend", "to", "explore", "is", "the", "comparison", "of", "the", "translations", "of", "these", "classes", "to", "independently-defined", "classes", "in", "other", "languages,", "such", "as", "French", "verb", "classes", "[7]", "or", "European", "WordNet.", "3", "These", "cross-linguistic", "generalizations", "will", "be", "equally", "valuable", "for", "both", "transfer-based", "and", "interlinguabased", "approaches", "to", "machine", "translation.", "Presumably", "both", "approaches", "need", "to", "be", "augmented", "with", "pragmatic", "information", "about", "tense", "and", "aspect", "and", "information", "structure,", "in", "particular", "coreference,", "in", "order", "to", "provide", "an", "adequate", "basis", "for", "translation", "in", "many", "circumstances.", "It", "could", "be", "argued", "that", "a", "language-specific", "predicate-argument", "structure", "will", "lend", "itself", "more", "readily", "to", "language-specific", "pragmatic", "annotation", "than", "a", "language-independent", "one,", "but", "it", "would", "still", "be", "necessary", "to", "ensure", "that", "the", "pragmatic", "annotation", "was", "meaningful", "in", "the", "target", "languages", "as", "well,", "i.e.,", "cross-linguistic.", "The", "discovery", "of", "cross-linguistic", "pragmatic", "features", "is", "an", "equally", "important", "area", "for", "future", "research."], "cited_papers": [{"title": "Organisation du lexique-grammaire des verbes fran\u00e7ais", "year": "1990", "authors": ["Christian Leclerc"]}], "target_citation_location": 80, "citation_locations": [80], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7a57dee6-9911-4351-b4e1-eea1c98188b5", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["To", "verify", "that", "the", "plug-and-play", "property", "of", "topk", "attention", "also", "holds", "at", "self-attention", "layers,", "we", "downloaded", "a", "BERT-large-uncased-whole-wordmasking", "checkpoint", "(Devlin et al., 2019)", "already", "fine-tuned", "on", "SQuAD", "v1", "(Rajpurkar et al., 2016)", "and", "evaluated", "its", "performance", "on", "the", "development", "set", "before", "and", "after", "replacing", "its", "self-attention", "layers", "with", "top-k", "attention.", "For", "k", "as", "low", "as", "16", "(4%", "of", "input", "length),", "we", "only", "saw", "a", "minor", "decrease", "in", "the", "exact", "match", "scores", "(86.9", "\u2192", "86.2).", "Moreover,", "to", "empirically", "verify", "that", "dense", "approximations", "of", "vanilla", "attention", "(Performer,", "RFA,", "etc)", "indeed", "require", "corrective", "pre-training,", "we", "repeated", "the", "measurement", "using", "Performer", "attention", "with", "256", "features,", "obtaining", "a", "score", "of", "0.38."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 19, "citation_locations": [19, 25], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7acdb690-770e-495e-80c1-fd548309f0f9", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["Given", "an", "input", "sentence", "x", "0,", "we", "want", "to", "find", "patch", "words", "p", "and", "a", "vulnerable", "example", "x0", "such", "that", "f", "(x", "0", "\u2295", "p)", "=", "f", "(x", "0", ").", "Follow", "Alzantot et al. (2018),", "we", "choose", "p", "from", "a", "predefined", "list", "of", "counter-fitted", "synonyms", "(Mrk\u0161i\u0107 et al., 2016)", "that", "maximizes", "|f", "soft", "(p", "(2))", "\u2212", "f", "soft", "(p", "(1)", ")|.", "Here", "f", "soft", "(x):", "X", "\u2192", "[0,", "1]", "denotes", "probability", "output", "(e.g.,", "after", "the", "softmax", "layer", "but", "before", "the", "final", "argmax),", "f", "soft", "(p", "(1))", "and", "f", "soft", "(p", "(2))", "denote", "the", "predictions", "for", "the", "single", "word,", "and", "we", "enumerate", "through", "all", "possible", "p", "for", "x", "0.", "Let", "k", "be", "the", "neighborhood", "distance,", "then", "the", "attack", "is", "equivalent", "to", "solving:x0", "=", "argmax", "x\u2208Neighbor", "k", "(x", "0)", "|F", "(x,", "p)|.(3)"], "cited_papers": [{"title": "Counter-fitting word vectors to linguistic constraints", "year": "2016", "authors": ["Nikola Mrk\u0161i\u0107", "\u00d3 Diarmuid", "Blaise S\u00e9aghdha", "Milica Thomson", "Lina Ga\u0161i\u0107", "Pei-Hao Rojas-Barahona", "David Su", "Tsung-Hsien Vandyke", "Steve Wen", "unk Young"]}], "target_citation_location": 42, "citation_locations": [31, 42], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7bc4421b-a0db-4f66-b331-dcdcd20aee8b", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["For", "comparison", "with", "previous", "research", "(Osterhout et al., 1997, M\u00fcnte et al., 2001),", "we", "decoded", "word", "length,", "frequency", "and", "class", "with", "linear", "SVMs", "in", "a", "temporally-resolved", "fashion", "from", "0", "to", "700", "ms", "poststimulus", "EEG,", "recorded", "during", "sentence", "reading."], "cited_papers": [{"title": "Differences in brain potentials to open and closed class words: class and frequency effects", "year": "2001", "authors": ["unk Thomas F M\u00fcnte", "M Bernardina", "Helga Wieringa", "Andras Weyerts", "Mike Szentkuti", "S\u00f6nke Matzke", "unk Johannes"]}, {"title": "Brain potentials elicited by words: word length and frequency predict the latency of an early negativity", "year": "1997", "authors": ["Lee Osterhout", "Michael Bersick", "Richard Mckinnon"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "group", "annotations": [[2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "7be4ceed-0718-4acf-8859-a6b7a3ebec38", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["EEG", "signals", "were", "extracted", "from", "-100", "to", "700", "ms", "relative", "to", "word", "onset.", "For", "baseline", "correction,", "we", "subtracted", "the", "channel-wise", "mean", "from", "-100", "ms", "to", "0", "ms", "from", "the", "evoked", "post-stimulus", "EEG", "response", "([0", "700]", "ms", "separately", "for", "each", "word,", "see", "Figure", "1).", "EEG", "data", "were", "spatially", "multivariate", "noise", "normalised", "using", "the", "noise", "covariance", "matrix", "estimated", "separately", "for", "each", "target", "class", "(Guggenmos et al., 2018).", "Each", "EEG", "trial", "was", "annotated", "with", "the", "gold", "part", "of", "speech", "tags", "of", "the", "current", "and", "subsequent", "words,", "their", "word", "lengths,", "and", "Zipf-logarithmic", "frequency", "scores", "from", "the", "Python", "package", "WordFreq", "(Speer et al., 2018)."], "cited_papers": [{"title": "Multivariate pattern analysis for meg: A comparison of dissimilarity measures", "year": "2018", "authors": ["Matthias Guggenmos", "Philipp Sterzer", "Radoslaw Martin Cichy"]}], "target_citation_location": 61, "citation_locations": [61, 92], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7c17508d-7eaf-4cfd-9b7f-fcae91e3b7a3", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["cosine", "similarity", "in", "GloVe", "(Pennington et al., 2014a),"], "cited_papers": [{"title": "GloVe: Global vectors for word representation", "year": "2014", "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning"]}], "target_citation_location": 4, "citation_locations": [4], "citation_type": "single", "annotations": [[2, 2, 2, 1, 1]]}
{"id": "7cde2ed7-1480-4906-bd09-ace84e922784", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["In", "areas", "such", "as", "image", "processing,", "the", "same", "question", "has", "been", "receiving", "a", "lot", "of", "attention", "and", "inspired", "a", "wave", "of", "methods", "for", "learning", "and", "evaluating", "unsupervised", "representation", "disentanglement", "(Ross and Doshi-Velez, 2021, Mathieu et al., 2019, Kim and Mnih, 2018, Burgess et al., 2018, Higgins et al., 2018 Higgins et al., , 2017) )", "and", "creation", "of", "large", "scale", "datasets", "(Dittadi et al., 2021).", "It", "has", "been", "argued", "that", "disentanglement", "is", "the", "means", "towards", "representation", "interpretability", "(Mathieu et al., 2019),", "generalization", "(Montero et al., 2021),", "and", "robustness", "(Bengio et al., 2013, Bengio, 2013).", "However,", "these", "benefits", "are", "yet", "to", "be", "realized", "and", "evaluated", "in", "text", "domain."], "cited_papers": [{"title": "Disentangling disentanglement in variational autoencoders", "year": "2019", "authors": ["Emile Mathieu", "Tom Rainforth", "Yee Whye Siddharth", "unk Teh"]}, {"title": "Benchmarks, algorithms, and metrics for hierarchical disentanglement", "year": "2021", "authors": ["Andrew Slavin Ross", "Finale Doshi-Velez"]}, {"title": "Disentangling by factorising", "year": "2018", "authors": ["Hyunjik Kim", "Andriy Mnih"]}, {"title": "beta-vae: Learning basic visual concepts with a constrained variational framework", "year": "2017", "authors": ["Irina Higgins", "Lo\u00efc Matthey", "Arka Pal", "Christopher Burgess", "Xavier Glorot", "Matthew Botvinick", "Shakir Mohamed", "Alexander Lerchner"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "Understanding disentangling in \u03b2-vae", "year": "2018", "authors": ["Christopher Burgess", "Irina Higgins", "Arka Pal", "Lo\u00efc Matthey", "Nick Watters", "Guillaume Desjardins", "Alexander Lerchner"]}], "target_citation_location": 29, "citation_locations": [29, 36, 49, 51, 54], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7d06ec80-091d-4a24-947d-012da3973b9b", "citing_paper": {"title": "Can Semantic Role Labeling Improve SMT?", "year": 2009, "authors": ["Dekai Wu", "Pascale Fung"]}, "text": ["Semantic", "parsers", "analyze", "a", "sentence", "with", "the", "aim", "of", "identifying", "the", "\"who", "did", "what", "to", "whom,", "for", "whom", "or", "what,", "how,", "where,", "when,", "and", "why.\"", "Shallow", "semantic", "parsing", "extracts", "the", "predicateargument", "structure", "of", "verbs", "in", "a", "sentence", "based", "on", "the", "syntactic", "tree", "of", "that", "sentence.", "For", "example,", "the", "predicate", "argument", "structure", "of", "the", "verb", "hold", "in", "Figure", "1", "specifies", "a", "\"holding\"", "relation", "between", "both", "sides", "(who)", "and", "meeting", "(what)", "on", "Sunday", "(when).", "For", "a", "sentence", "with", "multiple", "verbs,", "there", "can", "be", "multiple", "predicate", "argument", "structures.", "Shallow", "semantic", "parsing", "systems", "are", "mostly", "based", "on", "classifiers", "that", "learn", "from", "a", "manually", "annotated", "semantic", "corpus", "(Gildea and Jurafsky (2002),", "Pradhan et al. (2005)", ").", "Following", "the", "publication", "of", "the", "Proposional", "Bank", "(PropBank)", "(Palmer et al., 2005)", "first", "in", "English,", "then", "in", "Chinese,", "it", "has", "been", "possible", "to", "train", "these", "classifiers", "to", "perform", "semantic", "analysis", "on", "news", "wire", "type", "of", "texts."], "cited_papers": [{"title": "Automatic labeling of semantic roles", "year": "2002", "authors": ["Daniel Gildea", "Dan Jurafsky"]}], "target_citation_location": 102, "citation_locations": [102, 103, 113], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7d355f51-680c-4191-8865-2cc817a607ec", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["To", "deal", "with", "toxic", "comments,", "most", "approaches", "adopt", "supervised-machine", "learning", "techniques", "and", "are", "mainly", "focused", "on", "the", "English", "language", "(Poletto et al., 2020).", "These", "approaches", "range", "from", "surface-level", "features,", "as", "Bag-Of-Words", "(Paiva et al., 2019),", "linguistics", "features,", "as", "Part-Of-Speech", "information", "(Chen et al., 2012),", "deep", "neural", "networks,", "as", "Long", "Short-Term", "Memory", "(LSTM)", "(Fortuna et al., 2019)", "and", "Convolutional", "Neural", "Networks", "(CNN)", "(Badjatiya et al., 2017)", "to", "Transformer", "architectures", "(Leite et al., 2020).", "Despite", "interesting", "results", "achieved", "by", "Transformer", "architectures,", "there", "are", "still", "several", "rooms", "to", "be", "explored", "in", "this", "research", "area."], "cited_papers": [{"title": "Resources and benchmark corpora for hate speech detection: a systematic review", "year": "2020", "authors": ["Fabio Poletto", "Valerio Basile", "Manuela Sanguinetti", "Cristina Bosco", "Viviana Patti"]}], "target_citation_location": 19, "citation_locations": [19, 28, 34, 43, 49, 53], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7df4a0fa-eb5f-4bd3-b801-da53846df3c7", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Automatically", "translating", "the", "context,", "question", "and", "answer", "triples", "from", "a", "high-resource", "language,", "such", "as", "English", "(called", "source", "domain)", "to", "lowresource", "languages", "(called", "target", "domains)", "have", "enabled", "the", "evaluation", "of", "models", "for", "languages", "with", "no", "training", "data", "available", "but", "also", "the", "creation", "of", "large-scale", "MT-based", "QA", "corpora", "for", "the", "Italian", "(Croce et al., 2018 ), Spanish (Carrino et al., 2020),", "Arabic", "(Mozannar et al., 2019)", "and", "Korean", "(Youngmin", "Kim,", "2020)", "languages."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Neural learning for question answering in italian", "year": "2018", "authors": ["Danilo Croce", "Alexandra Zelenanska", "Roberto Basili"]}], "target_citation_location": 49, "citation_locations": [49, 51], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "7e481786-4496-470e-ba5e-03b98966fb70", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["To", "alleviate", "the", "issue,", "we", "add", "a", "special", "tag", "for", "the", "BT", "data", "(Caswell et al., 2019).", "With", "BT[t],", "we", "send", "a", "signal", "to", "the", "model", "that", "it", "is", "processing", "synthetic", "data,", "and", "thus,", "it", "may", "not", "hurt", "the", "learning", "over", "the", "real", "data.", "Table", "2", "(rows", "(c,g))", "shows", "the", "results."], "cited_papers": [{"title": "Tagged back-translation", "year": "2019", "authors": ["Isaac Caswell", "Ciprian Chelba", "David Grangier"]}], "target_citation_location": 13, "citation_locations": [13], "citation_type": "single", "annotations": [[3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7e773b92-eeb7-46a9-b044-232ec739f5e6", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["Previous", "studies", "on", "symbol-description", "extraction", "rely", "on", "pattern", "matching", "(Yokoi et al., 2011, Nghiem Quoc et al., 2010)", "and", "rule-based", "algorithms", "(Alexeeva et al., 2020).", "These", "methods", "might", "work", "for", "observed", "patterns", "with", "an", "assumption", "of", "close", "proximity", "between", "symbol", "and", "description.", "They", "may", "fail", "to", "capture", "distant", "symboldescription", "pairs", "and", "symbols", "in", "very", "complex", "structures", "such", "as", "algorithms", "in", "computer", "science", "literature."], "cited_papers": [{"title": "Contextual analysis of mathematical expressions for advanced mathematical search", "year": "2011", "authors": ["Keisuke Yokoi", "Minh-Quoc Nghiem"]}, {"title": "Mining coreference relations between formulas and text using Wikipedia", "year": "2010", "authors": ["Minh Nghiem Quoc", "Keisuke Yokoi"]}], "target_citation_location": 9, "citation_locations": [9, 13], "citation_type": "group", "annotations": [[3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "7e84dbe8-46f5-4f8c-aeb8-5d412e14e27f", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["Controllability", "Analysis", "on", "Temporal", "Frequency", "Then,", "we", "analyze", "the", "controllability", "of", "the", "temporal", "frequency", "\u03c4", "to", "present", "whether", "the", "coarse-grained", "or", "fine-grained", "tracepoints", "(sampling", "rate,", "in", "other", "words)", "affects", "the", "generation", "performance.", "As", "the", "Table", "4", "shows,", "we", "change", "the", "temporal", "frequency", "\u03c4", "from", "0.4", "to", "1.2.", "A", "performance", "drop", "is", "impressive", "with", "the", "\u03c4", "getting", "larger.", "The", "purpose", "of", "this", "experiment", "for", "various", "\u03c4", "is", "to", "simulate", "the", "trace", "drawing", "speed", "of", "users", "in", "a", "real", "application", "scenario,", "and", "a", "larger", "\u03c4", "is", "equivalent", "to", "a", "faster", "drawing", "speed.", "As", "Deng et al. (2020)", "has", "demonstrated,", "the", "length", "is", "one", "of", "the", "critical", "facts", "that", "impact", "quantitative", "performance.", "This", "result", "implies", "we", "can", "further", "decide", "to", "generate", "either", "a", "coarse-grained", "or", "fine-grained", "caption", "by", "controlling", "the", "time-frequency", "\u03c4."], "cited_papers": [{"title": "Length-controllable image captioning", "year": "2020", "authors": ["Chaorui Deng", "Ning Ding", "Mingkui Tan", "Qi Wu"]}], "target_citation_location": 91, "citation_locations": [91], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "7ee9a6db-d1db-4e9e-a93e-0b5c75a43d0f", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["Definition", "extraction", "from", "scientific", "document", "is", "close", "to", "the", "task", "presented", "in", "SemEval", "Task", "12.", "The", "Scientific", "Document", "Understanding", "workshop", "has", "hosted", "the", "Acronym", "Extraction", "and", "Acronym", "Disambiguation", "Shared", "Tasks,", "namely", "Acronym", "Extraction", "and", "Acronym", "Disambiguation", "Shared", "Tasks", "(Veyseh et al., 2021a (Veyseh et al., , 2022)).", "The", "prior", "studies", "in", "this", "research", "direction", "considers", "extracting", "definitions", "from", "the", "text", "(Spala et al., 2019 (Spala et al., , 2020,, Veyseh et al., 2020),", "or", "together", "with", "acronyms,", "and", "acronyms", "sense", "disambiguation", "(Pouran", "Ben", "Veyseh et al., 2020 Veyseh et al., , 2021))."], "cited_papers": [{"title": "MadDog: A web-based system for acronym identification and disambiguation", "year": "2021", "authors": ["Ben Amir Pouran", "Franck Veyseh", "Walter Dernoncourt", "Thien Huu Chang", "unk Nguyen"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 63, "citation_locations": [38, 52, 63], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "7f25e854-fda7-4e46-a3ec-40ed86395a23", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["To", "the", "best", "of", "our", "knowledge,", "the", "first", "algorithms", "similar", "to", "Codenames", "agents", "have", "been", "created", "by", "Shen et al. (2018)", "specifically", "to", "model", "human", "associations.", "In", "their", "simplified", "game,", "the", "board", "always", "consists", "of", "three", "nouns,", "and", "the", "agent", "gives", "a", "clue", "that", "must", "be", "one", "of", "three", "adjectives,", "and", "refers", "to", "exactly", "two", "of", "the", "board", "words.", "Their", "clues", "were", "generated", "based", "on", "the", "following", "five", "similarity", "functions:"], "cited_papers": [{"title": "Comparing models of associative meaning: An empirical investigation of reference in simple language games", "year": "2018", "authors": ["Matthias Judy Hanwen Shen", "Bjarke Hofer", "Roger Felbo", "unk Levy"]}], "target_citation_location": 17, "citation_locations": [17], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7f31bd04-720a-4471-9417-7b9557fa817d", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["Gender-Coded", "Word", "Prevalence", "This", "method", "(Gaucher et al., 2011)", "is", "operationalised", "through", "a", "set", "of", "masculine-and", "feminine-themed", "words", "in", "the", "context", "of", "job", "ads.", "\"Adventurous\"", "and", "\"stubborn\"", "are", "coded", "as", "masculine", "words", "while", "\"affectionate\"", "and", "\"kind\"", "are", "coded", "as", "feminine", "words.", "This", "research", "provides", "us", "with", "42", "masculine", "and", "40", "feminine", "words,", "with", "a", "wider", "set", "of", "potential", "words", "permeating", "from", "these", "(i.e.", "\"Compet*\"", "which", "may", "manifest", "itself", "as", "competitive,", "competition", "and", "so", "on).", "Our", "measure", "counts", "the", "prevalence", "of", "these", "words", "in", "a", "given", "text.", "The", "calculation", "is:"], "cited_papers": [{"title": "Evidence That Gendered Wording in Job Advertisements Exists and Sustains Gender Inequality", "year": "2011", "authors": ["Danielle Gaucher", "Justin Friesen", "Aaron Kay"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3]]}
{"id": "7f3c0c31-46b1-47f4-9a6b-1cf1567392d9", "citing_paper": {"title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables", "year": 2022, "authors": ["Nan Hu", "Zirui Wu", "Yuxuan Lai", "Xiao Liu", "Yansong Feng"]}, "text": ["Considering", "the", "inevitable", "expense", "in", "format", "conversion,", "we", "believe", "that", "each", "evidence", "in", "its", "original", "format", "can", "contribute", "necessary", "information", "to", "final", "verification,", "thus", "should", "be", "better", "encoded", "in", "its", "original", "format.", "This", "further", "indicates", "that", "we", "should", "design", "both", "sentence-to-table", "and", "table(cell)-to-sentence", "conversion", "methods", "to", "obtain", "all", "evidence", "in", "both", "formats,", "and", "maintain", "two", "parallel", "encoders", "to", "absorb", "the", "two", "formats,", "respectively.", "An", "advantage", "of", "doing", "so", "is", "to", "maximally", "encourage", "early", "interaction,", "which", "proves", "more", "effective", "than", "pair-wise", "encoding", "(Tymoshenko and Moschitti, 2021, Jiang et al., 2021)", "When", "converting", "table", "evidence", "into", "sentences,", "previous", "works", "either", "convert", "table", "cells", "to", "a", "concatenation", "of", "key-value", "pairs", "(Aly et al., 2021, Malon, 2021),", "or", "construct", "sentences", "in", "a", "coordinate-description", "style", "(Kotonya et al., 2021a).", "They", "pay", "less", "attention", "to", "the", "conventional", "organization", "of", "tables", "structures.", "We", "observe", "that,", "in", "a", "table,", "the", "column", "headers", "usually", "represent", "the", "types/properties", "and", "the", "row", "headers", "often", "denote", "entities", "or", "scopes.", "We", "argue", "that", "one", "should", "consider", "these", "conventions", "to", "convert", "a", "table", "cell", "evidence", "into", "more", "natural", "sentences,", "and", "later", "pretrained", "language", "models", "will", "be", "able", "to", "better", "capture", "the", "contextualized", "semantics", "of", "the", "table", "cells", "from", "generated", "sentences.", "On", "the", "other", "hand,", "existing", "pre-trained", "table", "models", "are", "trained", "to", "analyze", "one", "table", "at", "one", "time,", "while", "previous", "evidence", "conversion", "methods", "produce", "several", "small", "tables", "for", "one", "instance.", "It", "would", "be", "necessary", "to", "properly", "organize", "all", "evidence", "in", "one", "table", "so", "that", "pre-trained", "table", "models", "can", "allow", "the", "most", "interactions", "among", "all", "evidence", "pieces."], "cited_papers": [{"title": "Graph reasoning with context-aware linearization for interpretable fact extraction and verification", "year": "2021", "authors": ["Neema Kotonya", "Thomas Spooner", "Daniele Magazzeni", "Francesca Toni"]}], "target_citation_location": 108, "citation_locations": [81, 100, 108], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7fa53f42-a945-4a17-8ed4-79cf99b4845c", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["Given", "a", "question", "for", "an", "image,", "VCR", "needs", "to", "1.)", "correctly", "answer", "(Q\u2192A),", "2.)", "provide", "a", "rationale", "justifying", "its", "answer", "(QA\u2192R),", "3.)", "reason", "both", "of", "them", "(Q\u2192AR),", "which", "requires", "higher-order", "cognition", "and", "commonsense", "reasoning", "about", "the", "world.", "Following", "UNITER,", "we", "introduce", "a", "second-stage", "pretraining", "over", "the", "VCR", "dataset", "due", "to", "severe", "difference", "in", "dataset", "distribution", "compared", "to", "indomain", "image-text", "corpus.", "In", "addition,", "we", "also", "utilize", "a", "similar", "person", "grounding", "(Park et al., 2020)", "pretext", "task", "to", "tightly", "align", "the", "person", "tags", "in", "text", "and", "their", "visual", "locations.", "During", "finetuning", "stage,", "we", "concatenate", "each", "question", "along", "with", "each", "possible", "answer", "to", "form", "four", "kinds", "of", "text", "inputs,", "and", "feed", "each", "of", "them", "into", "Transformer", "network", "with", "corresponding", "image", "embeddings.", "Finally,", "a", "binary", "cross-entropy", "loss", "is", "adopted", "to", "supervise", "each", "pair.", "Since", "VCR", "questions", "explicitly", "reference", "objects", "at", "specific", "locations,", "we", "implement", "coreferencing", "between", "text", "and", "image", "by", "replacing", "referenced", "entities", "in", "the", "questions", "with", "their", "corresponding", "box", "locations.", "In", "the", "second", "stage", "pretraining", "for", "VCR,", "we", "reduce", "the", "learning", "rate", "to", "a", "constant", "5e-05", "and", "trained", "for", "an", "additional", "9K", "steps.", "Due", "to", "longer", "sequence", "lengths", "in", "the", "VCR", "dataset,", "a", "training", "batch-size", "of", "224", "is", "used.", "We", "also", "use", "a", "step", "size", "of", "2", "for", "gradient", "accumulation.", "After", "pretraining,", "we", "finetuned", "on", "the", "VCR", "task", "for", "10K", "steps", "with", "a", "learning", "rate", "of", "1e-04", "for", "both", "the", "Transformer", "and", "the", "CNNs.", "Linear", "warmup", "of", "the", "learning", "rate", "is", "applied", "for", "1000", "steps,", "followed", "by", "a", "linear", "decay", "ending", "at", "a", "total", "of", "10K", "steps."], "cited_papers": [{"title": "Visualcomet: Reasoning about the dynamic context of a still image", "year": "2020", "authors": ["Jae Park", "Chandra Bhagavatula", "Roozbeh Mottaghi", "Ali Farhadi", "Yejin Choi"]}], "target_citation_location": 69, "citation_locations": [69], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "7fedcf32-580d-4ef1-b9df-aeaa398f3c3e", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["MMB", "would", "also", "welcome", "anecdotal", "evidence,", "of", "the", "sort", "to", "be", "found", "in", "the", "work", "of", "Cassirer,", "that", "metaphorical", "uses", "of", "language", "were", "in", "some", "historical", "sense", "original,", "and", "not", "a", "later", "luxury.", "She", "rejected", "the", "view", "that", "language", "originally", "consisted", "of", "simple,", "unambiguous,", "Augustinian", "names", "of", "objects", "-the", "view", "parodied", "by", "Wittgenstein (1928 Wittgenstein ( , 1972) )", "in", "the", "opening", "of", "Philosophical", "investigations", "-but", "preferred", "the", "idea", "of", "original", "primitive", "atoms", "of", "wide,", "vague,", "unspecific", "meaning,", "which", "were", "then", "both", "refined", "to", "specific", "referents", "in", "use", "and", "constantly", "extended", "by", "metaphor.", "Here,", "for", "MMB,", "was", "the", "root", "not", "only", "of", "the", "metaphor,", "but", "also", "of", "metaphysics", "itself,", "which", "consisted", "for", "her,", "as", "for", "Wittgenstein,", "of", "words", "used", "outside", "their", "hitherto", "normal", "realm", "of", "application.", "But,", "whereas", "he", "thought", "that", "words", "were", "'on", "holiday'", "when", "so", "used,", "for", "her", "it", "was", "part", "of", "their", "everyday", "work."], "cited_papers": [{"title": "For English translation see Anscombe", "year": "1922", "authors": ["L Wittgenstein", "unk Untersuchungen"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 52, "citation_locations": [52], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "802e9017-6e2f-4264-95f3-18cc1180bd47", "citing_paper": {"title": "On the weak link between importance and prunability of attention heads", "year": 2020, "authors": ["Aakriti Budhraja", "Madhura Pande", "Preksha Nema", "Pratyush Kumar", "Mitesh Khapra"]}, "text": ["The", "middle", "layers", "in", "BERT", "have", "been", "shown", "to", "have", "specific", "characteristics", "of", "higher", "attention", "entropy", "and", "greater", "attention", "to", "specific", "tokens", "(Clark et al., 2019).", "We", "thus", "considered", "configurations", "where", "we", "compare", "pruning", "top", "and", "bottom", "layers", "against", "pruning", "middle", "layers", "(last", "eight", "rows", "of", "Table", "5).", "The", "results", "indicate", "a", "clear", "preference:", "In", "14", "out", "of", "16", "cases,", "pruning", "the", "middle", "layers", "performs", "worse", "that", "pruning", "equal", "number", "of", "layers", "distributed", "among", "top/bottom", "layers.", "Indeed,", "we", "incur", "an", "additional", "over", "2%", "average", "drop", "in", "accuracy", "for", "QNLI", "and", "SST-2", "tasks,", "indicating", "a", "task-specific", "sensitivity", "to", "pruning", "middle", "layers."], "cited_papers": [{"title": "What does bert look at? an analysis of bert's attention", "year": "2019", "authors": ["Kevin Clark", "Urvashi Khandelwal", "Omer Levy", "Christopher D Manning"]}], "target_citation_location": 22, "citation_locations": [22], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "802f8c01-d121-459e-97b1-92b4bda9de27", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["Recently,", "some", "works", "have", "used", "subword", "units", "level", "instead", "of", "word-level", "for", "translation.", "In", "[7],", "the", "rare", "and", "unknown", "words", "are", "encoded", "as", "subword", "units", "with", "the", "Byte", "Pair", "Encoding", "(BPE)", "algorithm.", "The", "authors", "show", "that", "this", "method", "can", "generate", "words", "which", "are", "unseen", "at", "training", "time.", "Another", "lower", "level", "for", "translation", "is", "the", "character-level", "NMT,", "which", "has", "been", "presented", "in", "several", "works", "[8, 9, 10]", "and", "showed", "promising", "results."], "cited_papers": [{"title": "Characterbased neural machine translation", "year": "2016", "authors": ["M Costa-Juss\u00e0", "J Fonollosa"]}, {"title": "Character-based neural machine translation", "year": "2015", "authors": ["W Ling", "I Trancoso", "C Dyer", "A Black"]}, {"title": "A character-level decoder without explicit segmentation for neural machine translation", "year": "2016", "authors": ["J Chung", "K Cho", "Y Bengio"]}], "target_citation_location": 63, "citation_locations": [14, 63], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]]}
{"id": "806e5e10-4f30-415d-bd85-8f8e29945c5d", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["In", "order", "to", "create", "diversity,", "existing", "methods", "attempted", "to", "produce", "uncertainty", "by", "introducing", "random", "noise", "into", "a", "latent", "variable", "(Gupta et al., 2018)", "or", "sampling", "next", "token", "widely", "from", "the", "vo-", "cabulary", "(Holtzman et al., 2020).", "However,", "these", "methods", "were", "not", "able", "to", "explicitly", "control", "varying", "semantics", "units", "and", "produce", "outputs", "of", "diverse", "content.", "Meanwhile,", "the", "input", "text", "alone", "contains", "too", "limited", "knowledge", "to", "support", "diverse", "reasoning", "and", "produce", "multiple", "reasonable", "outputs", "(Yu et al., 2022c).", "As", "an", "example,", "Table", "1", "shows", "the", "human", "evaluation", "results", "on", "two", "GCR", "tasks.", "While", "human", "annotators", "were", "able", "to", "produce", "2.60", "different", "yet", "reasonable", "explanations", "on", "the", "ComVE", "dataset,", "one", "SoTA", "diversity-promoting", "method", "(i.e.,", "nucleus", "sampling", "(Holtzman et al., 2020))", "could", "produce", "only", "2.15", "reasonable", "explanations."], "cited_papers": [{"title": "A deep generative framework for paraphrase generation", "year": "2018", "authors": ["Ankush Gupta", "Arvind Agarwal", "Prawaan Singh", "Piyush Rai"]}], "target_citation_location": 19, "citation_locations": [19, 29, 66, 104], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "80943c72-cc5b-4e2d-ba48-d568db9cdf24", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["Our", "baseline", "is", "the", "mBERT", "model", "(Devlin et al., 2018),", "which", "is", "pre-trained", "using", "pretext", "tasks", "like", "Masked", "Language", "Modelling", "and", "Next", "Sentence", "Prediction", "on", "a", "multilingual", "text", "corpus", "that", "includes", "our", "target", "languages,", "Hindi", "and", "Tamil.", "The", "default", "output", "head", "of", "mBERT", "is", "replaced", "with", "the", "head", "for", "the", "question-answering", "task.", "This", "is", "done", "by", "adding", "separate", "output", "heads", "for", "classifying", "the", "start", "and", "end", "positions", "as", "shown", "in", "Devlin et al. (2018)."], "cited_papers": [{"title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "year": "2018", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 6, "citation_locations": [6, 67], "citation_type": "single", "annotations": [[2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "80d909f1-e559-40b6-92c0-e91853524195", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["Shakkala", "was", "built", "by", "Barqawi (2017)", "for", "Arabic", "text", "diacritization", "using", "Bi-LSTM", "networks", "combined", "with", "character", "embeddings.", "Fadel et al. (2019)", "demonstrated", "the", "superiority", "of", "the", "neural", "approach", "of", "Shakkala", "compared", "to", "other", "different", "automatic", "diacritization", "systems", "available", "online", "e.g.,", "Ali-Soft, Farasa, Harakat, and MADAMIRA.", "Some", "recent", "work", "in", "Arabic", "NLP", "has", "started", "to", "make", "use", "of", "such", "systems.", "For", "example,", "Al-Sallab", "et", "al.", "(2017)", "proposed", "AROMA,", "a", "recursive", "deep", "learning", "model", "for", "opinion", "mining", "in", "Arabic.", "Preprocessing", "in", "AROMA", "included", "morphological", "tokenization", "and", "automatic", "diacritization", "carried", "out", "by", "MADAMIRA", "(Pasha et al., 2014).", "This", "resulted", "in", "improved", "performance", "in", "classifying", "opinion", "as", "positive", "or", "negative", "on", "a", "range", "of", "different", "Arabic", "corpora.", "Similarly,", "Baly et al. (2017)", "used", "a", "Recursive", "Neural", "Tensor", "Network", "(RNTN)", "for", "sentiment", "analysis", "and", "reported", "that", "adding", "orthographic", "features", "such", "as", "diacritics", "improved", "the", "performance.", "They", "incorporated", "orthographic", "features", "such", "as", "diacritics", "by", "enlarging", "the", "vocabulary", "to", "have", "distinct", "word", "forms", "for", "different", "versions", "of", "the", "word", "(diacritized/undiacritized)", "and", "then", "deriving", "embeddings", "by", "training", "a", "Continuous", "Bag", "of", "Words", "(CBOW)", "model", "(Mikolov et al., 2013).", "Similarly,", "Alqahtani et al. (2019)", "introduced", "automatic", "selective", "diacritization", "as", "a", "viable", "step", "in", "lexical", "disambiguation.", "They", "evaluated", "the", "system", "in", "downstream", "tasks", "including", "POS", "which", "improved", "from", "97.99%", "by", "baseline", "to", "98.70%.", "They", "trained", "word", "embeddings", "on", "selectively-diacritized", "dataset", "to", "enrich", "the", "vocabulary."], "cited_papers": [{"title": "MADAMIRA: A fast, comprehensive tool for morphological analysis and disambiguation of Arabic", "year": "2014", "authors": ["Arfath Pasha", "Mohamed Al-Badrashiny", "Mona Diab", "Ahmed Kholy", "Ramy Eskander", "Nizar Habash", "Manoj Pooleery", "Owen Rambow", "Ryan Roth"]}], "target_citation_location": 82, "citation_locations": [4, 16, 36, 82, 103, 162, 164], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "827a8fb5-65cd-42a9-a242-fada7d1bdad5", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["For", "sake", "of", "comparison,", "we", "have", "computed", "BLEU", "at", "word", "level", "using", "BPE", "method", "[7].", "We", "computed", "the", "subwords", "units", "in", "the", "output", "side", "of", "the", "neural", "network", "as", "done", "with", "Factored", "approach.", "We", "set", "the", "number", "of", "merge", "operations", "for", "the", "BPE", "algorithm,", "as", "explained", "in", "the", "paper", "[7],", "following", "equation", "12."], "cited_papers": [{"title": "Neural machine translation of rare words with subword units", "year": "2015", "authors": ["R Sennrich", "B Haddow", "A Birch"]}], "target_citation_location": 49, "citation_locations": [14, 49], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3]]}
{"id": "82939666-4a87-473d-afa9-44d85ad14a6f", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["Despite", "great", "progress", "has", "been", "made", "over", "improved", "accuracy,", "deep", "learning", "models", "are", "known", "to", "be", "brittle", "to", "out-of-domain", "data", "(Hendrycks et al., 2020, Wang et al., 2019),", "adversarial", "attacks", "(Mc-Coy et al., 2019, Jia and Liang, 2017, Jin et al., 2020),", "partly", "due", "to", "sometimes", "the", "models", "have", "exploited", "spurious", "correlations", "in", "the", "existing", "training", "data", "(Tu et al., 2020, Sagawa et al., 2020).", "In", "Figure", "1,", "we", "show", "an", "example", "of", "a", "sentiment", "classification", "model", "making", "spurious", "correlations", "over", "the", "phrases", "\"Spielberg\"", "and", "\"New", "York", "Subway\"", "due", "to", "their", "high", "co-occurrences", "with", "positive", "and", "negative", "labels", "respectively", "in", "the", "training", "data."], "cited_papers": [{"title": "Pretrained transformers improve out-of-distribution robustness", "year": "2020", "authors": ["Dan Hendrycks", "Xiaoyuan Liu", "Eric Wallace", "Adam Dziedzic", "Rishabh Krishnan", "Dawn Song"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 20, "citation_locations": [20, 23, 39], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "82e6844b-7b94-4cc3-81e6-4fc0c7469cff", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["Why", "care", "about", "compositionality", "in", "semantic", "parsing?", "If", "the", "goal", "of", "semantic", "parsing", "is", "not", "merely", "to", "automatically", "obtain", "a", "representation", "of", "the", "meaning", "of", "an", "utterance", "but", "also", "to", "understand", "why", "the", "parser", "produced", "that", "answer,", "i.e.,", "an", "explainable", "and", "transparent", "system,", "compositionality", "can", "help.", "In", "particular,", "in", "the", "output", "of", "our", "parser,", "every", "token", "is", "mapped", "to", "one", "of", "a", "finite", "number", "of", "meaning", "fragments", "(unlike", "a", "sequence-to-sequence", "system", "where", "a", "single", "token", "can", "in", "principle", "give", "rise", "to", "an", "unbounded", "number", "of", "output", "symbols),", "every", "clause", "belongs", "to", "one", "of", "these", "fragments", "(unlike", "a", "sequence-to-sequence", "system", "where", "the", "output", "is", "not", "usually", "anchored),", "and", "there", "is", "a", "straightforward", "rule", "that", "combines", "fragments", "into", "utterance", "meanings", "(unlike", "sequence-to-sequence", "systems", "where", "the", "interactions", "between", "tokens", "are", "opaque).", "This", "type", "of", "transparency", "is", "especially", "important", "in", "human-in-the-loop", "annotation,", "where", "parsers", "produce", "an", "initial", "annotation", "and", "annotators", "correct", "them.", "To", "do", "this", "efficiently", "and", "consistenly,", "annotators", "need", "to", "pinpoint", "where", "an", "error", "arises,", "and", "word-meaning", "pairings", "with", "a", "finite", "number", "of", "meanings", "seem", "a", "good", "handle", "on", "that.", "Bender et al. (2015)", "make", "a", "similar", "argument", "about", "grammar-based", "sembanking,", "pointing", "out", "the", "consistency,", "comprehensiveness,", "and", "scalability", "that", "compositionality", "afford.", "sequence-to-sequence", "ones", "is", "a", "big", "step", "ahead", "towards", "transparent", "DRS", "parsing.", "It", "is", "also", "worth", "noting", "that", "our", "sequence", "encoding", "scheme", "is", "equally", "applicable", "to", "incremental", "parsers,", "which", "potentailly", "afford", "a", "greater", "degree", "of", "psycholinguistic", "plausibility.", "In", "addition,", "the", "multi-task", "architecture", "of", "our", "approach", "is", "modular", "and", "allows", "for", "arbitrary", "additional", "sequence", "labeling", "tasks", "and", "factorizations."], "cited_papers": [{"title": "Layers of interpretation: On grammar and compositionality", "year": "2015", "authors": ["Emily Bender", "Dan Flickinger", "Stephan Oepen", "Woodley Packard", "Ann Copestake"]}], "target_citation_location": 177, "citation_locations": [177], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "83b3f0e4-645e-4121-b918-e5f09f42be58", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["There", "is", "a", "recent", "explosion", "of", "explanation-centred", "datasets", "for", "multi-hop", "question", "answering", "(Jhamtani and Clark, 2020, Xie et al., 2020, Jansen et al., 2018, Khot et al., 2020, Yang et al., 2018, Thayaparan et al., 2020, Wiegreffe and Marasovi\u0107, 2021).", "However,", "most", "of", "these", "datasets", "require", "the", "aggregation", "of", "only", "two", "sentences", "or", "paragraphs,", "making", "it", "hard", "to", "evaluate", "the", "robustness", "of", "the", "models", "in", "terms", "of", "semantic", "drift.", "On", "the", "other", "hand,", "the", "WorldTree", "corpus", "(Xie et al., 2020, Jansen et al., 2018)", "used", "in", "this", "shared", "task", "is", "explicitly", "designed", "to", "test", "multi-hop", "inference", "models", "on", "the", "reconstruction", "of", "long", "inference", "chains", "requiring", "the", "aggregation", "of", "an", "average", "of", "6", "facts,", "and", "as", "many", "as", "16", "facts."], "cited_papers": [{"title": "WorldTree V2: A Corpus of Science-Domain Structured Explanations and Inference Patterns supporting Multi-Hop Inference", "year": "2020", "authors": ["Zhengnan Xie", "Sebastian Thiem", "Jaycie Martin", "Elizabeth Wainwright", "Steven Marmorstein", "Peter Jansen"]}, {"title": "WorldTree: A Corpus of Explanation Graphs for Elementary Science Questions supporting Multi-hop Inference", "year": "2018", "authors": ["Peter Jansen", "Elizabeth Wainwright", "Steven Marmorstein", "Clayton Morrison"]}], "target_citation_location": 49, "citation_locations": [12, 49], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "83e7df43-9479-4485-8fb1-5897a23f020a", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["There", "are", "two", "ways", "to", "handle", "sentences", "with", "unbounded", "dependency.", "The", "first", "approach", "is", "straightforward", "memorybased", "approach", "which", "simply", "store", "a", "set", "of", "CSCs", "involves", "unbounded", "dependency.", "A", "large", "set", "of", "CSCs", "would", "have", "to", "be", "prepared", "for", "this,", "but", "its", "simplicity", "minimized", "computational", "requirements.", "Alternatively,", "we", "can", "employ", "somewhat", "linguistic", "treatment", "of", "this", "phenomena", "within", "our", "framework.", "The", "syntactic", "constraint", "network", "has", "a", "node", "representing", "TOPIC", "and", "FOCUS", "which", "usually", "bound", "to", "the", "displaced", "phrase.", "An", "address", "of", "CI", "for", "the", "displaced", "phrase", "(such", "as", "'the", "bug'", "in", "the", "example", "s9)", "is", "propagated", "to", "the", "TOPIC", "or", "FOCUS", "nodes", "in", "the", "syntactic", "constraint", "network.", "Further", "propagation", "of", "the", "address", "of", "the", "CI", "is", "controlled", "by", "acti-vation", "of", "nodes", "along", "the", "syntactic", "constraint", "network.", "The", "network", "virtually", "encodes", "a", "finite-state", "transition", "equivalent", "to", "{COMP|XCOMP}*GF-COMP", "[Kaplan and Zaenen, 1989]", "where", "GF-COMP", "denotes", "grammatical", "functions", "other", "than", "COMP.", "The", "address", "of", "the", "CI", "bound", "to", "TOPIC", "or", "FOCUS", "can", "propagate", "through", "the", "path", "based", "on", "the", "activation", "patterns", "of", "the", "syntactic", "constraint", "network,", "and", "the", "activation", "patterns", "are", "essentially", "controlled", "by", "markers", "flow", "from", "the", "memory", "network.", "When", "the", "CSC", "is", "accepted", "and", "there", "is", "a", "case-role", "not", "bound", "to", "any", "CI", "(OBJECT", "in", "the", "example),", "the", "CSE", "for", "the", "case-role", "bound", "with", "the", "CI", "propagated", "from", "the", "syntactic", "constraint", "network."], "cited_papers": [{"title": "Lexical-Functional Grammar: A Formal System for Grammatical Representation", "year": "1982", "authors": ["R Bresnan ", " Kaplan", "J Bresnan", "J Bresnan", "R Kaplan", "A Zaenen"]}], "target_citation_location": 134, "citation_locations": [134], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "840aa8e9-a04b-4d76-82d8-5ee970ac250f", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["DMSNAP", "complete", "parsing", "in", "the", "order", "of", "milliseconds.", "While", "actual", "SNAP", "hardware", "is", "now", "being", "assembled", "and", "to", "be", "fully", "operational", "by", "May", "1991,", "this", "section", "provides", "performance", "estimation", "with", "precise", "simulation", "of", "the", "SNAP", "machine.", "Simulations", "of", "the", "DMSNAP", "algorithm", "have", "been", "performed", "on", "a", "SUN", "3/280", "using", "the", "SNAP", "simulator", "which", "has", "been", "developed", "at", "USC", "[Lin and Moldovan, 1990", "].", "The", "simulator", "is", "implemented", "in", "both", "SUN", "Common", "LISP", "and", "C,", "and", "simulates", "the", "SNAP", "machine", "at", "the", "processor", "level.", "The", "LISP", "version", "of", "the", "simulators", "also", "provides", "information", "about", "the", "number", "of", "SNAP", "clock", "cycles", "required", "to", "perform", "the", "simulation."], "cited_papers": [{"title": "A Framework of a Mechanical Trans lation between Japanese and English by Analogy Principle", "year": "1968", "authors": ["C Moldovan ", " Lin", "D Moldovan", "\" Snap: Simulator Results ", " Moldovan", "D Lee", "W Lin", "C Nagao", "M Pollard", "C Sag", "I Quillian", "M Riesbeck", "C Martin", "C Riesbeck", "C Schank", "R Sato", "S Nagao", "M unk"]}], "target_citation_location": 58, "citation_locations": [58], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "840b0d15-05a6-4fc3-92b3-cf6c365dc92e", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["Our", "proposed", "SimpDefiner", "also", "takes", "the", "given", "word", "and", "context", "as", "input.", "Differently,", "our", "main", "focus", "is", "to", "generate", "definitions", "with", "appropriate", "complexity", "to", "better", "help", "language", "learners.", "Besides,", "our", "model", "is", "based", "on", "MASS", "(Song et al., 2019),", "which", "is", "a", "pre-trained", "encoder-decoder", "model", "and", "is", "suitable", "for", "generation", "tasks."], "cited_papers": [{"title": "Mass: Masked sequence to sequence pretraining for language generation", "year": "2019", "authors": ["Kaitao Song", "Xu Tan", "Tao Qin", "Jianfeng Lu", "Tie-Yan Liu"]}], "target_citation_location": 35, "citation_locations": [35], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "8441ce14-9ea3-4898-942c-aad2c60fb607", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["The", "candidate", "quality", "measure", "M", "can", "be", "defined", "in", "many", "ways.", "In", "this", "work", "we", "define", "it", "as", "the", "ROUGE", "(Lin, 2004)", "score", "of", "a", "candidate", "summary", "S", "i", "given", "the", "reference", "summary", "S", "*.", "To", "coordinate", "a", "pre-trained", "abstractive", "model,", "we", "1)", "use", "it", "to", "generate", "different", "candidate", "summaries", "with", "various", "levels", "of", "quality,", "2", "then", "2)", "encourage", "the", "model", "to", "assign", "higher", "estimated", "probabilities", "to", "better", "candidates", "by", "fine-tuning", "the", "model", "with", "a", "contrastive", "loss,", "following", "the", "previous", "work", "(Hopkins and May, 2011, Zhong et al., 2020):"], "cited_papers": [{"title": "ROUGE: A package for automatic evaluation of summaries", "year": "2004", "authors": ["Chin-Yew Lin"]}], "target_citation_location": 20, "citation_locations": [20, 80], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8444eaf8-9b06-470d-bb95-f19cef0149f9", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["The", "combination", "of", "lexical", "knowledge", "and", "rule", "knowledge", "enables", "WM", "to", "function", "as", "a", "full", "morphological", "component.", "As", "shown", "by", "ten", "Hacken", "(1998),", "the", "effects", "of", "this", "coverage", "are", "particularly", "striking", "in", "the", "domain", "of", "word", "formation,", "for", "which", "a", "system", "taking", "a", "lexicon", "as", "modelled", "in", "Fig.", "2B", "as", "a", "basis", "lacks", "the", "procedural", "component.", "Thus", "a", "formalism", "such", "as", "DATR,", "as", "described", "by", "Evans &amp, Gazdar (1996),", "though", "able", "to", "represent", "word", "formation", "relationships,", "cannot", "deal", "with", "unseen", "words", "without", "a", "separate", "recognition", "module.", "In", "WM,", "word", "formation", "rules", "are", "at", "the", "same", "time", "available", "declaratively,", "as", "the", "structural", "backbone", "of", "the", "database,", "and", "procedurally", "for", "the", "recognition", "of", "new", "words."], "cited_papers": [{"title": "DATR: A Language for Lexical Knowledge Representation", "year": "1996", "authors": ["Roger Evans", "Gerald Gazdar"]}], "target_citation_location": 65, "citation_locations": [65], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "845719bc-f932-425a-ae11-3f8e8c6c005d", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Previous", "research", "has", "demonstrated", "that", "some", "demographic", "settings", "are", "inherently", "more", "abusive", "than", "others.", "For", "example,", "a", "study", "by", "Stephens et al. (2013)", "mapped", "the", "locations", "of", "hateful", "tweets", "across", "the", "United", "States", "to", "uncover", "the", "regions", "where", "people", "use", "hate", "speech", "the", "most.", "They", "observed", "that", "areas", "with", "low", "diversity", "use", "more", "derogatory", "slurs", "against", "racial", "and", "sexual", "minorities.", "A", "separate", "line", "of", "work", "by", "Savicki et al. (1996)", "concluded", "that", "male-only", "discussion", "groups", "on", "the", "Internet", "use", "more", "coarse", "and", "abusive", "language", "than", "female-only", "groups.", "These", "works", "indicate", "that", "demographic", "settings", "can", "be", "predictive", "of", "the", "(abusive)", "nature", "of", "comments", "orig-inating", "from", "within", "them.", "User", "and", "community", "information", "constitutes", "a", "direct", "and", "simple", "way", "of", "capturing", "the", "demographic", "setting", "of", "a", "comment."], "cited_papers": [{"title": "Gender Language Style and Group Composition in Internet Discussion Groups", "year": "1996", "authors": ["Victor Savicki", "Dawn Lingenfelter", "Merle Kelley"]}], "target_citation_location": 63, "citation_locations": [19, 63], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "846b40c6-48a6-4de1-b18d-d51e2deb6f71", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["The", "second", "dataset", "is", "Debatepedia", "arguments", "(Hou and Jochim, 2017).", "A", "total", "of", "508", "topics", "are", "paired", "with", "15K", "pro", "and", "con", "responses,", "and", "we", "treat", "each", "pair", "as", "an", "argument", "and", "each", "topic", "and", "response", "as", "claim", "and", "statement,", "respectively."], "cited_papers": [{"title": "Argument relation classification using a joint inference model", "year": "2017", "authors": ["Yufang Hou", "Charles Jochim"]}], "target_citation_location": 6, "citation_locations": [6], "citation_type": "single", "annotations": [[2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "846eb893-8678-4dae-b80e-91e9c320d286", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["Comparing", "Eq.", "6", "with", "Eq.", "3,", "the", "major", "difference", "is", "that", "during", "inference", "the", "model", "makes", "new", "predictions", "based", "on", "its", "own", "previous", "predictions", "S", "&lt,t", "instead", "of", "the", "reference", "S", "*", "&lt,t.", "As", "a", "result,", "even", "if", "the", "generation", "model", "g", "achieves", "very", "high", "accuracy", "w.r.t.", "Eq.", "3,", "once", "S", "&lt,t", "starts", "to", "deviate", "from", "S", "*,", "there", "is", "the", "risk", "that", "the", "performance", "of", "g", "will", "significantly", "degrade.", "This", "problem", "has", "been", "identified", "as", "the", "exposure", "bias", "(Bengio et al., 2015)."], "cited_papers": [{"title": "Scheduled sampling for sequence prediction with recurrent neural networks", "year": "2015", "authors": ["Samy Bengio", "Oriol Vinyals", "Navdeep Jaitly", "Noam Shazeer"]}], "target_citation_location": 79, "citation_locations": [79], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "84a357bb-cfec-4d30-8538-2c4cda622669", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["Equations", "7", "and", "8", "attempt", "to", "account", "for", "this", "by", "using", "a", "shared", "weight", "concatenation", "and", "a", "weighted", "concatenation", "respectively.", "In", "equation", "7,", "W", "\u2208", "R", "k\u00d7k", "is", "a", "weight", "matrix,", "where", "the", "values", "are", "scaled", "down", "to", "1,", "in", "order", "to", "capture", "the", "relative", "importance", "of", "each", "h", "c", "i", "and", "h", "w", "i", "\u2200h", "c", "i", "\u2208", "h", "c,", "h", "w", "i", "\u2208", "h", "w.", "This", "shared", "weighting", "is", "a", "modification", "of", "the", "concept", "of", "leaky", "integration", "(Bengio et al., 2013).", "On", "the", "other", "hand,", "equation", "8", "uses", "two", "independent", "weight", "matrices,", "W", "c,", "W", "w", "\u2208", "R", "k\u00d7k,", "which", "does", "not", "constrain", "the", "network", "to", "use", "on", "other", "the", "other", "hidden", "representation.", "However,", "the", "gradients", "are", "still", "clipped", "at", "a", "low", "value", "(\u2248", "1)", "to", "avoid", "explosion."], "cited_papers": [{"title": "Advances in optimizing recurrent networks", "year": "2013", "authors": ["Yoshua Bengio", "Nicolas Boulanger-Lewandowski", "Razvan Pascanu"]}], "target_citation_location": 79, "citation_locations": [79], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "84ef5b77-05f3-404d-96cb-bcd15cbd0799", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["We", "utilised", "the", "ANLT", "metagrammatical", "formalism", "to", "develop", "a", "feature-based,", "declara", "tive", "description", "of", "PoS", "label", "sequences", "for", "English.", "This", "grammar", "compiles", "into", "a", "DCG-like", "grammar", "of", "approximately", "400", "rules.", "It", "has", "been", "designed", "to", "enumerate", "possible", "valencies", "for", "predicates", "(verbs,", "adj", "ectives", "and", "nouns)", "by", "including", "separate", "rules", "for", "each", "pattern", "of", "possible", "complementation", "in", "English.", "The", "distinction", "between", "arguments", "and", "adj", "uncts", "is", "expressed,", "following", "X-bar", "theory", "(e.g.", "Jackendoff, 1977),", "by", "Chomsky-adjunction", "of", "adjuncts", "to", "maximal", "projections", "{XP", "\ufffd", "XP", "Adjunct)", "as", "opposed", "to", "government", "of", "arguments", "(i.e.", "arguments", "are", "sisters", "within", "Xl", "projections,", "XI", "\ufffd", "XO", "Argl.", "..", "ArgN).", "Although", "the", "grammar", "enumerates", "complementation", "possibilities", "and", "checks", "for", "global", "sentential", "well-formedness,", "it", "is", "best", "de", "scribed", "as", "'intermediate'", "as", "it", "does", "not", "attempt", "to", "associate", "'displaced'", "constituents", "with", "their", "canonical", "position", "/", "grammatical", "role."], "cited_papers": [{"title": "X-bar Syntax", "year": "1977", "authors": ["R Jackendoff"]}], "target_citation_location": 70, "citation_locations": [70], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "84f15eab-3de8-4406-a3d0-02d6abed02ee", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["The", "exponential", "growth", "of", "published", "articles", "may", "exceeds", "many", "readers'", "ability", "to", "keep", "track", "of", "the", "development", "of", "their", "field", "of", "interest.", "Hence,", "automatic", "reading", "comprehension", "of", "scientific", "documents", "has", "attracted", "the", "attention", "of", "researchers", "across", "various", "domains", "such", "as", "Drug", "Discovery,", "Knowledge", "Base", "Construction,", "and", "Natural", "Language", "Processing.", "A", "crucial", "aspect", "of", "understanding", "scientific", "literature", "is", "understanding", "terminologies", "and", "formulae", "because", "they", "offer", "an", "explicit", "and", "precise", "interface", "to", "present", "the", "relation", "between", "scientific", "concepts", "(Schubotz et al., 2018).", "As", "such,", "a", "reading", "comprehension", "machine", "needs", "to", "(i)", "identify", "their", "descriptions", "and", "formulae,", "(ii)", "segment", "them", "into", "primitive", "terms", "and", "symbols,", "and", "(iii)", "link", "the", "associated", "terms", "and", "corresponding", "symbols."], "cited_papers": [{"title": "Improving the representation and conversion of mathematical formulae by considering their textual context", "year": "2018", "authors": ["Moritz Schubotz", "Andr\u00e9 Greiner-Petter", "Philipp Scharpf", "Norman Meuschke", "S Howard", "Bela Cohl", "unk Gipp"]}], "target_citation_location": 76, "citation_locations": [76], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "84fcbcbf-0a04-4d16-b9da-b2422fb62e7d", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["For", "semantics,", "the", "situation", "is", "even", "more", "complicated.", "While", "BERT's", "performance", "on", "natural", "language", "understanding", "tasks", "set", "a", "new", "state", "of", "the", "art,", "more", "targeted", "tests", "of", "its", "semantic", "abilities", "have", "yielded", "less", "positive", "results.", "BERT", "has", "limited", "knowledge", "of", "lexical", "semantic", "relations", "such", "as", "hypernymy", "(Ravichander et al., 2020)", "and", "antonymy", "(Staliunaite and Iacobacci, 2020).", "Moreover,", "it", "has", "fragile", "representations", "of", "named", "entities", "(Balasubramanian et al., 2020),", "and", "imprecise", "representations", "of", "numbers", "(Wallace et al., 2019).", "These", "flaws", "comprise", "specific", "linguistic", "phenomena", "that", "BERTScore,", "due", "to", "its", "use", "of", "BERT,", "might", "be", "unable", "to", "handle,", "and", "thus", "merit", "investigation."], "cited_papers": [{"title": "On the systematicity of probing contextualized word representations: The case of hypernymy in BERT", "year": "2020", "authors": ["Abhilasha Ravichander", "Eduard Hovy", "Kaheer Suleman", "Adam Trischler", "Jackie Chi Kit Cheung"]}], "target_citation_location": 46, "citation_locations": [46, 49, 58, 64], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "8509321c-37db-46cf-b730-4c655cee849c", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["Trained", "on", "Vietnamese", "texts", "of", "the", "CommonCrawl", "corpus", "ETNLP", "(Vu et al., 2019)", "x", "Trained", "on", "1GB", "texts", "of", "Vietnamese", "Wikipedia", "PhoBERT", "(Nguyen and Nguyen, 2020)", "x"], "cited_papers": [{"title": null, "year": "2020", "authors": ["unk Nguyen Van Nha"]}], "target_citation_location": 19, "citation_locations": [9, 19], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "8516d3fb-4292-49d8-b452-05a925a6665e", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["We", "have", "established", "that", "the", "performance", "of", "top-k", "attention", "is", "comparable", "to", "vanilla", "attention", "when", "training", "the", "model", "from", "scratch.", "In", "this", "set-up,", "several", "recently-proposed", "approaches", "have", "also", "reported", "competitive", "performances", "(Tay et al., 2021).", "Now,", "we", "consider", "a", "different", "and", "more", "practical", "setup,", "where", "the", "starting", "point", "is", "using", "an", "already", "pre-trained", "language", "model", "(Devlin et al., 2019, Raffel et al., 2020).", "As", "such", "models", "were", "trained", "using", "vanilla", "attention,", "replacing", "it", "with", "a", "new", "attention", "variant", "typically", "requires", "a", "corrective", "pretraining", "stage", "to", "allow", "the", "model", "weights", "to", "adjust", "to", "the", "new", "variant,", "which", "can", "be", "expensive", "for", "large", "models.", "For", "example,", "(Gupta and Berant, 2021, Peng et al., 2021)", "have", "shown", "that", "using", "random", "features", "without", "corrective", "pre-training", "leads", "to", "high", "error", "rates", "in", "a", "language", "modeling", "task.", "Moreover,", "as", "explained", "in", "\u00a72.1,", "most", "past", "methods", "are", "incompatible", "with", "feed-forward", "layers.", "In", "the", "subsequent", "experiments", "we", "show", "that", "it", "is", "possible", "to", "replace", "vanilla", "with", "top-k", "attention,", "at", "multi-head", "attention", "and", "feed-forward", "layers,", "and", "perform", "inference", "and", "fine-tuning", "without", "any", "need", "for", "such", "correction."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 52, "citation_locations": [31, 52, 94], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8534d42b-3d3b-42e7-8f33-c76924e4be01", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["For", "our", "contextual", "word", "embeddings,", "we", "use", "fastText", "embeddings", "for", "English", "(Bojanowski et al., 2017)", "which", "are", "pretrained", "on", "common-Crawl", "and", "the", "Wikipedia", "corpus.", "FastText", "embeddings", "are", "also", "used", "for", "Hindi,", "French,", "Spanish", "and", "Italian", "word", "representations", "(Grave et al., 2018).", "The", "bi-LSTM", "trains", "on", "a", "fixed", "300", "hidden", "dimensions", "for", "all", "the", "bi-LSTMs", "in", "the", "architecture."], "cited_papers": [{"title": "Learning word vectors for 157 languages", "year": "2018", "authors": ["Edouard Grave", "Piotr Bojanowski", "Prakhar Gupta", "Armand Joulin", "Tomas Mikolov"]}], "target_citation_location": 34, "citation_locations": [11, 34], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "85415672-de9f-4a49-9f43-7ffd18868fce", "citing_paper": {"title": "NEW TABULAR ALGORITHMS FOR LIG PARSING", "year": 2000, "authors": ["Mi G Uel Alonso Jor G E Grana", "Manuel Vilares"]}, "text": ["A", "linear", "indexed", "grammar", "is", "a", "tuple", "(Vr,", "V", "N,", "Vi,", "P,", "S),", "where", "Vr", "is", "a", "finite", "set", "of", "terminals,", "V", "N", "a", "finite", "set", "of", "non-terminals,", "Vi", "is", "a", "finite", "set", "of", "indices,", "SE", "V", "N", "is", "the", "start", "symbol", "and", "Pisa", "finite", "set", "of", "productions.", "Following", "[7]", "we", "consider", "productions", "in", "which", "at", "most", "one", "element", "can", "be", "pushed", "on", "or", "popped", "from", "a", "stack", "of", "indices", ":Ao", "[oo", "1]", "\u2794", "Ai", "[]", "...", "Ai", "-i", "l]", "Ai[oo,']", "Ai-i", "l]", "...", "Am", "[]", "Ao", "[]", "\u2794", "awhere", "m", "is", "the", "length", "of", "the", "production,", "A", "i", "E", "VN", "for", "each", "O", "-\ufffd", "j", "\ufffd", "m,", "Ai", "is", "the", "dependent", "child,", "oo", "is", "the", "part", "of", "the", "indices", "stack", "transmitted", "from", "the", "father", "to", "the", "dependent", "child,,,", ",'", "E", "Vi", "U", "{\u20ac}", "and", "for", "each", "production", "either,", "or", ",'", "or", "both", "must", "be", "\u20ac", "and", "a", "E", "VT", "U", "{\u20ac}."], "cited_papers": [{"title": "Applicability of indexed grammars to natural languages", "year": "1987", "authors": ["G Gazdar"]}], "target_citation_location": 49, "citation_locations": [49], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "85826bd2-b3de-4f91-941b-66b05c3e06fb", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Word", "associations", "have", "been", "a", "subject", "of", "active", "research", "for", "a", "long", "time", "in", "cognitive", "science", "and", "psycholinguistics", "for", "various", "reasons.", "They", "were", "used", "to", "study", "mental", "functioning,", "memory,", "and", "certain", "diseases.", "Word", "associations", "were", "also", "applied", "for", "modeling", "the", "cognitive", "lexicon", "and", "some", "linguistic", "processes", "(summarized", "by", "Bel-Enguix et al., 2019)."], "cited_papers": [{"title": null, "year": "2019", "authors": ["Gemma Bel-Enguix", "Helena G\u00f3mez-Adorno", "Jorge Reyes-Maga\u00f1a", "Gerardo Sierra"]}], "target_citation_location": 48, "citation_locations": [48], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1]]}
{"id": "85e3953b-2945-40c6-8183-d05f6ea0c034", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["When", "the", "parsing", "is", "done,", "a", "V-MARKER", "is", "passed", "to", "the", "target", "language", "(Japanese)", "expression", "WANT-CIRCUM-J", "from", "WANT-CIRCUM,", "and,", "then,", "to", "the", "first", "CSE", "of", "WANT-CIRCUM-J.", "Since", "the", "first", "CSE", "has", "a", "G-MARKER", "pointing", "to", "JON,", "'jon'", "becomes", "the", "first", "word", "in", "the", "translated", "Japanese", "sentence", "and", "then", "the", "V-MARKER", "is", "passed", "to", "the", "next", "CSE.", "See", "[Kitano, 1990b]", "for", "the", "details", "of", "generation", "process.", "This", "operation", "is", "repealed", "for", "all", "CSEs", "in", "the", "CSC.", "Finally,", "the", "Japanese", "sentence", "tl", "is", "constructed", "for", "the", "English", "sentence", "s1."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 57, "citation_locations": [57], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "86cf52b1-9c15-4c84-af4e-438b290ad8b6", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["Genuine", "tokens", "are", "tokens", "that", "causally", "affect", "a", "task's", "label", "(Srivastava et al., 2020, Wang and Culotta, 2020b),", "and", "thus", "the", "correlations", "between", "those", "tokens", "and", "the", "labels", "are", "what", "we", "expect", "the", "model", "to", "capture", "and", "to", "more", "heavily", "rely", "on.", "On", "the", "other", "hand,", "spurious", "tokens,", "or", "shortcuts", "as", "commonly", "denoted", "in", "prior", "work", "(Geirhos et al., 2020, Minderer et al., 2020),", "are", "features", "that", "correlate", "with", "task", "labels", "but", "are", "not", "genuine,", "and", "thus", "might", "fail", "to", "transfer", "to", "challenging", "test", "conditions", "(Geirhos et al., 2020)", "or", "out-of-distribution", "data,", "spurious", "tokens", "do", "not", "causally", "affect", "task", "labels", "(Srivastava et al., 2020, Wang and Culotta, 2020b)."], "cited_papers": [{"title": "Robustness to spurious correlations in text classification via automatically generated counterfactuals", "year": "2020", "authors": ["Zhao Wang", "Aron Culotta"]}, {"title": "Robustness to spurious correlations via human annotations", "year": "2020", "authors": ["Megha Srivastava", "Tatsunori Hashimoto", "Percy Liang"]}], "target_citation_location": 83, "citation_locations": [10, 49, 71, 83], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1]]}
{"id": "86e61aca-53e0-4d62-9435-b27d9e4ce3da", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["Task", "1:", "Sentiment", "classification.", "For", "the", "task", "of", "sentiment", "classification,", "we", "use", "several", "datasets", "in", "our", "experiments.", "To", "find", "shortcuts", "in", "Stanford", "Sentiment", "Treebank", "(SST-2)", "(Socher et al., 2013)", "dataset,", "we", "first", "train", "a", "model", "on", "SST-2", "training", "set", "which", "consists", "of", "67,", "349", "sentences.", "We", "then", "evaluate", "the", "model", "on", "SST-2", "training", "set", "5", "and", "Yelp", "(As-ghar,", "2016)", "test", "set", "and", "obtain", "attention", "scores.", "For", "cross-dataset", "analysis,", "we", "compare", "the", "important", "tokens", "extracted", "from", "SST-2", "and", "Yelp.", "Similarly,", "we", "train", "another", "model", "on", "80,", "000", "amazon", "kitchen", "reviews", "(He and McAuley, 2016),", "and", "apply", "it", "on", "the", "kitchen", "review", "dev", "set", "and", "the", "amazon", "electronics", "dev", "set,", "both", "having", "10,", "000", "reviews."], "cited_papers": [{"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "year": "2013", "authors": ["Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "D Christopher", "Andrew Manning", "Christopher Ng", "unk Potts"]}], "target_citation_location": 25, "citation_locations": [25, 86], "citation_type": "single", "annotations": [[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "878b7a5b-2938-408b-86b7-4a6f5d81bc2b", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["Logical", "mechanisms", "have", "not", "been", "actively", "studied", "in", "argumentative", "relation", "classification.", "Models", "based", "on", "hand-crafted", "features", "have", "used", "relatively", "simple", "lexical", "features,", "such", "as", "n-grams,", "discourse", "markers,", "and", "sentiment", "agreement", "and", "word", "overlap", "between", "two", "statements", "(Stab and Gurevych, 2017, Habernal and Gurevych, 2017, Persing and Ng, 2016, Rinott et al., 2015).", "Recently,", "neural", "models", "have", "become", "dominant", "approaches", "(Chakrabarty et al., 2019, Durmus et al., 2019, Eger et al., 2017).", "Despite", "their", "high", "accuracy", "and", "finding", "of", "some", "word-level", "interactions", "between", "statements", "(Xu et al., 2019, Chen et al., 2018),", "they", "provide", "quite", "limited", "insight", "into", "governing", "mechanisms", "in", "argumentative", "relations.", "Indeed,", "more", "and", "more", "evidence", "suggests", "that", "supervised", "models", "learn", "to", "overly", "rely", "on", "superficial", "cues,", "such", "as", "discourse", "markers", "(Optiz and Frank, 2019),", "negating", "words", "(Niven and Kao, 2019),", "and", "sentiment", "(Allaway and McKeown, 2020)", "behind", "the", "scenes.", "We", "instead", "use", "an", "interpretable", "method", "based", "on", "PSL", "to", "examine", "logical", "mechanisms", "(\u00a77)", "and", "then", "show", "evidence", "that", "these", "mechanisms", "can", "inform", "supervised", "models", "in", "intuitive", "ways", "(\u00a78)."], "cited_papers": [{"title": "Parsing argumentation structures in persuasive essays", "year": "2017", "authors": ["Christian Stab", "Iryna Gurevych"]}, {"title": "Show me your evidencean automatic method for context dependent evidence detection", "year": "2015", "authors": ["Ruty Rinott", "Lena Dankin", "Carlos Perez", "Mitesh Khapra", "Ehud Aharoni", "Noam Slonim"]}, {"title": "End-to-end argumentation mining in student essays", "year": "2016", "authors": ["Isaac Persing", "Vincent Ng"]}, {"title": "Argumentation mining in user-generated web discourse", "year": "2017", "authors": ["Ivan Habernal", "Iryna Gurevych"]}], "target_citation_location": 36, "citation_locations": [36, 44, 57, 89, 92, 95], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "88276289-1839-48a8-92ed-c207b13be5b6", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Among", "the", "configurations,", "FastText", "similarity", "combined", "with", "the", "Koyyalagunta", "scoring", "function", "was", "evaluated", "previously", "by", "Koyyalagunta et al. (2021),", "where", "it", "was", "the", "best", "agent", "without", "any", "language-specific", "resource,", "i.e.", "using", "raw", "corpora", "only.", "The", "results", "show", "that", "this", "is", "outperformed", "by", "many", "of", "our", "new", "configurations."], "cited_papers": [{"title": "Playing codenames with language graphs and word embeddings", "year": "2021", "authors": ["Divya Koyyalagunta", "Anna Sun", "Rachel Draelos", "Cynthia Rudin"]}], "target_citation_location": 15, "citation_locations": [15], "citation_type": "single", "annotations": [[2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "8868c686-94e6-4193-94de-7747f5f1a254", "citing_paper": {"title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation", "year": 2021, "authors": ["Hansi Hettiarachchi", "Tharindu Ranasinghe"]}, "text": ["Crosslingual", "Since", "there", "were", "no", "training", "data", "available", "for", "cross-lingual", "datasets,", "we", "followed", "a", "zero-shot", "approach", "for", "them.", "Multilingual", "and", "cross-lingual", "transformer", "models", "like", "multilingual", "BERT", "and", "XLM-R", "show", "strong", "cross-lingual", "transfer", "learning", "performance.", "They", "can", "be", "trained", "on", "one", "language,", "typically", "a", "resource-rich", "language", "and", "can", "be", "used", "to", "perform", "inference", "on", "another", "language.", "The", "cross-lingual", "nature", "of", "the", "transformer", "models", "has", "provided", "the", "ability", "to", "do", "this", "(Ranasinghe et al., 2020c).", "Therefore,", "we", "used", "the", "models", "trained", "on", "the", "English-English", "dataset", "to", "get", "predictions", "for", "cross-lingual", "datasets."], "cited_papers": [{"title": "TransQuest: Translation quality estimation with cross-lingual transformers", "year": "2020", "authors": ["Tharindu Ranasinghe", "Constantin Orasan", "Ruslan Mitkov"]}], "target_citation_location": 69, "citation_locations": [69], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "8885d58d-52a3-4c9b-ad62-dbb46017bf4b", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["Apart", "from", "the", "small", "gold", "set", "whose", "quality", "is", "guaranteed", "by", "human", "annotators,", "PMB", "3.0.0", "also", "contains", "silver", "and", "bronze", "data", "with", "partial", "or", "no", "manual", "checking", "of", "the", "annotations.", "Their", "lower", "quality", "is", "compensated", "for", "by", "quantity.", "Liu et al. (2019)", "report", "a", "large", "improvement", "for", "their", "DRS", "parser", "when", "first", "training", "on", "the", "bronze", "and", "silver", "data,", "then", "\"fine-tuning\"", "on", "gold", "data.", "Since", "we", "are", "using", "a", "Transformer", "model", "like", "them,", "we", "expected", "this", "technique", "could", "also", "boost", "our", "parser's", "performance.", "Thus,", "we", "tested", "our", "model", "with", "5", "epochs", "training", "on", "silver", "and", "bronze", "followed", "by", "5", "epochs", "on", "gold.", "The", "results", "are", "shown", "in", "Table", "5.", "They", "confirm", "that", "more", "data", "means", "better", "results", "even", "when", "the", "data", "is", "not", "perfect.", "Although", "the", "bigger", "training", "set", "also", "increases", "the", "number", "of", "classes", "for", "all", "three", "labels", "more", "than", "10-fold,", "the", "model", "seems", "to", "handle", "it", "just", "fine.", "The", "only", "downside", "is", "the", "longer", "training", "time:", "as", "the", "silver", "and", "bronze", "sets", "for", "English", "are,", "respectively,", "21", "and", "25", "times", "larger", "than", "the", "gold", "one,", "the", "time", "consumption", "jumps", "from", "a", "few", "minutes", "to", "more", "than", "10", "hours.", "2019)", "with", "the", "addition", "of", "BERT", "embeddings,", "and", "their", "\"best\"", "model", "encodes", "the", "character", "embedding", "and", "the", "BERT", "embedding", "separately", "before", "feeding", "their", "concatenated", "vector", "into", "the", "decoder,", "which", "achieved", "state-of-the-art", "results.", "Worth", "noting", "is", "their", "claim", "that", "it's", "best", "to", "keep", "BERT", "parameters", "\"frozen\",", "which", "we", "did", "not", "find", "to", "be", "the", "case", "for", "our", "model:", "in", "preliminary", "experimentation,", "finetuning", "BERT", "parameters", "with", "our", "model", "outperformed", "a", "corresponding", "frozen", "model", "by", "20%", "in", "Counter", "f-score."], "cited_papers": [{"title": "Discourse representation parsing for sentences and documents", "year": "2019", "authors": ["Jiangming Liu", "Shay Cohen", "Mirella Lapata"]}], "target_citation_location": 38, "citation_locations": [38], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "89153e94-6fe3-4973-84a9-a0f2e639e0ea", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["The", "transliteration", "of", "text", "and", "audio", "data", "into", "phonetic", "representations", "presents", "several", "other", "challenges", "related", "to", "potential", "loss", "of", "information", "or", "injection", "of", "noise:", "1.", "Loss", "of", "suprasegmental", "information:", "In", "some", "languages,", "meaning", "may", "be", "encoded", "through", "tones,", "or", "pitch", "changes", "across", "sounds", "(aka", "across", "segments,", "or", "\"suprasegmental\").", "Particularly", "for", "tonal", "languages", "such", "as", "Mandarin", "Chinese", "[cmn],", "this", "loss", "can", "represent", "a", "significant", "informational", "loss", "particularly", "for", "homophones", "with", "different", "tones,", "as", "seen", "in", "(Amrhein", "and", "Sennrich,", "2020).", "While", "IPA", "symbols", "can", "represent", "these", "intricacies,", "it", "adds", "complexity", "2.", "Phone/phoneme", "differences:", "As", "noted", "in", "(Li et al., 2020),", "speech", "sounds", "which", "are", "physically", "different", "(different", "phones),", "may", "be", "perceived", "as", "the", "same", "(one", "phoneme)", "by", "speakers", "of", "one", "language,", "but", "these", "same", "sounds", "could", "perhaps", "be", "distinguished", "by", "speakers", "of", "another", "language.", "For", "example,", "the", "French", "words", "words", "bouche,", "and", "b\u00fbche", "contain", "phones", "(/u/", "vs.", "/y/)", "which", "may", "sound", "\"the", "same\"", "to", "English", "speakers,", "but", "are", "semantically", "different", "to", "French", "speakers.", "In", "other", "words,", "in", "English,", "both", "phones", "map", "to", "the", "same", "phoneme", "perceptually.", "As", "the", "Allosaurus", "phone", "recognizer", "recognizes", "the", "actual", "phones/sounds,", "not", "their", "perceived", "phonemes,", "it", "would", "transcribe", "these", "two", "phones", "to", "different", "representations", "even", "for", "English", "speech.", "This", "can", "be", "mitigated", "to", "an", "extent", "by", "customizing", "the", "output", "of", "Allosaurus", "on", "a", "per-language", "basis,", "see", "Sec.", "4.3."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 94, "citation_locations": [94], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "89198528-f577-4afd-baca-63f44b27c280", "citing_paper": {"title": "Comparison of post-editing productivity between professional translators and lay users", "year": 2014, "authors": ["Nora Aranberri", "Gorka Labaka"]}, "text": ["Thanks", "to", "the", "significant", "improvement", "of", "machine", "translation", "(MT)", "over", "the", "past", "two", "decades,", "the", "translation", "industry", "has", "already", "started", "to", "exploit", "it,", "mainly", "by", "combining", "it", "with", "post-editing.", "A", "good", "number", "of", "recent", "works", "report", "a", "productivity", "increase", "thanks", "to", "postediting", "of", "MT", "output", "as", "compared", "to", "the", "traditional", "human", "translation", "(e.g.,", "Guerberof, 2009, Plitt and Masselot, 2010, Garcia, 2011, Pouliquen et al., 2011, Skadi\u0146\u0161 et al., 2011, den Bogaert and Sutter, 2013, Green et al., 2013, L\u00e4ubli et al., 2013)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Productivity or quality? Let's do both", "year": "2013", "authors": ["J Van Den Bogaert", "unk De", "N Sutter"]}, {"title": "The efficacy of human post-editing for language translation", "year": "2013", "authors": ["S Green", "J Heer", "C Manning"]}, {"title": "A productivity test of statistical machine translation post-editing in a typical localisation context", "year": "2010", "authors": ["M Plitt", "F Masselot"]}, {"title": "Productivity and quality in MT post-editing", "year": "2009", "authors": ["A Guerberof"]}, {"title": "Tapta: A user-driven translation system for patent documents based on domain-aware statistical machine translation", "year": "2011", "authors": ["B Pouliquen", "C Mazenc", "A Iorio"]}], "target_citation_location": 53, "citation_locations": [53], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1]]}
{"id": "8970ced6-b992-4e58-a3a8-a1dc27965bb3", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Text-based", "Game", "Playing", "and", "Generation.", "Recent", "text", "game", "playing", "works", "have", "focused", "on", "tackling", "three", "primary", "challenges:", "(1)", "how", "to", "represent", "agent", "knowledge", "to", "effectively", "operate", "in", "partially", "observable", "environments", "(Adhikari et al., 2020, Sautier et al., 2020),", "(2)", "scaling", "RL", "algorithms", "to", "handle", "combinatorial", "natural", "language", "state-action", "spaces", "(Zahavy et al., 2018, Ammanabrolu and Hausknecht, 2020, Jang et al., 2021),", "and", "(3)", "giving", "agents", "commonsense", "priors", "to", "better", "reason", "about", "the", "world", "(Murugesan et al., 2020 (Murugesan et al., , 2021) )", "On", "the", "flip", "side,", "we", "have", "procedural", "generation", "of", "games", "with", "works", "such", "as", "Short", "and", "Adams", "(2017),", "Risi", "and", "Togelius", "(2019),", "Khalifa", "et", "al."], "cited_papers": [{"title": "Graph Constrained Reinforcement Learning for Natural Language Action Spaces", "year": "2020", "authors": ["Prithviraj Ammanabrolu", "Matthew Hausknecht"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 42, "citation_locations": [30, 42, 55], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "8a6098c6-62c2-417d-a4f6-b9619982fddd", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["where", "X", "\u2208", "{A,", "B,", "C,", "D}).", "We", "consider", "two", "settings", "where", "each", "generative", "factor", "is", "embedded", "in", "a", "single", "dimension", "(denoted", "by", "Ex.1),", "or", "two", "dimensions", "(denoted", "by", "Ex.2).", "In", "each", "setting", "we", "uniformly", "sample", "20", "values", "from", "-1", "to", "1", "to", "represent", "20", "assignments", "per", "factor", "and", "use", "them", "to", "allocate", "the", "assignments", "into", "distinctive", "bins", "per", "each", "corresponding", "dimension.", "By", "concatenating", "dimensions", "for", "each", "generative", "factor,", "we", "construct", "two", "ideal", "disentangled", "representations", "for", "data", "points", "in", "this", "toy", "dataset,", "amounting", "to", "4", "and", "8", "dimensional", "representations,", "respectively.", "Using", "these", "representations", "(skipping", "the", "encoding", "step),", "we", "measured", "the", "above", "metrics.", "Table", "1", "(Ex.1", "and", "Ex.2", "columns)", "summarises", "the", "results,", "illustrating", "that", "out", "of", "the", "6", "metrics,", "Higgins et al. (2017),", "Ridgeway", "and", "Mozer", "(2018),", "Kim and Mnih (2018)", "are", "the", "only", "ones", "that", "reach", "the", "potential", "maximum", "(i.e.,", "100),", "while", "Chen et al. (2018)", "exhibits", "its", "sensitivity", "towards", "completeness", "when", "we", "allocate", "two", "dimensions", "per", "factors."], "cited_papers": [{"title": "Isolating sources of disentanglement in variational autoencoders", "year": "2018", "authors": ["T Ricky", "Xuechen Chen", "unk Li", "B Roger", "David Grosse", "unk Duvenaud"]}], "target_citation_location": 136, "citation_locations": [118, 123, 136], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "8a7cbc11-0280-4372-8b0d-3a0186874df3", "citing_paper": {"title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables", "year": 2022, "authors": ["Nan Hu", "Zirui Wu", "Yuxuan Lai", "Xiao Liu", "Yansong Feng"]}, "text": ["Following", "the", "widely", "adopted", "fact", "verification", "pipeline", "(Thorne et al., 2018, Aly et al., 2021),", "we", "take", "three", "steps", "to", "solve", "the", "FEVEROUS", "task", "(i)", "retrieving", "pages", "from", "the", "Wikipedia", "dump,", "(ii)", "extracting", "evidence", "from", "the", "retrieved", "pages,", "and", "(iii)", "verifying", "the", "claim", "according", "to", "extracted", "evidence."], "cited_papers": [{"title": "Feverous: Fact extraction and verification over unstructured and structured information", "year": "2021", "authors": ["Rami Aly", "Zhijiang Guo", "M Schlichtkrull", "James Thorne"]}, {"title": "FEVER: a large-scale dataset for fact extraction and VERification", "year": "2018", "authors": ["James Thorne", "Andreas Vlachos", "Christos Christodoulopoulos", "Arpit Mittal"]}], "target_citation_location": 7, "citation_locations": [7], "citation_type": "group", "annotations": [[2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "8aa01f75-555a-4236-987b-0719b4b890b5", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Twitter", "has", "been", "the", "most", "common", "online", "platform", "from", "which", "researchers", "have", "sourced", "datasets", "with", "user", "and", "community", "information.", "Gal\u00e1n-Garc\u00eda", "et", "al.", "(2016)", "constructed", "a", "dataset", "of", "1,", "900", "tweets", "from", "19", "different", "twitter", "accounts", "with", "time", "of", "publication,", "language,", "and", "geo-position", "for", "each", "tweet", "taken", "from", "the", "profile", "of", "the", "user", "who", "created", "it.", "Waseem and Hovy (2016)", "released", "a", "list", "of", "16,", "907", "tweet", "IDs", "along", "with", "their", "corresponding", "annotations,", "labeling", "each", "tweet", "as", "racist,", "sexist", "or", "neither.", "For", "each", "tweet,", "the", "dataset", "contains", "the", "gender", "of", "the", "user", "who", "created", "it", "along", "with", "their", "geo-location.", "Since", "Twitter", "APIs", "allow", "researchers", "to", "access", "information", "about", "a", "user", "given", "a", "tweet", "ID,", "the", "dataset", "of", "Waseem and Hovy (2016)", "was", "expanded", "by", "Mishra et al. (2018a)", "to", "include", "the", "follower-following", "information", "amongst", "users", "who", "created", "the", "tweets", "contained", "in", "the", "dataset.", "Ribeiro et al. (2018)", "2016)", "which", "respective", "contain", "5,", "668", "Portuguese", "tweets", "and", "13,", "766", "German", "tweets", "by", "using", "Twitter", "APIs", "to", "get", "user", "information", "such", "as", "gender,", "number", "of", "followers,", "number", "of", "status", "updates,", "etc.", "Deviating", "from", "Twitter,", "Pavlopoulos et al. (2017b)", "released", "a", "dataset", "of", "1.45M", "abusive", "and", "benign", "comments", "in", "Greek", "sourced", "from", "the", "news", "portal", "Gazzetta.", "For", "each", "comment,", "the", "dataset", "also", "contains", "the", "ID", "of", "the", "user", "who", "created", "the", "comment."], "cited_papers": [{"title": "Author profiling for abuse detection", "year": "2018", "authors": ["Pushkar Mishra", "Marco Tredici", "Helen Yannakoudakis", "Ekaterina Shutova"]}], "target_citation_location": 117, "citation_locations": [55, 113, 117, 133, 169], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8ac851c4-743d-44ca-b84a-fd8f86c00f6c", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["The", "study", "uses", "a", "self-built", "corpus.", "Since", "the", "phenomenon", "of", "public", "apologies", "is", "relatively", "recent", "in", "India,", "we", "could", "only", "access", "a", "corpus", "of", "18", "apologies", "available", "in", "the", "digital", "public", "domain,", "offered", "during", "2007-2017.", "The", "corpus", "is", "in", "the", "English", "language", "as", "it", "is", "the", "second", "official", "language", "in", "India.", "It", "is", "the", "lingua", "franca", "spoken", "amongst", "a", "wide", "proportion", "of", "the", "population", "and", "has", "about", "125", "million", "speakers,", "which", "is,", "country-wise,", "the", "second", "highest", "in", "the", "world,", "only", "below", "United", "States", "of", "America", "4.", "We", "employ", "a", "close", "reading", "approach", "(Amernic et al., 2007)", "for", "the", "analysis.", "All", "of", "the", "selected", "apologies", "were", "delivered", "in", "India,", "by", "Indians", "so", "as", "to", "understand", "any", "cultural", "implication", "of", "the", "communication.", "All", "of", "these", "were", "offered", "by", "senior", "executives", "of", "the", "company", "or", "prominent", "public", "personalities", "in", "India.", "Of", "these", "two", "were", "electronic", "mails,", "seven", "were", "letters,", "four", "were", "blog", "posts,", "four", "were", "tweets", "out", "of", "which", "two", "are", "related", "to", "the", "same", "event,", "and", "one", "was", "a", "media", "statement.", "Out", "of", "the", "18", "apologies,", "11", "were", "given", "by", "individual(s)", "in", "a", "role,", "3", "were", "given", "by", "organizations", "and", "4", "were", "given", "by", "individuals.", "The", "gender-wise", "distribution", "of", "the", "apology", "givers", "is", "14", "males", "and", "4", "females.", "The", "apologies", "selected", "have", "been", "assigned", "a", "code", "number", "for", "easy", "reference."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 92, "citation_locations": [92], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8b00fba7-4317-471f-98ff-f91a916027f5", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["In", "this", "section,", "we", "benchmark", "top-k", "attention", "in", "terms", "of", "time", "and", "memory,", "and", "compare", "it", "to", "vanilla", "attention,", "query-chunking", "without", "the", "top-k", "operation,", "and", "to", "Performer", "(Choromanski et al., 2021),", "as", "a", "representative", "of", "state-of-the-art", "linear", "attention", "variants.", "We", "separately", "benchmark", "(a)", "a", "single", "self-attention", "layer", "over", "long", "sequences,", "(b)", "a", "single", "feed-forward", "layer", "with", "a", "large", "feedforward", "dimension,", "and", "(c)", "a", "12-layer", "Transformer", "decoder", "with", "same", "architecture", "as", "BERT-base", "(Devlin et al., 2019)."], "cited_papers": [{"title": "Rethinking attention with performers", "year": "2021", "authors": ["Valerii Krzysztof Marcin Choromanski", "David Likhosherstov", "Xingyou Dohan", "Andreea Song", "Tamas Gane", "Peter Sarlos", "Jared Hawkins", "Afroz Davis", "Lukasz Mohiuddin", "David Kaiser", "Lucy Belanger", "Adrian Colwell", "unk Weller"]}], "target_citation_location": 27, "citation_locations": [27, 68], "citation_type": "single", "annotations": [[0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8bc60d2e-6458-4108-9fca-aec671910615", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["To", "the", "best", "of", "our", "knowledge,", "we", "are", "the", "first", "work", "to", "explore", "diverse", "knowledge", "reasoning", "on", "commonsense", "KG", "to", "generate", "multiple", "diverse", "output", "sequences.", "Therefore,", "we", "only", "compared", "our", "MoKGE", "with", "existing", "diversity-promoting", "baselines", "without", "using", "knowledge", "graph.", "VAE-based", "method.", "The", "variational", "auto-encoder", "(VAE)", "(Kingma", "and", "Welling,", "2014)", "is", "a", "deep", "generative", "latent", "variable", "model.", "VAE-based", "methods", "produce", "diverse", "outputs", "by", "sampling", "different", "latent", "variables", "from", "an", "approximate", "posterior", "distribution.", "CVAE-SVG", "(SVG", "is", "short", "for", "sentence", "variant", "generation)", "(Gupta et al., 2018)", "is", "a", "conditional", "VAE", "model", "that", "can", "produce", "multiple", "outputs", "based", "an", "original", "sentence", "as", "input.", "MoE-based", "method.", "Mixture", "models", "provide", "an", "alternative", "approach", "to", "generate", "diverse", "outputs", "by", "sampling", "different", "mixture", "components.", "We", "compare", "against", "two", "mixture", "of", "experts", "(MoE)", "implementations", "by", "Shen et al. (2019)", "and", "Cho et al. (2019).", "We", "refer", "them", "as", "MoE-prompt", "(Shen et al., 2019)", "and", "MoE-embed", "(Cho et al., 2019).", "Sampling-based", "method.", "Sampling", "methods", "create", "diverse", "outputs", "by", "sampling", "next", "token", "widely", "from", "the", "vocabulary.", "We", "compare", "against", "two", "sampling", "algorithms", "for", "decoding,", "including", "truncated", "sampling", "(Fan et al., 2018)", "and", "nucleus", "sampling", "(Holtzman et al., 2020).", "Truncated", "sampling", "(Fan et al., 2018)", "randomly", "samples", "words", "from", "top-k", "probability", "candidates", "of", "the", "predicted", "distribution", "at", "each", "decoding", "step.", "Nucleus", "sampling", "(Holtzman et al., 2020)", "avoids", "text", "degeneration", "by", "truncating", "the", "unreliable", "tails", "and", "sampling", "from", "the", "dynamic", "nucleus", "of", "tokens", "containing", "the", "vast", "majority", "of", "the", "probability", "mass."], "cited_papers": [{"title": "Hierarchical neural story generation", "year": "2018", "authors": ["Angela Fan", "Mike Lewis", "Yann Dauphin"]}], "target_citation_location": 161, "citation_locations": [79, 123, 125, 131, 134, 161, 165, 168, 186], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8c251b9f-ad18-4b1e-8565-968f09bef670", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["We", "create", "entity", "representations", "of", "a", "mention", "span", "m", "and", "a", "context", "s", "using", "ELMo", "(Peters et al., 2018)", "and", "BERT", "(Devlin et al., 2019).", "We", "largely", "follow", "the", "embedding", "procedure", "of", "Chen et al. (2019).", "Their", "downstream", "models", "use", "trainable", "weights", "to", "combine", "the", "vectors", "from", "the", "pre-trained", "model", "layers,", "we", "use", "this", "in", "the", "baselines", "as", "well", "except", "for", "the", "results", "in", "Table", "4", "and", "for", "ELMo.", "Note", "that", "we", "do", "not", "fine", "tune", "the", "ELMo", "and", "BERT", "parameters", "of", "the", "baselines,", "since", "our", "focus", "is", "on", "general", "entity", "representations", "that", "can", "work", "off-the-shelf", "rather", "than", "task", "specific", "entity", "representations.", "Our", "approach", "does", "not", "use", "task", "specific", "fine", "tuning", "either.", "ELMO", "We", "run", "ELMo", "on", "the", "entire", "sentence", "s", "and", "combine", "the", "three", "layer", "outputs", "using", "uniform", "weights.", "Then,", "we", "average", "contextualized", "vectors", "of", "the", "mention", "span", "m", "to", "obtain", "the", "entity", "representation."], "cited_papers": [{"title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 18, "citation_locations": [15, 18, 26], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8c291514-72c3-47ec-885c-c28956296a8b", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["With", "the", "regularization", "values,", "we", "fed", "several", "machine", "learning", "algorithms", "to", "identify", "and", "predict", "toxic", "comments.", "We", "experimented", "Multi", "Layer", "Perceptron,", "Na\u00efve", "Bayes,", "Decision", "Tree,", "Support", "Vector", "Machine,", "and", "Gradient", "Boosting", "from", "the", "Scikit-Learn", "library", "(Pedregosa et al., 2011)."], "cited_papers": [{"title": "Scikit-learn: Machine learning in Python", "year": "2011", "authors": ["F Pedregosa", "G Varoquaux", "A Gramfort", "V Michel", "B Thirion", "O Grisel", "M Blondel", "P Prettenhofer", "R Weiss", "V Dubourg", "J Vanderplas", "A Passos", "D Cournapeau", "M Brucher", "M Perrot", "E Duchesnay"]}], "target_citation_location": 35, "citation_locations": [35], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]]}
{"id": "8c96e170-7a8c-40c1-af7d-0f98bc149678", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["we", "have", "a", "single", "multiclass", "head", "that", "outputs", "the", "connecting", "preposition", "or", "NONE,", "in", "case", "the", "NPs", "are", "not", "connected.", "We", "also", "experiment", "with", "a", "frozen", "(or", "''probing'')", "variant", "of", "both", "models,", "in", "which", "we", "keep", "the", "MLM", "frozen,", "and", "update", "only", "the", "NP", "encoding", "and", "prediction", "heads.", "The", "frozen", "architecture", "is", "intended", "to", "quantify", "the", "degree", "to", "which", "the", "pretrained", "MLM", "encodes", "the", "relevant", "information,", "and", "it", "is", "very", "similar", "to", "the", "edge-probing", "architecture", "of", "Tenney et al. (2018).", "Finally,", "the", "static", "variant", "aims", "to", "measure", "how", "well", "a", "model", "can", "perform", "with", "NPs", "alone,", "without", "considering", "their", "context.", "This", "model", "sums", "all", "the", "static", "embeddings", "of", "each", "span", "and", "uses", "the", "same", "modeling", "as", "the", "coupled", "prediction.", "This", "baseline", "uses", "the", "300-dim", "word2vec", "non-contextualized", "embeddings", "(Mikolov et al., 2013).", "We", "experiment", "with", "two", "versions:", "decoupled", "and", "coupled."], "cited_papers": [{"title": "What do you learn from context? Probing for sentence structure in contextualized word representations", "year": "2018", "authors": ["Ian Tenney", "Patrick Xia", "Berlin Chen", "Alex Wang", "Adam Poliak", "Thomas Mccoy", "Najoung Kim", "Benjamin Van Durme", "Samuel Bowman", "Dipanjan Das", "Ellie Pavlick"]}], "target_citation_location": 76, "citation_locations": [76, 124], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8cc235c3-772d-408a-a3cc-faa89c54e974", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["Mixture", "Modelling", "[8],", "a", "well-established", "technique", "for", "combining", "multiple", "models,", "has", "been", "extensively", "used", "for", "language", "model", "adaptation", "in", "SMT", "[4].", "This", "technique", "has", "also", "been", "used", "for", "adapting", "the", "translation", "model", "in", "SMT", "with", "limited", "success", "[9].", "For", "the", "given", "task,", "since", "the", "size", "of", "the", "'in-domain'", "data", "was", "not", "significantly", "large,", "we", "used", "'suitable'", "subsets", "of", "data", "from", "the", "other", "available", "'out-ofdomain'", "corpora", "to", "enrich", "the", "models.", "For", "a", "mixture", "adapted", "language", "model,", "the", "probability", "of", "an", "n-gram", "hw", "is", "given", "as", "in", "(2):P", "r", "mix", "(w|h)", "=", "f", "*", "mix", "(w|h)", "+", "\u03bb", "mix", "(h)P", "r", "mix", "(w|", "h)", "(2)where", "w", "is", "the", "current", "word,", "h", "is", "the", "corresponding", "history,", "f", "*", "mix", "is", "the", "mixture", "model", "discounted", "relative", "fre-quency,", "\u03bb", "mix", "indicates", "the", "mixture", "model", "zero-frequency", "estimate", "and", "hw", "is", "the", "lower", "order", "n", "\u2212", "1", "gram.", "The", "discounted", "frequency", "and", "zero-frequency", "estimates", "are", "defined", "as", "follows:"], "cited_papers": [{"title": "Domain adaptation in statistical machine translation of user-forum data using componentlevel mixture modelling", "year": "2011", "authors": ["P Banerjee", "S Naskar", "J Roturier", "A Way", "J Van Genabith"]}], "target_citation_location": 37, "citation_locations": [2, 20, 37], "citation_type": "single", "annotations": [[3, 3, 0, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8e121d63-4fc5-4513-a494-4adc9cd3a10d", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["The", "training", "paradigm", "proposed", "in", "this", "paper", "may", "be", "extended", "to", "any", "Seq2Seq", "model.", "However,", "it", "can", "be", "a", "non-trivial", "overhead", "to", "generate", "the", "candidate", "summaries", "using", "large", "neural", "models", "on", "the", "entire", "training", "set.", "On", "the", "other", "hand,", "recent", "work", "(Raffel et al., 2020, Zhang et al., 2020, Schick and Sch\u00fctze, System Summary", "Reference", "chelsea", "forward", "tammy", "abraham", "nets", "first-half", "double", "for", "chelsea.", "dominic", "solanke", "adds", "a", "third", "late", "on", "as", "chelsea", "look", "set", "to", "win", "trophy.", "manchester", "city", "struggle", "without", "injured", "star", "thierry", "ambrose.", "read:", "mourinho", "warns", "his", "young", "chelsea", "players", "he", "can", "not", "play", "them", "all.", "click", "here", "to", "read", "our", "match", "report", "from", "man", "city", "'s", "academy", "stadium."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Exploring the limits of transfer learning with a unified text-totext transformer", "year": "2020", "authors": ["Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter Liu"]}], "target_citation_location": 41, "citation_locations": [41], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8e19c4ef-6fa8-43cd-98ec-d6a6b29e25d0", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["Construction", "with", "masked", "language", "model.", "We", "construct", "neighborhood", "sentences", "from", "x", "0", "by", "substituting", "at", "most", "k", "tokens.", "As", "shown", "in", "Algorithm", "1,", "the", "construction", "employs", "a", "recursive", "approach", "and", "replaces", "one", "token", "at", "a", "time.", "For", "each", "recursion,", "the", "algorithm", "first", "masks", "each", "token", "of", "the", "input", "sentence", "(may", "be", "the", "original", "x", "0", "or", "the", "x", "from", "last", "recursion)", "separately", "and", "predicts", "likely", "replacements", "with", "a", "masked", "language", "model", "(e.g.,", "DistilBERT, Sanh et al. 2019).", "To", "ensure", "the", "naturalness,", "we", "keep", "the", "top", "20", "tokens", "for", "each", "mask", "with", "the", "largest", "logit", "(subject", "to", "a", "threshold,", "Line", "9).", "Then,", "the", "algorithm", "constructs", "neighborhood", "sentences", "by", "replacing", "the", "mask", "with", "found", "tokens.", "We", "use", "the", "notation", "x", "in", "the", "following", "sections", "to", "denote", "the", "constructed", "sentences", "within", "the", "neighborhood.", "L", "\u2190", "SortDecreasing(L),", "9", "lmin", "\u2190", "max{L", "(\u03ba),", "L", "(0)", "\u2212", "\u03b4},"], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 72, "citation_locations": [72], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8e41a066-a5c1-4ca7-b26c-f8b9ee46857d", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["Culturally,", "saying", "sorry", "does", "not", "come", "easy", "to", "Indians", "and", "more", "so", "to", "Indian", "business", "and", "political", "leaders.", "This", "hesitation", "can", "perhaps", "be", "linked", "to", "the", "fact", "that", "in", "India", "a", "public", "apologyis", "seen", "as", "an", "admission", "of", "guilt", "(Maddux et al, 2012).", "On", "the", "other", "hand", "it", "is", "a", "common", "occurrence", "in", "countries", "like", "Japan", "and", "Hong", "Kong,", "where", "the", "corporate", "apology", "is", "an", "expression", "of", "eagerness", "to", "repair", "damage", "and", "relationships", "and", "does", "not", "imply", "guilt", "(ibid).", "In", "the", "past,", "the", "speech", "act", "of", "apology", "was", "almost", "absent", "from", "the", "repertoire", "of", "Indian", "corporates", "and", "public", "figures", "(Kaul et al,2015).", "Even", "written", "apologies", "were", "very", "few", "and", "were", "offered", "only", "when", "there", "was", "a", "strong", "demand", "from", "different", "sections", "of", "society.", "However,", "the", "new", "generation", "e-commerce", "companies", "seem", "to", "be", "heralding", "an", "attitudinal", "change", "in", "this", "corporate", "practice.", "This", "could", "be", "due", "to", "the", "increasing", "digital", "customer", "base", "for", "India", "Inc.", "India's", "internet", "user", "base", "has", "grown", "to", "324.95", "million", "in", "September", "2015,", "a", "27.73%", "YOY", "growth", "(TRAI,", "2016).", "On", "social", "media", "platforms", "situations", "can", "escalate", "rapidly,", "breaking", "down", "the", "traditional", "barriers", "of", "time,", "location,", "and", "gatekeepers", "of", "information", "(Kaul et al, 2015).", "Thus,", "in", "stark", "contrast", "to", "the", "past,", "we", "see", "a", "spate", "of", "apology", "e-mails,", "tweets", "and", "blog", "posts", "being", "offered", "by", "e-commerce", "players", "(ibid).", "Figure", "1", "shows", "the", "rising", "trend", "of", "apologies", "being", "given", "publicly", "in", "the", "written", "digital", "media,", "with", "a", "sharp", "increase", "from", "the", "year", "2016", "to", "2017.", "Since", "the", "practice", "of", "offering", "a", "public", "apology", "is", "relatively", "new", "for", "Indian", "businesses,", "it", "is", "to", "be", "understood", "that", "an", "apology", "not", "delivered", "effectively", "rather", "than", "mitigating", "the", "damage,", "can", "escalate", "the", "damage", "done.", "In", "this", "context,", "it", "is", "important", "to", "analyze", "the", "lexical", "choice", "made", "in", "these", "apologies", "and", "the", "implications", "thereof."], "cited_papers": [{"title": "Why 'I'm sorry' doesn't always translate", "year": "2012", "authors": ["William Maddux", "Peter Kim", "Tetsushi Okumara", "Jeanne Brett"]}], "target_citation_location": 39, "citation_locations": [39, 96, 186], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8e8a93fe-50f6-4b0c-b432-a51eb572b7ad", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["Subjective", "evaluation", "was", "performed", "after", "first", "poor", "BLEU", "results", "triggered", "some", "distrust.", "Many", "authors", "agree", "that", "BLEU", "metric", "systematically", "penalizes", "RBMT", "systems", "(Callison-Burch et al., 2006)", "and", "it", "is", "not", "suited", "for", "highly", "inflexible", "languages.", "Authors", "of", "METEOR", "(Banerjee et al., 2005),", "(Lavie, 2007)", "state", "that", "their", "system", "fixes", "most", "of", "the", "problems", "encountered", "using", "BLEU", "metric,", "they", "state", "that", "METEOR", "correlates", "highly", "with", "human", "judgement.", "Unfortunately", "METEOR", "does", "not", "support", "our", "language", "pair,", "we", "hope", "to", "change", "this", "in", "the", "near", "future,", "see", "further", "work", "Separate", "scales", "for", "fluency", "and", "adequacy", "were", "developed", "under", "the", "assumption", "that", "a", "translation", "might", "be", "disfluent", "but", "contain", "all", "the", "information", "from", "the", "source."], "cited_papers": [{"title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments", "year": "2005", "authors": ["S Banerjee", "A Lavie"]}], "target_citation_location": 35, "citation_locations": [22, 35, 36], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "8eae5aa3-977e-4b76-9a0c-c70cc5aadb3a", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["To", "test", "how", "well", "our", "data", "is", "suited", "for", "emotion", "projection,", "we", "projected", "the", "English", "annotations", "onto", "our", "Finnish", "unannotated", "data", "using", "OPUS", "tools", "(Aulamo et al., 2020).", "We", "chose", "Finnish", "as", "our", "main", "test", "language", "as", "we", "also", "have", "some", "annotated", "data", "for", "it", "to", "use", "as", "a", "test", "set.", "The", "manually", "annotated", "Finnish", "data", "consists", "of", "nearly", "20k", "individual", "annotations", "and", "almost", "15k", "unique", "annotated", "sentences", "plus", "an", "additional", "7,536", "sentences", "annotated", "as", "neutral", "6.", "The", "criteria", "for", "the", "inclusion", "of", "an", "annotation", "was", "the", "same", "as", "for", "English.", "The", "distribution", "of", "the", "number", "of", "labels", "and", "the", "labels", "themselves", "are", "quite", "similar", "to", "that", "of", "the", "English", "data.", "Relatively", "speaking", "there", "is", "a", "little", "less", "anticipation", "in", "the", "Finnish", "data,", "but", "anger", "is", "the", "biggest", "category", "in", "both", "languages.", "We", "used", "the", "11,128", "Finnish", "sentences", "for", "which", "directly", "parallel", "sentences", "existed", "and", "projected", "the", "English", "annotations", "on", "them", "using", "the", "unique", "alignment", "IDs", "for", "both", "languages", "as", "guide.", "Some", "of", "those", "parallel", "sentences", "were", "part", "of", "our", "already", "annotated", "data", "and", "were", "discarded", "as", "training", "data.", "This", "served", "as", "a", "useful", "point", "of", "comparison.", "The", "average", "annotation", "correlation", "using", "Cohen's", "kappa", "is", "0.44", "(although", "accuracy", "by", "percentage", "is", "over", "90%),", "and", "highest", "for", "joy", "at", "0.65,", "showing", "that", "annotation", "projection", "differs", "from", "human", "annotation", "to", "a", "similar", "degree", "as", "human", "annotations", "differ", "from", "each", "other."], "cited_papers": [{"title": "OpusTools and Parallel Corpus Diagnostics", "year": "2020", "authors": ["Mikko Aulamo", "Umut Sulubacak", "Sami Virpioja", "J\u00f6rg Tiedemann"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8eb9eece-4177-403b-99c2-f7d2e46ba907", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["For", "our", "PBSMT-based", "translation", "experiments", "we", "used", "OpenMaTrEx", "[15],", "an", "open", "source", "SMT", "system", "which", "provides", "a", "wrapper", "around", "the", "standard", "log-linear", "phrase-based", "SMT", "system", "Moses", "[6].", "Word", "alignment", "was", "performed", "using", "Giza++", "[16].", "The", "phrase", "and", "the", "reordering", "tables", "were", "built", "on", "the", "word", "alignments", "using", "the", "Moses", "training", "script.", "The", "feature", "weights", "for", "the", "log-linear", "combination", "of", "the", "feature", "functions", "were", "tuned", "using", "Minimum", "Error", "Rate", "Training", "(MERT)", "[7]", "on", "the", "devset", "with", "respect", "to", "BLEU", "[17].", "We", "used", "5-gram", "language", "models", "in", "all", "our", "experiments", "created", "using", "the", "IRSTLM", "language", "modelling", "toolkit", "[18]", "using", "Modified", "Kneser-Ney", "smoothing", "[19].", "Mixture", "adaptation", "of", "language", "models", "mentioned", "in", "Section", "2.2", "was", "also", "performed", "using", "the", "features", "of", "the", "IRSTLM", "toolkit.", "Results", "of", "translations", "in", "every", "phase", "of", "our", "experiments", "were", "evaluated", "using", "BLEU,", "METEOR", "[20]", "and", "TER", "[21]", "metrics.", "The", "datasets", "used", "for", "the", "experiments", "included", "the", "specific", "datasets", "released", "by", "the", "IWSLT", "2011", "evaluation", "campaign.", "The", "primary", "bi-lingual", "training", "data", "comprised", "of", "a", "collection", "of", "public", "speech", "transcriptions", "on", "a", "variety", "of", "topics", "from", "TED", "Talks.", "The", "development", "data", "released", "for", "the", "task,", "comprised", "of", "both", "the", "IWSLT-2010", "4", "development", "and", "test", "sets.", "However,", "for", "experiments", "reported", "in", "this", "paper,", "the", "IWSLT-2010", "development", "set", "and", "test", "sets", "were", "used", "for", "tuning", "and", "testing", "respectively.", "As", "an", "auxiliary", "out-of-domain", "source", "of", "bi-lingual", "training", "data,", "the", "Multi-UN", "corpus", "was", "also", "released.", "The", "monolingual", "data", "required", "to", "train", "lan-guage", "models", "also", "comprised", "of", "data", "from", "both", "Multi-UN", "and", "TED", "Talks.", "Table", "1", "shows", "the", "exact", "sentence", "counts", "of", "the", "different", "datasets", "used", "in", "the", "experiments."], "cited_papers": [{"title": "Meteor: an automatic metric for mt evaluation with high levels of correlation with human judgments", "year": "2007", "authors": ["A Lavie", "A Agarwal"]}], "target_citation_location": 134, "citation_locations": [8, 26, 33, 70, 78, 95, 100, 134, 137], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8f0f30f4-6921-4847-a820-1ffeae7c273a", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["LIGHT-Original.", "The", "task", "itself", "dervied", "from", "the", "original", "LIGHT", "dataset", "(Urbanek et al., 2019)", "and", "involves", "predicting", "the", "next", "action", "or", "utterance", "given", "the", "prior", "dialogue", "history", "as", "well", "as", "the", "current", "setting", "and", "persona", "for", "a", "character.", "They", "are", "collected", "in", "a", "chit-chat", "fashion,", "with", "no", "notion", "of", "objectives,", "and", "so", "provide", "priors", "on", "how", "to", "generally", "act", "consistently", "and", "speak", "in", "a", "fantasy", "world,", "but", "not", "directly", "how", "to", "complete", "quests."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 10, "citation_locations": [10], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8f359163-3ecc-4e7c-ac6d-6d529e3585ab", "citing_paper": {"title": "Diverse dialogue generation with context dependent dynamic loss function", "year": 2020, "authors": ["Ayaka Ueyama", "Yoshinobu Kano"]}, "text": ["However,", "sentence", "diversity", "is", "based", "not", "only", "on", "individual", "tokens,", "but", "also", "on", "the", "token", "sequence.", "We", "are", "able", "to", "compute", "weights", "for", "loss", "functions", "dynamically,", "depending", "on", "the", "context,", "while", "retaining", "the", "fluency", "of", "generated", "sentences.", "We", "propose", "such", "a", "loss", "function,", "Inverse", "N-gram", "Frequency", "(INF)", "loss,", "which", "uses", "the", "inverse", "of", "the", "frequency", "of", "the", "n-gram", "of", "the", "tokens,", "rather", "than", "the", "token", "frequency.", "We", "built", "a", "neural", "dialogue", "system", "trained", "by", "INF", "loss", "using", "huge", "amounts", "of", "dialogue", "data", "extracted", "from", "Twitter.", "After", "comparing", "models", "using", "the", "SCE", "loss,", "the", "ITF", "loss,", "and", "the", "INF", "loss,", "we", "evaluated", "their", "diversity", "and", "fluency.", "Results", "show", "that", "our", "proposed", "INF", "loss", "model", "outperformed", "the", "SCE", "loss", "and", "ITF", "loss", "models", "for", "most", "automatic", "assessment", "measures", "such", "as", "DIST-N", "(Li et al., 2016)", "and", "ROUGE", "(Lin, 2004).", "Our", "INF", "loss", "model", "also", "achieved", "higher", "scores", "on", "our", "human", "evaluations", "of", "coherence", "and", "richness."], "cited_papers": [{"title": "A diversity-promoting objective function for neural conversation models", "year": "2016", "authors": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan"]}], "target_citation_location": 129, "citation_locations": [129, 132], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8f883bbf-1439-4b2d-9310-e0950c5f0985", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["We", "collect", "a", "set", "of", "occurrences", "of", "typed", "entity", "mentions", "using", "hyperlinks", "in", "Wikipedia.", "Given", "a", "sentence", "with", "a", "hyperlink,", "we", "use", "the", "hyperlink", "as", "an", "entity", "mention", "m,", "the", "sentence", "as", "a", "context", "sentence", "s,", "and", "the", "Wiki", "categories", "of", "the", "destination", "page", "as", "the", "gold", "entity", "types", "t", "*.", "We", "use", "the", "preprocessing", "of", "Onoe and Durrett (2020)", "to", "modify", "the", "type", "set:", "they", "introduce", "more", "general", "categories", "into", "the", "Wikipedia", "category", "set", "by", "splitting", "existing", "complex", "categories.", "Following", "their", "work,", "we", "filter", "the", "resulting", "set", "to", "keep", "the", "60,000", "most", "frequent", "types.", "Scraping", "Wikipedia", "yields", "6M", "training", "examples", "that", "cover", "a", "wide", "range", "of", "entities", "and", "entity", "types."], "cited_papers": [{"title": "Fine-Grained Entity Typing for Domain Independent Entity Linking", "year": "2020", "authors": ["Yasumasa Onoe", "Greg Durrett"]}], "target_citation_location": 56, "citation_locations": [56], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8f8c298c-9584-4ccb-966a-4a411183e116", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["The", "use", "of", "synthetic", "datasets", "is", "the", "common", "practice", "for", "evaluating", "disentanglement", "in", "image", "domain", "(Dittadi et al., 2021, Higgins et al., 2017, Kim and Mnih, 2018).", "Generative", "simplistic", "datasets", "in", "image", "domain", "define", "independent", "generative", "factors", "(e.g.", "shape,", "color)", "behind", "the", "data", "generation.", "However,", "a", "comparable", "resource", "is", "missing", "in", "text", "domain.", "We", "develop", "two", "synthetic", "generative", "datasets", "with", "varying", "degrees", "of", "difficulty", "to", "analyse", "and", "measure", "disentanglement:", "The", "YNOC", "dataset", "(\u00a73.1)", "which", "has", "only", "three", "structures", "and", "generative", "factors", "appearing", "in", "every", "sentence,", "and", "the", "POS", "dataset", "(\u00a73.2)", "which", "has", "more", "structures", "while", "some", "generative", "factors", "are", "not", "guaranteed", "to", "appear", "in", "every", "sentence.", "The", "YNOC", "dataset", "offers", "a", "simpler", "setting", "for", "disentanglement.", "The", "templates", "were", "then", "converted", "into", "real", "sentences", "using", "10", "years,", "40", "names,", "20", "occupations,", "and", "30", "cities.", "This", "amounted", "to", "a", "total", "of", "720K", "sentences,", "split", "as", "(60%,20%,20%)", "into", "training,", "validation,", "and", "test", "sets."], "cited_papers": [{"title": "On the transfer of disentangled representations in realistic settings", "year": "2021", "authors": ["Andrea Dittadi", "Frederik Tr\u00e4uble", "Francesco Locatello", "Manuel Wuthrich", "Vaibhav Agrawal", "Ole Winther", "Stefan Bauer", "Bernhard Sch\u00f6lkopf"]}, {"title": "beta-vae: Learning basic visual concepts with a constrained variational framework", "year": "2017", "authors": ["Irina Higgins", "Lo\u00efc Matthey", "Arka Pal", "Christopher Burgess", "Xavier Glorot", "Matthew Botvinick", "Shakir Mohamed", "Alexander Lerchner"]}, {"title": "Disentangling by factorising", "year": "2018", "authors": ["Hyunjik Kim", "Andriy Mnih"]}], "target_citation_location": 15, "citation_locations": [15], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8fd8c1a0-5f91-43bd-8ea5-09c2e85dd4f7", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["where", "h", "v", "and", "h", "r", "are", "node", "embedding", "and", "relation", "embedding.", "We", "define", "the", "compositional", "operation", "as", "\u03d5(h", "u,", "h", "r)", "=", "h", "u", "\u2212h", "r", "inspired", "by", "the", "TransE", "(Bordes et al., 2013).", "The", "relation", "embedding", "is", "also", "updated", "via", "another", "linear", "transformation:"], "cited_papers": [{"title": "Translating embeddings for modeling multirelational data", "year": "2013", "authors": ["Antoine Bordes", "Nicolas Usunier", "Alberto Garcia-Duran", "Jason Weston", "Oksana Yakhnenko"]}], "target_citation_location": 31, "citation_locations": [31], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "8ff309b3-e036-48bb-9f33-81f950527a7c", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["Among", "four", "submitted", "systems,", "MaChAmp", "(der", "Goot,", "2022)", "and", "AN(L)P", "(Ping and Chi, 2022)", "teams", "used", "the", "default", "tokenizer", "from", "either", "BERT", "or", "mBERT,", "which", "are", "not", "designed", "for", "scientific", "documents.", "Consequently,", "they", "are", "unable", "to", "correctly", "segment", "the", "mathematic", "source,", "hence,", "they", "(Popovic and Laurito, 2022)", "and", "JBNU-CCLab", "(Lee", "and", "Na,", "2022)", "achieved", "much", "higher", "performances", "thanks", "to", "SciBERT", "tokenizer", "because", "it", "is", "trained", "on", "scientific", "literature.", "However,", "the", "SciBERT", "tokenizer", "is", "far", "from", "perfect", "such", "that", "JBNU-CCLab", "further", "proposed", "to", "tokenize", "the", "mathematical", "formulae", "using", "a", "customized", "rule-based", "tokenizer", "based", "on", "capital", "letters,", "numbers,", "and", "special", "characters(e.g.", "%,", "$,", "{,", "}).", "Hence,", "they", "achieved", "state-of-the-art", "performance", "on", "both", "NER", "and", "RE", "subtasks."], "cited_papers": [{"title": "Aifbwebscience at semeval-2022 task 12: Relation extraction firstusing relation extraction to identify entities", "year": "2022", "authors": ["Nicholas Popovic", "Walter Laurito"]}], "target_citation_location": 40, "citation_locations": [10, 40], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "902c98f4-4372-4b65-bb0f-8494f0a40f9e", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["An", "important", "desideratum", "of", "natural", "language", "generation", "(NLG)", "is", "to", "produce", "outputs", "that", "are", "not", "only", "correct", "but", "also", "diverse", "(Tevet and Berant, 2021).", "The", "term", "\"diversity\"", "in", "NLG", "is", "defined", "as", "the", "ability", "of", "a", "generative", "model", "to", "create", "a", "set", "of", "possible", "outputs", "that", "are", "each", "valid", "given", "the", "input", "and", "vary", "as", "widely", "as", "possible", "in", "terms", "of", "content,", "language", "style,", "and", "word", "variability", "(Gupta et al., 2018).", "This", "research", "problem", "is", "also", "referred", "as", "one-to-many", "generation", "(Shen et al., 2019, Cho et al., 2019, Yu et al., 2021, Shen et al., 2022)."], "cited_papers": [{"title": "Diversified query generation guided by knowledge graph", "year": "2022", "authors": ["Xinyao Shen", "Jiangjie Chen", "Jiaze Chen", "Chun Zeng", "Yanghua Xiao"]}, {"title": "Mixture models for diverse machine translation: Tricks of the trade", "year": "2019", "authors": ["Tianxiao Shen", "Myle Ott", "Michael Auli", "Marc'aurelio Ranzato"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "Mixture content selection for diverse sequence generation", "year": "2019", "authors": ["Jaemin Cho", "Minjoon Seo", "Hannaneh Hajishirzi"]}], "target_citation_location": 74, "citation_locations": [20, 64, 74], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]]}
{"id": "90f4ac70-239c-48e4-ba75-d03c4b4d92fd", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["EasyEnsemble", "(Liu et al., 2009)", "is", "used", "to", "represent", "a", "tradition", "approach", "in", "dealing", "with", "im-balanced", "dataset.", "For", "the", "vectorization,", "we", "trained", "a", "Sent2Vec", "(Pagliardini et al., 2018)", "using", "the", "combined", "1GB", "texts", "of", "Vietnamese", "Wikipedia", "data", "(Vu et al., 2019)", "and", "19", "GB", "texts", "of", "Vuong", "(2018)."], "cited_papers": [{"title": "Exploratory undersampling for class-imbalance learning", "year": "2009", "authors": ["X Liu", "J Wu", "Z Zhou"]}], "target_citation_location": 1, "citation_locations": [1, 21, 31], "citation_type": "single", "annotations": [[1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "90f84ca1-0448-4af7-870a-737329286161", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["Robust", "models", "(first-order).", "With", "the", "same", "setup", "as", "base", "models,", "we", "apply", "robust", "training", "methods", "to", "improve", "the", "resistance", "to", "word", "substitution", "attacks.", "Jia et al. (2019)", "provide", "a", "provably", "robust", "training", "method", "through", "Interval", "Bound", "Propagation", "(IBP,", "Dvijotham et al. 2018)", "for", "all", "word", "substitutions", "on", "BoW,", "CNN", "and", "LSTM.", "Xu et al. (2020)", "provide", "a", "provably", "robust", "training", "method", "on", "general", "computational", "graphs", "through", "a", "combination", "of", "forward", "and", "backward", "linear", "bound", "propagation,", "and", "the", "resulting", "3-layer", "Transformer", "is", "robust", "to", "up", "to", "6", "word", "substitutions.", "For", "both", "works", "we", "use", "the", "same", "set", "of", "counter-fitted", "synonyms", "provided", "in", "Jia et al. (2019).", "We", "skip", "BERT-base", "due", "to", "the", "lack", "of", "an", "effective", "robust", "training", "method."], "cited_papers": [{"title": "Training verified learners with learned verifiers", "year": "2018", "authors": ["Krishnamurthy Dvijotham", "Sven Gowal", "Robert Stanforth", "Relja Arandjelovic", "O' Brendan", "Jonathan Donoghue", "Pushmeet Uesato", "unk Kohli"]}], "target_citation_location": 35, "citation_locations": [23, 35, 45, 92], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "918e89aa-081d-495c-87d5-f16e00d39556", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["We", "built", "our", "HPB", "baseline", "using", "the", "Moses", "Chart", "Decoder", "[24].", "Continuous", "phrases", "are", "extracted", "according", "to", "the", "phrase", "based", "system", "settings", "explained", "in", "Section", "3.1.", "Maximum", "phrase", "length", "and", "maximum", "rule", "span", "are", "both", "set", "to", "12", "words.", "The", "maximum", "span", "for", "the", "chart", "during", "decoding", "is", "set", "to", "20", "words,", "above", "which", "only", "monotone", "concatenation", "of", "phrases", "is", "used.", "Rules", "extracted", "contain", "up", "to", "2", "non-terminals.", "Adjacent", "non-terminals", "on", "the", "source", "side", "are", "not", "allowed."], "cited_papers": [{"title": "A Unified Framework for Phrase-Based, Hierarchical, and Syntax-Based Statistical Machine Translation", "year": "2009", "authors": ["H Hoang", "P Koehn", "A Lopez"]}], "target_citation_location": 10, "citation_locations": [10], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "918f76f6-851f-47d1-8c82-bb33a68b5a38", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["In", "the", "same", "direction", "but", "with", "the", "other", "output", "information,", "we", "used", "only", "the", "factors", "embedding", "as", "feedback", "(see", "equation", "6).", "fb(y", "t\u22121)", "=", "y", "F", "t\u22121", "(6)", "where", "y", "F", "t\u22121", "is", "the", "embedding", "of", "the", "factors", "generated", "at", "the", "previous", "timestep."], "cited_papers": [{"title": "Large vocabulary SOUL neural network language models", "year": "2011", "authors": ["H.-S Le", "I Oparin", "A Messaoudi", "A Allauzen", "J.-L Gauvain", "F Yvon"]}], "target_citation_location": 27, "citation_locations": [27], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "91cde43a-b6eb-4a07-a90a-a4f58448a65b", "citing_paper": {"title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables", "year": 2022, "authors": ["Nan Hu", "Zirui Wu", "Yuxuan Lai", "Xiao Liu", "Yansong Feng"]}, "text": ["We", "use", "DRQA", "(Chen et al., 2017)", "to", "extract", "k", "sentences", "S", "=", "{s", "i}", "k", "i=1", "and", "n", "tables", "T", "=", "{t", "i}", "n", "i=1", "from", "the", "retrieved", "pages,", "respectively.", "Then", "we", "select", "cells", "from", "the", "extracted", "tables.", "Many", "instances", "in", "the", "FEVEROUS", "dataset", "require", "evidence", "cells", "from", "more", "than", "one", "table,", "and", "each", "retrieved", "table", "has", "different", "relevance", "score", "to", "the", "claim.", "However,", "the", "widely-used", "cell", "extractor", "(Aly et al., 2021)", "reserves", "cells", "from", "only", "one", "table", "in", "their", "implementation."], "cited_papers": [{"title": "Reading Wikipedia to answer opendomain questions", "year": "2017", "authors": ["Danqi Chen", "Adam Fisch", "Jason Weston", "Antoine Bordes"]}], "target_citation_location": 3, "citation_locations": [3, 66], "citation_type": "single", "annotations": [[2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "91ff3108-525b-466c-8e0d-acfae9946731", "citing_paper": {"title": "NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques", "year": 2021, "authors": ["Gunjan Chhablani", "Abheesht Sharma", "Harshit Pandey", "Yash Bhartia", "Shan Suthaharan"]}, "text": ["In", "SemEval", "2020-Task", "11", "(Da San Martino et al., 2020),", "the", "first", "sub-task", "-Span", "Identification", "-aims", "at", "detecting", "the", "beginning", "and", "the", "end", "offset", "for", "the", "propaganda", "spans", "in", "news", "articles.", "This", "sub-task", "is", "similar", "to", "SemEval", "2021-Task", "5.", "The", "proposed", "approaches", "for", "the", "sub-task", "can", "be", "broadly", "classified", "into", "Span", "Prediction", "or", "Token", "Classification.", "Most", "teams", "use", "multi-granular", "transformer-based", "systems", "for", "token", "classification/sequence", "tagging", "(Khosla et al., 2020, Morio et al., 2020, Patil et al., 2020).", "Inspired", "by", "Souza et al. (2019),", "Jurkiewicz et al. (2020)", "use", "RoBERTa-CRF", "based", "systems.", "Li and Xiao (2020)", "use", "a", "variant", "of", "SpanBERT", "span", "prediction", "system."], "cited_papers": [{"title": "Portuguese named entity recognition using BERT-CRF. CoRR, abs", "year": "1909", "authors": ["F\u00e1bio Souza", "Rodrigo Nogueira", "Roberto De", "Alencar Lotufo"]}], "target_citation_location": 63, "citation_locations": [4, 60, 63, 64, 69], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "9286449f-6ac5-4899-adb7-643f6f7754de", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["The", "system", "will", "use", "a", "wide", "variety", "of", "techniques,", "many", "of", "which", "are", "at", "the", "forefront", "of", "research.", "For", "the", "task", "of", "matching", "of", "user's", "input", "with", "the", "stored", "examples,", "parsing", "of", "a", "traditional", "nature", "may", "be", "employed,", "but", "the", "primary", "technique", "will", "involve", "stochastic", "or", "other", "pattern", "matching", "techniques.", "Because", "the", "aim", "is", "to", "match", "inputs", "with", "similar,", "but", "usually", "not", "identical", "examples", "in", "the", "database,", "the", "matching", "techniques", "must", "be", "flexible", "enough", "to", "locate", "a", "range", "of", "candidate", "matches", "against", "a", "given", "input.", "For", "this", "reason,", "pattern", "matching", "incorporating", "a", "similarity", "measure", "is", "indicated,", "such", "as", "the", "techniques", "proposed", "in", "[8, 22, 23, 40],", "though", "we", "are", "also", "experimenting", "with", "a", "connectionist", "approach", "to", "this", "problem", "([28]", ")."], "cited_papers": [{"title": "Example-based machine translation using connectionist matching", "year": "1992", "authors": ["I Mclean"]}], "target_citation_location": 115, "citation_locations": [102, 115], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1]]}
{"id": "9302e68b-36c3-4386-880d-de6016d3afbf", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["In", "Yamamoto", "and", "Church's", "work,", "they", "demonstrate", "how", "interesting", "multiword", "phrases", "can", "be", "discovered,", "by", "interesting", "they", "mean", "phrases", "that", "may", "be", "beneficial", "for", "information", "retrieval", "or", "computational", "lexicography", "as", "determined", "by", "Mutual", "Information", "(MI)", "or", "Residual", "Inverse", "Document", "Frequency", "(RIDF)", "(Church, 1995)", "scores."], "cited_papers": [{"title": "One term or two", "year": "1995", "authors": ["K Church"]}], "target_citation_location": 41, "citation_locations": [41], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "9345a9e3-df15-4903-8f07-eb1ceb169ff2", "citing_paper": {"title": "Corpora and Machine Translation", "year": 1993, "authors": ["Yorick Wilks"]}, "text": ["The", "basic", "AI", "argument", "for", "knowledge-based", "processing", "does", "not", "admit", "defeat", "and", "retreat,", "it", "just", "regroups.", "It", "has", "to", "accept", "Bar", "Hillel's", "old", "anti-MT", "argument", "(Bar", "Hillel", "1960)", "on", "its", "own", "side-i.e.", "that", "as", "he", "said,", "good", "MT", "must", "in", "the", "end", "need", "knowledge", "representations.", "One", "version", "of", "this", "argument", "is", "the", "primitive", "psychological", "one:", "humans", "do", "not", "do", "translation", "by", "exposure", "to", "such", "vast", "texts,", "because", "they", "simply", "have", "not", "had", "such", "exposure,", "and", "in", "the", "end", "how", "people", "do", "things", "will", "prove", "important.", "Note", "that", "this", "argument", "makes", "an", "empirical", "claim", "about", "human", "exposure", "to", "text", "that", "might", "be", "hard", "to", "substantiate.", "This", "argument", "will", "cut", "little", "ice", "with", "our", "opponents,", "but", "there", "may", "still", "be", "a", "good", "argument", "that", "we", "do", "need", "representations", "for", "tasks", "in", "NLP", "related", "to", "MT:", "e.g.", "we", "cannot", "really", "imagine", "doing", "summarization", "or", "question", "answering", "by", "purely", "statistical", "methods,", "can", "we?", "There", "is", "related", "practical", "evidence", "from", "message", "extraction:", "in", "the", "MUC", "competitions", "(Lehnert &amp, Sundheim 1991),", "the", "systems", "that", "have", "done", "best", "have", "been", "hybrids", "of", "preference", "and", "statistics,", "such", "as", "of", "Grishman", "and", "Lehnert,", "and", "not", "pure", "systems", "of", "either", "type."], "cited_papers": [{"title": "A performance evaluation of text analysis technologies", "year": "1991", "authors": ["W Lehnert", "B Sundheim"]}], "target_citation_location": 161, "citation_locations": [161], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "938527d2-d18d-48a8-9c41-6360021f1251", "citing_paper": {"title": "Comparison of post-editing productivity between professional translators and lay users", "year": 2014, "authors": ["Nora Aranberri", "Gorka Labaka"]}, "text": ["The", "attitude", "towards", "post-editing", "or,", "more", "generally,", "MT", "might", "also", "set", "the", "tone", "for", "the", "job", "and", "highlight", "the", "importance", "of", "more", "objective", "measurements", "rather", "than", "basing", "the", "integration", "of", "MT", "on", "translator", "perception", "only.", "The", "mismatch", "between", "the", "translators'", "perception", "of", "productivity", "and", "their", "actual", "productivity", "has", "been", "previously", "reported", "by", "Autodesk,", "specifically", "on", "the", "company's", "follow", "up", "work", "on", "Plitt and Masselot (2010).", "8", "To", "check", "for", "this", "effect,", "we", "asked", "participants", "to", "fill", "in", "a", "short", "questionnaire", "after", "completing", "the", "tasks.", "One", "of", "the", "questions", "asked", "was", "whether", "they", "thought", "having", "the", "MT", "output", "helped", "them", "complete", "the", "translation.", "They", "were", "asked", "to", "mark", "this", "on", "a", "scale", "from", "-5", "to", "5", "where", "-5", "meant", "that", "the", "MT", "output", "had", "greatly", "hindered", "their", "work", "and", "5", "meant", "that", "the", "MT", "output", "had", "greatly", "helped", "their", "work", "(see", "Table", "5).", "Overall,", "users", "were", "more", "positive", "about", "having", "the", "MT", "output", "displayed", "when", "translating,", "with", "only", "one", "out", "of", "six", "claiming", "that", "it", "hindered", "the", "process.", "In", "the", "case", "of", "translators,", "however,", "three", "out", "of", "six", "heavily", "penalized", "its", "use,", "one", "reported", "that", "it", "was", "better", "than", "not", "having", "it,", "and", "two", "reported", "some", "benefit.", "T1", "commented", "that", "translation", "and", "post-editing", "required", "different", "skills", "and", "that", "should", "the", "same", "time", "be", "spent", "in", "post-editing", "and", "translating,", "the", "translation", "would", "most", "probably", "be", "of", "better", "quality.", "T6", "was", "the", "most", "positive", "of", "all", "with", "regards", "to", "MT", "and", "admitted", "that", "the", "output", "helped", "in", "acquiring", "the", "terminology", "but", "was", "hopeless", "with", "syntax,", "which", "needed", "a", "complete", "rework.", "T2,", "T3", "and", "T4", "indicated", "that", "the", "MT", "output", "had", "clearly", "interfered", "in", "their", "job.", "T2", "reported", "that", "MT", "output", "slowed", "down", "the", "process", "considerably", "because", "reading,", "understanding", "and", "considering", "what", "to", "reuse", "from", "it", "was", "very", "time-consuming.", "T3", "commented", "that", "translating", "from", "scratch", "was", "easier", "and", "faster,", "and", "that", "even", "checking", "the", "MT", "output", "for", "terminology", "would", "most", "often", "not", "help.", "T4", "claimed", "that", "the", "MT", "system", "did", "not", "translate", "the", "order", "of", "the", "phrases", "properly,", "which", "rendered", "the", "translation", "incomprehensible.", "Interestingly,", "T3", "and", "T4", "did", "benefit", "from", "postediting."], "cited_papers": [{"title": "A productivity test of statistical machine translation post-editing in a typical localisation context", "year": "2010", "authors": ["M Plitt", "F Masselot"]}], "target_citation_location": 61, "citation_locations": [61], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "93aa21a9-2790-4c6c-9887-35f0d9706472", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Coordinated", "behavior", "or", "brigading,", "i.e.,", "when", "users", "with", "similar", "beliefs", "act", "in", "a", "coordinated", "manner", "in", "a", "social", "space", "towards", "some", "common", "objective", "(Parent et al., 2019)."], "cited_papers": [{"title": "Social media behavior, toxic masculinity, and depression", "year": "2019", "authors": ["Mike Parent", "Teresa Gobble", "Aaron Rochlen"]}], "target_citation_location": 23, "citation_locations": [23], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "93b75140-0b57-458d-aa01-a5c76f98d4f5", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["Our", "LTR", "features", "fall", "into", "four", "categories:", "term-based,", "score-based,", "proximity-based,", "and", "translation-based.", "These", "features", "are", "inspired", "by", "previous", "studies", "on", "LTR", "(Qin and Liu, 2013, Gallagher et al., 2020)", "and", "summarized", "in", "Table", "1.", "An", "enumeration", "of", "all", "features", "is", "presented", "in", "Appendix", "A."], "cited_papers": [{"title": "Feature extraction for large-scale text collections", "year": "2020", "authors": ["Luke Gallagher", "Antonio Mallia", "J Culpepper", "Torsten Suel", "B Barla Cambazoglu"]}, {"title": null, "year": "2013", "authors": ["Tao Qin", "Tie-Yan Liu"]}], "target_citation_location": 21, "citation_locations": [21], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "94a38cf8-b798-4401-aed0-b8ca9b481d28", "citing_paper": {"title": "A User-Based Usability Assessment of Raw Machine Translated Technical Instructions", "year": 2012, "authors": ["Stephen Doherty", "Sharon O'brien"]}, "text": ["There", "are", "relatively", "few", "studies", "of", "the", "usability", "of", "raw", "machine", "translated", "documentation", "by", "real", "end-users.", "For", "example,", "Tomita's", "work", "(Tomita, 1992, Tomita et al., 1993)", "focused", "on", "the", "concept", "of", "content", "comprehension.", "Fuji (1999)", "evaluated", "the", "informativeness,", "comprehension,", "and", "fluency", "of", "MT", "output,", "where", "participants", "had", "no", "reference", "to", "the", "source", "text,", "while", "Fuji et al. (2001)", "measured", "the", "concept", "of", "usefulness.", "Jones et al. (2005)", "measure", "the", "readability", "of", "MT", "output.", "While", "comprehensibility", "and", "readability", "are", "frequently", "considered", "to", "be", "components", "of", "usability,", "these", "studies", "address", "only", "specific", "aspects", "of", "the", "concept", "of", "usability.", "Gaspari's study (2004)", "in", "which", "real", "end", "users'", "needs", "are", "evaluated", "in", "the", "context", "of", "web", "usability", "comes", "closest", "to", "the", "study", "presented", "here.", "However,", "Gaspari's", "focus", "is", "on", "the", "usability", "of", "online", "MT", "systems,", "as", "opposed", "to", "the", "text", "they", "generate."], "cited_papers": [{"title": "Measuring human readability of machine generated text: three case studies in speech recognition and machine translation", "year": "2005", "authors": ["D Jones", "E Gibson", "W Shen", "N Granoien", "M Herzog", "D Reynolds", "C Weinstein"]}], "target_citation_location": 54, "citation_locations": [20, 28, 48, 54, 84], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "94ba9ec2-0eef-4dae-aec2-5dd91826516c", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["Irrespective", "of", "how", "the", "suffix", "array", "is", "created,", "Yamamoto and Church (2001)", "demonstrated", "how", "given", "a", "suffix", "array,", "frequencies", "of", "occurrence", "for", "all", "substrings", "can", "be", "ascertained", "in", "linear", "time.", "More", "precisely,", "by", "doing", "O(N)", "preprocessing,", "frequency", "information", "about", "any", "substring", "can", "be", "obtained", "in", "O(log", "N)", "time.", "Enumerating", "over", "all", "substrings", "naturally", "requires", "quadratic", "time.", "However,", "their", "technique", "works", "by", "partitioning", "substrings", "into", "at", "most", "2N", "classes", "which", "have", "unique", "collection", "frequency,", "the", "number", "of", "times", "the", "string", "occurs", "in", "the", "text,", "and", "document", "frequency,", "the", "number", "of", "separate", "documents", "the", "string", "occurs", "in.", "(The", "text", "may", "contain", "special", "end-of-document", "markers.)"], "cited_papers": [{"title": "Using suffix arrays to compute term frequency and document frequency for all substrings in a corpus", "year": "2001", "authors": ["M Yamamoto", "K Church"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "94dc3777-3438-4244-9ff0-dc0f320e53d2", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["In", "the", "Localized", "Narratives", "dataset", "(Pont-Tuset et al., 2020),", "the", "annotators", "describe", "the", "image", "while", "drawing", "the", "traces", "of", "their", "attention", "movement,", "which", "presents", "a", "spatial", "alignment", "between", "visual", "objects", "and", "caption", "tokens", "as", "well", "as", "a", "temporal", "alignment", "between", "user", "intention(by", "trace)", "and", "caption", "sentences.", "From", "Figure", "1,", "we", "see", "that", "the", "caption", "tokens,", "e.g.", "\"person\",", "\"horse\",", "\"trees\"", "can", "be", "grounded", "to", "the", "visual", "objects", "spatially,", "and", "the", "order", "of", "caption", "sentences", "can", "be", "arranged", "to", "align", "to", "the", "order", "of", "traces", "temporally.", "Although", "it", "is", "easy", "for", "humans", "to", "recognize", "which", "visual", "object", "is", "indicated", "by", "the", "traces,", "it", "is", "a", "challenge", "for", "the", "agent", "to", "recognize,", "emphasize", "and", "arrange", "visual", "semantics", "solely", "based", "on", "several", "tracepoints'", "coordinates.", "Thereby,", "we", "mainly", "devote", "our", "effort", "to", "the", "spatial", "grounding", "and", "temporal", "controllability", "of", "image", "captioning."], "cited_papers": [{"title": "Connecting vision and language with localized narratives", "year": "2020", "authors": ["Jordi Pont-Tuset", "Jasper Uijlings", "Beer Changpinyo", "Radu Soricut", "Vittorio Ferrari"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "95277296-d145-4d04-ba84-8d81355eeb10", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["For", "the", "English", "data", "we", "used", "Stanford", "NER", "(named", "entity", "recognition)", "(Finkel et al., 2005)", "to", "replace", "names", "and", "locations", "with", "the", "tags:", "[PERSON]", "and", "[LOCATION]", "respectively.", "We", "kept", "organization", "names", "as", "is", "because", "we", "felt", "that", "the", "emotions", "and", "sentiments", "towards", "some", "large", "well-known", "organizations", "differ", "too", "much", "(cf.", "IRS,", "FBI,", "WHO,", "EU,", "and", "MIT).", "For", "the", "Finnish", "data,", "we", "replaced", "names", "and", "locations", "using", "the", "Turku", "NER", "corpus", "(Luoma et al., 2020)."], "cited_papers": [{"title": "Incorporating non-local information into information extraction systems by gibbs sampling", "year": "2005", "authors": ["Jenny Finkel", "Trond Grenager", "Christopher Manning"]}], "target_citation_location": 11, "citation_locations": [11, 67], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "954f6fdb-7ef5-44c8-bd48-75c96e007330", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["In", "addition,", "we", "also", "examine", "the", "docTTTTTquery", "document", "expansion", "technique", "(Nogueira et al., 2019b, Nogueira and Lin, 2019)", "based", "on", "predicting", "queries", "for", "which", "a", "text", "would", "be", "relevant", "(henceforth,", "just", "d2q", "for", "short).", "The", "predicted", "queries", "are", "concatenated", "to", "the", "end", "of", "the", "original", "text,", "this", "greatly", "improves", "BoW", "retrieval.", "We", "call", "this", "variant", "BoW", "d2q", "and", "denote", "the", "corresponding", "pipeline", "BoW", "d2q", "(1000)", "+", "BERT."], "cited_papers": [{"title": "Document expansion by query prediction", "year": "2019", "authors": ["Rodrigo Nogueira", "Wei Yang", "Jimmy Lin", "Kyunghyun Cho"]}, {"title": "From doc2query to docTTTTTquery", "year": "2019", "authors": ["Rodrigo Nogueira", "Jimmy Lin"]}], "target_citation_location": 10, "citation_locations": [10], "citation_type": "group", "annotations": [[0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "959b202c-1f4b-46be-b82a-51ca8575bf97", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["ture.", "Dense", "representations", "of", "entities", "have", "similarly", "been", "applied", "to", "entity", "linking", "(Yamada et al., 2016, Eshel et al., 2017),", "as", "well", "as", "relation", "extraction", "(Baldini Soares et al., 2019),", "entity", "typing", "(Ling et al., 2020),", "and", "question", "answering", "(F\u00e9vry et al., 2020).", "Those", "approaches", "use", "millions", "of", "predefined", "entities,", "while", "our", "approach", "uses", "a", "much", "smaller", "number", "of", "types", "(10k", "or", "60k).", "This", "makes", "it", "simultaneously", "more", "compact", "and", "also", "more", "flexible", "when", "generalizing", "to", "unknown", "entities."], "cited_papers": [{"title": "Matching the Blanks: Distributional Similarity for Relation Learning", "year": "2019", "authors": ["unk Livio Baldini", "Nicholas Soares", "Jeffrey Fitzgerald", "Tom Ling", "unk Kwiatkowski"]}], "target_citation_location": 18, "citation_locations": [12, 18, 21, 25], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "968411c1-302d-490c-b922-392bbe018be3", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["End-to-End", "(E2E)", "Pretraining", "directly", "feed", "dense", "features", "on", "image", "grids", "from", "a", "visual", "backbone", "network", "into", "a", "Transformer", "network", "along", "with", "text", "tokens.", "As", "such,", "both", "the", "visual", "and", "Transformer", "networks", "are", "optimized", "jointly", "in", "an", "end-to-end", "manner", "in", "the", "pretraining", "&amp,", "finetuning", "stage.", "Pixel-Bert", "and", "SOHO", "(Huang et al., 2021 (Huang et al., , 2020) )", "pioneer", "the", "use", "of", "the", "E2E", "pretraining", "architecture", "and", "propose", "a", "novel", "visual-dictionary", "masked", "vision", "modeling", "task.", "E2E-VLP", "(Xu et al., 2021)", "presents", "a", "pretraining", "framework", "supervised", "with", "additional", "object", "detection", "and", "image", "captioning", "tasks", "to", "enhance", "visual", "semantics", "learning.", "It", "is", "worth", "noting", "that", "their", "object", "detection", "pretext", "task", "requires", "millions", "of", "bounding", "boxes", "annotation,", "unable", "to", "generalize", "to", "large-scale", "image-text", "corpus.", "ViLT", "(Kim et al., 2021)", "is", "the", "first", "to", "unify", "vision", "and", "language", "with", "a", "pure", "Transformer", "network,", "which", "has", "a", "simpler", "structure", "and", "enjoys", "faster", "inference.", "However,", "compared", "to", "the", "twostep", "methods,", "they", "are", "typically", "less", "expressive", "in", "terms", "of", "object-level", "concepts", "and", "thus", "suffer", "from", "weaker", "performances", "on", "challenging", "visual", "reasoning", "tasks.", "Our", "method", "is", "in", "line", "with", "the", "E2E", "pretraining", "framework.", "The", "key", "difference", "is", "that", "we", "propose", "to", "facilitate", "learning", "object-aware", "multi-modal", "representations", "by", "performing", "object", "semantic", "knowledge", "distillation."], "cited_papers": [{"title": "Pixel-bert: Aligning image pixels with text by deep multi-modal transformers", "year": "2020", "authors": ["Zhicheng Huang", "Zhaoyang Zeng", "Bei Liu", "Dongmei Fu", "Jianlong Fu"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 47, "citation_locations": [47, 66, 109], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "96b897c7-35a8-4dd4-8817-eeee43d42f43", "citing_paper": {"title": "Situation-Specific Multimodal Feature Adaptation", "year": 2021, "authors": ["\u00d6zge Alac"]}, "text": ["Integrating", "eye-movements", "of", "the", "speaker.", "Many", "eye-tracking", "technologies", "in", "the", "market", "employ", "a", "sufficient", "sampling", "frequency", "to", "enable", "gazecontingent", "applications.", "With", "advancements", "in", "the", "eye-tracking", "technology,", "incorporating", "eye", "movements", "of", "a", "speaker", "or", "a", "listener", "enables", "us", "to", "predict", "/", "resolve", "which", "entity", "is", "being", "referred", "to", "in", "a", "complex", "visual", "environment", "(Klerke and Plank, 2019, Mitev et al., 2018, Mishra et al., 2017, Koleva et al., 2015).", "However,", "these", "studies", "are", "limited", "to", "relatively", "simple", "scenes.", "Situated", "language", "understanding", "in", "a", "referentially", "complex", "environment", "or", "under", "noisy", "situations", "imposes", "a", "different", "level", "of", "challenge", "that", "we", "aim", "to", "address.", "The", "number", "of", "studies", "that", "utilize", "gaze", "features", "(Sood et al., 2020, Park et al., 2019, Karessli et al., 2017)", "is", "very", "limited.", "In", "this", "study,", "we", "propose", "to", "incorporate", "the", "eye-movements", "of", "the", "speaker", "to", "improve", "the", "crossmodal", "mapping", "performance.", "This", "additional", "deictic", "modality", "may", "improve", "the", "recovery", "of", "the", "intended", "meaning", "especially", "when", "the", "communication", "is", "noisy", "(acoustically", "or", "visually).", "The", "gaze", "embeddings", "will", "be", "created", "by", "using", "existing", "eyemovement", "datasets.", "However,", "there", "are", "only", "few", "big-size", "eye-movement", "datasets", "available", "(Alac \u00b8am et al., 2020b, Wilming et al., 2017, Ehinger et al., 2009).", "Thus,", "to", "enlarge", "available", "data,", "we", "will", "conduct", "a", "set", "of", "experimental", "studies", "with", "increasing", "referential", "complexity.", "There,", "we", "will", "record", "participants'", "instructions", "on", "a", "task-oriented", "scenario", "and", "their", "eye-movements", "regarding", "target", "objects."], "cited_papers": [{"title": "The impact of listener gaze on predicting reference resolution", "year": "2015", "authors": ["Nikolina Koleva", "Mart\u00edn Villalba", "Maria Staudte", "Alexander Koller"]}, {"title": "Using listener gaze to refer in installments benefits understanding", "year": "2018", "authors": ["Nikolina Mitev", "Patrick Renner", "Thies Pfeiffer", "Maria Staudte"]}, {"title": "Learning cognitive features from gaze data for sentiment and sarcasm classification using convolutional neural network", "year": "2017", "authors": ["Abhijit Mishra", "Kuntal Dey", "Pushpak Bhattacharyya"]}, {"title": "At a glance: The impact of gaze aggregation views on syntactic tagging", "year": "2019", "authors": ["Sigrid Klerke", "Barbara Plank"]}], "target_citation_location": 52, "citation_locations": [52, 93, 156], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "96ea6ea6-667e-4984-ab4b-d54f84ebf12d", "citing_paper": {"title": "Entity Attribute Relation Extraction with Attribute-Aware Embeddings", "year": 2020, "authors": ["Dan Iter", "Xiao Yu", "Fangtao Li"]}, "text": ["As", "proposed", "by", "Shwartz et al. (2016),", "adding", "the", "word", "embedding", "or", "distributive", "representation", "for", "the", "candidate", "strings", "can", "improve", "the", "performance", "of", "the", "model.", "The", "embeddings", "of", "the", "two", "candidate", "terms", "in", "the", "entity-attribute", "pair", "are", "concatenated", "to", "each", "side", "of", "the", "aggregated", "sentences", "vector", "described", "in", "the", "previous", "section.", "The", "embeddings", "for", "e", "and", "a", "are", "simply", "\u2212", "\u2192", "v", "e", "and", "\u2212", "\u2192", "v", "a.", "Thus", "the", "full", "representation", "of", "a", "entity-attribute", "pair", "is:\u2212", "\u2192", "v", "(e,a)", "=", "[\u2212", "\u2192", "v", "e,", "\u2212", "\u2192", "v", "sents(e,a),", "\u2212", "\u2192", "v", "a]"], "cited_papers": [{"title": "Improving hypernymy detection with an integrated path-based and distributional method", "year": "2016", "authors": ["Vered Shwartz", "Yoav Goldberg", "Ido Dagan"]}], "target_citation_location": 3, "citation_locations": [3], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "97157cc9-3253-4c40-950e-990ec7452baf", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["There", "have", "been", "great", "advances", "in", "argument", "mining-classifying", "the", "argumentative", "relation", "between", "statements", "as", "support,", "attack,", "or", "neutral.", "Recent", "research", "has", "focused", "on", "training", "complex", "neural", "networks", "on", "large", "labeled", "data.", "However,", "the", "behavior", "of", "such", "models", "remains", "obscure,", "and", "recent", "studies", "found", "evidence", "that", "those", "models", "may", "rely", "on", "spurious", "statistics", "of", "training", "data", "(Niven and Kao, 2019)", "and", "superficial", "cues", "irrelevant", "to", "the", "meaning", "of", "statements,", "such", "as", "discourse", "markers", "(Opitz and Frank, 2019).", "Hence,", "in", "this", "work,", "we", "turn", "to", "an", "interpretable", "method", "to", "investigate", "logical", "relations", "between", "statements,", "such", "as", "causal", "relations", "and", "factual", "contradiction.", "Such", "relations", "have", "been", "underemphasized", "in", "earlier", "studies", "(Feng and Hirst, 2011, Lawrence and Reed, 2016),", "possibly", "because", "their", "operationalization", "was", "unreliable", "then.", "Now", "that", "computational", "semantics", "is", "fast", "developing,", "our", "work", "takes", "a", "first", "step", "to", "computationally", "investigate", "how", "logical", "mechanisms", "contribute", "to", "building", "argumentative", "relations", "between", "statements", "and", "to", "classification", "accuracy", "with", "and", "without", "training", "on", "labeled", "data."], "cited_papers": [{"title": "Probing neural network comprehension of natural language arguments", "year": "2019", "authors": ["Timothy Niven", "Hung-Yu Kao"]}], "target_citation_location": 55, "citation_locations": [55, 69, 101], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "974445d7-0965-4b5c-9876-f1650eec4b9c", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["English-Spanish", "datasets", "We", "consider", "the", "Eu-roParl", "(1.7M", "sentences)", "(Koehn, 2005)", "and", "the", "NewsCommentary-v8", "(174k", "sentences)", "corpora", "for", "pre-training."], "cited_papers": [{"title": "Europarl: A parallel corpus for statistical machine translation", "year": "2005", "authors": ["Philipp Koehn"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2]]}
{"id": "97944eb4-9327-4ddb-bccf-91f679a1f487", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["The", "confound-controlled", "analysis", "dissociated", "word", "length,", "frequency", "and", "class", "effects", "in", "EEG.", "This", "replication", "of", "earlier", "ERP", "(Osterhout et al., 1997, M\u00fcnte et al., 1998)", "and", "MEG", "decoding", "work", "(King et al., 2020)", "validates", "a", "new", "EEG", "data", "set", "for", "an", "extensive", "morphosyntactically", "gold", "annotated", "corpus,", "c.f.", "Bhattasali et al. (2020).", "Transformers", "successfully", "decoded", "6", "PoS", "tags", "from", "single", "trial", "EEG", "with", "data", "augmentation", "and", "3-1", "pretraining", "(\u2248", "40%", "accuracy),", "raising", "the", "possibility", "to", "boost", "PoS", "induction", "with", "EEG-decoded", "PoS", "tags.", "While", "we", "acknowledge", "that", "our", "results", "are", "limited", "to", "EEG", "data", "from", "a", "single", "subject,", "given", "the", "spatial", "smoothness", "of", "EEG", "scalp", "topographies,", "we", "envision", "pretraining", "on", "EEG", "obtained", "from", "different", "participants.", "Further,", "because", "human", "brains", "generate", "similar", "neural", "signatures", "for", "word", "classes", "across", "different", "languages", "(c.f.", "Yudes", "(2016),", "M\u00fcnte et al. (2001),", "Hagoort et al. (2003)", "),", "pretraining", "PoS-EEG", "decoders", "on", "large", "morphosyntactically", "annotated", "EEG", "datasets", "for", "English", "followed", "by", "fine-tuning", "on", "a", "smaller", "annotated", "EEG", "data", "set", "for", "a", "low-resource", "language", "may", "enable", "successful", "generalisation", "to", "EEG", "obtained", "from", "reading", "non-annotated", "texts", "in", "this", "low-resource", "language.", "PoS-induction", "jointly", "based", "on", "annotated", "texts", "and", "EEG", "signals", "could", "thus", "be", "transformative", "for", "corpus", "generation", "of", "low-resource", "languages."], "cited_papers": [{"title": "The time-course of processing of grammatical class and semantic attributes of words: Dissociation by means of erp. Syntax-related ERP-effects in Dutch", "year": "2003", "authors": ["P Hagoort", "M Wassenaar", "C Brown"]}], "target_citation_location": 118, "citation_locations": [17, 22, 37, 117, 118], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "9838624d-0274-433e-94fa-d03811d74cdb", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["With", "the", "advent", "of", "deep", "learning,", "new", "automatic", "metrics", "have", "arisen,", "both", "in", "response", "to", "and", "making", "use", "of", "the", "technical", "advances", "brought", "by", "deep", "learning.", "In", "particular,", "metrics", "like", "COMET", "(Rei et al., 2020)", "and", "BERTScore", "use", "large", "pre-trained", "language", "models", "(LLMs)", "to", "generate", "scores", "for", "candidate", "sentences.", "The", "use", "of", "these", "LLMs", "allows", "for", "metrics", "that", "take", "advantage", "of", "the", "linguistic", "capabilities", "of", "these", "LLMs,", "and", "no", "longer", "rely", "solely", "on", "surface-level", "features", "such", "as", "n-grams."], "cited_papers": [{"title": "COMET: A neural framework for MT evaluation", "year": "2020", "authors": ["Ricardo Rei", "Craig Stewart", "Ana Farinha", "Alon Lavie"]}], "target_citation_location": 31, "citation_locations": [31], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "9851e2b5-c4ec-4f8d-9f12-2de68853ef31", "citing_paper": {"title": "ROI Analysis model for Language Service Providers", "year": 2013, "authors": ["Ekaterina Stambolieva"]}, "text": ["There", "is", "a", "current", "need", "for", "accurate", "ROI", "analysis", "schemes", "for", "LSPs.", "As", "Wiggins and Vashee (2012)", "discuss,", "LSPs", "that", "have", "not", "incorporated", "MT", "in", "their", "internal", "workflow", "by", "2015", "will", "be", "facing", "the", "risk", "of", "bankruptcy.", "Moreover,", "both", "researchers", "and", "professionals", "agree", "it", "is", "out", "of", "the", "question", "whether", "LSPs", "should", "implement", "the", "usage", "of", "MT", "in", "their", "respective", "businesses", "or", "not.", "The", "question", "has", "shifted", "to", "how", "LSPs", "can", "profit", "from", "the", "usage", "of", "MT", "internally", "and", "harvest", "the", "proven", "benefits."], "cited_papers": [{"title": "MT & ROI -Scoping, Defining, Measuring and Selecting Suitalbe Projects", "year": "2012", "authors": ["Dion Wiggins", "Kirti Vashee"]}], "target_citation_location": 13, "citation_locations": [13], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "98c8c7d6-c859-41a6-975b-8a1be12a55b2", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["Linguistic", "analysis", "of", "social", "discourse,", "using", "digital", "lexical", "resources", "and", "related", "software,", "has", "been", "an", "upward", "trend", "in", "the", "recent", "past.", "WordNet", "has", "been", "used", "for", "marking", "the", "event", "profile", "of", "news", "articles", "as", "a", "function", "of", "verb", "type", "(Klavans, 1998", ").", "An", "Adversary-Intent-Target", "(AIT)", "model", "has", "been", "developed", "which", "is", "based", "on", "an", "Ontology", "for", "the", "Analysis", "of", "Terrorist", "Attacks", "(Turner et al, 2011).", "DICTION", "5.0", "text", "analysis", "master", "variable,", "CERTAINTY", "has", "been", "used", "to", "analyze", "top", "management", "language", "for", "signals", "of", "possible", "deception", "(Craig et al, 2013)."], "cited_papers": [{"title": "Exploring top management language for signals of possible deception: The words of Satyam's chair Ramalinga Raju", "year": "2013", "authors": ["Russel Craig", "Tony Mortensen", "Shefali Iyer"]}], "target_citation_location": 81, "citation_locations": [39, 60, 81], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "98ff4304-f526-4a4c-9fb3-c7704bd6ed69", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Figure", "1", "shows", "an", "example", "in", "the", "commonsense", "explanation", "generation", "(ComVE)", "task.", "The", "dataset", "has", "collected", "explanations", "to", "counterfactual", "statements", "for", "sense-making", "from", "three", "annotators", "(Wang et al., 2020).", "From", "the", "annotations,", "we", "observed", "that", "different", "annotators", "gave", "explanations", "to", "the", "unreasonable", "statement", "from", "different", "perspectives", "to", "make", "them", "diverse", "in", "terms", "of", "content,", "e.g.,", "wrong", "effect", "and", "inappropriate", "usage."], "cited_papers": [{"title": "Semeval-2020 task 4: Commonsense validation and explanation", "year": "2020", "authors": ["Cunxiang Wang", "Shuailong Liang", "Yili Jin", "Yilong Wang", "Xiaodan Zhu", "Yue Zhang"]}], "target_citation_location": 25, "citation_locations": [25], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]]}
{"id": "9971c51a-5035-473c-a170-7a3cc88ab087", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["We", "use", "two", "recent", "models", "from", "the", "Quoref", "leaderboard:", "RoBERTa", "(Liu et al., 2019)", "and", "TASE", "(Segal", "et", "al.,", "2020),", "from", "which", "TASE", "has", "the", "state-ofthe-art", "results.", "We", "use", "RoBERTa-large", "from", "Hug-gingFace", "(Wolf et al., 2020).", "TASE", "casts", "MRC", "as", "a", "sequence", "tagging", "problem", "to", "handle", "questions", "with", "multi-span", "answers.", "It", "assigns", "a", "tag", "to", "every", "token", "of", "the", "context", "indicating", "whether", "the", "token", "is", "a", "part", "of", "the", "answer.", "We", "use", "the", "TASE", "IO", "+SSE", "setup", "that", "is", "a", "combination", "of", "their", "multi-span", "architecture", "and", "single-span", "extraction", "with", "IO", "tagging.We", "use", "the", "same", "configuration", "and", "hyper-parameters", "for", "TASE", "IO", "+SSE", "as", "described", "in", "Segal et al. (2020).", "We", "train", "all", "models", "for", "two", "epochs", "in", "all", "experiments.", "11", "We", "use", "the", "F1", "score", "that", "calculates", "the", "number", "of", "shared", "words", "between", "predictions", "and", "gold", "answers", "for", "evaluation."], "cited_papers": [{"title": "Transformers: State-of-the-art natural language processing", "year": "2020", "authors": ["Thomas Wolf", "Lysandre Debut", "Victor Sanh", "Julien Chaumond", "Clement Delangue", "Anthony Moi", "Pierric Cistac", "Tim Rault", "Rmi Louf", "Morgan Funtowicz", "Joe Davison", "Sam Shleifer", "Clara Patrick Von Platen", "Yacine Ma", "Julien Jernite", "Canwen Plu", "Teven Xu", "Sylvain Scao", "Mariama Gugger", "Quentin Drame", "Alexander Lhoest", "unk Rush"]}], "target_citation_location": 29, "citation_locations": [10, 29, 98], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "99c12b83-aa6c-4070-9d3d-c29952e86ef7", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["We", "used", "GNU", "Parallel", "for", "much", "of", "the", "dataset", "processing", "(Tange, 2011).", "In", "combination", "with", "Lhoest et al. (2021)", "from", "Hugging", "Face,", "GNU", "Parallel", "significantly", "accelerated", "pre-processing", "and", "phone", "transcription."], "cited_papers": [{"title": "Datasets: A community library for natural language processing", "year": "2021", "authors": ["Quentin Lhoest", "Albert Villanova Del Moral", "Yacine Jernite", "Abhishek Thakur", "Suraj Patrick Von Platen", "Julien Patil", "Mariama Chaumond", "Julien Drame", "Lewis Plu", "Joe Tunstall", "Mario Davison", "Gunjan \u0160a\u0161ko", "Bhavitvya Chhablani", "Simon Malik", "Teven Brandeis", "Victor Scao", "Canwen Sanh", "Nicolas Xu", "Angelina Patry", "Philipp Mcmillan-Major", "Sylvain Schmid", "unk Gugger"]}], "target_citation_location": 14, "citation_locations": [10, 14], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "9a0c76db-70ff-47e0-8545-cdcb78375e85", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Cross-batch", "negatives", "3", "The", "cross-batch", "negative", "sampling", "is", "implemented", "with", "differentiable", "all-gather", "operation", "provided", "in", "FleetX", "(Dong, 2020),", "that", "is", "a", "highly", "scalable", "distributed", "training", "engine", "of", "PaddlePaddle.", "The", "all-gather", "operator", "makes", "representation", "of", "passages", "across", "all", "GPUs", "visible", "on", "each", "GPU", "and", "thus", "the", "cross-batch", "negative", "sampling", "approach", "can", "be", "applied", "globally."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "9a423e82-1c4f-4716-9123-6d15eedfdc28", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["For", "natural", "language", "processing", "tasks", "in", "Vietnamese,", "there", "have", "been", "many", "pre-trained", "language", "models", "are", "available.", "In", "2016,", "Vu (2016)", "introduced", "the", "first", "monolingual", "pre-trained", "models", "for", "Vietnamese", "based", "on", "Word2Vec", "(Mikolov et al., 2013).", "The", "use", "of", "pre-trained", "Word2VecVN", "models", "was", "proved", "to", "be", "useful", "in", "various", "tasks,", "such", "as", "the", "name", "entity", "recognition", "task", "(Vu et al., 2018)."], "cited_papers": [{"title": "Efficient estimation of word representations in vector space", "year": "2013", "authors": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"]}], "target_citation_location": 30, "citation_locations": [18, 30, 52], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "9a7bae68-8e52-4c96-b671-2dbfda610cde", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["Long", "Range", "Arena", "(Tay et al., 2021)", "is", "a", "recently", "established", "benchmark", "for", "evaluating", "the", "ability", "of", "Transformer", "variants", "to", "handle", "long", "sequences.", "It", "comprises", "of", "multiple", "text", "classification", "tasks", "with", "inputs", "containing", "thousands", "of", "tokens", "(Table", "1).", "In", "ListOps", "(Nangia and Bowman, 2018),", "given", "a", "sequence", "of", "operations", "on", "single-digit", "integers,", "the", "model", "predicts", "a", "single-digit", "solution", "modeled", "as", "10-way", "classification.", "IMDb", "movie", "reviews", "(Maas et al., 2011)", "is", "a", "character-level", "binary", "sentiment", "classification", "task.", "Lastly,", "in", "the", "ACL", "Anthology", "Network", "(AAN)", "(Radev et al., 2013)", "task,", "a", "character-level", "model", "classifies", "if", "there", "is", "a", "citation", "between", "a", "pair", "of", "papers."], "cited_papers": [{"title": "Learning word vectors for sentiment analysis", "year": "2011", "authors": ["Andrew Maas", "Raymond Daly", "Peter Pham", "Dan Huang", "Andrew Ng", "Christopher Potts"]}], "target_citation_location": 59, "citation_locations": [3, 37, 59, 74], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "9af78c81-12f6-4ae0-860c-fddb23f7d14f", "citing_paper": {"title": "On the weak link between importance and prunability of attention heads", "year": 2020, "authors": ["Aakriti Budhraja", "Madhura Pande", "Preksha Nema", "Pratyush Kumar", "Mitesh Khapra"]}, "text": ["Recent", "work", "has", "identified", "that", "consecutive", "lay-", "ers", "of", "BERT", "have", "similar", "functionality", "(Lan et al., 2019).", "To", "study", "this,", "we", "considered", "configurations", "where", "six", "even", "and", "odd", "alternate", "layers", "are", "pruned", "and", "compare", "it", "with", "other", "strategies", "of", "pruning", "50%", "layers", "of", "BERT", "(Table", "6).", "We", "observe", "that", "the", "odd", "configuration", "performs", "better", "than", "the", "Top", "6", "and", "Bottom", "6", "configurations,", "indicating", "a", "preference", "to", "avoid", "pruning", "of", "consecutive", "layers.", "Effect", "of", "Fine-Tuning.", "Recent", "studies", "(Kovaleva et al., 2019, Houlsby et al., 2019)", "have", "reported", "that", "when", "fine-tuning", "BERT", "for", "specific", "tasks,", "the", "top", "layers", "change", "much", "more", "than", "the", "lower", "layers.", "We", "now", "evaluate", "this", "for", "fine-tuning", "after", "pruning."], "cited_papers": [{"title": "Albert: A lite bert for self-supervised learning of language representations", "year": "2019", "authors": ["Zhenzhong Lan", "Mingda Chen", "Sebastian Goodman", "Kevin Gimpel", "Piyush Sharma", "Radu Soricut"]}], "target_citation_location": 13, "citation_locations": [13, 73], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "9b61f41b-a475-4135-a1e6-d71fc92a3054", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["We", "are", "currently", "investigating", "whether", "our", "model", "is", "consistent", "with", "human", "language", "processing", "which", "has", "limited", "memory", "capacity", "[Gibson, 1990]."], "cited_papers": [{"title": "IXM2: A Parallel Associative Processor for Knowledge Processing", "year": "1990", "authors": ["T Gibson ", " Gibson", "unk Higuchi"]}], "target_citation_location": 18, "citation_locations": [18], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]]}
{"id": "9c035139-62d1-4230-a4e8-91e4d0fb4174", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["Nevertheless,", "it", "has", "been", "shown", "by", "Siminyu et al. (2021)", "that", "it", "is", "possible", "to", "improve", "phone", "recognition", "with", "even", "small", "amounts", "(approximately", "100", "sentences)", "of", "annotation.", "It", "may", "be", "possible", "to", "improve", "phonetic", "language", "modeling", "results", "by", "performing", "this", "fine-tuning", "in", "the", "target", "language."], "cited_papers": [{"title": "Phoneme recognition through fine tuning of phonetic representations: a case study on luhya language varieties", "year": "2021", "authors": ["Kathleen Siminyu", "Xinjian Li", "Antonios Anastasopoulos", "David Mortensen", "Michael Marlo", "Graham Neubig"]}], "target_citation_location": 6, "citation_locations": [6], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "9c2ce5fc-8ff2-4abf-94b1-c64c1ba96ad0", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["Turning", "our", "attention", "now", "to", "Arabic", "POS", "tagging,", "many", "approaches", "have", "also", "been", "adopted", "over", "the", "years", "including", "rule-based", "methods", "(Alqrainy, 2008, Zribi et al., 2016),", "statistical", "models", "(Al Shamsi and Guessoum, 2006, Kadim and Lazrek, 2018),", "hybrid", "models", "(Vashishtha and Susan, 2019, Forsati and Shamsfard, 2014)", "and", "neural", "networks", "(Yousif and Sembok, 2006, Yousif and Sembok, 2005).", "Performance", "is", "usually", "much", "higher", "for", "POS", "tagging", "than", "NER.", "Khoja (2001)", "introduced", "a", "hybrid", "POS", "tagger", "(with", "33", "tags)", "which", "combined", "HMM", "with", "a", "rule-based", "tagger.", "They", "used", "the", "Holy", "Quran", "Corpus", "and", "achieved", "an", "accuracy", "rate", "of", "97.6%", "and", "96.8%", "respectively.", "Yousif", "and", "Sembok", "(2008)", "used", "the", "SVM", "approach", "and", "a", "corpus", "of", "177", "tagged", "words.", "Zeroual and Abdelhak (2016)", "presented", "a", "probabilistic", "POS", "tagger", "for", "Arabic", "text", "based", "on", "HMM", "called", "Tree", "Tagger.", "The", "proposed", "tagger", "obtained", "accuracy", "rates", "of", "99.4%", "using", "Al-Mus'haf", "corpus."], "cited_papers": [{"title": "Sentence boundary detection for transcribed tunisian arabic", "year": "2016", "authors": ["In\u00e8s Zribi", "In\u00e8s Kammoun", "Mariem Ellouze", "Philippe Belguith", "unk Blache"]}, {"title": "A morphological-syntactical analysis approach for arabic textual tagging", "year": "2008", "authors": ["Shihadeh Alqrainy"]}], "target_citation_location": 20, "citation_locations": [20, 23, 26, 30, 41, 88], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "9c6095ee-1e81-4594-b3d4-1ad4befddcda", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["The", "memory", "component", "and", "action", "gate", "are", "endto-end", "trained", "in", "a", "self-supervised", "way,", "where", "the", "feedback", "is", "whether", "an", "utterance", "and", "its", "action", "representation", "lead", "to", "similar", "state", "transitions,", "We", "can", "measure", "such", "similarity", "using", "a", "dialogue", "state", "tracking", "(DST)", "model.", "However,", "a", "direct", "application", "of", "the", "DST", "model", "trained", "by", "Eqn.", "4", "might", "be", "prone", "to", "attribute", "changes", "between", "original", "utterances", "and", "compact", "natural", "language", "actions,", "which", "results", "in", "insufficient", "feedback.", "To", "address", "this", "issue,", "we", "adopt", "a", "denoising", "training", "strategy", "inspired", "by", "unsupervised", "machine", "translation", "(Lample et al., 2018 (Lample et al., , 2019)),", "and", "obtain", "a", "DST", "model", "that", "is", "more", "robust", "to", "the", "attribute", "transformation.", "Specifically,", "we", "apply", "a", "noise", "function", "g(x)", "to", "the", "utterances,", "and", "modify", "the", "DST", "model", "training", "loss", "as:L", "dst", "=", "d", "i", "\u2212", "log(b", "t", "p", "B", "(g(u", "t", "),", "g(x", "t\u22121", "),", "c", "t\u22121", "))", "(8)where", "the", "noise", "function", "corrupts", "the", "input", "utterance", "by", "performing", "word", "drops", "and", "word", "order", "shuffling", "as", "specified", "in", "Lample et al. (2018)."], "cited_papers": [{"title": "Unsupervised machine translation using monolingual corpora only", "year": "2018", "authors": ["Guillaume Lample", "Ludovic Denoyer", "Marc'aurelio Ranzato"]}], "target_citation_location": 156, "citation_locations": [87, 156], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "9c95e97c-cfef-470d-9e82-e0f1bf3a7c2b", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["Named", "Entity", "Disambiguation", "(NED)", "We", "use", "the", "standard", "English", "CoNLL-YAGO", "benchmark", "(Hoffart et al., 2011)", "preprocessed", "by", "Chen et al. (2019).", "For", "each", "entity", "mention,", "at", "most", "30", "candidate", "entities", "are", "selected", "using", "the", "CrossWikis", "dictionary", "(Spitkovsky", "and", "Chang,", "2012).", "This", "dataset", "contains", "18.5k", "training,", "4.8k", "dev,", "and", "4.5k", "test", "examples", "from", "newswire", "text,", "so", "the", "variety", "of", "entities", "and", "the", "writing", "styles", "are", "limited.", "For", "this", "reason,", "we", "create", "another", "NED", "dataset", "from", "WikilinksNED", "(Eshel et al., 2017),", "which", "includes", "a", "wide", "range", "of", "entities", "and", "diverse", "writing", "styles", "from", "scraped", "English", "web", "text", "linking", "to", "Wikipedia.", "We", "limit", "the", "number", "of", "candidate", "entities", "to", "3", "for", "each", "instance,", "which", "still", "makes", "a", "challenging", "benchmark.", "We", "create", "5k", "training,", "1k", "dev,", "and", "1k", "test", "examples", "and", "call", "this", "dataset", "WLNED.", "In", "both", "CoNLL-YAGO", "and", "WLNED,", "we", "form", "descriptions", "of", "candidate", "entities", "using", "the", "Wiki-Context", "data,", "but", "do", "not", "use", "any", "structural", "information", "from", "Wikipedia", "(hyperlinks,", "etc.).", "Our", "method", "simply", "computes", "cosine", "similarity", "and", "uses", "it", "as", "a", "score", "for", "each", "task,", "not", "introducing", "any", "new", "parameters.", "Our", "baselines", "use", "a", "trainable", "logistic", "regression", "layer", "over", "pre-trained", "embeddings", "to", "make", "classification", "decisions."], "cited_papers": [{"title": "Named Entity Disambiguation for Noisy Text", "year": "2017", "authors": ["Yotam Eshel", "Noam Cohen", "Kira Radinsky", "Shaul Markovitch", "Ikuya Yamada", "Omer Levy"]}], "target_citation_location": 69, "citation_locations": [11, 14, 69], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "9ca487ed-1497-4446-ad69-5b1fab9fe625", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["Adjectives", "are", "primarily", "used", "for", "modification", "of", "nouns.", "They", "have", "lexical", "organization", "and", "semantic", "properties", "that", "are", "not", "shared", "by", "other", "modifiers", "and", "are", "unique", "to", "them", "(Miller et al, 1993).", "The", "selected", "sense", "of", "the", "adjective", "sorry", "in", "WordNet", "has", "the", "gloss", "as", "feeling", "or", "expressing", "regret", "or", "sorrow", "or", "a", "sense", "of", "loss", "over", "something", "done", "or", "undone.", "The", "see", "also", "relation", "for", "this", "is", "the", "adjective", "penitent,", "repentant,", "which", "means", "feeling", "or", "expressing", "remorse", "for", "misdeeds.", "Thus,", "the", "underlying", "semantic", "connotation", "of", "the", "word", "is", "a", "feeling", "or", "an", "emotional", "state.", "An", "example", "of", "this", "is", "the", "sentence", "in", "the", "apology", "number", "3", "which", "states-We", "are", "truly", "sorry", "for", "this", "and", "will", "ensure", "that", "this", "never", "happens", "again.", "Here", "the", "use", "of", "sorry", "refers", "to", "the", "feelings", "expressed", "by", "the", "offender.", "In", "our", "dataset,", "out", "of", "the", "18", "communications,", "7", "have", "the", "use", "of", "sorry.", "In", "these", "7", "letters", "it", "is", "used", "12", "times."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 27, "citation_locations": [27], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "9d010954-b3c7-41d2-8e5a-ec5c0db53c8b", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["Control", "is", "handled", "using", "the", "syntactic", "constraint", "network.", "Sentence", "s7", "is", "an", "example", "of", "sentence", "involving", "functional", "control", "[Bresnan, 1982].", "In", "s7,", "both", "subject", "control", "and", "object", "control", "exist", "-the", "subject", "of", "'persuade'", "should", "be", "the", "subject", "of", "'tried'", "(subject", "control),", "and", "the", "subject", "of", "'help'", "should", "be", "the", "object", "of", "'persuade'", "(object", "control).", "In", "this", "case,", "CSCS", "for", "infinitival", "complement", "has", "CSE", "without", "NEXT", "link.", "Such", "an", "CSE", "represents", "missing", "subject.", "There", "are", "SUBJ,", "OBJ,", "and", "OBJ2", "nodes", "(these", "are", "functional", "controller)", "in", "the", "syntactic", "constraints", "network", "each", "of", "which", "store", "pointer", "to", "the", "CI", "node", "for", "possible", "controllee.", "Syntactic", "constraint", "links", "from", "each", "lexical", "items", "of", "the", "verb", "determine", "which", "functional", "controller", "is", "active.", "Activated", "functional", "controller", "propagate", "a", "pointer", "to", "the", "CI", "node", "to", "unbound", "subject", "nodes", "of", "CSCs", "for", "infinitival", "complements.", "Basically,", "one", "set", "of", "nodes", "for", "functional", "controller", "handles", "deeply", "nested", "cases", "due", "to", "functional", "locality."], "cited_papers": [{"title": "The Mental Representation of Grammatical Relations", "year": "1982", "authors": ["J Bresnan ", " Bresnan"]}], "target_citation_location": 18, "citation_locations": [18], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "9d2ed5ff-c948-4807-a155-0da8c4a5f40f", "citing_paper": {"title": "Situation-Specific Multimodal Feature Adaptation", "year": 2021, "authors": ["\u00d6zge Alac"]}, "text": ["HuRIC", "2.0", "(Bastianelli et al., 2014):", "audio", "files", "(656", "sentences)", "paired", "with", "their", "transcriptions", "referring", "to", "commands", "for", "a", "robot", "LAVA", "(Berzak et al., 2016):", "237", "sentences,", "with", "2", "to", "3", "interpretations", "per", "sentence,", "and", "a", "total", "of", "1679", "videos", "that", "depict", "visual", "variations", "of", "each", "interpretation", "CLEVR-Ref+", "(Liu et al., 2019):", "100", "K", "synthetic", "images", "with", "several", "referring", "expressions", "Eye4Ref", "(Alac", "\u00b8am", "et", "al.,", "2020b):", "86", "systematically", "controlled", "sentence--image", "pairs", "and", "2024", "eye-movement", "recordings", "from", "various", "referentially", "complex", "situations", "Multimodal", "embeddings", "will", "be", "created", "from", "this", "pool", "of", "datasets.", "Creating", "embeddings", "from", "various", "data", "sources", "will", "allow", "us", "to", "cover", "concepts", "from", "various", "aspects", "such", "as", "linguistic,", "auditory", "and", "visual", "representations.", "The", "variety", "on", "the", "visual", "modality", "will", "also", "help", "us", "to", "capture", "different", "visual", "depictions", "in", "a", "range", "from", "synthetic", "images", "to", "photographs.", "This", "will", "increase", "the", "representativeness", "of", "the", "concepts", "in", "the", "training", "dataset", "that", "will", "in", "return", "improve", "the", "prediction", "when", "it", "comes", "to", "unseen", "environments", "either", "in", "virtual", "reality", "or", "in", "a", "real-world", "setting.", "70", "%", "of", "this", "collection", "will", "be", "used", "to", "create", "multimodal", "concept", "embeddings.", "The", "remaining", "30", "%", "of", "the", "datasets", "will", "be", "included", "in", "the", "test", "and", "development", "sets", "after", "semi-automatic", "and", "manual", "annotation", "of", "contextual", "representations,", "target", "words,", "missing", "words,", "etc.", "However,", "Eye4REF", "will", "be", "used", "as", "main", "testset", "since", "it", "was", "systematically", "created", "to", "involve", "referentially", "complex", "situations."], "cited_papers": [{"title": "Huric: a human robot interaction corpus", "year": "2014", "authors": ["Emanuele Bastianelli", "Giuseppe Castellucci", "Danilo Croce", "Luca Iocchi", "Roberto Basili", "Daniele Nardi"]}], "target_citation_location": 2, "citation_locations": [2, 18, 42], "citation_type": "single", "annotations": [[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "9d67122c-0961-4a63-bf2e-27ed5f287826", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["A", "Note", "on", "Decontextualization", "Recently,", "Choi et al. (2021)", "introduced", "the", "text-decontextualization", "task,", "in", "which", "the", "input", "is", "a", "text", "and", "an", "enclosing", "textual", "context,", "and", "the", "goal", "is", "to", "produce", "a", "standalone", "text", "that", "can", "be", "fully", "interpreted", "outside", "of", "the", "enclosing", "context.", "The", "decontextualization", "task", "involves", "handling", "multiple", "linguistic", "phenomena,", "and,", "in", "order", "to", "perform", "it", "well,", "one", "must", "essentially", "perform", "a", "version", "of", "the", "NP", "Enrichment", "task.", "For", "example,", "decontextualizing", "''Prices", "are", "expected", "to", "rise''", "based", "on", "''Temporary", "copper", "shortage.", "Prices", "are", "expected", "to", "rise'',", "involves", "establishing", "the", "relation", "''Prices", "[of", "copper]", "are", "expected", "to", "rise'')."], "cited_papers": [{"title": "Decontextualization: Making sentences stand-alone", "year": "2021", "authors": ["Eunsol Choi", "Jennimaria Palomaki", "Matthew Lamm", "Tom Kwiatkowski", "Dipanjan Das", "Michael Collins"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "9e6a4570-4356-41fa-9d97-fbe46979c36e", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["In", "pairing", "two", "TAGs", "for", "MT,", "syntax-semantics", "mapping", "or", "paraphrase,", "under", "the", "redefinition", "of", "Synchronous", "TAG", "in", "Shieber (1994)", "there", "must", "be", "an", "isomorphism", "between", "the", "derivations", "of", "two", "strings", "to", "be", "paired.", "In", "TAG,", "for", "each", "DERIVED", "TREE", "derived", "from", "smaller", "elementary", "trees,", "there", "is", "a", "corresponding", "DERIVATION", "TREE", "which", "describes", "the", "history", "of", "the", "derivation.", "This", "derivation", "tree", "has", "a", "number", "of", "similarities", "to", "dependency", "trees,", "but", "is", "not", "exactly", "the", "same", "(Rambow and Joshi, 1997).", "In", "general", "there", "will", "not", "be", "an", "isomorphism", "between", "two", "such", "trees", "for", "any", "of", "the", "above", "applications,", "hence", "Shieber's", "proposed", "extension", "to", "allow", "\"bounded", "subderivation\"", "(which", "correspond", "to", "gCNs", "in", "the", "context", "of", "derivation", "trees).", "However,", "he", "also", "notes", "the", "possibility,", "further", "explored", "in", "Dras and Bleam (2000),", "that", "the", "pairing", "of", "gNCNs", "will", "be", "necessary.", "An", "example", "taken", "from", "the", "latter", "is", "in", "(2).", "teeth.", "The", "doctor", "wants", "to", "be", "able...", "to", "examine", "his", "teeth."], "cited_papers": [{"title": "Restricting the Weak-Generative Capacity of Synchronous Tree Adjoining Grammars", "year": "1994", "authors": ["S Shieber"]}], "target_citation_location": 17, "citation_locations": [17, 73, 119], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "9f3b2363-257c-43e6-8bcf-613ef0a20d9f", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["Apertium,", "the", "open-source", "MT", "platform", "that", "was", "used", "as", "basis", "in", "the", "case", "study,", "is", "described", "in", "the", "first", "section", "following", "the", "introduction.", "Materials", "and", "methods", "describe", "already", "available", "language", "processing", "tools", "and", "materials,", "mainly", "corpora.", "The", "newly", "developed", "methods", "are", "described", "in", "the", "same", "section.", "Following", "section", "describes", "results", "and", "evaluation", "methods.", "The", "last", "section", "describes", "discussion", "and", "further", "work.", "The", "modules", "are", "shown", "on", "Figure", "1,", "where", "the", "specially", "addressed", "modules", "are", "marked", "with", "a", "new", "colour", "and", "the", "two", "newly", "added", "modules", "are", "inserted.", "Each", "group's", "data", "creation", "was", "addressed", "by", "a", "particular", "method,", "monolingual", "dictionaries", "were", "constructed", "using", "bilingual", "dictionary", "data", "and", "applying", "automatic", "paradigm", "tagging", "techniques,", "bilingual", "dictionary", "was", "constructed", "using", "available", "bilingual", "word-list", "but", "a", "few", "methods", "for", "automatic", "bilingual", "dictionary", "construction", "were", "investigated,", "a", "method", "for", "automatic", "structural", "shallow-transfer", "rule", "construction", "(S\u00e1nchez-", "Mart\u00ednez et al., 2006)", "will", "be", "used", "to", "construct", "a", "set", "of", "structural", "transfer", "rules."], "cited_papers": [{"title": "Open-source Portuguese-Spanish machine translation", "year": "2006", "authors": ["Miriam Mart\u00ednez", "unk Scalco"]}], "target_citation_location": 139, "citation_locations": [139], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "9fa81d15-40bb-4745-aa43-3bccc67ee79a", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["In", "this", "paper,", "we", "propose", "to", "use", "the", "so-called", "continuous", "space", "language", "model.", "The", "basic", "idea", "of", "this", "approach", "is", "to", "project", "the", "word", "indices", "onto", "a", "continuous", "space", "and", "to", "use", "a", "probability", "estimator", "operating", "on", "this", "space", "[8].", "Since", "the", "resulting", "probability", "functions", "are", "smooth", "functions", "of", "the", "word", "representation,", "better", "generalization", "to", "unknown", "n-grams", "can", "be", "expected.", "A", "neural", "network", "can", "be", "used", "to", "simultaneously", "learn", "the", "projection", "of", "the", "words", "onto", "the", "continuous", "space", "and", "to", "estimate", "the", "n-gram", "probabilities.", "This", "is", "still", "a", "n-gram", "approach,", "but", "the", "language", "model", "posterior", "probabilities", "are", "\"interpolated\"", "for", "any", "possible", "context", "of", "length", "n", "\u2212", "1", "instead", "of", "backing-off", "to", "shorter", "contexts.", "This", "approach", "was", "already", "successfully", "applied", "in", "statistical", "machine", "translation", "systems,", "ranging", "from", "small", "IWSLT", "systems", "[9, 10]", "to", "large", "NIST", "systems", "[1]."], "cited_papers": [{"title": "Continuous space language models for the IWSLT 2006 task", "year": "2006", "authors": ["H Schwenk", "M Costa-Juss\u00e0", "J Fonollosa"]}, {"title": "The TALP ngram-based SMT system for IWSLT", "year": "2007", "authors": ["P Lambert", "M Costa-Juss\u00e0", "J Crego", "M Khalilov", "J No", "R Banchs", "J Fonollosa", "H Schwenk"]}], "target_citation_location": 129, "citation_locations": [39, 129, 134], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 3, 3, 3, 3]]}
{"id": "9fcafbcd-e993-4819-af98-c38406811d32", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["To", "extract", "the", "features", "regarding", "the", "network", "object", "classes,", "we", "applied", "a", "regularization", "method", "to", "the", "graph.", "Regularization", "is", "a", "kind", "of", "semi-supervised", "(or", "transductive)", "classification", "method", "that", "aims", "to", "find", "a", "set", "of", "labels,", "minimizing", "a", "cost", "function", "and", "satisfying", "two", "conditions:", "(i)", "the", "method", "needs", "to", "be", "consistent", "with", "the", "set", "of", "labels", "manually", "annotated", "and", "(ii)", "the", "method", "needs", "to", "be", "consistent", "with", "the", "network", "topology,", "considering", "that", "nearest", "neighbors", "tend", "to", "have", "the", "same", "labels", "(Ji et al., 2010)."], "cited_papers": [{"title": "Graph regularized transductive classification on heterogeneous information networks", "year": "2010", "authors": ["Ming Ji", "Yizhou Sun", "Marina Danilevsky", "Jiawei Han", "Jing Gao"]}], "target_citation_location": 79, "citation_locations": [79], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "a03f8ae9-ca55-4fd6-9630-401caf2b3c73", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["The", "study", "of", "the", "sentiment", "associated", "with", "the", "keywords", "is", "done", "using", "SentiWordNet", "(3.0),", "a", "lexical", "resource", "which", "assigns", "to", "each", "synset", "of", "WordNet", "three", "sentiment", "scores:", "positivity,", "negativity,", "objectivity", "(Stefano et al, 2010).", "The", "task", "of", "finding", "the", "sentiments", "of", "the", "words", "in", "an", "apology", "as", "expressed", "in", "online", "forums", "can", "be", "put", "to", "a", "rich", "set", "of", "applications", "(Esuli and Sebastiani, 2007).", "As", "for", "public", "apologies", "these", "tasks", "can", "range", "from", "tracking", "readers'", "opinions", "about", "the", "sincerity", "of", "the", "communication", "to", "customer", "relationship", "management.", "The", "selected", "synsets", "of", "the", "keywords", "were", "searched", "for", "in", "SentiWordNet.", "The", "sentiment", "scores", "of", "each", "of", "them", "were", "recorded", "and", "the", "results", "were", "analyzed.", "Table", "1", "shows", "the", "sentiment", "scores", "for", "positivity,", "negativity", "and", "objectivity", "for", "each", "of", "the", "keywords.", "In", "the", "analysis", "of", "the", "sentiments", "associated", "with", "keywords,", "of", "particular", "interest", "are", "the", "objective", "scores.", "The", "verb", "apologize", "has", "the", "highest", "objective", "score", "(1.0).", "Its", "negative", "and", "positive", "scores", "are", "zero.", "The", "high", "ObjScore", "(Objective", "Score)", "of", "one", "(1.0)", "implies", "that", "this", "verb", "does", "not", "convey", "any", "sentiment.", "In", "a", "public", "apology", "act,", "this", "could", "entail", "that", "when", "an", "organization", "or", "person", "renders", "an", "apology", "it", "distances", "itself", "from", "the", "event", "or", "issue", "and", "takes", "an", "objective", "position.", "Similarly", "the", "next", "highest", "ObjScore", "is", "for", "regret", "as", "a", "verb", "(0.75).", "Thus,", "both", "verbs", "-apologize", "and", "regretdo", "not", "connect", "with", "the", "negative", "sentiments", "associated", "with", "the", "act", "of", "an", "apology.Keywords", "PosScore", "[0,1]", "NegScore", "[0,1]", "ObjScore", "[0,The", "highest", "NegScore", "(Negative", "Score)", "is", "for", "the", "adjective", "sorry", "(0.75),", "followed", "by", "the", "noun", "regret", "which", "has", "a", "NegScore", "of", "0.625.", "The", "strong", "negative", "connotation", "of", "the", "adjective", "sorry", "could", "help", "the", "writer", "to", "convey", "his", "genuine", "feeling", "of", "remorse", "and", "hence", "should", "be", "preferred", "by", "the", "writer", "to", "connect", "with", "the", "reader", "at", "an", "emotional", "level.", "Since", "adjectives", "are", "the", "words", "that", "carry", "the", "most", "notions", "of", "sentiment,", "their", "use", "in", "the", "apology", "can", "carry", "the", "sentiment", "most", "effectively.", "This", "implies", "that", "the", "adjective", "sorry", "carries", "the", "highest", "sentimental", "load", "to", "convey", "the", "feeling", "associated", "with", "act", "of", "apology."], "cited_papers": [{"title": "SentiWordNet: a high-coverage lexical resource for opinion mining", "year": "2007", "authors": ["Andrea Esuli", "Fabrizio Sebastiani"]}], "target_citation_location": 57, "citation_locations": [30, 57], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a073a3be-44a4-445c-bd27-736495ea1a9f", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["For", "each", "task,", "we", "downloaded", "and", "directly", "used", "the", "vanilla", "Transformer", "code", "offered", "by", "the", "authors", "(Tay et al., 2021)", "and", "compared", "the", "performance", "before", "and", "after", "replacing", "the", "multi-head", "attention", "layers", "with", "top-128", "attention,", "using", "identical", "hyperparameters", "for", "both", "cases", "(details", "in", "\u00a7A.1).", "2", "Test", "accuracy", "measured", "at", "the", "training", "checkpoint", "with", "the", "highest", "accuracy", "on", "the", "development", "set", "is", "reported", "in", "Table", "1", "and", "the", "learning", "curves", "on", "the", "development", "and", "test", "sets", "are", "shown", "in", "Fig.", "5.", "On", "IMDb", "and", "AAN,", "the", "performance", "of", "top-128", "is", "comparable", "or", "better", "than", "vanilla", "attention.", "For", "ListOps,", "there", "is", "a", "minor", "drop", "in", "performance", "(1.5", "points),", "but", "learning", "curves", "(Figure", "5a)", "exhibit", "similar", "behaviour."], "cited_papers": [{"title": "Long Range Arena : A benchmark for efficient transformers", "year": "2021", "authors": ["Yi Tay", "Mostafa Dehghani", "Samira Abnar", "Yikang Shen", "Dara Bahri", "Philip Pham", "Jinfeng Rao", "Liu Yang", "Sebastian Ruder", "Donald Metzler"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a086fad3-b4a1-4730-98e7-01661875ab42", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["The", "data", "forming", "the", "multilingual", "corpus", "of", "examples", "are", "derived", "empirically", "from", "real-life", "examples", "of", "job", "adverts.", "For", "practical", "reasons,", "we", "cannot", "expect", "to", "have", "available", "a", "truly", "parallel", "corpus", "of", "texts", "in", "this", "domain.", "The", "contrastive", "linguistic", "knowledge", "of", "the", "system", "cannot", "therefore", "be", "captured", "by", "paired", "examples", "of", "translational", "equivalents", "as", "in", "the", "IBM", "statistical", "approach", "for", "example", "([5, 6]", "),", "so", "the", "more", "abstract", "intentional", "model", "is", "relied", "on", "as", "a", "kind", "of", "mediator,", "where", "it", "is", "the", "functional", "rather", "than", "formal", "property", "of", "the", "text", "fragment", "that", "gives", "its", "target", "language", "counterpart.", "The", "analysis", "of", "the", "multilingual", "corpora", "([2])", "provides", "us", "with", "data", "influencing", "the", "design", "of", "the", "linguistic", "representations", "to", "be", "used", "in", "the", "example", "database,", "as", "well", "as", "determining", "the", "content", "and", "form", "of", "both", "the", "intentional", "model", "-where", "the", "functional", "and", "pragmatic", "aspects", "of", "the", "job", "adverts", "are", "defined", "-and", "providing", "information", "to", "enable", "the", "domain", "knowledge", "of", "the", "system", "to", "be", "defined.", "This", "last", "is", "based", "on", "the", "prepositional", "content", "of", "the", "corpus,", "which", "determines", "not", "only", "what", "are", "the", "commonalities", "of", "the", "language", "of", "the", "domain,", "but", "also", "enabling", "illegal", "phrases", "to", "be", "identified,", "as", "well", "as", "revealing", "problems", "of", "non-equivalences,", "especially", "of", "job", "titles", "and", "qualifications,", "etc.", "An", "additional", "point", "of", "interest", "arising", "especially", "from", "the", "text-type", "and", "domain", "chosen", "is", "the", "likelihood", "of", "cultural", "differences", "being", "reflected", "in", "differences", "in", "the", "examples", "and", "hence", "in", "the", "intentional", "models.", "These", "may", "be", "superficial,", "such", "as", "the", "typical", "order", "of", "presenting", "the", "information,", "or", "may", "pose", "more", "serious", "problems", "(see", "below)."], "cited_papers": [{"title": "Sublanguage and multilingual corpus analysis for example-based machine translation", "year": "1992", "authors": ["Alexa unk", "M unk", "E Barcena"]}], "target_citation_location": 101, "citation_locations": [60, 101], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a0a393bc-cfd1-4e4c-b48b-dacd687b5ea5", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["A", "bilingual", "parallel", "corpus", "(Erjavec, 2004)", "was", "used", "for", "automatic", "evaluation", "using", "BLEU", "metric", "(Papineni et al., 2001).", "The", "results", "are", "presented", "in", "Table", "2.", "The", "values", "are", "quite", "low,", "partly", "due", "to", "reasons", "explained", "in", "(Callison-Burch", "et", "al.,", "partly", "due", "to", "unknown", "words", "in", "test", "corpus.", "Figure", "6", "shows", "results", "of", "evaluation", "of", "translation", "quality", "using", "subjective", "measures", "using", "methodology", "(LDC, 2005).", "The", "methodology", "is", "explained", "in", "chapter", "4.1.", "Four", "independent", "evaluators", "(two", "native", "speakers)", "evaluated", "sets", "of", "100", "sentences", "using", "this", "methodology."], "cited_papers": [{"title": "Assessment of fluency and adequacy in translations", "year": "2005", "authors": ["unk Ldc"]}], "target_citation_location": 57, "citation_locations": [4, 13, 57], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "a103e852-0a6b-459b-8289-ba84fde2aec0", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["Attack", "success", "rate", "(first-order).", "We", "quantify", "first-order", "robustness", "through", "attack", "success", "rate,", "which", "measures", "the", "ratio", "of", "test", "examples", "that", "an", "adversarial", "example", "can", "be", "found.", "We", "use", "firstorder", "attacks", "as", "a", "reference", "due", "to", "the", "lack", "of", "a", "direct", "baseline.", "We", "experiment", "with", "two", "black-box", "attacks:", "(1)", "The", "Genetic", "attack", "(Alzantot et al., 2018, Jia et al., 2019)", "uses", "a", "population-based", "op-timization", "algorithm", "that", "generates", "both", "syntactically", "and", "semantically", "similar", "adversarial", "examples,", "by", "replacing", "words", "within", "the", "list", "of", "counterfitted", "synonyms."], "cited_papers": [{"title": "Generating natural language adversarial examples", "year": "2018", "authors": ["Moustafa Alzantot", "Yash Sharma", "Ahmed Elgohary", "Bo-Jhang Ho", "Mani Srivastava", "Kai-Wei Chang"]}, {"title": "Certified robustness to adversarial word substitutions", "year": "2019", "authors": ["Robin Jia", "Aditi Raghunathan", "Kerem G\u00f6ksel", "Percy Liang"]}], "target_citation_location": 51, "citation_locations": [51], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "a2284fff-09b6-47a8-a548-635e266591f1", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["Despite", "of", "the", "advantages", "of", "using", "CCG", "categories", "to", "label", "non-terminals", "in", "the", "HPB", "system", "compared", "with", "SAMT", "labels,", "richness", "of", "CCG", "categories", "still", "leads", "to", "a", "large", "number", "of", "different", "non-terminal", "labels.", "This", "causes", "fragmentation", "of", "rule", "probabilities", "and", "consequently", "affects", "translation", "quality", "negatively.", "A", "CCG", "category", "C", "takes", "the", "form", "of", "C=(T\\L)/R", "where", "L", "represents", "the", "left", "argument", "category,", "R", "the", "right", "argument", "category,", "and", "T", "the", "resulting", "category.", "Each", "of", "these", "constituent", "categories", "might", "be", "atomic", "or", "complex.", "Furthermore,", "some", "atomic", "CCG", "categories", "have", "features", "expressed", "between", "brackets", "which", "describe", "certain", "syntactic", "information.", "For", "example,", "the", "atomic", "category", "S", "might", "have", "a", "feature", "attached", "to", "it", "which", "distinguishes", "types", "of", "sentences", "such", "as", "declarative", "S[dcl]", "or", "wh-question", "S[wq].", "All", "the", "additional", "information", "represented", "in", "a", "single", "CCG", "category", "increases", "the", "number", "of", "different", "CCG", "categories", "and", "leads", "to", "label", "sparsity", "problem.", "In", "order", "to", "address", "this", "problem,", "we", "simplify", "CCG", "non-terminal", "labels", "by", "reducing", "the", "amount", "of", "the", "information", "represented", "in", "them", "using", "the", "following", "approaches", "[14]:"], "cited_papers": [{"title": "CCG contextual labels in hierarchical phrase-based SMT", "year": "2011", "authors": ["H Almaghout", "J Jiang", "A Way"]}], "target_citation_location": 169, "citation_locations": [169], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "a237c8f2-31c8-44aa-a13e-7ba28d19e037", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["The", "main", "aspect", "of", "an", "apology", "lies", "in", "the", "verb", "that", "the", "tenderer", "chooses", "to", "use.", "We", "do", "an", "analysis", "of", "the", "two", "verbs,", "apologize", "and", "regret,", "using", "WordNet,", "the", "former", "being", "an", "explicit", "performative", "verb", "(Austin, 1975),", "The", "selected", "sense", "of", "the", "verb", "apologize", "is", "defined", "as", "-to", "acknowledge", "faults", "or", "shortcomings", "or", "failing.", "Its", "semantic", "relation", "of", "entailment", "is", "admit,", "acknowledge,", "which", "means", "to", "declare", "to", "be", "true", "or", "admit", "the", "existence", "or", "reality", "or", "truth", "of.", "One", "of", "its", "troponym", "is", "to", "concede,", "profess,", "confess", "which", "is", "defined", "as", "to", "admit", "(to", "a", "wrongdoing).", "The", "superordinate", "concept", "of", "this", "chain", "is", "the", "verb", "think,", "cogitate,", "cerebrate", "which", "is", "defined", "as-to", "use", "or", "exercise", "the", "mind", "or", "one's", "power", "of", "reason", "in", "order", "to", "make", "inferences,", "decisions,", "or", "arrive", "at", "a", "solution", "or", "judgments.", "Thus,", "it", "is", "clear", "from", "the", "semantic", "hierarchy", "that", "to", "apologize", "is", "to", "undergo", "a", "logical", "thought", "process,", "the", "natural", "entailment", "of", "which", "is", "to", "admit", "to", "a", "wrong.", "Once", "the", "wrongdoing", "is", "admitted", "the", "natural", "consequence", "should", "be", "to", "take", "responsibility", "and", "offer", "amends.", "For", "instance,", "apology", "number", "2", "says-I", "sincerely", "apologize", "to", "all", "Satyamites", "and", "stakeholders.", "This", "is", "a", "clear", "admission", "of", "wrongdoing.", "The", "selected", "concept", "of", "the", "verb", "regret", "is", "defined", "as", "to", "feel", "remorse", "for,", "feel", "sorry", "for", "or", "be", "contrite", "about.", "Its", "inherited", "hypernymy", "is", "to", "feel,", "experience,", "which", "is", "defined", "as", "to", "undergo", "an", "emotional", "sensation", "or", "be", "in", "a", "particular", "state", "of", "mind.", "Thus,", "to", "regret", "is", "to", "undergo", "a", "feeling", "by", "the", "offender", "about", "the", "wrongdoing.", "In", "the", "corpus", "apology", "number", "10,", "the", "Amazon", "India", "letter", "states,", "To", "the", "extent", "that", "these", "items", "offered", "by", "a", "third-party", "seller", "in", "Canada", "offended", "Indian", "sensibilities,", "Amazon", "regrets", "the", "same."], "cited_papers": [{"title": "How to do things with words", "year": "1975", "authors": ["L John", "unk Austin"]}], "target_citation_location": 36, "citation_locations": [36], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a27b0d1a-2db8-417a-8054-72e84cc8b355", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["Nonetheless,", "the", "established", "convention", "incorporates", "a", "distancing", "from", "the", "offence.", "Also,", "writers", "use", "apologies", "when", "they", "are", "apologising", "in", "a", "role", "(e.g.", "as", "the", "representative", "of", "an", "organisation).", "When", "speaking", "personally,", "they", "use", "other", "forms,", "typically", "sorry", "(Hatipo\u011flu, 2005).", "Another", "possibility", "is", "that", "use", "of", "the", "noun", "form", "enables", "the", "writer", "to", "avoid", "the", "personal", "pronoun,", "creating", "a", "distance", "between", "the", "writer", "and", "the", "responsibility", "for", "the", "offence", "(ibid).", "In", "our", "data,", "individuals", "have", "not", "used", "this", "form", "at", "all", "and", "of", "the", "seven", "occurrences", "of", "the", "noun", "form,", "six", "are", "by", "individuals", "as", "representative", "of", "an", "organisation.", "This", "co-relates", "to", "Harrison's", "finding", "that", "the", "word", "apology/", "apologies", "help", "the", "writers", "to", "distance", "themselves", "from", "the", "instance", "or", "event."], "cited_papers": [{"title": "Do apologies in e-mails follow spoken or written norms? Some examples from British English", "year": "2005", "authors": ["Ciler Hatipo\u011flu"]}], "target_citation_location": 37, "citation_locations": [37], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a2d9c9c1-318d-4d04-815b-880bbabcf658", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["We", "note", "that", "as", "we", "targeted", "at", "the", "one-to-many", "generation", "problem,", "we", "excluded", "those", "baseline", "methods", "mentioned", "in", "the", "related", "work", "that", "cannot", "produce", "multiple", "outputs,", "e.g.,", "Zhang et al. (2020a),", "Ji et al. (2020),", "Liu et al. (2021).", "Different", "from", "aforementioned", "methods,", "our", "MoKGE", "can", "seek", "diverse", "reasoning", "on", "KG", "to", "encourage", "various", "generation", "outputs", "without", "any", "additional", "conditions."], "cited_papers": [{"title": "Kg-bart: Knowledge graph-augmented bart for generative commonsense reasoning", "year": "2021", "authors": ["Ye Liu", "Yao Wan", "Lifang He", "Hao Peng", "Philip S Yu"]}], "target_citation_location": 29, "citation_locations": [27, 28, 29], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "a2eea626-2daa-4f77-a858-4a3821f38abf", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["A", "semantic", "analysis", "of", "the", "selected", "keywords", "was", "done", "using", "WordNet", "(3.1).", "We", "used", "semantic", "relations", "such", "as", "hypernymy,", "troponymy", "and", "entailment", "(Fellbaum, 1998)", "to", "find", "the", "implications", "that", "the", "keywords", "may", "have,", "as", "far", "as", "their", "communicative", "goals", "are", "concerned."], "cited_papers": [{"title": "WordNet: an electronic lexical database", "year": "1998", "authors": ["Christiane Fellbaum"]}], "target_citation_location": 22, "citation_locations": [22], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "a32cd508-6bda-4091-b597-4adfd02fe806", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["We", "use", "pretrained", "BERT", "2", "(Devlin et al., 2019)", "for", "the", "mention", "and", "context", "encoder.", "This", "BERT-based", "encoder", "accepts", "as", "input", "a", "token", "sequence", "formatted", "asx", "=", "[CLS]", "m", "[SEP]", "s", "[SEP],where", "the", "mention", "m", "and", "context", "s", "are", "chunked", "into", "WordPiece", "tokens", "(Wu et al., 2016).", "We", "encode", "the", "whole", "sequence", "using", "BERT", "and", "use", "the", "hidden", "vector", "at", "the", "[CLS]", "token", "as", "the", "mention", "and", "context", "representation:h", "[CLS]", "=", "BERTENCODER(x).Type", "Embeddings", "This", "output", "layer", "is", "a", "single", "linear", "layer", "whose", "parameter", "matrix", "can", "be", "viewed", "as", "a", "matrix", "of", "type", "embeddings", "E", "\u2208", "R", "|T", "|\u00d7d,", "where", "d", "is", "the", "dimension", "of", "the", "mention", "and", "context", "representation", "h", "[CLS].", "We", "obtain", "the", "output", "probabilities", "t", "by", "multiplying", "E", "by", "h", "[CLS],", "followed", "by", "an", "element-wise", "sigmoid", "function:t", "=", "\u03c3", "(E", "h", "[CLS]).", "3", "Similar", "to", "previous", "work", "(Choi et al., 2018, Onoe and Durrett, 2019),", "we", "assume", "independence", "between", "all", "entity", "type", "in", "T."], "cited_papers": [{"title": "Opensubtitles2016: Extracting large parallel corpora from movie and tv subtitles", "year": "2016", "authors": ["Pierre Lison", "J\u00f6rg Tiedemann ", " Khalid", "Thierry Choukri", "Sara Declerck", "Marko Goggi", "Bente Grobelnik", "Joseph Maegaard", "unk Mariani"]}], "target_citation_location": 40, "citation_locations": [5, 40, 104, 133], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a384298e-b13a-442a-99b9-72f539f757b5", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Throughout", "the", "paper,", "user", "refers", "to", "the", "user", "of", "an", "online", "platform", "who", "may", "have", "posted", "a", "comment", "that", "is", "to", "be", "classified", "as", "abusive", "or", "not.", "The", "community", "of", "this", "user", "comprises", "other", "users", "and", "contents", "that", "they", "interact", "with", "on", "the", "online", "plat-form.", "In", "other", "words,", "community", "refers", "to", "the", "neighborhood", "of", "the", "user", "in", "the", "social", "graph", "of", "the", "platform.", "Conversations", "online", "are", "inherently", "contextual.", "Consequently,", "abuse", "on", "online", "platforms", "can", "only", "be", "effectively", "interpreted", "within", "a", "larger", "context", "(Gao and Huang, 2017)", "rather", "than", "in", "isolation.", "This", "is", "especially", "true", "for", "implicit", "or", "generalized", "abuse,", "which", "are", "harder", "to", "interpret", "than", "explicit", "abuse", "for", "humans", "and", "machines", "alike.", "Information", "of", "the", "user", "who", "posted", "the", "comment,", "or", "of", "the", "surrounding", "community", "including", "the", "targets", "of", "the", "comment,", "offers", "insights", "into", "several", "aspects", "of", "the", "context", "that", "are", "otherwise", "not", "accessible", "through", "the", "linguistic", "content", "of", "the", "comment", "alone.", "Here,", "information", "may", "refer", "to", "demographic", "traits", "like", "age", "or", "gender,", "knowledge", "about", "linguistic", "behavior,", "location", "details,", "etc.", "Below", "we", "categorize", "and", "discuss", "the", "aspects", "of", "the", "context", "relevant", "to", "abusive", "language", "detection.", "Sociolinguistic", "norms.", "Sociolinguistics", "studies", "the", "effects", "of", "society", "on", "language", "and", "its", "usage.", "Researchers", "in", "the", "past", "have", "explored", "the", "links", "between", "the", "structures", "and", "norms", "of", "real-world", "communities", "and", "the", "linguistic", "practices", "of", "people", "(D'Arcy", "and", "Young, 2012).", "As", "in", "the", "physical", "world,", "individuals", "and", "communities", "on", "online", "platforms", "also", "abide", "by", "certain", "norms,", "which", "may", "be", "guided", "by", "their", "cultural", "backgrounds", "and/or", "are", "based", "on", "the", "standards", "laid", "down", "by", "the", "platforms", "themselves.", "These", "norms", "and", "standards", "reflect", "expectations", "of", "respectful", "behavior,", "local", "customs", "and", "language", "patterns", "within", "a", "region,", "etc.", "(Ben-David and Fern\u00e1ndez, 2016).", "Consequently,", "the", "decision", "of", "what", "is", "considered", "abusive", "must", "be", "made", "taking", "into", "account", "the", "sociolinguistic", "norms.", "User", "and", "community", "information,", "when", "leveraged", "alongside", "linguistic", "features,", "helps", "capture", "the", "relevant", "sociolinguistic", "norms", "in", "a", "myriad", "of", "ways.", "For", "example,", "a", "comment", "may", "contain", "the", "n-word,", "but", "interpretation", "of", "its", "use", "and", "or", "the", "intent", "is", "greatly", "facilitated", "by", "the", "knowledge", "of", "the", "ethnicity", "of", "the", "user", "who", "wrote", "the", "comment", "and/or", "the", "ethnicity", "of", "the", "target", "user", "or", "community."], "cited_papers": [{"title": "Hate speech and covert discrimination on social media: Monitoring the facebook pages of extreme-right political parties in spain", "year": "2016", "authors": ["Anat Ben", "-David unk", "Ariadna Matamoros Fern\u00e1ndez"]}], "target_citation_location": 274, "citation_locations": [82, 219, 274], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a3eeebc6-1689-461e-bc32-d5a56cfb7ab4", "citing_paper": {"title": "Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model", "year": 2022, "authors": ["Richard Futrell"]}, "text": ["Word", "co-occurrence", "probabilities", "are", "hard", "to", "estimate", "accurately", "from", "text", "data", "because", "empirical", "counts", "of", "a", "particular", "pair", "of", "words", "in", "a", "particular", "relation", "are", "often", "sparse.", "This", "limitation", "makes", "it", "hard", "to", "evaluate", "cognitive", "theories", "that", "operate", "on", "co-occurrence", "probabilities.", "Although", "high-performance", "pretrained", "language", "models", "now", "exist", "(Radford et al., 2019, Devlin et al., 2019, etc.),", "the", "probabilities", "of", "interest", "often", "cannot", "be", "read", "off", "of", "these", "models", "directly,", "because", "w", "and", "c", "might", "be", "defined", "by", "relations", "that", "cannot", "be", "straightforwardly", "detected", "in", "terms", "of", "linear", "word", "order", "or", "templates.", "For", "example,", "suppose", "we", "are", "interested", "in", "the", "distribution", "of", "adjectives", "attributively", "modifying", "a", "noun", "in", "English.", "It", "would", "not", "do", "to", "ask", "a", "language", "model", "for", "the", "distribution", "of", "words", "immediately", "preceding", "a", "noun,", "because", "some", "of", "these", "words", "will", "not", "be", "attributive", "adjectives."], "cited_papers": [{"title": "Language models are unsupervised multitask learners", "year": "2019", "authors": ["Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 48, "citation_locations": [48], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a3f66cf2-ec24-4eb9-8d1a-2d63b9b944b4", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["Several", "robust", "parsing", "systems", "exploit", "the", "comparative", "success", "of", "part-of-speech", "(PoS)", "taggers,", "such", "as", "Fidditch", "(Hindle, 1989)", "or", "MITFP (de \u2022 Marcken, 1990),", "by", "reducing", "the", "input", "to", "a", "determinate", "sequence", "of", "extended", "PoS", "labels", "of", "the", "type", "which", "can", "be", "practically", "disambiguated", "in", "context", "using", "a", "(H)MM", "PoS", "tagger", "(e.g.", "Church, 1988).", "Such", "approaches,", "by", "definition,", "cannot", "exploit", "subcategorisation,", "and", "probably", "achieve", "some", "of", "their", "robustness", "as", "a", "result.", "However,", "such", "parsers", "typically", "also", "employ", "heuristic", "rules,", "such", "as", "'low'", "attachment", "of", "PPs", "to", "produce", "unique", "'canonical'", "analyses.", "This", "latter", "step", "complicates", "the", "recovery", "of", "predicate", "argument", "structure", "and", "does", "not", "integrate", "with", "a", "probabilistic", "approach", "to", "parsing."], "cited_papers": [{"title": "A stochastic parts program and noun phrase parser for unrestricted text", "year": "1988", "authors": ["K Church"]}], "target_citation_location": 46, "citation_locations": [15, 17, 46], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "a427ae8f-78c4-4b37-a4b0-9942f4c0b228", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["The", "following", "are", "examples", "of", "the", "hierarchical", "CFG", "rules", "extracted", "from", "the", "Chinese-English", "sentence", "pair", "(Aozhou", "shi", "yu", "Beihan", "you", "bangjiao", "de", "shaoshu", "guojia", "zhiyi,", "Australia", "is", "one", "of", "the", "few", "countries", "that", "have", "diplomatic", "relations", "with", "North", "Korea)", "[3]:"], "cited_papers": [{"title": "A hierarchical phrase-based model for statistical machine translation", "year": "2005", "authors": ["D Chiang"]}], "target_citation_location": 39, "citation_locations": [39], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]}
{"id": "a4c231de-60c5-4e77-bd52-5059e67452e4", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["Toxic", "comments,", "posts,", "and", "other", "types", "of", "content", "became", "more", "common", "in", "social", "media", "nowadays.", "They", "contain", "forms", "of", "non-acceptable", "language", "(profanity),", "which", "may", "be", "concealed", "or", "explicit,", "including", "insults", "and", "threats", "directed", "to", "a", "group", "or", "individual", "(Zampieri et al., 2019).", "These", "comments", "spread", "rapidly", "on", "the", "internet,", "especially", "on", "social", "networks", "where", "they", "find", "acceptance,", "and", "may", "culminate", "in", "several", "threats", "to", "individuals,", "becoming", "a", "serious", "concern", "for", "government", "organizations,", "online", "communities,", "and", "social", "media", "platforms."], "cited_papers": [{"title": "SemEval-2019 task 6: Identifying and categorizing offensive language in social media (OffensEval)", "year": "2019", "authors": ["Marcos Zampieri", "Shervin Malmasi", "Preslav Nakov", "Sara Rosenthal", "Noura Farra", "Ritesh Kumar"]}], "target_citation_location": 38, "citation_locations": [38], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "a6309530-f8c3-4577-befa-8ea56b8c9530", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["Upon", "processing", "the", "first", "word", "'John'", "in", "the", "sentence", "s1,", "C-JOHN", "is", "activated", "so", "that", "C-JOHN", "gets", "an", "A-MARKER", "and", "a", "CI", "JOHN#l", "is", "created", "under", "C-JOHN.", "At", "this", "point,", "the", "corresponding", "Japanese", "lexical", "item", "is", "searched", "for,", "and", "JON", "is", "found.", "A", "G-MARKER", "is", "created", "on", "JON.", "The", "A-MARKER", "and", "G-MARKER", "propagate", "up", "through", "ISA", "links", "(activating", "C-MALE-PERSON", "and", "C-PERSON", "in", "sequence)", "and,", "then,", "ROLE", "links.", "When", "an", "A-MARKER", "collides", "with", "a", "P-MARKER", "at", "a", "CSE,", "the", "associated", "case", "role", "is", "bound", "with", "the", "source", "of", "the", "A-MARKER", "and", "the", "prediction", "is", "updated", "by", "passing", "P-MARKER", "to", "the", "next", "CSE.", "This", "P-MARKER", "is", "passed", "down", "ISA", "links.", "In", "this", "memory", "network,", "the", "ACTOR", "roles", "of", "concept", "sequences", "WANT-CIRCUM-E", "is", "bound", "to", "JOHN#", "1", "pointed", "by", "the", "A-MARKER.", "This", "is", "made", "possible", "in", "the", "SNAP", "architecture", "which", "allows", "markers", "to", "carry", "address", "as", "well", "as", "bit-vectors", "and", "values,", "where", "many", "other", "marker-passing", "machines", "such", "as", "NETL", "[Fahlman, 1979]", "and", "IXM2", "[Higuchi et al., 1991]", "only", "allow", "bit-vectors", "to", "be", "passed", "around,", "Also,", "G-MARKERs", "are", "placed", "on", "the", "ACTOR", "role", "CSE", "of", "WANT-CIRCUM-J.", "The", "G-MARKER", "points", "to", "the", "Japanese", "lexical", "item", "'jon'."], "cited_papers": [{"title": "A method for realizing Transfer-Driven Machine Translation", "year": "1979", "authors": ["S Fahlman ", " Fahlman", "unk Ford"]}], "target_citation_location": 156, "citation_locations": [156, 159], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a63668fe-aa33-4170-8252-975c9764dab2", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["As", "we", "discussed", "in", "Section", "4.1.2,", "we", "computed", "the", "annotation", "structure", "accuracy", "(ASA),", "and", "it", "turns", "out", "that", "its", "range", "was", "from", "98.9", "%", "to", "100.0", "%.", "This", "means", "that", "the", "proposed", "joint", "model", "can", "consistently", "predict", "transcriptions", "and", "the", "linguistic", "annotations", "in", "the", "correct", "order", "almost", "perfectly.", "We", "found", "that", "almost", "all", "errors", "of", "the", "transition", "occurred", "in", "the", "last", "word,", "which", "might", "be", "caused", "by", "beam", "search", "errors.", "Pipeline", "is", "ASR", "predicting", "transcriptions", "followed", "by", "the", "NLP-based", "linguistic", "annotation", "system", "(Graham and Mori, 2010).", "Proposed", "predicts", "graphemes", "and", "phonemes", "followed", "by", "POS", "tags", "from", "speech.", "Note", "that", "we", "used", "only", "the", "sentences", "whose", "hypothesized", "ASR", "transcript", "is", "predicted", "correctly", "for", "evaluation."], "cited_papers": [{"title": "Word-based partial annotation for efficient corpus construction", "year": "2010", "authors": ["N Graham", "S Mori"]}], "target_citation_location": 82, "citation_locations": [82], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a636ce40-a2b3-4eb3-8045-1abe6d25572f", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["This", "parsing", "algorithm", "is", "similar", "to", "the", "shift-reduce", "parser", "except", "that", "our", "algorithms", "handles", "ambiguities,", "parallel", "processing", "of", "each", "hypothesis,", "and", "top-down", "predictions", "of", "possible", "next", "input", "symbol.", "The", "generation", "algorithm", "implemented", "on", "SNAP", "is", "a", "version", "of", "the", "lexically", "guided", "bottom-up", "algorithm", "which", "is", "described", "in", "[Kitano, 1990b]."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 47, "citation_locations": [47], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]]}
{"id": "a669146d-8b27-41c5-970f-f6f050b39655", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["Lastly,", "we", "test", "two", "recent", "models", "from", "stance", "detection", "and", "dis/agreement", "classification.", "TGA", "Net", "(Allaway and McKeown, 2020)", "takes", "a", "statement-topic", "pair", "and", "predicts", "the", "statement's", "stance.", "It", "encodes", "the", "input", "using", "BERT", "and", "weighs", "topic", "tokens", "based", "on", "similarity", "to", "other", "topics.", "In", "our", "task,", "claims", "serve", "as", "''topics''.", "We", "use", "the", "published", "implementation,", "exploring", "{50,", "100,", "150,", "200}", "for", "the", "number", "of", "clusters", "and", "increasing", "the", "max", "input", "size", "to", "the", "BERT", "input", "size.", "Hybrid", "Net", "(Chen et al., 2018)", "takes", "a", "quote-response", "pair", "and", "predicts", "whether", "the", "response", "agrees", "or", "disagrees", "with", "the", "quote.", "It", "encodes", "the", "input", "using", "BiLSTM", "and", "uses", "selfand", "cross-attention", "between", "tokens.", "In", "our", "task,", "claims", "and", "statements", "serve", "as", "''quotes''", "and", "''responses'',", "respectively."], "cited_papers": [{"title": "Zero-shot stance detection: A dataset and model using generalized topic representations", "year": "2020", "authors": ["Emily Allaway", "Kathleen Mckeown"]}], "target_citation_location": 14, "citation_locations": [14, 75], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a67fff38-9064-4524-b890-47a119dd7b84", "citing_paper": {"title": "NEW TABULAR ALGORITHMS FOR LIG PARSING", "year": 2000, "authors": ["Mi G Uel Alonso Jor G E Grana", "Manuel Vilares"]}, "text": ["We", "have", "chosen", "the", "CYK-like", "algorithm", "for", "LIG", "described", "in", "(16]", "as", "our", "starting", "point.", "Due", "to", "the", "intrinsic", "limitations", "of", "this", "pure", "bottom-up", "algorithm,", "the", "grammars", "it", "can", "deal", "with", "are", "restricted", "to", "those", "having", "two", "elements,", "or", "one", "element", "which", "must", "be", "a", "terminal,", "in", "the", "right-hand", "side", "of", "each", "production.", "This", "restriction", "could", "be", "considered", "as", "the", "transposition", "of", "the", "Chomsky", "normal", "form", "to", "linear", "indexed", "grammars."], "cited_papers": [{"title": "Polynomial parsing of extensions of context-free gram mars", "year": "1991", "authors": ["K Vijay-Shanker", "D Weir"]}], "target_citation_location": 10, "citation_locations": [10], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a6ce77b5-960f-4dcb-a3d9-1990df5b0f1f", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["Datasets", "created", "for", "sentiment", "analysis", "have", "been", "available", "for", "researchers", "since", "at", "least", "the", "early", "2000s", "(M\u00e4ntyl\u00e4 et al., 2018).", "Such", "datasets", "generally", "use", "a", "binary", "or", "ternary", "annotation", "scheme", "(positive,", "negative", "+", "neutral)", "(e.g.", "Blitzer et al. (2007))", "and", "have", "traditionally", "been", "based", "on", "review", "data", "such", "as,", "e.g.", "Amazon", "product", "reviews,", "or", "movie", "reviews", "(Blitzer et al., 2007, Maas et al., 2011, Turney, 2002).", "Many,", "if", "not", "most,", "emotion", "datasets", "on", "the", "other", "hand", "use", "Twitter", "as", "a", "source", "and", "individual", "tweets", "as", "level", "of", "granularity", "(Schuff et al., 2017, Abdul-Mageed and Ungar, 2017, Mohammad et al., 2018).", "In", "the", "case", "of", "emotion", "datasets,", "the", "emotion", "taxonomies", "used", "are", "often", "based", "on", "Ekman (1971)", "and", "Plutchik (1980)", "(which", "is", "partially", "based", "on", "Ekman)."], "cited_papers": [{"title": "SemEval-2018 task 1: Affect in tweets", "year": "2018", "authors": ["Saif Mohammad", "Felipe Bravo-Marquez", "Mohammad Salameh", "Svetlana Kiritchenko"]}, {"title": "Annotation, modelling and analysis of fine-grained emotions on a stance and sentiment detection corpus", "year": "2017", "authors": ["Hendrik Schuff", "Jeremy Barnes", "Julian Mohme", "Sebastian Pad\u00f3", "Roman Klinger"]}, {"title": "Emonet: Fine-grained emotion detection with gated recurrent neural networks", "year": "2017", "authors": ["Muhammad Abdul", "-Mageed unk", "Lyle Ungar"]}], "target_citation_location": 73, "citation_locations": [16, 32, 50, 73, 88, 90], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a702ccbd-ab14-4496-97f5-0b7c6baec6eb", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["An", "already", "trained", "and", "tested", "POS", "tagger", "(Erjavec, 2006)", "was", "available", "for", "Slovenian", "language.", "Words", "were", "tagged", "using", "full", "MSD", "descriptions", "(Erjavec, 2004)", "and", "grouped", "into", "classes", "with", "same", "descriptions", "(words", "that", "had", "the", "same", "POS", "tag", "were", "grouped", "together).", "This", "process", "produced", "312", "classes", "in", "Slovene", "and", "274", "classes", "in", "Serbian", "language,", "see", "Table", "1", "for", "details.", "A", "linguist", "manually", "tagged", "the", "classes", "to", "paradigms."], "cited_papers": [{"title": "MULTEXT-East Version 3: Multilingual Morphosyntactic Specifications, Lexicons and Corpora", "year": "2004", "authors": ["Erjavec Toma\u017e"]}], "target_citation_location": 20, "citation_locations": [7, 20], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a74f1ba2-9366-4973-a777-735b858c361b", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["The", "oddest", "feature", "of", "MMB's", "breath-group", "work,", "stretching", "as", "it", "did", "over", "many", "years", "was", "that", "it", "referred", "constantly", "to", "breathing,", "but", "nothing", "ever", "rested", "on", "that:", "partitions", "were", "always", "inserted", "into", "text", "intuitively", "in", "a", "way", "that,", "to", "me", "at", "least,", "corresponded", "more", "naturally", "to", "the", "criteria", "just", "listed", "(keywords, punctuation, etc.).", "Finally,", "of", "course,", "it", "would", "be", "overbold", "to", "assert", "that", "there", "will", "never", "be", "applications", "of", "Greek", "rhetorical", "figures", "to", "the", "computer", "understanding", "of", "natural", "language,", "but", "none", "have", "as", "yet", "emerged,", "except", "their", "explicit", "and", "obvious", "use", "as", "forms", "of", "expression."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 50, "citation_locations": [50], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a7cd3d83-4f78-4aaf-ac60-18cc1754f418", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["More", "recently,", "Kocmi et al. (2021)", "run", "a", "large-scale", "comparison", "of", "MT", "metrics,", "including", "BERTScore", "using", "a", "large", "dataset", "of", "translations", "with", "human", "judgments,", "they", "find", "that", "BERTScore's", "performance", "is", "middle-of-the-road,", "though", "better", "than", "BLEU,", "and", "recommend", "COMET", "(Rei et al., 2020)", "for", "general", "use."], "cited_papers": [{"title": "COMET: A neural framework for MT evaluation", "year": "2020", "authors": ["Ricardo Rei", "Craig Stewart", "Ana Farinha", "Alon Lavie"]}], "target_citation_location": 35, "citation_locations": [2, 35], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 1, 1, 2, 2, 2]]}
{"id": "a7dc450a-d664-4fef-aa45-2e59aa458243", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["Although", "not", "a", "formalist", "herself,", "and", "considered", "an", "anti-formalist", "by", "many,", "MMB", "nevertheless", "believed", "passionately", "in", "the", "applicability", "of", "mathematical", "techniques", "to", "natural", "language,", "without", "them,", "she", "believed,", "there", "would", "be", "nothing", "worthy", "of", "the", "name", "of", "theory.", "Her", "opposition", "was", "to", "the", "assumption", "that", "formal", "logic,", "in", "particular,", "applied", "directly", "to", "natural", "language,", "and", "she", "would", "not", "concede", "much", "distinction", "between", "that", "and", "the", "methods", "of", "Chomsky (1965),", "a", "position", "that", "has", "some", "historical", "justification."], "cited_papers": [{"title": "Aspects of the theory of syntax", "year": "1965", "authors": ["N Chomsky"]}], "target_citation_location": 67, "citation_locations": [67], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "a8bc4df2-cc95-4b30-9042-ff2348d32736", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["To", "obtain", "s", "i,", "we", "use", "existing", "annotation", "tools", "or", "manual", "annotations", "to", "jointly", "align", "the", "training", "sets", "of", "the", "K", "output", "sequence", "types.", "These", "segments", "are", "used", "as", "training", "targets", "in", "an", "auto-regressive", "prediction", "task.", "In", "this", "way,", "our", "model", "implicitly", "learns", "to", "simultaneously", "predict", "and", "align", "K", "output", "sequences", "from", "an", "input", "X.", "We", "discuss", "further", "details", "of", "the", "data", "preparation", "in", "Section", "3.2.", "Letting", "y", "*", "i", "denote", "elements", "of", "the", "collapsed", "single-sequence", "representation", "s", "1", ",...,", "s", "S,", "the", "joint", "log-likelihood", "(Eq.", "(3))", "can", "be", "written", "asL", "=", "log", "p(y", "1", ",...,", "y", "K", "|X)", "=", "M", "*", "m=1", "log", "p(y", "*", "m", "|y", "*", "1", ",...,", "y", "*", "m\u22121,", "X).", "(9)Note", "that", "this", "form", "is", "almost", "equivalent", "to", "the", "single", "sequence", "objective", "function", "in", "Eq.", "(1)", "except", "for", "the", "variable", "y", "*", "m", "takes", "values", "from", "the", "union", "of", "the", "K", "symbol", "sets", "that", "represent", "the", "K", "output", "sequences", "and", "the", "length", "of", "this", "sequenceM", "*", "=", "K", "k=1", "M", "k,", "is", "the", "sum", "of", "the", "lengths", "of", "the", "K", "output", "sequences.This", "framework", "has", "various", "benefits", "compared", "with", "the", "existing", "frameworks", "described", "in", "Section", "2.", "Similar", "to", "the", "O2O", "model", "trained", "with", "the", "conditional", "chain", "mapping", "in", "Section", "2.2.2,", "this", "framework", "does", "not", "assume", "the", "conditional", "independence", "between", "output", "labels", "and", "has", "the", "flexibility", "to", "model", "the", "dependency", "between", "words/morphemes", "and", "linguistic", "annotations.", "Related", "works", "are", "using", "the", "O2O", "model,", "e.g.,", "(Yadav et al., 2020),", "but", "they", "are", "based", "on", "CTC", "and", "do", "not", "consider", "such", "an", "explicit", "output", "dependency.", "Also,", "the", "proposed", "method", "using", "Transformer", "can", "preserve", "a", "relationship", "between", "the", "word/morpheme", "and", "the", "corresponding", "linguistic", "annotations", "across", "the", "sequence", "based", "on", "the", "aligned", "representation", "s", "i", "in", "Eq.", "(8).", "Finally,", "this", "framework", "is", "equivalent", "to", "the", "original", "single-sequence", "objective", "function,", "and", "we", "can", "use", "an", "existing", "strong", "sequence-to-sequence", "model", "(transformer", "in", "this", "paper)", "without", "any", "modifications", "of", "the", "algorithm.", "The", "only", "process", "is", "to", "prepare", "the", "collapsed", "single", "sequence", "composed", "of", "s", "i,", "which", "is", "discussed", "in", "the", "next", "section."], "cited_papers": [{"title": "End-to-End Named Entity Recognition from English Speech", "year": "2020", "authors": ["H Yadav", "S Ghosh", "Y Yu", "R Shah"]}], "target_citation_location": 236, "citation_locations": [236], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "a936b3d4-87d1-4b88-ab33-f79babf669d9", "citing_paper": {"title": "SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering", "year": 2020, "authors": ["Aishwarya Ashok", "Ganapathy Natarajan", "Ramez Elmasri", "Laurel Smith-Stvan"]}, "text": ["At", "the", "sentence", "level,", "we", "pick", "the", "top", "1", "sentence,", "using", "Okapi", "BM25,", "as", "the", "gold", "standard.", "To", "retrieve", "the", "top", "1", "sentence", "using", "Okapi", "BM25,", "we", "used", "the", "question", "as", "the", "query", "and", "the", "product", "reviews", "as", "the", "documents.", "Okapi", "BM25", "is", "still", "widely", "used", "as", "a", "benchmark", "in", "similar", "tasks", "(Fan et al., 2019", ").", "An", "advantage", "of", "using", "the", "Okapi", "BM25", "is", "that", "it", "provides", "us", "with", "a", "tf-idf", "based", "benchmark", "(Sixto et al., 2016).", "Word", "vectors", "aim", "to", "reduce", "problem", "complexity", "by", "moving", "away", "from", "tf-idf", "methods", "which", "requires", "us", "to", "one-hot-encode", "the", "entire", "vocabulary."], "cited_papers": [{"title": "Improving the sentiment analysis process of spanish tweets with bm25", "year": "2016", "authors": ["Juan Sixto", "Aitor Almeida", "Diego L\u00f3pez-De Ipi\u00f1a"]}], "target_citation_location": 71, "citation_locations": [52, 71], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "a9a9aaed-25ee-4de8-8f8b-2b5080efcb81", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["Some", "emotions", "are", "also", "more", "closely", "correlated.", "In", "Plutchik's", "wheel", "(Plutchik, 1980)", "related", "emotions", "are", "placed", "on", "the", "same", "dyad", "so", "that", "for", "example", "for", "anger", "as", "a", "core", "emotion,", "there", "is", "also", "rage", "that", "is", "more", "intense,", "but", "highly", "correlated", "with", "anger,", "and", "annoyance", "which", "is", "less", "intense,", "but", "equally", "correlated.", "In", "this", "way", "it", "is", "also", "possible", "to", "map", "more", "distinct", "categories", "of", "emotions", "onto", "larger", "wholes,", "in", "this", "case", "rage", "and", "annoyance", "could", "be", "mapped", "to", "anger,", "or", "even", "more", "coarsely", "to", "negative.", "This", "approach", "has", "been", "employed", "by", "for", "example", "Abdul-Mageed and Ungar (2017)."], "cited_papers": [{"title": "A general psychoevolutionary theory of emotion", "year": "1980", "authors": ["Robert Plutchik"]}], "target_citation_location": 10, "citation_locations": [10, 93], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "aa121060-ee85-46db-8ebb-700b2b3caee0", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["2", "As", "pointed", "out", "by", "a", "reviewer,", "an", "even", "better", "factorization", "of", "fragments", "could", "potentially", "be", "achieved", "by", "indexing", "not", "with", "respect", "to", "linear", "position", "but", "with", "respect", "to", "the", "syntactic", "head", "word.", "This", "would", "require", "introducing", "a", "dependency", "parsing", "component.", "We", "leave", "this", "for", "future", "work.", "Sequence", "Labeling", "Transformer", "Model", "Our", "model", "is", "schematically", "depicted", "in", "Figure", "4.", "It", "takes", "an", "input", "sequence", "of", "tokens", "X", "=", "w", "1...", "w", "n", "and", "produces", "aligned", "output", "sequences", "Y", "s,", "Y", "f,", "Y", "i,", "which", "are", "word", "senses,", "fragments,", "and", "integration", "labels.", "Our", "model", "simply", "consists", "of", "a", "pre-trained", "BERT", "model", "(Devlin et al., 2019)", "and", "three", "linear", "classifiers.", "Each", "classifier", "can", "be", "seen", "as", "a", "sub-system", "of", "the", "semantic", "parser", "that", "produces", "one", "of", "the", "three", "labels", "(word", "sense,", "fragment,", "and", "integration", "label)."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 100, "citation_locations": [100], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "aa4c1a86-446e-4a89-8a2a-20673c116cb2", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["Bostan", "and", "Klinger (2018)", "analyze", "14", "existing", "emotion", "datasets", "of", "which", "only", "two", "are", "multilabel.", "These", "are", "AffectiveText", "(Strapparava and Mihalcea, 2007)", "and", "SSEC", "(Schuff et al., 2017).", "Nearly", "all", "of", "these", "datasets", "use", "an", "annotation", "scheme", "based", "on", "Ekman", "(Ekman, 1971, Ekman, 1992)", "with", "many", "adding", "a", "few", "labels", "often", "following", "Plutchik's", "theory", "of", "emotions", "(Plutchik, 1980).", "A", "typical", "emotion", "dataset", "consists", "of", "6-8", "categories.", "The", "exception", "Bostan", "and", "Klinger (2018)", "mention", "is", "CrowdFlower", "2", "with", "14", "categories,", "and", "those", "not", "mentioned", "in", "Bostan", "et", "al.", "are", "e.g.", "the", "SemEval", "2018", "task", "1", "subtask", "c", "dataset", "(Mohammad et al., 2018)", "with", "11", "categories,", "EmoNet", "with", "24", "(Abdul-Mageed and Ungar, 2017),", "and", "the", "GoEmotions", "dataset", "(Demszky et al., 2020)", "with", "27", "categories."], "cited_papers": [{"title": "Semeval-2007 task 14: Affective text", "year": "2007", "authors": ["Carlo Strapparava", "Rada Mihalcea"]}], "target_citation_location": 17, "citation_locations": [2, 17, 20, 33, 46, 59, 85, 92, 97], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "aa6c5b3b-6120-40ed-b1ad-6057a294745a", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["The", "existing", "approach", "to", "convert", "coreference", "annotations", "into", "(question,", "context,", "answer)", "tuples,", "which", "is", "used", "to", "improve", "coreference", "resolution", "performance", "(Wu et al., 2020b, Aralikatte et al., 2019),", "is", "to", "use", "the", "sentence", "of", "the", "anaphor", "as", "a", "declarative", "query,", "and", "its", "closest", "antecedent", "as", "the", "answer.", "The", "format", "of", "these", "queries", "is", "not", "compatible", "with", "questions", "in", "MRC", "datasets,", "and", "therefore,", "the", "impact", "of", "this", "data", "on", "MRC", "models", "may", "be", "limited.", "In", "this", "work,", "we", "instead", "generate", "questions", "from", "those", "declarative", "queries", "using", "an", "automatic", "question", "generation", "model.", "We", "use", "the", "BART", "model", "(Lewis et al., 2020)", "that", "is", "one", "of", "the", "state-of-the-art", "text", "generation", "models.", "Below", "we", "explain", "the", "details", "of", "each", "of", "these", "two", "approaches", "for", "creating", "QA", "data", "from", "CoNLL-2012.", "Table", "4", "shows", "examples", "from", "both", "approaches.", "2019)", "choose", "a", "sentence", "that", "contains", "an", "anaphor", "as", "a", "declarative", "query,", "the", "closest", "nonpronominal", "antecedent", "of", "that", "anaphor", "as", "the", "answer,", "and", "the", "corresponding", "document", "of", "the", "expressions", "as", "the", "context.", "10", "We", "remove", "the", "tuples", "in", "which", "the", "anaphor", "and", "its", "antecedent", "are", "identical.", "The", "reason", "is", "that", "(1)", "Quoref", "already", "contains", "many", "examples", "in", "which", "the", "coreference", "relation", "is", "between", "two", "mentions", "with", "the", "same", "string,", "and", "(2)", "even", "after", "removing", "such", "examples,", "CoNLL", "dec", "contains", "around", "four", "times", "more", "QA", "pairs", "than", "the", "Quoref", "training", "data."], "cited_papers": [{"title": "CorefQA: Coreference resolution as query-based span prediction", "year": "2020", "authors": ["Wei Wu", "Fei Wang", "Arianna Yuan", "Fei Wu", "Jiwei Li"]}, {"title": "A Simple Transfer Learning Baseline for Ellipsis Resolution", "year": "2019", "authors": ["Rahul Aralikatte", "Matthew Lamm", "Daniel Hardt", "Anders S\u00f8gaard"]}], "target_citation_location": 20, "citation_locations": [20, 88], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "aab2a284-5fd6-40c4-83b3-f9356062c06e", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["To", "solve", "this", "dilemma", "and", "bridge", "the", "gap", "between", "practical", "needs", "for", "simple", "definitions", "and", "current", "trivial", "definition", "generation", "systems,", "we", "present", "a", "novel", "method", "for", "the", "SDG", "task.", "As", "illustrated", "in", "Figure", "2,", "our", "method", "leverages", "a", "multitasking", "framework", "SimpDefiner", "to", "generate", "simple", "definitions", "by", "performing", "three", "sub-tasks", "at", "the", "same", "time,", "which", "are", "definition", "generation,", "text", "reconstruction,", "and", "language", "modeling", "tasks.", "The", "framework", "consists", "of", "a", "fully", "shared", "encoder", "and", "two", "partially", "shared", "decoders.", "We", "disentangle", "the", "complexity", "factors", "from", "the", "text", "by", "designing", "a", "parameter", "sharing", "scheme.", "Particularly,", "we", "share", "parameters", "in", "Complexity-Dependent", "Layer", "Normalization", "and", "Complexity-Dependent", "Query", "Projection", "of", "the", "transformer", "architecture", "(Vaswani et al., 2017)", "to", "control", "the", "complexity", "(Section", "3.3).", "Through", "joint", "learning", "and", "sharing", "parameters", "between", "the", "decoders,", "the", "SimpDefiner", "is", "able", "to", "generate", "complex", "and", "simple", "definitions", "simultaneously."], "cited_papers": [{"title": "Attention is all you need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 106, "citation_locations": [106], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "aad2da78-b66b-4c02-aff6-f7c2b056bd58", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["With", "the", "same", "parameters", "as", "for", "English,", "we", "used", "language-specific", "BERT", "models", "from", "Huggingface", "transformers", "(Wolf et al., 2019)", "for", "the", "Arabic,", "Chinese,", "Dutch,", "Finnish,", "German", "and", "Turkish", "datasets", "with", "5-fold", "cross-validation.", "The", "annotated", "Finnish", "dataset", "achieves", "an", "f1", "score", "of", "0.51.", "The", "projected", "annotations", "achieve", "slightly", "worse", "f1", "scores", "than", "the", "annotated", "dataset", "at", "0.45", "for", "Finnish", "(see", "table", "9).", "The", "other", "datasets", "achieve", "similar", "f1", "scores,", "with", "the", "Germanic", "languages", "of", "German", "and", "Dutch", "achieving", "almost", "as", "high", "scores", "as", "the", "original", "English", "dataset.", "This", "is", "likely", "a", "reflection", "of", "typological,", "cultural,", "and", "linguistic", "similarities", "between", "the", "languages", "making", "the", "translation", "to", "begin", "with", "more", "similar", "to", "the", "original", "and", "therefore", "minimizing", "information", "loss."], "cited_papers": [{"title": "Huggingface's transformers: State-of-the-art natural language processing", "year": "2019", "authors": ["Thomas Wolf", "Lysandre Debut", "Victor Sanh", "Julien Chaumond", "Clement Delangue", "Anthony Moi", "Pierric Cistac", "Tim Rault", "R\u00e9mi Louf", "Morgan Funtowicz"]}], "target_citation_location": 15, "citation_locations": [15], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ab29fb5d-f5f3-4af8-8067-747b95c45081", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["However,", "MMB's", "attitude", "to", "these", "primitives", "was", "very", "unlike", "that", "of", "other", "peddlers", "of", "conceptual", "primitives", "or", "languages", "of", "thought:", "at", "no", "point", "did", "she", "suggest,", "in", "the", "way", "that", "became", "fashionable", "later", "in", "cognitive", "science,", "that", "the", "primitive", "names", "constituted", "some", "sort", "of", "language", "in", "the", "mind", "or", "brain", "(Fodor's view, 1975)", "or", "that,", "although", "they", "appeared", "to", "be", "English,", "the", "primitives", "like", "'Move'", "and", "'Do'", "were", "really", "the", "names", "of", "underlying", "entities", "that", "were", "not", "in", "any", "particular", "language", "at", "all.", "This", "kind", "of", "naive", "imperialism", "of", "English", "has", "been", "the", "bane", "of", "linguistics", "for", "many", "years,", "and", "shows,", "by", "contrast,", "the", "far", "greater", "sophistication", "of", "the", "structuralism", "that", "preceded", "it."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 50, "citation_locations": [50], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ab429d5c-3f3a-47af-ad2d-a6fbb4748ae4", "citing_paper": {"title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables", "year": 2022, "authors": ["Nan Hu", "Zirui Wu", "Yuxuan Lai", "Xiao Liu", "Yansong Feng"]}, "text": ["An", "efficient", "and", "effective", "document", "retriever", "is", "required", "since", "the", "Wikipedia", "dump", "containing", "millions", "of", "pages.", "We", "first", "narrow", "the", "search", "space", "to", "several", "hundred", "pages", "(m", "0)", "with", "an", "efficient", "information", "retrieval", "method", "based", "on", "TF-IDF,", "namely,", "DRQA", "(Chen et al., 2017).", "A", "RoBERTa-based", "re-ranker", "(Saeed et al., 2021)", "and", "a", "BM25-based", "re-ranker", "are", "then", "applied", "in", "parallel", "to", "re-rank", "the", "m", "0", "document", "candidates.", "We", "combine", "the", "results", "of", "two", "re-rankers", "and", "keep", "top", "m", "documents", "since", "BM25", "focuses", "more", "on", "entity", "matching", "and", "RoBERTa-based", "re-ranker", "pays", "more", "attention", "to", "the", "overall", "sentence", "structure.", "The", "document", "scores", "are", "calculated", "as", "the", "sum", "of", "their", "rankings", "in", "the", "two", "re-rankers.", "Documents", "with", "lower", "scores", "have", "higher", "priority."], "cited_papers": [{"title": "Neural re-rankers for evidence retrieval in the feverous task", "year": "2021", "authors": ["Mohammed Saeed", "Giulio Alfarano", "Khai Nguyen", "Duc-Hong Pham", "Raphael Troncy", "Paolo Papotti"]}], "target_citation_location": 43, "citation_locations": [39, 43], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ab9b4581-bbae-4024-8b64-41677f0be38a", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["Thus", "there", "are", "a", "number", "of", "situations", "in", "which", "gCNs", "are", "not", "sufficient.", "Given", "that", "gCNs", "can", "be", "represented", "by", "Tree", "Substitution", "Grammars,", "as", "in", "Eisner (2003),", "which", "are", "in", "fact", "TAGs", "that", "do", "not", "allow", "precisely", "the", "kind", "of", "unbounded", "phenomena", "described", "by", "TAGs,", "this", "would", "suggest", "that", "using", "a", "TAG", "grammar", "to", "describe", "the", "gNCNs", "in", "order", "to", "decompose", "the", "trees", "would", "be", "feasible,", "and", "this", "is", "further", "an", "interesting", "question", "for", "theoretical", "reasons", "described", "below."], "cited_papers": [{"title": "Learning Non-Isomorphic Tree Mappings for Machine Translation", "year": "2003", "authors": ["J Eisner"]}], "target_citation_location": 25, "citation_locations": [25], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "abbb97d9-f4b3-46c7-9b36-6858c50b4e2e", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["In", "this", "part,", "we", "conduct", "the", "extensive", "experiments", "on", "MSMARCO", "dataset", "to", "examine", "the", "effectiveness", "of", "the", "three", "strategies", "in", "RocketQA.", "Results", "on", "NQ", "dataset", "has", "shown", "the", "similar", "findings", "(see", "in", "Section", "A.2", "in", "Appendix).", "First,", "we", "compare", "cross-batch", "negatives", "with", "inbatch", "negatives", "by", "using", "the", "same", "experimental", "setting", "(i.e.", "the", "number", "of", "epochs", "is", "40", "and", "the", "batch", "size", "is", "512", "on", "each", "single", "GPU).", "From", "the", "first", "two", "rows", "in", "Table", "3,", "we", "can", "see", "that", "the", "performance", "of", "the", "dense", "retriever", "can", "be", "improved", "with", "more", "negatives", "by", "cross-batch", "negatives.", "It", "is", "expected", "that", "when", "increasing", "the", "number", "of", "random", "negatives,", "it", "will", "reduce", "the", "discrepancy", "between", "training", "and", "inference.", "Furthermore,", "we", "investigate", "the", "effect", "of", "the", "number", "of", "random", "negatives.", "Specifically,", "we", "examine", "the", "performance", "of", "dual-encoders", "trained", "by", "using", "different", "numbers", "of", "random", "negatives", "with", "a", "fixed", "number", "of", "steps.", "From", "Figure", "4,", "we", "can", "see", "that", "the", "model", "performance", "increases,", "when", "the", "number", "of", "random", "negatives", "becomes", "larger.", "After", "a", "certain", "point,", "the", "model", "performance", "starts", "to", "drop,", "since", "a", "large", "batch", "size", "may", "bring", "difficulty", "for", "optimization", "on", "training", "data", "with", "limited", "size.", "We", "say", "that", "there", "should", "be", "a", "balance", "between", "the", "batch", "size", "and", "the", "number", "of", "negatives.", "When", "increasing", "the", "batch", "size,", "we", "will", "have", "more", "negatives", "for", "each", "question.", "However,", "when", "the", "size", "of", "training", "data", "is", "limited,", "a", "large", "batch", "size", "will", "bring", "difficulty", "for", "optimization.", "Second,", "we", "examine", "the", "effect", "of", "denoised", "hard", "negatives", "from", "the", "top-k", "passages", "retrieved", "by", "the", "dense", "retriever.", "As", "shown", "in", "the", "third", "row", "in", "Table", "3,", "the", "performance", "of", "the", "retriever", "significantly", "decreases", "by", "introducing", "hard", "negatives", "without", "denoising.", "We", "speculate", "that", "it", "is", "caused", "by", "the", "fact", "that", "there", "are", "a", "large", "number", "of", "unlabeled", "positives.", "Specifically,", "we", "manually", "examine", "the", "topretrieved", "passages", "of", "100", "questions,", "that", "were", "not", "labeled", "as", "true", "positives.", "We", "find", "that", "about", "70%", "of", "them", "are", "actually", "positives", "or", "highly", "relevant.", "Hence,", "it", "is", "likely", "to", "bring", "noise", "if", "we", "simply", "sample", "hard", "negatives", "from", "the", "top-retrieved", "passages", "by", "the", "dense", "retriever,", "which", "is", "a", "widely", "adopted", "strategy", "to", "sample", "hard", "negatives", "in", "previous", "studies", "(Gillick et al., 2019, Wu et al., 2020, Xiong et al., 2020).", "As", "a", "comparison,", "we", "propose", "denoised", "hard", "negatives", "by", "a", "powerful", "cross-encoder.", "From", "the", "fourth", "row", "in", "Table", "3,", "we", "can", "see", "that", "denoised", "negatives", "improve", "the", "performance", "of", "the", "dense", "retriever.", "To", "obtain", "more", "insights", "about", "denoised", "hard", "negatives,", "Table", "4", "gives", "the", "sampled", "hard", "negatives", "for", "two", "questions", "before", "and", "after", "denoising.", "Figure", "5", "further", "illustrates", "the", "ratio", "of", "filtered", "passages", "at", "different", "ranks.", "We", "can", "see", "that", "there", "are", "more", "passages", "filtered", "(i.e.", "denoised)", "at", "lower", "ranks,", "since", "it", "is", "likely", "to", "have", "more", "false", "negatives", "at", "lower", "ranks."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Learning dense representations for entity retrieval", "year": "2019", "authors": ["Daniel Gillick", "Sayali Kulkarni", "Larry Lansing", "Alessandro Presta", "Jason Baldridge", "Eugene Ie", "Diego Garc\u00eda-Olano"]}], "target_citation_location": 361, "citation_locations": [361], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ac2e4321-9781-4537-a807-e08111d1a7d4", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["For", "the", "Portuguese", "language,", "most", "of", "the", "works", "follow", "the", "trend", "of", "supervised", "approaches.", "de", "Pelle", "and", "Moreira", "(2017)", "created", "a", "dataset", "consist", "of", "1,", "250", "offensive", "comments", "and", "developed", "a", "baseline", "method", "based", "on", "n-gram", "features", "to", "classify", "offensive", "comments", "in", "their", "dataset.", "Fortuna et al. (2019)", "created", "a", "hate", "speech", "dataset", "composed", "of", "5,", "668", "tweets", "and", "developed", "a", "baseline", "classification", "using", "pre-trained", "word", "embeddings", "and", "LSTM", "in", "their", "dataset.", "Coutinho", "and", "Malheiros", "(2020)", "trained", "a", "logistic", "regression", "using", "superficial", "features", "for", "sentiment", "analysis.", "Then,", "they", "evaluated", "that", "model", "into", "a", "homophobia", "corpus", "to", "detect", "homophobic", "posts."], "cited_papers": [{"title": "A hierarchically-labeled Portuguese hate speech dataset", "year": "2019", "authors": ["Paula Fortuna", "Jo\u00e3o Rocha Da", "Juan Silva", "Leo Soler-Company", "S\u00e9rgio Wanner", "unk Nunes"]}], "target_citation_location": 44, "citation_locations": [44], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "aca5e2ad-8826-4668-b271-e1d1346d9ed9", "citing_paper": {"title": "Diverse dialogue generation with context dependent dynamic loss function", "year": 2020, "authors": ["Ayaka Ueyama", "Yoshinobu Kano"]}, "text": ["Recently,", "many", "reports", "have", "described", "studies", "using", "deep", "learning", "for", "dialogue", "systems", "that", "have", "achieved", "good", "performance.", "They", "can", "generate", "fluent", "sentences", "based", "on", "a", "user's", "utterances", "(Vinyals and Le, 2015, Shang et al., 2015, Serban et al., 2016).", "Nevertheless,", "such", "neural", "dialogue", "systems", "tend", "to", "generate", "phrases", "such", "as", "\"Yes\"", "and", "\"I", "do", "not", "know\"", "frequently", "in", "non-task-oriented", "dialog", "systems,", "referred", "to", "as", "the", "low", "diversity", "issue", "and", "the", "generic", "response", "issue.", "After", "training", "by", "a", "loss", "function", "of", "similarity", "with", "gold", "standard", "reference", "sentences,", "frequent", "phrases", "are", "more", "likely", "to", "be", "assigned", "a", "large", "occurrence", "probability", "than", "rare", "phrases", "are.", "Nakamura et al. (2018)", "proposed", "an", "Inverse", "Token", "Frequency", "(ITF)", "loss,", "which", "multiplies", "the", "Softmax", "Cross-Entropy", "(SCE)", "loss", "by", "weights", "based", "on", "the", "inverse", "of", "the", "frequency", "of", "tokens.", "This", "ITF", "loss", "incorporates", "the", "frequency", "distribution", "of", "token", "classes", "so", "that", "rare", "tokens", "become", "more", "likely", "to", "appear."], "cited_papers": [{"title": "Another diversity promoting objective function for neural dialogue generation", "year": "2018", "authors": ["Ryo Nakamura", "Katsuhito Sudoh", "Koichiro Yoshino", "Satoshi Nakamura"]}], "target_citation_location": 91, "citation_locations": [27, 91], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "acb98889-e9a5-46ce-b42c-416498fcd0a1", "citing_paper": {"title": "Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure", "year": 1999, "authors": ["Nicoletta Calzolari", "Antonio Zampolli"]}, "text": ["As", "other", "current", "actions", "in", "the", "field", "of", "LR", "(e.g.", "EAGLES,", "which", "is", "a", "direct", "descendant", "of", "the", "\"Pisa", "Group\",", "set-up", "at", "the", "Grosseto", "Workshop", "by", "the", "Istituto", "di", "Linguistica", "Computazionale", "(ILC)", "of", "Pisa", "and", "sponsored", "by", "the", "Association", "for", "Computational", "Linguistics", "Sept. 1999", "(ACL)", "to", "explore", "the", "feasibility", "of", "\"polytheoretical", "lexicons\"", "(Walker et al. 1987", ")),", "the", "PAROLE", "and", "SIMPLE", "projects,", "building", "large", "corpora", "and", "lexicons", "for", "many", "European", "languages,", "are", "the", "follow-up", "of", "some", "initiatives", "promoted", "at", "the", "Grosseto", "Workshop.", "The", "Council", "of", "Europe,", "which", "had", "co-sponsored", "the", "workshop,", "formed", "a", "group", "of", "experts,", "representing", "European", "institutes", "with", "a", "well", "established", "tradition", "in", "the", "field", "of", "lexical", "and", "corpus", "studies,", "to", "explore", "the", "feasibility", "of", "harmonising", "their", "activities,", "in", "order", "to", "establish", "a", "Network", "of", "European", "Reference", "Corpora", "(NERC,", "for", "which", "see", "Calzolari, Baker, Kruyt 1996, Zampolli 1996).", "This", "group,", "gradually", "enlarged", "to", "include", "members", "of", "all", "the", "European", "Union", "(EU)", "languages,", "constituted", "the", "PAROLE", "Consortium", "which", "has", "executed", "the", "LE", "(Language", "Engineering)", "PAROLE", "project", "now", "followed", "by", "the", "LE", "SIMPLE", "project", "carried", "on", "by", "a", "similar", "Consortium", "1."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Introduction", "year": "1996", "authors": ["A Zampolli"]}], "target_citation_location": 130, "citation_locations": [42, 51, 130], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "ad05d75b-ede6-4122-992b-6e401cf1ab8c", "citing_paper": {"title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection", "year": 2021, "authors": ["Henry Weld", "Guanghao Huang", "Jean Lee", "Tongshu Zhang", "Kunze Wang", "Xinghong Guo", "Siqu Long", "Josiah Soyeon", "Caren Han"]}, "text": ["Token-level", "Slot", "Annotation", "With", "the", "processed", "token-level", "data,", "an", "automated", "slot", "labelling", "is", "performed.", "Initially,", "we", "create", "six", "distinct", "slot", "labels:", "T", "(Toxicity),", "C", "(Character),", "D", "(Dotaspecific),", "S", "(game", "Slang),", "P", "(Pronoun)", "and", "O", "(Other).", "To", "construct", "the", "T", "lexicon,", "we", "combine", "several", "toxicity", "lexicons", "(see", "Section", "8", "Ethics)", "and", "remove", "overlaps.", "We", "also", "use", "the", "supplemental", "data", "sourced", "by", "M\u00e4rtens et al. (2015)", "for", "the", "gamerelated", "lexicons", "(C,", "D", "and", "S)", "and", "carefully", "modify", "it.", "The", "P", "lexicon", "(e.g.", "'u',", "'ur')", "is", "constructed", "by", "this", "research", "because", "in-game", "chat", "is", "extremely", "abbreviated.", "Then,", "we", "perform", "lexicon-based", "automation", "by", "exact", "matching", "each", "lower-cased", "token", "against", "the", "lexicons.", "Anything", "not", "matching", "a", "lexicon", "is", "labelled", "O.", "We", "contrast", "this", "with", "typical", "NLU", "slot", "labelling", "where", "a", "semantic", "concept", "can", "stretch", "over", "a", "span", "of", "words.", "In", "comparison", "to", "other", "toxicity", "datasets,", "our", "lexicon-based", "slot", "labelling", "enables", "deeper", "understanding", "of", "game", "context."], "cited_papers": [{"title": "Toxicity detection in multiplayer online games", "year": "2015", "authors": ["Marcus M\u00e4rtens", "Siqi Shen", "Alexandru Iosup", "Fernando Kuipers"]}], "target_citation_location": 60, "citation_locations": [60], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "add4a02a-4b34-4406-8f14-79257408a1d4", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["However,", "event", "detection", "as", "a", "problem", "shifts", "when", "we", "move", "away", "from", "the", "annotation", "paradigm", "of", "datasets", "such", "as", "ACE", "(Doddington et al., 2004)", "and", "TAC", "KBP", "(Mitamura et al., 2015)", "to", "TimeML", "datasets", "such", "as", "TimeBank", "(Pustejovsky et al., 2006),", "which", "are", "used", "in", "this", "paper.", "There", "has", "been", "limited", "use", "of", "deep", "learning", "methods", "on", "TimeBanks", "due", "to", "fewer", "event", "mentions", "and", "a", "need", "for", "data", "augmentation", "and", "bootstrapping.", "However,", "in", "this", "paper,", "we", "show", "that", "using", "subword", "level", "information,", "a", "language", "invariant", "deep", "learning", "model", "can", "provide", "similar", "event", "detection", "accuracies", "as", "heavily", "feature", "engineered", "language", "specific", "statistical", "methods", "without", "using", "any", "augmented", "data."], "cited_papers": [{"title": "The automatic content extraction (ace) program-tasks, data, and evaluation", "year": "2004", "authors": ["Alexis George R Doddington", "unk Mitchell", "A Mark", "unk Przybocki", "A Lance", "Stephanie Ramshaw", "Ralph Strassel", "unk Weischedel"]}], "target_citation_location": 20, "citation_locations": [20, 24, 31], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ae1957ef-036a-4924-be18-a3bc093a52a0", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["Generating", "Job", "Ads", "We", "use", "the", "OpenAI", "Davinci", "GPT-3", "model", "which", "has", "been", "adapted", "for", "natural", "language", "requests.", "We", "use", "default", "parameters", "values", "and", "500", "maximum", "tokens", "per", "completion", "(see", "Appendix", "B", "for", "hyperparameter", "details).", "Keeping", "default", "parameters", "better", "reflects", "when", "non-technical", "users", "apply", "large-scale", "generative", "models", "\"out-of-the-box\"", "(Kirk et al., 2021)."], "cited_papers": [{"title": "Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models", "year": "2021", "authors": ["Hannah Kirk", "Yennie Jun", "Haider Iqbal", "Elias Benussi", "Filippo Volpin", "Frederic Dreyer", "Aleksandar Shtedritski", "Yuki Asano"]}], "target_citation_location": 48, "citation_locations": [48], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "ae3d44a5-f262-49a9-8dbd-19c4c729f60f", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["We", "consider", "three", "baselines.", "Random", "assigns", "a", "relation", "to", "each", "argument", "randomly.", "Sentiment", "assigns", "a", "relation", "based", "on", "the", "claim", "and", "statement's", "agreement", "on", "sentiment:", "support", "if", "both", "are", "positive", "or", "negative,", "attack", "if", "they", "have", "opposite", "sentiments,", "and", "neutral", "otherwise.", "We", "compute", "a", "sentiment", "distribution", "by", "averaging", "all", "target-specific", "sentiments", "from", "our", "sentiment", "classifier", "(\u00a74.2).", "Textual", "entailment", "assigns", "support", "(attack)", "if", "the", "statement", "entails", "(contradicts)", "the", "claim,", "and", "neutral", "otherwise", "(Cabrio and Villata 2012).", "We", "use", "our", "textual", "entailment", "module", "(\u00a74.1).", "For", "Debatepedia,", "we", "choose", "between", "support", "and", "attack", "whichever", "has", "a", "higher", "probability."], "cited_papers": [{"title": "Combining textual entailment and argumentation theory for supporting online debates interactions", "year": "2012", "authors": ["Elena Cabrio", "Serena Villata"]}], "target_citation_location": 71, "citation_locations": [71], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ae5ddf50-4bad-45fd-b151-ae9890871b6d", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Overall", "training", "is", "done", "via", "A2C", "(Mnih et al., 2016)", "a", "policy", "gradient", "algorithm", "that", "maximizes", "long-term", "expected", "reward", "by", "comparing", "the", "advantage", "A(s", "t,", "a", "*", "t)", "of", "taking", "an", "action", "a", "t", "in", "a", "state", "s", "t", "to", "the", "average", "value", "of", "taking", "any", "valid", "action", "as", "predicted", "by", "the", "critic", "V", "(s", "t", ").", "The", "setup", "and", "network", "architectures", "used", "are", "similar", "to", "Ammanabrolu et al. (2021)", "and", "are", "summarized", "in", "Figure", "5.", "At", "every", "step,", "the", "LIGHT", "agent", "receives", "as", "input", "the", "text", "describing", "the", "setting,", "the", "character's", "persona", "&amp,", "motivation,", "and", "the", "full", "dialogue", "history.", "This", "is", "then", "encoded", "using", "a", "transformer", "based", "encoder", "and", "sent", "to", "the", "action", "and", "dialogue", "policy", "networks", "which", "output", "an", "action/dialogue", "utterance.", "These", "are", "then", "passed", "into", "the", "LIGHT", "environment", "which", "process", "them", "and", "returns", "rewards", "to", "be", "used", "by", "the", "agent."], "cited_papers": [{"title": "Asynchronous methods for deep reinforcement learning", "year": "2016", "authors": ["Volodymyr Mnih", "Adria Badia", "Mehdi Mirza", "Alex Graves", "Timothy Lillicrap", "Tim Harley", "David Silver", "Koray Kavukcuoglu"]}], "target_citation_location": 6, "citation_locations": [6, 63], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ae68ab23-857f-4911-9fea-04afa056d087", "citing_paper": {"title": "Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets", "year": 2021, "authors": ["George-Andrei Dima", "Dumitru-Clementin Cercel", "Mihai Dascalu"]}, "text": ["Augmented", "Training", "Dataset:", "Another", "explored", "solution", "for", "the", "unbalance", "in", "subtask", "1a", "consists", "in", "augmenting", "the", "poorly", "represented", "class", "(the", "positive", "class).", "We", "leverage", "the", "predefined", "augmentation", "approaches", "integrated", "into", "the", "Tex-tAttack", "library", "(Morris et al., 2020).", "New", "positive", "examples", "are", "generated", "by", "char", "swapping,", "by", "replacing", "words", "with", "synonyms", "from", "the", "Word-Net", "thesaurus", "(Miller, 1995),", "and", "by", "using", "methods", "from", "the", "CheckList", "testing", "-i.e.,", "transformations", "like", "location", "replacement", "or", "number", "alteration", "(Ribeiro et al., 2020).", "Five", "positive", "examples", "are", "automatically", "added", "for", "each", "initial", "positive", "sample,", "thus", "increasing", "the", "proportion", "of", "the", "poorly", "represented", "class", "from", "7%", "to", "almost", "45%."], "cited_papers": [{"title": "Beyond accuracy: Behavioral testing of nlp models with checklist", "year": "2020", "authors": ["Tongshuang Marco Tulio Ribeiro", "Carlos Wu", "Sameer Guestrin", "unk Singh"]}], "target_citation_location": 68, "citation_locations": [33, 51, 68], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "aeef5942-2940-408d-90f9-5e10f71859b7", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["DeKo", "is", "implemented", "as", "a", "series", "of", "finite-state", "transducers,", "using", "the", "FST-suite", "provided", "by", "AT&amp,T", "(Sproat 2000b).", "A", "more", "detailed", "description", "of", "the", "architecture", "is", "given", "in", "Schmid et al. (2001)", "and", "examples", "for", "the", "rule", "format", "are", "provided", "in", "S\u00e4uberlich (2001).", "We", "need", "to", "model", "three", "types", "of", "rules:"], "cited_papers": [{"title": "Lextools. A toolkit for finite-state linguistic analysis", "year": "2000", "authors": ["Richard Sproat"]}], "target_citation_location": 15, "citation_locations": [15, 26, 36], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "aef1ab18-d50f-436a-bb4e-265238d20bf1", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["One", "of", "the", "crucial", "issues", "regarding", "the", "evaluation", "of", "multi-hop", "inference", "models", "is", "the", "possibility", "to", "achieve", "strong", "overall", "performance", "without", "using", "real", "compositional", "methods", "(Min et al., 2019, Chen and Durrett, 2019, Trivedi et al., 2020).", "Therefore,", "in", "order", "to", "evaluate", "multi-hop", "inference", "more", "explicitly,", "we", "break", "down", "the", "performance", "of", "each", "model", "with", "respect", "to", "the", "difficulty", "of", "accessing", "specific", "facts", "in", "an", "explanation", "via", "direct", "lexical", "overlap.", "This", "comes", "from", "the", "assumption", "that", "facts", "sharing", "many", "terms", "with", "question", "or", "answer", "are", "relatively", "easier", "to", "find", "and", "rank", "highly."], "cited_papers": [{"title": "Understanding Dataset Design Choices for Multi-hop Reasoning", "year": "2019", "authors": ["Jifan Chen", "Greg Durrett"]}, {"title": "Compositional Questions Do Not Necessitate Multi-hop Reasoning", "year": "2019", "authors": ["Sewon Min", "Eric Wallace", "Sameer Singh", "Matt Gardner", "Hannaneh Hajishirzi", "Luke Zettlemoyer"]}, {"title": "Is Multihop QA in DIRE Condition? Measuring and Reducing Disconnected Reasoning", "year": "2020", "authors": ["Harsh Trivedi", "Niranjan Balasubramanian", "Tushar Khot", "Ashish Sabharwal"]}], "target_citation_location": 25, "citation_locations": [25], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "af1c5ea0-56fe-4c8c-bff3-4d20b2755244", "citing_paper": {"title": "Amrita_CEN_NLP@SDP2021 Task A and B", "year": 2021, "authors": ["Isha Indhu", "Kavya Kumar", "Lakshaya Karthikeyan"]}, "text": ["This", "paper", "reports", "the", "submissions", "of", "the", "Am-rita_CEN_NLP", "team", "for", "the", "3C", "Citation", "Context", "Classification", "shared", "task", "Kunnath et al. (2021).", "We", "used", "deep", "learning", "and", "machine", "learning", "models", "developed", "using", "Bi-LSTM", "and", "Random", "Forest", "algorithms", "Liaw et al. (2002),", "Premjith et al. (2019a),", "Premjith et al. (2019b)", "to", "complete", "the", "subtasks.", "They", "will", "be", "elaborated", "upon", "in", "Section", "4."], "cited_papers": [{"title": "Classification and regression by randomforest", "year": "2002", "authors": ["Andy Liaw", "Matthew Wiener"]}], "target_citation_location": 33, "citation_locations": [17, 33, 34, 35], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "af73f135-942b-405d-9166-b484e4928cbb", "citing_paper": {"title": "SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering", "year": 2020, "authors": ["Aishwarya Ashok", "Ganapathy Natarajan", "Ramez Elmasri", "Laurel Smith-Stvan"]}, "text": ["For", "the", "cosine", "similarity", "calculation,we", "use", "word2vec", "to", "calculate", "the", "sentence", "vector", "as", "sum", "of", "the", "word", "vectors", "of", "the", "words", "in", "the", "sentence.", "The", "calculation", "of", "sentence", "vector", "was", "to", "take", "advantage", "of", "the", "compositionality", "property", "using", "word2vec", "(Mikolov et al., 2013).", "We", "used", "word", "vectors", "of", "dimension", "100", "trained", "on", "the", "2015", "wikidump."], "cited_papers": [{"title": "Efficient estimation of word representations in vector space", "year": "2013", "authors": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"]}], "target_citation_location": 39, "citation_locations": [39], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "af7aef92-2892-49d3-ad18-541ea61a7131", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Instead,", "we", "can", "use", "methods", "that", "require", "only", "raw", "corpora.", "For", "this,", "the", "results", "of", "Spence and Owens (1990)", "are", "the", "most", "important", "studies", "of", "associations.", "They", "have", "shown", "that", "the", "amount", "of", "co-occurrences", "of", "words", "in", "a", "corpus", "is", "a", "good", "indicator", "of", "the", "semantic", "relationship", "between", "them", "and", "is", "also", "suitable", "for", "measuring", "the", "strength", "of", "associations.", "Bel", "Enguix et al. (2014)", "also", "predict", "associations", "from", "co-occurrences,", "using", "a", "network", "of", "bigram", "counts.", "Similar", "to", "their", "methods,", "we", "use", "weighted", "co-occurrences", "explicitly", "to", "model", "the", "connection", "of", "words", "(for", "details,", "see", "4.1.)."], "cited_papers": [{"title": "Lexical co-occurrence and association strength", "year": "1990", "authors": ["P Donald", "Kimberly Spence", "unk Owens"]}], "target_citation_location": 15, "citation_locations": [15, 57], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "af9db006-876a-4b9d-bd37-e2df00d79be8", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["It", "is", "again", "relatively", "recent", "that", "the", "notion", "of", "MT", "with", "restricted", "input", "has", "come", "to", "be", "associated", "with", "'sublanguage'", "([16, 24, 25, 26]", "),", "as", "opposed", "to", "the", "case", "previously,", "when", "it", "was", "typically", "the", "MT", "system", "which", "dictated", "the", "restrictions", "rather", "than", "vice", "versa", "(e.g.", "[11, 31]", ").", "In", "the", "system", "described", "here,", "the", "sublanguage", "approach", "gives", "us", "not", "only", "vocabulary", "and", "syntax,", "but", "also", "the", "contextual", "and", "domain", "knowledge", "employed", "by", "the", "system.", "And,", "in", "keeping", "with", "the", "strong", "corpus-based", "approach,", "these", "knowledge", "sources", "are", "derived", "directly", "from", "an", "analysis", "of", "corpora", "([2]", "),", "not", "from", "some", "linguist's", "introspection,", "as", "is", "the", "case", "in", "conventional", "rule-based", "MT", "systems.", "An", "additional", "point", "of", "interest", "in", "this", "research", "is", "the", "contrastive", "aspect,", "since", "our", "approach", "requires", "us", "to", "make", "an", "explicitly", "comparative", "analysis", "of", "three", "corpora", "which,", "it", "should", "be", "stressed,", "are", "not", "in", "fact", "parallel", "corpora,", "but", "simply", "collections", "of", "pragmatically", "similar", "material."], "cited_papers": [{"title": "Computer-aided translation: a business viewpoint", "year": "1979", "authors": ["J Elliston"]}, {"title": "Pre-editing and the use of simplified writing for MT: an engineer's experience of operating an MT system", "year": "1990", "authors": ["P Pym"]}], "target_citation_location": 44, "citation_locations": [20, 44, 91], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b018449b-a1e7-4f24-a9f1-ee94d1a579af", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["First,", "we", "apply", "our", "framework", "to", "the", "TQ-AutoTest", "dataset", "(Macketanz et al., 2018).", "Originally", "used", "for", "targeted", "evaluation", "of", "MT", "systems,", "it", "includes", "German", "source", "sentences", "that", "each", "exhibit", "one", "of", "14", "different", "linguistic", "phenomena,", "such", "as", "ambiguity,", "composition,", "and", "subordination."], "cited_papers": [{"title": "TQ-AutoTest -an automated test suite for (machine) translation quality", "year": "2018", "authors": ["Vivien Macketanz", "Renlong Ai", "Aljoscha Burchardt", "Hans Uszkoreit"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "b035355d-b503-4763-ab65-87b23be80f6b", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Here,", "we", "summarize", "the", "pre-training", "tasks", "for", "the", "encoders", "mentioned", "in", "Section", "4.2.", "These", "tasks", "are", "unchanged", "from", "those", "described", "in", "Ammanabrolu et al. (2021)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 21, "citation_locations": [21], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1]]}
{"id": "b07a0bb8-2fe4-45ac-be85-45d8184e3b15", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["Much", "work", "in", "NLP", "addresses", "the", "recovery", "of", "such", "verb-mediated", "relations", "(SRL)", "(Gildea and Jurafsky, 2002, Palmer et al., 2010),", "either", "using", "pre-specified", "role", "ontologies", "such", "as", "PropBank", "or", "FrameNet", "(Palmer et al., 2005, Ruppenhofer et al., 2016),", "or,", "more", "recently,", "using", "natural-languagebased", "representations", "(QA-SRL)", "(He et al., 2015, FitzGerald et al., 2018).", "Another", "well-studied", "kind", "of", "semantic", "relations", "between", "NPs", "is", "that", "of", "coreference", "(Vilain et al., 1995, Pradhan et al., 2012),", "where", "two", "(or", "more)", "NPs", "refer", "to", "the", "same", "entity."], "cited_papers": [{"title": "CoNLL-2012 shared task: Modeling multilingual unrestricted coreference in Onto-Notes", "year": "2012", "authors": ["Alessandro Sameer Pradhan", "Nianwen Moschitti", "Olga Xue", "Yuchen Uryupina", "unk Zhang"]}, {"title": "A model-theoretic coreference scoring scheme", "year": "1995", "authors": ["Marc Vilain", "John Burger", "John Aberdeen", "Dennis Connolly", "Lynette Hirschman"]}], "target_citation_location": 44, "citation_locations": [12, 23, 31, 44], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "b0c87bf3-5014-4c55-81db-1f11a6e28435", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["BoW", "+", "BERT", "As", "a", "baseline,", "we", "consider", "the", "retrieve-and-rerank", "approach", "originally", "proposed", "by", "Nogueira and Cho (2019),", "which", "has", "emerged", "as", "the", "standard", "architecture", "for", "applying", "pretrained", "transformers", "to", "ranking.", "We", "notate", "a", "specific", "configuration", "of", "this", "design", "as", "BoW(k", "0)", "+", "BERT,", "where", "k", "0", "denotes", "the", "number", "of", "candidates", "from", "bag-of-words", "retrieval", "that", "are", "then", "reranked", "by", "BERT.", "A", "commonly", "used", "default", "is", "BoW(1000)", "+", "BERT", "(Nogueira and Cho, 2019)."], "cited_papers": [{"title": null, "year": "2019", "authors": ["Rodrigo Nogueira", "Kyunghyun Cho"]}], "target_citation_location": 14, "citation_locations": [14, 66], "citation_type": "single", "annotations": [[0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b0d1f62f-c2ce-4f1a-b8b5-6f075f6b49c4", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Parametrizing", "Curriculum", "Difficulty.", "Given", "the", "relative", "imbalance", "of", "this", "multinomial", "distribution,", "as", "seen", "in", "Figure", "3,", "we", "hypothesize", "that", "a", "LIGHT", "agent", "only", "learns", "to", "do", "well", "on", "certain", "types", "of", "objectives", "and", "not", "others-memorizing", "trajectories", "for", "less", "seen", "quest", "types,", "i.e.", "those", "found", "in", "the", "tail", "of", "the", "distribution.", "Preliminary", "evidence", "for", "this", "hypothesis", "is", "also", "seen", "in", "Prabhumoye et al. (2020),", "where", "they", "show", "a", "positive", "correlation", "between", "the", "number", "of", "instances", "of", "a", "particular", "type", "of", "quest", "during", "training", "and", "the", "final", "test", "goal-achievement", "performance.", "Based", "on", "these", "observations", "and", "our", "initial", "hypothesis,", "we", "use", "this", "particular", "dimension", "to", "parametrize", "curriculum", "difficulty", "for", "training", "LIGHT", "agents-quest", "types", "that", "are", "rarer", "in", "the", "initial", "training", "data", "will", "be", "harder", "for", "the", "agent", "to", "generalize", "to", "in", "a", "zero-shot", "setting."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 59, "citation_locations": [59], "citation_type": "single", "annotations": [[0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b0d2c639-bda5-4912-865b-0b256b8889dc", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["At", "a", "high", "level,", "the", "entire", "premise", "of", "our", "work", "is", "the", "point", "of", "multi-stage", "ranking,", "in", "that", "the", "architecture", "evolved", "to", "achieve", "a", "good", "balance", "between", "effectiveness", "and", "efficiency", "in", "end-to-end", "retrieval.", "Motivated", "by", "the", "observation,", "dating", "back", "more", "than", "a", "decade,", "that", "effective", "techniques", "are", "often", "computationally", "expensive,", "multi-stage", "retrieval", "architectures", "control", "latency", "by", "applying", "expensive", "techniques", "over", "only", "the", "most", "promising", "candidates", "(Wang et al., 2011).", "This", "is", "often", "operationalized", "as", "optimizing", "for", "recall", "in", "the", "earlier", "stages", "of", "the", "pipeline.", "Specifically", "in", "the", "context", "of", "transformers,", "multi-stage", "neural", "pipelines", "have", "been", "explored", "in", "the", "past", "by", "many", "researchers", "(Nogueira et al., 2019a, Soldaini and Moschitti, 2020, Matsubara et al., 2020, Pradeep et al., 2021).", "The", "key", "difference", "in", "our", "work", "is", "the", "(re-)introduction", "of", "\"traditional\"", "feature-based", "learning-to-rank", "approaches", "alongside", "neural", "models.", "This", "aligns", "with", "our", "broader", "goal", "of", "investigating", "how", "learning", "to", "rank", "might", "contribute", "to", "modern", "retrieval", "approaches", "dominated", "by", "neural", "models.", "The", "computational", "costs", "associated", "with", "ranking", "using", "pretrained", "transformers", "can", "be", "reduced", "in", "various", "ways.", "We", "can", "accelerate", "inference", "using", "smaller", "or", "simpler", "models.", "Gao et al. (2020)", "use", "distillation", "to", "transfer", "knowledge", "captured", "in", "a", "larger", "model", "into", "a", "smaller", "model,", "achieving", "substantial", "speedups", "with", "minimal", "effectiveness", "loss.", "Hofst\u00e4tter et al. (2020)", "propose", "a", "simpler", "transformer", "model", "to", "capture", "contextual", "information", "that", "trades", "effectiveness", "for", "much", "faster", "inference.", "Additional", "examples", "of", "this", "approach", "include", "Mitra et al. (2020) and MacAvaney et al. (2020).", "An", "alternative", "is", "to", "introduce", "early-exit", "optimizations,", "as", "in", "Soldaini and Moschitti (2020)", "and", "Xin et al. (2020).", "Further", "speedups", "can", "be", "gained", "by", "making", "modifications", "to", "the", "backbone", "transformer", "model,", "as", "in", "Sanh et al. (2020).", "The", "key", "point", "is", "that", "our", "proposed", "LTR", "filtering", "module", "achieves", "speedups", "in", "a", "manner", "that", "is", "orthogonal", "to", "the", "methods", "discussed", "here,", "which", "focus", "on", "directly", "accelerating", "transformer", "inference.", "Thus,", "these", "approaches", "can", "be", "combined", "with", "our", "method", "for", "even", "greater", "efficiency", "gains."], "cited_papers": [{"title": "Early exiting BERT for efficient document ranking", "year": "2020", "authors": ["Ji Xin", "Rodrigo Nogueira", "Yaoliang Yu", "Jimmy Lin"]}], "target_citation_location": 220, "citation_locations": [65, 99, 163, 185, 208, 218, 220, 236], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b13a34ae-b9af-4cca-a89c-eae005576f40", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["There", "are", "two", "approaches", "to", "assessing", "the", "productivity", "of", "a", "word", "formation", "rule:", "the", "qualitative", "and", "the", "quantitative", "approach.", "For", "a", "full", "understanding,", "a", "combination", "of", "both", "perspectives", "is", "necessary.", "In", "the", "qualitative", "approach,", "all", "the", "restrictions", "and", "linguistic", "properties", "of", "the", "rule", "are", "described", "(see", "the", "next", "paragraph", "for", "some", "examples).", "The", "qualitative", "description", "does", "not", "exhaust", "our", "intuition", "of", "productivity,", "there", "is", "also", "a", "quantitative", "element", "involved:", "intuitively", "one", "could", "say", "that", "some", "word", "formation", "rules", "seem", "to", "produce", "new", "words", "more", "readily", "than", "others", "-an", "intuition", "which", "cannot", "be", "formalized.", "In", "quantitative", "studies", "this", "intuition", "is", "approximated", "by", "the", "question:", "how", "probable", "is", "it", "that", "we", "will", "see", "a", "new", "type", "(lexeme)", "produced", "by", "word", "formation", "process", "X", "after", "we", "have", "sampled", "a", "certain", "amount", "of", "text?", "Quantitative", "studies", "of", "the", "productivity", "of", "word", "formation", "processes", "are", "important", "for", "the", "design", "of", "word", "formation", "systems", "if", "the", "resources", "are", "limited", "and", "one", "has", "to", "concentrate", "on", "the", "most", "productive", "word", "formation", "processes", "(on", "the", "quantitative", "aspects", "of", "productivity", "see", "for", "example", "Baayen 1992 Baayen , 2000,, Baayen &amp, Lieber 1991, Plag 1999,", "for", "a", "discussion", "of", "some", "corpus", "related", "problems", "in", "calculating", "productivity", "indices", "see", "Evert &amp, L\u00fcdeling 2001)."], "cited_papers": [{"title": "Measuring morphological productivity: Is automatic preprocessing sufficient?", "year": "2001", "authors": ["Stefan Evert", "Anke L\u00fcdeling"]}], "target_citation_location": 188, "citation_locations": [174, 188], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "b16a4fd4-1212-4adf-ade8-932d21f17d6f", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["In", "recent", "years,", "most", "work", "on", "annotating", "naturallanguage", "text", "with", "comprehensive,", "broad-coverage", "meaning", "representations", "has", "been", "performed", "in", "three", "frameworks:", "Abstract", "Meaning", "Representations", "(Banarescu et al., 2013),", "Universal", "Cognitive", "Conceptual", "Annotation", "(Abend and Rappoport, 2013),", "and", "Discourse", "Representation", "Structures", "(Abzianidze et al., 2017).", "Accurate", "parsers", "exist", "for", "all", "three", "(e.g.,", "Lindemann et al., 2020, Oepen et al., 2020, van Noord et al., 2020).", "Each", "formalism", "has", "its", "specific", "strength:", "AMRs", "go", "very", "far", "in", "abstracting", "away", "from", "surface", "variation", "in", "how", "a", "certain", "meaning", "is", "expressed,", "UCCA", "has", "a", "clear", "mapping", "between", "form", "and", "meaning", "and", "a", "modular", "architecture,", "and", "DRSs", "ground", "natural", "language", "meaning", "in", "first-order", "logic,", "by", "explicitly", "representing", "the", "scopes", "of", "negation,", "quantification,", "disjunction,", "etc.", "In", "this", "paper,", "we", "focus", "on", "parsing", "to", "DRSs."], "cited_papers": [{"title": "MRP 2020: The second shared task on crossframework and cross-lingual meaning representation parsing", "year": "2020", "authors": ["Stephan Oepen", "Omri Abend", "Lasha Abzianidze", "Johan Bos", "Jan Hajic", "Daniel Hershcovich", "Bin Li", "O' Tim", "Nianwen Gorman", "Daniel Xue", "unk Zeman"]}, {"title": "Fast semantic parsing with welltypedness guarantees", "year": "2020", "authors": ["Matthias Lindemann", "Jonas Groschwitz", "Alexander Koller"]}, {"title": "Character-level representations improve DRS-based semantic parsing even in the age of BERT", "year": "2020", "authors": ["Rik Van Noord", "Antonio Toral", "Johan Bos"]}], "target_citation_location": 41, "citation_locations": [23, 28, 33, 41], "citation_type": "group", "annotations": [[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b1735d05-c237-41f8-9eb3-508f52139625", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["The", "size", "of", "aligned", "corpora", "that", "we", "were", "able", "to", "use", "was", "limited", "by", "available", "memory.", "The", "memory", "footprint", "chiefly", "consists", "of", "the", "text", "and", "8", "bytes/word", "to", "hold", "a", "word", "position", "array,", "and", "the", "suffix", "array.", "It", "is", "possible", "that", "algorithms", "for", "external", "suffix", "array", "construction", "could", "be", "employed,", "such", "as", "the", "DC3", "algorithm", "by", "Dementiev et al. (2005)", "so", "that", "even", "larger", "corpora", "could", "be", "used."], "cited_papers": [{"title": "Better external memory suffix array construction", "year": "2005", "authors": ["R Dementiev", "J K\u00e4rkk\u00e4inen", "J Mehnert", "P Sanders"]}], "target_citation_location": 56, "citation_locations": [56], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "b1b2f3bc-c051-4479-ac08-e71afb2a51f5", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["4.", "For", "French,", "we", "use", "the", "French", "TimeBank", "as", "it", "is", "the", "ISO-TimeML", "annotated", "reference", "corpus", "for", "event", "annotation", "tasks", "(Bittar et al., 2011).", "The", "corpus", "consists", "of", "16,208", "tokens", "and", "2,100", "event", "mentions."], "cited_papers": [{"title": "French timebank: an isotimeml annotated reference corpus", "year": "2011", "authors": ["Andr\u00e9 Bittar", "Pascal Amsili", "Pascal Denis", "Laurence Danlos"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "b1b3220f-8356-4cc4-bb5f-f4afa49642e6", "citing_paper": {"title": "Entity Attribute Relation Extraction with Attribute-Aware Embeddings", "year": 2020, "authors": ["Dan Iter", "Xiao Yu", "Fangtao Li"]}, "text": ["(1)", "we", "compare", "extracted", "entity-attribute", "pairs", "to", "those", "extracted", "by", "the", "previous", "state-ofthe-art", "Biperpedia", "(Gupta et al., 2014)", "and", "(2)", "we", "report", "precision", "over", "a", "small", "set", "of", "longtail", "entityattribute", "pairs", "that", "did", "not", "appear", "in", "our", "distant", "supervision."], "cited_papers": [{"title": "Biperpedia: An ontology for search applications", "year": "2014", "authors": ["Rahul Gupta", "Alon Halevy", "Xuezhi Wang", "Steven Whang", "Fei Wu"]}], "target_citation_location": 14, "citation_locations": [14], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "b220a762-92a1-4f29-a552-27700c0d909d", "citing_paper": {"title": "Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model", "year": 2022, "authors": ["Richard Futrell"]}, "text": ["For", "each", "language,", "I", "use", "the", "fastText", "aligned", "word", "vectors", "(Bojanowski et al., 2017, Joulin et al., 2018),", "3", "limiting", "the", "vocabulary", "set", "V", "to", "the", "top", "200,000", "vectors", "by", "frequency.", "For", "the", "target", "word", "vocabulary", "W,", "I", "take", "the", "10,000", "most", "frequent", "wordforms", "among", "all", "attributive", "adjectives", "extracted", "from", "the", "entire", "CoNLL", "Wikipedia", "dataset."], "cited_papers": [{"title": "Enriching word vectors with subword information", "year": "2017", "authors": ["Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov"]}, {"title": "Loss in translation: Learning bilingual word mapping with a retrieval criterion", "year": "2018", "authors": ["Armand Joulin", "Piotr Bojanowski", "Tomas Mikolov", "Herv\u00e9 J\u00e9gou", "Edouard Grave"]}], "target_citation_location": 10, "citation_locations": [10], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "b2dfd029-eca8-4132-8c33-cea4cc085b8d", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["To", "alleviate", "this,", "past", "work", "proposed", "approximation", "methods", "for", "the", "computation", "of", "softmax(QK", ").", "One", "major", "line", "of", "research", "focused", "on", "sparse", "attention", "variants,", "where", "only", "a", "few", "similarity", "scores", "are", "computed", "per", "query,", "and", "the", "rest", "are", "ignored.", "Methods", "differ", "by", "which", "query-key", "pairs", "are", "selected", "(Child et al., 2019, Ye et al., 2019, Qiu et al., 2020, Roy et al., 2021, Kitaev et al., 2020, Beltagy et al., 2020, Gupta and Berant, 2020, Vyas et al., 2020).", "A", "second", "line", "of", "research", "explored", "dense", "variants", "(Katharopoulos et al., 2020, Wang et al., 2020, Bello, 2021, Tay et al., 2020a)", "(cf.", "(Tay et al., 2020b)", "for", "a", "survey).", "For", "example,", "instead", "of", "computing", "the", "attention", "scores", "exactly", "for", "only", "a", "small", "number", "of", "querykey", "pairs,", "(Choromanski et al., 2021)", "compute", "an", "approximation", "of", "scores", "for", "all", "pairs."], "cited_papers": [{"title": "Efficient transformers: A survey", "year": "2009", "authors": ["Yi Tay", "M Dehghani", "Dara Bahri", "Donald Metzler"]}], "target_citation_location": 58, "citation_locations": [47, 56, 58, 79], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "b2e8e9c6-9d9e-4a07-900c-7b5207f086aa", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["A", "related", "area", "of", "LCP", "is", "CWI.", "Early", "studies", "on", "CWI", "either", "attempt", "to", "simplify", "all", "words", "(Thomas and Anderson, 2012)", "or", "set", "a", "frequency-based", "threshold", "(Biran et al., 2011).", "Shardlow (2013)", "indicates", "that", "a", "classification-based", "method", "to", "CWI", "is", "the", "most", "promising", "one.", "Most", "of", "the", "teams", "participating", "in", "two", "CWI", "shared", "tasks", "also", "use", "classification", "approaches", "with", "extensive", "feature", "engineering."], "cited_papers": [{"title": "Wordnet-based lexical simplification of a document", "year": "2012", "authors": ["Rebecca Thomas", "Sven Anderson"]}], "target_citation_location": 17, "citation_locations": [17, 23, 24], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b30d1dc5-0f24-48be-aa2a-01b0939f0915", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["Neural", "methods", "for", "abstractive", "summarization", "(Rush et al., 2015, Nallapati et al., 2016, Chopra et al., 2016, Lewis et al., 2020, Zhang et al., 2020)", "formulate", "summarization", "as", "a", "sequenceto-sequence", "(Seq2Seq)", "problem", "(Sutskever et al., 2014),", "learning", "to", "generate", "the", "summary", "in", "an", "autoregressive", "manner.", "Such", "models", "are", "commonly", "trained", "with", "maximum", "likelihood", "estimation", "(MLE),", "maximizing", "predictive", "probability", "of", "the", "reference", "output", "given", "the", "gold", "sub-sequence", "before", "it.", "However,", "during", "inference", "the", "model", "must", "also", "generate", "the", "output", "based", "on", "possibly", "erroneous", "previous", "steps.", "This", "can", "hurt", "model", "performance,", "a", "phenomenon", "often", "called", "exposure", "bias", "(Bengio et al., 2015, Ranzato et al., 2016).", "To", "maintain", "reasonable", "performance", "even", "in", "the", "case", "of", "a", "sub-sequence", "with", "errors,", "we", "argue", "that", "the", "model", "must", "accurately", "estimate", "relative", "quality", "of", "different", "generated", "outputs,", "since", "effective", "inference", "requires", "comparison", "among", "these", "candidates."], "cited_papers": [{"title": "Sequence to sequence learning with neural networks", "year": "2014", "authors": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le"]}], "target_citation_location": 13, "citation_locations": [5, 13, 73], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b348bb17-8fe0-4f10-bcc1-20e2fedb48a9", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["To", "compare", "the", "linguistic", "annotation", "performance,", "we", "prepared", "a", "pipeline", "system,", "i.e.,", "ASR", "followed", "by", "an", "NLP-based", "linguistic", "annotation.", "In", "the", "pipeline", "system,", "the", "separated", "model", "of", "CTC+Transformer", "first", "predicts", "graphemic", "sequences.", "Then,", "the", "linear", "SVM", "with", "L2", "normalization,", "trained", "using", "KyTea", "(Graham and Mori, 2010),", "predicts", "word", "boundaries", "and", "linguistic", "annotation", "from", "the", "predicted", "sequences.", "To", "train", "KyTea,", "we", "only", "used", "the", "transcriptions", "in", "the", "ASR", "training", "set", "to", "perform", "a", "fair", "comparison", "to", "the", "proposed", "method."], "cited_papers": [{"title": "Word-based partial annotation for efficient corpus construction", "year": "2010", "authors": ["N Graham", "S Mori"]}], "target_citation_location": 42, "citation_locations": [42], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "b353dc34-50ed-47f7-b567-1ab0993d2690", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["A", "key", "hypothesis", "in", "the", "pursuit", "towards", "creating", "goal-driven", "natural", "language-based", "agents", "posits", "that", "interactivity", "and", "environment", "grounding", "is", "critical", "for", "effective", "language", "learning", "(Barsalou, 2008, Bisk et al., 2020, Ammanabrolu and Riedl, 2021).", "Text", "games", "provide", "a", "platform", "on", "which", "to", "interactively", "train", "agents", "that", "can", "both", "act", "and", "speak", "in", "a", "situated", "manner-producing", "language", "that", "is", "both", "goal-driven", "and", "contextually", "relevant."], "cited_papers": [{"title": "Situated language learning via interactive narratives", "year": "2021", "authors": ["Prithviraj Ammanabrolu", "unk Mark O Riedl"]}, {"title": "Grounded cognition. Annual Review of Psychology", "year": "2008", "authors": ["Lawrence Barsalou"]}, {"title": "Experience grounds language", "year": "2020", "authors": ["Yonatan Bisk", "Ari Holtzman", "Jesse Thomason", "Jacob Andreas", "Yoshua Bengio", "Joyce Chai", "Mirella Lapata", "Angeliki Lazaridou", "Jonathan May", "Aleksandr Nisnevich", "Nicolas Pinto", "Joseph Turian"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "b372ef82-423a-4982-8816-d96d16e33be5", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["PLMs", "such", "as", "BERT", "(Bidirectional", "Encoder", "Representations", "from", "Transformers)", "use", "the", "encoder", "structure", "of", "the", "Transformer", "(Vaswani et al., 2017)", "for", "deep", "self-supervised", "learning,", "which", "requires", "task-specific", "fine-tuning.", "In", "this", "paper,", "the", "downstream", "task", "to", "predict", "the", "complexity", "scores,", "a", "real-value", "in", "the", "range", "of", "[0,1],", "of", "given", "words."], "cited_papers": [{"title": "Attention is all you need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b3777c20-bb10-45b1-aeac-3c6673d578ff", "citing_paper": {"title": "Effects of Word Alignment Visualization on Post-Editing Quality & Speed \u2020", "year": 2015, "authors": ["Lane Schwartz", "Isabel Lacruz", "Tatyana Bystrova"]}, "text": ["We", "hypothesize", "that", "any", "effects", "of", "word", "alignment", "visualization", "on", "post-editing", "may", "be", "dependent", "on", "the", "quality", "of", "the", "underlying", "machine", "translations", "displayed", "to", "the", "post-editors.", "Because", "we", "care", "about", "the", "adequacy", "of", "post-edited", "translations,", "we", "consider", "actual", "human", "judgements", "to", "be", "preferable", "to", "automated", "metrics", "such", "as", "BLEU", "(Papineni et al., 2002),", "which", "at", "best", "serve", "as", "a", "flawed", "proxy", "for", "human", "judgements.", "Instead,", "following", "Albrecht et al. (2009)", "and", "Schwartz et al. (2014),", "we", "therefore", "obtained", "human", "judgements", "of", "translation", "adequacy", "for", "the", "Russian-English", "and", "Spanish-English", "machine", "translations", "used", "in", "this", "study."], "cited_papers": [{"title": "Machine translation and monolingual postediting: The AFRL WMT-14 system", "year": "2014", "authors": ["L Schwartz", "T Anderson", "J Gwinnup", "K Young"]}], "target_citation_location": 65, "citation_locations": [49, 63, 65], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "b3d7f686-942b-466f-b815-d6b745522af0", "citing_paper": {"title": "Effects of Word Alignment Visualization on Post-Editing Quality & Speed \u2020", "year": 2015, "authors": ["Lane Schwartz", "Isabel Lacruz", "Tatyana Bystrova"]}, "text": ["Our", "post-editing", "interface", "can", "be", "seen", "in", "Figure", "1", "above.", "Each", "text", "was", "presented", "to", "posteditors", "in", "one", "of", "two", "variant", "modalities", "-word-level", "alignment", "links", "could", "either", "be", "visualized", "or", "left", "absent.", "In", "both", "variants,", "each", "source", "language", "segment", "was", "presented", "along", "with", "the", "corresponding", "machine", "translated", "English", "segment,", "a", "text", "field", "(initially", "populated", "with", "the", "machine", "translated", "segment)", "where", "the", "post-editor", "could", "make", "changes", "was", "also", "presented.", "In", "the", "first", "variant,", "the", "word-level", "alignment", "links", "produced", "by", "the", "machine", "translation", "decoder", "(Moses", "for", "Russian-English,", "Bing", "Translator", "for", "Spanish-English)", "were", "graphically", "displayed,", "linking", "source", "words", "to", "their", "corresponding", "machine", "translated", "target", "words.", "In", "the", "second", "variant,", "the", "word-level", "alignment", "links", "were", "omitted", "from", "the", "visualization", "interface.", "Figure", "2:", "Percentage", "of", "segments", "judged", "to", "be", "in", "each", "adequacy", "category.", "For", "each", "language", "pair,", "we", "report", "percentages", "for", "raw", "(unedited)", "machine", "translation", "output,", "as", "well", "as", "output", "postedited", "by", "a", "bilingual", "post-editor", "with", "access", "to", "alignments", "and", "without", "access", "to", "alignments.", "For", "Russian-English,", "we", "additionally", "report", "percentages", "for", "output", "post-edited", "by", "a", "monolingual", "post-editor", "(Schwartz et al., 2014)", "with", "access", "to", "alignments."], "cited_papers": [{"title": "Machine translation and monolingual postediting: The AFRL WMT-14 system", "year": "2014", "authors": ["L Schwartz", "T Anderson", "J Gwinnup", "K Young"]}], "target_citation_location": 172, "citation_locations": [172], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "b3e36325-b8e2-4391-b4dd-9373ff72e989", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["A", "research", "of", "already", "available", "and", "accessible", "language", "processing", "tools", "and", "materials,", "mostly", "corpora,", "revealed", "that", "there", "is", "a", "reasonably", "big", "amount", "of", "work", "already", "done", "for", "Slovenian", "language,", "less", "for", "Serbian.", "The", "tools", "for", "Slovenian", "language", "are", "(reasonable", "or", "even", "good", "quality):", "part", "of", "speech", "tagger", "(Erjavec, 2006)", "and", "(Brants, 2000),", "lemmatizer", "(Erjavec, 2006)", "and", "(Erjavec et al., 2004),", "stemmer", "(Popovi\u010d et al., 1992)", "and", "(Vilar et al., 2000),", "none", "of", "these", "tools", "exists", "for", "Serbian", "language.", "Both", "languages", "have", "solid", "monolingual", "reference", "corpora", "(going", "into", "hundreds", "of", "millions)", "and", "a", "small", "bilingual", "corpus", "(Erjavec, 2004)", "that", "was", "used", "mostly", "for", "evaluation", "purposes."], "cited_papers": [{"title": "Multilingual tokenisation, tagging, and lemmatisation with totale", "year": "2006", "authors": ["Erjavec Toma\u017e"]}], "target_citation_location": 47, "citation_locations": [47, 49, 51, 53, 55, 57, 83], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b425d550-0f15-4c6f-9f23-912efd02edef", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["As", "Kumar et al. (2021)", "showed,", "they", "might", "associate", "words", "that", "are", "not", "in", "a", "strong", "direct", "connection,", "but", "are", "only", "indirectly", "related", "(e.g.", "religion", "is", "not", "related", "to", "tree,", "but", "both", "are", "related", "to", "Christmas,", "therefore", "religion", "could", "be", "a", "clue", "for", "tree)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 1, "citation_locations": [1], "citation_type": "single", "annotations": [[2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "b4bc1895-8c4a-4fe3-9524-4db80703127e", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["A", "standard", "and", "probably", "the", "most", "common", "method", "to", "calculate", "word", "relatedness", "from", "co-occurrences", "is", "computing", "the", "pointwise", "mutual", "information", "(PMI)", "of", "two", "words.", "However,", "PMI", "has", "wellknown", "shortcomings,", "such", "as", "overvaluing", "the", "relatedness", "of", "rare", "words,", "and", "lacking", "a", "fixed", "upper", "and", "lower", "bound.", "Bouma (2009)", "introduced", "normalized", "PMI", "as", "PMI", "norm", "(x,", "y)", "=", "ln", "p(x,", "y)", "p(x)p(y)", "\u2212", "ln", "p(x,", "y),"], "cited_papers": [{"title": "Normalized (pointwise) mutual information in collocation extraction", "year": "2009", "authors": ["Gerlof Bouma"]}], "target_citation_location": 45, "citation_locations": [45], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "b4f389d3-a040-4f44-a144-b0a6fe8eca0b", "citing_paper": {"title": "Controlled Text Generation with Adversarial Learning", "year": 2020, "authors": ["Federico Betti", "Giorgia Ramponi", "Massimo Piccardi"]}, "text": ["As", "training", "loss,", "we", "have", "used", "a", "non-saturating", "GAN", "loss", "function", "[7],", "that,", "considering", "the", "doublediscriminator", "model,", "is", "extended", "as:lD", "=", "1", "m", "m", "X", "i=1", "\uf8ff\u2713", "log(D", "S", "(xr))", "+", "log(1", "D", "S", "(G(xz)))", "\u25c6", "+", "\u2713", "log(D", "T", "(xr))", "+", "log(1", "D", "T", "(G(xz)))\u25c6", "1", "All", "the", "training", "information", "and", "hyperparameters", "are", "described", "in", "Appendix", "D.", "We", "will", "release", "all", "our", "code", "publicly", "after", "the", "anonymity", "period.", "1:", "CTERM-GAN", "architecture", "lG", "=", "1", "m", "m", "X", "i=1", "\uf8ff", "log(D", "S", "(G(xz)))", "log(D", "T", "(G(xz)))where", "is", "a", "hyperparameter", "that", "assigns", "a", "relative", "weight", "to", "the", "topic", "discriminator", "with", "respect", "to", "the", "syntax", "one.", "plays", "an", "important", "role", "during", "training", "since,", "if", "it", "is", "too", "low,", "the", "model", "ignores", "the", "conditioning", "due", "to", "the", "limited", "penalty.", "Conversely,", "a", "too", "high", "a", "value", "would", "give", "too", "much", "importance", "to", "the", "conditioning,", "affecting", "the", "quality", "of", "the", "generated", "sentence."], "cited_papers": [{"title": null, "year": "2014", "authors": ["J Ian", "Jean Goodfellow", "Mehdi Pouget-Abadie", "Bing Mirza", "David Xu", "Sherjil Warde-Farley", "Aaron Ozair", "Yoshua Courville", "unk Bengio"]}], "target_citation_location": 11, "citation_locations": [11], "citation_type": "single", "annotations": [[0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b50958fb-9a20-46df-be27-be559c09d624", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["(a)", "the", "back", "vowels", "a,", "u,", "o", "and", "the", "diphthong", "au,", "can", "be", "fronted", "(umlauted)"], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 14, "citation_locations": [14], "citation_type": "single", "annotations": [[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "b5111a90-2ebd-40b5-9ecb-ae25ba19ae1e", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["Langage", "identification", "(langid)", "(Lui and Baldwin, 2012", "):", "We", "use", "fastText", "5", "for", "language", "identification", "filtering,", "which", "removes", "sentence", "pairs", "that", "are", "not", "predicted", "as", "the", "correct", "language", "on", "either", "side."], "cited_papers": [{"title": "langid. py: An off-the-shelf language identification tool", "year": "2012", "authors": ["Marco Lui", "Timothy Baldwin"]}], "target_citation_location": 3, "citation_locations": [3], "citation_type": "single", "annotations": [[0, 0, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "b5b01830-7534-4f4c-8dcb-5abfa3f4ce0e", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Figure", "7", "shows", "the", "overall", "architecture", "and", "training", "pipeline-our", "reinforcement", "learning", "pipeline", "is", "unchanged", "from", "that", "shown", "in", "Ammanabrolu et al. (2021)", "with", "the", "exception", "of", "the", "curriculum", "of", "quests", "performed", "by", "the", "agent", "and", "the", "way", "the", "speech", "rewards", "are", "designed.", "An", "encoder", "first", "takes", "in", "information", "about", "setting,", "persona,", "motivation", "for", "a", "single", "character", "then", "passes", "it", "onto", "a", "switch", "module.", "This", "switch", "module", "is", "a", "meta", "policy", "that", "decides", "if", "an", "agent", "should", "act", "or", "talk", "and", "is", "trained", "to", "mimic", "how", "often", "human", "experts", "act", "or", "talk", "while", "performing", "quests", "via", "demonstrations.", "Two", "separate", "policy", "networks", "make", "a", "decision", "on", "which", "action", "to", "perform", "or", "dialogue", "to", "say", "given", "the", "current", "context", "and", "a", "single", "shared", "critic", "attempts", "to", "measure", "the", "value", "of", "taking", "an", "action", "in", "a", "particular", "state."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 18, "citation_locations": [18], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b5cc6dca-1880-42c1-8c46-5a843dcf6e50", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["Our", "model", "f", "\u03b8", "to", "produce", "these", "embeddings", "is", "shown", "in", "Figure", "2:", "it", "takes", "as", "input", "the", "mention", "m", "and", "its", "context", "s", "and", "predicts", "probabilities", "for", "predefined", "entity", "types", "T.", "This", "is", "a", "Transformer-based", "typing", "model", "following", "the", "BERT", "model", "presented", "in", "Onoe and Durrett (2019).", "First,", "a", "Transformerbased", "encoder", "(Vaswani et al., 2017)", "maps", "the", "input", "variables,", "m", "and", "s,", "to", "an", "intermediate", "vector", "repre-sentation.", "A", "type", "embedding", "layer", "then", "projects", "the", "intermediate", "representation", "to", "a", "vector", "whose", "dimensions", "correspond", "to", "the", "entity", "types", "T.", "Finally,", "we", "apply", "a", "sigmoid", "function", "on", "each", "real-valued", "score", "in", "the", "vector", "to", "obtain", "the", "posterior", "probabilities", "that", "form", "our", "entity", "representation", "t", "(top", "of", "the", "figure)."], "cited_papers": [{"title": "Attention is All you Need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "Lukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 49, "citation_locations": [44, 49], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b60da26a-b940-43df-87a4-20271e6e9eb4", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["Regarding", "the", "conversion", "process", "of", "text", "and", "audio", "data,", "we", "leverage", "recent", "advances", "to", "transliterate", "this", "data", "into", "corresponding", "sounds", "represented", "by", "IPA", "phonetic", "symbols.", "This", "transliteration", "is", "possible", "for", "speech/audio", "data", "using", "tools", "such", "as", "the", "Allosaurus", "universal", "phone", "recognizer,", "which", "can", "be", "applied", "without", "additional", "training", "to", "any", "language", "(Li et al., 2020),", "though", "it", "can", "benefit", "from", "fine-tuning", "(Siminyu et al., 2021).", "To", "convert", "text", "data", "to", "phonemes", "we", "can", "use", "tools", "such", "as", "the", "Epitran", "grapheme-to-phoneme", "converter", "(Mortensen et al., 2018),", "which", "is", "specifically", "designed", "to", "provide", "precise", "phonetic", "transliterations", "in", "low-resource", "scenarios."], "cited_papers": [{"title": "Phoneme recognition through fine tuning of phonetic representations: a case study on luhya language varieties", "year": "2021", "authors": ["Kathleen Siminyu", "Xinjian Li", "Antonios Anastasopoulos", "David Mortensen", "Michael Marlo", "Graham Neubig"]}], "target_citation_location": 58, "citation_locations": [51, 58, 75], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b6545c9b-d530-49cf-8599-1b0dfb8abba8", "citing_paper": {"title": "NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques", "year": 2021, "authors": ["Gunjan Chhablani", "Abheesht Sharma", "Harshit Pandey", "Yash Bhartia", "Shan Suthaharan"]}, "text": ["Before", "the", "advent", "in", "research", "pertaining", "to", "toxic", "texts,", "Warner and Hirschberg (2012)", "modeled", "hate", "speech", "as", "a", "word", "sense", "disambiguation", "problem", "where", "SVM", "was", "used", "for", "classification", "of", "data.", "Mehdad and Tetreault (2016)", "used", "RNN", "Language", "Model", "with", "character", "and", "token", "based", "methods", "to", "classify", "the", "text.", "Recently,", "however,", "toxic", "text", "detection", "has", "garnered", "a", "lot", "of", "attention", "(Nobata et al., 2016, Park and Fung, 2017, Pavlopoulos et al., 2017, Wulczyn et al., 2017).", "The", "increase", "in", "offensive", "language", "research", "can", "partly", "be", "credited", "to", "various", "workshops", "such", "as", "Abusive", "Language", "Online", "1", "(Waseem et al., 2017),", "as", "well", "as", "other", "fora,", "such", "as", "GermEval", "for", "German", "texts,", "2", "or", "TRAC", "(Kumar et al., 2018)", "and", "Kaggle", "challenges", "3."], "cited_papers": [{"title": "Detecting hate speech on the world wide web", "year": "2012", "authors": ["William Warner", "Julia Hirschberg"]}], "target_citation_location": 9, "citation_locations": [9, 27, 53, 73, 88], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b65c467e-f045-48ec-abb9-7655f2d95d28", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["We", "participate", "in", "the", "Chinese-English", "streaming", "transcription", "track,", "where", "each", "sentence", "is", "broken", "into", "lines", "whose", "length", "is", "incremented", "by", "one", "word", "until", "the", "sentence", "is", "completed.", "An", "example", "is", "shown", "in", "Table", "1.", "For", "pre-training,", "we", "use", "the", "CWMT21", "parallel", "corpus", "(9.1M)", "2,", "and", "we", "fine-tune", "the", "pretrained", "model", "using", "transcription", "and", "translation", "of", "the", "BSTC", "(Baidu", "Speech", "Translation", "Corpus,37K)", "(Zhang et al., 2021),", "shown", "in", "Table", "2.", "We", "also", "use", "CWMT's", "10M", "Chinese", "monolingual", "data", "for", "synthetic", "data", "generation."], "cited_papers": [{"title": null, "year": "2021", "authors": ["Ruiqing Zhang", "Xiyang Wang", "Chuanqiang Zhang", "Zhongjun He", "Hua Wu", "Zhi Li", "Haifeng Wang", "Ying Chen", "Qinfei Li"]}], "target_citation_location": 61, "citation_locations": [61], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b6a61170-ede6-47ae-aab9-c5fc9cd9b1c5", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["DeepBlueAI.", "The", "model", "presented", "by", "Pan et al. (2021)", "represents", "the", "top-performing", "system", "in", "this", "edition", "of", "the", "shared", "task", "with", "a", "NDCG", "score", "of", "0.820", "-representing", "a", "substantial", "32%", "improvement", "when", "compared", "to", "the", "tf.idf", "baseline.", "The", "model", "employs", "a", "two", "step", "retrieval", "strategy.", "In", "the", "first", "step,", "a", "pre-trained", "language", "model", "is", "finetuned", "to", "retrieve", "the", "top-K", "(K", "&gt,", "100)", "relevant", "facts", "for", "each", "question", "and", "answer", "pair.", "Subsequently,", "the", "same", "architecture", "is", "adopted", "to", "build", "a", "re-ranking", "model", "to", "refine", "the", "list", "of", "the", "top-K", "candidate", "facts.", "The", "authors", "propose", "the", "use", "of", "a", "triplet", "loss", "for", "the", "fine-tuning", "of", "the", "model.", "Specifically,", "the", "triplet", "loss", "minimizes", "the", "distance", "between", "an", "anchor", "and", "a", "positive", "example,", "while", "maximizing", "the", "distance", "between", "the", "same", "anchor", "and", "a", "negative", "example.", "The", "team", "treats", "question", "and", "correct", "answer", "as", "the", "anchor,", "while", "the", "facts", "annotated", "with", "high", "ratings", "are", "adopted", "as", "positive", "examples.", "Different", "experiments", "are", "conducted", "with", "three", "negative", "sampling", "strategies", "for", "retrieval", "and", "re-ranking.", "The", "best", "results", "are", "obtained", "when", "sampling", "negative", "examples", "from", "the", "same", "tables", "of", "highly", "relevant", "facts.", "The", "authors", "find", "that", "the", "best", "performance", "is", "obtained", "when", "averaging", "the", "results", "from", "RoBERTa", "(Liu et al., 2019)", "facts", "to", "the", "question", "using", "BM25", "vectors", "and", "then", "update", "the", "query", "vector", "via", "a", "max", "operation.", "The", "iterative", "retrieval", "step", "is", "performed", "until", "a", "list", "of", "K", "=", "200", "facts", "is", "selected", "from", "the", "knowledge", "base.", "Subsequently,", "the", "top", "K", "explanation", "facts", "are", "re-ranked", "using", "language", "models.", "The", "best", "model", "consists", "of", "an", "ensemble", "of", "BERT", "(Devlin et al., 2019)", "and", "SciBERT", "(Beltagy et al., 2019).", "These", "models", "are", "fine-tuned", "to", "predict", "the", "target", "explanatory", "relevance", "ratings", "using", "the", "following", "input:", "Question", "+", "Answer", "[SEP]", "Explanation.", "Specifically,", "the", "authors", "frame", "the", "problem", "as", "a", "regression", "via", "mean", "squared", "error", "loss.", "The", "ensemble", "is", "achieved", "by", "linearly", "combining", "the", "scores", "of", "the", "models.", "The", "authors", "reported", "two", "negative", "results", "obtained", "using", "a", "two-stage", "approach", "and", "different", "negative", "sampling", "techniques.", "In", "the", "two-stage", "approach,", "the", "facts", "were", "firstly", "categorized", "using", "binary", "scores", "to", "discriminate", "between", "relevant", "and", "irrelevant", "sentences,", "and", "then", "re-ranked", "predicting", "the", "target", "explanatory", "relevance", "rating.", "Regarding", "the", "negative", "sampling", "strategy,", "the", "authors", "noticed", "that", "highest", "percentage", "of", "errors", "occurring", "at", "inference", "time", "was", "due", "to", "irrelevant", "facts", "that", "are", "lexically", "close", "to", "highly", "relevant", "explanation", "sentences.", "They", "attempted", "to", "alleviate", "this", "problem", "by", "randomly", "sampling", "facts", "from", "the", "knowledge", "base", "and", "retrieving", "close", "negative", "examples", "during", "training.", "Neither", "of", "these", "two", "methods", "resulted", "in", "significant", "improvements."], "cited_papers": [{"title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 253, "citation_locations": [5, 195, 253, 256], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b6c316e4-db7e-437e-af12-a6d506555b79", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["If", "we", "fine-tune", "a", "RoBERTa-large", "model", "on", "Quoref,", "it", "achieves", "78", "F1", "score", "while", "the", "estimated", "human", "performance", "is", "around", "93", "F1", "score", "(Dasigi et al., 2019).", "This", "high", "performance,", "given", "that", "RoBERTa", "can", "only", "predict", "continuous", "span", "answers", "while", "Quoref", "also", "contains", "discontinuous", "answers,", "indicates", "that", "either", "(1)", "Quoref", "presents", "coreference-aware", "QA", "very", "well", "so", "that", "the", "model", "can", "properly", "learn", "coreference", "reasoning", "from", "the", "training", "data,", "(2)", "pretrained", "transformer-based", "models", "have", "already", "learned", "coreference", "reasoning", "during", "their", "pre-training,", "e.g.,", "as", "suggested", "by", "Tenney et al. (2019)", "and", "Clark et al. (2019b),", "or", "(3)", "coreference", "reasoning", "is", "not", "necessarily", "required", "for", "solving", "most", "examples."], "cited_papers": [{"title": "BERT rediscovers the classical NLP pipeline", "year": "2019", "authors": ["Ian Tenney", "Dipanjan Das", "Ellie Pavlick"]}], "target_citation_location": 81, "citation_locations": [23, 81, 83], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "b721d2d7-6e0b-4a57-b09a-02dc444bd6ba", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["In", "the", "second", "approach,", "they", "first", "recognize", "examples", "that", "contain", "artifacts,", "and", "use", "this", "knowledge", "in", "the", "training", "objective", "to", "either", "skip", "or", "downweight", "biased", "examples", "(He et al., 2019, Clark et al., 2019a),", "or", "to", "regularize", "the", "confidence", "of", "the", "model", "on", "those", "examples", "(Utama et al., 2020a).", "The", "use", "of", "this", "information", "in", "the", "training", "objective", "improves", "the", "robustness", "of", "the", "model", "on", "adversarial", "datasets", "(He et al., 2019, Clark et al., 2019a, Utama et al., 2020a),", "i.e.,", "datasets", "that", "contain", "counterexamples", "in", "which", "relying", "on", "the", "bias", "results", "in", "an", "incorrect", "prediction.", "In", "addition,", "it", "can", "also", "improve", "in-domain", "performances", "as", "well", "as", "generalization", "across", "various", "datasets", "that", "represent", "the", "same", "task", "(Wu et al., 2020a, Utama et al., 2020b)."], "cited_papers": [{"title": "Unlearn dataset bias in natural language inference by fitting the residual", "year": "2019", "authors": ["He He", "Sheng Zha", "Haohan Wang"]}, {"title": "Don't take the easy way out: Ensemble based methods for avoiding known dataset biases", "year": "2019", "authors": ["Christopher Clark", "Mark Yatskar", "Luke Zettlemoyer"]}], "target_citation_location": 26, "citation_locations": [26, 38, 57, 94], "citation_type": "group", "annotations": [[2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b77e55d0-fd13-44f7-b6e5-d6cf34131cfa", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["For", "the", "definition", "generation", "dataset,", "we", "use", "the", "Chinese", "WordNet", "(CWN)", "(Huang et al., 2010),", "which", "is", "a", "semantic", "lexicon", "aiming", "to", "provide", "a", "knowledge", "base", "of", "sense", "distinction.", "2", "We", "use", "the", "corresponding", "words,", "contexts,", "and", "definitions", "in", "CWN", "for", "the", "definition", "generation", "task.", "We", "split", "the", "entire", "dataset", "into", "training,", "validation,", "and", "test", "sets", "roughly", "according", "to", "the", "ratio", "of", "8:1:1.", "For", "the", "simple", "text", "corpus,", "we", "extract", "58,867", "sentences", "from", "a", "number", "of", "primary", "level", "Chinese", "as", "Second", "Language", "textbooks,", "with", "an", "average", "sentence", "length", "of", "14.62."], "cited_papers": [{"title": "Chinese wordnet : design, implementation, and application of an infrastructure for cross-lingual knowledge processing", "year": "2010", "authors": ["Chu-Ren Huang", "S Hsieh", "Jia-Fei Hong", "Yun-Zhu Chen", "I Su", "Yong-Xiang Chen", "Sheng-Wei Huang"]}], "target_citation_location": 11, "citation_locations": [11], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b78925ff-d230-4202-b0c7-af12ed88c44a", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["Reversely,", "back-translation", "(Sennrich et al., 2015, Edunov et al., 2018)", "first", "trains", "a", "target-tosource", "model,", "which", "then", "utilizes", "target-side", "monolingual", "data", "to", "synthesis", "a", "pseudo-parallel", "corpus.", "We", "randomly", "select", "2M", "English", "sentences", "from", "the", "CWMT", "parallel", "corpus", "for", "back-translation."], "cited_papers": [{"title": "Improving neural machine translation models with monolingual data", "year": "2015", "authors": ["Rico Sennrich", "Barry Haddow", "Alexandra Birch"]}, {"title": "Understanding back-translation at scale", "year": "2018", "authors": ["Sergey Edunov", "Myle Ott", "Michael Auli", "David Grangier"]}], "target_citation_location": 2, "citation_locations": [2], "citation_type": "group", "annotations": [[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "b7ae5b3a-1aba-4acd-a36b-aa2e34afb1e7", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["A", "few", "researchers", "have", "started", "to", "exploit", "suffix", "arrays", "in", "phrase-based", "SMT", "systems.", "Callison-Burch et al. (2005)", "have", "shown", "how", "parallel", "suffix", "arrays", "can", "be", "used", "to", "efficiently", "compute", "phrase", "translations", "and", "significantly", "reduce", "the", "large", "memory", "footprints", "that", "phrased-based", "SMT", "systems", "suffer", "from", "when", "attempting", "to", "use", "longer", "(i.e.,", "n&gt,3)", "phrases.", "Zhang and Vogel (2005)", "describe", "a", "dynamic", "programming", "algorithm", "that", "more", "efficiently", "retrieves", "alignments", "for", "a", "set", "of", "phrases", "(such", "as", "all", "substrings", "from", "a", "sentence", "that", "is", "to", "be", "translated),", "which", "outperforms", "direct", "comparison", "binary", "search", "by", "a", "couple", "of", "orders", "of", "magnitude.", "Their", "improvement", "allows", "them", "to", "compute", "phrase", "alignments", "online."], "cited_papers": [{"title": "An Efficient Phrase-to-Phrase Alignment Model for Arbitrarily Long Phrases and Large Corpora", "year": "2005", "authors": ["Y Zhang", "S Vogel"]}], "target_citation_location": 49, "citation_locations": [13, 49], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "b7caed4e-eb9f-4df7-9a08-1c88f319a14b", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["Mitigation", "Multiple", "approaches", "have", "been", "proposed", "to", "mitigate", "shortcut", "learning", "and", "data", "biases", "(Clark et al., 2020, Bras et al., 2020, Zhou and Bansal, 2020, Minderer et al., 2020),", "through", "data", "augmentation", "(Jin et al., 2020, Alzantot et al., 2018),", "domain", "adaptation", "(Blitzer et al., 2006 (Blitzer et al., , 2007)),", "and", "multi-task", "learning", "(Tu et al., 2020).", "Du et al. (2021)", "proposes", "to", "mitigate", "shortcuts", "by", "suppressing", "model's", "prediction", "on", "examples", "with", "a", "large", "shortcut", "degree.", "Recent", "study", "has", "also", "shown", "removing", "spurious", "correlations", "can", "sometimes", "hurt", "model's", "accuracy", "(Khani and Liang, 2021).", "Orthogonal", "to", "existing", "works,", "we", "propose", "to", "first", "identify", "unrobust", "correlations", "in", "an", "NLP", "model", "and", "then", "propose", "a", "targeted", "mitigation", "to", "encourage", "the", "model", "to", "rely", "less", "on", "those", "unrobust", "correlations."], "cited_papers": [{"title": "Towards interpreting and mitigating shortcut learning behavior of NLU models", "year": "2021", "authors": ["Mengnan Du", "Varun Manjunatha", "Rajiv Jain", "Ruchi Deshpande", "Franck Dernoncourt", "Jiuxiang Gu", "Tong Sun", "Xia Hu"]}], "target_citation_location": 25, "citation_locations": [13, 17, 20, 24, 25, 54], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b7d8309f-dfa6-48ad-8f0a-778d96f366d1", "citing_paper": {"title": "SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering", "year": 2020, "authors": ["Aishwarya Ashok", "Ganapathy Natarajan", "Ramez Elmasri", "Laurel Smith-Stvan"]}, "text": ["At", "the", "answer", "level", "the", "top", "candidate", "sentences", "(up", "to", "10)", "returned", "by", "our", "system", "were", "compared", "against", "the", "review", "snippets", "as", "the", "gold", "standard.", "The", "review", "snippets", "were", "top", "review", "sentences", "returned", "by", "the", "system", "used", "by", "Gupta et al. (2019)", "(Gupta et al., 2019)", "Average", "ROUGE", "scores", "are", "reported", "in", "Table", "2.", "Both", "systems", "aim", "at", "providing", "the", "best", "candidate", "sentences.", "Looking", "at", "the", "precision", "scores,", "it", "is", "clear", "that", "our", "system", "performance", "is", "good", "in", "terms", "of", "returning", "relevant", "sentences,", "similar", "in", "content", "to", "the", "gold", "standard.", "The", "sim", "method", "still", "is", "the", "best", "performing", "method.", "We", "say", "this", "because,", "ROUGE-L", "looks", "for", "the", "longest", "common", "sub", "se-", "Looking", "at", "the", "similarity", "scores,", "it", "is", "clear", "that", "the", "candidate", "sentences", "returned", "by", "our", "system", "is", "almost", "exactly", "similar", "to", "the", "sentences", "returned", "by", "Gupta et al. (2019).", "Once", "again", "our", "system", "is", "able", "to", "perform", "on", "par", "with", "a", "more", "complicated", "system."], "cited_papers": [{"title": "Amazonqa: A review-based question answering task", "year": "2019", "authors": ["Mansi Gupta", "Nitish Kulkarni", "Raghuveer Chanda", "Anirudha Rayasam", "Zachary Lipton"]}], "target_citation_location": 38, "citation_locations": [38, 39, 130], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b7eb080b-d509-4326-ace7-987f8781d2d2", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["SARI", "SARI", "(Xu et al., 2016)", "is", "a", "lexical", "simplicity", "metric", "that", "measures", "how", "good", "are", "the", "words", "added,", "deleted", "and", "kept", "by", "a", "simplification", "model.", "This", "metric", "compares", "the", "model", "output", "to", "simplification", "references", "and", "the", "original", "sentence.", "We", "use", "the", "SARI", "implementation", "in", "the", "EASSE", "toolkit", "4."], "cited_papers": [{"title": "Optimizing statistical machine translation for text simplification", "year": "2016", "authors": ["Wei Xu", "Courtney Napoles", "Ellie Pavlick", "Quanze Chen", "Chris Callison-Burch"]}], "target_citation_location": 2, "citation_locations": [2], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "b7f0ab56-bd49-42fe-8d31-641ff7927a2c", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["We", "now", "describe", "this", "step", "using", "sentiment", "classification", "task", "as", "an", "example", "(more", "details", "can", "be", "found", "in", "Algorithm", "1).", "Let", "f", "be", "a", "well", "trained", "sentiment", "classification", "model.", "Given", "a", "corpus", "D,", "for", "each", "input", "sentence", "s", "i,", "i", "=", "1,...,", "n", "for", "a", "total", "of", "n", "sentences", "in", "the", "corpus,", "we", "apply", "f", "on", "it", "to", "obtain", "the", "output", "probability", "p", "pos", "i", "and", "p", "neg", "i", "for", "positive", "and", "negative", "label", "respectively.", "We", "then", "extract", "attention", "scores", "{a", "1", "i,", "a", "2", "i", ",...,", "a", "m", "i}", "for", "tokens", "{t", "1", "i,", "t", "2", "i", ",...,", "t", "m", "i}", "in", "sentence", "s", "i,", "where", "m", "is", "the", "length", "of", "the", "sentence.", "In", "BERT-based", "classification", "models,", "the", "embedding", "of", "[CLS]", "token", "in", "the", "final", "layer", "is", "fed", "to", "a", "classification", "layer.", "We", "thus", "extract", "the", "attention", "scores", "of", "each", "token", "t", "used", "for", "computing", "the", "embedding", "of", "the", "[CLS]", "token", "and", "average", "them", "across", "different", "heads.", "If", "p", "pos", "i", "&gt,", "p", "neg", "i,", "we", "obtain", "the", "updated", "attention", "score", "\u00e3j", "i", "=", "a", "j", "i", "*", "p", "pos", "i,", "otherwise\u00e3j", "i", "=", "\u2212a", "j", "i", "*", "p", "neg", "i", ".For", "each", "token", "t", "in", "the", "vocabulary", "V,", "we", "compute", "the", "average", "attention", "score:\u0101t", "=", "1", "mn", "\u03a3", "n", "i=1", "\u03a3", "m", "j=1", "[\u00e3", "j", "i", "1(t", "j", "i", "=", "t)],where", "we", "aggregate", "the", "attention", "scores", "\u00e3j", "i", "for", "token", "t,", "across", "all", "n", "sentences", "in", "the", "corpus.", "We", "then", "normalize", "the", "attention", "scores", "across", "the", "vocabulary", "to", "obtain", "the", "importance", "score", "for", "each", "token", "t:", "I", "t", "=", "\u0101t", "/\u03a3", "t\u2208V", "\u0101t.", "This", "can", "lead", "to", "very", "small", "I", "t", "for", "certain", "tokens,", "thus", "we", "take", "the", "log", "of", "all", "importance", "scores", "to", "avoid", "underflow,", "I", "\u2032", "t", "=", "log(I", "t", ").", "So", "far,", "we", "have", "computed", "the", "importance", "score", "for", "each", "token.", "However,", "we", "observe", "that", "some", "tokens", "appearing", "only", "very", "a", "few", "times", "could", "accidentally", "have", "very", "high", "importance", "scores.", "Thus,", "we", "propose", "to", "penalize", "the", "tokens", "with", "low", "frequencies:\u00cet", "=", "I", "\u2032", "t", "\u2212", "\u03bb/", "log(1", "+", "c", "t", "),", "where", "c", "t", "is", "the", "frequency", "of", "token", "t", "and", "\u03bb", "is", "a", "temperature", "parameter", "to", "adjust", "the", "degree", "that", "we", "want", "to", "penalize", "over", "the", "frequency."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 121, "citation_locations": [121], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b8080bdf-6269-4be7-8d8a-2837dbee97fc", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["Factored", "Neural", "Machine", "Translation", "(FNMT)", "approach", "handles", "the", "output", "vocabulary", "size", "problem", "using", "factors", "as", "a", "translation", "unit.", "The", "main", "motivation", "behind", "this", "factored", "representation", "is", "related", "to", "the", "human", "way", "to", "learn", "how", "to", "construct", "correct", "sentences.", "In", "this", "work,", "the", "factors", "are", "referring", "to", "the", "linguistic", "annotation", "at", "word", "level", "like", "the", "Part", "of", "Speech", "(POS)", "tags.", "Some", "works", "have", "used", "factors", "as", "additional", "information", "for", "language", "modeling", "[11]", "and", "also", "applied", "for", "neural", "networks", "language", "models", "[12, 13, 14].", "Recently,", "factors", "have", "been", "used", "as", "additional", "linguistic", "input", "features", "to", "improve", "a", "word-level", "NMT", "system", "[15]", "as", "well."], "cited_papers": [{"title": "Factored language models and generalized parallel backoff", "year": "2003", "authors": ["J Bilmes", "K Kirchhoff"]}], "target_citation_location": 70, "citation_locations": [70, 79, 96], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b8446e19-63f5-483e-ae5b-c23ec842953d", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["Returning", "to", "the", "different", "approaches", "of", "handling", "Arabic", "text.", "As", "discussed", "in", "the", "previous", "sections", "letter", "normalization", "and", "transliteration", "are", "examples", "of", "the", "simplification", "approach.", "For", "example,", "letter", "normalization", "is", "commonly", "applied", "to", "reduce", "the", "noise", "and", "sparsity", "in", "the", "data", "(Habash, 2010).", "For", "transliteration,", "Ameur", "et", "al.", "(2017)", "applied", "a", "bidirectional", "attention-based", "encoder-decoder", "model", "for", "the", "task", "of", "machine", "transliteration", "between", "Arabic", "and", "English."], "cited_papers": [{"title": "Introduction to arabic natural language processing", "year": "2010", "authors": ["Y Nizar", "unk Habash"]}], "target_citation_location": 41, "citation_locations": [41], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b8d1921d-e515-43e7-a738-1cbea861e80d", "citing_paper": {"title": "On the weak link between importance and prunability of attention heads", "year": 2020, "authors": ["Aakriti Budhraja", "Madhura Pande", "Preksha Nema", "Pratyush Kumar", "Mitesh Khapra"]}, "text": ["In", "the", "other", "major", "direction,", "these", "large", "Transformer-based", "models", "have", "been", "down-sized", "to", "be", "more", "time", "and", "space", "efficient.", "Different", "methods", "for", "down-sizing", "have", "been", "studied", "such", "as", "pruning", "(McCarley, 2019, Gordon et al., 2020, Sajjad et al., 2020),", "distillation", "(Sanh et al., 2019, Liu et al., 2019, Jiao et al., 2019),", "weight", "quantization", "(Zafrir et al., 2019, Shen et al., 2019),", "and", "weight", "factorization", "and", "parameter", "sharing", "(Lan et al., 2019).", "Pruning", "techniques", "have", "been", "particularly", "successful", "in", "reinforcing", "the", "folk-lore", "that", "these", "models", "are", "highly", "over-parameterized.", "These", "pruning", "methods", "prune", "parameters", "based", "on", "magnitude", "(Gordon et al., 2020),", "importance", "(McCarley, 2019)", "or", "layer-wise", "(Sajjad et al., 2020)."], "cited_papers": [{"title": "Q-bert: Hessian based ultra low precision quantization of bert", "year": "2019", "authors": ["Sheng Shen", "Zhen Dong", "Jiayu Ye", "Linjian Ma", "Zhewei Yao", "Amir Gholami", "W Michael", "Kurt Mahoney", "unk Keutzer"]}, {"title": null, "year": "2019", "authors": ["Ofir Zafrir", "Guy Boudoukh", "Peter Izsak", "Moshe Wasserblat"]}], "target_citation_location": 34, "citation_locations": [29, 31, 34, 41, 66, 68, 71], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b941fbea-b149-4563-83cc-b1add9a5db1f", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Our", "experiments", "are", "also", "based", "on", "the", "large", "monolingual", "French", "model", "CamemBERT", "(Martin et al., 2020)", "as", "well", "as", "on", "the", "two", "large", "multilingual", "models:", "XLM-R", "(Conneau et al., 2020)", "and", "mBERT", "(Devlin et al., 2019),", "both", "pre-trained", "from", "massive", "corpora", "dataset", "in", "more", "than", "100", "languages", "such", "as", "the", "Common", "Crawl", "(CC-100)", "or", "Wikipedia", "(Wiki-100).", "We", "also", "exploit", "two", "compact", "multilingual", "models", "with", "a", "distilled", "version", "of", "mBERT:", "distil-mBERT", "(Sanh et al., 2019)", "and", "small-mBERT", "(Abdaoui et al., 2020),", "a", "mBERT", "model", "whose", "the", "original", "vocabulary", "has", "been", "reduced", "to", "two", "languages", "(English", "and", "French).", "Table", "1", "gives", "a", "comparison", "of", "the", "models."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 26, "citation_locations": [12, 23, 26, 61, 64], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b947fa7e-ec49-405f-96e7-ee8b0c6fba68", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["We", "first", "compare", "RocketQA", "with", "the", "previous", "state-of-the-art", "approaches", "on", "passage", "retrieval.", "We", "consider", "both", "sparse", "and", "dense", "passage", "retriever", "baselines.", "The", "sparse", "retrievers", "include", "the", "traditional", "retriever", "BM25", "(Yang et al., 2017),", "and", "four", "traditional", "retrievers", "enhanced", "by", "neural", "networks,", "including", "doc2query", "(Nogueira et al., 2019c),", "DeepCT", "(Dai and Callan, 2019),", "docTTTT-Tquery", "(Nogueira et al., 2019a)", "and", "GAR", "(Mao et al., 2020).", "Both", "doc2query", "and", "docTTTTTquery", "employ", "neural", "question", "generation", "to", "expand", "documents.", "In", "contrast,", "GAR", "employs", "neural", "generation", "models", "to", "expand", "questions.", "Different", "from", "them,", "DeepCT", "utilizes", "BERT", "to", "learn", "the", "term", "weight.", "The", "dense", "passage", "retrievers", "include", "DPR", "(Karpukhin et al., 2020),", "ME-BERT", "(Luan et al., 2020)", "and", "ANCE", "(Xiong et al., 2020).", "Both", "DRP", "and", "ME-BERT", "use", "in-batch", "random", "sampling", "and", "hard", "negative", "sampling", "from", "the", "results", "retrieved", "by", "BM25,", "while", "ANCE", "enhances", "the", "hard", "negative", "sampling", "by", "using", "the", "dense", "retriever."], "cited_papers": [{"title": "Generation-augmented retrieval for open-domain question answering", "year": "2009", "authors": ["Yuning Mao", "Pengcheng He", "Xiaodong Liu", "Yelong Shen", "Jianfeng Gao", "Jiawei Han", "Weizhu Chen"]}], "target_citation_location": 47, "citation_locations": [29, 40, 42, 44, 47, 86, 88, 91], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "b9879f67-1a75-490e-8ab1-f0f3b9e480a7", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["where", "Y", "*", "denotes", "a", "set", "of", "all", "possible", "hypotheses.", "The", "Transformer", "(Vaswani et al., 2017)", "is", "a", "stateof-the-art", "NN", "architecture", "that", "can", "be", "used", "to", "maximize", "Eq.", "(1).", "The", "Transformer", "consists", "of", "two", "NNs:", "The", "Encoder", "network", "and", "the", "Decoder", "network.", "Let", "I", "emb", "and", "D", "emb", "be", "the", "sequence", "length", "and", "dimension", "of", "the", "acoustic", "embedding.", "The", "Encoder", "network", "generates", "a", "sequence", "of", "embeddings", "of", "the", "acoustic", "information", "E", "=", "{e", "i", "\u2208", "D", "emb}", "I", "emb", "i=1", "from", "input", "feature", "sequences,", "i.e.", "E", "=", "Encoder(X).", "The", "Decoder", "network", "predicts", "the", "output", "of", "the", "M", "-th", "step", "y", "M", "given", "a", "sub-sequence,", "including", "the", "current", "output", "\u0233", "=", "{y", "1,", "\u2022,", "y", "M", "\u22121}", "and", "E,", "i.e.", "y", "M", "=", "Decoder(\u0233,", "E).", "This", "conditional", "autoregressive", "modeling", "function", "is", "particularly", "important", "in", "this", "paper", "since", "it", "can", "explicitly", "model", "the", "relationship", "between", "output", "labels,", "unlike", "CTC."], "cited_papers": [{"title": "Attention is all you need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 12, "citation_locations": [12], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "b995c9bc-6d9a-4c02-a61d-5562e7b01d99", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["As", "noted", "by", "Urbanek et al. (2019)", "and", "Ammanabrolu et al. (2021),", "the", "ability", "to", "speak", "and", "act", "in", "these", "textual", "fantasy", "worlds", "has", "implications", "for", "domains", "beyond", "text-games.", "Text", "games", "are", "a", "platform", "where", "agents", "can", "interact", "in", "a", "relatively", "isolated", "environment", "and", "learn", "to", "interactively", "communicate", "effectively", "through", "natural", "language", "in", "a", "situated", "manner.", "Our", "methods", "use", "both", "large", "language", "models", "and", "deep", "reinforcement", "learning", "and", "are", "prone", "to", "the", "pitfalls", "that", "other", "contemporary", "methods", "using", "these", "techniques", "face,", "especially", "in", "the", "areas", "of", "dialogue", "and", "text", "game", "systems.", "We", "mitigate", "this", "first", "pitfall", "by", "restricting", "our", "current", "system", "to", "a", "retrieval", "based", "dialogue,", "ensuring", "that", "we", "can", "filter", "out", "non-normative", "dialogue", "usages", "beforehand,", "though", "we", "will", "note", "that", "the", "system", "can", "be", "extended", "to", "generative", "systems", "as", "described", "in", "Prabhumoye et al. (2020).", "Further,", "the", "LIGHT", "dataset", "is", "crowdsourced", "and", "contains", "data", "biases", "that", "can", "be", "attributed", "to", "the", "crowdworkers", "tasked", "with", "creating", "the", "data.", "Dinan", "et", "al.", "(2020)", "provides", "an", "in", "depth", "discussion", "regarding", "the", "inherent", "dataset", "biases,", "such", "as", "gender", "bias", "in", "the", "distribution", "of", "characters,", "in", "LIGHT", "and", "techniques", "to", "mitigate", "them-we", "follow", "these", "methods", "to", "reduce", "their", "effects", "on", "both", "the", "environment", "generation", "and", "agent", "training", "procedures.", "The", "LIGHT", "environment", "further", "allows", "us", "to", "factorize", "the", "overall", "action", "space", "A", "into", "A", "as", "the", "set", "of", "possible", "textual", "actions", "or", "commands", "(e.g.", "get", "sword,", "steal", "coins", "from", "merchant),", "and", "U", "as", "the", "set", "of", "possible", "dialogues", "that", "can", "be", "uttered", "by", "an", "agent,", "thus", "making", "it", "a", "factored", "POMDP", "(Degris and Sigaud, 2013).", "This", "in", "turn", "means", "that,", "for", "a", "given", "quest", "q,", "each", "expert", "human", "demonstration", "D(q)", "=", "\u03b1", "*", "0,", "\u03b1", "*", "1", "...\u03b1", "*", "n", "can", "be", "factorized", "into", "two", "sub-sequences", "of", "expert", "demonstrations", "of", "actions", "and", "dialogue", "D", "A", "(q)", "=", "a", "*", "0,", "a", "*", "1,", "...a", "*", "n", "and", "D", "U", "(q)", "=", "u", "*", "0,", "u", "*", "1,", "...u", "*", "m", "respectively.", "The", "factorized", "action", "spaces", "A", "and", "U", "are", "constructed", "by", "enumerating", "all", "possible", "actions/dialogue", "utterances", "in", "the", "all", "human", "demonstrations", "in", "LIGHT-quests."], "cited_papers": [{"title": "Factored markov decision processes. Markov Decision Processes in Artificial Intelligence", "year": "2013", "authors": ["Thomas Degris", "Olivier Sigaud"]}], "target_citation_location": 247, "citation_locations": [3, 5, 126, 247], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "badb4cc2-692a-41ef-b85c-7931b5489a60", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Although", "the", "canonical", "way", "to", "represent", "words", "is", "to", "assign", "them", "to", "vectors,", "if", "the", "goal", "is", "to", "model", "connections", "between", "words,", "a", "graph", "structure", "is", "at", "least", "as", "suitable.", "When", "each", "word", "is", "represented", "by", "a", "vector,", "the", "similarity", "between", "them", "is", "most", "often", "calculated", "as", "the", "cosine", "of", "the", "angle", "of", "the", "two", "vectors.", "In", "the", "case", "of", "graph", "representations,", "all", "words", "in", "the", "dictionary", "correspond", "to", "the", "vertices", "of", "a", "large", "graph,", "and", "the", "distance", "between", "them", "can", "be", "defined", "in", "many", "ways", "depending", "on", "the", "graph.", "One", "option", "is", "the", "length", "or", "weight", "of", "the", "shortest", "path", "between", "the", "two", "vertices.", "Knowledge", "graphs", "(Miller, 1992, Speer and Havasi, 2012, Navigli and Ponzetto, 2010a)", "were", "already", "used", "to", "model", "word", "connections", "in", "previous", "Codenames", "agents,", "but", "other", "types", "of", "language", "graphs", "also", "exist,", "which", "could", "be", "utilized", "for", "this", "task", "as", "well."], "cited_papers": [{"title": "WordNet: A lexical database for English", "year": "1992", "authors": ["A George", "unk Miller"]}, {"title": "Representing general relational knowledge in ConceptNet 5", "year": "2012", "authors": ["Robyn Speer", "Catherine Havasi"]}, {"title": "Ba-belNet: Building a very large multilingual semantic network", "year": "2010", "authors": ["Roberto Navigli", "Simone Ponzetto"]}], "target_citation_location": 107, "citation_locations": [107], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "bb03bd62-2af2-4de6-b8cf-a2e192da8b1f", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["In", "fact,", "homophily", "is", "so", "prominent,", "Mishra et al. (2019)", "noted", "in", "their", "work", "that", "the", "profiles", "they", "generated", "from", "the", "social", "graph", "of", "users", "and", "tweets", "could", "encode", "patters", "of", "similar", "linguistic", "practices", "amongst", "connected", "users", "in", "the", "Waseem", "and", "Hovy", "(2016)", "dataset,", "hence", "allowing", "for", "comments", "with", "implicit", "and", "generalized", "sexism", "or", "racism", "to", "be", "better", "detected.", "Moreover,", "homophily", "has", "direct", "associations", "with", "all", "the", "four", "aspects", "of", "context", "that", "we", "described", "in", "section", "2,", "i.e.,", "similar", "sociolinguistic", "norms", "and", "shared", "language", "markers", "facilitate", "homophilic", "ties", "in", "social", "networks", "(Kovacs and Kleinbaum, 2020),", "as", "do", "shared", "beliefs,", "stereotypes,", "and", "demographic", "traits", "(Mishra et al., 2018a).", "Therefore,", "capturing", "homophily", "allows", "for", "all", "the", "four", "aspects", "to", "be", "directly", "captured", "together.", "We", "note", "that", "just", "exploiting", "simplistic", "and", "limited", "inductive", "biases", "that", "are", "easy", "to", "extract,", "like", "gender", "of", "the", "user,", "can", "render", "methods", "prone", "to", "making", "faulty", "generalizations", "because", "of", "overfitting", "to", "patterns", "in", "the", "training", "data.", "This", "is", "also", "evident", "from", "the", "observations", "that", "Mishra et al. (2019)", "made", "in", "their", "work.", "They", "noted", "that", "the", "profiles", "they", "generated", "from", "the", "social", "graph", "consisting", "of", "user", "and", "tweet", "nodes", "improved", "F", "1", "scores", "over", "the", "profiles", "Mishra et al. (2018a)", "generated", "from", "the", "social", "graph", "just", "consisting", "of", "users,", "with", "the", "gains", "mainly", "coming", "from", "increase", "in", "precision."], "cited_papers": [{"title": "Language-style similarity and social networks", "year": "2020", "authors": ["Balazs Kovacs", "Adam Kleinbaum"]}], "target_citation_location": 88, "citation_locations": [6, 88, 97, 157, 186], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "bb22e956-bac3-4ce9-80c4-6a006e3d9006", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["Task-oriented", "dialogue", "systems", "complete", "tasks", "for", "users,", "such", "as", "making", "a", "hotel", "reservation", "or", "finding", "train", "routes,", "in", "a", "multi-turn", "conversation", "(Gao et al., 2018, Sun et al., 2016 Sun et al., , 2017)).", "The", "generated", "system", "utterances", "should", "not", "only", "be", "naturally", "sound,", "but", "more", "importantly", "be", "informative,", "i.e.,", "to", "proceed", "the", "dialogue", "towards", "task", "completion.", "To", "fulfill", "this", "requirement,", "conditioned", "response", "generation", "is", "widely", "adopted", "based", "on", "system", "actions", "*", "Rui", "Zhang", "is", "the", "corresponding", "author.", "(Wen et al., 2017, Chen et al., 2019).", "The", "response", "generation", "process", "is", "decoupled", "into", "two", "consecutive", "steps,", "where", "an", "action", "is", "first", "selected", "and", "then", "an", "utterance", "is", "generated", "conditioned", "on", "this", "action.", "One", "can", "optimize", "each", "step", "towards", "its", "goal,", "i.e.,", "informative", "and", "naturally", "sound,", "without", "impinging", "the", "other", "(Yarats and Lewis, 2018).", "However,", "such", "approaches", "rely", "on", "action", "annotations", "(as", "in", "Table", "1),", "which", "require", "domain", "knowledge", "and", "extensive", "efforts", "to", "obtain."], "cited_papers": [{"title": null, "year": "2018", "authors": ["Jianfeng Gao", "Michel Galley", "Lihong Li"]}, {"title": "Collaborative intent prediction with real-time contextual data", "year": "2017", "authors": ["Yu Sun", "Nicholas Yuan", "Xing Xie"]}, {"title": "Contextual intent tracking for personal assistants", "year": "2016", "authors": ["Yu Sun", "Nicholas Yuan", "Yingzi Wang", "Xing Xie", "Kieran Mcdonald", "Rui Zhang"]}], "target_citation_location": 21, "citation_locations": [21, 66, 110], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "bb299960-c458-40fa-87aa-7dd6f4ceab76", "citing_paper": {"title": "NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques", "year": 2021, "authors": ["Gunjan Chhablani", "Abheesht Sharma", "Harshit Pandey", "Yash Bhartia", "Shan Suthaharan"]}, "text": ["In", "SemEval-2021", "Task-5,", "Pavlopoulos et al. (2021)", "provide", "a", "dataset", "of", "10k", "English", "texts", "filtered", "from", "Civil", "Comments", "(Borkan et al., 2019)", "dataset.", "Each", "text", "is", "crowd-annotated", "with", "character", "offsets", "that", "make", "the", "text", "toxic.", "The", "task", "is", "to", "predict", "these", "character", "offsets", "given", "the", "text.", "The", "work", "presented", "in", "this", "paper", "aims", "to", "provide", "a", "comprehensive", "analysis", "of", "simple", "Token", "Classification", "(TC)", "and", "Span", "Prediction", "(SP)", "methods", "across", "multiple", "BERT-based", "models", "-BERT", "(Devlin et al., 2019),", "RoBERTa", "(Liu et al., 2019)", "and", "SpanBERT", "(Joshi et al., 2020).", "Additionally,", "we", "experiment", "with", "a", "few", "hybrid", "approaches", "-Multi-Span", "(MSP),", "where", "the", "model", "is", "trained", "on", "multiple", "spans", "simultaneously,", "Span+Token", "(SP-TC),", "where", "the", "model", "is", "trained", "on", "both", "kinds", "of", "tasks", "simultaneously,", "LSTM-CRF", "(LC),", "which", "uses", "a", "LSTM", "and", "CRF", "layer", "on", "top", "of", "BERT-based", "models,", "and", "a", "combination", "of", "predicted", "offsets", "for", "above", "techniques", "using", "union/intersection.", "In", "Section", "2,", "we", "perform", "a", "compendious", "literature", "survey.", "Section", "3", "elucidates", "our", "approach,", "including", "the", "modelling", "aspect,", "the", "various", "variants", "of", "the", "base", "model,", "and", "the", "different", "Hybrid", "Systems.", "In", "Section", "4,", "we", "describe", "our", "experimental", "setup", "and", "hyperparameters", "used", "for", "our", "methods.", "Lastly,", "in", "Section", "5", "we", "analyze", "our", "results", "and", "perform", "ablative", "analysis", "on", "our", "systems."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 67, "citation_locations": [3, 15, 67, 69, 72], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "bb567dec-2847-4922-895d-aff2b8c116d2", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["When", "processing", "human", "language", "it", "is", "difficult", "to", "operate", "only", "at", "the", "level", "of", "individual", "words.", "While", "for", "some", "tasks,", "perhaps", "monolingual", "information", "retrieval", "in", "particular,", "this", "might", "seem", "reasonable,", "for", "others", "such", "as", "machine", "translation,", "cross-language", "question", "answering,", "and", "translin-gual", "information", "retrieval,", "restriction", "to", "processing", "single", "words", "is", "a", "significant", "impediment.", "There", "has", "been", "much", "recent", "interest", "in", "computational", "approaches", "to", "dealing", "with", "multiword", "expressions", "(MWEs)", "as", "workshops", "at", "ACL-2006 , SIGIR-2005 , ACL-2004", "and", "other", "conferences", "attest."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 70, "citation_locations": [70], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3]]}
{"id": "bb83fc28-3660-41e5-b4dc-9d2a3a7ce20c", "citing_paper": {"title": "ROI Analysis model for Language Service Providers", "year": 2013, "authors": ["Ekaterina Stambolieva"]}, "text": ["The", "other", "50%", "consider", "it", "as", "bad.", "Moreover,", "the", "in-house", "translators", "classify", "the", "post-editing", "effort", "(Avramidis et al., 2012)", "as", "intermediate,", "but", "this", "information", "might", "be", "unreliable", "due", "to", "insufficient", "numbers", "of", "answers", "on", "the", "MT", "output", "understandability", "question."], "cited_papers": [{"title": "Involving Language Professionals in the Evaluation of Machine Translation", "year": "2012", "authors": ["Eleftherios Avramidis", "Aljoscha Burchardt", "Christian Federmann", "Maja Popovic", "Cindy Tscherwinka", "David Vilar Torres"]}], "target_citation_location": 15, "citation_locations": [15], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "bb90f344-4046-4fa0-92e6-7021a64ada2f", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["The", "SDG", "task", "is", "challenging", "because", "it", "requires", "a", "model", "to", "learn", "from", "a", "standard", "dictionary", "containing", "complex", "definitions", "and", "then", "generate", "simple", "ones,", "and", "hence", "fully", "unsupervised.", "A", "seemingly", "feasible", "solution", "is", "to", "generate", "definitions", "first", "and", "then", "simplify", "them,", "i.e.,", "the", "generationsimplification", "pipeline.", "However,", "the", "simplification", "task", "requires", "dataset", "with", "complex-simple", "sentence", "pairs,", "and", "such", "data", "is", "also", "difficult", "to", "find", "in", "languages", "other", "than", "English", "(Martin et al., 2020).", "Besides,", "the", "pipeline", "methods", "do", "not", "perform", "well", "due", "to", "accumulated", "errors", "(Section", "6.1)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 68, "citation_locations": [68], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "bba94bb9-5c82-4b57-a77a-27b2d71346cb", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["Our", "training", "data", "include", "five", "datasets", "for", "target-based", "sentiment", "classification:", "SemEval17", "(Rosenthal et al., 2017),", "entities", "(Dong et al., 2014),", "open", "domain", "(Mitchell et al., 2013),", "Irish", "politics", "(Bakliwal et al., 2013),", "and", "our", "annotations", "of", "positive/negative", "norms", "toward", "norm", "targets", "(\u00a75.1).", "These", "annotations", "highly", "improve", "classification", "of", "sentiments", "expressed", "through", "advocacy", "and", "opposition", "in", "normative", "statements.", "Pretraining", "on", "general", "sentiment", "resourcessubjectivity", "lexicon", "(Wilson et al., 2005)", "and", "sen-timent140", "(Go et al., 2009)", "-also", "helps", "(Table", "3:", "Mapping", "between", "corpus-specific", "labels", "and", "our", "labels", "for", "the", "causality", "module.", "\u2020", "The", "order", "of", "two", "input", "texts", "are", "reversed.", "\u2021", "The", "second", "input", "text", "is", "replaced", "with", "a", "random", "text", "in", "the", "corpus."], "cited_papers": [{"title": "SemEval-2017 Task 4: Sentiment analysis in twitter", "year": "2017", "authors": ["Sara Rosenthal", "Noura Farra", "Preslav Nakov"]}], "target_citation_location": 11, "citation_locations": [11, 13, 16, 19, 51, 54], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "bbcd3403-1245-4ce3-af46-6938106b88c1", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["A", "line", "of", "work", "has", "been", "proposed", "to", "study", "the", "vulnerability", "of", "natural", "language", "models,", "through", "transformations", "such", "as", "character-level", "perturbations", "(Ebrahimi et al., 2018),", "word-level", "perturbations", "(Jin et al., 2019, Ren et al., 2019, Yang et al., 2020, Hsieh et al., 2019, Cheng et al., 2020, Li et al., 2020),", "prepending", "or", "appending", "a", "sequence", "(Jia and Liang, 2017, Wallace et al., 2019a),", "and", "generative", "models", "(Zhao et al., 2018b).", "They", "focus", "on", "constructing", "adversarial", "examples", "from", "the", "test", "set", "that", "alter", "the", "prediction,", "whereas", "our", "methods", "focus", "on", "finding", "vulnerable", "examples", "beyond", "the", "test", "set", "whose", "prediction", "can", "be", "altered.", "Robustness", "beyond", "the", "test", "set.", "Several", "works", "have", "studied", "model", "robustness", "beyond", "test", "sets", "but", "mostly", "focused", "on", "computer", "vision", "tasks.", "Zhang et al. (2019)", "demonstrate", "that", "a", "robustly", "trained", "model", "could", "still", "be", "vulnerable", "to", "small", "perturbations", "if", "the", "input", "comes", "from", "a", "distribution", "only", "slightly", "different", "than", "a", "normal", "test", "set", "(e.g.,", "images", "with", "slightly", "different", "contrasts).", "Hendrycks and Dietterich (2019)", "study", "more", "sources", "of", "common", "corruptions", "such", "as", "brightness,", "motion", "blur", "and", "fog.", "Unlike", "in", "computer", "vision", "where", "simple", "image", "transformations", "can", "be", "used,", "in", "our", "natural", "language", "setting,", "generating", "a", "valid", "example", "beyond", "test", "set", "is", "more", "challenging", "because", "language", "semantics", "and", "grammar", "must", "be", "maintained.", "Counterfactual", "fairness.", "Kusner et al. (2017)", "propose", "counterfactual", "fairness", "and", "consider", "a", "model", "fair", "if", "changing", "the", "protected", "attributes", "does", "not", "affect", "the", "distribution", "of", "prediction.", "We", "follow", "the", "definition", "and", "focus", "on", "evaluating", "the", "counterfactual", "bias", "between", "pairs", "of", "protected", "tokens.", "Existing", "literature", "quantifies", "fairness", "on", "a", "test", "dataset", "or", "through", "templates", "(Feldman et al., 2015, Kiritchenko and Mohammad, 2018, May et al., 2019, Huang et al., 2020).", "For", "instance,", "Garg et al. (2019)", "quantify", "the", "absolute", "counterfactual", "token", "fairness", "gap", "on", "the", "test", "set,", "Prabhakaran", "et", "al.", "(2019)", "study", "perturbation", "sensitivity", "for", "named", "entities", "on", "a", "given", "set", "of", "corpus.", "Wallace et al. (2019b),", "Sheng et al. (2019 Sheng et al. ( , 2020) )", "study", "how", "language", "generation", "models", "respond", "differently", "to", "prompt", "sentences", "containing", "mentions", "of", "different", "demographic", "groups.", "In", "contrast,", "our", "method", "quantifies", "the", "bias", "on", "the", "constructed", "neighborhood."], "cited_papers": [{"title": "HotFlip: White-box adversarial examples for text classification", "year": "2018", "authors": ["Javid Ebrahimi", "Anyi Rao", "Daniel Lowd", "Dejing Dou"]}], "target_citation_location": 21, "citation_locations": [21, 24, 30, 34, 87, 122, 172, 220, 223, 251, 252], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "bbd4bef9-76e9-48c4-9b65-f7bbee66a2ac", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["chitecture", "(Luan et al., 2020).", "The", "cross-encoder", "is", "more", "effective", "and", "robust,", "while", "it", "is", "inefficient", "over", "a", "large", "number", "of", "candidates", "in", "inference.", "Hence,", "we", "first", "train", "a", "cross-encoder", "(following", "the", "architecture", "shown", "in", "Figure", "1b).", "Then,", "when", "sampling", "hard", "negatives", "from", "the", "top-ranked", "passages", "retrieved", "by", "a", "dense", "retriever,", "we", "select", "only", "the", "passages", "that", "are", "predicted", "as", "negatives", "by", "the", "cross-encoder", "with", "high", "confidence", "scores.", "The", "selected", "top-retrieved", "passages", "can", "be", "considered", "as", "denosied", "samples", "that", "are", "more", "reliable", "to", "be", "used", "as", "hard", "negatives."], "cited_papers": [{"title": "Sparse, dense, and attentional representations for text retrieval. CoRR, abs", "year": null, "authors": ["Yi Luan", "Jacob Eisenstein", "Kristina Toutanova", "Michael Collins"]}], "target_citation_location": 1, "citation_locations": [1], "citation_type": "single", "annotations": [[0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "bbe41768-bd84-4fc2-9b86-4c5bce7f84ef", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["BLEU", "Previous", "definition", "generation", "studies", "(Noraset et al., 2017, Yang et al., 2020, Kong et al., 2020)", "used", "the", "BLEU", "(Papineni et al., 2002)", "score", "to", "measure", "the", "closeness", "of", "generated", "results", "to", "the", "standard", "answers,", "and", "to", "evaluate", "the", "accuracy", "of", "results.", "Since", "the", "English", "test", "set", "is", "manually", "annotated,", "we", "calculate", "the", "BLEU", "score", "of", "both", "complex", "and", "simple", "definitions,", "respectively."], "cited_papers": [{"title": "Bleu: a method for automatic evaluation of machine translation", "year": "2002", "authors": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu"]}], "target_citation_location": 9, "citation_locations": [5, 9], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "bc08eaf9-312d-4fa2-be86-b7d5e4652b8d", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["For", "model", "training,", "we", "used", "Adam", "with", "batch", "size", "of", "60,", "learning", "rate", "of", "3e-5,", "L2", "weight", "decay", "of", "0.01,", "learning", "rate", "warm", "up", "over", "the", "first", "10,000", "steps,", "and", "linear", "decay", "of", "learning", "rate.", "Our", "models", "were", "trained", "by", "one", "Tesla", "V100", "GPU", "card", "with", "32GB", "memory,", "and", "implemented", "on", "PyTorch", "with", "the", "Huggingface's", "Transformer", "(Wolf et al., 2020).", "All", "Transformer-based", "methods", "were", "trained", "with", "30", "epochs,", "taken", "about", "4-5", "hours", "on", "the", "ComVE", "dataset", "and", "7-9", "hours", "on", "the", "\u03b1-NLG", "dataset."], "cited_papers": [{"title": "Transformers: State-of-theart natural language processing", "year": "2020", "authors": ["Thomas Wolf"]}], "target_citation_location": 56, "citation_locations": [56], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "bc40d290-c329-4923-bc33-42edfeb9a20a", "citing_paper": {"title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation", "year": 2021, "authors": ["Hansi Hettiarachchi", "Tharindu Ranasinghe"]}, "text": ["This", "paper", "describes", "our", "submission", "to", "SemEval-2021", "Task", "2", "(Martelli et al., 2021).", "Our", "approach", "is", "mainly", "focused", "on", "transformer-based", "models", "with", "different", "text", "pair", "classification", "architectures.", "We", "remodel", "the", "default", "text", "pair", "classification", "architecture", "and", "introduce", "several", "strategies", "that", "outperform", "the", "default", "text", "pair", "classification", "architecture", "for", "this", "task.", "For", "effortless", "generalisation", "across", "the", "languages,", "we", "do", "not", "use", "any", "language-specific", "processing", "and", "resources.", "In", "the", "subtasks", "where", "only", "a", "few", "training", "instances", "were", "available,", "we", "use", "few-shot", "learning", "and", "in", "the", "subtasks", "where", "there", "were", "no", "training", "instances", "were", "available,", "we", "use", "zero-shot", "learning", "taking", "advantage", "of", "the", "cross-lingual", "nature", "of", "the", "multilingual", "transformer", "models."], "cited_papers": [{"title": "SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC)", "year": "2021", "authors": ["Federico Martelli", "Najla Kalach", "Gabriele Tola", "Roberto Navigli"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "bcb216af-e9a3-4130-9fc7-7e07aada89bf", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["As", "a", "first", "step,", "we", "consider", "only", "cases", "where", "at", "any", "node", "during", "the", "tree", "traversal", "in", "the", "BURS,", "there", "is", "only", "potentially", "one", "gNCN", "at", "a", "time:", "that", "is,", "it", "is", "not", "possible", "to", "embed", "or", "overlap", "these", "gNCNs.", "In", "order", "to", "explain", "this,", "consider", "first", "the", "example", "below.", "The", "input", "AST", "(ignoring", "the", "annotations", "on", "the", "nodes)", "is", "in", "Figure", "7,", "pattern", "trees,", "in", "the", "form", "of", "a", "TAG", "grammar", "(with", "associated", "costs", "still", "indicated", "by", "),", "are", "also", "in", "Figure", "7.", "The", "algorithm", "we", "use", "for", "bottom-up", "pattern", "matching,", "adapted", "from", "that", "of", "Grune et al. (2000),", "is", "in", "Figure", "8."], "cited_papers": [{"title": "Handling Structural Divergences and Recovering Dropped Arguments in a Korean/English Machine Translation System", "year": "2000", "authors": ["H Grune", "C Bal", "K Jacobs", "unk Langendoen", "U Chichester", "B Han", "M Lavoie", "O Palmer", "R Rambow", "T Kittredge", "N Korelsky", "M Kim", "unk Kim"]}], "target_citation_location": 96, "citation_locations": [96], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2]]}
{"id": "bd31bd3c-34ba-4184-862d-8894318efa07", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Expert", "parameterization.", "Independently", "parameterizing", "each", "expert", "may", "exacerbate", "overfitting", "since", "the", "number", "of", "parameters", "increases", "linearly", "with", "the", "number", "of", "experts", "(Shen et al., 2019).", "We", "follow", "the", "parameter", "sharing", "schema", "in", "Cho et al. (2019),", "Shen et al. (2019)", "to", "avoid", "this", "issue.", "This", "only", "requires", "a", "negligible", "increase", "in", "parameters", "over", "the", "baseline", "model", "that", "does", "not", "uses", "MoE.", "In", "our", "experiments,", "we", "compared", "adding", "a", "unique", "expert", "embedding", "to", "each", "input", "token", "with", "adding", "an", "expert", "prefix", "token", "before", "the", "input", "text", "sequence,", "where", "they", "achieved", "very", "similar", "performance."], "cited_papers": [{"title": "Mixture content selection for diverse sequence generation", "year": "2019", "authors": ["Jaemin Cho", "Minjoon Seo", "Hannaneh Hajishirzi"]}], "target_citation_location": 29, "citation_locations": [21, 29, 30], "citation_type": "single", "annotations": [[0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "bdd3156d-a5eb-4207-8302-3f73c1e2bb8e", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["Table", "5", "presents", "the", "results", "of", "evaluating", "the", "impact", "of", "using", "coreference", "annotations", "to", "improve", "coreference", "reasoning", "in", "MRC.", "We", "report", "the", "re-sults", "for", "both", "of", "the", "examined", "state-of-the-art", "models,", "i.", "(Rajpurkar et al., 2016)", "and", "is", "then", "finetuned", "on", "Quoref."], "cited_papers": [{"title": "SQuAD: 100,000+ questions for machine comprehension of text", "year": "2016", "authors": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang"]}], "target_citation_location": 31, "citation_locations": [31], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2]]}
{"id": "be13aedc-6fd8-4f39-a529-07290150d14e", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["In", "most", "studies,", "model", "robustness", "is", "evaluated", "based", "on", "a", "given", "test", "dataset", "or", "synthetic", "sentences", "constructed", "from", "templates", "(Ribeiro et al., 2020).", "Specifically,", "the", "robustness", "of", "a", "model", "is", "often", "evaluated", "by", "the", "ratio", "of", "test", "examples", "where", "the", "model", "prediction", "cannot", "be", "altered", "by", "semantic-invariant", "perturbation.", "We", "refer", "to", "this", "type", "of", "evaluations", "as", "the", "first-order", "robustness", "evaluation.", "However,", "even", "if", "a", "model", "is", "first-order", "robust", "on", "an", "input", "sentence", "x", "0,", "it", "is", "possible", "that", "the", "model", "is", "not", "robust", "on", "a", "natural", "sentence", "x0", "that", "is", "slightly", "modified", "from", "x", "0.", "In", "that", "case,", "adversarial", "examples", "still", "exist", "even", "if", "first-order", "attacks", "cannot", "find", "any", "of", "them", "from", "the", "given", "test", "dataset.", "Throughout", "this", "paper,", "we", "call", "x0", "a", "vulnerable", "example.", "The", "existence", "of", "such", "examples", "exposes", "weaknesses", "in", "models'", "understanding", "and", "presents", "challenges", "for", "model", "deployment.", "Fig.", "1", "illustrates", "an", "example."], "cited_papers": [{"title": "Beyond accuracy: Behavioral testing of nlp models with checklist", "year": "2020", "authors": ["Tongshuang Marco Tulio Ribeiro", "Carlos Wu", "Sameer Guestrin", "unk Singh"]}], "target_citation_location": 19, "citation_locations": [19], "citation_type": "single", "annotations": [[0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "be27df6c-aff2-457c-86b5-2a03cd2ff745", "citing_paper": {"title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection", "year": 2021, "authors": ["Henry Weld", "Guanghao Huang", "Jean Lee", "Tongshu Zhang", "Kunze Wang", "Xinghong Guo", "Siqu Long", "Josiah Soyeon", "Caren Han"]}, "text": ["By", "conducting", "a", "joint", "model", "for", "the", "two", "tasks,", "a", "synergistic", "effect", "can", "be", "achieved", "(Zhang et", "2019b).", "To", "build", "multi-turn", "dialogue", "datasets,", "most", "studies", "have", "recruited", "workers", "via", "crowd-sourcing", "to", "collect", "task-oriented", "dialogues", "across", "different", "domains", "(e.g.", "in-car", "assistant", "(Eric et al., 2017),", "navigation", "and", "events", "(Gupta et al., 2018),", "multidomains", "(Budzianowski et al., 2018),", "personal", "notifications", "(Schuster et al., 2019)", ").", "Recently,", "deep", "learning", "models", "have", "also", "been", "extensively", "studied", "in", "order", "to", "capture", "the", "contextual", "signals", "from", "multiple", "sequential", "inputs.", "(e.g.", "BiLSTM", "with", "attention", "(Wang et al., 2019),", "GRU", "with", "self-attention", "and", "context-fusion", "(Gupta et al., 2019).", "The", "models", "listed", "all", "show", "an", "increase", "in", "semantic", "detection", "performance", "when", "the", "context", "is", "included", "in", "the", "analysis."], "cited_papers": [{"title": "Multiwoz-a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling", "year": "2018", "authors": ["Pawe\u0142 Budzianowski", "Tsung-Hsien Wen", "Bo-Hsiang Tseng", "I\u00f1igo Casanueva", "Stefan Ultes", "Milica Osman Ramadan", "unk Gasic"]}], "target_citation_location": 45, "citation_locations": [15, 39, 43, 45, 48, 74, 80], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "be2d317c-a293-4dfc-a29a-230586962e1a", "citing_paper": {"title": "Controlled Text Generation with Adversarial Learning", "year": 2020, "authors": ["Federico Betti", "Giorgia Ramponi", "Massimo Piccardi"]}, "text": ["In", "these", "experiments", "we", "have", "compared", "the", "sentiment-conditioned", "text", "generation", "of", "CTERM-GAN", "with", "that", "of", "SeqGAN", "[24],", "SentiGAN", "[20]", "and", "an", "RNNLM", "baseline", "[14].", "Following", "the", "experiments", "carried", "out", "in", "[20],", "the", "conditioning", "has", "been", "performed", "based", "on", "only", "two", "sentiments,", "positive", "or", "negative.", "In", "this", "case,", "the", "conditioning", "vector,", "c,", "taken", "as", "input", "by", "CTERM-GAN", "is", "a", "one-hot", "binary", "variable", "representing", "the", "desired", "sentiment.", "The", "RNNLM", "and", "SeqGAN", "models", "have", "been", "trained", "separately", "on", "the", "two", "sentiments", "by", "treating", "positive", "and", "negative", "sentences", "as", "two", "separate", "datasets,", "while", "SentiGAN", "and", "the", "proposed", "model", "have", "been", "trained", "jointly.", "This", "procedure", "makes", "the", "results", "comparable", "although", "it", "is", "clear", "how", "the", "flexibility", "of", "SentiGAN", "and", "CTERM-GAN", "makes", "these", "models", "more", "general.", "Dataset", "We", "have", "used", "two", "datasets,", "Movie", "Reviews", "(MR)", "[19]", "and", "Customer", "Reviews", "(CR)", "[10],", "where", "individual", "sentences", "are", "annotated", "as", "either", "positive", "or", "negative.", "The", "Movie", "Reviews", "dataset", "consists", "of", "user", "reviews", "of", "movies,", "with", "2,", "133", "positive", "and", "2,", "370", "negative", "sentences.", "The", "Customer", "Reviews", "dataset", "consists", "of", "1,", "500", "reviews", "of", "products", "sold", "online,", "with", "positive/negative", "annotation", "at", "sentence", "level.", "For", "this", "task,", "only", "sentences", "of", "length", "shorter", "than", "15", "words", "have", "been", "retained,", "to", "be", "able", "to", "use", "the", "same", "preprocessing", "as", "[20]."], "cited_papers": [{"title": "SentiGAN: Generating Sentimental Texts via Mixture Adversarial Networks", "year": "2018", "authors": ["Ke Wang", "Xiaojun Wan"]}], "target_citation_location": 30, "citation_locations": [16, 18, 23, 30, 129, 134, 206], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "be64e9e5-3c17-4d6c-9599-5b5bc6a6dfa7", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["More", "recently,", "researchers", "have", "noted", "that", "the", "linguistic", "features", "of", "a", "comment", "alone", "may", "not", "be", "sufficient", "to", "classify", "it", "as", "abusive", "or", "not.", "Information", "of", "the", "user", "who", "posted", "the", "comment,", "and", "of", "the", "surrounding", "social", "community", "of", "that", "user,", "further", "provides", "valuable", "insights", "into", "the", "abusiveness", "of", "the", "comment.", "An", "example", "of", "this", "is", "the", "study", "by", "Zook (2012),", "which", "mapped", "the", "locations", "of", "racist", "tweets", "in", "response", "to", "President", "Obama's", "re-election", "to", "show", "that", "such", "tweets", "were", "not", "uniformly", "distributed", "across", "the", "United", "States", "but", "instead", "came", "from", "specific", "geographical", "communities", "of", "users.", "Other", "works", "have", "also", "shown", "how", "users", "on", "online", "platforms", "organize", "into", "communities", "based", "on", "factors", "such", "as", "shared", "beliefs,", "stereotypes,", "linguistic", "norms,", "or", "geographical", "propinquity", "(Jurgens, 2013, Nguyen and Ros\u00e9, 2011)."], "cited_papers": [{"title": "Mapping racist tweets in response to president obama's re-election", "year": "2012", "authors": ["Matthew Zook"]}], "target_citation_location": 59, "citation_locations": [59, 121], "citation_type": "single", "annotations": [[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "be72350d-bc60-4a94-b1b6-f0138819c399", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["To", "investigate", "what", "logical", "mechanisms", "govern", "argumentative", "relations,", "we", "hypothesize", "that", "governing", "mechanisms", "should", "be", "able", "to", "classify", "the", "relations", "without", "directly", "training", "on", "relationlabeled", "data.", "Thus,", "we", "first", "compile", "a", "set", "of", "rules", "specifying", "logical", "and", "theory-informed", "mechanisms", "that", "signal", "the", "support", "and", "attack", "relations", "(\u00a73).", "The", "rules", "are", "grouped", "into", "four", "mechanisms:", "factual", "consistency,", "sentiment", "coherence,", "causal", "relation,", "and", "normative", "relation.", "These", "rules", "are", "combined", "via", "probabilistic", "soft", "logic", "(PSL)", "(Bach et al., 2017)", "to", "estimate", "the", "optimal", "argumentative", "relations", "between", "statements.", "We", "operationalize", "each", "mechanism", "by", "training", "semantic", "modules", "on", "public", "datasets", "so", "that", "the", "modules", "reflect", "real-world", "knowledge", "necessary", "for", "reasoning", "(\u00a74).", "For", "normative", "relation,", "we", "build", "a", "necessary", "dataset", "via", "rich", "annotation", "of", "the", "normative", "argumentation", "schemes", "argument", "from", "consequences", "and", "practical", "reasoning", "(Walton et al., 2008),", "by", "developing", "a", "novel", "and", "reliable", "annotation", "protocol", "(\u00a75)."], "cited_papers": [{"title": "Hinge-Loss Markov random fields and probabilistic soft logic", "year": "2017", "authors": ["H Stephen", "Matthias Bach", "Bert Broecheler", "Lise Huang", "unk Getoor"]}], "target_citation_location": 72, "citation_locations": [72, 125], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "be7b59b6-8ed0-465f-80c7-dad86afca06e", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["the", "BERT", "model", "(Devlin et al., 2018),"], "cited_papers": [{"title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "year": "2018", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 3, "citation_locations": [3], "citation_type": "single", "annotations": [[1, 1, 1, 1]]}
{"id": "bed8a3bb-bb24-4215-9a11-c798ca8e63ee", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["Base", "models.", "For", "BoW,", "CNN,", "and", "LSTM,", "all", "models", "use", "pre-trained", "GloVe", "embeddings", "(Pennington et al., 2014),", "and", "have", "one", "hidden", "layer", "of", "the", "corresponding", "type", "with", "100", "hidden", "size.", "Similar", "to", "the", "baseline", "performance", "reported", "in", "GLUE", "(Wang et al., 2019),", "our", "trained", "models", "have", "an", "evaluation", "accuracy", "of", "81.4%,", "82.5%,", "and", "81.7%,", "respectively.", "For", "attention-based", "models,", "we", "train", "a", "3-layer", "Transformer", "(the", "largest", "size", "in", "Shi et al. 2020)", "and", "fine-tune", "a", "pre-trained", "bertbase-uncased", "from", "HuggingFace", "(Wolf et al., 2020).", "The", "Transformer", "uses", "4", "attention", "heads", "and", "64", "hidden", "size,", "and", "obtains", "82.1%", "accuracy."], "cited_papers": [{"title": "Glove: Global vectors for word representation", "year": "2014", "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning"]}], "target_citation_location": 13, "citation_locations": [13, 35, 61, 69], "citation_type": "single", "annotations": [[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "bf26fa04-98f7-4f28-9227-3f3809d59d5e", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["Improving", "content", "diversity", "in", "NLG.", "Most", "of", "the", "existing", "diversity-promoting", "work", "has", "focused", "on", "improving", "syntactic", "and", "lexical", "diversity,", "such", "as", "different", "language", "style", "in", "machine", "translation", "(Shen et al., 2019)", "and", "word", "variability", "in", "paraphrase", "generation", "(Gupta et al., 2018).", "Nevertheless,", "methods", "for", "improving", "content", "diversity", "in", "NLG", "systems", "have", "been", "rarely", "studied", "in", "the", "existing", "literature.", "We", "believe", "that", "generating", "diverse", "content", "is", "one", "of", "the", "most", "promising", "aspects", "of", "machine", "intelligence,", "which", "can", "be", "applied", "to", "a", "wide", "range", "of", "real-world", "applications,", "not", "only", "limited", "to", "commonsense", "reasoning."], "cited_papers": [{"title": "Mixture models for diverse machine translation: Tricks of the trade", "year": "2019", "authors": ["Tianxiao Shen", "Myle Ott", "Michael Auli", "Marc'aurelio Ranzato"]}], "target_citation_location": 27, "citation_locations": [27, 34], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c01f0833-0a99-4bd6-bb28-06144c2f043d", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["Impact", "on", "Job", "Applications", "While", "our", "goal", "was", "to", "generate", "gender-neutral", "job", "ads,", "it", "remains", "possible", "that", "neutrality", "may", "still", "dissuade", "a", "particular", "group", "from", "applying", "(Gaucher et al., 2011).", "Our", "work", "cannot", "comment", "experimentally", "on", "whether", "less-biased", "ads", "at", "the", "text-level", "result", "in", "a", "greater", "diversity", "of", "applicants.", "Further", "social", "science", "and", "experimental", "research", "is", "thus", "necessary", "to", "understand", "the", "effects", "that", "language", "in", "job", "ads", "has", "on", "applications", "from", "various", "protected", "groups."], "cited_papers": [{"title": "Evidence That Gendered Wording in Job Advertisements Exists and Sustains Gender Inequality", "year": "2011", "authors": ["Danielle Gaucher", "Justin Friesen", "Aaron Kay"]}], "target_citation_location": 26, "citation_locations": [26], "citation_type": "single", "annotations": [[0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "c06a4614-803d-4d81-8ffa-3806ffa6debb", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["Concerning", "the", "use", "of", "examples", "for", "generation", "by", "'recombination',", "since", "the", "system", "is", "example-based,", "the", "issue", "here", "is", "not", "so", "much", "generation", "from", "representations", "-which", "are", "largely", "given", "a", "priori", "by", "the", "corpus", "of", "examples", "-but", "the", "capability", "of", "such", "a", "mechanism", "to", "generate", "texts", "which", "are", "not", "directly", "represented", "in", "the", "database", "of", "examples.", "The", "general", "advantages", "of", "example-based", "natural", "language", "processing", "have", "already", "been", "discussed.", "However,", "it", "is", "very", "much", "appreciated", "that", "in", "order", "for", "example-based", "systems", "to", "have", "any", "real", "degree", "of", "flexibility", "they", "must", "be", "afforded", "some", "degree", "of", "generative", "capacity", "above", "and", "beyond", "that", "supported", "by", "'static'", "individual", "examples.", "This", "increased", "flexibility", "is", "gained", "by", "matching", "against", "subcomponents", "of", "more", "than", "one", "example", "across", "the", "example", "database.", "This", "may", "occur", "when", "an", "input", "text", "does", "not", "match", "against", "one", "complete", "example", "but", "several", "examples", "match", "against", "parts", "of", "the", "input.", "Obviously", "it", "is", "important", "not", "to", "reject", "the", "input", "text", "outright", "as", "'ill-formed'", "in", "some", "way,", "but", "attempt", "to", "generate", "a", "corresponding", "'clone'", "([18])", "of", "the", "input", "based", "on", "the", "highest", "scoring", "matches", "returned", "by", "the", "matching", "process.", "There", "is", "a", "need", "for", "information", "to", "guide", "this", "process,", "and", "this", "information", "comes", "from", "the", "intentional", "model", "and", "domain", "knowledge."], "cited_papers": [{"title": "The processing of natural language by analogy with specific reference to Machine Translation", "year": "1991", "authors": ["D Jones"]}], "target_citation_location": 168, "citation_locations": [168], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "c0d5756b-1f6f-40cc-bdbb-89c5fcf6182e", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Another", "advantage", "is", "that", "it", "provides", "precomputed", "contextual", "word", "representations.", "QA", "models", "based", "on", "LSTMs", "are", "built", "on", "top", "of", "static", "word", "embeddings", "models", "such", "as", "GloVe", "(Pennington et al., 2014).", "Even", "these", "models", "have", "up", "to", "40", "times", "fewer", "parameters", "than", "a", "BERT-based", "model,", "they", "rely", "on", "LSTM-based", "encoders", "to", "produce", "contextual", "embeddings", "which", "considerably", "lengthens", "the", "time", "required", "for", "training", "and", "makes", "the", "dependence", "on", "supervised", "data", "more", "important."], "cited_papers": [{"title": "Glove: Global vectors for word representation", "year": "2014", "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning"]}], "target_citation_location": 27, "citation_locations": [27], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "c1893101-42ce-40bf-8ff7-d55b190d9ff7", "citing_paper": {"title": "Diverse dialogue generation with context dependent dynamic loss function", "year": 2020, "authors": ["Ayaka Ueyama", "Yoshinobu Kano"]}, "text": ["Japanese", "and", "English", "Twitter", "conversations", "were", "extracted", "from", "Twitter", "replies,", "adjacent", "tweets", "as", "pairs", "of", "[utterance, response]", "to", "construct", "a", "single-turn", "dialogue", "dataset", "of", "one", "million", "dialogue", "pairs", "for", "each", "language.", "SentencePiece", "(Kudo and Richardson, 2018)", "was", "trained", "using", "a", "dataset", "with", "a", "vocabulary", "of", "32,000", "for", "both", "Japanese", "and", "English", "data.", "We", "then", "used", "these", "SentencePiece", "models", "to", "tokenize", "the", "training", "set", "into", "subwords.", "Each", "of", "the", "verification", "set", "and", "the", "test", "set", "consists", "of", "1024", "pairs."], "cited_papers": [{"title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing", "year": "2018", "authors": ["Taku Kudo", "John Richardson"]}], "target_citation_location": 31, "citation_locations": [15, 31], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "c1ce5d38-b055-4ab5-8a8d-5b13fafa33c8", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["The", "above", "conditions", "are,", "of", "course,", "far", "from", "reality,", "since", "such", "a", "distance", "function,", "which", "perfectly", "corresponds", "to", "the", "mental", "representations", "of", "all", "people,", "certainly", "does", "not", "exist.", "This", "is", "clear", "from", "the", "fact", "that", "in", "classical", "association", "tests,", "where", "the", "actual", "task", "is", "to", "find", "nearest", "neighbors,", "the", "subjects", "never", "give", "the", "same", "answer", "(Palermo and Jenkins, 1964, Postman and Keppel, 2014", ").", "However,", "it", "is", "a", "meaningful", "task", "to", "create", "a", "similarity", "function", "and", "construct", "a", "similarity", "matrix", "S", "\u2208", "R", "V", "\u00d7V,", "in", "which", "S", "ij", "=", "s(w", "i,", "w", "j)", "approximates", "the", "average", "similarity", "perceived", "by", "people."], "cited_papers": [{"title": "Norms of word association", "year": "2014", "authors": ["Leo Postman", "Geoffrey Keppel"]}, {"title": "Word association norms: Grade school through college", "year": "1964", "authors": ["S David", "James J Palermo", "unk Jenkins"]}], "target_citation_location": 55, "citation_locations": [55], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c1eabee9-d646-4781-9792-01e791a0403e", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Different", "from", "the", "above", "term-based", "approaches,", "dense", "passage", "retrieval", "has", "been", "proposed", "to", "represent", "both", "questions", "and", "documents", "as", "dense", "vectors", "(i.e.,", "embeddings),", "typically", "in", "a", "dual-encoder", "architecture", "(as", "shown", "in", "Figure", "1a).", "Existing", "approaches", "can", "be", "divided", "into", "two", "categories:", "(1)", "self-supervised", "pre-training", "for", "retrieval", "(Lee et al., 2019, Guu et al., 2020, Chang et al., 2020)", "and", "(2)", "fine-tuning", "pre-trained", "language", "models", "on", "labeled", "data.", "Our", "work", "follows", "the", "second", "class", "of", "approaches,", "which", "show", "better", "performance", "with", "less", "cost.", "Although", "the", "dual-encoder", "architecture", "enables", "the", "appealing", "paradigm", "of", "dense", "retrieval,", "it", "is", "difficult", "to", "effectively", "train", "a", "retriever", "with", "such", "an", "architecture.", "As", "discussed", "in", "Section", "1,", "it", "suffers", "from", "a", "number", "of", "challenges,", "including", "the", "training", "and", "inference", "discrepancy,", "a", "large", "number", "of", "unlabeled", "positives", "and", "limited", "training", "data.", "Several", "recent", "studies", "(Karpukhin et al., 2020, Luan et al., 2020, Chang et al., 2020, Henderson et al., 2017)", "tried", "to", "address", "the", "first", "challenge", "by", "designing", "complicated", "sampling", "mechanism", "to", "generate", "hard", "negatives.", "However,", "it", "still", "suffers", "from", "the", "issue", "of", "false", "negatives.", "The", "later", "two", "challenges", "have", "seldom", "been", "considered", "for", "open-domain", "QA."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "REALM: retrievalaugmented language model pre-training", "year": "2002", "authors": ["Kelvin Guu", "Kenton Lee", "Zora Tung", "Panupong Pasupat", "Ming-Wei Chang"]}], "target_citation_location": 46, "citation_locations": [46, 125], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c1fa5f2f-dad1-4ed5-8a8b-7ddb86c29fa9", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["Recently", "researchers", "in", "statistical", "machine", "translation", "have", "developed", "methods", "to", "move", "beyond", "single", "word", "alignments", "and", "create", "richer", "translation", "models", "that", "contain", "phrasal", "alignments", "(Och and Ney, 2004).", "The", "general", "method", "is", "to", "induce", "single", "word", "alignments", "using", "maximum", "likelihood", "estimates", "obtained", "from", "parallel", "data", "such", "as", "by", "IBM", "Model", "1", "(Brown et al., 1993)", "and", "to", "use", "these", "alignments", "to", "suggest", "adjacent", "words", "that", "may", "compose", "a", "meaningful", "phrase.", "By", "examining", "bidirectional", "alignments", "for", "the", "same", "parallel", "data", "a", "'symmetrized", "alignment", "matrix'", "can", "be", "obtained,", "and", "from", "this", "information", "potential", "translations", "of", "word", "sequences", "can", "be", "obtained.", "As", "long", "as", "contiguous", "sequences", "are", "examined", "it", "does", "not", "matter", "if", "the", "two", "languages", "have", "different", "word", "order.", "The", "approach", "can", "be", "further", "generalized", "by", "working", "with", "word", "classes", "so", "that", "hypotheses", "for", "unseen", "phrases", "can", "be", "generated."], "cited_papers": [{"title": "The mathematics of statistical machine translation", "year": "1993", "authors": ["P Brown", "S Della Pietra", "V Della Pietra", "R Mercer"]}], "target_citation_location": 48, "citation_locations": [24, 48], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c2434e48-43c7-45ee-b934-29e84b1d73c8", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["During", "fine-tuning,", "for", "each", "data", "point", "in", "the", "original", "batch", "(B", "o)", "of", "size", "n,", "we", "pick", "one", "of", "its", "corresponding", "translations", "uniformly", "at", "random", "and", "form", "a", "translated", "batch", "(B", "p)", "of", "the", "same", "size", "n.", "It", "is", "important", "to", "note", "that", "B", "o", "itself", "is", "taken", "from", "the", "combined", "dataset", "of", "source", "instances", "and", "translated", "instances.", "The", "two", "batches", "that", "form", "a", "pair", "are", "denoted", "as", "original", "batch", "and", "pair", "batch,", "respectively,", "in", "Figure", "4.", "We", "use", "the", "same", "mBERT", "network", "up", "to", "a", "specific", "layer", "as", "our", "encoder", "(enc)", "to", "transform", "B", "o", "and", "B", "p", "to", "get", "the", "embeddings,", "E", "o,", "E", "p", "\u2208", "R", "n", "*", "t", "*", "d,", "respectively.", "Then,", "we", "apply", "a", "global", "average", "pooling", "(gap)", "operation", "to", "aggregate", "the", "vector", "representations", "of", "t", "tokens", "into", "a", "single", "vector", "representation", "of", "dimension", "d", "for", "each", "instance", "in", "each", "batch.", "This", "will", "result", "in", "the", "aggregated", "embeddings", "O,", "P", "\u2208", "R", "n", "*", "d", "for", "B", "o", "and", "B", "p,", "respectively.", "With", "these", "n", "feature", "vectors", "in", "the", "original", "and", "the", "translated", "batch,", "we", "follow", "the", "CLIP", "(Radford et al., 2021)", "approach", "and", "compute", "the", "contrastive", "loss", "using", "the", "cross-entropy", "loss", "(L", "ce", ").", "Specifically,", "we", "multiply", "the", "matrices", "O", "and", "P", "T", "to", "get", "the", "logits", "matrix", "Q", "\u2208", "R", "n", "*", "n.", "Then,", "we", "apply", "the", "cross-entropy", "loss", "L", "ce", "row-wise", "and", "column-wise", "to", "the", "logits", "matrix", "Q,", "with", "its", "diagonal", "locations", "as", "original", "classes", "for", "each", "row", "and", "column,", "respectively.O", "=", "gap(enc(B", "o", ")),(2)"], "cited_papers": [{"title": "Learning transferable visual models from natural language supervision", "year": "2021", "authors": ["Alec Radford", "Jong Kim", "Chris Hallacy", "Aditya Ramesh", "Gabriel Goh", "Sandhini Agarwal", "Girish Sastry", "Amanda Askell", "Pamela Mishkin", "Jack Clark"]}], "target_citation_location": 183, "citation_locations": [183], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "c2870237-481d-4ad7-8033-2f7e3b173c1e", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["The", "LIGHT", "Questing", "Environment.", "The", "LIGHT", "game", "environment", "(Urbanek et al., 2019)", "1", "is", "a", "multi-user", "fantasy", "text-adventure", "game", "consisting", "of", "a", "rich,", "diverse", "set", "of", "1775", "characters,", "663", "locations,", "and", "3462", "objects.", "Characters", "are", "able", "to", "perform", "templated", "actions", "to", "interact", "with", "both", "objects", "and", "characters,", "and", "can", "speak", "to", "other", "characters", "through", "free", "form", "text", "dialogues.", "Actions", "in", "text", "games", "generally", "consist", "of", "verb", "phrases", "(VP)", "followed", "optionally", "by", "prepositional", "phrases", "(VP", "PP).", "For", "example,", "get", "OBJ,", "put", "OBJ,", "give", "OBJ", "to", "CHAR,", "etc..", "These", "actions", "change", "the", "state", "of", "the", "world", "which", "is", "expressed", "through", "text", "descriptions."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c2b7e0ae-6f8b-40a4-9b4c-35279921651b", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["Monolingual", "and", "bilingual", "dictionaries", "were", "constructed", "using", "a", "large", "bilingual", "word", "list", "of", "unchecked", "quality.", "Paradigms", "were", "hand-written", "according", "to", "(Topori\u0161i\u010d, 2000)."], "cited_papers": [{"title": "Slovenska slovnica", "year": "2000", "authors": ["J Topori\u0161i\u010d"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1]]}
{"id": "c33bdda7-a739-471b-87e3-7516f6d2e7b7", "citing_paper": {"title": "Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets", "year": 2021, "authors": ["George-Andrei Dima", "Dumitru-Clementin Cercel", "Mihai Dascalu"]}, "text": ["Given", "that", "Task", "1", "was", "present", "in", "previous", "editions", "of", "the", "SMM4h", "shared", "task", "(Weissenbacher et al., 2018 (Weissenbacher et al., , 2019,, Klein et al., 2020),", "several", "approaches", "were", "employed", "to", "address", "its", "challenges.", "For", "example,", "the", "winning", "team", "from", "2019", "(Miftahutdinov et al., 2019)", "used", "an", "ensemble", "of", "BioBERT-CRF", "models", "for", "the", "ADE", "extraction", "task,", "while", "addressing", "the", "resolution", "task", "as", "a", "classification.", "The", "system", "proposed", "by", "Miftahutdinov et al. (2020)", "ranked", "first", "at", "the", "end-to-end", "2020", "competition", "using", "the", "pretrained", "EnDR-BERT", "(Tutubalina et al., 2020)", "and", "the", "CSIRO", "Adverse", "Drug", "Event", "Corpus", "(CADEC)", "(Karimi et al., 2015)", "for", "further", "training", "the", "model.", "In", "addition,", "Dima et al. (2020)", "showed", "that", "bidirectional", "Transformers", "trained", "using", "class", "weighting,", "together", "with", "ensembles", "that", "combine", "various", "configurations,", "achieve", "an", "F1-score", "of", ".705", "on", "the", "dataset", "made", "available", "for", "that", "edition", "of", "the", "competition."], "cited_papers": [{"title": "Approaching smm4h 2020 with ensembles of bert flavours", "year": "2020", "authors": ["George-Andrei Dima", "Andrei-Marius Avram", "Dumitru-Clementin Cercel"]}], "target_citation_location": 83, "citation_locations": [14, 30, 54, 66, 75, 83], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "c39660ac-2608-4255-b784-aed65067488c", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["Proximity-based", "features", "Traditional", "retrieval", "models", "assume", "terms", "are", "independent", "and", "ignore", "their", "relationships,", "but", "the", "proximity", "among", "query", "terms", "often", "serves", "as", "an", "important", "relevance", "signal.", "Thus,", "we", "include", "features", "that", "directly", "capture", "the", "proximity", "of", "query", "terms,", "such", "as", "the", "counts", "of", "ordered", "and", "unordered", "co-occurrence", "of", "bigrams", "within", "different", "window", "sizes.", "We", "compute", "the", "scores", "of", "proximity-based", "retrieval", "functions,", "such", "as", "SDM", "(Metzler and Croft, 2005, Gallagher et al., 2020)", "and", "BM25-TP", "(Lu et al., 2015, Gallagher et al., 2020),", "as", "our", "features."], "cited_papers": [{"title": "On the cost of extracting proximity features for term-dependency models", "year": "2015", "authors": ["Xiaolu Lu", "Alistair Moffat", "J Culpepper"]}, {"title": "Feature extraction for large-scale text collections", "year": "2020", "authors": ["Luke Gallagher", "Antonio Mallia", "J Culpepper", "Torsten Suel", "B Barla Cambazoglu"]}], "target_citation_location": 67, "citation_locations": [64, 67], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2, 2]]}
{"id": "c3e81620-6b45-44d5-959e-00e3e5f04b38", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["improves", "the", "performance", "on", "some", "coreferencerelated", "datasets", "(Wu et al., 2020b, Aralikatte et al., 2019).", "There", "are", "also", "various", "datasets", "for", "the", "task", "of", "reading", "comprehension", "on", "which", "the", "model", "requires", "to", "perform", "coreference", "reasoning", "to", "answer", "some", "of", "the", "questions,", "e.g.,", "DROP", "(Dua et al., 2019),", "DuoRC", "(Saha et al., 2018),", "MultiRC", "(Khashabi et al., 2018),", "etc."], "cited_papers": [{"title": "Looking beyond the surface: A challenge set for reading comprehension over multiple sentences", "year": "2018", "authors": ["Daniel Khashabi", "Snigdha Chaturvedi", "Michael Roth", "Shyam Upadhyay", "Dan Roth"]}], "target_citation_location": 40, "citation_locations": [7, 36, 38, 40], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 0]]}
{"id": "c3ffb89d-9303-40e8-b997-5f507d45e8d9", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["Previous", "annotation", "tasks", "have", "shown", "that", "even", "with", "binary", "or", "ternary", "classification", "schemes,", "human", "annotators", "agree", "only", "about", "70-80%", "of", "the", "time", "and", "the", "more", "categories", "there", "are,", "the", "harder", "it", "becomes", "for", "annotators", "to", "agree", "(Boland et al., 2013, Mozeti\u010d et al., 2016).", "For", "example,", "when", "creating", "the", "DENS", "dataset", "(Liu et al., 2019),", "only", "21%", "of", "their", "annotations", "had", "consensus", "between", "all", "annotators", "with", "73.5%", "having", "to", "resort", "to", "majority", "agreement,", "and", "a", "further", "5.5%", "could", "not", "be", "agreed", "upon", "and", "were", "left", "to", "expert", "annotators", "to", "be", "resolved."], "cited_papers": [{"title": "Creating an Annotated Corpus for Sentiment Analysis of German Product Reviews", "year": "2013", "authors": ["Katarina Boland", "Andias Wira-Alam", "Reinhard Messerschmidt"]}, {"title": "Multilingual twitter sentiment classification: The role of human annotators", "year": "2016", "authors": ["Igor Mozeti\u010d", "Miha Gr\u010dar", "Jasmina Smailovi\u0107"]}], "target_citation_location": 36, "citation_locations": [36, 44], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c45aa521-f82c-446c-a9db-f13595450d2c", "citing_paper": {"title": "NEW TABULAR ALGORITHMS FOR LIG PARSING", "year": 2000, "authors": ["Mi G Uel Alonso Jor G E Grana", "Manuel Vilares"]}, "text": ["To", "parse", "this", "type", "of", "grammars,", "tabulation", "techniques", "with", "polynomial", "complexity", "can", "be", "designed", "based", "on", "a", "property", "defined", "in", "[17],", "that", "we", "call", "context-freeness", "property", "of", "LIG,", "establishing", "that", "ifA[,]", "\u21d2", "uB[", "]w", "where", "u,", "w", "E", "v,,", "A,", "B", "E", "VN,,", "E", "Vi", "U", "{\u20ac}", "and", "B[]", "is", "a", "dependent", "descendant", "of", "A[,],", "then", "for", "each", "Yi,", "Y2", "E_", "(VN[Vt]", "U", "VT", ")*and", "/3", "E", "V/", "we", "have", "Y1", "A[/3,]Y2", "\u21d2", "Y1uB[,B]wY2.", "Also,", "if", "B[,]", "is", "a", "dependent", "descendant", "of", "A[]", "and", "A[]", "\u21d2", "uB[,]w", "then", "Y", "1", "A[/3]Y", "2", "\u21d2", "Y", "1", "uB", "[/3,]wY", "2."], "cited_papers": [{"title": "We ir. 1993. Parsing some constrained grammar formalisms. Co m putational Linguistics", "year": null, "authors": ["K Vijay-Shanker", "D unk"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c45ea55b-d55f-4611-bafa-d55298cc8345", "citing_paper": {"title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables", "year": 2022, "authors": ["Nan Hu", "Zirui Wu", "Yuxuan Lai", "Xiao Liu", "Yansong Feng"]}, "text": ["Fact", "Verification", "over", "Structured", "and", "Unstructured", "Evidence", "FEVEROUS", "(Aly et al., 2021)", "is", "the", "first", "dataset", "of", "fact", "verification", "on", "structured", "and", "unstructured", "evidence.", "Many", "previous", "works", "follow", "the", "baseline", "settings", "and", "convert", "all", "evidence", "to", "text", "format", "to", "perform", "evidence", "interaction.", "They", "transform", "each", "cell", "to", "header-value", "pairs", "(Aly et al., 2021, Malon, 2021)", "or", "in", "a", "cell", "location", "indication", "type", "(Kotonya et al., 2021a).", "They", "pay", "less", "attention", "to", "making", "the", "converted", "text", "more", "consistent", "with", "natural", "language", "expressions", "or", "identifying", "what", "the", "context", "cells", "represent.", "Bouziane et al. (2021)", "propose", "to", "convert", "all", "evidence", "to", "tables.", "They", "simply", "convert", "each", "sentence", "to", "a", "2-cell", "table", "with", "the", "Wikipedia", "title", "and", "itself", "instead", "of", "packing", "closely-tied", "evidence", "and", "building", "a", "global", "evidence", "table.", "There", "are", "also", "works", "focusing", "on", "the", "first", "two", "steps", "two", "improve", "the", "final", "results.", "Saeed et al. (2021)", "propose", "to", "add", "a", "document", "re-ranker", "to", "strengthen", "the", "document", "retrieval.", "Multi-hop", "Dense", "Retriever", "(Bouziane et al., 2021)", "and", "T5", "generator", "(Malon, 2021)", "are", "introduced", "to", "better", "extract", "multi-hop", "evidence."], "cited_papers": [{"title": "Feverous: Fact extraction and verification over unstructured and structured information", "year": "2021", "authors": ["Rami Aly", "Zhijiang Guo", "M Schlichtkrull", "James Thorne"]}], "target_citation_location": 8, "citation_locations": [8, 46, 54, 77, 126, 141, 145], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c4982e58-c244-41ba-a6c1-7883e8d1fe83", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["In", "this", "paper,", "we", "introduce", "our", "system", "for", "the", "lexical", "complexity", "prediction", "task", "of", "the", "SemEval-2021", "(Matthew et al., 2021).", "We", "fulfill", "this", "task", "by", "leveraging", "multiple", "pre-trained", "language", "models", "(PLM)", "with", "different", "training", "strategies.", "There", "are", "two", "main", "steps", "for", "our", "system:", "(i)", "fine-tuning", "numbers", "of", "heterogeneous", "PLMs,", "including", "BERT", "(Devlin et al., 2019),", "ALBERT", "(Lan et al., 2019),", "RoBERTa", "(Liu et al., 2019)", "and", "ERNIE", "(Zhang et al., 2019),", "with", "various", "hyperparameters", "and", "training", "strategies,", "obtaining", "diverse", "models,", "(ii)", "applying", "an", "effective", "stacking", "mechanism", "on", "top", "of", "these", "PLMs", "to", "predict", "the", "final", "complexity", "scores."], "cited_papers": [{"title": "ALBERT: A lite BERT for self-supervised learning of language representations", "year": "2019", "authors": ["Zhenzhong Lan", "Mingda Chen", "Sebastian Goodman", "Kevin Gimpel", "Piyush Sharma", "Radu Soricut"]}], "target_citation_location": 50, "citation_locations": [16, 48, 50, 52, 55], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "c4d30f90-45e1-4460-b739-fab1505a3944", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["Constructing", "long", "inference", "chains", "can", "be", "extremely", "challenging", "for", "existing", "models,", "which", "generally", "exhibit", "a", "large", "drop", "in", "performance", "when", "composing", "explanations", "and", "inference", "chains", "requiring", "more", "than", "2", "inference", "steps", "(Fried et al., 2015, Jansen et al., 2017 Jansen et al., , 2018,, Khashabi et al., 2019, Yadav et al., 2020).", "To", "this", "end,", "this", "Shared", "Task", "on", "Multi-hop", "Inference", "for", "Explanation", "Regeneration", "(Jansen and Ustalov, 2019, 2020)", "has", "focused", "on", "expanding", "the", "capacity", "of", "models", "to", "compose", "long", "inference", "chains,", "where", "participants", "are", "asked", "to", "develop", "systems", "capable", "of", "reconstructing", "detailed", "explanations", "for", "science", "exam", "questions", "drawn", "from", "the", "WorldTree", "explanation", "corpus", "(Xie et al., 2020, Jansen et al., 2018),", "which", "range", "in", "compositional", "complexity", "from", "1", "to", "16", "facts", "(with", "the", "average", "explanation", "including", "6", "facts)."], "cited_papers": [{"title": "WorldTree V2: A Corpus of Science-Domain Structured Explanations and Inference Patterns supporting Multi-Hop Inference", "year": "2020", "authors": ["Zhengnan Xie", "Sebastian Thiem", "Jaycie Martin", "Elizabeth Wainwright", "Steven Marmorstein", "Peter Jansen"]}, {"title": "WorldTree: A Corpus of Explanation Graphs for Elementary Science Questions supporting Multi-hop Inference", "year": "2018", "authors": ["Peter Jansen", "Elizabeth Wainwright", "Steven Marmorstein", "Clayton Morrison"]}], "target_citation_location": 80, "citation_locations": [31, 44, 80], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "c4e8d6e3-8fdb-4fdb-8b24-dfdf26c3e310", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["Visual", "Entailment", "(VE):", "VE", "task", "aims", "to", "predict", "whether", "an", "image", "semantically", "entails", "the", "text", "and", "requires", "fine-grained", "reasoning", "ability", "in", "a", "model.", "VE", "dataset", "is", "built", "upon", "SNLI", "(Bowman et al., 2015)", "and", "Flickr30k.", "Each", "image-text", "pair", "is", "assigned", "with", "one", "of", "three", "classes:", "entailment,", "neutral,", "contradiction.", "As", "in", "UNITER,", "we", "formulate", "it", "as", "3-way", "classification", "problem", "based", "on", "h", "cls.", "The", "batch", "size", "is", "32", "per", "GPU", "while", "other", "finetuning", "strategies", "are", "the", "same."], "cited_papers": [{"title": "A large annotated corpus for learning natural language inference", "year": "2015", "authors": ["Gabor Samuel R Bowman", "Christopher Angeli", "Christopher D Potts", "unk Manning"]}], "target_citation_location": 29, "citation_locations": [29], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c4f927ee-8350-45e8-86e6-47de9f29c88e", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["To", "model", "such", "indirect", "connections,", "we", "multiply", "the", "relatedness", "matrix", "by", "itself,", "and", "use", "the", "values", "of", "the", "squared", "matrix", "S", "\u2032", "as", "the", "relatedness", "measure", "between", "two", "words.", "By", "the", "definition", "of", "matrix", "multiplication,S", "\u2032", "ij", "=", "n", "k=1", "s", "i,k", "s", "k,j", ",that", "is,", "if", "we", "define", "G", "0", "as", "a", "graph", "whose", "neighborhood", "matrix", "is", "the", "NPMI", "matrix", "then", "S", "\u2032", "ij", "is", "the", "sum", "of", "the", "product", "of", "the", "weights", "on", "all", "two-length", "paths", "v", "i", "\u2212", "v", "k", "\u2212", "v", "j", "in", "G", "0.", "Since", "all", "edge", "weights", "are", "between", "0", "and", "1,", "considering", "the", "weight", "of", "a", "path", "as", "the", "product", "of", "its", "edge", "weights", "gives", "a", "valid", "relatedness", "measure:", "longer", "paths", "and", "paths", "that", "contain", "smaller", "weights", "will", "yield", "to", "smaller", "relatedness", "values.", "Artetxe et al. (2018)", "also", "showed", "on", "word", "embeddings,", "that", "different", "powers", "of", "embedding", "matrices", "are", "beneficial", "for", "word", "similarity", "and", "word", "relatedness", "tasks,", "and", "that", "the", "optimal", "power", "is", "higher", "for", "relatedness", "than", "for", "similarity."], "cited_papers": [{"title": "Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrinsic evaluation", "year": "2018", "authors": ["Mikel Artetxe", "Gorka Labaka", "I\u00f1igo Lopez-Gazpio", "Eneko Agirre"]}], "target_citation_location": 130, "citation_locations": [130], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "c5cf19ad-0bff-4b2a-9222-92ec756ac0e8", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["For", "trace", "feature,", "we", "use", "\u03c4", "=", "0.4s", "to", "extract", "trace", "segment", "for", "feature", "extraction.", "The", "embedding", "size", "d,", "number", "of", "transformer", "layers,", "hidden", "size", "of", "the", "transformer", "feed-forward", "layer", "are", "768,", "2,", "and", "768,", "respectively.", "The", "number", "of", "attention", "heads", "is", "8,", "and", "the", "dropout", "rate", "is", "0.1.", "We", "adopt", "the", "Adam-W", "optimizer", "(Loshchilov and Hutter, 2019)", "with", "learning", "rate", "of", "7e-4(which", "is", "the", "best", "performance", "setting", "of", "baseline,", "and", "adopted", "widely", "for", "other", "trials),", "and", "set", "two", "momentum", "parameters", "\u03b2", "1", "=", "0.9", "and", "\u03b2", "2", "=", "0.99.", "We", "set", "the", "batch", "size", "to", "256.", "All", "models", "are", "trained", "on", "4", "Tesla", "V100", "GPUs", "with", "32GB", "memory", "for", "10", "to", "12", "hours."], "cited_papers": [{"title": "Decoupled weight decay regularization", "year": "2019", "authors": ["Ilya Loshchilov", "Frank Hutter"]}], "target_citation_location": 54, "citation_locations": [54], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "c6821ffc-c5ac-493b-9a7f-fb86cad58859", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["We", "propose", "a", "three-stage", "pipeline", "called", "Multilingual", "Constrative", "Training", "(MuCoT)", "to", "effectively", "train", "the", "mBERT", "model", "for", "question-answering", "in", "low-resource", "languages.", "An", "illustration", "of", "this", "pipeline", "for", "two", "low-resource", "languages,", "namely", "Tamil", "and", "Hindi,", "is", "shown", "in", "Figure", "3.", "The", "first", "stage", "is", "pre-training", "the", "baseline", "multilingual", "model", "(mBERT).", "The", "second", "stage", "involves", "pre-training", "the", "QA", "head", "using", "the", "large-scale", "dataset(s)", "in", "high", "resource", "language(s).", "In", "Figure", "3,", "English", "is", "considered", "the", "high-resource", "language", "and", "SQuAD", "(Rajpurkar et al., 2016)", "dataset", "is", "used", "to", "pre-train", "the", "QA", "head", "and", "obtain", "the", "mBERT-QA", "model.", "The", "final", "stage", "involves", "fine-tuning", "the", "mBERT-QA", "model", "using", "both", "original", "and", "augmented", "samples", "from", "the", "target", "low-resource", "languages.", "In", "this", "work,", "ChAII", "(Google, 2021)", "dataset", "is", "used", "for", "obtaining", "training", "samples", "in", "Tamil", "and", "Hindi."], "cited_papers": [{"title": "ChAII -Hindi and Tamil question answering", "year": "2021", "authors": ["unk Google"]}], "target_citation_location": 113, "citation_locations": [76, 113], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "c6c13533-48e8-456a-a244-4f2f05252078", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Another", "graph,", "created", "as", "an", "alternative", "for", "word", "embeddings,", "is", "GraphGlove", "(Ryabinin et al., 2020),", "where", "the", "edges", "of", "the", "graph", "are", "optimized", "by", "the", "cost", "function", "of", "GloVe", "(Pennington et al., 2014b),", "so", "that", "the", "shortest", "path", "between", "two", "vertices", "gives", "the", "distance", "of", "the", "corresponding", "words."], "cited_papers": [{"title": "Glove: Global vectors for word representation", "year": "2014", "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning"]}], "target_citation_location": 26, "citation_locations": [11, 26], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "c782ec57-4a75-47d8-91f4-8f65bf69ea65", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["Recent", "studies", "show", "that", "NLP", "models", "are", "vulnerable", "to", "adversarial", "perturbations.", "A", "seemingly", "\"invariance", "transformation\"", "(a.k.a.", "adversarial", "perturbation)", "such", "as", "synonym", "substitutions", "(Alzantot et al., 2018, Zang et al., 2020)", "or", "syntax-guided", "paraphrasing", "(Iyyer et al., 2018, Huang and Chang, 2021)", "can", "alter", "the", "prediction.", "To", "mitigate", "the", "model", "vulnerability,", "robust", "training", "methods", "have", "been", "proposed", "and", "shown", "effective", "(Miyato et al., 2017, Jia et al., 2019, Huang et al., 2019, Zhou et al., 2020)."], "cited_papers": [{"title": "Word-level textual adversarial attacking as combinatorial optimization", "year": "2020", "authors": ["Yuan Zang", "Fanchao Qi", "Chenghao Yang", "Zhiyuan Liu", "Meng Zhang", "Qun Liu", "Maosong Sun"]}, {"title": "Generating natural language adversarial examples", "year": "2018", "authors": ["Moustafa Alzantot", "Yash Sharma", "Ahmed Elgohary", "Bo-Jhang Ho", "Mani Srivastava", "Kai-Wei Chang"]}], "target_citation_location": 22, "citation_locations": [22, 26, 45], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c8dfb5ed-c3d5-4af5-ae7e-8ec57034cb57", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["While", "manual,", "human", "evaluation", "of", "machine", "translation", "(MT)", "systems", "is", "still", "the", "gold", "standard,", "automatic", "evaluation", "metrics", "have", "long", "been", "used", "for", "their", "relative", "speed", "and", "inexpensiveness.", "Early", "automatic", "metrics", "were", "easy", "to", "implement", "and", "somewhat", "correlated", "with", "human", "judgements,", "but", "have", "clear", "limitations:", "BLEU", "(Papineni et al., 2002)", "relies", "on", "n-gram", "overlap,", "and", "is", "thus", "not", "robust", "to", "differing", "word", "order", "or", "choice.", "In", "contrast,", "ME-TEOR", "(Lavie and Agarwal, 2007)", "requires", "training,", "but", "depends", "on", "token", "alignment,", "which", "is", "also", "a", "fraught", "task."], "cited_papers": [{"title": "Bleu: a method for automatic evaluation of machine translation", "year": "2002", "authors": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu"]}], "target_citation_location": 45, "citation_locations": [45, 64], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "c8e1a2b9-62ed-4aff-bcbd-079acade107c", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["Using", "CCG", "categories", "to", "label", "non-terminals", "in", "HPB", "rules", "can", "produce", "better", "translation", "quality", "and", "smaller", "trans-lation", "models", "in", "comparison", "with", "SAMT", "[12].", "CCG", "nonterminal", "labels", "are", "less", "sparse", "and", "represent", "richer", "and", "more", "accurate", "syntactic", "constraints", "compared", "to", "SAMT", "nonterminal", "labels", "[12]."], "cited_papers": [{"title": "CCG augmented hierarchical phrase-based machine translation", "year": "2010", "authors": ["H Almaghout", "J Jiang", "A Way"]}], "target_citation_location": 22, "citation_locations": [22, 42], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "c8f9e443-f9ed-44c7-8743-e433bc231276", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Considering", "the", "previous", "results", "on", "the", "relationship", "between", "associations", "and", "co-occurrences", "(Spence", "and", "Owens, 1990, Shen et al., 2018),", "we", "create", "our", "distance", "matrices", "not", "from", "the", "latest", "neural", "methods", "of", "NLP,", "but", "from", "co-occurrences", "counted", "1", "The", "game:", "http://spymasters.herokuapp.com/", "Source", "code", "and", "data:", "https://github.com/xerevity/", "CodeNamesAgent", "in", "raw", "text.", "As", "English", "corpora", "we", "use", "the", "concatenation", "of", "the", "English", "Wikipedia", "and", "the", "English", "OpenSubtitles", "corpus,", "consisting", "of", "5.692", "billion", "tokens", "in", "total.", "For", "Hungarian,", "we", "use", "the", "lemmatized", "version", "of", "the", "Hungarian", "Webcorpus", "(Nemeskey,", "2020),", "also", "including", "the", "Hungarian", "Wikipedia", "(1.414", "billion", "tokens).", "We", "work", "with", "vocabulary", "sizes", "15K", "in", "English", "and", "10K", "in", "Hungarian,", "and", "remove", "stopwords."], "cited_papers": [{"title": "Comparing models of associative meaning: An empirical investigation of reference in simple language games", "year": "2018", "authors": ["Matthias Judy Hanwen Shen", "Bjarke Hofer", "Roger Felbo", "unk Levy"]}, {"title": "Lexical co-occurrence and association strength", "year": "1990", "authors": ["P Donald", "Kimberly Spence", "unk Owens"]}], "target_citation_location": 13, "citation_locations": [13], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "c8feb0eb-e4da-47df-9bd2-f72f75072d86", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["The", "train", "data", "have", "been", "extracted", "from", "different", "domains", "and", "sources,", "which", "are", "not", "necessarily", "the", "same", "as", "the", "evaluation", "sets", "provided", "for", "the", "Shared", "Task.", "Therefore,", "the", "official", "development", "set", "(995", "sentences", "per", "language)", "is", "split", "into", "three", "parts:", "25%-25%-50%.", "The", "first", "two", "parts", "are", "our", "custom", "dev", "and", "devtest", "sets", "3.", "We", "add", "the", "50%", "section", "to", "the", "training", "set", "with", "a", "sampling", "distribution", "of", "20%,", "to", "reduce", "the", "domain", "gap", "in", "the", "training", "data.", "Likewise,", "we", "extract", "a", "sample", "of", "the", "training", "and", "double", "the", "size", "of", "the", "development", "set.", "The", "mixed", "data", "in", "the", "validation", "set", "is", "relevant,", "as", "it", "allows", "to", "evaluate", "how", "the", "model", "fits", "with", "all", "the", "domains.", "We", "used", "the", "same", "multi-text", "sentences", "for", "evaluation,", "and", "avoid", "any", "overlapping", "of", "the", "Spanish", "side", "with", "the", "training", "set,", "this", "is", "also", "important", "as", "we", "are", "going", "to", "evaluate", "multilingual", "models.", "Evaluation", "for", "all", "the", "models", "used", "BLEU", "(Papineni et al., 2002)", "and", "chrF", "(Popovi\u0107, 2015)", "metrics."], "cited_papers": [{"title": "Bleu: a method for automatic evaluation of machine translation", "year": "2002", "authors": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu"]}], "target_citation_location": 154, "citation_locations": [154, 157], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3]]}
{"id": "c92274f4-90eb-4d64-96a6-35fbac37acac", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["We", "evaluate", "our", "experiments", "on", "the", "English", "to", "French", "Spoken", "Language", "Translation", "task", "from", "IWSLT", "2015", "evaluation", "campaign", "3.", "A", "data", "selection", "method", "[18]", "consisting", "on", "scoring", "the", "sentences", "according", "to", "a", "in-domain", "language", "model", "has", "been", "applied.", "We", "have", "used", "as", "available", "parallel", "corpora", "(news-commentary,", "united-nations,", "europarl,", "wikipedia,", "and", "two", "crawled", "corpora)", "and", "Technology", "Entertainment", "Design", "(TED", "4)", "corpus", "as", "in-domain", "corpus.", "The", "data", "selection", "allows", "us", "to", "train", "the", "models", "in", "a", "faster", "way", "taking", "into", "account", "the", "sentences", "which", "contain", "relevant", "information", "of", "the", "domain", "and", "avoids", "noisy", "data.", "We", "also", "did", "a", "preprocessing", "to", "convert", "html", "entities", "and", "filter", "out", "the", "sentences", "with", "more", "than", "50", "words", "for", "both", "source", "and", "target", "languages.", "We", "finally", "end", "up", "with", "a", "selected", "corpus", "of", "2M", "sentences", "(50.5", "millions", "of", "words),", "leading", "to", "147K", "unique", "tokens", "for", "English", "side", "and", "266K", "unique", "tokens", "for", "French", "side."], "cited_papers": [{"title": "XenC: An open-source tool for data selection in natural language processing", "year": "2013", "authors": ["A Rousseau"]}], "target_citation_location": 23, "citation_locations": [23], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "ca45ebfe-fa15-4881-85ae-cadd9bba63ac", "citing_paper": {"title": "Associating semantic components with intersective Levin classes", "year": 1997, "authors": ["Hoa Dang", "Joseph Rosenzweig", "Martha Palmer"]}, "text": ["Two", "current", "approaches", "to", "English", "verb", "classifications", "are", "WordNet", "synonym", "sets", "[9]", "and", "Levin", "classes", "[8].", "WordNet", "is", "an", "on-line", "lexical", "database", "of", "English", "that", "currently", "contains", "about", "120,000", "sets", "of", "noun,", "verb", "adjective,", "and", "adverb", "synonyms,", "each", "representing", "a", "lexicalized", "concept.", "A", "synset", "(synonym", "set)", "contains", "besides", "all", "the", "word", "forms", "that", "can", "refer", "to", "a", "given", "concept,", "a", "definitional", "gloss", "and", "-in", "most", "cases", "-an", "example", "sentence.", "Words", "and", "synsets", "are", "interrelated", "by", "means", "of", "lexical", "and", "semantic-conceptual", "links,", "respectively.", "Antonymy", "or", "semantic", "opposition", "links", "individual", "words,", "while", "the", "super-/subordinate", "relation", "links", "entire", "synsets.", "WordNet", "was", "designed", "principally", "as", "a", "semantic", "network,", "and", "contains", "little", "syntactic", "information."], "cited_papers": [{"title": "Five papers on wordnet", "year": "1990", "authors": ["G Miller", "R Beckwith", "C Fellbaum", "D Gross", "K Miller"]}], "target_citation_location": 11, "citation_locations": [11, 15], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "caad037e-0200-4b18-8588-4625e5521b5a", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["(2)", "a.", "sing", "song", "b.", "fleur", "floral", "Hockett (1954)", "outlines", "two", "models", "of", "describing", "what", "we", "can", "observe", "in", "these", "examples.", "In", "the", "Item", "and", "Arrangement", "(IA)", "model,", "(1a)", "is", "the", "combination", "of", "a", "stem", "clear", "and", "a", "prefix", "un.", "This", "combination", "results", "in", "the", "concatenation", "of", "the", "two", "forms", "and", "the", "compositional", "combination", "of", "syntactic", "and", "semantic", "properties.", "In", "(1a)", "the", "result", "is", "a", "form", "unclear", "with", "the", "syntactic", "category", "Adjective", "and", "the", "meaning", "of", "an", "antonym", "of", "clear.", "The", "examples", "in", "(2)", "require", "additional", "rules", "to", "modify", "the", "stem.", "In", "(2a),", "stem", "vowel", "change", "is", "the", "only", "thing", "marking", "the", "difference", "between", "the", "two", "words.", "The", "alternative", "model", "is", "called", "Item", "&amp,", "Process", "(IP).", "In", "this", "model,", "word", "formation", "rules", "are", "processes", "applying", "to", "a", "base.", "In", "(1a),", "the", "process", "adds", "un", "to", "the", "left", "of", "the", "stem", "clear.", "In", "(2a),", "the", "process", "changes", "the", "stem", "vowel", "of", "sing.", "In", "IP", "there", "are", "no", "morphemes", "but", "only", "lexemes", "and", "processes.", "In", "modern", "morphological", "theories", "both", "are", "represented,", "e.g.", "Lieber (1992)", "for", "IA", "and", "Anderson (1992)", "for", "IP.", "An", "important", "difference", "for", "our", "purposes", "is", "that", "in", "IA", "we", "have", "a", "tree", "structure", "whereas", "in", "IP", "we", "have", "a", "derivation", "history.", "A", "tree", "structure", "represents", "the", "relationship", "between", "morphemes,", "e.g.", "(3).", "A", "derivation", "history", "lists", "the", "different", "stages", "rules", "applying,", "e.g.", "(4).", "It", "should", "be", "noted", "that", "there", "are", "many", "variants", "of", "IA", "and", "IP.", "The", "reason", "we", "are", "interested", "in", "word", "formation", "rules", "is", "their", "productivity.", "Productivity", "is", "a", "difficult", "and", "controversial", "concept,", "cf.", "Bauer (2001).", "Basically,", "a", "productive", "word", "formation", "rule", "can", "be", "used", "to", "produce", "new", "lexical", "items.", "When", "a", "speaker", "has", "a", "productive", "word", "formation", "rule", "at", "her", "disposal,", "she", "can", "use", "a", "word", "not", "in", "her", "mental", "lexicon", "and", "be", "understood", "as", "far", "as", "other", "speakers", "have", "the", "same", "word", "formation", "rule", "available.", "The", "productivity", "of", "word", "formation", "makes", "it", "impossible", "to", "cover", "the", "entire", "lexicon", "in", "a", "finite", "list."], "cited_papers": [{"title": "Two Models of Grammatical Description", "year": "1954", "authors": ["Charles Hockett"]}], "target_citation_location": 7, "citation_locations": [7, 169, 173, 253], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cae64c10-3d1e-4811-bc88-a6a5f25250de", "citing_paper": {"title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation", "year": 2021, "authors": ["Hansi Hettiarachchi", "Tharindu Ranasinghe"]}, "text": ["Supervised", "systems", "Supervised", "systems", "rely", "on", "semantically-annotated", "corpora", "for", "training", "(Raganato et al., 2017, Bevilacqua and Navigli, 2019).", "Early", "approaches", "were", "based", "on", "traditional", "machine", "learning", "algorithms", "like", "support", "vector", "machines", "(Iacobacci et al., 2016).", "With", "the", "word", "embedding-based", "approaches", "getting", "popular", "in", "natural", "language", "processing", "tasks,", "more", "recent", "approaches", "on", "WSD", "were", "based", "on", "neural", "network", "architectures", "(Melamud et al., 2016, Raganato et al., 2017).", "However,", "they", "rely", "on", "large", "manuallycurated", "training", "data", "to", "train", "the", "machine", "learning", "models", "which", "in", "turn", "hinders", "the", "ability", "of", "these", "approaches", "to", "scale", "over", "unseen", "words", "and", "new", "languages.", "More", "recently,", "contextual", "representations", "of", "words", "have", "been", "used", "in", "WSD", "where", "the", "contextual", "representations", "have", "been", "employed", "for", "the", "creation", "of", "sense", "embeddings", "(Peters et al., 2018).", "However,", "they", "also", "rely", "on", "sense-annotated", "corpora", "to", "gather", "contextual", "information", "for", "each", "sense,", "and", "hence", "are", "limited", "to", "languages", "for", "which", "gold", "annotations", "are", "available.", "A", "very", "recent", "approach", "SensEmBERT", "(Scarlini et al., 2020)", "provide", "WSD", "by", "leveraging", "the", "mapping", "between", "senses", "and", "Wikipedia", "pages,", "the", "relations", "among", "BabelNet", "synsets", "and", "the", "expressiveness", "of", "contextualised", "embeddings,", "getting", "rid", "of", "manual", "annotations.", "However,", "SensEmBERT", "(Scarlini et al., 2020)", "only", "supports", "five", "languages", "making", "it", "difficult", "to", "use", "with", "other", "languages."], "cited_papers": [{"title": "Neural sequence learning models for word sense disambiguation", "year": "2017", "authors": ["Alessandro Raganato", "Claudio Bovi", "Roberto Navigli"]}, {"title": "Quasi bidirectional encoder representations from transformers for word sense disambiguation", "year": "2019", "authors": ["Michele Bevilacqua", "Roberto Navigli"]}], "target_citation_location": 10, "citation_locations": [10, 24, 48, 104, 136, 166], "citation_type": "group", "annotations": [[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cb1ddfeb-57cc-43b7-9e85-7b4e76edf8f9", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["CCG", "[5]", "is", "a", "grammar", "formalism", "which", "consists", "of", "a", "lexicon", "that", "pairs", "words", "with", "lexical", "categories", "(supertags)", "and", "a", "set", "of", "combinatory", "rules", "which", "specify", "how", "the", "categories", "are", "combined.", "A", "supertag", "is", "a", "rich", "syntactic", "description", "that", "specifies", "the", "local", "syntactic", "context", "of", "the", "word", "in", "the", "form", "of", "a", "set", "of", "arguments.", "Most", "of", "the", "CCG", "grammar", "is", "contained", "in", "the", "lexicon,", "that", "is", "why", "CCG", "has", "simpler", "combinatory", "rules", "in", "comparison", "to", "CFG", "production", "rules.", "CCG", "categories", "are", "divided", "into", "atomic", "and", "complex", "categories.", "Examples", "of", "atomic", "categories", "are:", "S", "(sentence),", "N", "(noun),", "NP", "(noun", "phrase),", "etc.", "Complex", "categories", "such", "as", "S\\NP", "and", "(S\\NP)/NP", "are", "functions", "which", "specify", "the", "type", "and", "directionality", "of", "their", "arguments", "and", "results.", "Complex", "categories", "have", "the", "following", "formats:"], "cited_papers": [{"title": "The syntactic process", "year": "2000", "authors": ["M Steedman"]}], "target_citation_location": 1, "citation_locations": [1], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cb202cb8-bcfa-4195-9380-6732823a6956", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Curriculum", "Learning.", "Curriculums", "in", "reinforcement", "learning", "have", "traditionally", "been", "used", "to", "set", "goals", "of", "steadily", "increasing", "difficulty", "for", "an", "agent", "(Bengio et al., 2009, Schmidhuber, 2013).", "The", "difficulty", "of", "these", "curriculums", "are", "generally", "measured", "difficulty", "via", "proxy", "of", "agent", "performance", "(Narvekar", "et", "al.,", "2020)-methods", "either", "choose", "to", "adversarially", "set", "goals", "of", "steadily", "increasing", "difficulty", "(Sukhbaatar et al., 2018, Racaniere et al., 2019, Dennis et al., 2020, Campero et al., 2021)", "or", "to", "maximize", "learning", "performance", "based", "on", "environment", "instances", "an", "agent", "finds", "difficult", "historically", "(Graves et al., 2017, Portelas et al., 2020).", "While", "we", "were", "inspired", "by", "these", "works,", "they", "all", "focus", "on", "searching", "for", "goals", "for", "agents", "which", "can", "be", "difficult", "to", "scale", "to", "complex", "tasks", "such", "our", "own", "natural", "language", "motivation-based", "goals.", "We'd", "also", "like", "to", "note", "that", "most", "works", "using", "procedural", "generation", "to", "benchmark", "RL", "agents", "such", "as", "Cobbe et al. (2020),", "K\u00fcttler et al. (2020),", "Samvelyan et al. (2021)", "rely", "on", "the", "underlying", "richness", "of", "the", "game", "engines", "to", "generate", "novel", "environments", "as", "opposed", "to", "learning", "to", "generate."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Curriculum learning", "year": "2009", "authors": ["Yoshua Bengio", "J\u00e9r\u00f4me Louradour", "Ronan Collobert", "Jason Weston"]}], "target_citation_location": 20, "citation_locations": [20, 49, 64, 114, 115, 116], "citation_type": "group", "annotations": [[0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cb4053ee-1893-4665-beda-745978a15d4c", "citing_paper": {"title": "Effects of Word Alignment Visualization on Post-Editing Quality & Speed \u2020", "year": 2015, "authors": ["Lane Schwartz", "Isabel Lacruz", "Tatyana Bystrova"]}, "text": ["The", "keystroke", "logging", "data", "gathered", "for", "Spanish-English", "post-editors", "allowed", "the", "computation", "of", "Pause", "to", "Word", "Ratio", "(PWR).", "For", "each", "segment,", "PWR", "is", "the", "ratio", "of", "the", "number", "of", "pauses", "exceeding", "300ms", "to", "the", "number", "of", "words", "in", "the", "MT", "segment,", "it", "is", "a", "measure", "of", "cognitive", "effort", "in", "post-editing", "(Lacruz and Shreve, 2014).", "Higher", "PWR", "corresponds", "to", "higher", "cognitive", "effort.", "Contrary", "to", "expectation,", "the", "mean", "PWR", "for", "Spanish-English", "post-editors", "was", "slightly", "higher", "for", "the", "segments", "with", "alignment", "(0.70)", "than", "for", "those", "without", "alignment", "(0.63).", "However,", "the", "numerical", "difference", "was", "not", "significant."], "cited_papers": [{"title": "Pauses and cognitive effort in post-editing", "year": "2014", "authors": ["I Lacruz", "G Shreve", "S O'brien", "L Balling", "M Carl", "M Simard", "L Specia"]}], "target_citation_location": 49, "citation_locations": [49], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cbbc42db-ac7f-4ca0-a97e-689b52a97604", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["The", "design", "of", "the", "system", "is", "in", "response", "to", "perceived", "weaknesses", "in", "the", "classical", "approach", "to", "MT,", "as", "still", "found", "in", "so-called", "state-of-the-art", "developments", "(cf.", "[42]", "):", "notably", "these", "include", "reliance", "on", "structure-preserving", "translation", "as", "a", "first", "choice,", "a", "stratificational", "approach", "to", "both", "linguistic", "and", "computing", "aspects,", "leading", "to", "a", "predominantly", "bottom-up", "compositional", "system", "design,", "and", "the", "reliance", "on", "the", "intuitions", "and", "introspection", "of", "linguists", "rather", "than", "'real'", "data.", "The", "system", "design", "is", "influenced", "by", "a", "number", "of", "recent", "research", "directions", "including", "Dialogue-Based", "MT", "with", "a", "monolingual", "user,", "Example-Based", "MT,", "corpus-based", "MT,", "and", "the", "use", "of", "sublanguage."], "cited_papers": [{"title": "Current research in machine translation", "year": "1990", "authors": ["H Somers"]}], "target_citation_location": 25, "citation_locations": [25], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cbd9cf72-3895-4f74-8013-b0c84e18c37c", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["We", "also", "use", "an", "SVM", "classifier", "with", "linear", "kernel", "and", "regularization", "parameter", "of", "1.", "Word", "unigrams,", "bigrams", "and", "trigrams", "were", "used", "as", "features", "in", "this", "case.", "Implementation", "was", "done", "using", "the", "LinearSVC", "class", "from", "the", "scikit-learn", "library", "(Pedregosa et al., 2011)."], "cited_papers": [{"title": "Scikit-learn: Machine learning in python", "year": "2011", "authors": ["Fabian Pedregosa", "Ga\u00ebl Varoquaux", "Alexandre Gramfort", "Vincent Michel", "Bertrand Thirion", "Olivier Grisel", "Mathieu Blondel", "Peter Prettenhofer", "Ron Weiss", "Vincent Dubourg"]}], "target_citation_location": 37, "citation_locations": [37], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1]]}
{"id": "cc0f481d-26e3-4aff-83f8-48fac0712ce5", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["Ten", "Hacken (1999)", "describes", "the", "opposition", "between", "the", "coverage", "of", "the", "lexical", "component", "in", "the", "standard", "approach", "and", "in", "WM", "in", "terms", "of", "two", "orthogonal", "dichotomies:"], "cited_papers": [{"title": "Two Perspectives on the Reusability of Lexical Resources", "year": "1999", "authors": ["Pius Ten Hacken"]}], "target_citation_location": 1, "citation_locations": [1], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "cc436d75-8ab5-41dd-8f72-64a703602bbd", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Pre-training.", "We", "test", "two", "model", "types,", "drawing", "from", "Ammanabrolu et al. (2021),", "to", "determine", "if", "pre-training", "effects", "curriculums", "learning."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "cc8302e8-4679-4359-a017-03b61e7f5d9d", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Goal", "oriented", "Dialogue.", "Sub-tasks", "within", "the", "overall", "task", "of", "goal", "oriented", "dialogue,", "such", "as", "dialogue", "state", "management", "(Singh et al., 2000, Pietquin et al., 2011, Fatemi et al., 2016)", "and", "response", "generation", "(Li et al., 2016)", "have", "used", "RL", "to", "boost", "performance.", "As", "noted", "by", "Ammanabrolu et al. (2021),", "the", "negotiation", "tasks", "of", "(Yarats", "and", "Lewis, 2017, Lewis et al., 2017),", "where", "two", "agents", "are", "trying", "to", "convince", "each", "other", "to", "perform", "certain", "actions,", "are", "related", "to", "the", "tasks", "in", "LIGHT-Quests.", "These", "works", "all", "lack", "environment", "grounding."], "cited_papers": [{"title": "Deal or no deal? end-to-end learning for negotiation dialogues", "year": "2017", "authors": ["Mike Lewis", "Denis Yarats", "N Yann", "Devi Dauphin", "Dhruv Parikh", "unk Batra"]}], "target_citation_location": 38, "citation_locations": [17, 21, 31, 38], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "ccd5d634-0649-4b94-ae48-143a423418d9", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["Bilingual", "parallel", "corpus", "(Erjavec, 2004)", "was", "used", "in", "automatic", "(BLEU)", "evaluation", "of", "translations.", "This", "corpus", "consists", "of", "8600", "sentences", "that", "were", "not", "used", "in", "translation", "system", "construction."], "cited_papers": [{"title": "MULTEXT-East Version 3: Multilingual Morphosyntactic Specifications, Lexicons and Corpora", "year": "2004", "authors": ["Erjavec Toma\u017e"]}], "target_citation_location": 3, "citation_locations": [3], "citation_type": "single", "annotations": [[1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "ccf1092b-a446-414c-bbd0-aebded69372a", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["Style", "transfer", "aims", "to", "change", "the", "style", "attributes", "while", "preserving", "the", "content.", "Our", "work", "is", "related", "to", "unsupervised", "style", "transfer", "by", "regarding", "the", "text", "complexity", "as", "one", "of", "the", "style", "attributes", "(Kawashima and Takagi, 2019).", "Dumoulin et al. (2017)", "demonstrated", "that", "the", "neural", "networks", "can", "capture", "the", "artistic", "style", "of", "a", "diversity", "of", "paintings.", "The", "authors", "discovered", "that", "adjusting", "parameters", "in", "the", "layer", "normalization", "mechanism", "leads", "to", "different", "artistic", "styles.", "This", "method", "permits", "users", "to", "transform", "images", "to", "arbitrary", "styles", "learned", "from", "individual", "paintings.", "Jin et al. (2020)", "successfully", "applied", "this", "method", "to", "the", "task", "of", "headline", "generation,", "allowing", "the", "model", "to", "generate", "headlines", "of", "a", "specific", "style,", "such", "as", "humorous,", "romantic", "or", "click-baity,", "in", "an", "unsupervised", "manner."], "cited_papers": [{"title": "A learned representation for artistic style", "year": "2017", "authors": ["Jonathon Vincent Dumoulin", "Manjunath Shlens", "unk Kudlur"]}], "target_citation_location": 32, "citation_locations": [31, 32, 78], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cdde4f9a-c38a-4952-b44d-fee5644c5136", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["We", "use", "max-pooling", "over", "the", "output", "embedding", "(instead", "of", "mean-pooling", "as", "it", "better", "incorporates", "the", "nature", "of", "natural", "language", "sequences", "(Xiang et al., 2016", "))", "as:w", "c", "i", "=", "max", "i", "e", "w", "i", "i", "(2)For", "a", "total", "of", "h", "filters,", "each", "of", "varying", "widths,", "we", "get", "different", "representations", "of", "w", "i.", "Thereforew", "c", "i", "=", "[w", "c", "1,", "w", "c", "2", ",...,", "w", "c", "h", "]is", "the", "representation", "of", "the", "ith", "word."], "cited_papers": [{"title": "Incorporating label dependency for answer quality tagging in community question answering via cnn-lstm-crf", "year": "2016", "authors": ["Yang Xiang", "Xiaoqiang Zhou", "Qingcai Chen", "Zhihui Zheng", "Buzhou Tang", "Xiaolong Wang", "Yang Qin"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ce47ae72-2785-47fa-a72a-212284f06af3", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["The", "Transformer", "architecture", "(Vaswani et al., 2017)", "has", "been", "successful", "in", "a", "wide", "range", "of", "natural", "language", "processing", "tasks,", "including", "machine", "translation", "(Edunov et al., 2018),", "language", "modeling", "(Roy et al., 2021),", "question-answering", "(Karpukhin et al., 2020),", "and", "many", "more.", "Transformers", "pre-trained", "on", "large", "amounts", "of", "text", "with", "a", "language", "modeling", "(LM)", "objective,", "have", "become", "the", "standard", "in", "NLP,", "exhibiting", "surprising", "amounts", "of", "linguistic", "and", "world", "knowledge", "(Peters et al., 2018, Devlin et al., 2019, Petroni et al., 2019, Hewitt and Manning, 2019, Roberts et al., 2020)."], "cited_papers": [{"title": "A structural probe for finding syntax in word representations", "year": "2019", "authors": ["John Hewitt", "Christopher Manning"]}, {"title": "Deep contextualized word representations", "year": "2018", "authors": ["Matthew Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer"]}, {"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "Language models as knowledge bases?", "year": "2019", "authors": ["Fabio Petroni", "Tim Rockt\u00e4schel", "Sebastian Riedel", "Patrick Lewis", "Anton Bakhtin", "Yuxiang Wu", "Alexander Miller"]}], "target_citation_location": 55, "citation_locations": [3, 19, 22, 24, 55], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "ce48aae5-9388-416a-816c-734202436494", "citing_paper": {"title": "NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques", "year": 2021, "authors": ["Gunjan Chhablani", "Abheesht Sharma", "Harshit Pandey", "Yash Bhartia", "Shan Suthaharan"]}, "text": ["For", "all", "BERT-based", "models,", "we", "use", "Hugging-Face's", "transformers", "(Wolf et al., 2020)", "in", "PyTorch.", "For", "CRF,", "we", "use", "the", "pytorch-crf", "(Kurniawan, 2018)", "library.", "We", "use", "a", "batch", "size", "of", "4,", "train", "for", "3", "epochs,", "5", "Our", "code", "can", "be", "found", "at:", "https://github.com/", "gchhablani/toxic-spans-detection.", "6", "We", "also", "use", "Integrated", "Gradients", "to", "understand", "what", "the", "models", "focus", "on.", "For", "discussion,", "see", "Appendix", "B.", "use", "a", "linear", "learning", "rate", "decay,", "and", "an", "AdamW", "optimizer", "with", "a", "weight", "decay", "of", "0.01.", "The", "initial", "learning", "rate", "is", "2e\u22125.", "During", "tokenization,", "the", "maximum", "length", "allowed", "is", "384,", "with", "the", "exception", "of", "RoBERTa", "Span+Token", "where", "it", "is", "512.", "We", "use", "LARGE", "models", "for", "all", "-BERT,", "RoBERTa", "and", "SpanBERT,", "unless", "otherwise", "specified."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 8, "citation_locations": [8, 17], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cea6ed8d-724f-4d7f-88bd-1323edbb717b", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["TAG", "is", "a", "grammar", "formalism", "based", "on", "trees", "rather", "than", "context", "free", "rules", "(Joshi, 1987).", "Elementary", "trees", "are", "of", "two", "types,", "initial", "trees", "and", "auxiliary", "trees.", "Auxiliary", "trees", "have", "a", "designated", "foot", "node,", "marked", "with", "a", "*,", "whose", "label", "is", "the", "same", "as", "that", "of", "the", "root.", "In", "Figure", "6,", "\u00ab", "\u00bd", "and", "\u00ab", "\u00be", "are", "initial", "trees,", "\u00ac", "\u00bd", "is", "an", "auxiliary", "tree.", "The", "trees", "are", "combined", "together", "by", "two", "operations,", "substitution", "and", "adjunction.", "Under", "substitution,", "a", "node", "marked", "for", "substitution", "5", "in", "a", "tree", "is", "replaced", "by", "an", "initial", "tree", "with", "the", "same", "label", "at", "the", "root,", "under", "adjunction,", "an", "internal", "node", "in", "a", "tree", "is", "'split", "apart',", "replaced", "by", "an", "auxiliary", "tree", "with", "the", "same", "label", "at", "the", "root", "and", "foot.", "In", "the", "DERIVED", "TREE", "for", "the", "string,", "in", "Figure", "6,", "copies", "of", "\u00ac", "\u00bd", "have", "been", "adjoined", "either", "at", "the", "root", "node", "labelled", "of", "other", "nodes", "\u00ac", "\u00bd", "or", "ultimately", "at", "the", "node", "of", "\u00ab", "\u00bd,", "an", "\u00ab", "\u00be", "tree", "has", "been", "substituted", "into", "each", "\u00ac", "\u00bd", "tree", "at", "the", "node", "labelled.", "The", "derivation", "history", "is", "recorded", "in", "the", "DERIVATION", "TREE", "(Figure", "6).", "It", "can", "be", "seen", "that", "the", "TAG", "property", "of", "an", "'extended", "domain", "of", "locality'", "can", "allow", "the", "two", "s", "in", "the", "generated", "string", "to", "be", "separated", "by", "an", "abitrary", "amount", "of", "intervening", "material,", "this", "characteristic", "is", "used", "for", "representation", "of,", "for", "example,", "WH-phenomena", "when", "TAG", "derived", "trees", "are", "used", "for", "a", "linguistic", "representation.", "Of", "more", "interest", "for", "us", "than", "the", "derived", "string", "is", "the", "nature", "of", "the", "derived", "tree:", "the", "branches", "containing", "the", "nodes", "in", "the", "derived", "tree", "are", "also", "separated", "by", "an", "arbitary", "distance."], "cited_papers": [{"title": "An introduction to Tree Adjoining Grammars", "year": "1987", "authors": ["A Joshi"]}], "target_citation_location": 13, "citation_locations": [13], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cec66e16-86e7-4fb6-9cf7-55b68c51b7f6", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["Even", "in", "the", "presence", "of", "such", "an", "agreement,", "learning", "to", "disentangle", "the", "surface", "realization", "of", "the", "underlying", "factors", "of", "data", "(e.g.,", "semantics,", "syntactic,", "lexical)", "in", "the", "representation", "space", "is", "a", "nontrivial", "task.", "Additionally,", "there", "is", "no", "established", "study", "for", "evaluating", "such", "models", "in", "NLP.", "A", "handful", "of", "recent", "works", "have", "looked", "into", "disentanglement", "for", "text", "by", "splitting", "the", "representation", "space", "into", "predefined", "disentangled", "subspaces", "such", "as", "style", "and", "content", "(Cheng et al., 2020, John et al., 2019),", "or", "syntax", "and", "semantics", "(Balasubramanian et al., 2021, Bao et al., 2019, Chen et al., 2019),", "and", "rely", "on", "supervision", "during", "training.", "However,", "a", "generalizable", "and", "realistic", "approach", "needs", "to", "be", "unsupervised", "and", "capable", "of", "identifying", "the", "underlying", "factors", "solely", "via", "the", "regularities", "presented", "in", "data."], "cited_papers": [{"title": "Improving disentangled text representation learning with information-theoretic guidance", "year": "2020", "authors": ["Pengyu Cheng", "Dinghan Martin Renqiang Min", "Christopher Shen", "Yizhe Malon", "Yitong Zhang", "Lawrence Li", "unk Carin"]}, {"title": "Designing and interpreting probes with control tasks", "year": "2019", "authors": ["John Hewitt", "Percy Liang"]}], "target_citation_location": 69, "citation_locations": [69, 74], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ced94dcf-5f64-47e0-a249-9ebebf072a01", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["Next,", "we", "experiment", "with", "three", "neural", "models", "based", "on", "a", "pre-trained", "masked", "language", "model", "(MLM),", "specifically,", "SpanBERT", "(Joshi et al., 2020).", "We", "also", "experiment", "with", "an", "additional", "baseline", "with", "uncontextualized", "word", "embeddings."], "cited_papers": [{"title": "SpanBERT: Improving pre-training by representing and predicting spans", "year": "2020", "authors": ["Mandar Joshi", "Danqi Chen", "Yinhan Liu", "Daniel Weld", "Luke Zettlemoyer", "Omer Levy"]}], "target_citation_location": 17, "citation_locations": [17], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cedaa71a-6d1d-417c-a724-4a7d8e529a10", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["Performance", "is", "plotted", "on", "the", "vertical", "axis", "and", "measured", "for", "different", "frequency", "bins.", "The", "Zipfian", "distribution", "of", "terms", "suggests", "assessing", "performance", "by", "frequency", "ranges", "growing", "by", "a", "constant", "factor", "(Zipf, 1949),", "accordingly", "we", "used", "a", "logarithmic", "scale", "with", "base=3.", "The", "number", "of", "terms", "per", "bin", "is", "given", "in", "parentheses.", "Some", "of", "the", "previous", "work", "cited", "in", "Section", "2", "described", "performance", "for", "selected", "subsets", "of", "terms,", "typically", "high", "frequency", "terms", "that", "are", "easier", "to", "translate.", "We", "believe", "presenting", "translation", "accuracy", "as", "a", "function", "of", "source", "term", "frequency", "is", "more", "informative."], "cited_papers": [{"title": "Human Behavior and the Principle of Least-Effort", "year": "1949", "authors": ["G Zipf"]}], "target_citation_location": 29, "citation_locations": [29], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ceed5f31-cf33-4166-85e7-b1cb097b6b6d", "citing_paper": {"title": "A Parameter-Based Message-Passing Parser for MT of Korean and English", "year": 1994, "authors": ["Bonnie Dorr", "Jye-Hoon Lee", "Sungki Suh"]}, "text": ["We", "combine", "the", "benefits", "of", "the", "message-passing", "paradigm", "with", "the", "benefits", "of", "the", "parameterized", "approach", "to", "build", "a", "more", "efficient,", "but", "easily", "extensible", "system,", "called", "PRINCITRAN.", "1", "Our", "work", "extends", "that", "of", "Lin and Goebel (1993)", "and", "Lin (1993)", "in", "that", "it", "provides", "a", "parameterization", "mechanism", "along", "the", "lines", "of", "Dorr", "(1993b)", "that", "allows", "the", "system", "to", "be", "ported", "to", "languages", "other", "than", "English.", "We", "focus", "particularly", "on", "the", "problem", "of", "processing", "head-final", "languages", "such", "as", "Korean.", "The", "algorithm", "has", "been", "implemented", "in", "C++", "and", "successfully", "tested", "on", "well-known,", "translationally", "divergent", "sentences."], "cited_papers": [{"title": "Principle-based parsing without overgeneration", "year": "1993", "authors": ["D Lin"]}], "target_citation_location": 34, "citation_locations": [32, 34], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cfcd19c0-a232-4e1e-b8ee-711d1b15f694", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["We", "anticipate", "exploring", "various", "extensions", "to", "and", "validations", "of", "this", "method", "in", "the", "future.", "Specifically,", "we", "would", "like", "to", "explore", "methods", "that", "might", "mitigate", "performance", "degradation", "due", "to", "a", "lack", "of", "word", "boundaries", "in", "our", "method.", "Subword", "tokenization", "techniques,", "such", "as", "Byte-Pair", "Encodings", "(BPE)", "(Sennrich et al., 2016, Gage, 1994),", "or", "character-based", "word", "segmentation", "techniques", "might", "help", "in", "detecting", "and", "exploiting", "repeating", "patterns", "within", "the", "phonetic", "representation.", "Furthermore,", "the", "word", "embedding", "techniques", "used", "by", "(Chaudhary et al., 2018)", "or", "(Bharadwaj et al., 2016)", "have", "been", "shown", "to", "work", "well,", "and", "would", "be", "worth", "investigating", "how", "the", "removal", "of", "spacedelimited", "word", "boundaries", "would", "affect", "this."], "cited_papers": [{"title": "Phonologically aware neural model for named entity recognition in low resource transfer settings", "year": "2016", "authors": ["Akash Bharadwaj", "David Mortensen", "Chris Dyer", "Jaime Carbonell"]}], "target_citation_location": 71, "citation_locations": [44, 69, 71], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "cfd8380b-bc52-4a28-bc4b-c07d925267d2", "citing_paper": {"title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation", "year": 2021, "authors": ["Hansi Hettiarachchi", "Tharindu Ranasinghe"]}, "text": ["vi", "Entity", "Pool", "Strategy", "-To", "effectively", "deal", "with", "rare", "words,", "transformer", "models", "use", "sub-word", "units", "or", "WordPiece", "tokens", "as", "the", "input", "to", "build", "the", "models", "(Devlin et al., 2019).", "Therefore,", "there", "is", "a", "possibility", "that", "one", "target", "word", "can", "be", "separated", "into", "several", "sub-words.", "In", "this", "strategy,", "we", "generate", "separate", "fixed-length", "embeddings", "for", "each", "target", "word", "by", "passing", "its", "sub-word", "outputs", "through", "a", "pooling", "layer.", "The", "pooled", "outputs", "are", "concatenated", "and", "fed", "into", "a", "softmax", "layer", "to", "predict", "the", "labels", "(Figure", "2e)."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 25, "citation_locations": [25], "citation_type": "single", "annotations": [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "cfeb3360-0679-48ec-abea-5ebcf4342ab2", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["ATOMIC-LIGHT.", "ATOMIC-LIGHT", "is", "a", "(domain-adapted)", "fantasy", "commonsense", "knowledge", "graph,", "and", "as", "such", "provides", "priors", "for", "an", "agent", "on", "how", "to", "act", "consistently", "in", "the", "world.", "For", "example,", "given", "a", "clause", "such", "as", "\"The", "knight", "wishes", "to", "slay", "the", "dragon,", "as", "a", "result", "the", "knight", "needs", "to", "acquire", "a", "sword,\"", "the", "task", "would", "be", "to", "predict", "the", "underlined", "text-a", "form", "of", "knowledge", "graph", "completion", "(Wang et al., 2017)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 63, "citation_locations": [63], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]]}
{"id": "d047939f-bc58-4e0a-b094-90dc79aac010", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["The", "probabilistic", "parser", "was", "tested", "on", "the", "250", "sentences", "held", "out", "from", "the", "manually-created", "treebank", "(with", "mean", "length", "18.2", "tokens,", "mean", "number", "of", "parses", "per", "sentence", "977,", "and", "APB", "1.", "25", "2),", "in", "this", "test", "85", "sentences", "(34", "%", ").", "had", "the", "correct", "analysis", "ranked", "in", "the", "top", "three", "3", "This", "figure", "rose", "to", "51", "%", "for", "sentences", "of", "less", "than", "20", "words.", "Considering", "just", "the", "highest", "ranked", "anal", "ysis", "for", "each", "sentence,", "in", "Sampson, Haigh &amp, Atwell's (1989)", "measure", "of", "correct", "rule", "application", "the", "parser", "scored", "a", "mean", "of", "83.5%", "correct", "over", "all", "250", "sentences.", "Table", "2", "shows", "the", "results", "of", "this", "test-with", "respect", "to", "the", "original", "Susanne", "bracketings-using", "the", "Grammar", "\ufffdvaluation", "Interest", "Group", "scheme", "(GEIG,", "see", "e.g.", "Harrison et al., 1991).", "This", "compares", "unlabelled", "brack", "etings", "derived", "from", "corpus", "treebanks", "with", "those", "derived", "from", "parses", "for", "the", "same", "sentences", "by", "computing", "recall,", "the", "ratio", "of", "matched", "brackets", "over", "all", "brackets", "in", "the", "treebank,", "precision,", "the", "ratio", "of", "matched", "brackets", "over", "all", "brackets", "found", "by", "the", "parser,", "'crossing", "'", "brackets,", "the", "number", "of", "times", "a", "bracketed", "sequence", "output", "by", "the", "parser", "overlaps", "with", "one", "from", "the", "treebank", "but", "neither", "is", "properly", "contained", "in", "the", "other,", "and", "minC,", "the", "number", "of", "sentences", "for", "which", "all", "of", "the", "analyses", "had", "one", "or", "more", "crossings.", "The", "table", "also", "gives", "an", "indication", "of", "the", "best", "and", "worst", "possible", "performance", "of", "the", "disambiguation", "component", "of", "the", "system,", "showing", "the", "results", "obtained", "when", "parse", "selection", "is", "replaced", "by", "a", "simple", "random", "choice,", "and", "the", "results", "of", "eval", "uating", "the", "manually-created", "treebank", "against", "the", "corresponding", "Susanne", "bracketings.", "In", "this", "latter", "figure,", "the", "mean", "number", "of", "crossings", "is", "greater", "than", "zero", "mainly", "because", "of", "compound", "noun", "bracketing", "ambiguity", "which", "our", "grammar", "does", "not", "attempt", "to", "resolve,", "always", "returning", "minC", "Crossings", "Recall", "(%)", "Precision", "(%)", "Probabilistic", "parser", "analyses", "Top-ranked", "Black (1993:7)", "uses", "the", "crossing", "brackets", "measure", "to", "define", "a", "notion", "of", "structural", "consistency,", "where", "the", "structural", "consistency", "rate", "for", "the", "grammar", "is", "defined", "as", "the", "proportion", "of", "sentences", "for", "which", "at", "least", "one", "analysis", "contains", "no", "crossing", "brackets,", "and", "reports", "a", "rate", "of", "around", "95%", "for", "the", "IBM", "grammar", "tested", "on", "the", "computer", "manual", "corpus.", "The", "problem", "with", "the", "GEIG", "scheme", "and", "with", "structural", "consistency", "is", "that", "both", "are", "still", "weak", "measures", "(designed", "to", "avoid", "problems", "of", "parser/treebank", "representational", "compatibility)", "which", "lead", "to", "unintuitive", "numbers", "whose", "significance", "still", "depends", "heavily", "on", "details", "of", "the", "relationship", "between", "the", "representations", "compared", "(c.f.", "the", "compound", "noun", "issue", "mentioned", "above)."], "cited_papers": [{"title": "Evaluating syntax performance of parser/ grammars of English", "year": "1991", "authors": ["P Harrison", "S Abney", "E Black", "D Flickenger", "C Gdaniec", "R Grishman", "D Hindle", "B Lngria", "M Marcus", "B Santorini", "T Strzalkowski"]}], "target_citation_location": 115, "citation_locations": [74, 115, 293, 294], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d08a2bd1-53d8-4118-bdb4-b0c27e814377", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["Some", "emotions", "are", "also", "harder", "to", "detect,", "even", "for", "humans.", "Demszky et al. (2020)", "show", "that", "the", "emotions", "of", "admiration,", "approval,", "annoyance,", "gratitude", "had", "the", "highest", "interrater", "correlations", "at", "around", "0.6,", "and", "grief,", "relief,", "pride,", "nervousness,", "embarrassment", "had", "the", "lowest", "interrater", "correlations", "between", "0-0.2,", "with", "a", "vast", "majority", "of", "emotions", "falling", "in", "the", "range", "of", "0.3-0.5", "for", "interrater", "correlation.", "Emotions", "are", "also", "expressed", "differently", "in", "text", "with", "anger", "and", "disgust", "expressed", "explicitly,", "and", "surprise", "in", "context", "(Alm et al., 2005)."], "cited_papers": [{"title": "Emotions from text: Machine learning for textbased emotion prediction", "year": "2005", "authors": ["Cecilia Ovesdotter Alm", "Dan Roth", "Richard Sproat"]}], "target_citation_location": 73, "citation_locations": [10, 73], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "d0c522fd-fe86-44ef-aa5b-68f4ca714632", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["As", "a", "baseline", "experiment", "we", "applied", "our", "NIST", "Arabic/English", "system", "[1]", "to", "the", "BTEC", "task", "of", "this", "evaluation.", "It", "can", "be", "seen", "in", "Table", "4,", "first", "line,", "that", "a", "system", "optimized", "on", "a", "news", "task", "does", "not", "perform", "very", "well", "on", "tourism", "related", "short", "sentences", "of", "the", "BTEC", "task.", "Note", "that", "both", "systems", "use", "exactly", "the", "same", "tokenization.", "Using", "a", "language", "model", "optimized", "on", "the", "BTEC", "task", "does", "improve", "the", "BLEU", "score", "by", "3.8", "points", "on", "Dev6,", "but", "only", "marginally", "on", "Dev5.", "Also,", "the", "BLEU", "score", "obtained", "by", "this", "generic", "system", "is", "comparable", "to", "the", "one", "obtained", "when", "using", "the", "in-domain", "BTEC", "corpus", "to", "train", "the", "translation", "model.", "On", "the", "other", "hand,", "there", "is", "a", "4:", "BLEU", "scores", "of", "a", "generic", "Arabic/English", "translation", "system", "(NIST", "task)."], "cited_papers": [{"title": "Data selection and smoothing in an open-source system for the 2008 NIST machine translation evaluation", "year": "2008", "authors": ["H Schwenk", "Y Est\u00e8ve"]}], "target_citation_location": 10, "citation_locations": [10], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d1098b72-70de-4bb6-9a74-51392a01de43", "citing_paper": {"title": "SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering", "year": 2020, "authors": ["Aishwarya Ashok", "Ganapathy Natarajan", "Ramez Elmasri", "Laurel Smith-Stvan"]}, "text": ["Early", "work", "in", "opinion", "question", "answering", "addressed", "separating", "facts", "from", "opinions", "(Yu and Hatzivassiloglou, 2003),", "and", "the", "authors", "used", "a", "Na\u00efve", "Bayes", "classifier", "to", "identify", "polarity", "of", "the", "opinions.", "Kim and Hovy (2005)", "aimed", "at", "identifying", "the", "opinion", "holder", "of", "the", "opinions.", "Stoyanov et al. (2005)", "explained", "the", "differences", "between", "fact", "based", "and", "opinionated", "answers", "and", "how", "traditional", "QA", "systems", "will", "not", "be", "able", "to", "handle", "multiple", "perspectives", "for", "answers.", "Some", "works", "aimed", "at", "using", "community", "based", "question-answers", "to", "provide", "unique", "answers", "to", "questions", "(Liu et al., 2007, Somasundaran et al., 2007).", "Moghaddam and Ester (2011)", "made", "use", "of", "online", "reviews", "to", "answer", "questions", "on", "aspects", "of", "a", "product.", "Li et al. (2009)", "and", "Yu et al. (2012)", "used", "graphs", "and", "trees", "to", "answer", "opinion", "questions.", "Wan and McAuley (2016)", "modeled", "ambiguity", "and", "subjectivity", "in", "opinion", "QA", "using", "statistical", "models.", "Gupta et al. (2019)", "give", "baselines", "for", "answer", "generation", "systems", "given", "the", "question", "and", "reviews.", "We", "use", "their", "results", "as", "the", "baseline", "for", "our", "evaluation.", "We", "also", "discuss", "the", "dataset", "from", "this", "paper", "in", "4.2.", "While", "most", "systems", "used", "in", "the", "works", "described", "above", "are", "supervised", "learning", "models,", "our", "system", "used", "unsupervised", "learning", "to", "answer", "binary", "(yes/no)", "questions."], "cited_papers": [{"title": "Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences", "year": "2003", "authors": ["Hong Yu", "Vasileios Hatzivassiloglou"]}], "target_citation_location": 11, "citation_locations": [11, 26, 36, 75, 76, 90, 92, 101, 112], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d19f0fe9-b005-42e9-81e0-e21945b86ac1", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["Entity", "typing", "information", "has", "been", "used", "across", "a", "range", "of", "NLP", "tasks,", "including", "models", "for", "entity", "linking", "and", "coreference", "(Durrett and Klein, 2014)."], "cited_papers": [{"title": null, "year": "2014", "authors": ["Greg Durrett", "Dan Klein"]}], "target_citation_location": 19, "citation_locations": [19], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "d1d86793-5500-481d-afb5-afd31a14792c", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["The", "advantages", "of", "EBMT", "are", "that", "translation", "quality", "is", "assured,", "because", "the", "example", "translations", "are", "real.", "The", "system", "knows", "its", "limitations:", "if", "a", "suitable", "example", "cannot", "be", "found,", "the", "system", "will", "not", "translate", "on", "a", "word-for-word", "basis", "as", "in", "rule-based", "MT.", "This", "approach", "does", "not", "depend", "on", "structure", "preservation", "as", "a", "first", "choice", "(cf.", "[41],", "p.84),", "and", "perhaps", "most", "interesting", "of", "all,", "it", "is", "easy", "to", "extend", "an", "EBMT", "system:", "we", "simply", "add", "more", "examples", "to", "the", "database.", "Unlike", "in", "rule-based", "MT,", "there", "is", "not", "the", "overhead", "of", "'entropy'", "of", "performance,", "where", "the", "addition", "of", "a", "new", "rule", "has", "unforeseen", "repercussions", "on", "the", "rest", "of", "the", "system,", "which", "sometimes", "do", "not", "surface", "until", "many", "months", "after", "the", "change", "was", "made,", "and", "therefore", "are", "extremely", "difficult", "to", "trace."], "cited_papers": [{"title": "Some thoughts on interface structure(s)", "year": "1987", "authors": ["H Somers"]}], "target_citation_location": 54, "citation_locations": [54], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d1eaff2d-73c4-4f55-a655-09b4632056c5", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["Deep", "models", "such", "as", "Transformers", "rely", "heavily", "on", "the", "availability", "of", "a", "large", "amount", "of", "annotated", "data,", "which", "is", "available", "only", "for", "prominent", "languages", "like", "English,", "Russian,", "German", "or", "Spanish", "(Ponti et al., 2019, Joshi et al., 2020).", "For", "a", "majority", "of", "other", "languages", "with", "a", "minimal", "number", "of", "annotations,", "cross-lingual", "transfer", "learning", "(Prettenhofer and Stein, 2011, Wan et al., 2011, Ruder et al., 2019)", "has", "been", "proposed", "as", "a", "possible", "solution.", "This", "approach", "can", "transfer", "knowledge", "from", "the", "annotation-rich", "source", "language", "to", "low-resource", "or", "zero-resource", "target", "languages.", "Furthermore,", "multilingual", "models", "(Lewis et al., 2019, Clark et al., 2020)", "can", "be", "used", "to", "mitigate", "the", "data", "scarcity", "problem.", "For", "example,", "LASER", "(Artetxe and Schwenk, 2019)", "used", "a", "bidirectional", "LSTM", "(Hochreiter and Schmidhuber, 1997)", "encoder", "with", "a", "byte", "pair", "encoding", "vocabulary", "shared", "between", "languages.", "This", "work", "showed", "that", "joint", "training", "of", "multiple", "languages", "helped", "to", "improve", "the", "model", "performance", "for", "low-resource", "languages.", "LaBSE", "(Feng et al., 2020)", "used", "the", "mBERT", "(Devlin et al., 2018)", "encoder", "pre-trained", "with", "masked", "language", "modelling", "and", "translation", "language", "modelling", "(Lample and Conneau, 2019)", "tasks.", "It", "attempted", "to", "optimize", "the", "dual", "encoder", "translation", "ranking", "(Guo et al., 2018)", "loss", "during", "pre-training", "to", "achieve", "similar", "embedding", "for", "the", "same", "text", "in", "different", "languages."], "cited_papers": [{"title": "Biweighting domain adaptation for cross-language text classification", "year": "2011", "authors": ["Chang Wan", "Rong Pan", "Jiefei Li"]}, {"title": "Cross-lingual adaptation using structural correspondence learning", "year": "2011", "authors": ["Peter Prettenhofer", "Benno Stein"]}, {"title": "A survey of cross-lingual word embedding models", "year": "2019", "authors": ["Sebastian Ruder", "Ivan Vuli\u0107", "Anders S\u00f8gaard"]}], "target_citation_location": 46, "citation_locations": [30, 46, 73, 86, 91, 121, 125, 136, 147], "citation_type": "group", "annotations": [[3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d1f7bbfd-8039-4468-b0f5-f271da43a751", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Recently,", "Pires et al. (2019)", "and", "Conneau et al. (2020)", "have", "shown", "that", "multilingual", "models", "underperformed,", "when", "applied", "on", "poorly", "endowed", "languages.", "Additionally,", "as", "mentioned", "in", "subsection", "2.1,", "recent", "works", "(Zhang et al., 2021, Mosbach et al., 2021)", "have", "highlighted", "the", "limitation", "of", "Transformer-based", "transfer", "learning", "with", "strong", "instabilities", "arising", "from", "the", "small-scale", "learning."], "cited_papers": [{"title": "Revisiting fewsample {bert} fine-tuning", "year": "2021", "authors": ["Tianyi Zhang", "Felix Wu", "Arzoo Katiyar", "Q Kilian", "Yoav Weinberger", "unk Artzi"]}, {"title": "On the stability of fine-tuning {bert}: Misconceptions, explanations, and strong baselines", "year": "2021", "authors": ["Marius Mosbach", "Maksym Andriushchenko", "Dietrich Klakow"]}], "target_citation_location": 24, "citation_locations": [1, 3, 24], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "d21bc691-ccc4-47ff-8f17-6715a20183d5", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["For", "the", "downstream", "NER", "tasks", "we", "map", "or", "encode", "the", "NER", "annotations", "into", "the", "phonetic", "representation.", "We", "thus", "edited", "the", "labels", "(PER,", "ORG,", "DATE,", "and", "LOC)", "to", "convert", "them", "from", "word-level", "labels", "to", "phone-level", "labels", "as", "shown", "in", "Fig.", "3.", "Unlike", "(Kuru et al., 2016),", "we", "leave", "in", "the", "B-and", "I-prefixes."], "cited_papers": [{"title": "CharNER: Character-level named entity recognition", "year": "2016", "authors": ["Onur Kuru", "Deniz Ozan Arkan Can", "unk Yuret"]}], "target_citation_location": 41, "citation_locations": [41], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0]]}
{"id": "d3050638-de02-47ee-b244-5fd40b3b4e0b", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["Furthermore,", "Kumar", "et", "al.", "(2021)", "studied", "if", "the", "decisions", "of", "human", "players", "can", "be", "predicted", "in", "an", "amended", "version", "of", "Codenames.", "For", "the", "predictions,", "they", "used", "word2vec", "and", "GloVe", "word", "embeddings,", "as", "well", "as", "several", "similarity", "measures", "on", "free", "association", "datasets,", "in", "particular", "SWOW", "(De Deyne et al., 2019)", "and", "USF", "(Nelson et al., 2004).", "They", "found", "that", "similarity", "based", "on", "random", "walks", "in", "SWOW", "performed", "the", "best,", "from", "which", "they", "concluded", "that", "not", "only", "direct", "associations,", "but", "indirect", "connections", "are", "also", "important", "in", "this", "game."], "cited_papers": [{"title": "The university of south florida free association, rhyme, and word fragment norms", "year": "2004", "authors": ["Cathy Douglas L Nelson", "Thomas A Mcevoy", "unk Schreiber"]}], "target_citation_location": 47, "citation_locations": [44, 47], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "d3161053-a0cd-465e-9d0f-114785f3f95f", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["Table", "2", "presents", "the", "F1", "scores", "for", "our", "various", "training", "scenarios", "in", "the", "downstream", "NER3", "task,", "which", "should", "be", "the", "most", "challenging", "for", "our", "phonetic", "models.", "The", "influence", "of", "pre-training", "is", "more", "noticeable", "for", "this", "task.", "Further,", "the", "models", "pretrained", "on", "the", "kin", "audio", "and", "text", "data", "have", "the", "best", "performance.", "This", "is", "likely", "due", "to", "the", "fact", "that", "the", "kin", "data", "is", "both", "large", "and", "higher", "quality", "(in", "terms", "of", "sound", "quality)", "as", "compared", "to", "the", "ALFFA", "Swahili", "data.", "This", "benefit", "of", "this", "data", "size", "and", "quality", "appears", "to", "outweigh", "any", "degradation", "due", "to", "the", "pre-training", "occurring", "in", "a", "different", "(although", "related)", "language.", ").", "Average", "of", "at", "least", "three", "trials", "per", "experiment,", "scores", "calculated", "with", "seqeval", "library.", "(Nakayama, 2018)", "The", "importance", "(or", "relative", "impact)", "of", "pretraining", "phonetic", "language", "models", "increases", "with", "the", "complexity", "of", "the", "NER", "task.", "Fig.", "4", "shows", "the", "maximum", "percentage", "improvement", "due", "to", "pretraining", "for", "each", "of", "our", "NER", "tasks.", "This", "suggests", "that", "simple", "NLP", "tasks", "with", "a", "small", "number", "of", "output", "classes", "are", "much", "easier", "to", "port", "to", "phonetic", "representations,", "even", "without", "pre-training,", "while", "more", "complicated", "NLP", "tasks", "may", "require", "a", "more", "significant", "amount", "of", "text", "and/or", "audio", "data", "for", "pretraining.", "We", "expect", "this", "trend", "to", "carry", "through", "to", "tasks", "like", "sentiment", "analysis,", "which", "could", "be", "formulated", "as", "a", "simple", "classification", "task", "with", "NEG,", "NEU,", "and", "POS", "sentiment", "labels", "or", "a", "more", "complicated", "aspect", "based", "sentiment", "analysis", "task."], "cited_papers": [{"title": "seqeval: A python framework for sequence labeling evaluation", "year": "2018", "authors": ["Hiroki Nakayama"]}], "target_citation_location": 118, "citation_locations": [104, 118], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d39dd45a-2fc8-46a1-9ad9-9624d3a124e2", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["We", "define", "realism", "as", "the", "inability", "to", "distinguish", "between", "human-and", "machine-generated", "ads.", "Human", "annotators", "are", "best", "placed", "to", "assess", "realism", "(e.g.", "see", "Brown et al., 2020)", "but", "employing", "and", "paying", "them", "to", "assess", "over", "10,000", "ads", "was", "not", "feasible.", "Therefore,", "we", "train", "a", "discriminator", "model", "tasked", "with", "the", "binary", "prediction", "of", "whether", "a", "given", "input", "text", "was", "generated", "by", "a", "human", "or", "GPT-3", "and", "validate", "a", "sample", "of", "ads", "using", "human", "annotators.", "Real", "ads", "were", "longer", "(M", "=", "2,846", "characters,", "SD", "=", "2,038)", "than", "generated", "ones", "(M", "=", "514,", "SD", "=", "210)", "so", "we", "truncate", "texts", "to", "500", "characters.", "For", "prediction,", "we", "use", "a", "Multinominal", "Naive-Bayes", "(MNB)", "model,", "which", "we", "train,", "validate", "and", "test", "using", "an", "80:10:10", "split", "taken", "from", "the", "real", "and", "generated", "ads", "(described", "in", "Sec.", "3.2).", "6", "For", "our", "realism", "metric,", "we", "then", "use", "this", "model's", "predicted", "probability", "that", "an", "ad", "is", "real.", "To", "assess", "the", "robustness", "of", "this", "metric,", "we", "randomly", "sample", "10", "ads", "from", "each", "job", "category", "(female-biased,", "male-biased", "and", "neutral)", "for", "each", "experimental", "condition", "(N", "=", "150).", "We", "then", "ask", "three", "independent", "annotators", "to", "label", "the", "ad", "for", "whether", "it", "was", "human-or", "machine-generated", "and", "take", "the", "majority", "vote.", "7", "The", "accuracy", "of", "the", "majority", "label", "compared", "against", "the", "ground", "truth", "ad", "origin", "(real-world", "or", "GPT-3", "generated)", "proxies", "ad", "quality", "and", "realism."], "cited_papers": [{"title": "Language models are few-shot learners", "year": "2020", "authors": ["Tom Brown", "Benjamin Mann", "Nick Ryder", "Melanie Subbiah", "Jared Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell"]}], "target_citation_location": 22, "citation_locations": [22], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d3c16d9f-45b5-42d7-874c-c4663b7400e3", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["Table", "2", "shows", "BLEU,", "TER", "and", "METEOR", "scores", "for", "the", "baseline", "and", "CCG-based", "HPB", "systems", "on", "Ar-En", "translation", "using", "just", "TED", "data", "for", "the", "translation", "and", "language", "models.", "HPB-CCG", "contextual", "labels", "system", "was", "the", "best", "performing", "system", "in", "terms", "of", "BLEU,", "outperforming", "the", "PB", "and", "HPB", "baseline", "systems", "by", "0.1", "and", "0.12", "absolute", "BLEU", "points", "(0.42%", "and", "0.51%", "relative),", "respectively.", "However,", "these", "improvements", "are", "not", "statistically", "significant", "[25].", "The", "results", "also", "show", "that", "dropping", "features", "from", "the", "CCG", "categories", "and", "contextual", "labels", "had", "a", "negative", "effect", "on", "performance.", "Table", "3", "shows", "the", "evaluation", "results", "for", "the", "baseline", "and", "CCG-based", "HPB", "systems", "on", "Ar-En", "translation", "using", "TED", "data", "for", "the", "translation", "model", "and", "mixture", "adapted", "language", "models.", "Using", "mixture", "adaptation", "of", "language", "model", "leads", "to", "an", "increase", "of", "5.99", "absolute", "BLEU", "points", "(25.41%", "relative)", "for", "the", "best", "performing", "system", "(CCG", "contextual", "labels", "system)", "over", "the", "corresponding", "TED-trained", "model", "score", "in", "Table", "2.", "Language", "model", "adaptation", "also", "caused", "the", "PB-SMT", "model", "scores", "to", "improve", "by", "5.16", "absolute", "BLEU", "points", "(21.99%", "relative)", "over", "the", "corresponding", "unadapted", "PBSMT", "models.", "As", "with", "the", "unadapted", "systems,", "the", "HPB-CCG", "contextual", "labels", "system", "is", "also", "the", "best", "performing", "system", "within", "all", "the", "systems", "with", "adapted", "language", "models,", "across", "all", "evaluation", "metrics.", "It", "outperformed", "the", "mixture-model", "adapted", "HPB", "systems", "by", "a", "statistically", "insignificant", "0.1", "absolute", "BLEU", "points", "(0.34%", "relative).", "However,", "it", "improved", "over", "the", "UN-enhanced", "mixture-model", "adapted", "PB", "system", "by", "0.93", "absolute", "BLEU", "points", "(3.25%", "relative)", "providing", "a", "statistically", "significance", "at", "p-level=0.05.", "The", "results", "further", "demonstrate", "that", "dropping", "features", "from", "CCG", "labels", "caused", "the", "performance", "of", "the", "CCG-based", "systems", "to", "deteriorate.", "For", "the", "Ar-En", "translation", "task,", "the", "best", "performing", "system", "i.e.", "the", "HPB-CCG", "contextual", "labels", "system", "(HPB-CCG", "context)", "was", "submitted", "as", "the", "primary", "run", "in", "the", "evaluation", "campaign."], "cited_papers": [{"title": "Statistical Significance Tests for Machine Translation Evaluation", "year": "2004", "authors": ["P Koehn"]}], "target_citation_location": 67, "citation_locations": [67], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d40cd438-72ce-43a1-9b11-53f93a7fafae", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["E", "q", "\u03c6", "(z|x)", "[log", "p", "\u03b8", "(x|z)]", "\u2212", "\u03b2D", "KL", "(q", "\u03c6", "(z|x),", "p(z))", "\u2212\u03bbD", "M", "M", "D", "(q", "\u03c6", "(z),", "p(z))where", "D", "M", "M", "D", "is", "computed", "using", "maximum", "mean", "discrepancy", "(Gretton et al. (2012),", "MMD)", "and", "\u03bb", "is", "the", "scalar", "weight.", "This", "term", "regularises", "the", "aggregated", "posterior", "q", "\u03c6", "(z)", "with", "a", "factorised", "spikeand-slab", "prior", "(Mitchell and Beauchamp, 1988),", "which", "aims", "for", "disentanglement", "via", "clustering", "and", "sparsifying", "the", "representations", "of", "z."], "cited_papers": [{"title": "Bayesian variable selection in linear regression", "year": "1988", "authors": ["T Mitchell", "J Beauchamp"]}], "target_citation_location": 55, "citation_locations": [33, 55], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "d44f0100-1f97-4b62-91b5-cdfdece6664e", "citing_paper": {"title": "Situation-Specific Multimodal Feature Adaptation", "year": 2021, "authors": ["\u00d6zge Alac"]}, "text": ["In", "the", "second", "objective,", "we", "quantify", "the", "contribution", "of", "each", "modality", "and", "their", "aspects", "given", "the", "situation", "to", "mimic", "human", "heuristic", "processing", "capability.", "Language", "comprehension", "involves", "complex", "sequential", "decision", "making", "and", "is", "affected", "by", "both", "uncertainty", "about", "the", "current", "input", "and", "lack", "of", "knowledge", "about", "the", "upcoming", "material.", "Thus,", "people", "use", "-to", "a", "large", "extent", "-fast", "and", "frugal", "heuristics,", "i.e.", "choosing", "a", "good-enough", "representation", "(Ferreira, 2003).", "The", "heuristic", "view", "provides", "a", "valid", "explanation", "for", "scenarios", "with", "a", "conversation", "inside", "noisy", "conditions.", "Instead", "of", "waiting", "/", "asking", "for", "clarification,", "the", "model", "will", "reach", "a", "good-enough", "decision", "based", "on", "all", "information", "gathered", "through", "all", "available", "input", "channels.", "In", "order", "to", "do", "that,", "the", "set", "of", "important", "features", "given", "the", "situated", "setting", "should", "be", "chosen", "automatically."], "cited_papers": [{"title": "The misinterpretation of noncanonical sentences", "year": "2003", "authors": ["Fernanda Ferreira"]}], "target_citation_location": 64, "citation_locations": [64], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d46b2de9-379a-4a20-82ce-641eb4e889c9", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["Agreement", "analysis", "over", "annotations.", "Since", "this", "annotation", "task", "is", "non-trivial", "and", "sometimes", "subjective,", "we", "further", "compute", "the", "intraclass", "correlation", "score", "(Bartko, 1966)", "for", "the", "Amazon", "Mechanical", "Turk", "annotations.", "Our", "collected", "annotations", "reaches", "an", "intraclass", "correlation", "score", "of", "0.72,", "showing", "a", "good", "agreement", "among", "annotators.", "Another", "agreement", "we", "analyze", "is", "showing", "annotators", "5", "sample", "sentences", "compared", "to", "showing", "them", "all", "sentences,", "to", "avoid", "sample", "bias.", "We", "ask", "annotators", "to", "annotate", "a", "batch", "of", "25", "tokens", "with", "all", "sentences", "containing", "the", "corresponding", "token", "shown", "to", "them.", "The", "agreement", "reaches", "84.0%,", "indicating", "that", "showing", "5", "sample", "sentences", "does", "not", "significantly", "affect", "annotator's", "decision", "on", "the", "target", "token.", "More", "details", "of", "Amazon", "Mechanical", "Turk", "interface", "can", "be", "found", "in", "the", "Appendix."], "cited_papers": [{"title": "The intraclass correlation coefficient as a measure of reliability", "year": "1966", "authors": ["J John", "unk Bartko"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d473a327-e9ec-4be0-8fc8-8368a5318b03", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["The", "Use", "of", "Prepositions", "as", "Semantic", "Labels", "While", "the", "relations", "we", "identify", "between", "NPs", "can", "be", "expressed", "using", "prepositions,", "one", "could", "argue", "that", "using", "prepositions", "as", "semantic", "labels", "is", "not", "ideal,", "due", "to", "their", "inherent", "ambiguity", "(Schneider et al., 2015 (Schneider et al., , 2016 (Schneider et al., , 2018,, Gessler et al., 2021):", "indeed", "a", "preposition", "such", "as", "for", "has", "multiple", "senses,", "and", "can", "indicate", "a", "large", "set", "of", "semantic", "relations", "ranging", "from", "BENEFICIARY", "to", "DURATION."], "cited_papers": [{"title": "Comprehensive supersense disambiguation of English prepositions and possessives", "year": "2018", "authors": ["Nathan Schneider", "Jena Hwang", "Vivek Srikumar", "Jakob Prange", "Austin Blodgett", "Sarah Moeller", "Aviram Stern", "Adi Shalev", "Omri Abend"]}, {"title": "A hierarchy with, of, and for preposition supersenses", "year": "2015", "authors": ["Nathan Schneider", "Vivek Srikumar", "Jena Hwang", "Martha Palmer"]}, {"title": "A corpus of preposition supersenses", "year": "2016", "authors": ["Nathan Schneider", "Jena Hwang", "Vivek Srikumar", "Meredith Green", "Abhijit Suresh", "Kathryn Conger", "O' Tim", "Martha Gorman", "unk Palmer"]}, {"title": "Supersense and sensibility: Proxy tasks for semantic annotation of prepositions", "year": "2021", "authors": ["Luke Gessler", "Shira Wein", "Nathan Schneider"]}], "target_citation_location": 36, "citation_locations": [36], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "d4d97802-5a6d-4ad1-a54a-6865f0e370ec", "citing_paper": {"title": "A User-Based Usability Assessment of Raw Machine Translated Technical Instructions", "year": 2012, "authors": ["Stephen Doherty", "Sharon O'brien"]}, "text": ["While", "there", "is", "some", "divergence", "around", "the", "definition", "of", "usability,", "the", "majority", "of", "terms", "in", "the", "literature", "closely", "adhere", "to", "the", "ISO", "definition.", "Following", "the", "ISO/TR", "16982", "definition,", "usability", "is", "understood", "here", "as", "\"the", "extent", "to", "which", "a", "product", "can", "be", "used", "by", "specified", "users", "to", "achieve", "specified", "goals", "with", "effectiveness,", "efficiency,", "and", "satisfaction", "in", "a", "specified", "context", "of", "use\"", "(ISO, 2002).", "The", "objective", "of", "this", "study", "was", "to", "establish", "how", "usable", "raw", "machine", "translated", "instructions", "were", "for", "end", "users", "in", "comparison", "with", "the", "original", "source", "text,", "which", "was", "in", "English."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 60, "citation_locations": [60], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "d5309f1c-3a62-470f-a3ab-e1668003f0f9", "citing_paper": {"title": "Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*", "year": 1991, "authors": ["Hiroaki Kitano", "Dan Moldovan", "Seungho Cha"]}, "text": ["Syntactic", "constraint", "network", "(SCN)", "is", "a", "new", "feature", "which", "has", "not", "been", "used", "in", "the", "previous", "works", "in", "memory-based", "NLP", "SCN", "is", "used", "to", "handle", "syntactic", "phenomena", "without", "undermining", "benefits", "of", "memory-based", "approach.", "Although,", "unification", "has", "been", "the", "central", "operation", "in", "the", "recent", "syntactic", "theories", "such", "as", "LFG", "[Kaplan and Bresnan, 1982]", "and", "HPSG", "[Pollard and Sag, 1987],", "we", "prefer", "SCN", "over", "unificationbased", "approach", "because", "unification", "is", "computationally", "expensive", "and", "it", "is", "not", "suitable", "for", "massively", "parallel", "implementation.", "Although", "there", "is", "a", "report", "on", "an", "unification", "algorithm", "on", "massively", "parallel", "machines", "[Kitano. 1991b],", "still", "it", "is", "computationally", "expensive,", "and", "takes", "up", "major", "part", "of", "computing", "lime", "even", "on", "SNAP.", "In", "addition.", "there", "is", "a", "report", "that", "unification", "is", "not", "necessary", "the", "correct", "mechanism", "of", "enforcing", "Figure", "2:", "Concept", "Sequence", "on", "SNAP", "agreement", "[Ingria, 1990].", "Also,", "the", "classification-based", "approach", "[Kasper, 1989],", "which", "pre-compiles", "a", "hierarchy", "of", "feature", "structures", "in", "the", "form", "of", "a", "semantic", "network,", "can", "carry", "out", "similar", "task", "with", "less", "computational", "cost", "[Kim and Moldovan, 1990].", "Finally,", "current", "unification", "hard-rejects", "failure", "which", "is", "not", "desirable", "from", "our", "point.", "We", "want", "the", "system", "to", "be", "robust", "enough", "that", "while", "recognizing", "minor", "syntactic", "violation,", "it", "keep", "processing", "to", "get", "meaning", "of", "the", "sentence."], "cited_papers": [{"title": "Unification and Classification: An Experiment in Information-Based Parsing", "year": "1989", "authors": ["R Kasper ", " Kasper"]}], "target_citation_location": 130, "citation_locations": [48, 51, 85, 125, 130, 154], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d5671bb6-a860-4c87-9eb3-0f6c88f2e069", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["The", "TNE", "task", "we", "define", "side-steps", "all", "the", "above", "issues.", "It", "is", "based", "on", "the", "text", "alone,", "without", "revealing", "additional", "information", "not", "present", "in", "the", "text.", "The", "exhaustive", "nature", "of", "the", "task", "entails", "looking", "both", "at", "positive", "instances", "(where", "a", "relation", "exists)", "and", "negative", "ones", "(where", "it", "doesn't),", "making", "it", "harder", "for", "models", "to", "pick", "up", "shallow", "heuristics.", "We", "don't", "reveal", "information", "to", "a", "model,", "beyond", "the", "information", "that", "the", "two", "NPs", "appear", "in", "the", "same", "text.", "Finally,", "the", "list", "of", "NPs", "to", "be", "considered", "is", "pre-specified,", "isolating", "the", "problem", "of", "understanding", "the", "relations", "between", "NPs", "in", "the", "text", "from", "the", "much", "easier", "yet", "intervening", "problem", "of", "identifying", "NPs", "and", "agreeing", "on", "their", "exact", "spans.", "of, against, in, by, on, about, with, after, to, from, for, among, under, at, between, during, near, over, before, inside, outside, into, around", "Table", "1:", "Prepositions", "used", "in", "TNE.", "Thus,", "we", "consider", "TNE", "a", "less", "biased", "and", "less", "gameable", "measure", "of", "RC", "than", "QA-based", "benchmarks.", "Of", "course,", "the", "information", "captured", "by", "TNE", "is", "limited", "and", "does", "not", "cover", "all", "levels", "of", "text", "understanding.", "Yet,", "performing", "the", "task", "correctly", "entails", "a", "non-trivial", "comprehension", "of", "texts,", "which", "human", "readers", "do", "as", "a", "byproduct", "of", "reading."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 115, "citation_locations": [115], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d5ba19e6-4390-4d3b-8ea3-b5c126173671", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Another", "approach", "consists", "of", "translating", "the", "QA", "triples", "of", "the", "target", "domain", "into", "the", "source", "domain,", "so", "the", "model", "trained", "on", "the", "source", "language", "can", "be", "directly", "applied", "on", "the", "translated", "target", "language", "testing", "data.", "As", "an", "exemple,", "Asai et al. (2018)", "'s", "method", "consisted", "of", "combining", "the", "alignment", "attention", "scores", "from", "a", "MT", "model", "with", "an", "English", "QA", "model", "to", "guide", "the", "answer", "extraction", "process."], "cited_papers": [{"title": "Multilingual extractive reading comprehension by runtime machine translation", "year": "2018", "authors": ["Akari Asai", "Akiko Eriguchi", "Kazuma Hashimoto", "Yoshimasa Tsuruoka"]}], "target_citation_location": 38, "citation_locations": [38], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "d5db8202-d4c5-4610-8f66-9649d4038baf", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["Although", "first", "suggested", "by", "Kay", "[20],", "the", "alternative", "idea", "of", "an", "MT", "system", "for", "a", "monolingual", "user", "seems", "only", "to", "have", "really", "been", "followed", "up", "about", "five", "years", "ago,", "when", "several", "proposals", "for", "interactive", "MT", "for", "monolingual", "users", "were", "apparently", "initiated", "[7, 14, 17, 38, 48, 49]."], "cited_papers": [{"title": "Machine translation as an expert task", "year": "1987", "authors": ["R Johnson", "P Whitelock"]}, {"title": "Knowledge-based machine translation, the CMU approach", "year": "1987", "authors": ["J Carbonell", "M Tomita"]}, {"title": "Linguistic and extra-linguistic knowledge", "year": "1986", "authors": ["K Schubert"]}, {"title": "Machine translation in a monolingual environment", "year": "1990", "authors": ["X Huang"]}, {"title": "Strategies for interactive machine translation: the experience and implications of the UMIST Japanese project", "year": "1986", "authors": ["P Whitelock", "M Wood", "B Chandler", "N Holden", "H Horsfall"]}, {"title": "Interactive translation: a new approach", "year": "1988", "authors": ["R Zajac"]}], "target_citation_location": 41, "citation_locations": [5, 41], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1]]}
{"id": "d6034a5c-0a60-4c94-bcb0-cf5bc56ab134", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["We", "extensively", "evaluate", "top-k", "attention", "on", "a", "wide", "range", "of", "tasks", "and", "demonstrate", "its", "mentioned", "advantages.", "Training", "from", "scratch,", "we", "show", "top-k", "attention", "performs", "as", "well", "as", "vanilla", "self-attention", "on", "Long", "Range", "Arena,", "a", "benchmark", "dedicated", "to", "evaluating", "the", "ability", "of", "transformers", "to", "handle", "long", "sequences,", "and", "in", "a", "language", "modeling", "task", "(WikiText-103).", "Second,", "we", "show", "top-k", "attention", "can", "be", "used", "as", "a", "drop-in", "replacement", "for", "vanilla", "attention", "at", "inference", "time", "without", "any", "additional", "training", "at", "the", "feed-forward", "layer", "of", "the", "UnifiedQA", "model", "(Khashabi et al., 2020)", "on", "12", "different", "question", "answering", "(QA)", "datasets,", "reducing", "the", "number", "of", "keys", "used", "per", "query", "by", "more", "than", "99%.", "Last,", "we", "show", "top-k", "attention", "obtains", "similar", "performance", "to", "vanilla", "attention", "on", "a", "wide", "range", "of", "QA", "tasks", "when", "fine-tuning", "T5", "(Raffel et al., 2020),", "without", "the", "need", "for", "any", "corrective", "pre-training."], "cited_papers": [{"title": "UNIFIEDQA: Crossing format boundaries with a single QA system", "year": "2020", "authors": ["Daniel Khashabi", "Sewon Min", "Tushar Khot", "Ashish Sabharwal", "Oyvind Tafjord", "Peter Clark", "Hannaneh Hajishirzi"]}], "target_citation_location": 83, "citation_locations": [83, 124], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d644c245-27f5-4d66-980b-a6bfc5521453", "citing_paper": {"title": "Entity Attribute Relation Extraction with Attribute-Aware Embeddings", "year": 2020, "authors": ["Dan Iter", "Xiao Yu", "Fangtao Li"]}, "text": ["We", "initialize", "attribute", "embeddings", "with", "Glove", "(Pennington et al., 2014)", "word", "embeddings.", "For", "an", "entity,", "we", "take", "all", "the", "known", "attributes", "from", "K", "e.", "The", "representation", "of", "each", "entity", "is", "the", "weighted", "sum", "of", "the", "known", "attributes,", "with", "learned", "attention", "weights.", "The", "weights", "are", "shared", "between", "entities", "and", "attributes."], "cited_papers": [{"title": "Glove: Global vectors for word representation", "year": "2014", "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning"]}], "target_citation_location": 6, "citation_locations": [6], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d648c9a3-a0fe-424e-84ca-46519b1b9be4", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["We", "further", "compared", "our", "strategy", "with", "other", "graph-based", "approaches:", "Text", "Graph", "Convolutional", "Network", "(TextGCN)", "(Yao et al., 2019)", "and", "Heterogeneous", "Graph", "Attention", "Network", "(HGAT)", "(Yang et al., 2021).", "The", "former", "models", "the", "whole", "text", "corpus", "as", "a", "document-word", "graph", "with", "word", "co-occurrence", "relations", "and", "applies", "GCN", "for", "classification.", "The", "latter", "models", "the", "texts", "using", "a", "heterogeneous", "information", "network", "framework", "and", "adopts", "heterogeneous", "graph", "attention", "to", "embed", "that", "framework", "for", "text", "classification", "based", "on", "a", "dual-level", "attention", "mechanism.", "Finally,", "we", "compared", "our", "approach", "with", "a", "transformer-based", "method", "as", "it", "has", "achieved", "remarkable", "results", "in", "several", "areas", "of", "Natural", "Language", "Processing", "(NLP).", "We", "compared", "our", "strategy", "with", "BR-BERT", "(Leite et al., 2020),", "which", "is", "a", "monolingual", "BERT,", "and", "M-BERT", "(Leite et al., 2020),", "which", "is", "a", "multilingual", "BERT.", "Table", "5", "shows", "the", "comparison", "between", "these", "methods.", "As", "we", "can", "see", "from", "Table", "5,", "our", "approach", "outperformed", "the", "graph-based", "methods", "and", "reached", "a", "competitive", "result", "compared", "to", "transformer", "models.", "Although", "our", "strategy", "did", "not", "outperform", "transformers,", "we", "believe", "the", "results", "are", "very", "promising,", "since", "it", "requires", "much", "less", "computational", "power", "than", "transformers.", "Moreover,", "our", "method", "requires", "less", "annotated", "data", "(only", "10%)", "than", "transformers", "to", "achieve", "interesting", "results."], "cited_papers": [{"title": "Graph convolutional networks for text classification", "year": "2019", "authors": ["Liang Yao", "Chengsheng Mao", "Yuan Luo"]}], "target_citation_location": 14, "citation_locations": [14, 21, 100, 108], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d66953d2-c2ff-4a09-89d0-887c28f12c83", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["In", "our", "experiments,", "we", "use", "ChAII", "(Google, 2021)", "question-answering", "dataset", "for", "fine-tuning", "and", "evaluation.", "This", "dataset", "was", "recently", "released", "by", "Google", "Research", "India", "and", "has", "1,114", "records", "of", "context,", "question,", "answer,", "and", "its", "corresponding", "start", "position", "in", "the", "context", "for", "Tamil", "and", "Hindi", "languages.", "Hindi", "is", "represented", "predominantly", "in", "the", "dataset", "with", "nearly", "two-thirds", "of", "the", "records.", "As", "the", "ChAII", "dataset", "has", "been", "published", "as", "part", "of", "an", "ongoing", "Kaggle", "competition", "(Google, 2021),", "the", "complete", "test", "dataset", "has", "not", "been", "disclosed", "to", "the", "public.", "Hence,", "we", "have", "used", "Scikit-learn's", "train_test_split", "method", "with", "a", "test", "size", "of", "100,", "stratified", "on", "language", "and", "with", "a", "random", "seed", "of", "0,", "to", "get", "the", "test", "split", "from", "the", "training", "data.", "Similarly,", "we", "applied", "the", "same", "method", "over", "the", "filtered", "train", "split", "to", "get", "the", "validation", "split", "of", "100", "samples.", "We", "also", "use", "the", "translations", "and", "transliterations", "of", "this", "training", "split", "as", "augmented", "samples", "for", "fine-tuning", "the", "QA", "model.", "Stanford", "Question", "Answering", "Dataset", "(SQuAD)", "(Rajpurkar et al., 2016)", "is", "the", "most", "popular", "question-answering", "dataset", "in", "English.", "This", "dataset", "had", "been", "crowdsourced", "to", "form", "100K", "records", "of", "answerable", "question-answer", "pairs", "along", "with", "the", "context.", "This", "dataset", "is", "used", "to", "pre-train", "the", "QA", "head", "added", "to", "the", "pre-trained", "mBERT", "model,", "which", "is", "subsequently", "fine-tuned", "using", "the", "ChAII", "dataset."], "cited_papers": [{"title": "ChAII -Hindi and Tamil question answering", "year": "2021", "authors": ["unk Google"]}], "target_citation_location": 70, "citation_locations": [6, 70, 157], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d66a1065-66cb-4417-8154-f69410a94a7e", "citing_paper": {"title": "A Parameter-Based Message-Passing Parser for MT of Korean and English", "year": 1994, "authors": ["Bonnie Dorr", "Jye-Hoon Lee", "Sungki Suh"]}, "text": ["We", "are", "currently", "incorporating", "the", "parameterized", "parser", "into", "an", "interlingual", "MT", "system", "called", "PRINCITRAN.", "The", "current", "framework", "is", "well-suited", "to", "an", "interlingual", "design", "since", "the", "linking", "rules", "between", "the", "syntactic", "representations", "given", "above", "and", "the", "underlying", "lexical-semantic", "representation", "are", "well-defined", "(see", "Dorr (1993a)", ").", "We", "adopt", "the", "Lexical", "Conceptual", "Structure", "(LCS)", "of", "Dorr's", "work", "and", "use", "a", "parameter-setting", "approach", "to", "account", "for", "the", "divergences", "presented", "in", "the", "last", "section.", "(Dorr (1993b)", "describes", "a", "parametric", "approach", "to", "mapping", "between", "the", "interlingua", "and", "the", "syntactic", "structure.)"], "cited_papers": [{"title": "Interlingual machine translation: a parameterized approach", "year": "1993", "authors": ["B Dorr"]}], "target_citation_location": 68, "citation_locations": [41, 68], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "d75a0957-3626-4538-bb1e-c836d9d6a796", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["We", "also", "compare", "with", "the", "semi-rule-based", "system", "used", "for", "pre-annotating", "the", "Parallel", "Meaning", "Bank", "(Abzianidze et al., 2017).", "Van Noord et al. (2020)", "call", "this", "system", "\"Pro", "Boxer\".", "In", "a", "sense,", "Pro", "Boxer", "is", "closest", "in", "approach", "to", "ours", "because", "it", "makes", "use", "of", "neural", "taggers", "for", "making", "token-level", "tagging", "predictions.", "It", "differs", "from", "ours", "and", "all", "other", "systems", "however", "in", "that", "it", "is", "not", "fully", "trainable", "from", "examples,", "the", "translation", "from", "tags", "to", "DRSs", "is", "done", "via", "hand-crafted", "rules.", "Moreover,", "it", "relies", "on", "a", "CCG", "parser", "that", "creates", "explicit", "syntactic", "representation", "which", "is", "perhaps", "more", "complexity", "than", "needed.", "As", "van", "Noord", "et", "al.", "also", "point", "out,", "the", "comparison", "with", "Pro", "Boxer", "is", "not", "quite", "fair", "because", "it", "is", "the", "system", "that", "produced", "the", "PMB", "pre-annotations", "and", "thus", "profits", "from", "anchoring", "bias."], "cited_papers": [{"title": "Character-level representations improve DRS-based semantic parsing even in the age of BERT", "year": "2020", "authors": ["Rik Van Noord", "Antonio Toral", "Johan Bos"]}], "target_citation_location": 15, "citation_locations": [14, 15], "citation_type": "single", "annotations": [[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d75da8af-87b1-474c-9293-78f64eb12fb7", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["Large", "explanations", "are", "typically", "evaluated", "on", "two", "dimensions:", "relevance", "and", "completeness.", "Relevance", "refers", "to", "whether", "each", "fact", "in", "an", "explanation", "is", "relevant,", "topical,", "and", "required", "to", "complete", "the", "chain", "of", "inference", "that", "moves", "from", "question", "to", "correct", "answer.", "Conversely,", "completeness", "evaluates", "whether", "the", "entire", "set", "of", "facts", "in", "the", "explanation,", "together,", "composes", "a", "complete", "chain", "of", "inference", "from", "question", "to", "answer,", "without", "significant", "gaps.", "In", "practice,", "both", "of", "these", "are", "challenging", "to", "evaluate", "automatically", "(Buckley and Voorhees, 2004, Voorhees, 2002),", "given", "that", "multi-hop", "datasets", "typically", "include", "a", "single", "example", "of", "a", "complete", "explanation,", "in", "large", "part", "due", "to", "the", "time", "and", "expense", "associated", "with", "generating", "such", "annotation.", "Underscoring", "this", "difficulty,", "post-competition", "manual", "analyses", "on", "participating", "systems", "in", "the", "previous", "two", "iterations", "of", "this", "shared", "task", "showed", "that", "models", "may", "be", "performing", "up", "to", "20%", "better", "at", "retrieving", "correct", "facts", "to", "build", "their", "explanation", "from,", "highlighting", "this", "significant", "methodological", "challenge."], "cited_papers": [{"title": "Retrieval Evaluation with Incomplete Information", "year": "2004", "authors": ["Chris Buckley", "Ellen Voorhees"]}, {"title": "The Philosophy of Information Retrieval Evaluation", "year": "2002", "authors": ["Ellen Voorhees"]}], "target_citation_location": 74, "citation_locations": [74], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "d76bb0fd-60bd-44b7-a655-784adbdc8e19", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["Neural", "Machine", "Translation", "(NMT)", "approach", "has", "been", "further", "developed", "in", "the", "last", "years", "[1, 2].", "In", "contrast", "to", "the", "traditional", "phrased-based", "statistical", "machine", "translation", "[3]", "that", "represents", "and", "translates", "the", "input", "sentence", "with", "a", "set", "of", "phrases,", "NMT", "uses", "the", "sequence", "to", "sequence", "learning", "architecture", "and", "the", "whole", "input", "sentence", "is", "considered", "as", "one", "unit", "for", "translation", "[4].", "Recently,", "NMT", "is", "gaining", "more", "and", "more", "interest", "and", "showing", "better", "accuracy", "than", "phrase-based", "system", "translating", "several", "language", "pairs.", "In", "spite", "of", "these", "recent", "improvements,", "the", "NMT", "systems", "still", "have", "some", "restrictions", "and", "difficulties", "to", "translate.", "One", "of", "them", "is", "the", "high", "computational", "of", "the", "softmax", "function", "which", "requires", "to", "normalize", "all", "the", "output", "vocabulary", "size."], "cited_papers": [{"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "year": "2014", "authors": ["K Cho", "B Van Merrienboer", "C G\u00fclc \u00b8ehre", "F Bougares", "H Schwenk", "Y Bengio"]}], "target_citation_location": 56, "citation_locations": [13, 23, 56], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d781dc37-7528-4ef1-8fe4-237f761b4520", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["We", "conduct", "all", "experiments", "with", "the", "deep", "learning", "framework", "PaddlePaddle", "(Ma et al., 2019)", "on", "up", "to", "eight", "NVIDIA", "Tesla", "V100", "GPUs", "(with", "32G", "RAM)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 10, "citation_locations": [10], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "d782a346-89a3-47e8-892d-8e4a9134de23", "citing_paper": {"title": "Controlled Text Generation with Adversarial Learning", "year": 2020, "authors": ["Federico Betti", "Giorgia Ramponi", "Massimo Piccardi"]}, "text": ["The", "generator", "is", "based", "on", "a", "Relational", "Memory", "with", "self-attention", "[18, 16].", "This", "model", "updates", "its", "\"internal", "values\"", "and", "produces", "its", "final", "output", "by", "selecting", "from", "its", "memory", "cells", "with", "a", "self-attention", "mechanism.", "Leveraging", "an", "idea", "similar", "to", "that", "of", "image-based", "conditional", "GANs", "[15],", "we", "introduce", "an", "external", "conditioning", "into", "the", "generator.", "First,", "given", "the", "conditioning", "input", "c", "2", "R", "d,", "the", "model", "computes", "an", "embedding", "t", "for", "c", "using", "functionf", "\u2713:", "R", "d!", "R", "m,", "with", "m", "&lt,", "d.Function", "f", "\u2713", "has", "been", "implemented", "using", "a", "feed-forward", "neural", "network", "with", "a", "self-attention", "layer.", "The", "conditioning", "vector", "c", "may", "originate", "from", "any", "type", "of", "different", "source", "as", "long", "as", "it", "remains", "consistent", "during", "the", "individual", "training.", "Depending", "on", "the", "required", "task,", "as", "shown", "in", "the", "experiment", "phase,", "it", "will", "change.", "This", "vector", "c", "is", "the", "only", "link", "between", "the", "conditioning", "and", "the", "generative", "model,", "its", "influence", "on", "the", "final", "output", "will", "be", "crucial", "for", "the", "conditioning", "of", "the", "generated", "sentence.", "f", "\u2713", "has", "been", "adopted", "to", "give", "the", "model", "the", "ability", "to", "learn", "the", "best", "manipulation", "of", "the", "conditioning", "vector", "to", "insert", "into", "the", "memory."], "cited_papers": [{"title": null, "year": "2018", "authors": ["Adam Santoro", "Ryan Faulkner", "David Raposo", "Jack Rae", "Mike Chrzanowski", "Th\u00e9ophane Weber", "Daan Wierstra"]}, {"title": "RelGAN: Relational Generative Adversarial Networks for Text Generation", "year": "2019", "authors": ["Weili Nie", "Nina Narodytska", "Ankit Patel"]}], "target_citation_location": 10, "citation_locations": [10, 42], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d782b259-0217-4707-a5a1-6721f122f734", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["All", "of", "the", "models", "in", "the", "pipeline", "described", "in", "Section", "2", "are", "trained", "using", "only", "the", "training", "set", "of", "the", "original", "LIGHT", "and", "LIGHT-Quests", "data.", "LIGHT-Quests", "inherits", "characters,", "locations,", "and", "objects", "from", "the", "original", "LIGHT", "dataset", "and", "adds", "on", "motivations", "and", "goals", "in", "the", "form", "of", "quests.", "Thus,", "the", "character,", "location,", "and", "object", "retrieval", "models", "are", "evaluated", "on", "the", "LIGHT", "unseen", "test", "set", "and", "the", "motivation", "and", "goal", "generation", "models", "are", "evaluated", "on", "the", "LIGHT-Quests", "test", "set.", "We", "report", "the", "standard", "array", "of", "metrics:", "hits@10", "and", "F1", "ranking", "prediction", "score", "for", "retrieval", "models,", "and", "F1", "(as", "a", "harmonic", "average", "of", "BLEU-1 (Papineni et al., 2002)", "and", "ROUGE-1", "(Lin, 2004))", "and", "perplexity", "for", "generative", "models.", "Hyperparameters", "for", "all", "models", "are", "found", "in", "Appendix", "A.6.", "Analysis.", "Table", "1", "presents", "the", "results", "of", "this", "evaluation.", "There", "are", "two", "primary", "trends", "to", "note:", "(1)", "character", "retrieval", "is", "easier", "than", "retrieving", "location", "and", "objects,", "and", "(2)", "goal", "action", "generation", "is", "easier", "than", "motivation", "generation.", "We", "hypothesize", "that", "the", "first", "trend", "is", "a", "direct", "consequence", "of", "the", "fact", "that", "generated", "motivations", "and", "goals", "regularly", "contain", "the", "names", "of", "the", "characters", "involved", "but", "mostly", "leave", "implicit", "information", "such", "as", "the", "objects", "required-e.g.", "the", "action", "hit", "dragon", "as", "a", "knight", "would", "require", "a", "weapon", "such", "as", "a", "sword", "to", "be", "equipped", "first.", "The", "second", "trend", "stems", "from", "the", "fact", "that", "goal", "actions", "can", "often", "be", "thought", "of", "as", "condensed", "version", "of", "the", "short", "motivation-number", "of", "tokens", "required", "to", "generate", "goal", "actions", "is", "far", "less", "than", "short", "motivations.", "This", "implies", "that", "the", "goal", "action", "model", "is", "akin", "to", "a", "summarization", "model", "as", "opposed", "to", "the", "short", "motivation", "model", "which", "has", "the", "more", "difficult", "task", "of", "generating", "the", "motivation", "with", "only", "initial", "persona", "and", "location", "information."], "cited_papers": [{"title": "ROUGE: A package for automatic evaluation of summaries", "year": "2004", "authors": ["Chin-Yew Lin"]}], "target_citation_location": 103, "citation_locations": [100, 103], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d81cfae9-9762-4879-869b-be0318f5413e", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["In", "this", "context,", "the", "main", "question", "then", "arises:", "shouldn't", "machine", "translation", "be", "multilingual", "for", "languages", "spoken", "in", "a", "multilingual", "country", "like", "Peru?", "By", "taking", "advantage", "of", "few", "resources,", "and", "other", "strategies", "such", "as", "multilingual", "unsupervised", "subword", "segmentation", "models", "(Kudo, 2018),", "pretraining", "with", "high", "resource", "language-pairs", "(Kocmi and Bojar, 2018),", "back-translation", "(Sennrich et al., 2016a),", "and", "fine-tuning", "(Neubig and Hu, 2018),", "we", "deployed", "the", "first", "many-to-one", "and", "one-to-many", "multilingual", "NMT", "models", "(paired", "with", "Spanish)", "for", "four", "indigenous", "languages:", "Aymara,", "Ashaninka,", "Quechua", "and", "Shipibo-Konibo."], "cited_papers": [{"title": "Subword regularization: Improving neural network translation models with multiple subword candidates", "year": "2018", "authors": ["Taku Kudo"]}], "target_citation_location": 38, "citation_locations": [38, 44, 46, 49], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "d8e0ca45-a15a-4789-99cf-beae9301c6cf", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["The", "use", "of", "both", "language", "and", "vision", "transfer", "learning", "is", "important", "for", "multimodal", "tasks.", "This", "line", "of", "research", "has", "attracted", "much", "attention", "with", "various", "new", "language-vision", "models,", "such", "as", "VilBERT", "(Lu et al., 2019),", "12-in-1", "(Lu et al., 2020).", "No", "participants", "employ", "into", "this", "approach", "in", "the", "ReINTEL", "challenge", "due", "to", "the", "lack", "of", "language", "and", "vision", "pre-trained", "models", "in", "Vietnamese.", "Moreover,", "it", "is", "required", "to", "have", "extensive", "computer", "resources", "for", "applying", "this", "approach", "in", "a", "data", "challenge.", "In", "the", "future,", "we", "expect", "to", "see", "more", "research", "done", "in", "this", "direction", "because", "both", "images", "and", "texts", "are", "essential", "to", "SNS", "issues."], "cited_papers": [{"title": "Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks", "year": "1908", "authors": ["Jiasen Lu", "Dhruv Batra", "Devi Parikh", "Stefan Lee"]}], "target_citation_location": 30, "citation_locations": [30, 32], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d909c729-1c38-46f4-ba99-17c657130f02", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["This", "grammar", "was", "developed", "and", "refined", "in", "a", "corpus-based", "fashion", "(e.g.", "see", "Black, 1993)", "by", "testing", "against", "sentences", "from", "the", "Susanne", "corpus", "(Sampson, 1994),", "a", "138K", "word", "treebanked", "and", "balanced", "subset", "of", "the", "Brown", "corpus", "1."], "cited_papers": [{"title": "Statistically-Driven Computer Grammars of English: The IBM/ Lancaster Approach", "year": "1993", "authors": ["E Black", "R Garside", "G Leech"]}], "target_citation_location": 12, "citation_locations": [12, 21], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "d91f0dbb-f313-4c5f-8151-61b42c517741", "citing_paper": {"title": "End-to-end ASR to jointly predict transcriptions and linguistic annotations", "year": 2021, "authors": ["Motoi Omachi", "Yuya Fujita", "Shinji Watanabe", "Matthew Wiesner"]}, "text": ["One", "frequently", "used", "NN", "architecture", "(Ueno et al., 2018, Gowda et al., 2019, Sanabria and Metze, 2018, Adams et al., 2019)", "that", "maximizes", "Eq.", "(3)", "is", "the", "O2M", "model", "trained", "with", "multi-task", "learning.", "Fig.", "1(a)", "shows", "the", "architecture", "of", "the", "model.", "The", "O2M", "model", "outputs", "several", "types", "of", "sequences", "independently.", "In", "other", "words,", "multi-task", "learning", "is", "derived", "by", "assuming", "conditional", "independence", "of", "output", "token", "types", "for", "Eq.", "(3),", "as", "follows:"], "cited_papers": [{"title": "Multi-task multi-resolution char-to-BPE cross-attention decoder for end-to-end speech recognition", "year": "2019", "authors": ["D Gowda", "A Garg", "K Kim", "M Kumar", "C Kim"]}, {"title": "Massively multilingual adversarial speech recognition", "year": "2019", "authors": ["O Adams", "M Wiesner", "S Watanabe", "D Yarowsky"]}, {"title": "Acoustic-to-word attention-based model complemented with character-level CTC-based model", "year": "2018", "authors": ["S Ueno", "H Inaguma", "M Mimura", "T Kawahara"]}, {"title": "Hierarchical multitask learning with CTC", "year": "2018", "authors": ["R Sanabria", "F Metze"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "group", "annotations": [[2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d924752c-106d-433e-928a-c21b4fe96a10", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["The", "goal", "of", "statistical", "machine", "translation", "is", "to", "produce", "a", "target", "sentence", "e", "from", "a", "source", "sentence", "f.", "It", "is", "today", "common", "practice", "to", "use", "phrases", "as", "translation", "units", "[4, 5]", "and", "a", "log", "linear", "framework", "in", "order", "to", "introduce", "several", "models", "explaining", "the", "translation", "process:"], "cited_papers": [{"title": "Statistical phrasedbased machine translation", "year": "2003", "authors": ["P Koehn", "F Och", "D Marcu"]}, {"title": "A systematic comparison of various statistical alignement models", "year": "2003", "authors": ["F Och", "H Ney"]}], "target_citation_location": 29, "citation_locations": [29], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "d92d23a4-a980-473e-b089-052ea437c200", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["Early", "work", "on", "the", "detection", "and", "classification", "of", "Named", "Entities", "in", "Arabic", "NER", "used", "a", "rule-based", "or", "grammar-based", "approach", "(Mesfar, 2007, Shaalan and Raza, 2007).", "Subsequently,", "the", "field", "shifted", "generally", "to", "a", "machine", "learning", "approach", "-thus", "avoiding", "the", "time-consuming", "and", "expensive", "maintenance", "of", "rule-sets.", "Within", "this", "general", "approach", "a", "wide", "variety", "of", "techniques", "have", "all", "been", "applied", "to", "the", "Arabic", "NER", "problem", "including", "Support", "Vector", "Machines", "(SVM)", "(Benajiba et al., 2008b),", "Conditional", "Random", "Fields", "(CRF)", "(Abdul-Hamid and Darwish, 2010, Benajiba et al., 2008a, AbdelRahman et al., 2010),", "Maximum", "Entropy", "(ME)", "(Benajiba et al., 2007),", "Hidden", "Markov", "Models", "(HMM)", "and", "Decision", "Trees", "(Nadeau and Sekine, 2007).", "Notably,", "Benajiba et al. (2007)", "developed", "an", "Arabic", "NER", "system,", "ANERsys", "1.0,", "which", "employed", "maximum", "entropy", "and", "could", "recognize", "four", "types", "of", "Named", "Entities."], "cited_papers": [{"title": "Arabic named entity recognition: An svm-based approach", "year": "2008", "authors": ["Yassine Benajiba", "Mona Diab", "Paolo Rosso"]}], "target_citation_location": 62, "citation_locations": [19, 62, 67, 71, 79, 81], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "d933e38e-3e62-4671-8792-708f83927afb", "citing_paper": {"title": "Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets", "year": 2021, "authors": ["George-Andrei Dima", "Dumitru-Clementin Cercel", "Mihai Dascalu"]}, "text": ["All", "three", "subtasks", "are", "addressed", "simultaneously", "using", "a", "Multi-Task", "Learning", "(MTL)", "architecture", "(Caruana, 1997)", "that", "leverages", "acquired", "knowledge", "from", "one", "subtask", "to", "another.", "Furthermore,", "we", "approached", "the", "challenge", "of", "unbalanced", "classes", "in", "the", "first", "subtask", "by", "considering", "class", "weights", "and", "by", "augmenting", "the", "training", "data", "set."], "cited_papers": [{"title": "Multitask learning", "year": "1997", "authors": ["Rich Caruana"]}], "target_citation_location": 12, "citation_locations": [12], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "d9469df9-033b-4bd6-aaa5-677ef78c9517", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["that", "disentangled", "representations", "are", "likely", "to", "be", "easier", "to", "discriminate,", "although", "the", "role", "of", "sparsely", "learned", "representations", "could", "contribute", "to", "MAT-VAE's", "success", "as", "well", "(Prokhorov et al., 2020)."], "cited_papers": [{"title": "Hierarchical sparse variational autoencoder for text encoding", "year": "2020", "authors": ["Victor Prokhorov", "Yingzhen Li", "Ehsan Shareghi", "Nigel Collier"]}], "target_citation_location": 24, "citation_locations": [24], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]]}
{"id": "d963ddf8-2591-4a7f-9c2f-9f83e44440b3", "citing_paper": {"title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection", "year": 2021, "authors": ["Henry Weld", "Guanghao Huang", "Jean Lee", "Tongshu Zhang", "Kunze Wang", "Xinghong Guo", "Siqu Long", "Josiah Soyeon", "Caren Han"]}, "text": ["As", "the", "popularity", "of", "multi-player", "online", "games", "has", "grown,", "the", "phenomenon", "of", "in-game", "toxic", "behavior", "has", "taken", "root", "within", "them.", "Toxic", "behavior", "is", "strongly", "present", "in", "recent", "online", "games", "and", "is", "problematic", "to", "the", "gaming", "industry", "(Adinolf and Turkay, 2018).", "For", "instance,", "74%", "of", "US", "players", "of", "such", "games", "report", "harassment", "with", "65%", "experiencing", "severe", "harassment.", "(ADL, 2019)."], "cited_papers": [{"title": "Free to play: Hate, harassment and positive social experiences in online games", "year": "2019", "authors": ["Adl unk"]}], "target_citation_location": 53, "citation_locations": [36, 53], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "d96c1858-24e6-4bd2-8674-796121d73a46", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["For", "the", "experiments,", "we", "used", "a", "Transformer-base", "model", "(Vaswani et al., 2017)", "with", "the", "default", "configuration", "in", "Marian", "NMT", "(Junczys-Dowmunt et al., 2018).", "The", "steps", "are", "as", "follows:"], "cited_papers": [{"title": "Attention is all you need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 8, "citation_locations": [8, 16], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0]]}
{"id": "da16dd57-31a8-4be1-b089-10279c3a9b67", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["More", "recently", "and", "following", "the", "general", "trend", "towards", "neural", "approaches,", "Gridach (2016)", "developed", "a", "character", "aware", "neural", "network", "model", "which", "attempts", "to", "capture", "contextual", "characteristics", "in", "Arabic", "by", "placing", "a", "CRF", "on", "top", "of", "a", "Bi-LSTM.", "This", "provided", "a", "hard", "state-of-the-art", "for", "other", "systems", "to", "beat", "and", "provides", "the", "foundation", "of", "our", "own", "approach.", "Very", "recently,", "Ali et al. (2019)", "applied", "a", "neural", "network", "model", "with", "a", "multi-attention", "layer", "to", "extract", "Arabic", "NEs.", "They", "used", "two", "attention", "units,", "the", "embedding", "attention", "layer,", "and", "the", "self-attention", "unit.", "They", "achieved", "an", "F1", "score", "of", "91.31", "to", "achieve", "a", "new", "stateof-the-art", "on", "a", "large", "dataset", "proposed", "for", "evaluation", "in", "the", "same", "work.", "At", "the", "same", "time,", "Khalifa and Shaalan (2019)", "used", "character", "Convolutional", "Neural", "Networks", "(CNN)", "as", "a", "replacement", "for", "characterlevel", "bidirectional", "Long", "Short-Term", "Memory", "(LSTM)", "in", "Arabic", "NER.", "Their", "proposed", "system", "was", "able", "to", "outperform", "the", "state-of-art", "systems,", "including", "character-level", "Bi-LSTM", "on", "various", "standard", "Arabic", "NER", "corpora.", "Antoun et al. (2020)", "proposed", "AraBERTv0.1", "which", "involves", "pretraining", "the", "BERT", "transformer", "model", "for", "the", "Arabic", "language.", "They", "compared", "AraBERTv0.1", "and", "the", "Bi-LSTM-CRF", "model", "on", "ANERCorp,", "the", "former", "achieved", "84.2", "F1", "scores", "whereas", "the", "later", "achieved", "81.7.", "Most", "recently,", "Sheng et al. (2020)", "proposed", "a", "transfer", "learning", "approach", "for", "Arabic", "NER", "with", "Deep", "Neural", "Networks", "where", "they", "showed", "that", "their", "model", "outperformed", "significantly", "the", "Bi-LSTM-CRF", "model.", "We", "have", "not", "considered", "this", "approach", "here", "because", "our", "aim", "is", "not", "to", "create", "a", "new", "state", "of", "the", "art", "model", "but", "to", "show", "the", "effectiveness", "of", "incorporating", "language", "specific", "characteristics", "in", "the", "form", "of", "embeddings."], "cited_papers": [{"title": "Poise: Efficient cross-domain chinese named entity recognization via transfer learning", "year": "2020", "authors": ["Jiabao Sheng", "Aishan Wumaier", "Zhe Li"]}], "target_citation_location": 184, "citation_locations": [10, 55, 109, 148, 184], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "da577feb-fbb8-41ae-a798-6fd9ffaf46a7", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["Robustness", "and", "Bias", "An", "increasing", "body", "of", "work", "has", "been", "conducted", "on", "understanding", "robustness", "in", "deep", "neural", "networks,", "particularly,", "how", "models", "sometimes", "might", "exploit", "spurious", "correlations", "(Tu et al., 2020, Sagawa et al., 2020)", "and", "take", "shortcuts", "(Geirhos et al., 2020)", "Figure", "2:", "Our", "proposed", "pipeline", "to", "identify", "spurious", "correlations", "at", "scale.", "In", "the", "first", "step,", "we", "extract", "important", "tokens", "from", "input", "text.", "In", "the", "second", "step,", "we", "analyze", "extracted", "tokens", "from", "various", "datasets", "to", "identify", "likely", "\"spurious\"", "tokens.", "Finally,", "we", "further", "validate", "the", "output", "from", "the", "second", "step", "through", "knowledge-aware", "perturbation."], "cited_papers": [{"title": "Shortcut learning in deep neural networks", "year": "2020", "authors": ["Robert Geirhos", "J\u00f6rn-Henrik Jacobsen", "Claudio Michaelis", "Richard Zemel", "Wieland Brendel", "Matthias Bethge", "Felix Wichmann"]}], "target_citation_location": 30, "citation_locations": [26, 30], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "da5e9de2-d926-44ca-b819-5a4c10580559", "citing_paper": {"title": "drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM", "year": 2022, "authors": ["Dylan Phelps"]}, "text": ["For", "predicting", "the", "similarity", "scores,", "a", "separate", "model", "is", "used", "for", "each", "of", "the", "languages", "BERT-Base", "(Devlin et al., 2019)", "for", "English,", "BERTimbau", "for", "Portuguese,", "and", "Bertinho-Base", "for", "Galician.", "The", "created", "BERTRAM", "embeddings", "for", "each", "of", "the", "idioms", "found", "within", "the", "task", "are", "added", "into", "the", "embedding", "matrix", "of", "the", "relevant", "model.", "These", "models", "are", "used", "within", "a", "Sentence", "BERT", "(Reimers and Gurevych, 2019)", "setup,", "implemented", "using", "the", "SentenceTransformers", "library,", "which", "consists", "of", "a", "siamese", "network", "structure", "that", "uses", "mean", "squared", "error", "over", "the", "cosine", "similarities", "of", "the", "input", "sentences", "as", "it's", "loss", "function.", "This", "allows", "us", "to", "use", "the", "contextualised", "embedding", "outputs", "of", "our", "BERT", "networks", "to", "find", "cosine", "similarity", "between", "a", "given", "pair", "of", "sentences."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 16, "citation_locations": [16, 57], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "daae2ef1-fcce-4e29-8a71-0c489604cffd", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["The", "caption", "generation", "backbone", "is", "a", "transformerbased", "encoder-decoder", "proposed", "by", "Vaswani et al. (2017),", "which", "mainly", "employs", "a", "multi-head", "attention", "mechanism", "and", "achieves", "top-tier", "performance", "in", "many", "sequential", "related", "tasks.", "Here,", "we", "highlight", "several", "task-oriented", "modifications."], "cited_papers": [{"title": "Attention is all you need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 10, "citation_locations": [10], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]}
{"id": "daf92ca4-3924-4ac2-919e-1cbcf8ab9bd7", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["The", "last", "problem", "is", "not", "necessarily", "linked", "to", "finite-state", "approaches,", "but", "in", "two-level", "morphology,", "cf.", "Koskenniemi (1983),", "Antworth (1990),", "the", "way", "features", "are", "handled", "is", "specifically", "geared", "towards", "inflection.", "The", "first", "two", "problems", "are", "inherent", "in", "finite-state", "technology", "and", "can", "only", "be", "handled", "by", "one", "of", "the", "following", "strategies:"], "cited_papers": [{"title": "Two-Level Morphology: A General Computational Model for Word-Form Recognition and Production", "year": "1983", "authors": ["Kimmo Koskenniemi"]}], "target_citation_location": 15, "citation_locations": [15, 16], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "db0138ad-4de2-4e08-b6ef-9a0c1950290f", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["In", "fact,", "deploying", "ever-larger", "models", "raises", "questions", "and", "concerns", "about", "the", "increasing", "magnitude", "of", "the", "temporal,", "financial,", "and", "environmental", "cost", "of", "training", "and", "usability", "(Strubell et al., 2019, Moosavi et al., 2020).", "Typically,", "due", "to", "their", "resource", "requirements,", "these", "models", "are", "trained", "and", "deployed", "for", "industrial", "operations", "on", "remote", "servers.", "This", "leads", "to", "a", "high", "use", "of", "over-the-air", "communications,", "which", "are", "particularly", "resourceintensive", "(G\u00fcnd\u00fcz et al., 2019).", "In", "particular,", "some", "NLP", "applications", "(speech", "recognition,", "speech", "to", "text,", "etc.)", "have", "some", "known", "problems", "related", "to", "network", "latency,", "transmission", "path", "difficulties,", "or", "privacy", "concerns.", "To", "reduce", "the", "impact", "of", "these", "communications,", "there", "is", "a", "solution", "that", "is", "to", "allow", "these", "models", "to", "run", "directly", "on", "peripheral", "or", "mobile", "devices,", "that", "is,", "in", "environments", "with", "limited", "resources", "that", "require", "lightweight,", "responsive", "models", "and", "energy", "efficiency.", "Reducing", "the", "size", "of", "the", "models", "is", "therefore", "one", "of", "the", "increasingly", "favoured", "avenues,", "especially", "for", "the", "reduction", "of", "memory", "resources", "and", "computation", "time", "involved", "in", "training", "and", "use."], "cited_papers": [{"title": "Machine learning in the air", "year": "2019", "authors": ["Deniz G\u00fcnd\u00fcz", "Nicholas Paul De Kerret", "David Sidiropoulos", "Chandra Gesbert", "Mihaela Murthy", "unk Van Der Schaar"]}], "target_citation_location": 56, "citation_locations": [24, 56], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "db55c12d-f54b-4cc8-bc2b-1bfa9539d782", "citing_paper": {"title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables", "year": 2022, "authors": ["Nan Hu", "Zirui Wu", "Yuxuan Lai", "Xiao Liu", "Yansong Feng"]}, "text": ["Specifically,", "for", "the", "document", "retrieval", "step,", "we", "narrow", "the", "search", "space", "with", "an", "information", "retrieval", "model", "DRQA", "(Chen et al., 2017)", "and", "then", "rerank", "the", "retrieved", "pages.", "For", "the", "evidence", "retrieval", "step,", "we", "design", "a", "multi-turn", "cell", "selector", "to", "extract", "sentence", "evidence", "and", "table", "evidence", "respectively,", "and", "select", "evidence", "cells", "from", "tables.", "Finally,", "we", "propose", "a", "Dual", "Channel", "Unified", "Format", "verification", "model", "(DCUF,", "shown", "in", "Figure", "2)", "for", "the", "verification", "step.", "DCUF", "converts", "evidence", "to", "a", "unified", "table/sentence", "format", "with", "carefully-designed", "evidence", "conversion", "and", "re-organization", "methods", "in", "each", "channel,", "and", "combine", "dual-channel", "encodings", "to", "make", "the", "final", "prediction."], "cited_papers": [{"title": "Reading Wikipedia to answer opendomain questions", "year": "2017", "authors": ["Danqi Chen", "Adam Fisch", "Jason Weston", "Antoine Bordes"]}], "target_citation_location": 17, "citation_locations": [17], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "db903d99-0333-41eb-8847-af58e210ef76", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["The", "existing", "self-supervised", "VLP", "approaches", "can", "be", "largely", "categorized", "into", "two", "groups:", "the", "twostep", "pretraining", "and", "the", "end-to-end", "pretraining,", "depending", "on", "whether", "they", "rely", "on", "visual", "object", "embeddings", "as", "input", "for", "the", "Transformer.", "Two-step", "Pretraining", "firstly", "employ", "an", "off-theshelf", "object", "detector", "to", "convert", "an", "image", "into", "a", "set", "of", "object", "embeddings,", "and", "then", "feed", "them", "into", "a", "Transformer", "jointly", "with", "text", "embeddings", "to", "generate", "their", "multi-modal", "representations.", "Hence", "their", "visual", "feature", "networks", "are", "not", "optimized", "during", "both", "pretraining", "&amp,", "finetuning", "stage.", "Most", "of", "these", "methods,", "such", "as", "LXMERT", "(Tan and Bansal, 2019)", ",ViLBert", "(Lu et al., 2019),", "VL-Bert", "(Su et al., 2020),", "Unicoder-VL", "(Li et al., 2020a)", "and", "UNITER", "(Chen et al., 2020),", "adopt", "BERT-like", "objectives", "to", "train", "their", "networks,", "which", "include", "Masked", "Language", "Modeling", "(MLM),", "Masked", "Vision", "Modeling", "(MVM)", "and", "Image-Text", "Matching", "(ITM).", "In", "addition,", "VILLA", "(Gan et al., 2020)", "develops", "an", "advanced", "adversarial", "pretraining", "and", "finetuning", "strategy", "to", "improve", "generalization", "ability.", "OSCAR", "(Li et al., 2020b)", "and", "VINVL", "(Zhang et al., 2021)", "introduce", "object", "labels", "to", "bridge", "different", "modalities", "and", "revisit", "the", "importance", "of", "visual", "features.", "Ernie-ViL", "(Yu et al., 2020)", "exploits", "structured", "knowledge", "in", "the", "text", "and", "constructs", "scene", "graph", "prediction", "tasks", "to", "learn", "joint", "representations.", "UNIMO", "(Li et al., 2021)", "proposes", "a", "unified", "model", "to", "leverage", "large-scale", "free", "text", "corpus,", "image", "collections,", "and", "image-text", "pairs", "simultaneously", "through", "a", "contrastive", "learning", "task.", "Despite", "their", "strong", "performances,", "those", "methods", "are", "limited", "by", "the", "object", "detector", "and", "neglect", "visual", "cues", "outside", "of", "object", "regions,", "often", "leading", "to", "mistakes", "in", "downstream", "tasks."], "cited_papers": [{"title": "Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks", "year": "2019", "authors": ["Jiasen Lu", "Dhruv Batra", "Devi Parikh", "Stefan Lee"]}], "target_citation_location": 90, "citation_locations": [88, 90, 92, 94, 97, 122, 136, 139, 155, 173], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "dc4c5f4f-581e-4686-871c-71197b8b9b69", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["A", "probabilistic", "LR", "parser", "was", "trained", "with", "the", "integrated", "grammar", "by", "exploiting", "the", "Susanne", "treebank", "bracketing.", "An", "LR", "parser", "(Briscoe and Carroll, 1993)", "was", "applied", "to", "unlabelled", "brack", "eted", "sentences", "from", "the", "Susanne", "treebank,", "and", "a", "new", "treebank", "of", "1758", "correct", "and", "complete", "analyses", "with", "respect", "to", "the", "integrated", "grammar", "was", "constructed", "semi-automatically", "by", "manu", "ally\u2022", "resolving", "the", "remaining", "ambiguities.", "250", "sentences", "from", "the", "new", "treebank", "were", "kept", "back", "for", "testing.", "The", "remainder,", "together", "with", "a", "further", "set", "of", "analyses", "from", "2285", "tree", "bank", "sentences", "that", "were", "not", "checked", "manually,", "were", "used", "to", "train", "a", "probabilistic", "version", "of", "the", "LR", "parser,", "using", "Good-Turing", "smoothing", "to", "estimate", "the", "probability", "of", "unseen", "transitions", "in", "the", "LALR(", "1)", "table", "(Briscoe and Carroll, 1993, Carroll, 1993).", "The", "probabilistic", "parser", "can", "then", "return", "a", "ranking", "of", "all", "possible", "analyses", "for", "a", "sentence,", "or", "efficiently", "return", "just", "the", "n-most", "probable", "(Carroll, 1993)."], "cited_papers": [{"title": "Practical unification-based parsing of natural language", "year": "1993", "authors": ["J Carroll"]}], "target_citation_location": 136, "citation_locations": [19, 113, 136], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "dc51c7f7-12a4-4851-a436-b0219281df69", "citing_paper": {"title": "The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008", "year": 2008, "authors": ["Holger Schwenk", "Yannick Est\u00e8ve", "Sadaf Rauf"]}, "text": ["This", "paper", "describes", "the", "system", "developed", "by", "the", "LIUM", "laboratory", "for", "the", "2008", "IWSLT", "evaluation.", "We", "only", "participated", "in", "the", "Arabic/English", "BTEC", "task.", "The", "architecture", "of", "the", "system", "is", "very", "similar", "to", "a", "large", "system", "built", "for", "the", "NIST", "Arabic/English", "task", "[1]", "or", "a", "system", "built", "for", "the", "translation", "between", "French", "and", "English", "[2].", "All", "three", "are", "statistical", "phrase-based", "machine", "translation", "systems", "based", "on", "the", "freely", "available", "Moses", "decoder", "[3],", "with", "extensions", "for", "rescoring", "nbest", "lists", "with", "a", "continuous", "space", "language", "model", "in", "a", "second", "pass.", "No", "system", "combination", "is", "used."], "cited_papers": [{"title": "Moses: Open source toolkit for statistical machine translation", "year": "2007", "authors": ["Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens", "Chris Dyer", "Ondrej Bojar", "Alexandra Constantin", "Evan Herbst"]}], "target_citation_location": 69, "citation_locations": [41, 53, 69], "citation_type": "single", "annotations": [[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0]]}
{"id": "dc597aad-0377-40f8-855d-34efc52a1fe8", "citing_paper": {"title": "Associating semantic components with intersective Levin classes", "year": 1997, "authors": ["Hoa Dang", "Joseph Rosenzweig", "Martha Palmer"]}, "text": ["Levin", "verb", "classes", "are", "based", "on", "the", "ability", "of", "a", "verb", "to", "occur", "or", "not", "occur", "in", "pairs", "of", "syntactic", "frames", "that", "are", "in", "some", "sense", "meaning", "preserving,", "hence", "the", "term", "diathesis", "alternations", "[8].", "The", "distribution", "of", "syntactic", "frames", "a", "verb", "can", "appear", "in", "determines", "its", "class", "membership.", "The", "fundamental", "assumption", "is", "that", "the", "syntactic", "frames", "are", "a", "direct", "reflection", "of", "the", "underlying", "semantics.", "Levin", "classes", "are", "supposed", "to", "provide", "very", "specific", "sets", "of", "syntactic", "frames", "that", "are", "associated", "with", "the", "individual", "classes."], "cited_papers": [{"title": "English Verb Classes and Alternations", "year": "1993", "authors": ["B Levin"]}], "target_citation_location": 33, "citation_locations": [33], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "dd28c9a1-7c80-4f89-af04-4d619ebe1142", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["Totale", "toolkit", "(Erjavec, 2006)", "was", "used", "to", "POS", "tag", "(Brants, 2000)", "and", "lemmatize", "(Erjavec et al., 2004)", "words", "in", "the", "bilingual", "word", "list,", "POS", "tagger", "was", "also", "used", "in", "automatic", "paradigm", "classifying,", "see", "chapter", "3.3.1", "for", "further", "description."], "cited_papers": [{"title": "TnT -a statistical part-of-speech tagger", "year": "2000", "authors": ["Thorsten Brants"]}], "target_citation_location": 8, "citation_locations": [2, 8, 11], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "dd3e417c-7e23-4a42-b28d-3b28b7bfc5f2", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["With", "the", "success", "of", "BERT", "(Devlin et al., 2018)", "in", "language", "modeling,", "self-supervised", "Vision-and-Language", "Pretraining", "(VLP)", "has", "attracted", "much", "interest", "from", "AI", "community,", "which", "aims", "to", "learn", "generalizable", "multi-modal", "representations", "from", "largescale", "image-text", "data.", "Combined", "with", "a", "pretrainthen-transfer", "strategy,", "it", "shows", "great", "potential", "in", "tackling", "vision", "and", "language", "reasoning", "tasks,", "such", "as", "image-text", "retrieval,", "visual", "question", "answering", "(VQA)", "and", "visual", "entailment", "(Antol et al., 2015, Lee et al., 2018, Xie et al., 2019, Liu et al., 2021 Liu et al., , 2020)).", "A", "critical", "step", "in", "such", "representation", "learning", "is", "to", "jointly", "model", "linguistic", "entities", "and", "visual", "semantic", "concepts", "(e.g.,", "attributes,", "objects,", "and", "relations),", "as", "well", "as", "their", "alignment.", "However,", "this", "is", "particularly", "challenging", "due", "to", "large", "discrepancy", "in", "visual", "and", "language", "representations", "(pixels", "vs", "words)", "and", "lack", "of", "entity-level", "cross-modal", "correspondence", "in", "supervision."], "cited_papers": [{"title": null, "year": "2019", "authors": ["Ning Xie", "Farley Lai", "Derek Doran", "Asim Kadav"]}, {"title": null, "year": null, "authors": ["unknown"]}, {"title": "Vqa: Visual question answering", "year": "2015", "authors": ["Stanislaw Antol", "Aishwarya Agrawal", "Jiasen Lu", "Margaret Mitchell", "Dhruv Batra", "Lawrence Zitnick", "Devi Parikh"]}], "target_citation_location": 58, "citation_locations": [5, 58], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "dd4ef0be-16ed-449e-b488-468f67d747a9", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["SQuAD", "(v1.1)", "(Rajpurkar et al., 2016)"], "cited_papers": [{"title": "SQuAD: 100,000+ questions for machine comprehension of text", "year": "2016", "authors": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang"]}], "target_citation_location": 2, "citation_locations": [2], "citation_type": "single", "annotations": [[1, 1, 1]]}
{"id": "ddc10399-1e68-4ac9-b0f3-ecaa56a4a04a", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["To", "take", "advantage", "of", "the", "potential", "lexical", "sharing", "of", "the", "languages", "(e.g.", "loanwords)", "and", "address", "the", "polysynthetic", "nature", "of", "the", "indigenous", "languages,", "we", "trained", "a", "unique", "multilingual", "segmentation", "model", "by", "sampling", "all", "languages", "with", "a", "uniform", "distribution.", "We", "used", "the", "unigram", "model", "implementation", "in", "SentencePiece", "(Kudo and Richardson, 2018)", "with", "a", "vocabulary", "size", "of", "32,000."], "cited_papers": [{"title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing", "year": "2018", "authors": ["Taku Kudo", "John Richardson"]}], "target_citation_location": 45, "citation_locations": [45], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "de0b30e0-f0c6-4c52-bb86-3848564257e9", "citing_paper": {"title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables", "year": 2022, "authors": ["Nan Hu", "Zirui Wu", "Yuxuan Lai", "Xiao Liu", "Yansong Feng"]}, "text": ["We", "get", "a", "global", "evidence", "table", "by", "stacking", "the", "m", "tables", "from", "sentences", "and", "n", "tables", "from", "tabular", "evidence,", "as", "illustrated", "in", "Figure", "3.", "Then,", "we", "feed", "the", "claim", "and", "the", "global", "evidence", "table", "to", "a", "pretrained", "table", "model,", "TAPAS", "(Herzig et al., 2020),", "and", "get", "the", "tabular", "format", "evidence", "representation."], "cited_papers": [{"title": "TaPas: Weakly supervised table parsing via pre-training", "year": "2020", "authors": ["Jonathan Herzig", "Krzysztof Nowak", "Thomas M\u00fcller", "Francesco Piccinno", "Julian Eisenschlos"]}], "target_citation_location": 40, "citation_locations": [40], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "de17a61d-3b0b-428e-9573-9e1c1e1c5f34", "citing_paper": {"title": "DRS Parsing as Sequence Labeling", "year": 2022, "authors": ["Minxing Shen", "Kilian Evang"]}, "text": ["2", "Encoding", "Anchored", "DRSs", "as", "Sequences", "G\u00f3mez-Rodr\u00edguez and Vilares (2018),", "Strzyz et al. (2019),", "Vilares et al. (2020)", "encode", "syntax", "trees", "as", "token", "labels", "to", "cast", "syntactic", "parsing", "as", "a", "sequence", "labeling", "task.", "We", "apply", "a", "similar", "method", "to", "DRS", "parsing.", "We", "will", "use", "a", "simplified", "example", "from", "the", "Parallel", "Meaning", "Bank", "(PMB,", "Abzianidze et al., 2017)", "for", "exposition."], "cited_papers": [{"title": "Viable dependency parsing as sequence labeling", "year": "2019", "authors": ["Michalina Strzyz", "David Vilares", "Carlos G\u00f3mez-Rodr\u00edguez"]}], "target_citation_location": 7, "citation_locations": [6, 7, 8, 44], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "de9d6dfc-c29d-4951-8cb8-85d3731fbfc2", "citing_paper": {"title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection", "year": 2021, "authors": ["Henry Weld", "Guanghao Huang", "Jean Lee", "Tongshu Zhang", "Kunze Wang", "Xinghong Guo", "Siqu Long", "Josiah Soyeon", "Caren Han"]}, "text": ["For", "our", "automated", "slot", "labelling,", "we", "generated", "the", "game", "toxicity", "lexicon", "by", "taking", "the", "supplemental", "materials", "released", "by", "M\u00e4rtens et al. (2015)", "and", "ElSherief et al. (2018)", "and", "the", "list", "of", "words", "banned", "by", "Google", "6.", "We", "then", "added", "variants", "or", "new", "toxic", "words", "found", "in", "the", "utterances", "extracted", "from", "Kaggle.", "For", "intent", "labelling,", "all", "volunteer", "annotators", "were", "recruited", "from", "academia", "and", "research", "students.", "They", "were", "informed", "about", "toxic", "behavior", "in", "online", "games", "before", "handling", "the", "data.", "Our", "instructions", "allowed", "them", "to", "feel", "free", "to", "leave", "if", "they", "were", "uncomfortable", "with", "the", "content.", "Due", "to", "privacy", "considerations,", "we", "group", "them", "by", "online", "game", "experiences", "and", "do", "not", "take", "into", "account", "annotators'", "demographic", "information."], "cited_papers": [{"title": "Toxicity detection in multiplayer online games", "year": "2015", "authors": ["Marcus M\u00e4rtens", "Siqi Shen", "Alexandru Iosup", "Fernando Kuipers"]}], "target_citation_location": 18, "citation_locations": [18, 20], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "deddf69d-1f88-4cc4-9c39-c4e821f6891d", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["The", "two", "structures", "from", "which", "she", "hoped", "the", "most", "were", "lattices", "and", "'fans',", "a", "notion", "she", "derived", "from", "some", "work", "of", "Brouwer (1952).", "MMB", "believed", "lattices", "(Masterman, 1959a)", "to", "be", "the", "underlying", "structure", "of", "thesauri", "while", "fans", "(Masterman, 1957a)", "mapped", "the", "spreading", "out", "of", "the", "new", "senses", "of", "words,", "indefinitely", "into", "the", "future.", "She", "spent", "some", "time", "trying", "to", "amalgamate", "both", "representations", "into", "a", "single", "structure.", "These", "efforts", "have", "not", "met", "with", "much", "success", "nor", "have", "they", "been", "taken", "up", "by", "others,", "although", "Zellig", "Harris", "did", "at", "one", "time", "toy", "with", "lattices", "as", "language", "structures,", "and", "Mellish has recently (1988)", "sought", "to", "link", "lattice", "structures", "again", "to", "Halliday's", "categories", "of", "grammar", "and", "semantics."], "cited_papers": [{"title": "Historical background, principles and methods of intuitionism", "year": "1952", "authors": ["L Brouwer"]}], "target_citation_location": 21, "citation_locations": [21, 25, 35, 93], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "df0059af-5216-4ac1-bf44-31a066bee86d", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["We", "used", "Plutchik's", "core", "emotions", "as", "our", "annotation", "scheme", "resulting", "in", "8", "distinct", "emotion", "categories", "plus", "neutral.", "The", "Sentimentator", "platform", "( \u00d6hman and Kajava, 2018, \u00d6hman et al., 2018)", "allows", "for", "the", "annotation", "of", "intensities", "resulting", "in", "what", "is", "essentially", "30", "emotions", "and", "sentiments,", "however,", "as", "the", "intensity", "score", "is", "not", "available", "for", "all", "annotations,", "the", "intensity", "scores", "were", "discarded.", "The", "granularity", "of", "our", "annotations", "roughly", "correspond", "to", "sentence-level", "annotations,", "although", "as", "our", "source", "data", "is", "movie", "subtitles,", "our", "shortest", "subtitle", "is!", "and", "the", "longest", "subtitle", "consists", "of", "three", "separate", "sentences.", "A", "majority", "of", "the", "subtitles", "for", "English", "were", "assigned", "one", "emotion", "label", "(78%),", "17%", "were", "assigned", "two,", "and", "roughly", "5%", "had", "three", "or", "more", "categories", "(see", "also", "Table", "3)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 20, "citation_locations": [20], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "df13d196-e144-4523-9dc6-fe102bc04ada", "citing_paper": {"title": "Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model", "year": 2022, "authors": ["Richard Futrell"]}, "text": ["A", "related", "literature", "in", "corpus", "linguistics", "and", "NLP", "has", "explored", "the", "nature", "of", "restricted", "binary", "word", "co-occurrences,", "called", "collocations", "(for", "recent", "examples,", "see", "Savary et al., 2017, Kutuzov et al., 2017, Garcia et al., 2021, Espinosa Anke et al., 2021).", "This", "work", "focuses", "narrowly", "on", "the", "estimation", "of", "bilexical", "conditional", "probabilities,", "which", "are", "often", "inputs", "to", "models", "for", "collocation", "detection."], "cited_papers": [{"title": "Assessing the representations of idiomaticity in vector models with a noun compound dataset labeled at type and token levels", "year": "2021", "authors": ["Marcos Garcia", "Tiago Vieira", "Carolina Scarton", "Marco Idiart", "Aline Villavicencio"]}, {"title": "The PARSEME shared task on automatic identification of verbal multiword expressions", "year": "2017", "authors": ["Agata Savary", "Carlos Ramisch", "Silvio Cordeiro", "Federico Sangati", "Veronika Vincze", "Behrang Qasem-Izadeh", "Marie Candito", "Fabienne Cap", "Voula Giouli", "Ivelina Stoyanova", "Antoine Doucet"]}, {"title": "Evaluating language models for the retrieval and categorization of lexical collocations", "year": "2021", "authors": ["Luis Espinosa Anke", "Joan Codina-Filba", "Leo Wanner"]}, {"title": "Clustering of Russian adjective-noun constructions using word embeddings", "year": "2017", "authors": ["Andrey Kutuzov", "Elizaveta Kuzmenko", "Lidia Pivovarova"]}], "target_citation_location": 23, "citation_locations": [23], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "df2bbd85-0f68-4bd7-b10a-e37f2a319469", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["Data", "set.", "The", "stimulus", "set", "includes", "4,479", "sentences", "(74,953", "tokens)", "selected", "from", "the", "English", "Web", "Treebank", "(Bies et al., 2012),", "covering", "the", "genres", "weblogs,", "newsgroups,", "reviews", "and", "Yahoo", "Answers.", "The", "mean", "sentence", "length", "is", "16.7", "words", "(standard", "deviation:", "12.23).", "75", "sessions", "of", "EEG", "data", "are", "included", "over", "20", "days,", "each", "lasting", "20-25", "minutes,", "from", "a", "single", "subject", "who", "read", "approximately", "five", "and", "a", "half", "iterations", "of", "the", "stimulus", "set", "(i.e.", "24,323", "sentences", "and", "404,205", "tokens", "in", "total,", "thereby", "substantially", "exceeding", "current", "freely", "accessible", "data", "sets,", "e.g.", "(Bhattasali et al., 2020).", "Three", "sessions", "were", "excluded", "because", "of", "data", "corruption."], "cited_papers": [{"title": "The alice datasets: fMRI & EEG observations of natural language comprehension", "year": "2020", "authors": ["Shohini Bhattasali", "Jonathan Brennan", "Wen-Ming Luh", "Berta Franzluebbers", "John Hale"]}], "target_citation_location": 83, "citation_locations": [16, 83], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "df3d43b3-8e7e-49ee-b2ab-12e26f0f270b", "citing_paper": {"title": "Effects of Word Alignment Visualization on Post-Editing Quality & Speed \u2020", "year": 2015, "authors": ["Lane Schwartz", "Isabel Lacruz", "Tatyana Bystrova"]}, "text": ["For", "each", "segment,", "the", "human", "rater", "was", "presented", "with", "a", "vertically-arranged", "list", "showing", "all", "variants", "of", "that", "segment.", "The", "first", "entry", "in", "each", "list", "was", "the", "segment", "in", "the", "source", "language", "(Russian).", "The", "source", "segment", "was", "followed", "by", "the", "reference", "translation", "in", "English.", "The", "subsequent", "eight", "entries", "were", "English", "translations", "of", "the", "source", "segment,", "presented", "in", "a", "randomized", "order.", "The", "English", "translations", "included", "the", "unedited", "machine", "translation", "output,", "as", "produced", "by", "Moses,", "a", "post-edited", "translation", "produced", "by", "a", "monolingual", "post-editor", "from", "Schwartz et al. (2014),", "and", "the", "six", "post-edited", "translations", "produced", "by", "the", "Russian-English", "bilingual", "posteditors", "in", "this", "study."], "cited_papers": [{"title": "Machine translation and monolingual postediting: The AFRL WMT-14 system", "year": "2014", "authors": ["L Schwartz", "T Anderson", "J Gwinnup", "K Young"]}], "target_citation_location": 81, "citation_locations": [81], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "df63b3d2-68c7-4a74-918a-5dfb787100d8", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["Note", "that", "the", "difference", "between", "total", "annotations", "excluding", "neutral", "(24,164)", "and", "the", "combined", "number", "of", "annotations", "(22, 424)", "differ", "because", "once", "the", "dataset", "was", "saved", "as", "a", "Python", "dictionary,", "identical", "lines", "were", "merged", "as", "one", "(i.e.", "some", "common", "movie", "lines", "like", "\"All", "right", "then!\"", "and", "\"I", "love", "you\"", "appeared", "multiple", "times", "from", "different", "sources).", "Additionally,", "lines", "annotated", "as", "both", "neutral", "and", "an", "emotion", "were", "removed", "from", "the", "neutral", "set."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "df77517d-588a-4c0b-8532-8ddd14712d0e", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["In", "this", "paper,", "our", "metric", "of", "interest", "is", "BERTScore", "(Zhang et al., 2020).", "To", "compute", "BERTScore,", "we", "first", "feed", "a", "reference", "and", "candidate", "translation", "for", "a", "given", "sentence", "into", "BERT,", "and", "retrieve", "their", "token", "level", "vector", "representations.", "Let", "z", "be", "the", "representations", "of", "the", "reference", "and", "\u1e91", "those", "of", "the", "candidate.", "Then", "we", "compute", "the", "precision", "and", "recall", "metrics", "for", "BERTScore", "by", "comparing", "each", "token", "representation", "z", "i", "of", "the", "reference", "translation", "to", "each", "token", "representation", "\u1e91j", "of", "the", "candidate", "translation", "as", "follows:P", "BERT", "=", "1", "|\u1e91|", "\u1e91j", "\u2208\u1e91", "max", "z", "i", "\u2208z", "z", "i", "\u1e91j", "R", "BERT", "=", "1", "|z|", "z", "i", "\u2208z", "max", "\u1e91j", "\u2208\u1e91", "z", "i", "\u1e91jThe", "F", "1", "score", "can", "be", "defined", "as", "usual.", "As", "BERTScore", "can", "range", "from", "-1", "to", "1,", "but", "most", "often", "inhabits", "the", "upper", "end", "of", "that", "range,", "its", "creators", "suggest", "the", "use", "of", "baseline", "scaling,", "which", "generally", "leaves", "BERTScore", "in", "the", "range", "[0,1],", "as", "desired", "for", "use", "with", "our", "prior", "formalization.", "Baseline", "rescaling", "is", "performed", "for", "P", "BERT", "asPBERT", "=", "P", "BERT", "\u2212", "a", "1", "\u2212", "aand", "likewise", "for", "R", "BERT,", "a", "is", "an", "empirical", "lower", "bound", "on", "observed", "BERTScore."], "cited_papers": [{"title": null, "year": "2020", "authors": ["Tianyi Zhang", "Varsha Kishore", "Felix Wu", "Kilian Weinberger", "Yoav Artzi"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "dfa13521-56fc-4ad0-8034-1d86d63485ea", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["Attention-guided", "Grounding", "A", "cross-attention", "matrix", "is", "generated", "in", "shape", "(N,", "T,", "L,", "H)", "during", "the", "transformer's", "decoding", "steps.", "Here", "N", "denotes", "the", "number", "of", "pre-detected", "visual", "objects,", "T", "denotes", "the", "number", "of", "tokens", "in", "a", "caption", "sentence", "after", "padding,", "L", "denotes", "the", "number", "of", "transformer", "layers,", "and", "H", "denotes", "the", "number", "of", "attention", "heads", "in", "transformer", "layers.", "Two", "linear", "projections", "and", "layer", "normalization", "(Ba et al., 2016)", "are", "applied", "sequentially", "on", "dimension", "L", "and", "H,", "respectively", "reducing", "the", "dimension", "to", "1.", "Thus,", "for", "a", "single", "instance,", "we", "eventually", "calculate", "an", "attention", "matrix", "A", "\u2208", "R", "N", "\u00d7T."], "cited_papers": [{"title": "Layer normalization. ArXiv", "year": "2016", "authors": ["Jimmy Ba", "J Kiros", "Geoffrey Hinton"]}], "target_citation_location": 63, "citation_locations": [63], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "dfbea9cb-9309-4521-ae76-602a88b6b00f", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["Another", "domain", "in", "which", "WM", "databases", "have", "been", "used", "is", "terminology.", "In", "collaboration", "with", "the", "UBS", "bank,", "a", "module", "was", "developed", "which", "recognizes", "banking", "terminology", "in", "unseen", "text", "and", "provides", "an", "on-line", "link", "to", "the", "relevant", "entry", "in", "a", "terminological", "database,", "cf.", "Zappatore &amp, ten Hacken (2000).", "Here", "the", "WFRules", "are", "used", "not", "only", "as", "a", "structuring", "device", "of", "the", "terminological", "lexicon,", "but", "also", "as", "a", "way", "for", "recognizing", "terms", "when", "they", "are", "'hidden'", "in", "nominalizations,", "compounds,", "etc.", "Thus,", "Verwaltungsrat", "('board", "of", "directors')", "is", "also", "recognized", "in", "Verwaltungsratsvakanz", "('vacancy", "in", "the", "board", "of", "directors').", "One", "of", "the", "reasons", "why", "WM", "is", "particularly", "suited", "to", "this", "task", "in", "a", "multilingual", "system", "(German,", "English,", "Italian)", "is", "that", "it", "can", "treat", "singleword", "and", "multi-word", "terms", "equally."], "cited_papers": [{"title": "Word Manager and Banking Terminology: Industrial Application of a General System", "year": "2000", "authors": ["Daniela Zappatore", "Pius Hacken"]}], "target_citation_location": 42, "citation_locations": [42], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "dfec6a62-320c-4664-9868-79b9cd78310c", "citing_paper": {"title": "Translation of Multiword Expressions Using Parallel Suffix Arrays", "year": 2006, "authors": ["Paul Mcnamee", "James Mayfield"]}, "text": ["In", "future", "work", "we", "hope", "to", "study", "the", "effect", "of", "corpus", "size", "and", "corpus", "diversity", "on", "translation", "effectiveness.", "We", "also", "hope", "to", "focus", "on", "evaluation", "of", "longer", "MWEs", "(i.e.,", "trigrams", "and", "longer)", "as", "well", "as", "consider", "the", "possibility", "that", "efficient", "suffix-based", "wildcard", "searches", "(Gusfield, 1997)", "may", "enable", "correct", "translation", "of", "non-contiguous", "phrases."], "cited_papers": [{"title": null, "year": "1997", "authors": ["D Gusfield"]}], "target_citation_location": 43, "citation_locations": [43], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "dff516a6-7520-496d-94f1-7e36f29ab7d1", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["MMB", "must", "be", "credited", "with", "helping", "to", "keep", "belief", "in", "MT", "alive", "during", "long", "years", "of", "public", "scepticism,", "and", "above", "all", "with", "the", "belief", "that", "MT", "was", "an", "intellectually", "challenging", "and", "interesting", "task", "(Masterman, 1957b (Masterman, , 1961)).", "I", "think", "that", "is", "now", "widely", "granted,", "although", "it", "was", "not", "conceded", "within", "artificial", "intelligence,", "for", "example,", "until", "relatively", "recently.", "There", "it", "was", "generally", "thought", "that,", "although", "language", "understanding", "in", "general", "required", "inference", "knowledge", "of", "the", "world", "and", "processing", "of", "almost", "arbitrary", "complexity,", "MT", "did", "not:", "it", "was", "a", "task", "that", "required", "only", "superficial", "processing", "of", "language.", "I", "think", "that", "now", "almost", "everyone", "concedes", "that", "that", "view", "is", "false."], "cited_papers": [{"title": "Agricola in curvo terram dimovit aratro. Cambridge Language Research Unit, Memorandum ML 84", "year": "1957", "authors": ["M Masterman"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 33, "citation_locations": [33], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "dffa2cdb-afa0-4f74-a43d-313fb82177be", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["Various", "studies", "attempted", "to", "generate", "multiple", "different", "definitions", "for", "polysemous", "words.", "Gadetsky et al. (2018)", "tackled", "this", "problem", "by", "computing", "the", "AdaGram", "vectors", "(Bartunov et al., 2016)", "of", "input", "words,", "which", "are", "capable", "of", "learning", "different", "representations", "at", "desired", "semantic", "resolutions.", "However,", "generating", "different", "definitions", "based", "on", "contexts,", "i.e.,", "example", "sentences,", "became", "the", "mainstream", "method", "(Chang et al., 2018, Reid et al., 2020, Li et al., 2020, Bevilacqua et al., 2020", ").", "Among", "them,", "some", "studies", "used", "pre-trained", "language", "models", "to", "obtain", "contextualized", "embeddings.", "Reid et al. (2020)", "initialized", "encoders", "with", "BERT", "(Devlin et al., 2019)", "and", "employed", "variational", "inference", "for", "estimation", "and", "leveraged", "contextualized", "word", "embeddings", "for", "improved", "performance.", "Bevilacqua et al. (2020)", "employed", "a", "novel", "spanbased", "encoding", "scheme", "to", "fine-tune", "a", "pre-trained", "English", "encoder-decoder", "system", "to", "generate", "definitions.", "Huang et al. (2021)", "leveraged", "the", "T5", "(Raffel et al., 2019)", "model", "for", "this", "task", "and", "introduced", "a", "re-ranking", "mechanism", "to", "model", "specificity", "in", "definitions."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 68, "citation_locations": [11, 20, 49, 63, 68, 83, 100, 104], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e00d6fbe-5de1-4217-9aba-4ea52a7705b0", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["In", "typical", "neural", "NLP", "systems,", "entities", "are", "embedded", "in", "the", "same", "space", "as", "other", "words", "either", "in", "context-independent", "(Mikolov et al., 2013, Pennington et al., 2014)", "or", "in", "context-dependent", "ways", "(Peters et al., 2018, Devlin et al., 2019).", "Such", "approaches", "are", "powerful:", "pre-trained", "language", "models", "implicitly", "learn", "factual", "knowledge", "about", "those", "entities", "(Petroni et al., 2019, Roberts et al., 2020, Jiang et al., 2020)", "and", "these", "representations", "can", "be", "grounded", "in", "structured", "and", "human-curated", "knowledge", "bases", "(Logan et al., 2019, Levine et al., 2019, Peters et al., 2019, Zhang et al., 2019, Poerner et al., 2019, Xiong et al., 2020, Wang et al., 2020).", "However,", "these", "embeddings", "do", "not", "explicitly", "maintain", "representations", "of", "this", "knowledge,", "and", "dense", "entity", "representations", "are", "not", "directly", "interpretable.", "Knowledge", "probing", "tasks", "can", "be", "used", "to", "measure", "LMs'", "factual", "knowledge", "(Petroni et al., 2019),", "but", "designing", "the", "right", "probing", "task", "is", "another", "hard", "problem", "(Chen et al., 2019, Poerner et al., 2019),", "particularly", "if", "the", "probes", "are", "parameter-rich", "(Hewitt and Manning, 2019)."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "BERT is Not a Knowledge Base (Yet): Factual Knowledge vs. Name-Based Reasoning in Unsupervised QA", "year": "2019", "authors": ["Nina Poerner", "Ulli Waltinger", "Hinrich Sch\u00fctze"]}], "target_citation_location": 93, "citation_locations": [18, 23, 38, 51, 82, 93, 100], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "e01792f6-ebd7-4bbc-b175-f490fac9aac8", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["We", "define", "text-level", "bias", "as", "the", "frequency", "of", "certain", "words", "which", "are", "recognised", "as", "favouring", "one", "gender", "over", "another.", "The", "problem", "is", "then", "in", "defining", "this", "list", "of", "words.", "To", "avoid", "overfitting", "to", "one", "axis", "of", "gender", "bias,", "we", "construct", "a", "composite", "score", "based", "on", "pre-existing", "lists", "which", "have", "in", "turn", "been", "defined", "through", "experiments", "and", "empirical", "assessments", "(Schmader et al., 2007, Gaucher et al., 2011, Sap et al., 2017, Stanczak and Augenstein, 2021).", "The", "presence", "of", "words", "which", "are", "more", "likely", "to", "be", "associated", "with", "one", "gender", "does", "not", "directly", "result", "in", "biased", "outcomes.", "Bias", "may", "be", "more", "accurately", "measured", "as", "the", "relative", "gender", "distribution", "of", "applicants", "who", "apply", "to", "a", "given", "ad.", "In", "this", "work,", "we", "focus", "on", "gendered", "word", "lists", "as", "one", "overt", "presentation", "of", "gender", "bias", "but", "encourage", "further", "research", "to", "empirically", "measure", "allocational", "harm,", "so", "long", "as", "any", "experiments", "consider", "the", "ethical", "issues", "of", "posting", "\"fake\"", "ads", "online."], "cited_papers": [{"title": "Evidence That Gendered Wording in Job Advertisements Exists and Sustains Gender Inequality", "year": "2011", "authors": ["Danielle Gaucher", "Justin Friesen", "Aaron Kay"]}, {"title": "Connotation frames of power and agency in modern films", "year": "2017", "authors": ["Maarten Sap", "Marcella Prasettio", "Ari Holtzman", "Hannah Rashkin", "Yejin Choi"]}, {"title": null, "year": "2021", "authors": ["Karolina Stanczak", "Isabelle Augenstein"]}, {"title": "A Linguistic Comparison of Letters of Recommendation for Male and Female Chemistry and Biochemistry Job Applicants", "year": "2007", "authors": ["Toni Schmader", "Jessica Whitehead", "Vicki Wysocki"]}], "target_citation_location": 58, "citation_locations": [58], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e0744dd2-c1b8-4560-ae83-e959a86a8837", "citing_paper": {"title": "USST's System for AutoSimTrans 2022", "year": 2022, "authors": ["Jiahui Zhu", "Jun Yu"]}, "text": ["During", "the", "fine-tuning", "phase,", "we", "first", "apply", "finetuning", "on", "a", "small", "spoken", "corpus.", "For", "better", "domain", "adaptation,", "we", "adopt", "mixed", "fine-tuning", "(Chu et al., 2017),", "which", "trains", "on", "a", "mixed", "dataset", "that", "includes", "a", "subsampled", "general", "corpus", "and", "an", "upsampled", "spoken", "corpus.", "Thirdly,", "we", "propose", "a", "method", "called", "\"in-domain", "mixed", "fine-tuning\",", "which", "further", "improve", "the", "BLEU", "score", "than", "mixed", "finetuning.", "Specifically,", "inspired", "by", "in-domain", "data", "filtering", "(Moore and Lewis, 2010, Ng et al., 2019),", "we", "mixed", "upsampled", "spoken", "data", "with", "selected", "in-domain", "data", "from", "general", "corpus", "rather", "than", "random", "subsampled."], "cited_papers": [{"title": "Intelligent selection of language model training data", "year": "2010", "authors": ["C Robert", "William Moore", "unk Lewis"]}, {"title": "Facebook fair's wmt19 news translation task submission", "year": "2019", "authors": ["Nathan Ng", "Kyra Yee", "Alexei Baevski", "Myle Ott", "Michael Auli", "Sergey Edunov"]}], "target_citation_location": 63, "citation_locations": [21, 63], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "e0804fb0-436f-4200-8f89-a88f21e17ee1", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["Electro-/Magnetoencephalography", "(EEG/MEG),", "which", "measures", "neural", "activity", "at", "millisecond", "resolution,", "is", "a", "key", "neuroscientific", "method", "to", "assess", "how", "neural", "representations", "unfold", "dynamically", "in", "language", "processing.", "Early", "event", "related", "potential", "(ERP)", "studies", "that", "rely", "on", "averaging", "EEG", "activity", "across", "multiple", "trials", "have", "shown", "that", "EEG", "signal", "magnitude", "and", "topography", "depend", "on", "word", "length,", "frequency", "and", "open", "vs.", "closed", "class.", "Word", "length", "effects", "arose", "in", "EEG", "at", "about", "150", "ms,", "frequency", "effects", "at", "200", "ms", "and", "word", "class", "effects", "from", "400-700", "ms", "(Osterhout et al., 1997, Brown et al., 1999, Neville et al., 1992, M\u00fcnte et al., 1998, Segalowitz and Lane, 2000, M\u00fcnte et al., 2001, Dufau et al., 2015).", "Recent", "studies", "were", "able", "to", "predict", "these", "and", "other", "(e.g.", "semantic)", "aspects", "based", "on", "single", "trial", "multi-channel", "EEG/MEG", "activity", "(Ling et al., 2019, Chan et al., 2011, King et al., 2020).", "Importantly,", "the", "aim", "of", "cognitive", "neuroscience", "studies", "is", "to", "dissociate", "when", "(i.e.", "latency)", "and", "where", "(i.e."], "cited_papers": [{"title": "Decoding word and category-specific spatiotemporal representations from meg and eeg", "year": "2011", "authors": ["Alexander Chan", "Eric Halgren", "Ksenija Marinkovic", "Sydney Cash"]}, {"title": "Back-to-back regression: Disentangling the influence of correlated factors from multivariate observations", "year": "2020", "authors": ["Jean-R\u00e9mi King", "Fran\u00e7ois Charton", "David Lopez-Paz", "Maxime Oquab"]}, {"title": "How are visual words represented? insights from eeg-based visual word decoding, feature derivation and image reconstruction", "year": "2019", "authors": ["Shouyu Ling", "Andy Lee", "Blair Armstrong", "Adrian Nestor"]}], "target_citation_location": 99, "citation_locations": [79, 99], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e0e0dc11-cdef-4a1a-a73a-44d732b50c53", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["Reddit.", "A", "further", "tuning", "dataset", "is", "derived", "from", "an", "existing", "Reddit", "dataset,", "pushshift.io", "(Baumgartner et al., 2020)", "as", "seen", "in", "Roller et al. (2020).", "This", "dataset", "has", "been", "used", "in", "several", "existing", "dialoguebased", "studies", "and", "has", "been", "shown", "to", "result", "in", "more", "natural", "conversations", "(Yang et al., 2018, Mazar\u00e9 et al., 2018)."], "cited_papers": [{"title": "The pushshift reddit dataset", "year": "2020", "authors": ["Jason Baumgartner", "Savvas Zannettou", "Brian Keegan", "Megan Squire", "Jeremy Blackburn"]}], "target_citation_location": 13, "citation_locations": [13, 17, 38], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]}
{"id": "e0e76457-0f51-49bb-a709-eb08fc6c3144", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["With", "the", "advent", "of", "social", "media,", "anti-social", "and", "abusive", "behavior", "has", "become", "a", "prominent", "occurrence", "online.", "Undesirable", "psychological", "effects", "of", "abuse", "on", "individuals", "make", "it", "an", "important", "societal", "problem", "of", "our", "time.", "Munro (2011)", "studied", "the", "ill-effects", "of", "online", "abuse", "on", "children,", "concluding", "that", "children", "may", "develop", "depression,", "anxiety,", "and", "other", "mental", "health", "problems", "as", "a", "result", "of", "their", "encounters", "online.", "Pew", "Research", "Center,", "in", "its", "latest", "report", "on", "online", "harassment", "(Duggan, 2017),", "revealed", "that", "40%", "of", "adults", "in", "the", "United", "States", "have", "experienced", "abusive", "behavior", "online,", "of", "which", "18%", "have", "faced", "severe", "forms", "of", "harassment,", "e.g.,", "that", "of", "sexual", "nature.", "These", "statistics", "stress", "the", "need", "for", "automated", "detection", "and", "moderation", "systems.", "Hence,", "in", "recent", "years,", "a", "new", "research", "effort", "on", "abusive", "language", "detection", "has", "sprung", "up", "in", "NLP."], "cited_papers": [{"title": "The protection of children online: a brief scoping review to identify vulnerable groups", "year": "2011", "authors": ["Emily Munro"]}], "target_citation_location": 32, "citation_locations": [32, 70], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e0fadaa6-9561-492a-83c6-0cba1610811b", "citing_paper": {"title": "DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*", "year": 1995, "authors": ["Ted Briscoe", "John Carroll"]}, "text": ["To", "our", "knowledge", "these", "are", "the", "first", "experiments", "which", "objectively", "demonstrate", "the", "utility", "of", "punctuation", "for", "resolving", "syntactic", "ambiguity", "and", "improving", "parser", "coverage.", "They", "extend", "work", "by", "Jones (1994)", "and", "Briscoe and Carroll (1994)", "by", "applying", "a", "wide-coverage", "text", "grammar", "to", "substantial", "quantities", "of", "naturally-punctuated", "text", "and", "by", "quantifying", "the", "contribution", "of", "punctuation", "to", "ambiguity", "resolution", "in", "a", "well-defined", "probabilistic", "parse", "selection", "model."], "cited_papers": [{"title": "Parsing {with) Punctuation. Rank Xerox Research Centre", "year": "1994", "authors": ["E Briscoe", "J Carroll"]}], "target_citation_location": 29, "citation_locations": [27, 29], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "e124351d-a18a-4952-9886-210bab3741ca", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["We", "approach", "this", "discussion", "from", "three", "different", "perspectives,", "that", "of", "the", "designers", "of", "the", "detection", "method,", "that", "of", "the", "user", "creating", "comments,", "and", "that", "of", "the", "larger", "communities.", "By", "breaking", "the", "discussion", "down", "in", "this", "manner,", "we", "explore", "the", "different", "choices", "that", "exist", "for", "operationalization", "and", "the", "purposes", "they", "can", "serve.", "Designers", "of", "the", "method.", "For", "the", "designers", "of", "the", "detection", "method,", "explainability", "can", "serve", "as", "a", "principled", "mechanism", "for", "understanding", "and", "reasoning", "about", "the", "behavior", "of", "their", "method,", "which", "is", "important", "for", "multiple", "reasons.", "Firstly,", "if", "the", "detection", "method", "exhibits", "all", "the", "four", "properties", "of", "explain-ability,", "then", "the", "designers", "can", "easily", "gain", "insights", "into", "the", "factors", "that", "contributed", "to", "the", "decision", "made", "by", "the", "method", "given", "a", "comment.", "This", "can", "allow", "the", "designers", "to", "recognize", "when", "the", "method", "may", "be", "overly", "relying", "on", "a", "specific", "factor,", "e.g.,", "the", "demographic", "traits.", "In", "the", "case", "of", "social", "feature", "engineering", "and", "user", "embeddings", "based", "methods,", "operationalization", "of", "explainability", "via", "feature", "attribution", "such", "as", "LIME", "(Ribeiro et al., 2016)", "and", "Integrated", "Gradients", "(Sundararajan et al., 2017)", "can", "be", "effective", "in", "offering", "such", "insights.", "For", "social", "graph", "based", "methods", "that", "employ", "graph", "neural", "networks,", "attribution", "techniques", "like", "GNNExplainer", "(Ying et al., 2019)", "can", "be", "used", "instead.", "The", "second", "reason", "why", "explainability", "is", "important", "for", "the", "designers", "is", "because", "it", "can", "allow", "them", "to", "optimize", "the", "method", "by", "removing", "inputs", "that", "do", "not", "contribute", "significantly.", "Here", "again,", "explainability", "via", "feature", "attribution", "can", "be", "effective.", "Lastly,", "explainability", "is", "also", "important", "for", "the", "designers", "to", "understand", "how", "their", "method", "would", "perform", "in", "cases", "where", "a", "user", "may", "try", "obfuscate", "abusive", "language", "(Nobata et al., 2016).", "Counterfactual", "explanations", "can", "constitute", "an", "effective", "operationalization", "for", "the", "designers", "to", "identify", "the", "parts", "of", "their", "method", "that", "are", "most", "vulnerable", "to", "obfuscations."], "cited_papers": [{"title": "Axiomatic attribution for deep networks", "year": "2017", "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"]}], "target_citation_location": 166, "citation_locations": [162, 166, 188, 255], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e17a0312-40fd-48ec-937b-8ba23793a50c", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["To", "apply", "RDS", "(Nguyen et al., 2020)", "for", "the", "data", "splitting", "process,", "it", "requires", "to", "have", "baseline", "learners", "to", "obtain", "rewards", "for", "the", "reinforced", "process.", "It", "is", "recommended", "to", "choose", "representative", "baseline", "learners,", "to", "let", "the", "reinforced", "learner", "better", "capture", "different", "learning", "behaviors.", "The", "use", "of", "these", "baseline", "learners", "is", "important", "since", "each", "learner", "will", "behave", "differently", "depending", "on", "the", "patterns", "contained", "in", "the", "target", "data.", "As", "a", "result,", "RDS", "helps", "to", "increase", "the", "diversity", "of", "the", "data", "samples", "in", "different", "sets.", "Here", "we", "employ", "three", "models", "to", "classify", "reliable", "news", "using", "textual", "features", "as", "follows:", "Bi-LSTM", "network", "is", "a", "standard", "baseline", "for", "most", "of", "text", "classification", "tasks."], "cited_papers": [{"title": null, "year": "2020", "authors": ["unk Nguyen Van Nha"]}], "target_citation_location": 3, "citation_locations": [3], "citation_type": "single", "annotations": [[2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e181c429-8548-4c8a-a85a-86f4e56dd798", "citing_paper": {"title": "Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes", "year": 2021, "authors": ["Yohan Jo", "Seojin Bang", "Chris Reed", "Eduard Hovy"]}, "text": ["For", "each", "pair", "of", "normative", "claim", "C", "and", "statement", "S,", "we", "annotate", "the", "following", "information:", "(1a)", "Whether", "C", "advocates", "for", "or", "opposes", "its", "norm", "target,", "and", "(1b)", "the", "norm", "target", "T", "(Figure", "1", "TASK", "1),", "(2a)", "Whether", "S", "uses", "a", "norm,", "consequence,", "or", "property", "for", "justification,", "and", "(2b)", "the", "justification", "J", "(Figure", "1", "TASK", "2),", "(3a)", "Whether", "J's", "focus", "is", "on", "advocating", "for", "T", "or", "opposing", "T,", "and", "(3b)", "whether", "J", "is", "positive", "or", "negative", "(Figure", "1", "TASK", "3).", "6", "Our", "annotation", "schema", "is", "richer", "than", "existing", "ones", "(Lawrence and Reed, 2016, Reisert et al., 2018).", "Due", "to", "the", "increased", "complexity,", "however,", "our", "annotation", "is", "split", "into", "three", "pipelined", "tasks.", "For", "this", "annotation,", "we", "randomly", "sampled", "1,000", "arguments", "from", "Kialo", "whose", "claims", "are", "normative", "(see", "\u00a76", "and", "Table", "4", "for", "details)."], "cited_papers": [{"title": "Feasible annotation scheme for capturing policy argument reasoning using argument templates", "year": "2018", "authors": ["Paul Reisert", "Naoya Inoue", "Tatsuki Kuribayashi", "Kentaro Inui"]}, {"title": "Argument mining using argumentation scheme structures", "year": "2016", "authors": ["John Lawrence", "Chris Reed"]}], "target_citation_location": 88, "citation_locations": [88], "citation_type": "group", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e1af8da9-6584-4609-80dd-39bae7b41c78", "citing_paper": {"title": "Associating semantic components with intersective Levin classes", "year": 1997, "authors": ["Hoa Dang", "Joseph Rosenzweig", "Martha Palmer"]}, "text": ["In", "addition", "to", "Levin", "classes", "like", "cut", "whose", "members", "have", "core", "senses", "that", "are", "closely", "and", "systematically", "related", "in", "the", "WordNet", "hierarchy,", "other", "Levin", "classes", "are", "composed", "of", "verbs", "that", "exhibit", "a", "wider", "range", "of", "possible", "semantic", "components.", "The", "split", "verbs", "(blow,", "break,", "cut,", "draw,", "hack,", "hew,", "kick,", "knock,", "pry,", "pull,", "push,", "rip,", "roll,", "saw,", "shove,", "slip,", "split,", "tear,", "tug,", "yank)", "do", "not", "obviously", "form", "a", "tight", "semantic", "class.", "Instead,", "in", "their", "use", "as", "split", "verbs,", "each", "verb", "manifests", "an", "extended", "sense", "that", "can", "be", "paraphrased", "as", "\"separate", "by", "V-ing,\"", "where", "\"V\"", "is", "the", "basic", "meaning", "of", "that", "verb", "[8].", "Many", "of", "the", "verbs", "(e.g.,", "draw,", "pull,", "push,", "shove,", "tug,", "yank)", "that", "do", "not", "have", "an", "inherent", "semantic", "component", "of", "\"separating\"", "belong", "to", "this", "class", "because", "of", "the", "component", "of", "force", "in", "their", "meaning.", "They", "are", "interpretable", "as", "verbs", "of", "splitting", "or", "separating", "only", "in", "particular", "syntactic", "frames.", "The", "adjunction", "of", "the", "apart", "adverb", "adds", "a", "change", "of", "state", "semantic", "component", "with", "respect", "to", "the", "object", "which", "is", "not", "present", "otherwise."], "cited_papers": [{"title": "English Verb Classes and Alternations", "year": "1993", "authors": ["B Levin"]}], "target_citation_location": 99, "citation_locations": [99], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e1f95ae4-099f-43ad-88ba-c90dd5a19005", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["Named", "Entity", "Recognition", "(NER)", "and", "Part-of-Speech", "(POS)", "tagging", "have", "traditionally", "been", "used", "as", "preprocessing", "steps", "in", "many", "Natural", "Language", "Processing", "(NLP)", "applications.", "For", "example,", "Yadav and Bethard (2018)", "discussed", "the", "use", "of", "NER", "across", "question", "answering,", "information", "retrieval,", "co-reference", "resolution,", "topic", "modeling,", "and", "machine", "translation.", "Similarly,", "POS", "tagging", "is", "often", "applied", "early", "in", "the", "NLP", "pipeline", "for", "many", "applications", "including", "information", "retrieval", "systems,", "syntax,", "and", "semantic", "analysis,", "speech", "recognition", "systems", "and", "machine", "translation", "(Abumalloh et al., 2016).", "In", "recent", "years,", "Arabic", "has", "been", "studied", "increasingly", "due", "to", "the", "explosion", "in", "the", "number", "of", "Arabic", "users", "on", "social", "media", "and", "the", "internet", "in", "general.", "Arabic", "is", "a", "morphologically", "rich", "language", "with", "complex", "grammatical", "structure", "(Shaalan et al., 2019).", "Arabic", "NLP", "researchers", "have", "used", "two", "types", "of", "approaches", "and", "sometimes", "a", "mixture", "of", "both", "to", "work", "with", "Arabic", "text.", "The", "first", "approach", "is", "the", "simplification", "approach", "where", "researchers", "tend", "to", "apply", "preprocessing", "(transformation)", "that", "simplify", "Arabic", "text", "such", "as", "letter", "normalization", "(Habash, 2010)", "and", "transliteration", "(Ameur et al., 2017).", "The", "second", "approach", "is", "the", "enrichment", "approach", "where", "researchers", "tend", "to", "apply", "minimum", "modification", "to", "the", "Arabic", "text", "and", "devise", "a", "way", "of", "incorporating", "the", "enriched", "features", "and", "potentially", "add", "more", "features", "to", "it."], "cited_papers": [{"title": "Character convolutions for arabic named entity recognition with long short-term memory networks", "year": "2019", "authors": ["Muhammad Khalifa", "Khaled Shaalan"]}], "target_citation_location": 107, "citation_locations": [24, 70, 107, 150, 153], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e20db031-7148-4536-9ca0-e772224ad4a5", "citing_paper": {"title": "Corpora and Machine Translation", "year": 1993, "authors": ["Yorick Wilks"]}, "text": ["\"It", "is", "well", "known", "that", "Western", "Languages", "are", "50%", "redundant.", "Experiment", "shows", "that", "if", "an", "average", "person", "guesses", "the", "successive", "words", "in", "a", "completely", "unknown", "sentence", "he", "has", "to", "be", "told", "only", "half", "of", "them.", "Experiment", "shows", "that", "this", "also", "applies", "to", "guessing", "the", "successive", "word-ideas", "in", "a", "foreign", "language.", "How", "can", "this", "fact", "be", "used", "in", "machine", "translation\"", "(King 1956", ")."], "cited_papers": [{"title": "Stochastic methods of mechanical translation", "year": "1956", "authors": ["G King"]}], "target_citation_location": 59, "citation_locations": [59], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1]]}
{"id": "e21a289d-865f-4e51-a00a-2c942a1384e4", "citing_paper": {"title": "A Language Invariant Neural Method for TimeML Event Detection", "year": 2019, "authors": ["Suhan Prabhu", "Pranav Goel", "Alok Debnath", "Manish Shrivastava"]}, "text": ["For", "Italian,", "we", "train", "and", "test", "solely", "on", "the", "Ita-TimeBank,", "whereas", "the", "current", "state", "of", "the", "art", "system", "trained", "on", "an", "augmented", "Ita-TimeBank", "(Caselli et al., 2011b),", "which", "was", "enriched", "with", "more", "labeled", "data.", "Similarly,", "in", "French,", "we", "use", "the", "established", "French", "TimeBank,", "while", "experiments", "in", "French", "so", "far", "have", "been", "on", "self-annotated", "(Arnulphy et al., 2015)", "or", "TimeML", "corpora", "(Bittar, 2009).", "Since", "these", "repositories", "of", "augmented", "data", "were", "not", "available", "to", "us", "at", "the", "time", "of", "writing", "this", "paper,", "the", "values", "reflect", "the", "same.", "However,", "it", "is", "to", "be", "noted", "that", "our", "system", "does", "provide", "an", "accuracy", "that", "is", "close", "to", "the", "currently", "reported", "stateof-the-art", "even", "in", "the", "absence", "of", "language", "specific", "features,", "explaining", "the", "fact", "that", "sub-word", "information", "is", "necessary", "for", "event", "detection", "in", "Italian", "and", "French", "as", "well."], "cited_papers": [{"title": "Data-driven approach using semantics for recognizing and classifying timeml events in italian", "year": "2011", "authors": ["Tommaso Caselli", "Hector Llorens", "Borja Navarro-Colorado", "Estela Saquete"]}], "target_citation_location": 23, "citation_locations": [23, 50, 54], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e23a8865-802a-405e-b4d1-1683f95e7f3b", "citing_paper": {"title": "Can Semantic Role Labeling Improve SMT?", "year": 2009, "authors": ["Dekai Wu", "Pascale Fung"]}, "text": ["We", "approach", "this", "promise", "with", "caution,", "however,", "given", "the", "painful", "lessons", "learned", "through", "the", "historical", "difficulty", "of", "making", "syntactic", "and", "semantic", "models", "contribute", "to", "improving", "SMT", "accuracy.", "The", "past", "decade", "has", "at", "last", "seen", "increasing", "amounts", "of", "evidence", "that", "SMT", "accuracy", "can", "indeed", "be", "improved", "via", "tree-structured", "and", "syntactic", "models", "(e.g.,", "Wu (1997),", "Chiang and Wu (2008),", "Wu and Chiang (2009))", "despite", "numerous", "disappoint-ing", "attempts", "Och et al. (2004).", "More", "recently,", "lexical", "semantics", "models", "for", "word", "sense", "disambiguation", "have", "also", "finally", "been", "successfully", "applied", "to", "increasing", "SMT", "accuracy", "(e.g.,", "Carpuat and Wu (2007), Chan et al. (2007),", "Gim\u00e9nez and M\u00e0rquez (2007a))", "again", "after", "surprising", "initial", "failures", "(e.g.,", "Carpuat and Wu (2005)", ").", "In", "both", "the", "syntactic", "and", "semantic", "cases,", "improving", "SMT", "accuracy", "ultimately", "required", "making", "major", "adaptations", "to", "the", "original", "linguistic", "models.", "We", "can", "reasonably", "expect", "it", "to", "be", "at", "least", "as", "difficult", "to", "successfully", "adapt", "the", "even", "more", "complex", "types", "of", "lexical", "semantics", "modeling", "from", "semantic", "parsing", "and", "role", "labeling."], "cited_papers": [{"title": "Word sense disambiguation vs. statistical machine translation", "year": "2005", "authors": ["Marine Carpuat", "Dekai Wu"]}], "target_citation_location": 87, "citation_locations": [51, 52, 53, 58, 79, 80, 87], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e2592514-c969-4d5f-882d-81554964e434", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["There", "is", "an", "ever", "increasing", "need", "for", "labeled", "datasets", "for", "machine", "learning.", "This", "is", "true", "for", "English", "as", "well", "as", "other,", "often", "under-resourced,", "languages.", "We", "provide", "a", "cross-lingual", "fine-grained", "sentence-level", "emotion", "and", "sentiment", "dataset.", "The", "dataset", "consists", "of", "parallel", "manually", "annotated", "data", "for", "English", "and", "Finnish,", "with", "additional", "parallel", "datasets", "of", "varying", "sizes", "for", "a", "total", "of", "32", "languages", "created", "by", "annotation", "projection.", "We", "use", "Plutchik's", "Wheel", "of", "Emotions", "(anger,", "anticipation,", "disgust,", "fear,", "joy,", "sadness,", "surprise,", "trust)", "(Plutchik, 1980)", "as", "our", "annotation", "scheme", "with", "the", "addition", "of", "neutral", "on", "movie", "subtitle", "data", "from", "OPUS", "(Lison and Tiedemann, 2016)."], "cited_papers": [{"title": "A general psychoevolutionary theory of emotion", "year": "1980", "authors": ["Robert Plutchik"]}], "target_citation_location": 77, "citation_locations": [77, 93], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "e28cbfe9-da2d-4603-8535-35f8ab60178c", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["Besides,", "we", "also", "conduct", "a", "manual", "evaluation", "on", "the", "Chinese", "test", "set,", "and", "the", "results", "are", "listed", "in", "Table", "5.", "From", "the", "averaged", "scores,", "we", "observe", "that", "SimpDefiner", "outperforms", "MASS", "by", "0.2", "in", "terms", "of", "accuracy", "(more", "accurate)", "and", "0.18", "in", "terms", "of", "simplicity", "(more", "straightforward).", "On", "the", "accuracy", "score,", "all", "three", "annotators", "agree", "that", "SimpDefiner", "has", "higher", "accuracy", "than", "MASS,", "which", "shows", "the", "superiority", "of", "our", "framework.", "As", "expected,", "the", "golden", "definitions", "have", "the", "highest", "accuracy", "in", "the", "table,", "far", "exceeding", "the", "definitions", "generated", "by", "the", "two", "models.", "We", "believe", "this", "is", "caused", "by", "insufficient", "knowledge", "in", "the", "model,", "and", "this", "can", "be", "solved", "by", "using", "larger", "pretrained", "models,", "such", "as", "BART", "(Lewis et al., 2019).", "On", "the", "simplicity", "score,", "three", "annotators", "agree", "that", "SimpDefiner", "generates", "simpler", "definitions", "than", "MASS,", "and", "two", "of", "three", "annotators", "think", "SimpDefiner", "generates", "simpler", "definitions", "than", "the", "golden", "ones."], "cited_papers": [{"title": "BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension", "year": "1910", "authors": ["Mike Lewis", "Yinhan Liu", "Naman Goyal", "Marjan Ghazvininejad", "Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer"]}], "target_citation_location": 113, "citation_locations": [113], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e2967de0-c95e-443c-b0e7-364773b98c30", "citing_paper": {"title": "Entity Attribute Relation Extraction with Attribute-Aware Embeddings", "year": 2020, "authors": ["Dan Iter", "Xiao Yu", "Fangtao Li"]}, "text": ["Sentences", "are", "represented", "with", "their", "shortest", "dependency", "path", "between", "two", "candidates,", "as", "proposed", "in", "(Fundel et al., 2006).", "The", "bottom", "of", "Figure", "1", "shows", "an", "example", "of", "the", "shortest", "path", "between", "an", "entity", "and", "attribute", "for", "one", "sentence.", "We", "converts", "each", "sentence", "from", "a", "string", "to", "a", "list", "of", "terms,", "where", "the", "first", "and", "last", "term", "is", "either", "the", "entity", "or", "the", "attribute.", "Each", "term", "in", "the", "dependency", "path", "is", "represented", "by", "the", "lemma", "of", "the", "term,", "the", "part-of-speech", "tag,", "the", "dependency", "label,", "the", "direction", "of", "the", "dependency", "path", "to", "the", "parent", "(left,", "right", "or", "root).", "Each", "of", "these", "features", "is", "embedded", "and", "concatenated", "to", "produce", "a", "sequence", "of", "vectors", "that", "represents", "the", "dependency", "path.", "The", "concatenation", "is", "the", "edge", "representation\u2212", "\u2192", "v", "edge", "=", "[\u2212", "\u2192", "v", "lemma,", "\u2212", "\u2192", "v", "pos,", "\u2212", "\u2192", "v", "dep,", "\u2212", "\u2192", "v", "dir", "]The", "sequence", "of", "terms", "in", "each", "path", "is", "input", "into", "an", "LSTM", "to", "produce", "a", "single", "vector", "representation", "for", "the", "sentence,", "\u2212", "\u2192", "v", "s.", "This", "is", "repeated", "for", "each", "sentence", "producing", "one", "vector", "per", "sentence.", "The", "sentences", "are", "aggregated", "with", "a", "weighted", "mean", "of", "the", "sentence", "representations", "to", "form", "a", "representation", "of", "the", "multiset", "of", "sentences,", "\u2212", "\u2192", "v", "sents(e,a)."], "cited_papers": [{"title": "Relex-relation extraction using dependency parse trees", "year": "2006", "authors": ["Katrin Fundel", "Robert K\u00fcffner", "Ralf Zimmer"]}], "target_citation_location": 14, "citation_locations": [14], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e2b6129c-c740-44fe-bc67-b1b39fcdadfc", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["Early", "studies", "of", "conditioned", "response", "generation", "focus", "on", "enriching", "the", "meaning", "representations", "in", "task-oriented", "dialogues,", "e.g.,", "utilizing", "graph", "structures", "and", "hierarchies", "among", "actions", "(Chen et al., 2019, Yang et al., 2020),", "decomposing", "into", "fine-grained", "actions", "(Shu et al., 2019),", "or", "encoding", "syntax", "attributes", "(Balakrishnan et al., 2019).", "Since", "these", "approaches", "often", "assume", "expensive", "action", "annotations,", "recent", "years", "have", "seen", "a", "growing", "interest", "in", "learning", "latent", "actions", "in", "an", "unsupervised", "way", "(Zhao et al., 2019, Huang et al., 2020a).", "These", "approaches", "build", "on", "either", "adversarial", "learning", "(Hu et al., 2017, Wang et al., 2018, Yang et al., 2018)", "or", "variational", "inference", "(Kingma", "and", "Welling,", "2014)", "and", "encode", "all", "system", "utterances", "via", "a", "self-reconstruction", "task", "or", "distant", "supervision", "(Yarats and Lewis, 2018).", "Due", "to", "their", "implicit", "nature,", "latent", "actions", "are", "difficult", "to", "generalize,", "and", "we", "aim", "to", "overcome", "this", "limitation", "by", "learning", "explicit", "action", "representations."], "cited_papers": [{"title": "Constrained decoding for neural NLG from compositional representations in task-oriented dialogue", "year": "2019", "authors": ["Anusha Balakrishnan", "Jinfeng Rao", "Kartikeya Upasani", "Michael White", "Rajen Subba"]}], "target_citation_location": 33, "citation_locations": [23, 28, 33, 57, 65, 85], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e2df4f1f-1c75-4b2f-9dc5-a22e1255bf6d", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["We", "consider", "z", "as", "a", "disentangled", "representation", "for", "x,", "if", "the", "changes", "in", "single", "latent", "dimensions", "of", "z", "are", "sensitive", "to", "changes", "in", "single", "generative", "factors", "of", "x", "while", "being", "relatively", "invariant", "to", "changes", "in", "other", "factors", "(Bengio et al., 2013).", "Several", "probabilistic", "models", "are", "designed", "to", "reveal", "this", "process,", "here", "we", "look", "at", "some", "of", "the", "most", "widely", "used", "ones."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 37, "citation_locations": [37], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e34aba93-b24f-468e-bcfd-a446d0dbc201", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["A", "related", "thrust", "of", "the", "literature", "has", "looked", "at", "understanding", "entities", "using", "interpretable", "embeddings", "based", "around", "feature", "norms", "(McRae et al., 2005),", "this", "has", "advantages", "for", "learning", "in", "few-shot", "setups", "(Wang et al., 2017).", "However,", "most", "of", "this", "past", "work", "has", "used", "embeddings", "that", "are", "much", "lowerdimensional", "than", "ours,", "and", "don't", "necessarily", "to", "scale", "to", "broad-domain", "text", "or", "all", "of", "Wikipedia."], "cited_papers": [{"title": "Semantic feature production norms for a large set of living and nonliving things", "year": "2005", "authors": ["Ken Mcrae", "George Cree", "Mark Seidenberg", "Chris Mcnorgan"]}], "target_citation_location": 18, "citation_locations": [18, 27], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e39f9948-f8df-442d-b919-6e9b478a8be3", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["To", "meet", "these", "constraints,", "compact", "models", "represent", "one", "of", "the", "most", "promising", "solutions.", "As", "far", "as", "we", "know,", "they", "have", "only", "been", "evaluated", "on", "the", "comprehension", "tasks", "covered", "by", "GLUE", "(Wang et al., 2018)", "and", "the", "question-answering", "task", "with", "the", "SQuAD", "corpus", "(Rajpurkar et al., 2016)", "with", "abundant", "data,", "in", "English.", "The", "improvements", "resulting", "from", "the", "algorithmic", "optimizations", "of", "the", "models,", "although", "significant,", "raise", "questions", "about", "their", "effectiveness", "on", "lower-scale", "learning", "problems", "on", "poorly", "endowed", "languages.", "The", "works", "of", "Zhang et al. (2021)", "and", "Mosbach et al. (2021)", "have", "furthermore", "shown", "degraded", "performance", "in", "these", "conditions.", "These", "two", "reflections", "are", "at", "the", "origin", "of", "a", "double", "question", "which", "our", "contribution", "attempts", "to", "answer.", "On", "the", "one", "hand,", "what", "is", "the", "behavior", "of", "a", "Transformer-based", "model", "in", "the", "context", "of", "a", "question-answering", "task", "in", "French,", "a", "task", "that", "is", "poorly", "endowed", "in", "this", "language?", "On", "the", "other", "hand,", "what", "are", "the", "impacts", "of", "algorithmic", "improvements", "of", "these", "same", "models", "in", "this", "context?"], "cited_papers": [{"title": "Revisiting fewsample {bert} fine-tuning", "year": "2021", "authors": ["Tianyi Zhang", "Felix Wu", "Arzoo Katiyar", "Q Kilian", "Yoav Weinberger", "unk Artzi"]}], "target_citation_location": 73, "citation_locations": [30, 39, 73, 75], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e3f10b78-eab8-4092-bd29-e8643542b8ca", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["Our", "approach", "to", "compression", "involves", "learning", "a", "sparse", "trainable", "mask", "that", "restricts", "the", "set", "of", "types", "considered.", "We", "parameterize", "the", "dot", "product", "6", "and", "cosine", "similarity", "7", "operations", "with", "a", "weight", "matrix", "W,", "a", "diagonal", "matrix", "diag(w", "1,", "w", "2,", "...,", "w", "|T", "|)", "whose", "components", "correspond", "to", "the", "entity", "types", "in", "T.", "The", "parameters", "W", "can", "be", "learned", "directly", "on", "downstream", "tasks", "(e.g.,", "CAP", "and", "NED).", "Note", "that", "in", "the", "cosine", "scoring", "function,", "we", "clip", "these", "parameter", "values", "to", "be", "between", "0", "and", "1.", "We", "train", "with", "the", "standard", "downstream", "task", "objective,", "but", "with", "an", "additional", "L", "1", "regularization", "term", "applied", "to", "W", "(Tibshirani, 1994)", "to", "encourage", "the", "W", "values", "to", "be", "sparse."], "cited_papers": [{"title": "Regression Shrinkage and Selection Via the Lasso", "year": "1994", "authors": ["Robert Tibshirani"]}], "target_citation_location": 104, "citation_locations": [104], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "e3fe6ca5-b0e6-4731-a9f5-cbce89bb2916", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["E", "q", "\u03c6", "(z|x)", "log", "p", "\u03b8", "(x|z)", "\u2212", "\u03b2", "|D", "KL", "(q", "\u03c6", "(z|x),", "p(z))", "\u2212", "C|where", "C", "is", "a", "positive", "real", "value", "which", "represents", "the", "target", "KL-divergence", "term", "value.", "This", "has", "an", "information-theoretic", "interpretation,", "where", "the", "placed", "constraint", "C", "on", "the", "KL", "term", "is", "seen", "as", "the", "amount", "of", "information", "transmitted", "from", "a", "sender", "(encoder)", "to", "a", "receiver", "(decoder)", "via", "the", "message", "(z)", "(Alemi et al., 2018),", "and", "impacts", "the", "sharpness", "of", "the", "posterior", "distribution", "(Prokhorov et al., 2019).", "This", "constraint", "allows", "the", "model", "to", "prioritize", "underlying", "factors", "of", "data", "according", "to", "the", "availability", "of", "channel", "capacity", "and", "their", "contributions", "to", "the", "reconstruction", "loss", "improvement.", "(Mathieu et al., 2019)", "introduces", "an", "additional", "term", "to", "\u03b2-VAE,", "D", "M", "M", "D", "(q", "\u03c6", "(z),", "p", "\u03b8", "(z)),"], "cited_papers": [{"title": "On the importance of the Kullback-Leibler divergence term in variational autoencoders for text generation", "year": "2019", "authors": ["Victor Prokhorov", "Ehsan Shareghi", "Yingzhen Li", "Mohammad Taher Pilehvar", "Nigel Collier"]}], "target_citation_location": 74, "citation_locations": [65, 74, 101], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e4e36957-290f-4e99-8375-2d4daa7046ab", "citing_paper": {"title": "A Fine-Grained Analysis of BERTScore", "year": 2021, "authors": ["Michael Hanna", "Ond\u0159ej Bojar"]}, "text": ["The", "original", "paper", "introducing", "BERTScore", "(Zhang et al., 2020)", "naturally", "compared", "BERTScore's", "correlations", "with", "human", "judgments", "to", "that", "of", "other", "metrics.", "However,", "various", "other", "surveys", "of", "MT", "metrics,", "as", "well", "as", "datasets", "and", "methodologies", "have", "been", "conducted,", "offering", "insights", "into", "how", "MT", "system", "and", "metric", "performance", "should", "be", "measured."], "cited_papers": [{"title": null, "year": "2020", "authors": ["Tianyi Zhang", "Varsha Kishore", "Felix Wu", "Kilian Weinberger", "Yoav Artzi"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e51b688a-af91-406d-a1c8-5e9059fb5224", "citing_paper": {"title": "Diverse dialogue generation with context dependent dynamic loss function", "year": 2020, "authors": ["Ayaka Ueyama", "Yoshinobu Kano"]}, "text": ["Both", "the", "encoder", "and", "decoder", "are", "six-layer", "Transformer", "(Vaswani et al., 2017),", "the", "number", "of", "heads", "of", "Multi-Head", "Attention", "is", "8,", "the", "token", "embedding", "dimension", "is", "512,", "and", "the", "ratio", "of", "Dropout", "is", "0.1.", "Adam", "(Kingma", "and", "Ba,", "2015)", "was", "used", "as", "the", "optimization", "method", "for", "parameters", "during", "training.", "The", "learning", "rate", "of", "Adam", "was", "set", "to", "0.001.", "Hyperparameters", "\u03bb,", "which", "adjust", "the", "frequency", "of", "ITF", "model", "and", "INF", "model,", "were", "set", "as", "0.2,", "0.4,", "0.6,", "or", "0.8.", "The", "INF", "model", "uses", "bi-gram", "as", "its", "n-gram", "function."], "cited_papers": [{"title": "Attention is all you need", "year": "2017", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e556a220-804d-46df-ba92-3381758995a1", "citing_paper": {"title": "A Semi-Supervised Approach to Detect Toxic Comments", "year": 2021, "authors": ["Ghivvago Saraiva", "Rafael Anchi\u00eata", "Francisco Neto", "Raimundo Moura"]}, "text": ["The", "strategy", "of", "weighting", "links", "between", "a", "token", "and", "a", "sentence", "node", "is", "straightforward.", "The", "weight", "is", "the", "average", "3", "of", "embedding", "vectors", "of", "the", "token", "node.", "To", "get", "embedding", "values", "for", "each", "token,", "we", "used", "100-dimensional", "GloVe", "embeddings", "4", "for", "the", "Portuguese", "language", "(Hartmann et al., 2017).", "Figure", "3", "shows", "the", "scheme", "of", "the", "network", "designed", "for", "this", "task.", "One", "can", "see", "that", "the", "edges", "are", "undirected", "and", "weighted,", "and", "a", "sentence", "node", "may", "share", "several", "token", "nodes", "whenever", "the", "token", "is", "in", "the", "sentence,", "i.e.,", "the", "edges", "between", "token", "nodes", "and", "sentence", "nodes", "are", "based", "on", "word", "occurrence", "in", "sentence."], "cited_papers": [{"title": "Portuguese word embeddings: Evaluating on word analogies and natural language tasks", "year": "2017", "authors": ["Nathan Hartmann", "Erick Fonseca", "Christopher Shulby", "Marcos Treviso", "J\u00e9ssica Silva", "Sandra Alu\u00edsio"]}], "target_citation_location": 44, "citation_locations": [44], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e5db6294-d9cf-49fc-ba85-e8e656814da3", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["Kinyarwanda", "[kin]", "data", "is", "used", "in", "our", "experiments", "as", "a", "language", "related", "to", "the", "target", "language", "(swh)", "with", "existing", "text", "and", "audio", "resources", "that,", "in", "some", "ways,", "surpasses", "those", "available", "in", "the", "target", "language.", "Thus,", "we", "pre-train", "some", "models", "on", "kin", "data", "while", "fine-tuning", "for", "the", "downstream", "NER", "task", "using", "swh", "data."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 1, "citation_locations": [1], "citation_type": "single", "annotations": [[1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "e62e758e-632e-43e5-ae61-3cb4e7fc26a1", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["Hierarchical", "Phrase-Based", "(HPB)", "SMT", "[3]", "is", "a", "tree-based", "model", "which", "extracts", "a", "synchronous", "Context-Free", "Grammar", "(CFG)", "automatically", "from", "the", "training", "corpus.", "HPB", "SMT", "is", "based", "on", "phrases", "extracted", "according", "to", "the", "PB", "model", "[2].", "Thus,", "HPB", "SMT", "tries", "to", "build", "upon", "the", "strengths", "of", "PB", "SMT", "and", "adds", "to", "it", "the", "ability", "to", "translate", "discontinuous", "phrases", "and", "learn", "phrase-reordering", "in", "hierarchical", "rules", "without", "a", "separate", "reordering", "model.", "HPB", "SMT", "uses", "hierarchical", "rules", "as", "a", "translation", "unit.", "These", "rules", "are", "rewrite", "rules", "with", "aligned", "pairs", "of", "right-hand", "sides,", "taking", "the", "following", "form:"], "cited_papers": [{"title": "Statistical phrasebased translation", "year": "2003", "authors": ["P Koehn", "F Och", "D Marcu"]}], "target_citation_location": 33, "citation_locations": [4, 33], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e66bd00f-1c74-4aad-8a4e-75f4fc1cf92b", "citing_paper": {"title": "Diverse dialogue generation with context dependent dynamic loss function", "year": 2020, "authors": ["Ayaka Ueyama", "Yoshinobu Kano"]}, "text": ["The", "diversity", "of", "neural", "dialogue", "generation", "has", "been", "studied", "actively.", "Li et al. (2016)", "first", "addressed", "this", "problem", "using", "Maximum", "Mutual", "Information", "(MMI)", "as", "the", "objective", "function", "of", "the", "neural", "model.", "Takayama and Arase (2019)", "used", "Positive", "Pointwise", "Mutual", "Information", "(PPMI)", "to", "identify", "keywords", "in", "the", "dialogue", "corpus", "that", "were", "likely", "to", "appear", "both", "in", "response", "utterances", "and", "their", "input", "utterances.", "Xing et al. (2017)", "proposed", "a", "model", "that", "uses", "topic", "words", "extracted", "from", "conversations", "to", "simulate", "human", "prior", "knowledge,", "generating", "informative", "and", "interesting", "responses.", "In", "addition,", "Variational", "Au-toEncoder", "(VAE)", "and", "Generative", "Adversarial", "Network", "(GAN),", "which", "were", "proposed", "originally", "for", "image", "generation,", "have", "also", "been", "applied", "to", "text", "and", "dialogue", "generation", "(Kingma and Welling, 2014, Bowman et al., 2016, Xu et al., 2018).", "Although", "GAN", "helps", "to", "reduce", "response", "text", "ambiguity,", "their", "primary", "purpose", "was", "not", "diversity.", "Zhang et al. (2018)", "proposed", "and", "demonstrated", "the", "effectiveness", "of", "Adversarial", "Information", "Maximization", "(AIM)", "as", "a", "new", "method", "for", "generating", "informative", "and", "diverse", "conversational", "responses.", "Their", "work", "also", "resolved", "instability", "that", "arose", "when", "training", "the", "GAN", "model."], "cited_papers": [{"title": "Diversity-Promoting GAN: A Cross-Entropy Based Generative Adversarial Network for Diversified Text Generation", "year": "2018", "authors": ["Jingjing Xu", "Xuancheng Ren", "Junyang Lin", "Xu Sun"]}, {"title": "Auto-encoding variational bayes", "year": "2014", "authors": ["P Diederik", "Max Kingma", "unk Welling"]}, {"title": "Generating sentences from a continuous space", "year": "2016", "authors": ["R Samuel", "Luke Bowman", "Oriol Vilnis", "Andrew Vinyals", "Rafal Dai", "Samy J\u00f3zefowicz", "unk Bengio"]}], "target_citation_location": 102, "citation_locations": [10, 28, 55, 102, 117], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e6c849ed-c8b8-4299-a8fb-a31abeb3de36", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["Earlier,", "it", "was", "stated", "that", "the", "design", "of", "the", "system", "was", "in", "response", "to", "perceived", "weaknesses", "in", "the", "classical", "approaches", "to", "MT.", "It", "should", "now", "be", "clear", "that", "the", "approach", "will", "avoid", "structurepreserving", "translation", "as", "a", "first", "choice,", "since", "the", "translation", "process", "involves", "no", "analysis", "of", "syntactic", "structure", "as", "such,", "the", "stratificational", "approach", "to", "linguistic", "description", "is", "likewise", "absent,", "and", "the", "predominantly", "bottom-up", "compositional", "theory-driven", "translation", "algorithm", "is", "replaced", "by", "a", "more", "global", "data-driven", "process,", "finally,", "the", "use", "of", "examples", "rather", "than", "rules", "and", "lexicons", "derived", "from", "linguists'", "introspection", "mean", "that", "the", "system", "will", "produce", "more", "natural", "output", "(especially", "where", "source", "and", "target", "are", "structurally", "dissimilar:", "so-called", "metaphors", "and", "idioms),", "will", "be", "more", "robust,", "easier", "to", "extend", "and", "to", "debug", "([37]", ")."], "cited_papers": [{"title": "Toward memory-based translation", "year": "1990", "authors": ["S Sato", "M Nagao"]}], "target_citation_location": 120, "citation_locations": [120], "citation_type": "single", "annotations": [[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "e7075c1b-2617-42fd-8f77-dc3386473bb4", "citing_paper": {"title": "Coreference Reasoning in Machine Reading Comprehension", "year": 2021, "authors": ["Mingzhu Wu", "Nafise Moosavi", "Dan Roth", "Iryna Gurevych"]}, "text": ["One", "of", "the", "known", "drawbacks", "of", "many", "NLP", "datasets", "is", "that", "they", "contain", "artifacts.", "2", "Models", "tend", "to", "ex-ploit", "these", "easy-to-learn", "patterns", "in", "the", "early", "stages", "of", "training", "(Arpit et al., 2017, Liu et al., 2020, Utama et al., 2020b),", "and", "therefore,", "they", "may", "not", "focus", "on", "learning", "harder", "patterns", "of", "the", "data", "that", "are", "useful", "for", "solving", "the", "underlying", "task.", "As", "a", "result,", "overfitting", "to", "dataset-specific", "artifacts", "limits", "the", "robustness", "and", "generalization", "of", "NLP", "models."], "cited_papers": [{"title": "Towards debiasing NLU models from unknown biases", "year": "2020", "authors": ["Nafise Sadat Prasetya Ajie Utama", "Iryna Moosavi", "unk Gurevych"]}, {"title": "A closer look at memorization in deep networks", "year": "2017", "authors": ["Devansh Arpit", "Stanis\u0142aw Jastrzundefinedbski", "Nicolas Ballas", "David Krueger", "Emmanuel Bengio", "Maxinder Kanwal", "Tegan Maharaj", "Asja Fischer", "Aaron Courville", "Yoshua Bengio", "Simon Lacoste-Julien"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 28, "citation_locations": [28], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "e735d5fc-2e9f-4bf8-87ac-8f3dfa200a0b", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["3.", "Simple", "errors", "in", "phone", "recognition:", "As", "noted", "in", "(Siminyu et al., 2021),", "even", "the", "best-trained", "Allosaurus", "models,", "fine-tuned", "on", "languagespecific", "data,", "have", "a", "non-trivial", "Phone", "Error", "Rate", "(PER)."], "cited_papers": [{"title": "Phoneme recognition through fine tuning of phonetic representations: a case study on luhya language varieties", "year": "2021", "authors": ["Kathleen Siminyu", "Xinjian Li", "Antonios Anastasopoulos", "David Mortensen", "Michael Marlo", "Graham Neubig"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "e743246e-7d87-4589-81bc-93cead60236b", "citing_paper": {"title": "Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model", "year": 2022, "authors": ["Richard Futrell"]}, "text": ["Implementation", "In", "all", "experiments", "reported", "below,", "stochastic", "gradient", "descent", "is", "performed", "using", "the", "Adam", "algorithm", "with", "default", "initial", "learning", "rate", "(Kingma and Ba, 2015).", "All", "experiments", "are", "implemented", "in", "PyTorch", "with", "use", "of", "opt_einsum", "to", "compute", "the", "partition", "function", "(Smith and Gray, 2018, Paszke et al., 2019)."], "cited_papers": [{"title": "Adam: A method for stochastic optimization", "year": "2015", "authors": ["P Diederik", "Jimmy Kingma", "unk Ba"]}], "target_citation_location": 20, "citation_locations": [20, 36], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e778e001-3a73-4842-8714-cb172cbc2710", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["The", "trend", "of", "recent", "years", "consists", "in", "training", "large", "pre-trained", "language", "models", "on", "ever", "larger", "corpora,", "with", "an", "ever-increasing", "amount", "of", "parameters,", "which", "requires", "considerable", "computational", "resources", "that", "only", "a", "few", "companies", "and", "institutions", "can", "afford.", "For", "example,", "the", "base", "model", "of", "BERT", "with", "110", "million", "parameters", "was", "pre-trained", "on", "16", "gigabytes", "(GB)", "of", "text,", "while", "the", "GPT-3", "model", "(Brown et al., 2020)", "was", "pre-trained", "on", "45", "terabytes", "(TB)", "of", "text", "and", "has", "175", "billion", "parameters."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 59, "citation_locations": [59], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "e790ae5f-dd67-4d90-b80f-1370c88cb0d7", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["UFET", "This", "ultra-fine", "entity", "typing", "dataset", "is", "created", "by", "Choi et al. (2018).", "This", "dataset", "consists", "of", "6k", "manually", "annotated", "examples.", "The", "entity", "mention", "spans", "could", "be", "named", "entities,", "nominal", "expressions,", "and", "pronouns", "while", "Wiki-based", "datasets", "mostly", "provide", "named", "entity", "mention", "spans.", "We", "use", "5.5k", "examples", "for", "training", "and", "500", "examples", "for", "validation.", "Note", "that", "because", "our", "goal", "in", "this", "work", "is", "downstream", "task", "performance,", "we", "deviate", "from", "the", "standard", "train/dev/test", "splits", "of", "2k/2k/2k", "in", "favor", "of", "higher", "performance."], "cited_papers": [{"title": "Ultra-Fine Entity Typing", "year": "2018", "authors": ["Eunsol Choi", "Omer Levy", "Yejin Choi", "Luke Zettlemoyer"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "e7b141d5-5a9d-4923-b4bc-cd6a4566cb10", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["We", "evaluate", "our", "embedding", "approach", "on", "benchmark", "tasks", "for", "entity", "representations.", "We", "use", "coreference", "arc", "prediction", "(CAP)", "and", "named", "entity", "disambiguation", "on", "CoNLL-YAGO,", "two", "tasks", "in", "the", "EntEval", "suite", "(Chen et al., 2019),", "as", "well", "as", "entity", "linking", "on", "WikilinksNED", "(Eshel et al., 2017),", "which", "covers", "broader", "entities", "and", "writing", "styles.", "We", "compare", "our", "approach", "against", "entity", "representations", "produced", "directly", "by", "pre-trained", "models."], "cited_papers": [{"title": "Named Entity Disambiguation for Noisy Text", "year": "2017", "authors": ["Yotam Eshel", "Noam Cohen", "Kira Radinsky", "Shaul Markovitch", "Ikuya Yamada", "Omer Levy"]}], "target_citation_location": 37, "citation_locations": [29, 37], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e8271a79-0893-4952-8e30-43e5a196bf29", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["Gridach", "(2016)", "proposed", "a", "character", "aware", "neural", "network", "model", "using", "a", "CRF", "on", "top", "of", "a", "Bi-LSTM.", "The", "aim", "of", "that", "model", "was", "to", "predict", "the", "NER", "tags", "by", "exploiting", "word", "and", "character", "embeddings.", "In", "our", "approach,", "we", "follow", "the", "same", "architecture.", "First,", "as", "shown", "in", "Figure", "(2)", "we", "use", "the", "character", "model", "directly", "to", "individually", "train", "character", "embeddings.", "The", "inputs", "to", "this", "model", "are", "word", "and", "character", "input", "layers", "as", "indicated", "by", "arrow", "(A).", "The", "word", "embedding", "layer", "takes", "as", "input", "pre-trained", "embedding", "matrix", "developed", "by", "Soliman et al. (2017),", "transforming", "the", "word", "input", "layer", "into", "word", "embeddings.", "The", "character", "embedding", "layer", "is", "randomly", "initialized", "and", "trained", "by", "the", "C-Bi-LSTM.", "The", "forward", "and", "the", "backward", "output", "from", "this", "C-Bi-LSTM", "is", "concatenated", "with", "the", "output", "from", "the", "word", "embedding", "layer", "and", "passed", "to", "the", "main", "Bi-LSTM.", "The", "output", "from", "this", "is", "passed", "to", "a", "Dense", "layer", "which", "maps", "the", "output", "of", "the", "main", "Bi-LSTM", "to", "the", "CRF", "layer,", "following", "Lample et al. (2016).", "After", "training", "the", "character", "model,", "we", "extract", "the", "forward", "and", "the", "backward", "output", "of", "the", "C-Bi-LSTM", "and", "use", "them", "to", "initialize", "the", "character", "embedding", "layer", "in", "the", "combination", "model."], "cited_papers": [{"title": "Aravec: A set of arabic word embedding models for use in arabic nlp", "year": "2017", "authors": ["Kareem Abu Bakr Soliman", "unk Eissa", "unk Samhaa R El-Beltagy"]}], "target_citation_location": 87, "citation_locations": [87, 156], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e8507ea4-8beb-4769-b354-1e20d6cf2be9", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["To", "this", "aim,", "we", "propose", "to", "use", "a", "memory", "component", "as", "the", "additional", "vocabulary.", "Note", "that", "the", "selection", "of", "words", "to", "build", "the", "vocabulary", "is", "task", "dependent,", "and", "we", "select", "the", "words", "appearing", "in", "state", "annotations", "and", "content", "words", "2", "extracted", "from", "task", "descriptions", "provided", "in", "the", "dataset", "(Budzianowski et al., 2018).", "This", "simple", "strategy", "is", "intuitive", "and", "turns", "out", "to", "be", "empirically", "competitive."], "cited_papers": [{"title": "Multiwoz -a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling", "year": "2018", "authors": ["Pawel Budzianowski", "Tsung-Hsien Wen", "Bo-Hsiang Tseng", "I\u00f1igo Casanueva", "Stefan Ultes", "Milica Osman Ramadan", "unk Gasic"]}], "target_citation_location": 48, "citation_locations": [48], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e91cbfb4-4cc0-40eb-b398-05e640b28da3", "citing_paper": {"title": "Effects of Word Alignment Visualization on Post-Editing Quality & Speed \u2020", "year": 2015, "authors": ["Lane Schwartz", "Isabel Lacruz", "Tatyana Bystrova"]}, "text": ["The", "Spanish", "language", "news", "articles", "used", "in", "this", "study", "lack", "corresponding", "reference", "translations.", "Thus,", "unlike", "the", "case", "of", "our", "Russian", "data,", "no", "matter", "how", "high", "the", "quality", "of", "machine", "translations,", "no", "Spanish-English", "machine", "translation", "segment", "could", "possibly", "receive", "a", "score", "of", "12.", "For", "Spanish-English,", "we", "therefore", "follow", "the", "10-point", "adequacy", "scale", "of", "Albrecht et al. (2009).", "This", "adequacy", "scale", "is", "shown", "in", "Table", "1b", "on", "page", "2,", "this", "scale", "is", "very", "similar", "to", "the", "former,", "but", "has", "a", "high", "of", "10", "(the", "meaning", "of", "the", "source", "sentence", "is", "fully", "conveyed", "in", "the", "English", "translation)", "instead", "of", "12."], "cited_papers": [{"title": "Correcting automatic translations through collaborations between MT and monolingual target-language users", "year": "2009", "authors": ["J Albrecht", "R Hwa", "G Marai"]}], "target_citation_location": 52, "citation_locations": [52], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e9677c2c-a5eb-4071-81b7-6ac4a71022bb", "citing_paper": {"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "year": 2022, "authors": ["Wenhao Yu", "Chenguang Zhu", "Lianhui Qin", "Zhihan Zhang", "Tong Zhao", "Meng Jiang"]}, "text": ["We", "evaluated", "the", "performance", "of", "different", "generation", "models", "from", "two", "aspects:", "quality", "(or", "say", "accuracy)", "and", "diversity.", "Quality", "tests", "the", "appropriateness", "of", "the", "generated", "response", "with", "respect", "to", "the", "context,", "and", "diversity", "tests", "the", "lexical", "and", "semantic", "diversity", "of", "the", "appropriate", "sequences", "generated", "by", "the", "model.", "These", "evaluation", "metrics", "have", "been", "widely", "used", "in", "existing", "work", "(Ott et al., 2018, Vijayakumar et al., 2018, Zhu et al., 2018, Cho et al., 2019, Yu et al., 2021)."], "cited_papers": [{"title": "Mixture content selection for diverse sequence generation", "year": "2019", "authors": ["Jaemin Cho", "Minjoon Seo", "Hannaneh Hajishirzi"]}, {"title": "Diverse beam search for improved description of complex scenes", "year": "2018", "authors": ["K Ashwin", "Michael Vijayakumar", "unk Cogswell", "R Ramprasaath", "Qing Selvaraju", "Stefan Sun", "David Lee", "Dhruv Crandall", "unk Batra"]}, {"title": "Analyzing uncertainty in neural machine translation", "year": "2018", "authors": ["Myle Ott", "Michael Auli", "David Grangier", "Marc'aurelio Ranzato"]}, {"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 56, "citation_locations": [56], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]]}
{"id": "e97663ba-0d76-402f-a077-468b09f8d775", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["We", "investigate", "this", "relation", "from", "the", "opposite", "direction", "by", "evaluating", "whether", "our", "model", "(BRIO-Mul),", "which", "is", "trained", "to", "have", "better", "sequencelevel", "performance,", "would", "also", "be", "more", "calibrated", "at", "the", "token-level", "compared", "with", "the", "baseline", "models", "that", "are", "trained", "using", "MLE", "and", "label", "smoothing.", "We", "follow", "previous", "work", "by", "using", "the", "Expected", "Calibration", "Error", "(Naeini et al., 2015)", "(ECE)", "as", "the", "evaluation", "metric", "of", "calibration:ECE", "=", "M", "m=1", "|B", "m", "|", "n", "|acc(B", "m)", "\u2212", "conf(B", "m", ")|", "(12)where", "the", "samples", "are", "grouped", "into", "M", "equal-width", "buckets", "by", "confidence", "(conf),", "B", "m", "denotes", "the", "m-th", "bucket,", "and", "n", "is", "the", "total", "number", "of", "samples.", "Following", "Wang et al. (2020),", "we", "evaluate", "model", "calibration", "on", "the", "system-generated", "summaries", "during", "inference", "and", "use", "the", "tercom", "toolkit", "11", "to", "assign", "labels", "(correct/incorrect)", "to", "the", "system-generated", "summaries", "based", "on", "the", "reference", "summaries."], "cited_papers": [{"title": "Obtaining well calibrated probabilities using bayesian binning", "year": "2015", "authors": ["Gregory Mahdi Pakdaman Naeini", "Milos Cooper", "unk Hauskrecht"]}], "target_citation_location": 53, "citation_locations": [53, 101], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "e9a3bd7b-c881-4432-8787-2dbb243f26f6", "citing_paper": {"title": "Amrita_CEN_NLP@SDP2021 Task A and B", "year": 2021, "authors": ["Isha Indhu", "Kavya Kumar", "Lakshaya Karthikeyan"]}, "text": ["In", "the", "evolution", "of", "the", "Information", "Age,", "where", "colossal", "amounts", "of", "research", "papers", "and", "scientific", "literature", "are", "now", "available,", "the", "need", "for", "a", "method", "which", "measures", "the", "scientific", "impact", "of", "a", "paper", "has", "become", "paramount.", "One", "such", "method", "is", "citation", "analysis.", "Citations", "are", "defined", "as", "a", "reference", "to", "the", "source", "of", "information", "used", "in", "one's", "research.", "The", "conventional", "approach", "to", "citation", "analysis", "involves", "utilising", "the", "frequency", "of", "citations", "Zhou et al. (2020)", "while", "treating", "all", "citations", "equally.", "This", "methodology", "provides", "a", "vague", "or", "even", "inaccurate", "overview", "of", "scientific", "development."], "cited_papers": [{"title": "Is self-citation biased? an investigation via the lens of citation polarity, density, and location", "year": "2020", "authors": ["Lina Zhou", "Uchechukwuka Amadi", "Dongsong Zhang"]}], "target_citation_location": 68, "citation_locations": [68], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "eaa0003b-2712-4cc8-bcc4-03088ed11239", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["These", "methods", "leverage", "the", "social", "relations", "(e.g.,", "friendship)", "that", "exist", "amongst", "users", "in", "a", "social", "network.", "Mishra et al. (2018a)", "constructed", "a", "social", "graph", "of", "all", "the", "users", "whose", "tweets", "are", "in", "the", "dataset", "of", "Waseem", "and", "Hovy", "(Waseem and Hovy, 2016).", "Nodes", "were", "the", "users", "and", "edges", "the", "follower-following", "relationship", "amongst", "them", "on", "Twitter.", "The", "researchers", "applied", "node2vec", "(Grover and Leskovec, 2016)", "to", "this", "graph", "to", "generate", "representations", "for", "users,", "i.e.,", "profiles,", "which", "capture", "information", "about", "their", "social", "connections.", "The", "addition", "of", "these", "profiles", "on", "top", "of", "linguistic", "representations", "of", "tweets", "yielded", "significant", "gains", "whereby", "the", "F", "1", "scores", "on", "the", "racism", "and", "sexism", "classes", "increased", "from", "72.28%", "and", "72.09%", "to", "75.09%", "and", "82.75%", "respectively.", "The", "gains", "were", "attributed", "to", "the", "fact", "that", "the", "profiles", "captured", "not", "only", "information", "about", "respective", "communities", "of", "users", "but", "also", "enabled", "modeling", "of", "the", "topical", "contexts", "amongst", "the", "connected", "users.", "Mishra et al. (2019)", "further", "expanded", "on", "this", "work", "by", "adding", "tweet", "nodes", "to", "the", "social", "graph", "of", "Mishra et al. (2018a)", "alongside", "user", "nodes.", "They", "connected", "every", "tweet", "node", "to", "the", "corresponding", "user", "who", "posted", "the", "tweet.", "They", "then", "used", "a", "graph", "convolutional", "network", "(Kipf and Welling, 2017)", "to", "create", "profiles", "of", "users", "that", "now", "captured", "their", "linguistic", "behavior", "too.", "When", "they", "used", "these", "profiles", "together", "with", "the", "linguistic", "representations", "of", "tweets,", "F", "1", "scores", "on", "the", "racism", "and", "sexism", "classes", "further", "improved", "to", "79.49%", "and", "84.44%", "respectively.", "Ribeiro et al. (2018)", "also", "applied", "graph", "neural", "networks,", "Graph-Sage", "(Hamilton et al., 2017),", "to", "their", "social", "graph", "of", "approximately", "100k", "Twitter", "users", "to", "generate", "profiles", "that", "they", "used", "to", "classify", "the", "users", "as", "hate-ful", "or", "normal.", "They", "noted", "that", "their", "social", "graph", "based", "method", "outperformed", "traditional", "gradientboosted", "decision", "tree", "classifiers", "by", "15", "F", "1", "points", "on", "the", "same", "task.", "Tredici", "et", "al.", "(2019)", "constructed", "a", "graph", "of", "users", "whose", "tweets", "are", "in", "the", "hate-speech", "dataset", "of", "Founta et al. (2018b).", "Nodes", "were", "uses", "and", "edges", "between", "them", "signified", "that", "one", "user", "retweeted", "the", "other.", "They", "used", "Graph", "Attention", "Networks", "(Veli\u010dkovi\u0107 et al., 2018)", "to", "generate", "representations", "of", "users", "from", "this", "graph,", "which", "when", "used", "alongside", "linguistic", "representations,", "provided", "a", "gain", "of", "5", "F", "1", "points.", "Cecillon", "et", "al.", "(2021)", "worked", "with", "a", "social", "graph", "of", "users", "from", "a", "French", "gaming", "website", "where", "weighted", "edges", "represented", "the", "intensity", "of", "communication", "between", "the", "users.", "Then", "for", "each", "comment", "to", "be", "classified,", "the", "researchers", "extracted", "the", "ego-graph", "of", "its", "author", "and", "created", "a", "feature", "vector", "for", "the", "comment", "from", "the", "ego-graph", "using", "node2vec", "along", "with", "measures", "like", "degree", "centrality.", "An", "SVM", "trained", "with", "these", "graph-based", "feature", "vectors", "reached", "89", "F", "1", "points", "as", "opposed", "to", "81", "F", "1", "points", "when", "trained", "with", "content", "features."], "cited_papers": [{"title": "Characterizing and detecting hateful users on twitter", "year": "2018", "authors": ["Manoel Ribeiro", "Pedro Calais", "Yuri Santos", "Virg\u00edlio Almeida", "Wagner Meira"]}], "target_citation_location": 218, "citation_locations": [16, 35, 53, 138, 153, 177, 218, 225, 289, 309], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "eadd5eef-badc-49f1-8b09-215e5b9eef83", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["Open-domain", "question", "answering", "(QA)", "aims", "to", "find", "the", "answers", "to", "natural", "language", "questions", "from", "a", "large", "collection", "of", "documents.", "Early", "QA", "systems", "(Brill et al., 2002, Dang et al., 2007, Ferrucci et al., 2010)", "constructed", "complicated", "pipelines", "consisting", "of", "multiple", "components,", "including", "question", "understanding,", "document", "retrieval,", "passage", "ranking", "and", "answer", "extraction.", "Recently,", "inspired", "by", "the", "advancements", "of", "machine", "reading", "comprehension", "(MRC),", "Chen et al. (2017)", "proposed", "a", "simplified", "two-stage", "approach,", "where", "a", "traditional", "IR", "*", "Corresponding", "authors."], "cited_papers": [{"title": "Reading wikipedia to answer opendomain questions", "year": "2017", "authors": ["Danqi Chen", "Adam Fisch", "Jason Weston", "Antoine Bordes"]}], "target_citation_location": 50, "citation_locations": [22, 50], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "eb7dba90-186b-44d4-a7fe-ab5cc7e27fff", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["Bridging", "vs.", "TNE", "Bridging", "has", "been", "extensively", "studied", "in", "the", "past", "decades,", "as", "we", "discuss", "in", "\u00a710.", "Here,", "we", "explore", "how", "many", "of", "the", "relations", "we", "collected", "correspond", "to", "the", "definition", "of", "bridging.", "We", "use", "the", "same", "three", "documents", "from", "the", "analysis", "described", "above,", "and", "follow", "the", "annotation", "scheme", "from", "ISNotes1.0", "(Markert et al., 2012)", "16", "to", "annotate", "them", "for", "bridging.", "We", "found", "that", "15", "out", "of", "the", "590", "links", "(2.5%)", "in", "these", "documents", "are", "bridging", "links", "(i.e.,", "meet", "the", "criteria", "for", "bridging", "defined", "in", "ISNotes).", "These", "three", "documents", "contain", "104", "NPs,", "that", "is,", "the", "ratio", "of", "bridging", "links", "per", "NP", "is", "0.14.", "While", "the", "ratio", "is", "small,", "it", "is", "larger", "than", "the", "ratio", "in", "ISNotes,", "which", "contains", "663", "bridging", "links", "out", "of", "11K", "annotated", "NPs", "(Hou et al., 2013b),", "that", "is,", "0.06", "bridging", "links", "per", "NP."], "cited_papers": [{"title": "Global inference for bridging anaphora resolution", "year": "2013", "authors": ["Yufang Hou", "Katja Markert", "Michael Strube"]}], "target_citation_location": 123, "citation_locations": [51, 123], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "ebf371c7-124b-4743-8aa8-c2e75dac012d", "citing_paper": {"title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "year": 2020, "authors": ["Emily \u00d6hman", "Marc P\u00e0mies", "Kaisla Kajava", "J\u00f6rg Tiedemann"]}, "text": ["The", "final", "dataset", "contained", "17,520", "unique", "emotion-annotated", "subtitles", "as", "shown", "in", "table", "3.", "In", "addition", "there", "are", "some", "6.5k", "subtitles", "annotated", "as", "neutral.", "The", "label", "distribution", "can", "be", "seen", "in", "table", "3", "The", "emotion", "labels", "are", "surprisingly", "balanced", "with", "the", "exception", "of", "anger", "and", "anticipation,", "which", "are", "more", "common", "than", "the", "other", "labels.", "In", "comparison", "with", "one", "of", "the", "most", "well-known", "emotion", "datasets", "using", "the", "same", "annotation", "scheme,", "the", "NRC", "emotion", "lexicon", "(EmoLex)", "(Mohammad and Turney, 2013),", "the", "distribution", "differs", "somewhat.", "Although", "anger", "is", "a", "large", "category", "in", "both", "datasets,", "fear", "is", "average", "in", "our", "dataset,", "but", "the", "largest", "category", "in", "EmoLex.", "It", "is", "hard", "to", "speculate", "why", "this", "is,", "but", "one", "possible", "reason", "is", "the", "different", "source", "data."], "cited_papers": [{"title": "Crowdsourcing a word-emotion association lexicon", "year": "2013", "authors": ["M Saif", "Peter Mohammad", "unk Turney"]}], "target_citation_location": 73, "citation_locations": [73], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "ec4fcdb8-a454-4760-a5d2-23cc233d8269", "citing_paper": {"title": "Comparison of post-editing productivity between professional translators and lay users", "year": 2014, "authors": ["Nora Aranberri", "Gorka Labaka"]}, "text": ["Post-editing", "research", "has", "so", "far", "focused", "on", "mainstream", "languages.", "An", "added", "challenge", "of", "this", "work", "is", "the", "use", "of", "an", "English", "to", "Basque", "MT", "system", "for", "post-editing.", "Research", "on", "Basque", "MT", "has", "been", "ongoing", "for", "a", "few", "years", "now", "(Diaz", "de", "Ilarraza et al, 2000a, 2000b, Labaka et al., 2007, Espa\u00f1a-Bonet et al., 2011, Mayor et al., 2011).", "However,", "Basque", "being", "a", "lowresourced", "language,", "researchers", "and", "developers", "have", "found", "themselves", "with", "limited", "resources", "to", "build", "competitive", "MT", "systems", "and", "automated", "translation", "has", "not", "been", "included", "within", "the", "translation", "processes", "of", "local", "LSPs", "yet.", "To", "our", "knowledge,", "this", "is", "the", "first", "(open)", "productivity", "experiment", "done", "for", "the", "English", "to", "Basque", "translation", "direction.", "Laurenzi et al. (2013)", "pointed", "out", "the", "existence", "of", "many", "communities", "that", "could", "benefit", "greatly", "from", "machine", "translation", "but,", "as", "in", "the", "case", "presented", "in", "this", "work,", "have", "not", "yet", "started", "to", "use", "it,", "as", "authors", "suggest,", "either", "due", "to", "lack", "of", "awareness", "or", "barriers", "to", "adoption.", "The", "work", "in", "Laurenzi et al. (2013)", "presents", "a", "feasibility", "study", "to", "introduce", "MT", "coupled", "with", "post-editing", "in", "local", "and", "regional", "health", "departments", "in", "the", "United", "States.", "It", "highlights", "a", "number", "of", "requirements", "the", "translation", "platform", "should", "address,", "such", "as", "being", "intuitive", "and", "easy", "to", "install,", "allowing", "users", "to", "share", "ongoing", "and", "completed", "jobs.", "Our", "work", "builds", "on", "this", "first", "feasibility", "study", "and", "goes", "a", "step", "forward", "by", "assessing", "the", "actual", "translation", "performance.", "We", "identify", "a", "suitable", "tool", "for", "our", "users", "that", "is", "intuitive,", "easy", "to", "access", "and", "allows", "sharing", "translation", "resources", "such", "as", "translation", "memories", "(TM)", "or", "specialized", "MT", "engines", "and", "measure", "productivity", "gain,", "while", "comparing", "it", "with", "the", "performance", "of", "professional", "translators."], "cited_papers": [{"title": "Building a Lexicon for an English-Basque Machine translation System from Heteogeneous Wide-Coverage dictionaries", "year": "2000", "authors": ["A Diaz De Ilarraza", "A Mayor", "K Sarasola"]}, {"title": "Reusability of Wide-Coverage Linguistic Resources in the Construction of a Multilingual Machine Translation System", "year": "2000", "authors": ["A Diaz De Ilarraza", "A Mayor", "K Sarasola"]}, {"title": "Matxin, an open-source rule-based machine translation system for Basque", "year": "2011", "authors": ["A Mayor", "I Alegria", "A Diaz De Ilarraza", "G Labaka", "M Lersundi", "K Sarasola"]}, {"title": "Hybrid Machine Translation Guided by a Rule-Based System", "year": "2011", "authors": ["C Espa\u00f1a-Bonet", "G Labaka", "A Diaz De Ilarraza", "L M\u00e0rquez", "K Sarasola"]}, {"title": "Comparing Rule-Based and Data-Driven Approaches to Spanish-to-Basque Machine Translation", "year": "2007", "authors": ["G Labaka", "N Stroppa", "A Way", "K Sarasola"]}], "target_citation_location": 41, "citation_locations": [41, 95, 142], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ec7ccbf9-e7ec-46dc-9dc5-c30dd0a94ea8", "citing_paper": {"title": "Word Formation in Computational Linguistics", "year": 2002, "authors": ["Pius Ten Hacken"]}, "text": ["In", "an", "Item", "and", "Process", "approach", "stem", "changes", "are", "dealt", "with", "via", "rules.", "Since", "stem", "changes", "in", "German", "are", "not", "regular", "or", "predictable", "we", "follow", "Fuhrhop (1998)", "and", "Eisenberg (1998)", "on", "listing", "the", "forms", "that", "an", "element", "may", "take.", "These", "forms", "are", "called", "word", "formation", "stem", "forms.", "Free", "and", "bound", "morphological", "elements", "have", "one", "or", "more", "derivation", "stem", "form(s)", "and", "one", "or", "more", "compounding", "stem", "form(s).", "Very", "often", "these", "stem", "forms", "look", "just", "like", "the", "regular", "stem.", "Consider", "the", "examples", "in", "Table", "4", "Here", "you", "can", "see", "that", "the", "suffix", "-keit", "has", "no", "derivation", "stem", "form.", "That", "means", "that", "it", "cannot", "be", "used", "in", "further", "derivation", "(it", "is", "a", "so-called", "closing", "suffix,", "see", "Aronoff &amp, Fuhrhop 2001", ").", "It", "has", "a", "compounding", "stem", "form,", "however.", "The", "word", "formation", "stem", "forms", "are", "propagated", "in", "complex", "words", "using", "these", "elements:", "each", "complex", "word", "ending", "in", "-keit,", "for", "example,", "will", "automatically", "have", "a", "compounding", "stem", "form", "ending", "in", "-keits.", "17", "Such", "an", "approach", "minimized", "the", "ambiguities", "that", "stem", "changes", "can", "cause.", "However,", "one", "has", "to", "acquire", "all", "the", "word", "formation", "stem", "forms.", "For", "our", "lexicon", "this", "is", "done", "semi-automatically", "as", "described", "in", "Heid, S\u00e4uberlich &amp, Fitschen (2002)."], "cited_papers": [{"title": "Grundriss der deutschen Grammatik", "year": "1998", "authors": ["Peter Eisenberg"]}], "target_citation_location": 27, "citation_locations": [25, 27, 111, 184], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "eca92735-123a-498e-8eeb-2a0e95161ac0", "citing_paper": {"title": "NEW TABULAR ALGORITHMS FOR LIG PARSING", "year": 2000, "authors": ["Mi G Uel Alonso Jor G E Grana", "Manuel Vilares"]}, "text": ["Thee", "Adjoining", "Grammars", "(TAG)", "[8]", "and", "Linear", "Indexed", "Grammars", "(LIG)", "[7 ]", "are", "extensions", "of", "Con", "text", "Free", "Grammars", "(CFG).", "Thee", "adjoining", "grammars", "use", "trees", "instead", "of", "productions", "as", "primary", "representing", "structure", "and", "seems", "to", "be", "adequate", "to", "describe", "syntactic", "phenomena", "occurring", "in", "nat", "ural", "language,", "due", "to", "their", "extended", "domain", "of", "locality", "and", "to", "their", "ability", "for", "factoring", "recursion", "from", "the", "domain", "of", "dependencies.", "Linear", "indexed", "grammars", "associate", "a", "stack", "of", "indices", "with", "each", "non-terminal", "symbol,", "with", "the", "restriction", "that", "the", "indices", "stack", "of", "the", "head", "non-terminal", "of", "each", "pro", "duction", "(the", "fa", "ther)", "can", "be", "inherited", "by", "at", "most", "one", "body", "non-terminal", "(the", "dependent", "child)", "while", "the", "other", "stacks", "must", "have", "a", "bounded", "stack", "size."], "cited_papers": [{"title": "Tree-adjoining grammars", "year": "1997", "authors": ["A Joshi", "Y Schabes"]}], "target_citation_location": 4, "citation_locations": [4, 10], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ecd9b935-3ee4-46e1-8a03-9d48ff7e372d", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["To", "investigate", "the", "relationship", "of", "the", "above", "defined", "relatedness", "measures,", "we", "compute", "correlations", "between", "the", "score", "they", "assign", "to", "100.000", "random", "word", "pairs.", "As", "Table", "1", "shows,", "none", "of", "the", "measures", "are", "near", "equivalent,", "but", "they", "have", "nonzero", "correlations.", "They", "also", "show", "high", "positive", "correlations", "with", "MEN", "(Bruni et al., 2012)", "and", "WS-353", "relatedness", "(Agirre et al., 2009),", "as", "can", "be", "seen", "in", "Table", "2,", "which", "is", "hopeful", "for", "their", "usability", "as", "relatedness", "in", "Codenames", "agents."], "cited_papers": [{"title": "Distributional semantics in technicolor", "year": "2012", "authors": ["Elia Bruni", "Gemma Boleda", "Marco Baroni", "Nam-Khanh Tran"]}], "target_citation_location": 47, "citation_locations": [47, 51], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "ed0c6f7f-6df2-4a97-84ab-48e31f8c1b38", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["Figure", "1:", "Pipeline", "of", "NMT", "system", "with", "Factored", "output", "Multiple", "output", "neural", "networks", "were", "previously", "pro-posed", "[16]", "using", "scheduled", "decoders", "with", "multiple", "source", "and", "target", "languages.", "In", "contrast", "to", "this,", "the", "FNMT", "system", "simultaneously", "produces", "several", "outputs.", "Given", "both", "outputs", "(lemma", "and", "factors)", "and", "linguistic", "resources,", "the", "final", "surface", "form", "is", "easily", "generated."], "cited_papers": [{"title": "Multi-way, multilingual neural machine translation with a shared attention mechanism", "year": "2016", "authors": ["O Firat", "K Cho", "Y Bengio"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ed38a348-392a-4574-b1ee-6122ed6afc7e", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["A", "three-fold", "analysis", "of", "the", "selected", "keywords", "was", "done.", "The", "semantics", "of", "the", "words", "was", "studied", "by", "using", "WordNet.", "In", "dialogue", "acts", "such", "as", "apologizing,", "thanking,", "or", "expressing", "sympathy,", "affective", "language", "is", "often", "employed", "to", "represent", "and", "convey", "psychological", "attitudes", "(Novielli et al, 2013).", "Also,", "there", "is", "what", "is", "called", "a", "'heartfelt", "apology'", "as", "against", "'routine", "apology", "(Owen, 1983", ").", "Hence,", "it", "was", "decided", "to", "further", "explore", "the", "sentiments", "and", "emotions", "associated", "with", "the", "keywords.", "The", "sentiments", "were", "studied", "using", "SentiWordNet", "and", "the", "emotion", "labels", "were", "determined", "through", "WordNet-Affect.", "The", "analysis", "and", "conclusions", "thus", "drawn", "are", "presented", "below."], "cited_papers": [{"title": "Apologies and remedial exchanges. The Hague. Mouton", "year": "1983", "authors": ["Marion Owen"]}], "target_citation_location": 54, "citation_locations": [40, 54], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ee0ec525-b395-41ce-9057-8fa92bdcd10d", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Communities.", "There", "can", "be", "scenarios", "where", "whole", "communities", "of", "users", "on", "a", "platform", "may", "be", "indulging", "in", "abusive", "behavior,", "e.g.,", "by", "widely", "circulating", "an", "abusive", "view", "against", "a", "demographic", "group", "based", "on", "shared", "beliefs,", "common", "stereotypes", "or", "other", "homophilic", "ties.", "In", "such", "cases,", "just", "taking", "down", "specific", "instances", "of", "abusive", "language", "and", "providing", "justifications", "individually", "to", "the", "respective", "users", "may", "not", "prove", "effective.", "Users", "may", "continue", "to", "promote", "the", "abusive", "view,", "defying", "the", "norms", "of", "the", "platform", "in", "the", "process", "and", "ignoring", "the", "justifications", "given", "to", "them.", "The", "reason", "for", "this", "comes", "from", "social", "influence", "theory", "which", "says", "that", "a", "user's", "behavior", "is", "affected", "by", "three", "broad", "varieties", "of", "social", "influence", "(Kelman, 1958),", "i.e.,", "compliance,", "identification,", "and", "internalization.", "Compliance", "occurs", "when", "the", "user", "behaves", "a", "certain", "way", "so", "as", "to", "appear", "in", "congruence", "with", "opinions", "of", "others", "who", "matter", "to", "them,", "identification", "occurs", "when", "the", "user", "adopts", "behaviors", "in", "order", "to", "associate", "with", "others", "they", "admire,", "and", "internalization", "is", "when", "the", "user", "adopts", "the", "values", "and", "beliefs", "of", "others.", "The", "influences", "occur", "because", "of", "two", "needs", "of", "the", "user,", "the", "need", "to", "be", "liked", "(normative)", "and", "the", "need", "to", "be", "right", "(informational).", "In", "order", "to", "fulfill", "the", "latter,", "people", "may", "accept", "the", "three", "varieties", "of", "influence", "when", "there", "is", "lack", "of", "information,", "a", "concept", "known", "as", "social", "proof", "(Cialdini, 2007)."], "cited_papers": [{"title": "Influence: The psychology of persuasion", "year": "2007", "authors": ["B Robert", "unk Cialdini"]}], "target_citation_location": 217, "citation_locations": [111, 217], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "ee872191-3ed6-47f9-b616-f1f304b01bf3", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["One", "of", "the", "most", "exciting", "outcomes", "is", "the", "deteriorated", "performance", "of", "the", "multilingual", "models", "using", "BT", "data,", "as", "we", "usually", "expect", "that", "added", "backtranslated", "texts", "would", "benefit", "performance.", "Using", "tags", "(BT[t])", "to", "differentiate", "which", "data", "is", "synthetic", "or", "not", "is", "only", "a", "simple", "step", "to", "address", "this", "issue,", "however,", "there", "could", "be", "evaluated", "more", "informed", "strategies", "for", "denoising", "or", "performing", "online", "data", "selection", "(Wang et al., 2018)."], "cited_papers": [{"title": "Denoising neural machine translation training with trusted data and online data selection", "year": "2018", "authors": ["Wei Wang", "Taro Watanabe", "Macduff Hughes", "Tetsuji Nakagawa", "Ciprian Chelba"]}], "target_citation_location": 63, "citation_locations": [30, 63], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "eea1a9c4-6cbe-4ddd-98a2-681ad43b6985", "citing_paper": {"title": "Interactive multilingual text generation for a monolingual user", "year": 1992, "authors": ["Harold Somers"]}, "text": ["EBMT", "proceeds", "by", "finding", "suitable", "examples", "in", "the", "database", "and", "then", "'recombining'", "them", "appropriately.", "Key", "factors", "are", "therefore", "the", "efficient", "retrieval", "of", "texts", "from", "the", "database", "which", "are", "sufficiently", "similar", "to", "the", "given", "text", "([8, 22, 40]", "),", "and", "the", "alignment", "of", "translation", "pairs,", "given", "a", "bilingual", "corpus", "([6,9,10,12,23]", ")."], "cited_papers": [{"title": "Repetitions processing using a metric space and the angle of similarity", "year": "1990", "authors": ["J Carroll"]}, {"title": "Text-translation alignment", "year": "1988", "authors": ["M Kay", "M R\u00f6scheisen"]}, {"title": "Analogical Modeling of Language", "year": "1989", "authors": ["R Skousen"]}], "target_citation_location": 34, "citation_locations": [34, 46], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3]]}
{"id": "eedb26e0-ee97-4f69-9b19-97fcea3f5db6", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["Outside", "of", "speech", "recognition", "focused", "work,", "Shen et al. (2020)", "(and", "other", "researchers", "cited", "therein)", "attempt", "to", "\"fuse\"", "audio", "and", "text", "at", "the", "word", "level", "for", "emotion", "recognition.", "They", "introduce", "another", "architecture", "that", "internally", "represents", "both", "audio", "and", "text.", "However,", "the", "so-called", "WISE", "framework", "relies", "on", "speech", "recognition", "to", "generate", "the", "text", "corresponding", "to", "audio", "frames", "in", "real-time.", "The", "current", "work", "explicitly", "avoids", "reliance", "on", "speech", "recognition.", "The", "2021", "Multimodal", "Sentiment", "Analysis", "(MuSe)", "challenge", "continues", "this", "vein", "of", "research", "integrating", "audio,", "video,", "text,", "and", "physiology", "data", "in", "an", "emotion", "recognition", "task", "(Stappen et al., 2021).", "Contributions", "to", "this", "challenge,", "such", "as", "Vlasenko et al. (2021),", "introduce", "a", "variety", "of", "ways", "to", "\"fuse\"", "audio", "and", "text", "inputs.", "However,", "these", "contributions", "are", "squarely", "focused", "on", "emotion/sentiment", "analysis", "and", "do", "not", "propose", "methods", "for", "flexible,", "phonetic", "language", "models.", "Lakhotia et al. (2021)", "introduced", "functionality", "for", "\"textless\"", "NLP.", "They", "explored", "the", "possibility", "of", "creating", "a", "dialogue", "system", "from", "only", "audio", "inputs", "(i.e.,", "without", "text).", "As", "part", "of", "this", "system,", "language", "models", "are", "directly", "trained", "on", "audio", "units", "without", "any", "text.", "This", "advances", "the", "state-of-the-art", "with", "regard", "to", "self-supervised", "speech", "methods,", "but", "it", "does", "not", "provide", "the", "flexibility", "in", "audio", "and/or", "text", "language", "modeling", "introduced", "here."], "cited_papers": [{"title": "Fusion of acoustic and linguistic information using supervised autoencoder for improved emotion recognition", "year": "2021", "authors": ["Bogdan Vlasenko", "Ravishankar Prasad", "Mathew Magimai.-Doss unk"]}], "target_citation_location": 95, "citation_locations": [6, 88, 95, 126], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "eedc2ab3-7226-4adb-846d-56c74047e42b", "citing_paper": {"title": "Decoding Part-of-Speech from Human EEG Signals", "year": 2022, "authors": ["Alex Murphy", "Bernd Bohnet", "Ryan Mcdonald", "Uta Noppeney"]}, "text": ["To", "minimise", "confounds", "arising", "from", "the", "preceding", "word", "in", "the", "sentence,", "we", "balanced", "the", "test", "set", "with", "respect", "to", "the", "open/closed", "class", "status", "of", "the", "previous", "word.", "Similarly,", "we", "controlled", "the", "decoding", "of", "word", "frequency", "for", "word", "length,", "and", "the", "analysis", "of", "word", "length", "for", "word", "frequency,", "and", "both", "analyses", "for", "open/closed", "class", "and", "sentence", "position.", "2", "shows", "the", "mean", "accuracy", "values", "(averaged", "across", "10", "seed", "points)", "from", "the", "test", "set", "(centred", "on", "the", "last", "bin", "of", "each", "time", "window", "(Grootswagers et al., 2017))", "with", "\u00b1", "68%", "CI.", "The", "classification", "responses", "for", "the", "test", "set", "from", "the", "model", "that", "performed", "best", "on", "the", "dev", "set", "were", "entered", "into", "a", "two-sided", "binomial", "test,", "separately", "for", "each", "time", "window.", "Solid", "lines", "in", "Figure", "2", "above", "the", "decoding", "accuracy", "time", "courses", "indicate", "time", "points", "that", "were", "significant", "at", "(p", "&lt,", "0.05)", "False", "Discovery", "Rate", "(FDR)", "corrected", "for", "multiple", "comparisons", "(Rouam, 2013)", "across", "time", "(i.e.", "160", "tests)."], "cited_papers": [{"title": "Decoding dynamic brain patterns from evoked responses: A tutorial on multivariate pattern analysis applied to time series neuroimaging data", "year": "2017", "authors": ["Tijl Grootswagers", "Susan Wardle", "Thomas Carlson"]}], "target_citation_location": 80, "citation_locations": [80, 143], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ef6a7075-81fc-486b-900e-17700bba307e", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["The", "interaction", "layer", "is", "the", "core", "element", "of", "the", "architecture", "for", "which", "several", "kinds", "attention", "mechanisms", "has", "been", "developed", "to", "improve", "the", "QA", "matching", "process", "such", "as", "bi-attention", "(Seo et al., 2017),", "co-attention", "(Xiong et al., 2017 , 2018 ), multi-level inter-attention (Huang et al., 2018)", "or", "re-attention", "(Hu et al., 2018),", "to", "name", "just", "a", "few."], "cited_papers": [{"title": "Reinforced mnemonic reader for machine reading comprehension", "year": "2018", "authors": ["Minghao Hu", "Yuxing Peng", "Zhen Huang", "Xipeng Qiu", "Furu Wei", "Ming Zhou"]}], "target_citation_location": 33, "citation_locations": [28, 30, 33], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2]]}
{"id": "efd4b71f-acc4-48fa-bed5-474e63370c02", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["Technical", "Details", "All", "neural", "models", "are", "trained", "using", "cross-entropy", "loss", "and", "optimized", "with", "Adam", "(Kingma", "and", "Ba,", "2015),", "using", "the", "AllenNLP", "library", "(Gardner et al., 2018).", "We", "train", "using", "a", "1e", "\u2212", "5", "learning", "rate", "for", "40", "epochs,", "with", "early", "stopping", "based", "the", "F1", "metric", "on", "the", "development", "set.", "We", "use", "SpanBERT", "(Joshi et al., 2020)", "as", "the", "pretrained", "MLM,", "as", "it", "was", "found", "to", "work", "well", "on", "span-based", "tasks", "with", "its", "base", "and", "the", "large", "variants.", "The", "anchor", "and", "complement", "encoding", "MLPs", "have", "one", "500-dim", "hidden", "layer", "and", "output", "500dim", "representations.", "The", "prediction", "MLPs", "have", "one", "100-dim", "hidden", "layer.", "All", "MLPs", "use", "the", "ReLU", "activation.", "We", "used", "the", "same", "hyperparameters", "for", "all", "baselines", "and", "did", "not", "tune", "them.", "18"], "cited_papers": [{"title": "SpanBERT: Improving pre-training by representing and predicting spans", "year": "2020", "authors": ["Mandar Joshi", "Danqi Chen", "Yinhan Liu", "Daniel Weld", "Luke Zettlemoyer", "Omer Levy"]}], "target_citation_location": 49, "citation_locations": [22, 49], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f019f2b4-aa79-4238-8c85-ccbf4ebf96fc", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["For", "swh", "pre-training", "data", "we", "use:", "(i)", "the", "\"Language", "Modeling", "Data", "for", "Swahili\"", "dataset", "(Shikali", "and", "Refuoe,", "2019)", "hosted", "on", "Hugging", "Face", "(which", "we", "refer", "to", "as", "the", "\"HF", "Swahili\"", "data", "set),", "and", "(ii)", "the", "ALFFA", "speech", "dataset", "(Gelas et al., 2012).", "For", "ALFFA", "data", "we", "process", "both", "the", "audio", "files", "(using", "Allosaurus)", "and", "the", "original", "\"gold\"", "text", "transcriptions", "(using", "Epitran)."], "cited_papers": [{"title": "Developments of Swahili resources for an automatic speech recognition system", "year": "2012", "authors": ["Hadrien Gelas", "Laurent Besacier", "Francois Pellegrino"]}], "target_citation_location": 38, "citation_locations": [38], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "f04ecbbd-4328-45d5-b4f1-4eba8d91459e", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["The", "reward", "and", "risk", "of", "using", "generative", "models", "in", "tasks", "related", "to", "job", "search", "are", "debated.", "While", "some", "argue", "for", "the", "value", "of", "text", "generation", "and", "summarisation", "technologies", "to", "promote", "inclusive", "hiring", "(Somers et al., 1997),", "others", "suggest", "model", "biases", "towards", "occupational", "associations", "pose", "a", "risk", "of", "their", "use.", "Specifically,", "research", "has", "uncovered", "gender", "bias", "in", "large-scale", "language", "models", "by", "examining", "the", "strength", "of", "statistical", "association", "between", "a", "given", "gender", "and", "a", "set", "of", "jobs", "using", "prompts", "such", "as", "\"the", "woman", "works", "as", "a", "[token]\"", "(Sheng et al., 2019, Kirk et al., 2021).", "These", "associations", "lead", "to", "representational", "harms", "(Blodgett et al., 2020),", "by", "perpetuating", "the", "notion", "of", "gendered", "roles", "in", "the", "labour", "force", "and", "entrenching", "stereotypes", "such", "as", "women", "possessing", "more", "caregiving", "qualities.", "However,", "it", "is", "unclear", "how", "these", "model", "biases", "translate", "directly", "to", "language", "generation", "in", "applied", "downstream", "tasks,", "that", "is,", "how", "they", "may", "give", "rise", "to", "allocational", "harms.", "One", "example", "of", "such", "a", "task", "is", "the", "generation", "of", "job", "advertisements", "(ads)", "which", "exemplifies", "the", "risk", "of", "allocational", "harms", "because", "candidates", "from", "a", "given", "group", "may", "be", "discouraged", "to", "apply", "as", "a", "result", "of", "biased", "language.", "Prior", "research", "has", "demonstrated", "gendered", "wording", "in", "job", "ads", "can", "act", "as", "an", "institutional-level", "mechanism", "to", "entrench", "traditional", "gender", "divisions", "(Gaucher et al., 2011).", "1", "Gender", "bias", "in", "natural", "language", "processing", "(NLP)", "has", "been", "more", "widely-discussed", "(Sun et al., 2019, Blodgett et al., 2020, Lu et al., 2020),", "with", "some", "specific", "work", "documenting", "bias", "of", "generative", "language", "models", "(Solaiman et al., 2019, Brown et al., 2020, Kirk et al., 2021).", "Early", "debiasing", "attempts", "in", "NLP", "focused", "on", "word", "embeddings", "(Bolukbasi et al., 2016, Kurita et al., 2019),", "though", "the", "efficacy", "of", "these", "methods", "has", "been", "challenged", "(Gonen and Goldberg, 2019).", "Some", "recent", "research", "seeks", "to", "align", "generative", "language", "models", "with", "societally-desirable", "values", "(Solaiman and Dennison, 2021),", "reduce", "various", "dimensions", "of", "groupdirected", "bias", "(Liu et al., 2021b, Smith and Williams, 2021)", "and", "decrease", "risk", "of", "toxicity", "(Ouyang et al., 2022).", "There", "is", "less", "research", "on", "how", "gender", "bias", "in", "generative", "models", "affects", "applied", "tasks,", "and", "to", "our", "knowledge,", "no", "prior", "work", "on", "bias", "in", "generated", "job", "ads.", "Furthermore,", "there", "is", "a", "lack", "of", "research", "advising", "on", "how", "industry", "practitioners", "can", "effectively", "and", "cheaply", "debias", "outputs", "whilst", "retaining", "quality,", "accuracy", "and", "realism."], "cited_papers": [{"title": "Language (technology) is power: A critical survey of \"bias\" in NLP", "year": "2020", "authors": ["unk Su Lin", "Solon Blodgett", "Hal Barocas", "Iii Daum\u00e9", "Hanna Wallach"]}], "target_citation_location": 89, "citation_locations": [32, 82, 89, 195, 208, 219, 229, 239, 252, 259, 265], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f0c0a129-1e3b-42d4-b107-a0d043e90e6f", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["Bidirectional", "Encoder", "Representations", "from", "Transformers", "(BERT)", "(Devlin et al., 2018)", "is", "a", "deep", "learning", "model", "for", "general-purpose", "language", "representations.", "BERT", "is", "often", "used", "as", "the", "backbone", "model", "for", "several", "NLP", "tasks", "like", "semantic", "analysis,", "question", "answering,", "and", "named", "entity", "recognition.", "The", "bidirectional", "transformer", "used", "in", "BERT", "has", "a", "deeper", "sense", "of", "language", "context", "and", "generates", "intricate", "semantic", "feature", "representations.", "These", "representations", "are", "learned", "through", "a", "pre-training", "step", "using", "Next", "Sentence", "Prediction", "(NSP)", "and", "Masked", "Language", "Modelling", "(MLM)", "as", "pretext", "tasks", "and", "transferred", "to", "the", "downstream", "NLP", "tasks.", "The", "goal", "of", "the", "Next", "Sentence", "Prediction", "task", "is", "to", "identify", "whether", "the", "two", "input", "sentences", "are", "consecutive", "or", "not.", "In", "Masked", "Language", "Modelling,", "BERT", "is", "trained", "to", "predict", "randomly", "masked", "words", "in", "a", "sentence.", "The", "Transformer", "network", "receives", "a", "sequence", "of", "tokens", "as", "input", "and", "utilizes", "the", "attention", "mechanism", "to", "learn", "the", "contextual", "relationships", "between", "words", "in", "a", "text.", "These", "relationships", "can", "then", "be", "used", "to", "extract", "high-quality"], "cited_papers": [{"title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "year": "2018", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 6, "citation_locations": [6], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f100b61d-f511-48e3-b577-779b391db96f", "citing_paper": {"title": "Rapid development of RBMT systems for related languages", "year": 2007, "authors": ["Jernej Vicic"]}, "text": ["The", "TNT", "tagger", "(Brants, 2000),", "which", "was", "used", "in", "the", "process,", "relies", "heavily", "on", "context", "to", "disambiguate", "ambiguities.", "In", "a", "word", "list", "each", "word", "is", "treated", "separately,", "there", "is", "no", "context,", "so", "the", "word", "tagging", "quality", "is", "lower", "than", "the", "values", "on", "running", "text."], "cited_papers": [{"title": "TnT -a statistical part-of-speech tagger", "year": "2000", "authors": ["Thorsten Brants"]}], "target_citation_location": 3, "citation_locations": [3], "citation_type": "single", "annotations": [[1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f210640e-8557-4dbf-a2e3-23d65f44e1a5", "citing_paper": {"title": "Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP", "year": 2020, "authors": ["Ahmed Younes", "Julie Weeds"]}, "text": ["The", "authors", "also", "built", "their", "own", "linguistic", "resources,", "ANERcorp", "(an", "annotated", "corpus)", "and", "ANERgazet", "(a", "gazetteer),", "which", "have", "become", "benchmarks", "for", "evaluation.", "At", "this", "time,", "work", "was", "also", "done", "on", "incorporating", "POS", "information", "to", "improve", "NER.", "For", "example,", "Benajiba and Rosso (2007)", "proposed", "ANERsys", "2.0,", "where", "they", "used", "a", "POS", "tagger", "and", "a", "two", "step", "approach", "to", "enhance", "the", "performance", "of", "ANERsys", "1.0."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 38, "citation_locations": [38], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "f265f8da-598f-4b3d-a9ce-b1d85810e598", "citing_paper": {"title": "DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach", "year": 2021, "authors": ["Chunguang Pan", "Bingyan Song", "Shengguang Wang", "Zhipeng Luo"]}, "text": ["In", "CWI 2018 (Yimam et al., 2018),", "a", "multilingual", "dataset", "was", "provided", "containing", "English,", "German,", "Spanish", "and", "French", "and", "there", "were", "two", "subtasks:", "binary", "classification", "and", "probabilistic", "classification.", "The", "submitted", "systems", "mainly", "use", "traditional", "machine", "learning", "classifiers(e.g.", "SVM,", "Random", "Forests)", "with", "features", "(Butnaru and Ionescu, 2018, Kajiwara and Komachi, 2018),", "deep", "learning", "methods", "(Hartmann and Dos Santos, 2018, De Hertog and Tack, 2018)", "and", "ensemble", "methods", "(Gooding and Kochmar, 2018, Aroyehun et al., 2018).", "More", "recently,", "(Gooding and Kochmar, 2019)", "propose", "a", "new", "perspective", "by", "treating", "CWI", "as", "a", "sequence", "labeling", "task", "that", "can", "detect", "both", "complex", "words", "and", "phrases.", "All", "these", "methods", "are", "different", "from", "ours", "which", "utilizes", "heterogeneous", "PLMs", "with", "various", "training", "strategies."], "cited_papers": [{"title": "Deep learning architecture for complexword identification", "year": "2018", "authors": ["Dirk De Hertog", "Ana\u00efs Tack"]}, {"title": "Nilc at cwi 2018: Exploring feature engineering and feature learning", "year": "2018", "authors": ["Nathan Hartmann", "Leandro Borges Dos Santos"]}], "target_citation_location": 41, "citation_locations": [1, 37, 41, 45, 48], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f288c696-1dbe-4551-9bbc-555110eea7e6", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["the", "candidate", "summaries.", "In", "other", "words,", "we", "give", "the", "abstractive", "model", "a", "dual", "role:", "as", "a", "generation", "model,", "it", "generates", "the", "output", "summaries", "in", "an", "autoregressive", "way,", "as", "an", "evaluation", "model,", "it", "can", "be", "used", "to", "score", "the", "quality", "of", "candidate", "summaries", "by", "estimating", "a", "probability", "distribution", "over", "candidate", "outputs.", "The", "generation", "model", "is", "trained", "using", "the", "standard", "MLE", "loss,", "but", "to", "train", "the", "evaluation", "model", "we", "introduce", "a", "contrastive", "loss", "(Hadsell et al., 2006)", "defined", "over", "different", "candidate", "summaries", "generated", "by", "pre-trained", "abstractive", "models", "(Fig.", "1),", "following", "previous", "work", "on", "ranking-based", "or", "contrastive", "learning", "(Hopkins and May, 2011, Zhong et al., 2020, Liu et al., 2021b)."], "cited_papers": [{"title": "Dimensionality reduction by learning an invariant mapping", "year": "2006", "authors": ["Raia Hadsell", "Sumit Chopra", "Yann Lecun"]}], "target_citation_location": 71, "citation_locations": [71, 92], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "f3cc896a-b43b-43c4-b1c1-14dcf7217f09", "citing_paper": {"title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements", "year": 2022, "authors": ["Conrad Borchers", "Dalia Sara Gala", "Benjamin Gilburt", "Eduard Oravkin", "Wilfried Bounsi", "Yuki Asano", "Hannah Kirk"]}, "text": ["Gender", "bias", "in", "language", "is", "complex", "and", "no", "single", "measure", "can", "capture", "all", "presentations", "of", "societal", "harms", "(Blodgett et al., 2020).", "Several", "methodologies", "to", "measure", "and", "mitigate", "bias", "cannot", "be", "applied", "in", "our", "setting", "given", "the", "lack", "of", "public", "access", "to", "GPT-3's", "model", "architecture", "or", "training", "dataset,", "and", "the", "enormous", "resources", "needed", "to", "retrain", "the", "model", "from", "scratch.", "In", "particular,", "this", "includes", "training", "data", "augmentation", "(Sen et al., 2021),", "adjusting", "model", "behaviour", "via", "adversarial", "learning", "(Zhang et al., 2018, Berg et al., 2022),", "and", "amending", "model", "embeddings", "(Dev and Phillips, 2019)."], "cited_papers": [{"title": "Attenuating bias in word vectors", "year": "2019", "authors": ["Sunipa Dev", "Jeff Phillips"]}], "target_citation_location": 74, "citation_locations": [17, 62, 69, 74], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1]]}
{"id": "f3fffb9e-8839-4b93-b7f1-3bc8d779addd", "citing_paper": {"title": "drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM", "year": 2022, "authors": ["Dylan Phelps"]}, "text": ["Adopting", "the", "idiom", "principle", "(Sinclair, 1991)", "to", "produce", "a", "single", "token", "representation", "for", "MWEs", "has", "been", "used", "widely", "within", "static", "embedding", "distributional", "semantic", "models", "(Mikolov et al., 2013, Cordeiro et al., 2019).", "Within", "contextualised", "representation", "models,", "Hashempour and Villavicencio, 2020", "show", "that", "the", "contextualised", "representations", "produced", "by", "context2vec", "(Melamud et al., 2016)", "and", "BERT", "(Devlin et al., 2019)", "models", "can", "be", "used", "to", "differentiate", "between", "idiomatic", "and", "literal", "uses", "of", "MWEs.", "However,", "the", "MWEs", "are", "only", "represented", "by", "one", "token", "in", "the", "input,", "before", "being", "broken", "into", "many", "tokens", "using", "BERTs", "word", "piece", "tokenizer.", "Tayyar", "Madabushi", "et", "al.,", "2021", "add", "a", "token", "to", "the", "BERT", "embedding", "matrix", "and", "shows", "that", "this", "method", "improves", "representations", "through", "increased", "performance", "on", "their", "proposed", "STS", "task.", "The", "embeddings", "they", "add", "to", "BERT", "are", "randomly", "initialised,", "however,", "and", "only", "trained", "during", "the", "fine-tun", "step", "on", "limited", "data.", "Form", "embeddings", "are", "then", "learnt", "using", "trained", "ngram", "character", "embeddings,", "before", "being", "passed", "with", "a", "context", "into", "a", "BERT", "model.", "The", "output", "of", "the", "BERT", "model", "forms", "the", "embedding", "for", "that", "specific", "context.", "To", "incorporate", "knowledge", "from", "many", "contexts", "an", "attention", "layer", "is", "applied", "over", "the", "outputs", "for", "each", "context", "to", "get", "the", "final", "embedding.", "There", "exist", "other", "models", "to", "produce", "effective", "embeddings", "from", "a", "small", "number", "of", "contexts", "(Zhao et al., 2018, Pinter et al., 2017),", "however,", "BERTRAM", "is", "the", "only", "model", "that", "is", "non-bag-ofwords", "and", "incorporates", "both", "form", "and", "context", "information", "when", "creating", "the", "embedding."], "cited_papers": [{"title": "Distributed representations of words and phrases and their compositionality", "year": "2013", "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg Corrado", "Jeff Dean"]}, {"title": "Unsupervised compositionality prediction of nominal compounds", "year": "2019", "authors": ["Silvio Cordeiro", "Aline Villavicencio", "Marco Idiart", "Carlos Ramisch"]}], "target_citation_location": 23, "citation_locations": [4, 23, 28, 37, 40, 194], "citation_type": "group", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f466aa70-6b4e-41e6-8d38-f5c6b80095ce", "citing_paper": {"title": "Amrita_CEN_NLP@SDP2021 Task A and B", "year": 2021, "authors": ["Isha Indhu", "Kavya Kumar", "Lakshaya Karthikeyan"]}, "text": ["Though", "the", "importance", "of", "categorizing", "scientific", "literature", "according", "to", "context", "is", "apparent,", "the", "reported", "amount", "of", "research", "that", "has", "been", "carried", "out", "is", "insufficient.", "Along", "with", "a", "classification", "model,", "Teufel et al. (2006)", "also", "proposed", "an", "annotation", "scheme", "for", "the", "categorization", "of", "the", "citations.", "12", "classes", "were", "considered", "for", "annotation.", "From", "116", "articles,", "2829", "citation", "samples", "were", "gathered.", "These", "were", "used", "to", "train", "the", "machine", "learning", "model.", "113K", "algorithms", "were", "used", "for", "classification", "with", "hand-engineered", "features.", "One", "of", "such", "features", "was", "cue", "phrases.", "Features", "such", "as", "patternbased", "features,", "topic-based", "features,", "and", "prototypical", "argument", "features", "were", "used", "by", "D.", "Jurgens Jurgens et al. (2018)", "to", "separate", "the", "documents", "into", "its", "6", "corresponding", "classes.", "The", "RandomForest", "algorithm", "was", "used", "for", "classification.", "Cohan et al. (2019)", "also", "utilised", "Glove,", "ELMO", "word", "embedding", "features,", "and", "Bi-LSTM", "with", "attention", "models", "to", "aid", "in", "the", "classification", "of", "the", "citations.", "Kunnath et al. (2020)", "organized", "the", "first", "shared", "task", "on", "citation", "classification", "in", "2020,", "where", "different", "teams", "came", "up", "with", "different", "approaches", "to", "solve", "3c", "classification", "problem."], "cited_papers": [{"title": "Overview of the 2020 wosp 3c citation context classification task", "year": "2020", "authors": ["N Suchetha", "David Kunnath", "Bikash Pride", "Petr Gyawali", "unk Knoth"]}], "target_citation_location": 133, "citation_locations": [29, 95, 112, 133], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "f4a88566-0d6e-434f-b41b-0c9f26dbd8af", "citing_paper": {"title": "Themes in the work of Margaret Masterman", "year": 1988, "authors": ["Yorick Wilks"]}, "text": ["What", "MMB", "sought", "was", "a", "compromise", "system", "of", "meaning", "representation", "for", "MT:", "one", "that", "was", "fundamental", "to", "the", "process", "of", "translation,", "but", "did", "not", "constitute", "a", "detailed", "representation", "of", "all", "the", "relevant", "knowledge", "of", "the", "world.", "She", "believed", "there", "was", "a", "level", "of", "representation,", "linguistic", "if", "you", "will,", "probably", "vague", "as", "well,", "but", "which", "was", "sufficient", "for", "MT.", "In", "that", "sense,", "she", "totally", "denied", "the", "assumption", "behind", "Bar-Hillel's", "critique", "of", "MT (1953)", "-which", "was", "taken", "up", "by", "some", "artificial", "intelligence", "researchers", "afterwards", "(although", "not,", "of", "course,", "the", "same", "ones", "as", "referred", "to", "in", "the", "last", "paragraph)", "-that", "MT", "and", "language", "understanding", "in", "general", "did", "require", "the", "explicit", "representation", "of", "all", "world", "knowledge.", "This", "position", "of", "hers", "cannot", "be", "separated", "from", "her", "quasi-idealist", "belief", "(see", "further", "below)", "that", "world", "knowledge", "cannot", "be", "represented", "independently", "of", "some", "language,", "and", "hence", "that", "any", "true", "distinction", "between", "meaning", "representation", "and", "the", "representation", "of", "world", "knowledge", "is,", "ultimately,", "misconceived", "(see", "her", "discussion", "of", "Whorf", "[Masterman, 1961]", ").", "The", "only", "dispute", "can", "be", "about", "the", "'level'", "or", "'grain'", "of", "representation", "that", "particular", "acts", "of", "translation", "require."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 70, "citation_locations": [70, 158], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f4beca71-804e-4845-9657-796efa73b421", "citing_paper": {"title": "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation", "year": 2021, "authors": ["Chong Zhang", "Jieyu Zhao", "Huan Zhang", "Kai-Wei Chang", "Cho-Jui Hsieh"]}, "text": ["Furthermore,", "we", "extend", "the", "double", "perturbation", "framework", "to", "evaluate", "counterfactual", "biases", "(Kusner et al., 2017)", "(\u00a74)", "in", "English.", "When", "the", "test", "dataset", "is", "small,", "our", "framework", "can", "help", "improve", "the", "evaluation", "robustness", "by", "revealing", "the", "hidden", "biases", "not", "directly", "shown", "in", "the", "test", "dataset.", "Intuitively,", "a", "fair", "model", "should", "make", "the", "same", "prediction", "for", "nearly", "identical", "examples", "referencing", "different", "groups", "(Garg et al., 2019)", "with", "different", "protected", "attributes", "(e.g.,", "gender,", "race).", "In", "our", "evaluation,", "we", "consider", "a", "model", "biased", "if", "substituting", "tokens", "associated", "with", "protected", "attributes", "changes", "the", "expected", "prediction,", "which", "is", "the", "average", "prediction", "among", "all", "examples", "within", "the", "neighborhood.", "For", "instance,", "a", "toxicity", "classifier", "is", "biased", "if", "it", "tends", "to", "increase", "the", "toxicity", "if", "we", "substitute", "straight", "\u2192", "gay", "in", "an", "input", "sentence", "(Dixon et al., 2018).", "In", "the", "experiments,", "we", "evaluate", "the", "expected", "sentiment", "predictions", "on", "pairs", "of", "protected", "tokens", "(e.g.,", "(he,", "she),", "(gay,", "straight)),", "and", "demonstrate", "that", "our", "method", "is", "able", "to", "reveal", "the", "hidden", "model", "biases."], "cited_papers": [{"title": "Counterfactual fairness", "year": "2017", "authors": ["J Matt", "Joshua Kusner", "Chris Loftus", "Ricardo Russell", "unk Silva"]}], "target_citation_location": 11, "citation_locations": [11, 57, 119], "citation_type": "single", "annotations": [[0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f4c3474d-756f-412b-96c2-8605a2896d17", "citing_paper": {"title": "Peru is Multilingual, Its Machine Translation Should Be Too?", "year": 2021, "authors": ["Arturo Oncevay"]}, "text": ["Pre-training", "We", "pre-trained", "two", "MT", "models", "with", "the", "Spanish-English", "language-pair", "in", "both", "directions.", "We", "did", "not", "include", "an", "agglutinative", "language", "like", "Finnish", "(Ortega et al., 2020b)", "for", "two", "reasons:", "it", "is", "not", "a", "must", "to", "consider", "highly", "related", "languages", "for", "effective", "transfer", "learning", "(e.g.", "English-German", "to", "English-Tamil", "(Bawden et al., 2020)", "),", "and", "we", "wanted", "to", "translate", "the", "English", "side", "of", "en-aym,", "en-quy", "and", "en-quz", "to", "augment", "their", "correspondent", "Spanish-paired", "datasets.", "The", "en\u2192es", "and", "es\u2192en", "models", "achieved", "34.4", "and", "32.3", "BLEU", "points,", "respectively,", "in", "the", "newsdev2013", "set."], "cited_papers": [{"title": "Neural machine translation with a polysynthetic low resource language", "year": "2020", "authors": ["E John", "Richard Ortega", "Kyunghyun Castro Mamani", "unk Cho"]}], "target_citation_location": 22, "citation_locations": [22, 44], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f51d6772-3f8a-4f44-85c4-422de48e14a7", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["The", "benefits", "of", "a", "New", "York", "Subway", "system", "is", "that", "a", "person", "can", "get", "from", "A", "to", "B", "without", "being", "stuck", "in", "traffic", "and", "subway", "trains", "are", "faster", "than", "buses.", "(Prediction:", "Negative)", "Natural", "Language", "Inference", "(McCoy et al., 2019),", "synonym", "substitutions", "(Alzantot et al., 2018),", "or", "adding", "adversarial", "sentences", "for", "QA", "(Jia and Liang, 2017).", "More", "recent", "work", "on", "testing", "models'", "behaviour", "using", "CheckList (Ribeiro et al., 2020)", "also", "used", "a", "pre-defined", "series", "of", "test", "types,", "e.g.,", "adding", "negation,", "temporal", "change,", "and", "switching", "locations/person", "names.", "However,", "for", "safe", "deployment", "of", "NLP", "models", "in", "the", "real", "world,", "in", "addition", "to", "predefining", "a", "small", "or", "limited", "set", "of", "patterns", "which", "the", "model", "could", "be", "vulnerable", "to,", "it", "is", "also", "important", "to", "proactively", "discover", "and", "identify", "models'", "unrobust", "regions", "automatically", "and", "comprehensively."], "cited_papers": [{"title": "Generating natural language adversarial examples", "year": "2018", "authors": ["Moustafa Alzantot", "Yash Sharma", "Ahmed Elgohary", "Bo-Jhang Ho", "Mani Srivastava", "Kai-Wei Chang"]}], "target_citation_location": 38, "citation_locations": [35, 38, 45, 54], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f5503cf8-0586-4384-a9af-619ff3e4f385", "citing_paper": {"title": "Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data", "year": 2022, "authors": ["Colin Leong", "Daniel Whitenack"]}, "text": ["For", "fine-tuning", "the", "downstream", "NER", "task,", "we", "use", "the", "MasakhaNER", "data", "set", "(Adelani et al., 2021).", "As", "with", "other", "text-based", "data", "sets,", "we", "transform", "the", "NER", "sample", "with", "Epitran", "to", "map", "the", "samples", "into", "the", "phonetic", "representation."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 12, "citation_locations": [12], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "f5a38cce-af2a-4d85-806d-b86709c0053b", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["connection", "according", "to", "the", "knowledge", "graph", "ConceptNet5", "(Speer and Havasi, 2012),"], "cited_papers": [{"title": "Representing general relational knowledge in ConceptNet 5", "year": "2012", "authors": ["Robyn Speer", "Catherine Havasi"]}], "target_citation_location": 7, "citation_locations": [7], "citation_type": "single", "annotations": [[2, 2, 2, 1, 1, 1, 1, 1]]}
{"id": "f5a49007-d18b-445d-bc63-6a2ceb50dc66", "citing_paper": {"title": "MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages", "year": 2022, "authors": ["Karthik Gokul", "Abhishek Kumar", "Gehlot Singh", "Shaji Sahal", "Karthik Mullappilly", "unk Nandakumar"]}, "text": ["First,", "we", "observe", "from", "Table", "2", "that", "just", "having", "intermediate", "SQuAD", "pre-training", "in", "English,", "improves", "the", "overall", "Jaccard", "score", "significantly", "from", "0.44", "to", "0.5.", "Furthermore,", "we", "fine-tune", "by", "dividing", "translated", "and", "transliterated", "data", "into", "Indo-Aryan", "and", "Dravidian", "language", "families", "to", "study", "how", "translated", "and", "transliterated", "pairs", "serve", "as", "supervised", "cross-lingual", "signals", "when", "languages", "share", "semantics", "and", "structure", "(Mikolov et al., 2013).", "Although", "transliteration", "improves", "the", "Jaccard", "scores", "in", "certain", "cases", "compared", "to", "the", "baseline,", "the", "trend", "is", "not", "consistent.", "Moreover,", "contrastive", "training", "does", "not", "help", "in", "the", "case", "of", "transliteration", "as", "shown", "in", "Table", "3.", "This", "could", "be", "because", "the", "QA", "model", "is", "pre-trained", "only", "with", "regular", "text", "and", "not", "with", "transliteration", "style", "text."], "cited_papers": [{"title": "Exploiting similarities among languages for machine translation", "year": "2013", "authors": ["Tomas Mikolov", "V Quoc", "Ilya Le", "unk Sutskever"]}], "target_citation_location": 57, "citation_locations": [57], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f5a6696c-7497-4c37-845a-0e116e2dc31d", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["Increasing", "the", "Beam", "Width", "While", "theoretically", "a", "larger", "beam", "width", "(i.e.", "the", "number", "of", "candidates", "maintained", "during", "beam", "search)", "would", "allow", "more", "candidates", "to", "be", "considered", "and", "therefore", "increase", "the", "upper", "bound", "of", "the", "performance,", "in", "practice", "model", "performance", "may", "be", "lower", "if", "the", "beam", "width", "is", "too", "large.", "The", "reason", "for", "this", "phenomenon", "is", "closely", "related", "to", "the", "low", "sequence-level", "coordination", "of", "the", "generator.", "Specifically,", "increasing", "the", "beam", "width", "may", "introduce", "candidates", "with", "lower", "quality", "(Stahlberg and Byrne, 2019),", "and", "the", "generator", "may", "not", "be", "able", "to", "differentiate", "them", "from", "high-quality", "candidates.", "In", "Tab.", "5,", "we", "compare", "the", "performance", "of", "the", "pre-trained", "BART", "and", "our", "model", "(BRIO-Mul)", "with", "different", "beam", "widths", "used", "during", "inference.", "We", "observe", "that", "the", "performance", "of", "BART", "goes", "down", "as", "the", "beam", "width", "increases.", "On", "the", "other", "hand,", "our", "model", "is", "able", "to", "achieve", "better", "performance", "with", "a", "larger", "number", "of", "beams,", "demonstrating", "that", "our", "training", "method", "can", "improve", "the", "coordination", "of", "the", "model", "by", "encouraging", "the", "model", "to", "assign", "estimated", "probabilities", "to", "candidate", "summaries", "wellcorrelated", "with", "their", "quality.", "Training", "with", "Different", "Evaluation", "Metrics", "In", "the", "previous", "experiments,", "we", "used", "ROUGE", "as", "the", "evaluation", "metric", "to", "define", "the", "target", "ordering", "of", "the", "candidate", "summaries", "(Eq.7).", "To", "evaluate", "our", "method's", "performance", "beyond", "ROUGE,", "we", "use", "a", "model-based", "semantic", "similarity", "metric,", "BERTScore", "(Zhang* et al., 2020),", "7", "as", "the", "evaluation", "metric", "M", "in", "Eq.7", "to", "compare", "the", "performance", "of", "different", "candidate", "summaries.", "Then,", "we", "trained", "another", "version", "of", "BRIO-Mul", "based", "on", "the", "order", "of", "candidate", "summaries", "calculated", "by", "BERTScore."], "cited_papers": [{"title": "On NMT search errors and model errors: Cat got your tongue?", "year": "2019", "authors": ["Felix Stahlberg", "Bill Byrne"]}], "target_citation_location": 76, "citation_locations": [76, 212], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f5f89e3d-8963-4b5c-a3b0-b7fb58af2738", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["First", "and", "foremost,", "we", "observed", "the", "fact", "that,", "due", "to", "a", "mix", "of", "factors", "such", "as", "greater", "media", "vigilance,", "and", "the", "viral", "nature", "of", "social", "media,", "there", "is", "certainly", "an", "increased", "willingness", "to", "issue", "public", "apologies", "in", "India", "(Kaul et.al, 2015).", "However,", "apologies", "available", "in", "the", "public", "domain", "are", "still", "limited,", "and", "so", "we", "cannot", "draw", "any", "generalizations", "from", "them.", "Hence,", "we", "can", "put", "forth", "certain", "trends", "and", "suggestions", "which", "need", "to", "be", "tested", "further", "on", "a", "much", "bigger", "corpus."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}], "target_citation_location": 38, "citation_locations": [38], "citation_type": "single", "annotations": [[0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f66c7d9c-d8ab-42a9-b67f-1252d2a123a7", "citing_paper": {"title": "A Parameter-Based Message-Passing Parser for MT of Korean and English", "year": 1994, "authors": ["Bonnie Dorr", "Jye-Hoon Lee", "Sungki Suh"]}, "text": ["This", "paper", "presents", "an", "efficient,", "implemented", "approach", "to", "cross-linguistic", "parsing", "for", "interlingual", "MT.", "Our", "design", "is", "based", "on", "Government-Binding", "(GB)", "Theory", "(Chomsky, 1981, Haegeman, 1991, van Riemsdijk and Williams, 1986).", "One", "of", "the", "drawbacks", "to", "alternative", "GBbased", "parsing", "approaches", "is", "that", "they", "generally", "adopt", "a", "filter-based", "paradigm,", "generating", "all", "possible", "candidate", "structures", "of", "the", "sentence", "that", "satisfy", "Xbar", "theory,", "and", "then", "subsequently", "applying", "filters", "to", "eliminate", "those", "structures", "that", "violate", "GB", "principles.", "(See,", "for", "example,", "Abney (1989),", "Correa (1991),", "Dorr (1991),", "Fong (1991),", "and Frank 1990.)", "The", "current", "approach", "provides", "an", "alternative", "to", "filter-based", "designs", "which", "avoids", "these", "difficulties", "by", "applying", "principles", "to", "descriptions", "of", "structures", "without", "actually", "building", "the", "structures", "themselves.", "In", "effect,", "structure", "building", "is", "deferred", "until", "the", "descriptions", "satisfy", "all", "principles."], "cited_papers": [{"title": "Principle-based parsing for machine translation", "year": "1991", "authors": ["B Dorr"]}], "target_citation_location": 69, "citation_locations": [21, 67, 68, 69, 70, 71], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f6ee4f73-7dcd-4ff3-aeaa-ac18dbfbce87", "citing_paper": {"title": "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets", "year": 2021, "authors": ["Lan Zhang", "Victor Prokhorov", "Ehsan Shareghi"]}, "text": ["Training", "Configuration.", "We", "adopt", "the", "VAE", "architecture", "from", "(Bowman et al., 2016),", "using", "a", "LSTM", "encoder-decoder.", "Unless", "stated", "otherwise,", "(word", "embedding,", "LSTM,", "representation", "embedding)", "dimensionalities", "for", "YNOC", "and", "POS", "datasets", "are", "(4D,", "32D,", "4D)", "and", "(4D,", "64D,", "8D),", "respectively,", "and", "we", "use", "the", "latent", "code", "to", "initialize", "the", "hidden", "state", "of", "the", "LSTM", "decoder.", "We", "use", "greedy", "decoding.", "All", "models", "are", "trained", "from", "multiple", "random", "starts", "using", "Adam", "(Kingma", "and", "Ba,", "2015)", "with", "learning", "rate", "0.001", "for", "10", "epochs.", "We", "set", "batch", "size", "to", "256", "and", "512", "for", "YNOC", "and", "POS,", "respectively."], "cited_papers": [{"title": "Generating sentences from a continuous space", "year": "2016", "authors": ["R Samuel", "Luke Bowman", "Oriol Vilnis", "Andrew Vinyals", "Rafal Dai", "Samy J\u00f3zefowicz", "unk Bengio"]}], "target_citation_location": 8, "citation_locations": [8], "citation_type": "single", "annotations": [[0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "f76fa34a-843b-4a53-829f-75a57c020b30", "citing_paper": {"title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models", "year": 2022, "authors": ["Tianlu Wang", "Rohit Sridhar", "Diyi Yang", "Xuezhi Wang"]}, "text": ["Task", "2:", "Occupation", "classification.", "Following", "Pruthi et al. (2020),", "we", "use", "the", "biographies", "(De-Arteaga et al., 2019)", "to", "predict", "whether", "the", "occupation", "is", "a", "surgeon", "or", "physician", "(non-surgeon).", "The", "training", "data", "consists", "of", "17,", "629", "biographies", "and", "the", "dev", "set", "contains", "2,", "519", "samples."], "cited_papers": [{"title": "Learning to deceive with attention-based explanations", "year": "2020", "authors": ["Danish Pruthi", "Mansi Gupta", "Bhuwan Dhingra", "Graham Neubig", "Zachary Lipton"]}], "target_citation_location": 5, "citation_locations": [5, 10], "citation_type": "single", "annotations": [[0, 0, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "f79c701a-2a82-4e76-a7d0-1672497e2fb2", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["Trained", "on", "ImageNet", "(Deng et al., 2009)", "YOLO", "(Redmon et al., 2015)", "x", "Trained", "on", "ImageNet", "(Deng et al., 2009)", "EfficientNet", "B7", "(Tan and Le, 2019)", "x", "Trained", "on", "ImageNet", "(Deng et al., 2009)", "Table", "1:", "List", "of", "pre-trained", "models", "registered", "by", "all", "participants", "of", "ReINTEL", "challenge", "in", "2020."], "cited_papers": [{"title": "ImageNet: A Large-Scale Hierarchical Image Database", "year": "2009", "authors": ["J Deng", "W Dong", "R Socher", "L.-J Li", "K Li", "L Fei-Fei"]}], "target_citation_location": 3, "citation_locations": [3, 5, 10, 13, 18], "citation_type": "single", "annotations": [[3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "f7e6993f-8d3d-48ba-a4c3-b1d113bf0777", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["Top-k", "attention", "is", "a", "highly", "accurate", "approximation", "to", "vanilla", "attention", "and", "is", "a", "plug-andplay", "replacement", "at", "both", "multi-head", "attention", "and", "feed-forward", "layers", "of", "a", "Transformer.", "This", "is", "unlike", "past", "attention", "variants", "(Katharopoulos et al., 2020, Choromanski et al., 2021, Peng et al., 2021)", "that", "require", "an", "expensive", "corrective", "pretraining", "stage", "to", "adjust", "model", "weights", "to", "the", "new", "variant,", "which", "can", "be", "prohibitive", "for", "large", "models.", "We", "show", "top-k", "attention", "can", "replace", "vanilla", "attention", "in", "a", "zero-shot", "inference", "setup", "and", "at", "finetuning", "time", "without", "any", "corrective", "pre-training."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Rethinking attention with performers", "year": "2021", "authors": ["Valerii Krzysztof Marcin Choromanski", "David Likhosherstov", "Xingyou Dohan", "Andreea Song", "Tamas Gane", "Peter Sarlos", "Jared Hawkins", "Afroz Davis", "Lukasz Mohiuddin", "David Kaiser", "Lucy Belanger", "Adrian Colwell", "unk Weller"]}, {"title": "Random feature attention", "year": "2021", "authors": ["Hao Peng", "Nikolaos Pappas", "Dani Yogatama", "Roy Schwartz", "Noah Smith", "Lingpeng Kong"]}], "target_citation_location": 31, "citation_locations": [31], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f867655e-b5f0-4cd0-8136-1c24bbb4ce07", "citing_paper": {"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "year": 2022, "authors": ["Cunliang Kong", "Yun Chen", "Hengyuan Zhang", "Liner Yang", "Erhong Yang"]}, "text": ["Semantic", "Similarity", "In", "addition", "to", "the", "BLEU", "score,", "we", "use", "the", "sentence-transformers", "toolkit", "(Reimers and Gurevych, 2020)", "to", "convert", "the", "generated", "definitions", "and", "references", "into", "sentence", "vectors,", "and", "calculate", "cosine", "similarity", "between", "them."], "cited_papers": [{"title": "Making monolingual sentence embeddings multilingual using knowledge distillation", "year": "2020", "authors": ["Nils Reimers", "Iryna Gurevych"]}], "target_citation_location": 13, "citation_locations": [13], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "f9297770-ed8c-4eef-b0ed-a84aabb59127", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["There", "is", "a", "person", "sitting", "on", "a", "horse.", "he", "is", "holding", "a", "horse", "thread", "and", "he", "is", "wearing", "a", "cap.", "there", "are", "flags,", "board", "on", "the", "left", "side.", "we", "can", "see", "in", "the", "background", "sky,", "trees.", "Contrastive", "Learning", "Recently,", "contrastive", "learning", "has", "been", "widely", "studied", "in", "unsupervised", "representation", "learning", "for", "vision,", "(He et al., 2020, Chen et al., 2020, Grill et al., 2020, Caron et al., 2020, Chen and He, 2020),", "language", "(Mikolov et al., 2013, Saunshi et al., 2019, Chi et al., 2020, Fang and Xie, 2020, Giorgi et al., 2020, Kong et al., 2020, Gunel et al., 2021),", "or", "multi-modal", "(Sun et al., 2019, Luo et al., 2020).", "The", "goal", "is", "to", "learn", "semantic", "representation", "between", "two", "views", "by", "allowing", "the", "positive", "sample", "to", "be", "similar", "(in", "semantic", "space)", "and", "negatives", "to", "be", "dissimilar", "semantically", "simultaneously.", "CLIP", "(Radford et al.)", "and", "MIL-NCE", "(Miech et al., 2020)", "has", "demonstrated", "the", "effectiveness", "for", "learning", "the", "semantic", "mapping", "between", "vision", "and", "language.", "Previous", "attempts", "mainly", "exploit", "the", "InfoNCE", "(Oord et al., 2018)", "objective", "to", "maximize", "a", "lower", "bound", "of", "the", "mutual", "information.", "This", "paper", "extends", "the", "multimodal", "contrastive", "learning", "between", "the", "trace", "in", "the", "image", "and", "captioning", "sentence.", "In", "the", "same", "image,", "they", "correspond", "to", "each", "other", "semantically.", "This", "motivates", "us", "to", "design", "a", "contrastive", "loss", "for", "better", "2022", "alignment", "between", "the", "trace", "and", "language."], "cited_papers": [{"title": "End-to-End Learning of Visual Representations from Uncurated Instructional Videos", "year": "2020", "authors": ["Antoine Miech", "Jean-Baptiste Alayrac", "Lucas Smaira", "Ivan Laptev", "Josef Sivic", "Andrew Zisserman"]}], "target_citation_location": 89, "citation_locations": [51, 53, 56, 86, 89, 109], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f93665c3-5c07-429e-914c-d30824fa3f03", "citing_paper": {"title": "SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions", "year": 2022, "authors": ["Viet Lai", "Amir Pouran", "Ben Veyseh", "Franck Dernoncourt", "Thien Nguyen"]}, "text": ["Ping", "and", "Chi", "(2022)", "(AN(L)P)", "participated", "in", "the", "Entity", "Extraction", "only.", "They", "finetuned", "a", "BERTlarge", "model", "(Devlin et al., 2019)", "for", "each", "domain.", "For", "cs.ai", "domain,", "they", "used", "data", "from", "cs.ai", "only,", "whereas,", "for", "the", "other", "domain,", "they", "augmented", "the", "in-domain", "data", "with", "the", "data", "from", "cs.ai."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "f9477533-842c-4699-a7a5-3bc1b576f679", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["If", "the", "pattern", "tree", "we", "want", "to", "complete", "is", "only", "the", "most", "embedded-that", "is,", "it", "is", "not", "possible", "to", "overlap", "gNCNs-this", "corresponds", "to", "the", "operation", "of", "unrestricted", "TAG", "adjoining.", "That", "is,", "from", "the", "example,", "only", "the", "last", "\u00ac", "\u00bdannotation", "is", "accessible,", "so", "the", "obvious", "model", "is", "a", "stack.", "The", "procedure", "is", "then", "an", "implementation", "of", "some", "form", "of", "bottom-up", "tree", "pushdown", "automaton", "(buTPDA)", "(Schimpf and Gallier, 1985),", "a", "tree", "automaton", "augmented", "with", "a", "stack,", "in", "the", "same", "way", "a", "pushdown", "automaton", "(PDA)", "is", "a", "a", "finite-state", "automaton", "(FSA)", "plus", "a", "stack."], "cited_papers": [{"title": "Tree pushdown automata", "year": "1985", "authors": ["K Schimpf", "J Gallier"]}], "target_citation_location": 63, "citation_locations": [63], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "f965ab21-b971-4deb-9dc8-9ca7b83695cd", "citing_paper": {"title": "Non-Contiguous Tree Parsing", "year": 2004, "authors": ["Mark Dras", "Chung-Hye Han"]}, "text": ["automaton.", "Thus", "it", "is", "possible", "for", "the", "stack", "to", "be", "accessed", "on", "different", "paths,", "and", "so", "it", "is", "possible", "for", "paths", "to", "be", "dependent", "(e.g.", "one", "path", "in", "the", "tree", "is", "\u00d2,", "another", "is", "\u00d2", ").", "Grammars", "that", "generate", "MCSLs", "cannot", "have", "dependent", "paths", "(Weir, 1988).", "But", "if", "access", "to", "the", "stack", "is", "restricted", "to", "a", "single", "path-in", "the", "same", "manner", "that", "restricting", "stack", "passing", "to", "a", "single", "non-terminal", "child", "in", "an", "indexed", "grammar", "produces", "a", "linear", "indexed", "grammar", "(Gazdar, 1988),", "which", "generates", "MCSLs-the", "power", "of", "the", "TPDA", "is", "suitably", "restricted.", "The", "idea", "is", "related", "to", "the", "Embedded", "Pushdown", "Automaton", "(EPDA)", "of", "Vijay-Shanker (1987),", "although", "this", "is", "of", "course", "a", "string", "automaton", "rather", "than", "a", "tree", "automaton."], "cited_papers": [{"title": "A study of tree adjoining grammars", "year": "1987", "authors": ["K Vijay-Shanker"]}], "target_citation_location": 100, "citation_locations": [44, 78, 100], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "f9d0218b-2756-4538-b196-6b650e03d626", "citing_paper": {"title": "NEW TABULAR ALGORITHMS FOR LIG PARSING", "year": 2000, "authors": ["Mi G Uel Alonso Jor G E Grana", "Manuel Vilares"]}, "text": ["vComp[oo][oo-y]", "1", "_", "[E,", "h", "I", "C\u2794", "Y4\u2022,,", "1,", "p,q", "I", "D,", "r,", "s]", "Earley", "-", "[E,", "h", "I", "A[oo]", "\u2794", "Y1", "B[oo", "1]", "Y2", ",'Y',", "i,", "k", "I", "D,", "r,", "s]As", "an", "alternative", "approach,", "Boullier", "[4]", "defines", "the", "shared", "forest", "for", "a", "LIG", "g", "=", "(Vr,", "VN,", "Vi,", "P,", "S)", "and", "an", "input", "string", "w", "by", "means", "of", "a", "linear", "derivation", "grammar,", "a", "context-free", "grammar", "recognizing", "the", "language", "defined", "by", "the", "sequences", "of", "LIG", "of", "g", "that", "could", "be", "used", "to", "derive", "w.", "Previously", "to", "the", "construction", "of", "the", "linear", "derivation", "grammar,", "we", "must", "compute", "the", "transitive", "closure", "for", "a", "set", "of", "relations", "on", "V", "N", "x", "V", "N."], "cited_papers": [{"title": "Another facet of LIG parsing", "year": "1996", "authors": ["P Boullier"]}], "target_citation_location": 36, "citation_locations": [36], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f9e23ad5-7e99-4111-a0ac-7cd808cfeedc", "citing_paper": {"title": "Text-based NP Enrichment", "year": 2022, "authors": ["Yanai Elazar", "Victoria Basmov", "Yoav Goldberg", "Reut Tsarfaty"]}, "text": ["We", "trained", "and", "qualified", "23", "workers", "on", "the", "Amazon", "Mechanical", "Turk", "(AMT)", "platform,", "to", "participate", "in", "the", "coreference,", "NP", "relations,", "and", "consolidation", "tasks.", "We", "follow", "the", "controlled", "crowdsourcing", "protocol", "suggested", "by", "Roit et al. (2020)", "and", "Pyatkin et al. (2020),", "giving", "detailed", "than", "two", "prepositions", "for", "the", "same", "NP", "pairs", "is", "not", "common,", "and", "two", "prepositions", "occur", "in", "11.6%", "of", "the", "test-set.", "For", "simplicity,", "in", "this", "work,", "we", "consider", "a", "single", "preposition", "for", "each", "NP", "pair,", "but", "the", "collected", "data", "may", "contain", "two", "prepositions", "for", "some", "pairs.", "We", "paid", "$1.50,", "$2.50,", "and", "$1.5)", "for", "each", "HIT", "in", "the", "coreference,", "NP-relations,", "and", "consolidation", "tasks,", "respectively.", "The", "price", "for", "the", "NPrelations", "task", "was", "raised", "to", "$2.70", "for", "the", "test", "and", "out-of-domain", "subsets.", "We", "additionally", "paid", "bonus", "payments", "on", "multiple", "occasions.", "Overall,", "we", "aimed", "at", "paying", "at", "least", "the", "minimum", "wage", "in", "the", "United", "States."], "cited_papers": [{"title": "Controlled crowdsourcing for high-quality QA-SRL annotation", "year": "2020", "authors": ["Paul Roit", "Ayal Klein", "Daniela Stepanov", "Jonathan Mamou", "Julian Michael", "Gabriel Stanovsky", "Luke Zettlemoyer", "Ido Dagan"]}], "target_citation_location": 31, "citation_locations": [31, 33], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "f9f4ea46-0ffe-4b4e-9bfe-e514b146bc86", "citing_paper": {"title": "Interpretable Entity Representations through Large-Scale Typing", "year": 2020, "authors": ["Yasumasa Onoe", "Greg Durrett"]}, "text": ["Coreference", "Arc", "Prediction", "(CAP)", "We", "use", "the", "English", "CAP", "dataset", "derived", "from", "PreCo", "(Chen et al., 2018)", "by", "Chen et al. (2019).", "The", "creators", "of", "the", "dataset", "partition", "the", "data", "by", "cosine", "similarity", "of", "GloVe", "(Pennington et al., 2014)", "embeddings", "of", "mention", "spans", "and", "balance", "the", "number", "of", "positive", "and", "negative", "examples", "in", "each", "bucket,", "so", "that", "models", "do", "not", "solve", "the", "task", "by", "capturing", "surface", "features", "of", "entity", "mention", "spans.", "The", "original", "data", "split", "provides", "8k", "examples", "for", "each", "of", "the", "training,", "development,", "and", "test", "sets."], "cited_papers": [{"title": "PreCo: A large-scale dataset in preschool vocabulary for coreference resolution", "year": "2018", "authors": ["Hong Chen", "Zhenhua Fan", "Hao Lu", "Alan Yuille", "Shu Rong"]}], "target_citation_location": 13, "citation_locations": [13, 15, 29], "citation_type": "single", "annotations": [[0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "fb535e52-d4db-4986-aae1-005ad71f8346", "citing_paper": {"title": "Situated Dialogue Learning through Procedural Environment Generation", "year": 2022, "authors": ["Prithviraj Ammanabrolu", "Renee Jia", "Mark Riedl", "Sanmit Narvekar", "Bei Peng", "Matteo Leonetti", "Jivko Sinapov", "Matthew Taylor", "Peter Stone", "Olivier Pietquin", "Matthieu Geist", "Senthilkumar Chan", "Shrimai Prabhumoye", "Margaret Li", "Jack Urbanek", "Sebastien Racaniere", "Andrew Lampinen", "Adam Santoro", "David Reichert", "Vlad Firoiu", "Tim- Othy Lillicrap", "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Mikayel Samvelyan", "Robert Kirk", "Vitaly Kurin", "Jack Parker-Holder", "Minqi Jiang", "Eric Hambro", "Fabio Petroni", "Heinrich Kuttler", "Edward Grefenstette", "Tim Rockt\u00e4schel", "unk Minihack", "Satinder Singh", "Michael Kearns", "Diane Litman", "Marilyn Walker", "unk Reinforcement", "Sainbayar Sukhbaatar", "Zeming Lin", "Ilya Kostrikov", "Gabriel Synnaeve", "Angela Fan", "Siddharth Karamcheti", "Saachi Jain", "Samuel Humeau", "Douwe Kiela", "Arthur Szlam", "Yinfei Yang", "Steve Yuan", "Daniel Cer", "Sheng-Yi Kong", "Noah Constant", "Petr Pilar", "Heming Ge"]}, "text": ["In", "sequential", "decision", "making", "problems", "in", "particular,", "this", "generalization", "gap", "is", "the", "result", "of", "an", "agent", "simply", "memorizing", "trajectories,", "e.g.", "the", "sequence", "of", "actions", "and", "dialogues", "required", "to", "finish", "a", "game,", "and", "thus", "being", "unable", "to", "react", "in", "novel", "scenarios-i.e.", "the", "agent", "learns", "from", "the", "head", "the", "training", "data", "and", "simply", "memorizes", "the", "long", "tail.", "One", "way", "of", "decreasing", "this", "generalization", "gap", "is", "by", "training", "agents", "on", "procedurally", "generated", "environments-wherein", "the", "agent", "learns", "a", "family", "of", "parametrized", "tasks", "with", "a", "significantly", "larger", "state-action", "spaces", "than", "singular", "environments,", "thus", "effectively", "making", "the", "memorization", "of", "trajectories", "impossible", "(Justesen et al., 2018, Cobbe et al., 2020).", "Drawing", "inspiration", "from", "all", "of", "these", "ideas,", "we", "create", "a", "method", "that", "learns", "to", "create", "a", "training", "curriculum", "of", "increasingly", "more", "difficult", "novel", "procedurally", "generated", "environments."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Leveraging procedural generation to benchmark reinforcement learning", "year": "2020", "authors": ["Karl Cobbe", "Chris Hesse", "Jacob Hilton", "John Schulman"]}], "target_citation_location": 95, "citation_locations": [95], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "fb63048b-1992-45a5-8c25-83ea3ab5ca77", "citing_paper": {"title": "Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability", "year": 2021, "authors": ["Pushkar Mishra", "Helen Yannakoudakis", "Ekaterina Shutova"]}, "text": ["Homophily,", "i.e.,", "the", "tendency", "of", "users", "in", "a", "social", "space", "forge", "ties", "with", "others", "who", "are", "similar", "to", "them", "in", "socially", "significant", "ways", "(McPherson et al., 2001)."], "cited_papers": [{"title": "Birds of a feather: Homophily in social networks", "year": "2001", "authors": ["Miller Mcpherson", "Lynn Smith-Lovin", "James M Cook"]}], "target_citation_location": 23, "citation_locations": [23], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
{"id": "fb7abf79-4193-40b1-837f-faf336334e97", "citing_paper": {"title": "NEW TABULAR ALGORITHMS FOR LIG PARSING", "year": 2000, "authors": ["Mi G Uel Alonso Jor G E Grana", "Manuel Vilares"]}, "text": ["To", "avoid", "the", "use", "of", "additional", "data", "structures,", "such", "as", "finite", "automata", "or", "precomputed", "relations,", "we", "have", "been", "inspired", "by", "the", "use", "of", "context-free", "grammars", "to", "represent", "the", "parse", "forest", "of", "tree", "adjoining", "grammars", "[18]", "in", "order", "to", "capture", "the", "context-freeness", "of", "production", "application", "in", "the", "case", "of", "LIG."], "cited_papers": [{"title": "The use of shared forest in tree adjoining grammar parsing", "year": "1993", "authors": ["K Vijay-Shanker", "D Weir"]}], "target_citation_location": 34, "citation_locations": [34], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "fb89456d-b72b-4869-ab47-787138efce3b", "citing_paper": {"title": "BRIO: Bringing Order to Abstractive Summarization", "year": 2022, "authors": ["Yixin Liu", "Pengfei Liu", "Dragomir Radev", "Graham Neubig"]}, "text": ["Training", "Methods", "of", "Seq2Seq", "Models", "In", "order", "to", "align", "the", "training", "objective", "and", "evaluation", "metric,", "structured", "losses", "have", "been", "used", "for", "the", "Seq2Seq", "model", "training.", "Among", "them,", "marginbased", "losses", "(Herbrich et al., 1999, Taskar et al., 2004, Gimpel and Smith, 2010),", "which", "require", "the", "model", "to", "assign", "higher", "probability", "to", "the", "better", "output,", "are", "a", "major", "category.", "Many", "margin-based", "losses", "used", "in", "modern", "seq2seq", "models", "(Wiseman and Rush, 2016, Edunov et al., 2018)", "assume", "a", "deterministic", "(one-point)", "distribution:", "a", "model", "can", "achieve", "zero", "loss", "if", "it", "can", "assign", "a", "much", "higher", "probability", "to", "the", "(pseudo)-reference,", "regardless", "of", "relative", "comparisons", "of", "other", "candidate", "summaries.", "By", "contrast,", "our", "method", "has", "a", "non-deterministic", "assumption", "(Eq.", "7),", "which", "focuses", "on", "the", "pair-wise", "ranking", "of", "a", "set", "of", "candidate", "summaries."], "cited_papers": [{"title": "Classical structured prediction losses for sequence to sequence learning", "year": "2018", "authors": ["Sergey Edunov", "Myle Ott", "Michael Auli", "David Grangier", "Marc'aurelio Ranzato"]}, {"title": "Sequence-to-sequence learning as beam-search optimization", "year": "2016", "authors": ["Sam Wiseman", "Alexander Rush"]}], "target_citation_location": 54, "citation_locations": [29, 54], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "fbd1fc3f-52f2-445d-88ad-09b62369efef", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["All", "the", "collected", "data", "were", "originally", "posted", "in", "the", "period", "of", "March", "-June", "2020.", "During", "this", "time,", "Vietnam", "was", "facing", "a", "second", "wave", "of", "Covid-19", "with", "a", "drastic", "increase", "from", "20", "to", "355", "cases", "(WHO, 2020).", "The", "spread", "of", "Covid-19", "results", "in", "an", "'infodemic'", "in", "which", "misleading", "information", "is", "disseminated", "rapidly", "especially", "on", "social", "media", "(Hou et al., 2020, Huynh et al., 2020).", "Hence,", "this", "period", "is", "a", "potential", "source", "of", "fake", "news.", "Besides", "Covid-19,", "the", "items", "in", "our", "dataset", "cover", "a", "wide", "range", "of", "domains", "including", "entertainment,", "sport,", "finance", "and", "healthcare.", "The", "result", "of", "the", "data", "collection", "stage", "is", "10,007", "items", "that", "are", "prepared", "for", "the", "annotation", "process."], "cited_papers": [{"title": "The covid-19 risk perception: A survey on socioeconomics and media attention", "year": "2020", "authors": ["Toan Luu Huynh"]}, {"title": "Assessment of public attention, risk perception, emotional and behavioural responses to the covid-19 outbreak: social media surveillance in china. Risk Perception, Emotional and Behavioural Responses to the COVID-19 Outbreak: Social Media", "year": "2020", "authors": ["Zhiyuan Hou", "Fanxing Du", "Hao Jiang", "Xinyu Zhou", "Leesa Lin"]}], "target_citation_location": 54, "citation_locations": [34, 54], "citation_type": "group", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "fc71c5ec-81ec-4676-b68b-8230221c48a3", "citing_paper": {"title": "Factored Neural Machine Translation Architectures", "year": 2016, "authors": ["Mercedes Garc\u00eda-Mart\u00ednez", "Lo\u00efc Barrault", "Fethi Bougares"]}, "text": ["The", "encoder-decoder", "architecture,", "used", "for", "NMT,", "consists", "of", "two", "recurrent", "neural", "networks", "(RNN),", "one", "for", "the", "encoder", "and", "the", "other", "for", "the", "decoder.", "The", "encoder", "maps", "a", "source", "sequence", "into", "a", "sequence", "of", "continuous", "space", "vectors", "and", "the", "decoder", "maps", "this", "representation", "back", "to", "a", "target", "sequence.", "Our", "trained", "neural", "translation", "models", "are", "based", "on", "an", "encoder-decoder", "deep", "neural", "network,", "equipped", "with", "an", "attention", "mechanism", "[1],", "as", "described", "in", "Figure", "2.", "This", "architecture", "consists", "of", "a", "bidirectional", "RNN", "encoder", "(as", "seen", "in", "stage", "1", "of", "Figure", "2).", "An", "input", "sentence", "is", "encoded", "in", "a", "sequence", "of", "annotations", "(one", "for", "each", "input", "word),", "corresponding", "to", "the", "concatenation", "of", "the", "outputs", "of", "a", "forward", "and", "a", "backward", "RNN.", "Each", "annotation", "represents", "the", "full", "sentence", "with", "a", "strong", "focus", "on", "the", "current", "word.", "The", "decoder", "is", "composed", "of", "a", "conditional", "RNN", "as", "provided", "for", "the", "DL4MT", "winter", "school", "1", "(see", "stage", "3", "of", "Figure", "2),", "equipped", "with", "an", "attention", "mechanism", "(stage", "2).", "The", "attention", "mechanism", "aims", "at", "providing", "weights", "for", "each", "annotation", "in", "order", "to", "generate", "a", "context", "vector", "(by", "performing", "a", "weighted", "sum", "over", "the", "annotations).", "The", "attention", "mechanism", "uses", "the", "hidden", "state", "at", "timestep", "j", "of", "the", "decoder", "RNN", "along", "with", "the", "annotation", "h", "i", "to", "generate", "a", "coefficient", "e", "ij.", "A", "softmax", "operation", "is", "performed", "over", "those", "coefficients", "to", "generate", "the", "annotation", "weights", "\u03b1", "ij.", "As", "described", "in", "[1],", "the", "annotation", "weights", "can", "be", "used", "to", "align", "the", "input", "words", "to", "the", "output", "words.", "The", "RNN", "takes", "as", "input", "the", "context", "vector,", "the", "embedding", "of", "the", "previous", "output", "word", "(stage", "4", "of", "Figure", "2),", "and", "of", "course,", "its", "hidden", "state.", "Finally,", "on", "stage", "5", "of", "the", "Figure", "2,", "the", "output", "probabilities", "of", "the", "target", "vocabulary", "are", "computed.", "The", "word", "with", "the", "highest", "probability", "is", "selected", "to", "be", "the", "translation", "output", "at", "each", "timestep.", "The", "encoder", "and", "the", "decoder", "are", "trained", "jointly", "to", "maximize", "the", "conditional", "probability", "of", "the", "correct", "translation."], "cited_papers": [{"title": "Neural machine translation by jointly learning to align and translate", "year": "2014", "authors": ["D Bahdanau", "K Cho", "Y Bengio"]}], "target_citation_location": 65, "citation_locations": [65, 228], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "fc751059-495e-4b8c-8b15-0743718bd138", "citing_paper": {"title": "TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration", "year": 2021, "authors": ["Mokanarangan Thayaparan", "Marco Valentino", "Peter Jansen", "Dmitry Ustalov"]}, "text": ["Semantic", "Drift.", "Multi-hop", "question", "answering", "systems", "suffer", "from", "the", "tendency", "of", "composing", "out-of-context", "inference", "chains", "as", "the", "number", "of", "required", "hops", "(aggregated", "facts)", "increases.", "This", "phenomenon,", "known", "as", "semantic", "drift,", "has", "been", "observed", "in", "a", "number", "of", "works", "(Fried et al., 2015, Jansen, 2017),", "which", "have", "empirically", "demonstrated", "that", "multi-hop", "inference", "models", "exhibit", "a", "substantial", "drop", "in", "performance", "when", "aggregating", "more", "than", "2", "facts", "or", "paragraphs.", "Semantic", "drift", "has", "been", "observed", "across", "a", "variety", "of", "representations", "and", "traversal", "methods,", "including", "word", "and", "dependency", "level", "(Pan et al., 2017, Fried et al., 2015),", "sentence", "level", "(Jansen et al., 2017),", "and", "paragraph", "level", "(Clark and Gardner, 2018).", "Khashabi et al. (2019)", "have", "demonstrated", "that", "ongoing", "efforts", "on", "\"very", "long\"", "multi-hop", "reasoning", "are", "unlikely", "to", "succeed", "without", "the", "adoption", "of", "a", "richer", "underlying", "representation", "that", "allows", "for", "reasoning", "with", "fewer", "hops."], "cited_papers": [{"title": "Simple and Effective Multi-Paragraph Reading Comprehension", "year": "2018", "authors": ["Christopher Clark", "Matt Gardner"]}], "target_citation_location": 86, "citation_locations": [38, 79, 82, 86, 87], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "fc96b33b-04c3-4529-a68d-b44daed0300c", "citing_paper": {"title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering", "year": 2021, "authors": ["Yingqi Qu", "Yuchen Ding", "Jing Liu", "Kai Liu", "Ruiyang Ren", "Wayne Zhao", "Daxiang Dong", "Hua Wu", "Haifeng Wang"]}, "text": ["We", "conduct", "the", "experiments", "on", "two", "popular", "QA", "benchmarks:", "MSMARCO", "Passage", "Ranking", "(Nguyen et al., 2016)", "and", "Natural", "Questions", "(NQ)", "(Kwiatkowski et al., 2019).", "The", "statistics", "of", "the", "datasets", "are", "listed", "in", "Table", "1.", "MSMARCO", "Passage", "Ranking", "MSMARCO", "is", "originally", "designed", "for", "multiple", "passage", "MRC,", "and", "its", "questions", "were", "sampled", "from", "Bing", "search", "logs.", "Based", "on", "the", "questions", "and", "passages", "in", "MS-MARCO", "Question", "Answering,", "a", "dataset", "for", "passage", "ranking", "was", "created,", "namely", "MSMARCO", "Passage", "Ranking,", "consisting", "of", "about", "8.8", "million", "passages.", "The", "goal", "is", "to", "find", "positive", "passages", "that", "answer", "the", "questions."], "cited_papers": [{"title": "MS MARCO: A human generated machine reading comprehension dataset", "year": "2016", "authors": ["Tri Nguyen", "Mir Rosenberg", "Xia Song", "Jianfeng Gao", "Saurabh Tiwary", "Rangan Majumder", "Li Deng"]}], "target_citation_location": 12, "citation_locations": [12, 17], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "fcd4b288-f863-407e-bac2-453847791966", "citing_paper": {"title": "Control Image Captioning Spatially and Temporally", "year": 2021, "authors": ["Kun Yan", "Ji Lei", "Huaishao Luo", "Ming Zhou", "Nan Duan", "Shuai Ma"]}, "text": ["Most", "previous", "attempts", "aim", "to", "describe", "the", "image", "indicating", "the", "salient", "objects", "and", "relations", "without", "considering", "user", "intention.", "To", "generate", "controllable", "and", "explainable", "captions,", "recent", "works", "dedicated", "to", "establishing", "a", "new", "controllable", "image", "captioning", "task", "to", "generate", "the", "caption", "at", "will.", "The", "captioning", "process", "can", "be", "controlled", "by", "POS", "tagging", "(Deshpande et al., 2018),", "sentiment", "(You et al., 2018),", "length", "(Deng et al., 2020),", "bounding", "boxes", "(Cornia et al., 2019),", "and", "mouse", "traces", "(Pont-Tuset et al., 2020)."], "cited_papers": [{"title": "Image captioning at will: A versatile scheme for effectively injecting sentiments into image descriptions", "year": "2018", "authors": ["Quanzeng You", "Jin Hailin", "Jiebo Luo"]}], "target_citation_location": 52, "citation_locations": [50, 52, 54, 57, 61], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]]}
{"id": "fcf16339-bf4f-455b-b1f3-98fe9fe1c09f", "citing_paper": {"title": "On the Usability of Transformers-based models for a French Question-Answering task", "year": 2021, "authors": ["Oralie Cattan", "Christophe Servan", "Sophie Rosset"]}, "text": ["Transformer-based", "language", "models", "such", "as", "BERT", "(Devlin et al., 2019)", "are", "pre-trained", "on", "largescale", "data", "collections", "sourced", "from", "Wikipedia", "or", "Common", "Crawl", "(CC)", "with", "one", "or", "multiple", "training", "objectives", "(masked", "language", "modeling,", "next", "sentence", "or", "sentence", "order", "prediction).", "This", "pretraining", "can", "be", "followed", "by", "supervised", "fine-tuning", "according", "to", "the", "tasks,", "whether", "generatives", "(machine", "translation,", "abstractive", "summarization)", "or", "discriminatives", "(classification,", "question-answering).", "The", "ensuing", "fine-tuning", "phase", "allows", "for", "better", "initialization", "of", "the", "models", "parameters", "while", "requiring", "less", "task-specific", "data", "so", "as", "to", "make", "the", "training", "of", "subsequent", "tasks", "faster."], "cited_papers": [{"title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "year": "2019", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]}], "target_citation_location": 6, "citation_locations": [6], "citation_type": "single", "annotations": [[3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "fd501c3f-97d1-4aed-a124-6dd00f87ba16", "citing_paper": {"title": "Generalizable and Explainable Dialogue Generation via Explicit Action Learning", "year": 2020, "authors": ["Xinting Huang", "Jianzhong Qi", "Yu Sun", "Rui Zhang"]}, "text": ["Obtaining", "salient", "words", "by", "applying", "existing", "saliency", "identification", "approaches", "(Ribeiro et al., 2018)", "is,", "however,", "unable", "to", "produce", "unified", "action", "representations.", "Specifically,", "system", "utterances", "with", "the", "same", "intention", "might", "not", "share", "similar", "wordings,", "and", "existing", "attribution", "approaches", "can", "only", "identify", "salient", "words", "within", "utterances.", "We", "tackle", "this", "challenge", "by", "proposing", "a", "memoryaugmented", "saliency", "approach", "that", "identifies", "salient", "words", "from", "a", "broader", "vocabulary.", "The", "vocabulary", "consists", "of", "all", "the", "words", "that", "could", "compose", "natural", "language", "actions,", "1", "and", "each", "word", "is", "stored", "as", "a", "slot", "in", "the", "memory", "component.", "By", "incorporating", "the", "memory", "component", "into", "a", "dialogue", "state", "tracking", "model,", "we", "use", "each", "system", "utterance", "as", "a", "query", "to", "perform", "memory", "retrieval,", "and", "the", "retrieval", "results", "are", "considered", "as", "salient", "words.", "The", "retrieval", "results", "might", "contain", "words", "that", "are", "redundant", "since", "we", "do", "not", "have", "direct", "supervision", "for", "the", "retrieval", "operations.", "For", "example,", "the", "resulting", "salient", "words", "might", "be", "\"but", "turn", "bland\"", "in", "the", "example", "shown", "earlier,", "which", "include", "unnecessary", "words", "and", "may", "lead", "to", "degenerated", "action", "results.", "To", "obtain", "compact", "action", "representations,", "we", "propose", "an", "auxiliary", "task", "based", "on", "pseudo", "parallel", "corpus,", "i.e.,", "dialogue", "context", "and", "state", "annotation", "pairs.", "We", "observe", "that", "dialogue", "states", "serve", "as", "good", "examples", "of", "how", "compact", "representation", "should", "be.", "Therefore,", "we", "use", "the", "encoded", "dialogue", "context", "as", "query", "and", "ask", "the", "memory", "component", "to", "reconstruct", "its", "text-based", "dialogue", "states.", "In", "this", "way,", "the", "obtained", "concise", "actions", "generalize", "better", "and", "can", "be", "easily", "interpreted."], "cited_papers": [{"title": "Anchors: High-precision modelagnostic explanations", "year": "2018", "authors": ["Sameer Marco Tulio Ribeiro", "Carlos Singh", "unk Guestrin"]}], "target_citation_location": 9, "citation_locations": [9], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "fdc151e0-68dd-48f4-97a6-4d35585f56e6", "citing_paper": {"title": "Codenames as a Game of Co-occurrence Counting", "year": 2022, "authors": ["R\u00e9ka Cserh\u00e1ti", "Istv\u00e1n Koll\u00e1th", "Andr\u00e1s Kicsi", "G\u00e1bor Berend"]}, "text": ["We", "also", "introduced", "innovations", "in", "terms", "of", "scoring", "functions,", "firstly", "by", "refining", "the", "scoring", "function", "of", "Koyyalagunta et al. (2021),", "and", "secondly", "by", "using", "the", "harmonic", "mean", "of", "the", "relatedness", "to", "the", "clue", "word.", "This", "improved", "the", "performance", "of", "the", "best", "agents", "substantially."], "cited_papers": [{"title": "Playing codenames with language graphs and word embeddings", "year": "2021", "authors": ["Divya Koyyalagunta", "Anna Sun", "Rachel Draelos", "Cynthia Rudin"]}], "target_citation_location": 16, "citation_locations": [16], "citation_type": "single", "annotations": [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2]]}
{"id": "fe0b0157-b696-414c-9194-c546f6bb253b", "citing_paper": {"title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation", "year": 2021, "authors": ["Hansi Hettiarachchi", "Tharindu Ranasinghe"]}, "text": ["As", "future", "work,", "we", "would", "be", "looking", "to", "improve", "our", "results", "more", "with", "new", "strategies.", "We", "would", "like", "to", "experiment", "with", "whether", "adding", "languagespecific", "processing", "and", "resources", "would", "improve", "the", "results.", "We", "are", "keen", "to", "add", "different", "neural", "network", "architectures", "like", "Siamese", "transformer", "networks", "(Reimers and Gurevych, 2019)", "that", "perform", "well", "in", "sentence", "pair", "classification", "tasks", "(Ranasinghe et al., 2019b, Mueller and Thyagarajan, 2016)", "to", "the", "TransWiC", "framework.", "Furthermore,", "we", "are", "hoping", "to", "work", "in", "a", "multi-task", "environment", "and", "experiment", "whether", "transfer", "learning", "from", "a", "similar", "task", "like", "semantic", "textual", "similarity", "(Cer et al., 2017)", "would", "improve", "the", "results", "for", "this", "task."], "cited_papers": [{"title": "Siamese recurrent architectures for learning sentence similarity. AAAI'16", "year": "2016", "authors": ["Jonas Mueller", "Aditya Thyagarajan"]}, {"title": "Semantic textual similarity with Siamese neural networks", "year": "2019", "authors": ["Tharindu Ranasinghe", "Constantin Orasan", "Ruslan Mitkov"]}], "target_citation_location": 53, "citation_locations": [44, 53, 81], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "feb46988-6785-4ae8-86c9-8bc66a6623c5", "citing_paper": {"title": "Memory-efficient Transformers via Top-k Attention", "year": 2021, "authors": ["Ankit Gupta", "Guy Dar", "Shaya Goodman", "David Ciprut", "Jonathan Berant", "Ibm Research"]}, "text": ["Taking", "inspiration", "from", "gradient", "checkpointing", "(Chen et al., 2016),", "we", "observe", "that", "if", "the", "inputs", "Q", "C,", "K,", "V", "are", "available", "during", "the", "backward", "pass,", "we", "can", "re-compute", "o", "C", "and", "then", "use", "the", "produced", "intermediate", "activations", "to", "computed", "(Q", "C)", "from", "d", "(o", "C", ").", "Once", "d", "(Q", "C)", "is", "computed,", "we", "can", "again", "discard", "the", "intermediate", "activations", "and", "gradients", "produced", "during", "this", "step", "and", "move", "on", "to", "the", "next", "chunk.", "This", "ensures", "that", "the", "peak", "memory", "usage", "during", "the", "backward", "pass", "through", "the", "attention", "layer", "is", "bounded", "by", "the", "memory", "required", "to", "backpropagate", "through", "a", "single", "chunk."], "cited_papers": [{"title": "Training deep nets with sublinear memory cost", "year": "2016", "authors": ["T Chen", "B Xu", "C Zhang", "Carlos Guestrin"]}], "target_citation_location": 5, "citation_locations": [5], "citation_type": "single", "annotations": [[2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "fefb3024-cbe0-4d1e-97b3-ba94c58bea03", "citing_paper": {"title": "Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking", "year": 2021, "authors": ["Yue Zhang", "Chengcheng Hu", "Yuqi Liu", "Hui Fang", "Jimmy Lin"]}, "text": ["For", "the", "final-stage", "neural", "reranker,", "we", "experiment", "with", "BERT-large", "and", "T5-base", "in", "the", "PyGaggle", "library", "fine-tuned", "on", "the", "MS", "MARCO", "passage", "data.", "4", "We", "simply", "use", "checkpoints", "provided", "by", "the", "library,", "as", "our", "work", "is", "not", "specifically", "focused", "on", "final-stage", "neural", "reranking.", "Previous", "evaluations", "(Nogueira and Cho, 2019, Nogueira et al., 2020, Pradeep et al., 2021)", "have", "already", "verified", "that", "these", "two", "models", "serve", "as", "competitive", "baselines.", "We", "pad", "all", "the", "token", "sequences", "in", "the", "batch", "to", "have", "the", "same", "length", "and", "truncate", "them", "if", "their", "lengths", "exceed", "512", "tokens."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": null, "year": "2019", "authors": ["Rodrigo Nogueira", "Kyunghyun Cho"]}], "target_citation_location": 44, "citation_locations": [44], "citation_type": "group", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ff0e76c1-ea64-4737-88db-16b26fe3017f", "citing_paper": {"title": "ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites", "year": 2020, "authors": ["Duc-Trong Le", "Xuan-Son Vu", "Nhu-Dung To", "Huu-Quang Nguyen", "Thuy-Trinh Nguyen", "Linh Le", "Anh-Tuan Nguyen", "Minh-Duc Hoang", "Nghia Le", "Huyen Nguyen", "Hoang Nguyen"]}, "text": ["Trained", "on", "20GB", "texts", "of", "both", "Vietnamese", "news", "and", "Vietnamese", "Wikipedia", "Bert4News", "(Nha, 2020)", "x", "Trained", "on", "more", "than", "20GB", "texts", "of", "Vietnamese", "news", "vElectra", "and", "ViBERT", "(The et al., 2020)", "x", "vElectra", "was", "trained", "on", "10GB", "texts,", "whereas", "ViBERT", "was", "trained", "on", "60GB", "texts", "of", "Vietnamese", "news", "VGG16", "(Simonyan and Zisserman, 2015)", "x"], "cited_papers": [{"title": "Very deep convolutional networks for large-scale image recognition", "year": "2015", "authors": ["Karen Simonyan", "Andrew Zisserman"]}], "target_citation_location": 45, "citation_locations": [12, 26, 45], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1]]}
{"id": "ff7d6a09-4ff8-4d2a-a879-96d1e23381d2", "citing_paper": {"title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation", "year": 2022, "authors": ["Yongfei Liu", "Chenfei Wu", "Shao-Yen Tseng", "Vasudev Lal", "Xuming He", "Nan Duan"]}, "text": ["Pretraining", "Corpus:", "Following", "the", "E2E", "pretraining", "strategy", "(Huang et al., 2021 (Huang et al., , 2020,, Xu et al., 2021),", "we", "take", "indomain", "datasets:", "MSCOCO", "(Lin et al., 2014)", "and", "VG", "(Krishna et al., 2016)", "as", "pretraining", "datasets", "since", "it", "is", "widely", "used", "in", "literature.", "In", "total,", "two", "datasets", "comprise", "about", "200K", "images", "and", "5.6M", "image-text", "pairs,", "where", "each", "image", "is", "associated", "with", "multiple", "captions.", "VQA2.0", "R@1", "/", "R@5/", "R@10", "R@1", "/", "R@5", "/", "R@10", "val", "/", "test", "dev", "/", "test-p", "test-dev", "/", "-std", "two-step", "pretraining", "ViLBert", "(Lu et al.,", "MSCOCO-TR(5K)", "VCR", "R@1", "/", "R@5", "/", "R@10", "R@1", "/", "R@5", "/", "R@10", "R@1", "/", "R@5", "/", "R@10", "R@1", "/", "R@5", "/", "R@10", "Q\u2192A", "QA\u2192R", "Q\u2192AR", "two-step", "pretraining", "Unicoder-VL", "(Li et al., 2020a)", "Implementation", "Details:", "We", "follow", "BERT", "to", "tokenize", "caption", "into", "word", "tokens", "by", "using", "Word-Piece,", "and", "resize", "the", "image", "into", "(800,", "1333)", "as", "prior", "works.", "For", "model", "architecture,", "a", "widely-used", "ResNet101", "for", "visual", "encoding", "and", "12-layer", "Transformer", "for", "multi-modal", "fusion", "are", "adopted", "for", "a", "fair", "comparison.", "Both", "networks", "are", "initialized", "with", "Im-ageNet", "and", "BERT", "pretrained", "parameters.", "Besides,", "following", "the", "majority", "of", "two-step", "methods,", "we", "apply", "the", "widely-used", "object", "detector", "BUTD", "(Anderson et al., 2018)", "to", "generate", "object", "proposals", "as", "well", "as", "their", "RoI", "embeddings", "as", "our", "supervision."], "cited_papers": [{"title": null, "year": null, "authors": ["unknown"]}, {"title": "Pixel-bert: Aligning image pixels with text by deep multi-modal transformers", "year": "2020", "authors": ["Zhicheng Huang", "Zhaoyang Zeng", "Bei Liu", "Dongmei Fu", "Jianlong Fu"]}, {"title": "E2e-vlp: End-to-end vision-language pre-training enhanced by visual learning", "year": "2021", "authors": ["Haiyang Xu", "Ming Yan", "Chenliang Li", "Bin Bi", "Songfang Huang", "Wenming Xiao", "Fei Huang"]}], "target_citation_location": 7, "citation_locations": [7, 13, 16, 69, 98, 168], "citation_type": "group", "annotations": [[0, 0, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ff962ec5-2856-4848-a1d2-09919d4e49b3", "citing_paper": {"title": "Public Apologies in India -Semantics, Sentiment and Emotion", "year": 2018, "authors": ["Sangeeta Shukla", "Rajita Shukla"]}, "text": ["The", "nouns", "are", "organized", "as", "an", "inheritance", "system", "in", "WordNet", "(Fellbaum, 1998).", "Under", "this", "system", "there", "is", "a", "sequence", "of", "levels,", "a", "hierarchy,", "in", "which", "the", "lower", "levels", "inherit", "the", "features", "of", "the", "top", "levels,", "plus", "have", "at", "least", "one", "distinguishing", "feature.", "The", "two", "semantic", "relations", "of", "interest", "in", "the", "present", "study", "are", "hypernymy", "and", "hyponymy", "(Fellbaum, 1998).", "The", "selected", "sense", "of", "the", "noun", "apology", "has", "the", "gloss", "-an", "expression", "of", "regret", "at", "having", "caused", "trouble", "for", "someone.", "It", "has", "acknowledgement", "as", "its", "direct", "hypernymy,", "which", "is", "defined", "as", "a", "statement", "acknowledging", "something", "or", "someone.", "From", "the", "communicative", "perspective", "this", "acknowledgment", "is", "a", "precursor", "to", "the", "expectation", "of", "some", "sort", "of", "reparation", "or", "compensation", "on", "the", "part", "of", "the", "offended.", "In", "the", "corpus,", "the", "apology", "number", "7,", "has", "the", "sentence,", "We", "would", "like", "to", "tender", "an", "unconditional", "apology", "to", "the", "society", "at", "large", "and", "especially", "to", "the", "affected", "families", "and", "to", "everyone", "whom", "we", "have", "offended.", "This", "is", "an", "unequivocal", "expression", "of", "apology", "and", "shows", "that", "tenderers", "do", "not", "want", "to", "make", "any", "excuses", "for", "their", "wrongdoing.", "The", "gloss", "of", "selected", "sense", "of", "the", "noun", "regret", "is", "sadness", "associated", "with", "some", "wrong", "done", "or", "some", "disappointment.", "The", "direct", "hypernymy", "of", "this", "is", "the", "concept", "of", "sadness", "which", "is", "emotions", "experienced", "when", "not", "in", "a", "state", "of", "well-being.", "This", "is", "followed", "by", "the", "concept", "of", "feeling", "or", "the", "experiencing", "of", "affective", "and", "emotional", "states.", "Thus", "the", "hypernymy", "relation", "makes", "it", "clear", "that", "regret", "is", "a", "kind", "of", "feeling", "associated", "with", "sadness.", "From", "a", "communicative", "point", "of", "view,", "it", "is", "simply", "an", "expression", "of", "an", "emotion", "on", "the", "part", "of", "the", "tenderer", "of", "the", "apology", "and", "not", "necessarily", "expression", "of", "remorse", "or", "liability.", "For", "example,", "in", "apology", "number", "13,", "the", "Member", "of", "Parliament", "states,", "I", "write", "to", "convey", "my", "regrets", "for", "the", "unfortunate", "incident", "that", "took", "place", "on", "23rd", "March", "2017", "in", "the", "Air", "India", "flight", "No.", "AI", "852,", "seat", "No.1F.", "Given", "that", "the", "writer", "only", "uses", "the", "noun", "regret,", "it", "can", "be", "implied", "that", "the", "writer", "feels", "sad", "about", "the", "incident", "but", "not", "necessarily", "repentant.", "However,", "it", "is", "important", "to", "look", "at", "the", "results", "of", "SentiWordNet", "and", "WordNet-Affect", "to", "understand", "the", "implications", "and", "underlying", "emotions", "and", "sentiments", "before", "arriving", "at", "any", "further", "conclusions."], "cited_papers": [{"title": "WordNet: an electronic lexical database", "year": "1998", "authors": ["Christiane Fellbaum"]}], "target_citation_location": 10, "citation_locations": [10, 55], "citation_type": "single", "annotations": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}
{"id": "ffb43d18-fe53-40e7-9dcf-556f8356276c", "citing_paper": {"title": "The DCU Machine Translation Systems for IWSLT 2011", "year": 2011, "authors": ["Pratyush Banerjee", "Hala Almaghout", "Sudip Naskar", "Johann Roturier", "Jie Jiang", "Andy Way", "Josef Van Genabith"]}, "text": ["Arabic", "being", "a", "morphologically", "rich", "language,", "has", "many", "different", "surface", "forms", "of", "words", "with", "same", "root.", "This", "phenomenon", "poses", "a", "data", "sparsity", "problem", "for", "SMT", "systems.", "In", "order", "to", "reduce", "data", "sparsity,", "we", "segment", "the", "Arabic", "data", "morphologically", "before", "training.", "The", "Arabic", "data", "is", "segmented", "according", "to", "the", "D3", "segmentation", "scheme", "using", "MADA", "(Morphological", "Analysis", "and", "Disambiguation", "for", "Arabic).", "5", "For", "all", "the", "available", "Chinese", "data,", "we", "segment", "the", "sentences", "to", "words", "using", "the", "Stanford", "Chinese", "Word", "Segmenter", "[22].", "English", "data", "is", "lower-cased", "and", "tokenized", "in", "the", "preprocessing", "step."], "cited_papers": [{"title": "A conditional random field word segmenter", "year": "2005", "authors": ["H Tseng", "P Chang", "G Andrew", "D Jurafsky", "C Manning"]}], "target_citation_location": 78, "citation_locations": [78], "citation_type": "single", "annotations": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}

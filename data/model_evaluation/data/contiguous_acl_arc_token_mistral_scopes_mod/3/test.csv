token_context,word_context,seg_context,sent_cotext,label
"['', 'Fortunately , indirect associations are usually not difficult to identify , because they tend to be weaker than the direct associations on which they are based( #AUTHOR_TAG c ) .', 'The majority of indirect associations can be filtered out by a simple competition heuristic:']","['', 'Fortunately , indirect associations are usually not difficult to identify , because they tend to be weaker than the direct associations on which they are based( #AUTHOR_TAG c ) .', 'The majority of indirect associations can be filtered out by a simple competition heuristic:']","['', 'Fortunately , indirect associations are usually not difficult to identify , because they tend to be weaker than the direct associations on which they are based( #AUTHOR_TAG c ) .', 'The majority of indirect associations can be filtered out by a simple competition heuristic: Whenever several word tokens']","['', 'Fortunately , indirect associations are usually not difficult to identify , because they tend to be weaker than the direct associations on which they are based( #AUTHOR_TAG c ) .', '']",0
"['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( Brown et al. , 1988 ; #AUTHOR_TAG ; Brown et al. , 1993 a ) .', '']","['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( Brown et al. , 1988 ; #AUTHOR_TAG ; Brown et al. , 1993 a ) .', 'However, the']","['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( Brown et al. , 1988 ; #AUTHOR_TAG ; Brown et al. , 1993 a ) .', '']","['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( Brown et al. , 1988 ; #AUTHOR_TAG ; Brown et al. , 1993 a ) .', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', '']",0
"['.', ""Models of translational equivalence that are ignorant of indirect associations have `` a tendency ... to be confused by collocates ''( #AUTHOR_TAG ) ."", 'Fortunately, indirect']","['uk.', ""Models of translational equivalence that are ignorant of indirect associations have `` a tendency ... to be confused by collocates ''( #AUTHOR_TAG ) ."", 'Fortunately, indirect']","['.', ""Models of translational equivalence that are ignorant of indirect associations have `` a tendency ... to be confused by collocates ''( #AUTHOR_TAG ) ."", 'Fortunately, indirect associations are usually not difficult to identify']","['', ""Models of translational equivalence that are ignorant of indirect associations have `` a tendency ... to be confused by collocates ''( #AUTHOR_TAG ) ."", 'Fortunately, indirect associations are usually not difficult to identify, because they tend to be weaker than the direct associations on which they are based(Melamed, 1996 c).', '']",0
"[', certain machine-assisted translation tools (e.g.( #AUTHOR_TAG ; Melamed , 1996 b ) ), concordancing for bilingual']","[', certain machine-assisted translation tools (e.g.( #AUTHOR_TAG ; Melamed , 1996 b ) ), concordancing for bilingual lexicography(Catizone et al., 1993; Gale & Church, 1991) , computer- assisted language learning, corpus linguistics (Melby.']","[', certain machine-assisted translation tools (e.g.( #AUTHOR_TAG ; Melamed , 1996 b ) ), concordancing for bilingual lexicography(Catizone et al., 1993; Gale & Church, 1991) , computer- assisted language learning, corpus linguistics (M']","['( #AUTHOR_TAG ; Melamed , 1996']",0
"['', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be( #AUTHOR_TAG ; Wu & Xia , 1994 ; Chen , 1996 ) .', 'The likelihoods in the word-to-word model remain un']","['from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be( #AUTHOR_TAG ; Wu & Xia , 1994 ; Chen , 1996 ) .', 'The likelihoods in the word-to-word model remain unnormalized, so they do not compete']","['from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be( #AUTHOR_TAG ; Wu & Xia , 1994 ; Chen , 1996 ) .', 'The likelihoods in the word-to-word model remain un']","['some have tried, it is not clear how to extract such accurate lexicons from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be( #AUTHOR_TAG ; Wu & Xia , 1994 ; Chen , 1996 ) .', 'The likelihoods in the word-to-word model remain unnormalized, so they do not compete']",0
"[', certain machine-assisted translation tools (e.g.(Macklovitch, 1994; Melamed, 1996 b)), concordancing for bilingual lexicography(Catizone et al., 1993; #AUTHOR_TAG ) , computer- assisted language learning, corpus linguistics (Melby. 1981), and cross-lingual information retrieval (Oard &Dorr, 1996)']","[', certain machine-assisted translation tools (e.g.(Macklovitch, 1994; Melamed, 1996 b)), concordancing for bilingual lexicography(Catizone et al., 1993; #AUTHOR_TAG ) , computer- assisted language learning, corpus linguistics (Melby. 1981), and cross-lingual information retrieval (Oard &Dorr, 1996)']","[', certain machine-assisted translation tools (e.g.(Macklovitch, 1994; Melamed, 1996 b)), concordancing for bilingual lexicography(Catizone et al., 1993; #AUTHOR_TAG ) , computer- assisted language learning, corpus linguistics (Melby. 1981), and cross-lingual information retrieval (Oard &Dorr, 1996)']","['the past decade, researchers at IBM have devel- oped a series of increasingly sophisticated statistical models for machine translation(Brown et al., 1988; Brown et al., 1990; Brown et al., 1993 a).', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply.', 'Table look-up using an ex- plicit translation lexicon is sufficient and preferable for many multilingual NLP applications, including ""crummy"" MT on the World Wide Web (Church & I-Iovy, 1993) , certain machine-assisted translation tools (e.g.(Macklovitch, 1994; Melamed, 1996 b)), concordancing for bilingual lexicography(Catizone et al., 1993; #AUTHOR_TAG ) , computer- assisted language learning, corpus linguistics (Melby. 1981), and cross-lingual information retrieval (Oard &Dorr, 1996)']",0
"[', certain machine-assisted translation tools (e.g.(Macklovitch, 1994; #AUTHOR_TAG b )), concordancing for bilingual']","[', certain machine-assisted translation tools (e.g.(Macklovitch, 1994; #AUTHOR_TAG b )), concordancing for bilingual lexicography(Catizone et al., 1993; Gale & Church , 1991 ) , computer- assisted']","[', certain machine-assisted translation tools (e.g.(Macklovitch, 1994; #AUTHOR_TAG b )), concordancing for bilingual lexicography(Catizone et al., 1993; Gale & Church , 1991 ) , computer- assisted language learning, corpus linguistics']","['(Macklovitch, 1994; #AUTHOR_TAG']",0
"['2We could just as easily use other symmetric ""association"" measures, such as 02( Gale & Church , 1991 ) or the Dice coefficient( #AUTHOR_TAG ) .', '']","['2We could just as easily use other symmetric ""association"" measures, such as 02( Gale & Church , 1991 ) or the Dice coefficient( #AUTHOR_TAG ) .', '']","['2We could just as easily use other symmetric ""association"" measures, such as 02( Gale & Church , 1991 ) or the Dice coefficient( #AUTHOR_TAG ) .', '']","['2We could just as easily use other symmetric ""association"" measures, such as 02( Gale & Church , 1991 ) or the Dice coefficient( #AUTHOR_TAG ) .', '']",1
"['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( #AUTHOR_TAG ; Brown et al. , 1990 ; Brown et al. , 1993 a ) .', '']","['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( #AUTHOR_TAG ; Brown et al. , 1990 ; Brown et al. , 1993 a ) .', 'However, the']","['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( #AUTHOR_TAG ; Brown et al. , 1990 ; Brown et al. , 1993 a ) .', '']","['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( #AUTHOR_TAG ; Brown et al. , 1990 ; Brown et al. , 1993 a ) .', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', '']",0
"['', 'The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each other( Gale & Church , 1991 ; #AUTHOR_TAG a ) .', '']","['', 'The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each other( Gale & Church , 1991 ; #AUTHOR_TAG a ) .', '']","['', 'The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each other( Gale & Church , 1991 ; #AUTHOR_TAG a ) .', '']","['', 'The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each other( Gale & Church , 1991 ; #AUTHOR_TAG a ) .', '']",0
"['induced a two-class word-to-word model of translational equivalence from 13 million words of the Canadian Hansards , aligned using the method in( #AUTHOR_TAG )']","['induced a two-class word-to-word model of translational equivalence from 13 million words of the Canadian Hansards , aligned using the method in( #AUTHOR_TAG )']","['induced a two-class word-to-word model of translational equivalence from 13 million words of the Canadian Hansards , aligned using the method in( #AUTHOR_TAG )']","['induced a two-class word-to-word model of translational equivalence from 13 million words of the Canadian Hansards , aligned using the method in( #AUTHOR_TAG )']",5
"[') < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( Brown et al. , 1990 ; #AUTHOR_TAG ; Chen , 1996 ) .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( Brown et al. , 1990 ; #AUTHOR_TAG ; Chen , 1996 ) .', '']","[') < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( Brown et al. , 1990 ; #AUTHOR_TAG ; Chen , 1996 ) .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( Brown et al. , 1990 ; #AUTHOR_TAG ; Chen , 1996 ) .', '']",0
"['model was also used to induce a translation lexicon from a 6200-word corpus of French/English weather reports.', '#AUTHOR_TAG reported that the translation lexicon that our model induced from this tiny bitext accounted for 30 % of the word types with precision between 84 % and 90 % .', 'Recall drops when there is tess training data, because the model refuses to make predictions that it cannot make with']","['model was also used to induce a translation lexicon from a 6200-word corpus of French/English weather reports.', '#AUTHOR_TAG reported that the translation lexicon that our model induced from this tiny bitext accounted for 30 % of the word types with precision between 84 % and 90 % .', 'Recall drops when there is tess training data, because the model refuses to make predictions that it cannot make with confidence.', '']","['model was also used to induce a translation lexicon from a 6200-word corpus of French/English weather reports.', '#AUTHOR_TAG reported that the translation lexicon that our model induced from this tiny bitext accounted for 30 % of the word types with precision between 84 % and 90 % .', 'Recall drops when there is tess training data, because the model refuses to make predictions that it cannot make with']","['model was also used to induce a translation lexicon from a 6200-word corpus of French/English weather reports.', '#AUTHOR_TAG reported that the translation lexicon that our model induced from this tiny bitext accounted for 30 % of the word types with precision between 84 % and 90 % .', 'Recall drops when there is tess training data, because the model refuses to make predictions that it cannot make with confidence.', '']",0
"['-occurrence With the exception of(Fung, 1998 b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts( #AUTHOR_TAG ; Kumano & Hirakawa, 1994;Fung, 1998 a;Melamed, 1995) .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in']","['-occurrence With the exception of(Fung, 1998 b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts( #AUTHOR_TAG ; Kumano & Hirakawa, 1994;Fung, 1998 a;Melamed, 1995) .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in']","['-occurrence With the exception of(Fung, 1998 b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts( #AUTHOR_TAG ; Kumano & Hirakawa, 1994;Fung, 1998 a;Melamed, 1995) .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in']","['-occurrence With the exception of(Fung, 1998 b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts( #AUTHOR_TAG ; Kumano & Hirakawa, 1994;Fung, 1998 a;Melamed, 1995) .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in various ways.', 'The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each otherMelamed, 1996 a).', '']",0
"['Wide Web( Church & Hovy , 1993 ) , certain machine-assisted translation tools ( e.g.( Macklovitch , 1994 ; Melamed , 1996 b ) ) , concordancing for bilingual lexicography( #AUTHOR_TAG ; Gale & Church , 1991 ) , computerassisted language learning , corpus linguistics ( Melby']","['Wide Web( Church & Hovy , 1993 ) , certain machine-assisted translation tools ( e.g.( Macklovitch , 1994 ; Melamed , 1996 b ) ) , concordancing for bilingual lexicography( #AUTHOR_TAG ; Gale & Church , 1991 ) , computerassisted language learning , corpus linguistics ( Melby']","['including ""crummy"" MT on the World Wide Web( Church & Hovy , 1993 ) , certain machine-assisted translation tools ( e.g.( Macklovitch , 1994 ; Melamed , 1996 b ) ) , concordancing for bilingual lexicography( #AUTHOR_TAG ; Gale & Church , 1991 ) , computerassisted language learning , corpus linguistics ( Melby . 1981), and cross-lingual information retrieval (Oard &Dorr, 1996)']","['the past decade, researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation(Brown et al., 1988; Brown et al., 1990; Brown et al., 1993 a).', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', 'Table look-up using an explicit translation lexicon is sufficient and preferable for many multilingual NLP applications , including ""crummy"" MT on the World Wide Web( Church & Hovy , 1993 ) , certain machine-assisted translation tools ( e.g.( Macklovitch , 1994 ; Melamed , 1996 b ) ) , concordancing for bilingual lexicography( #AUTHOR_TAG ; Gale & Church , 1991 ) , computerassisted language learning , corpus linguistics ( Melby . 1981), and cross-lingual information retrieval (Oard &Dorr, 1996)']",0
"['better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech, frequency of co-occurrence, relative word position, and translational entropy .', ""Another interesting extension is to broaden the definition of a `` word '' to include multi-word lexical units( #AUTHOR_TAG ) ."", 'If such units can be identified a priori, their translations can be estimated without modifying the word-to-word model.', 'In this manner, the model can account for a wider range of translation phenomena']","['better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech, frequency of co-occurrence, relative word position, and translational entropy .', ""Another interesting extension is to broaden the definition of a `` word '' to include multi-word lexical units( #AUTHOR_TAG ) ."", 'If such units can be identified a priori, their translations can be estimated without modifying the word-to-word model.', 'In this manner, the model can account for a wider range of translation phenomena']","['better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech, frequency of co-occurrence, relative word position, and translational entropy .', ""Another interesting extension is to broaden the definition of a `` word '' to include multi-word lexical units( #AUTHOR_TAG ) ."", 'If such units can be identified a priori, their translations can be estimated without modifying the word-to-word model.', 'In this manner, the model can account for a wider range of translation phenomena']","['better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech, frequency of co-occurrence, relative word position, and translational entropy .', ""Another interesting extension is to broaden the definition of a `` word '' to include multi-word lexical units( #AUTHOR_TAG ) ."", 'If such units can be identified a priori, their translations can be estimated without modifying the word-to-word model.', 'In this manner, the model can account for a wider range of translation phenomena']",3
"['', 'For each co-occurring pair of word types u and v , these likelihoods are initially set proportional to their co-occurrence frequency ( â\x80\x9e , v ) and inversely proportional to their marginal frequencies n ( u ) and n ( v ) 1 , following( #AUTHOR_TAG ) 2 .', ""When the L(u, v) are re-estimated, the model's hidden parameters come into play""]","['', 'For each co-occurring pair of word types u and v , these likelihoods are initially set proportional to their co-occurrence frequency ( â\x80\x9e , v ) and inversely proportional to their marginal frequencies n ( u ) and n ( v ) 1 , following( #AUTHOR_TAG ) 2 .', ""When the L(u, v) are re-estimated, the model's hidden parameters come into play""]","['', 'For each co-occurring pair of word types u and v , these likelihoods are initially set proportional to their co-occurrence frequency ( â\x80\x9e , v ) and inversely proportional to their marginal frequencies n ( u ) and n ( v ) 1 , following( #AUTHOR_TAG ) 2 .', ""When the L(u, v) are re-estimated, the model's hidden parameters come into play""]","['', 'For each co-occurring pair of word types u and v , these likelihoods are initially set proportional to their co-occurrence frequency ( â\x80\x9e , v ) and inversely proportional to their marginal frequencies n ( u ) and n ( v ) 1 , following( #AUTHOR_TAG ) 2 .', ""When the L(u, v) are re-estimated, the model's hidden parameters come into play""]",5
"['the exception of( Fung , 1995 b ) , previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts( Gale & Church , 1991 ; Kumano & Hirakawa , 1994 ; Fung , 1995 a ;#AUTHOR_TAG ) .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in various ways.', 'The most']","['the exception of( Fung , 1995 b ) , previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts( Gale & Church , 1991 ; Kumano & Hirakawa , 1994 ; Fung , 1995 a ;#AUTHOR_TAG ) .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in various ways.', 'The most']","['the exception of( Fung , 1995 b ) , previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts( Gale & Church , 1991 ; Kumano & Hirakawa , 1994 ; Fung , 1995 a ;#AUTHOR_TAG ) .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in various ways.', 'The most common way is to divide each half of the bitext into an equal number of']","['the exception of( Fung , 1995 b ) , previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts( Gale & Church , 1991 ; Kumano & Hirakawa , 1994 ; Fung , 1995 a ;#AUTHOR_TAG ) .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in various ways.', '']",0
"[') < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( Brown et al. , 1990 ; Dagan et al. , 1993 ; #AUTHOR_TAG ) .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( Brown et al. , 1990 ; Dagan et al. , 1993 ; #AUTHOR_TAG ) .', '']","[') < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( Brown et al. , 1990 ; Dagan et al. , 1993 ; #AUTHOR_TAG ) .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( Brown et al. , 1990 ; Dagan et al. , 1993 ; #AUTHOR_TAG ) .', '']",1
"[""advantage that Brown et al.'s Model i has over our word-to-word model is that their objective function has no local maxima."", 'By using the EM algorithm( #AUTHOR_TAG ) , they can guarantee convergence towards the globally optimum parameter set .', '']","[""advantage that Brown et al.'s Model i has over our word-to-word model is that their objective function has no local maxima."", 'By using the EM algorithm( #AUTHOR_TAG ) , they can guarantee convergence towards the globally optimum parameter set .', '']","[""advantage that Brown et al.'s Model i has over our word-to-word model is that their objective function has no local maxima."", 'By using the EM algorithm( #AUTHOR_TAG ) , they can guarantee convergence towards the globally optimum parameter set .', '']","[""advantage that Brown et al.'s Model i has over our word-to-word model is that their objective function has no local maxima."", 'By using the EM algorithm( #AUTHOR_TAG ) , they can guarantee convergence towards the globally optimum parameter set .', 'In contrast, the dynamic nature of the competitive linking algorithm changes the Pr(datalmodel ) in a non-monotonic fashion.', '']",0
"['better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech , frequency of co-occurrence , relative word position , and translational entropy( #AUTHOR_TAG ) .', '']","['better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech , frequency of co-occurrence , relative word position , and translational entropy( #AUTHOR_TAG ) .', '']","['better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech , frequency of co-occurrence , relative word position , and translational entropy( #AUTHOR_TAG ) .', 'Another interesting extension is to broad']","['better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech , frequency of co-occurrence , relative word position , and translational entropy( #AUTHOR_TAG ) .', '']",3
"['the basic word-to-word model, the hidden parameters A + and A-depend only on the distributions of link frequencies generated by the competitive linking algorithm.', 'More accurate models can be induced by taking into account various features of the linked tokens.', 'For example , frequent words are translated less consistently than rare words( #AUTHOR_TAG )']","['the basic word-to-word model, the hidden parameters A + and A-depend only on the distributions of link frequencies generated by the competitive linking algorithm.', 'More accurate models can be induced by taking into account various features of the linked tokens.', 'For example , frequent words are translated less consistently than rare words( #AUTHOR_TAG )']","['the basic word-to-word model, the hidden parameters A + and A-depend only on the distributions of link frequencies generated by the competitive linking algorithm.', 'More accurate models can be induced by taking into account various features of the linked tokens.', 'For example , frequent words are translated less consistently than rare words( #AUTHOR_TAG )']","['the basic word-to-word model, the hidden parameters A + and A-depend only on the distributions of link frequencies generated by the competitive linking algorithm.', 'More accurate models can be induced by taking into account various features of the linked tokens.', 'For example , frequent words are translated less consistently than rare words( #AUTHOR_TAG )']",0
"[') < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( #AUTHOR_TAG ; Dagan et al. , 1993 ; Chen , 1996 ) .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( #AUTHOR_TAG ; Dagan et al. , 1993 ; Chen , 1996 ) .', '']","[') < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( #AUTHOR_TAG ; Dagan et al. , 1993 ; Chen , 1996 ) .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values( #AUTHOR_TAG ; Dagan et al. , 1993 ; Chen , 1996 ) .', '']",1
"[""2We could just as easily use other symmetric `` association '' measures , such as 02( #AUTHOR_TAG ) or the Dice coefficient( Smadja , 1992 ) ."", '']","[""2We could just as easily use other symmetric `` association '' measures , such as 02( #AUTHOR_TAG ) or the Dice coefficient( Smadja , 1992 ) ."", '']","[""2We could just as easily use other symmetric `` association '' measures , such as 02( #AUTHOR_TAG ) or the Dice coefficient( Smadja , 1992 ) ."", '']","[""2We could just as easily use other symmetric `` association '' measures , such as 02( #AUTHOR_TAG ) or the Dice coefficient( Smadja , 1992 ) ."", '']",1
"['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( Brown et al. , 1988 ; Brown et al. , 1990 ; #AUTHOR_TAG a ) .', '']","['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( Brown et al. , 1988 ; Brown et al. , 1990 ; #AUTHOR_TAG a ) .', 'However, the']","['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( Brown et al. , 1988 ; Brown et al. , 1990 ; #AUTHOR_TAG a ) .', '']","['the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation( Brown et al. , 1988 ; Brown et al. , 1990 ; #AUTHOR_TAG a ) .', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', '']",0
"['', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be( Gale & Church , 1991 ; Wu & Xia , 1994 ; #AUTHOR_TAG ) .', 'The likelihoods in the word-to-word model remain un']","['from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be( Gale & Church , 1991 ; Wu & Xia , 1994 ; #AUTHOR_TAG ) .', 'The likelihoods in the word-to-word model remain unnormalized, so they do not compete']","['from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be( Gale & Church , 1991 ; Wu & Xia , 1994 ; #AUTHOR_TAG ) .', 'The likelihoods in the word-to-word model remain un']","['some have tried, it is not clear how to extract such accurate lexicons from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be( Gale & Church , 1991 ; Wu & Xia , 1994 ; #AUTHOR_TAG ) .', 'The likelihoods in the word-to-word model remain unnormalized, so they do not compete']",0
"['', 'This method of incorporating dictionary information seems simpler than the method proposed by Brown et al. for their models( #AUTHOR_TAG b ) .', 'for their models(Brown et al., 1993 b']","['', 'This method of incorporating dictionary information seems simpler than the method proposed by Brown et al. for their models( #AUTHOR_TAG b ) .', 'for their models(Brown et al., 1993 b).', 'When the hidden parameters are conditioned on different link classes, the estimation method does not change; it is just repeated for each link class']","['', 'This method of incorporating dictionary information seems simpler than the method proposed by Brown et al. for their models( #AUTHOR_TAG b ) .', 'for their models(Brown et al., 1993 b']","['', 'This method of incorporating dictionary information seems simpler than the method proposed by Brown et al. for their models( #AUTHOR_TAG b ) .', 'for their models(Brown et al., 1993 b).', 'When the hidden parameters are conditioned on different link classes, the estimation method does not change; it is just repeated for each link class']",1
"['', ""The most detailed evaluation of link tokens to date was performed by( #AUTHOR_TAG ) , who trained Brown et al. 's Model 2 on 74 million words of the Canadian Hansards ."", 'These authors kindly provided us with the links generated by that model in 51 aligned sentences from a heldout test set.', 'We generated links in the same 51 sentences using our two-class word-to-word model, and manually evaluated the content-word links from both models.', '']","['', ""The most detailed evaluation of link tokens to date was performed by( #AUTHOR_TAG ) , who trained Brown et al. 's Model 2 on 74 million words of the Canadian Hansards ."", 'These authors kindly provided us with the links generated by that model in 51 aligned sentences from a heldout test set.', 'We generated links in the same 51 sentences using our two-class word-to-word model, and manually evaluated the content-word links from both models.', '']","['', ""The most detailed evaluation of link tokens to date was performed by( #AUTHOR_TAG ) , who trained Brown et al. 's Model 2 on 74 million words of the Canadian Hansards ."", 'These authors kindly provided us with the links generated by that model in 51 aligned sentences from a heldout test set.', 'We generated links in the same 51 sentences using our two-class word-to-word model, and manually evaluated the content-word links from both models.', '']","['', ""The most detailed evaluation of link tokens to date was performed by( #AUTHOR_TAG ) , who trained Brown et al. 's Model 2 on 74 million words of the Canadian Hansards ."", 'These authors kindly provided us with the links generated by that model in 51 aligned sentences from a heldout test set.', 'We generated links in the same 51 sentences using our two-class word-to-word model, and manually evaluated the content-word links from both models.', '']",1
"['11', '11 From( #AUTHOR_TAG ) , we find that the performance of SAMT system is similar with the method of labeling SCFG rules with POS tags .', 'Thus, to be convenient, we only conduct experiments with the SAMT system']","['11', '11 From( #AUTHOR_TAG ) , we find that the performance of SAMT system is similar with the method of labeling SCFG rules with POS tags .', 'Thus, to be convenient, we only conduct experiments with the SAMT system']","['11', '11 From( #AUTHOR_TAG ) , we find that the performance of SAMT system is similar with the method of labeling SCFG rules with POS tags .', 'Thus, to be convenient, we only conduct experiments with the SAMT system']","['', '11 From( #AUTHOR_TAG ) , we find that the performance of SAMT system is similar with the method of labeling SCFG rules with POS tags .', 'Thus, to be convenient, we only conduct experiments with the SAMT system']",4
"['', 'Differently ,#AUTHOR_TAG designed a sampler to infer an STSG by fixing the tree structure and exploring the space of alignment .', 'We']","['', 'Differently ,#AUTHOR_TAG designed a sampler to infer an STSG by fixing the tree structure and exploring the space of alignment .', 'We']","['', 'Differently ,#AUTHOR_TAG designed a sampler to infer an STSG by fixing the tree structure and exploring the space of alignment .', 'We believe that it is possible to investigate the space of both tree structure and alignment simultaneously.', 'This subject will be']","['', 'Differently ,#AUTHOR_TAG designed a sampler to infer an STSG by fixing the tree structure and exploring the space of alignment .', 'We believe that it is possible to investigate the space of both tree structure and alignment simultaneously.', '']",4
['obtained SCFG is further used in a phrase-based and hierarchical phrase-based system( #AUTHOR_TAG )'],['obtained SCFG is further used in a phrase-based and hierarchical phrase-based system( #AUTHOR_TAG )'],"['obtained SCFG is further used in a phrase-based and hierarchical phrase-based system( #AUTHOR_TAG ) .', '']","['', 'The obtained SCFG is further used in a phrase-based and hierarchical phrase-based system( #AUTHOR_TAG ) .', '']",1
"['', '#AUTHOR_TAG , 2009 , 2010 ) utilized Bayesian methods to learn synchronous context free grammars ( SCFG ) from a parallel corpus .', '']","['', '#AUTHOR_TAG , 2009 , 2010 ) utilized Bayesian methods to learn synchronous context free grammars ( SCFG ) from a parallel corpus .', '']","['', '#AUTHOR_TAG , 2009 , 2010 ) utilized Bayesian methods to learn synchronous context free grammars ( SCFG ) from a parallel corpus .', '']","['', '#AUTHOR_TAG , 2009 , 2010 ) utilized Bayesian methods to learn synchronous context free grammars ( SCFG ) from a parallel corpus .', 'The obtained SCFG is further used in a phrase-based and hierarchical phrase-based system(Chiang, 2007) .', '']",1
"['translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on( Galley et al. , 2006 ) and( #AUTHOR_TAG ) .', '']","['translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on( Galley et al. , 2006 ) and( #AUTHOR_TAG ) .', '']","['translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on( Galley et al. , 2006 ) and( #AUTHOR_TAG ) .', '']","['translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on( Galley et al. , 2006 ) and( #AUTHOR_TAG ) .', '']",5
"['', 'Our previous work( #AUTHOR_TAG ) designed an EMbased method to construct unsupervised trees for tree-based translation models .', 'This work differs from']","['', 'Our previous work( #AUTHOR_TAG ) designed an EMbased method to construct unsupervised trees for tree-based translation models .', 'This work differs from']","['', 'Our previous work( #AUTHOR_TAG ) designed an EMbased method to construct unsupervised trees for tree-based translation models .', 'This work differs from']","['', 'Our previous work( #AUTHOR_TAG ) designed an EMbased method to construct unsupervised trees for tree-based translation models .', '']",1
"['', 'Then , we binarize the English parse trees using the head binarization approach( #AUTHOR_TAG ) and use the resulting binary parse trees to build another s2t system']","['', 'Then , we binarize the English parse trees using the head binarization approach( #AUTHOR_TAG ) and use the resulting binary parse trees to build another s2t system']","['the above s2t system, we first use the parse tree, which is generated by parsing the English side of the bilingual data with the Berkeley parser(Petrov et al., 2006) .', 'Then , we binarize the English parse trees using the head binarization approach( #AUTHOR_TAG ) and use the resulting binary parse trees to build another s2t system']","['build the above s2t system, we first use the parse tree, which is generated by parsing the English side of the bilingual data with the Berkeley parser(Petrov et al., 2006) .', 'Then , we binarize the English parse trees using the head binarization approach( #AUTHOR_TAG ) and use the resulting binary parse trees to build another s2t system']",5
"['MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;#AUTHOR_TAG ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;#AUTHOR_TAG ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;#AUTHOR_TAG ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;#AUTHOR_TAG ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']",0
"['MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; #AUTHOR_TAG ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; #AUTHOR_TAG ; Zhang et al. , 2011 b )']","['MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; #AUTHOR_TAG ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; #AUTHOR_TAG ; Zhang et al. , 2011 b )']",0
"['', '#AUTHOR_TAG adopted a Bayesian method to infer an STSG by exploring the space of alignments based on parse trees']","['', '#AUTHOR_TAG adopted a Bayesian method to infer an STSG by exploring the space of alignments based on parse trees']","['', '#AUTHOR_TAG adopted a Bayesian method to infer an STSG by exploring the space of alignments based on parse trees .', '']","['', '#AUTHOR_TAG adopted a Bayesian method to infer an STSG by exploring the space of alignments based on parse trees .', '']",1
['we follow#AUTHOR_TAG and decompose the prior probability P0 ( r | N ) into two factors as follows'],['we follow#AUTHOR_TAG and decompose the prior probability P0 ( r | N ) into two factors as follows'],['we follow#AUTHOR_TAG and decompose the prior probability P0 ( r | N ) into two factors as follows'],"['', 'Because each rule r consists of a target tree fragment frag and a source string str in the model , we follow#AUTHOR_TAG and decompose the prior probability P0 ( r | N ) into two factors as follows']",5
"['', '#AUTHOR_TAG further labeled the SCFG rules with POS tags and unsupervised word classes .', '']","['categories.', '#AUTHOR_TAG further labeled the SCFG rules with POS tags and unsupervised word classes .', '']","['', '#AUTHOR_TAG further labeled the SCFG rules with POS tags and unsupervised word classes .', '']","['', '#AUTHOR_TAG further labeled the SCFG rules with POS tags and unsupervised word classes .', '']",1
"['the initial target U-trees , source sentences and word alignment , we extract minimal GHKM translation rules7 in terms of frontier nodes( #AUTHOR_TAG ) .', 'Frontier nodes are the tree nodes that can map onto contiguous substrings on the source side via word alignment.', 'For']","['the initial target U-trees , source sentences and word alignment , we extract minimal GHKM translation rules7 in terms of frontier nodes( #AUTHOR_TAG ) .', 'Frontier nodes are the tree nodes that can map onto contiguous substrings on the source side via word alignment.', 'For example, the bold italic nodes with shadows in Figure 2 are frontier nodes.', '']","['the initial target U-trees , source sentences and word alignment , we extract minimal GHKM translation rules7 in terms of frontier nodes( #AUTHOR_TAG ) .', 'Frontier nodes are the tree nodes that can map onto contiguous substrings on the source side via word alignment.', 'For']","['the initial target U-trees , source sentences and word alignment , we extract minimal GHKM translation rules7 in terms of frontier nodes( #AUTHOR_TAG ) .', 'Frontier nodes are the tree nodes that can map onto contiguous substrings on the source side via word alignment.', 'For example, the bold italic nodes with shadows in Figure 2 are frontier nodes.', '']",5
"['', '#AUTHOR_TAG re-trained the linguistic parsers bilingually based on word alignment']","['', '#AUTHOR_TAG re-trained the linguistic parsers bilingually based on word alignment']","['', '#AUTHOR_TAG re-trained the linguistic parsers bilingually based on word alignment .', '']","['', '#AUTHOR_TAG re-trained the linguistic parsers bilingually based on word alignment .', '']",1
"['', 'The statistical significance test is performed by the re-sampling approach( #AUTHOR_TAG )']","['', 'The statistical significance test is performed by the re-sampling approach( #AUTHOR_TAG )']","['', 'The statistical significance test is performed by the re-sampling approach( #AUTHOR_TAG )']","['', 'The statistical significance test is performed by the re-sampling approach( #AUTHOR_TAG )']",5
"['translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on( #AUTHOR_TAG ) and ( Marcu et al. 2006 ) .', '']","['translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on( #AUTHOR_TAG ) and ( Marcu et al. 2006 ) .', '']","['translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on( #AUTHOR_TAG ) and ( Marcu et al. 2006 ) .', '']","['translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on( #AUTHOR_TAG ) and ( Marcu et al. 2006 ) .', '']",5
"['', '#AUTHOR_TAG employed a Bayesian method to learn discontinuous SCFG rules']","['', '#AUTHOR_TAG employed a Bayesian method to learn discontinuous SCFG rules']","['', '#AUTHOR_TAG employed a Bayesian method to learn discontinuous SCFG rules .', 'This study differs from their work because we concentrate on constructing tree structures for tree-based translation models.', '']","['', '#AUTHOR_TAG employed a Bayesian method to learn discontinuous SCFG rules .', 'This study differs from their work because we concentrate on constructing tree structures for tree-based translation models.', '']",1
"['', '#AUTHOR_TAG andBurkett et al. ( 2010 ) focused on joint parsing and alignment']","['tree-based translation models than SCFG.', '#AUTHOR_TAG andBurkett et al. ( 2010 ) focused on joint parsing and alignment']","['', '#AUTHOR_TAG andBurkett et al. ( 2010 ) focused on joint parsing and alignment .', '']","['', '#AUTHOR_TAG andBurkett et al. ( 2010 ) focused on joint parsing and alignment .', 'They utilized the bilingual Tree-bank to train a joint model for both parsing and word alignment.', '']",1
['9 We only use the minimal GHKM rules( #AUTHOR_TAG ) here to reduce the complexity of the sampler'],"['', '9 We only use the minimal GHKM rules( #AUTHOR_TAG ) here to reduce the complexity of the sampler']",['9 We only use the minimal GHKM rules( #AUTHOR_TAG ) here to reduce the complexity of the sampler'],"['', '9 We only use the minimal GHKM rules( #AUTHOR_TAG ) here to reduce the complexity of the sampler']",5
"['', 'In the system , we extract both the minimal GHKM rules( #AUTHOR_TAG ) , and the rules of SPMT Model 1( Galley et al. , 2006 ) with phrases up to length L = 5 on the source side']","['', 'In the system , we extract both the minimal GHKM rules( #AUTHOR_TAG ) , and the rules of SPMT Model 1( Galley et al. , 2006 ) with phrases up to length L = 5 on the source side']","['', 'In the system , we extract both the minimal GHKM rules( #AUTHOR_TAG ) , and the rules of SPMT Model 1( Galley et al. , 2006 ) with phrases up to length L = 5 on the source side']","['', 'In the system , we extract both the minimal GHKM rules( #AUTHOR_TAG ) , and the rules of SPMT Model 1( Galley et al. , 2006 ) with phrases up to length L = 5 on the source side']",5
"['.', 'Using the GHKM algorithm( #AUTHOR_TAG ) , we can get two different STSG derivations from the two U-trees based on the fixed word alignment .', 'Each derivation carries a set of STSG rules (i.e., minimal GHKM translation rules) of its']","['U-trees.', 'Using the GHKM algorithm( #AUTHOR_TAG ) , we can get two different STSG derivations from the two U-trees based on the fixed word alignment .', 'Each derivation carries a set of STSG rules (i.e., minimal GHKM translation rules) of its own.', ""In the two derivations, the STSG rules defined by the two states include the one rooted at the s-node's lowest ancestor frontier node, and the one rooted at the s-node if it is a frontier node."", '']","['', 'Using the GHKM algorithm( #AUTHOR_TAG ) , we can get two different STSG derivations from the two U-trees based on the fixed word alignment .', 'Each derivation carries a set of STSG rules (i.e., minimal GHKM translation rules) of its']","['', 'Using the GHKM algorithm( #AUTHOR_TAG ) , we can get two different STSG derivations from the two U-trees based on the fixed word alignment .', 'Each derivation carries a set of STSG rules (i.e., minimal GHKM translation rules) of its own.', ""In the two derivations, the STSG rules defined by the two states include the one rooted at the s-node's lowest ancestor frontier node, and the one rooted at the s-node if it is a frontier node."", '']",5
"['MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; #AUTHOR_TAG , 2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; #AUTHOR_TAG , 2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; #AUTHOR_TAG , 2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;Quirk et al. , 2005 ; #AUTHOR_TAG , 2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']",0
"['MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;#AUTHOR_TAG ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;#AUTHOR_TAG ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;#AUTHOR_TAG ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( Liu et al. , 2006 ,  2009 ;#AUTHOR_TAG ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']",0
"['create the baseline system , we use the opensource Joshua 4.0 system( Ganitkevitch et al. , 2012 ) to build a hierarchical phrase-based ( HPB ) system , and a syntax-augmented MT ( SAMT ) 11 system( #AUTHOR_TAG ) respectively']","['create the baseline system , we use the opensource Joshua 4.0 system( Ganitkevitch et al. , 2012 ) to build a hierarchical phrase-based ( HPB ) system , and a syntax-augmented MT ( SAMT ) 11 system( #AUTHOR_TAG ) respectively']","['create the baseline system , we use the opensource Joshua 4.0 system( Ganitkevitch et al. , 2012 ) to build a hierarchical phrase-based ( HPB ) system , and a syntax-augmented MT ( SAMT ) 11 system( #AUTHOR_TAG ) respectively']","['create the baseline system , we use the opensource Joshua 4.0 system( Ganitkevitch et al. , 2012 ) to build a hierarchical phrase-based ( HPB ) system , and a syntax-augmented MT ( SAMT ) 11 system( #AUTHOR_TAG ) respectively']",5
"['build the above s2t system , we first use the parse tree , which is generated by parsing the English side of the bilingual data with the Berkeley parser( #AUTHOR_TAG ) .', 'Then, we binarize the English parse trees']","['build the above s2t system , we first use the parse tree , which is generated by parsing the English side of the bilingual data with the Berkeley parser( #AUTHOR_TAG ) .', 'Then, we binarize the English parse trees']","['build the above s2t system , we first use the parse tree , which is generated by parsing the English side of the bilingual data with the Berkeley parser( #AUTHOR_TAG ) .', 'Then, we binarize the English parse trees using']","['build the above s2t system , we first use the parse tree , which is generated by parsing the English side of the bilingual data with the Berkeley parser( #AUTHOR_TAG ) .', 'Then, we binarize the English parse trees using the head binarization approach(Wang et al., 2007) and use the resulting binary parse trees to build another s2t system']",5
"['how many child nodes to assign each node.', 'Differently, we require that each multi-word non-terminal node must have two child nodes.', 'This is because the binary structure has been verified to be very effective for tree-based translation( #AUTHOR_TAG ; Zhang et al. , 2011 a )']","['how many child nodes to assign each node.', 'Differently, we require that each multi-word non-terminal node must have two child nodes.', 'This is because the binary structure has been verified to be very effective for tree-based translation( #AUTHOR_TAG ; Zhang et al. , 2011 a )']","['how many child nodes to assign each node.', 'Differently, we require that each multi-word non-terminal node must have two child nodes.', 'This is because the binary structure has been verified to be very effective for tree-based translation( #AUTHOR_TAG ; Zhang et al. , 2011 a )']","['the probability of producing the target tree fragment frag.', 'To generate frag, used a geometric prior to decide how many child nodes to assign each node.', 'Differently, we require that each multi-word non-terminal node must have two child nodes.', 'This is because the binary structure has been verified to be very effective for tree-based translation( #AUTHOR_TAG ; Zhang et al. , 2011 a )']",4
"['recent years, tree-based translation models1 are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( #AUTHOR_TAG , 2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models1 are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( #AUTHOR_TAG , 2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models1 are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( #AUTHOR_TAG , 2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']","['recent years, tree-based translation models1 are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality( #AUTHOR_TAG , 2009 ;Quirk et al. , 2005 ; Galley et al. , 2004 ,  2006 ;Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011 b )']",0
"['2) Parse trees are actually only used to model and explain the monolingual structure, rather than the bilingual mapping between language pairs.', 'This indicates that parse trees are usually not the optimal choice for training tree-based translation models( #AUTHOR_TAG )']","['for training.', '2) Parse trees are actually only used to model and explain the monolingual structure, rather than the bilingual mapping between language pairs.', 'This indicates that parse trees are usually not the optimal choice for training tree-based translation models( #AUTHOR_TAG )']","['2) Parse trees are actually only used to model and explain the monolingual structure, rather than the bilingual mapping between language pairs.', 'This indicates that parse trees are usually not the optimal choice for training tree-based translation models( #AUTHOR_TAG )']","[', for many language pairs, it is difficult to acquire such corresponding linguistic parsers due to the lack of Tree-bank resources for training.', '2) Parse trees are actually only used to model and explain the monolingual structure, rather than the bilingual mapping between language pairs.', 'This indicates that parse trees are usually not the optimal choice for training tree-based translation models( #AUTHOR_TAG )']",0
['#AUTHOR_TAG focused on joint parsing and alignment'],['#AUTHOR_TAG focused on joint parsing and alignment'],"['#AUTHOR_TAG focused on joint parsing and alignment .', '']","['', 'Burkett and Klein ( 2008 ) and#AUTHOR_TAG focused on joint parsing and alignment .', 'They utilized the bilingual Tree-bank to train a joint model for both parsing and word alignment.', '']",1
"['', '#AUTHOR_TAG utilized a transformation-based method to learn a sequence of monolingual tree transformations for translation']","['', '#AUTHOR_TAG utilized a transformation-based method to learn a sequence of monolingual tree transformations for translation']","['', '#AUTHOR_TAG utilized a transformation-based method to learn a sequence of monolingual tree transformations for translation .', '']","['', '#AUTHOR_TAG utilized a transformation-based method to learn a sequence of monolingual tree transformations for translation .', '']",1
"['(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by( Blunsom et al. , 2009 ) and( #AUTHOR_TAG ) , we define P ( str | frag ) as follows : where csw is the number of words in the source string']","['(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by( Blunsom et al. , 2009 ) and( #AUTHOR_TAG ) , we define P ( str | frag ) as follows : where csw is the number of words in the source string']","['(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by( Blunsom et al. , 2009 ) and( #AUTHOR_TAG ) , we define P ( str | frag ) as follows : where csw is the number of words in the source string']","['(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by( Blunsom et al. , 2009 ) and( #AUTHOR_TAG ) , we define P ( str | frag ) as follows : where csw is the number of words in the source string']",4
"['(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by( #AUTHOR_TAG ) and( Cohn and Blunsom , 2009 ) , we define P ( str | frag ) as follows : where csw is the number of words in the source string']","['(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by( #AUTHOR_TAG ) and( Cohn and Blunsom , 2009 ) , we define P ( str | frag ) as follows : where csw is the number of words in the source string']","['(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by( #AUTHOR_TAG ) and( Cohn and Blunsom , 2009 ) , we define P ( str | frag ) as follows : where csw is the number of words in the source string']","['(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by( #AUTHOR_TAG ) and( Cohn and Blunsom , 2009 ) , we define P ( str | frag ) as follows : where csw is the number of words in the source string']",4
"['addition , we find that the Bayesian SCFG grammar can not even significantly outperform the heuristic SCFG grammar( #AUTHOR_TAG ) 5 .', 'This would indicate that the SCFG-based derivation tree as by-product is also not such good for tree-based translation models.', '']","['addition , we find that the Bayesian SCFG grammar can not even significantly outperform the heuristic SCFG grammar( #AUTHOR_TAG ) 5 .', 'This would indicate that the SCFG-based derivation tree as by-product is also not such good for tree-based translation models.', '']","['addition , we find that the Bayesian SCFG grammar can not even significantly outperform the heuristic SCFG grammar( #AUTHOR_TAG ) 5 .', 'This would indicate that the SCFG-based derivation tree as by-product is also not such good for tree-based translation models.', '']","['addition , we find that the Bayesian SCFG grammar can not even significantly outperform the heuristic SCFG grammar( #AUTHOR_TAG ) 5 .', 'This would indicate that the SCFG-based derivation tree as by-product is also not such good for tree-based translation models.', '']",1
"['', '#AUTHOR_TAG substituted the non-terminal X in hierarchical phrase-based model by extended syntactic categories .', '']","['we do not rely on any Tree-bank resources and focus on generating effective unsupervised tree structures for tree-based translation models.', '#AUTHOR_TAG substituted the non-terminal X in hierarchical phrase-based model by extended syntactic categories .', '']","['we do not rely on any Tree-bank resources and focus on generating effective unsupervised tree structures for tree-based translation models.', '#AUTHOR_TAG substituted the non-terminal X in hierarchical phrase-based model by extended syntactic categories .', '']","['', 'Compared to their work, we do not rely on any Tree-bank resources and focus on generating effective unsupervised tree structures for tree-based translation models.', '#AUTHOR_TAG substituted the non-terminal X in hierarchical phrase-based model by extended syntactic categories .', '']",1
"['', 'This recognizer incrementally outputs word hypotheses as soon as they are found in the best-scored path in the forward search( #AUTHOR_TAG ) using the ISTAR ( Incremental Structure Transmitter And Receiver ) protocol , which conveys word graph information as well as word hypotheses']","['', 'This recognizer incrementally outputs word hypotheses as soon as they are found in the best-scored path in the forward search( #AUTHOR_TAG ) using the ISTAR ( Incremental Structure Transmitter And Receiver ) protocol , which conveys word graph information as well as word hypotheses']","['Japan(Kobayashi et al., 1992) .', 'This recognizer incrementally outputs word hypotheses as soon as they are found in the best-scored path in the forward search( #AUTHOR_TAG ) using the ISTAR ( Incremental Structure Transmitter And Receiver ) protocol , which conveys word graph information as well as word hypotheses .', '']","['hypotheses.', 'As the recogn/fion engine, either VoiceRex, developed by NTI""(Noda et al., 1998) , or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan(Kobayashi et al., 1992) .', 'This recognizer incrementally outputs word hypotheses as soon as they are found in the best-scored path in the forward search( #AUTHOR_TAG ) using the ISTAR ( Incremental Structure Transmitter And Receiver ) protocol , which conveys word graph information as well as word hypotheses .', '']",0
"['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( #AUTHOR_TAG ; Allen et al. , 1996 ; Zue et al. , 2000 ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( #AUTHOR_TAG ; Allen et al. , 1996 ; Zue et al. , 2000 ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( #AUTHOR_TAG ; Allen et al. , 1996 ; Zue et al. , 2000 ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( #AUTHOR_TAG ; Allen et al. , 1996 ; Zue et al. , 2000 ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']",0
"['have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests( #AUTHOR_TAG ; Chu-Carroll , 1999 ) .', '']","['have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests( #AUTHOR_TAG ; Chu-Carroll , 1999 ) .', '']","['have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests( #AUTHOR_TAG ; Chu-Carroll , 1999 ) .', '']","['have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests( #AUTHOR_TAG ; Chu-Carroll , 1999 ) .', 'Incorporating such techniques would deo crease the system developer workload.', '']",3
"['ctions defined here decide what string should be spoken and send that string to the speech output module based on the current dialogue state.', 'They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of#AUTHOR_TAG']","['ctions defined here decide what string should be spoken and send that string to the speech output module based on the current dialogue state.', 'They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of#AUTHOR_TAG']","['ctions defined here decide what string should be spoken and send that string to the speech output module based on the current dialogue state.', 'They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of#AUTHOR_TAG']","['ctions defined here decide what string should be spoken and send that string to the speech output module based on the current dialogue state.', 'They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of#AUTHOR_TAG']",1
"['the recogn/fion engine, either VoiceRex, developed by NTI""(Noda et al., 1998) , or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan( #AUTHOR_TAG ) .', '']","['the recogn/fion engine, either VoiceRex, developed by NTI""(Noda et al., 1998) , or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan( #AUTHOR_TAG ) .', '']","['the recogn/fion engine, either VoiceRex, developed by NTI""(Noda et al., 1998) , or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan( #AUTHOR_TAG ) .', '']","['hypotheses.', 'As the recogn/fion engine, either VoiceRex, developed by NTI""(Noda et al., 1998) , or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan( #AUTHOR_TAG ) .', '']",5
"['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; Allen et al. , 1996 ; Zue et al. , 2000 ; #AUTHOR_TAG ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; Allen et al. , 1996 ; Zue et al. , 2000 ; #AUTHOR_TAG ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; Allen et al. , 1996 ; Zue et al. , 2000 ; #AUTHOR_TAG ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; Allen et al. , 1996 ; Zue et al. , 2000 ; #AUTHOR_TAG ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']",0
"['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; Allen et al. , 1996 ; #AUTHOR_TAG ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; Allen et al. , 1996 ; #AUTHOR_TAG ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; Allen et al. , 1996 ; #AUTHOR_TAG ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; Allen et al. , 1996 ; #AUTHOR_TAG ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']",0
"['has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system( #AUTHOR_TAG b ) , a video-recording programming system , a schedule management system( Nakano et al. , 1999 a ) , and a weather infomiation system( Dohsaka et al. , 2000 ) .', '']","['has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system( #AUTHOR_TAG b ) , a video-recording programming system , a schedule management system( Nakano et al. , 1999 a ) , and a weather infomiation system( Dohsaka et al. , 2000 ) .', '']","['has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system( #AUTHOR_TAG b ) , a video-recording programming system , a schedule management system( Nakano et al. , 1999 a ) , and a weather infomiation system( Dohsaka et al. , 2000 ) .', '']","['has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system( #AUTHOR_TAG b ) , a video-recording programming system , a schedule management system( Nakano et al. , 1999 a ) , and a weather infomiation system( Dohsaka et al. , 2000 ) .', '']",2
"['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; #AUTHOR_TAG ; Zue et al. , 2000 ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; #AUTHOR_TAG ; Zue et al. , 2000 ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; #AUTHOR_TAG ; Zue et al. , 2000 ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']","['recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems( Aust et al. , 1995 ; #AUTHOR_TAG ; Zue et al. , 2000 ; Walker et al. , 2000 ) .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain']",0
"['', 'Since the language understanding module utilizes unification, a wide variety of linguistic phenomena can be covered.', 'For example , speech repairs , particle omission , and fillers can be dealt with in the framework of unification grammar( #AUTHOR_TAG ; Nakano and Shimazu , 1999 ) .', 'The language generation module features Common Lisp functions, so there is']","['', 'Since the language understanding module utilizes unification, a wide variety of linguistic phenomena can be covered.', 'For example , speech repairs , particle omission , and fillers can be dealt with in the framework of unification grammar( #AUTHOR_TAG ; Nakano and Shimazu , 1999 ) .', 'The language generation module features Common Lisp functions, so there is']","['', 'Since the language understanding module utilizes unification, a wide variety of linguistic phenomena can be covered.', 'For example , speech repairs , particle omission , and fillers can be dealt with in the framework of unification grammar( #AUTHOR_TAG ; Nakano and Shimazu , 1999 ) .', 'The language generation module features Common Lisp functions, so there is']","['', 'Since the language understanding module utilizes unification, a wide variety of linguistic phenomena can be covered.', 'For example , speech repairs , particle omission , and fillers can be dealt with in the framework of unification grammar( #AUTHOR_TAG ; Nakano and Shimazu , 1999 ) .', 'The language generation module features Common Lisp functions, so there is no limitation on the description.', '']",3
"['the language generation module works in parallel with the language understanding module , utterance generation is possible even while the system is listening to user utterances and that utterance understanding is possible even while it is speaking( #AUTHOR_TAG a ) .', 'Thus the system can respond immediately after user pauses when the user has the initiative.', '']","['the language generation module works in parallel with the language understanding module , utterance generation is possible even while the system is listening to user utterances and that utterance understanding is possible even while it is speaking( #AUTHOR_TAG a ) .', 'Thus the system can respond immediately after user pauses when the user has the initiative.', '']","['the language generation module works in parallel with the language understanding module , utterance generation is possible even while the system is listening to user utterances and that utterance understanding is possible even while it is speaking( #AUTHOR_TAG a ) .', 'Thus the system can respond immediately after user pauses when the user has the initiative.', '']","['the language generation module works in parallel with the language understanding module , utterance generation is possible even while the system is listening to user utterances and that utterance understanding is possible even while it is speaking( #AUTHOR_TAG a ) .', 'Thus the system can respond immediately after user pauses when the user has the initiative.', '']",0
"['has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system( Nakano et al. , 1999 b ) , a video-recording programming system , a schedule management system( Nakano et al. , 1999 a ) , and a weather infomiation system( #AUTHOR_TAG ) .', '']","['has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system( Nakano et al. , 1999 b ) , a video-recording programming system , a schedule management system( Nakano et al. , 1999 a ) , and a weather infomiation system( #AUTHOR_TAG ) .', '']","['has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system( Nakano et al. , 1999 b ) , a video-recording programming system , a schedule management system( Nakano et al. , 1999 a ) , and a weather infomiation system( #AUTHOR_TAG ) .', '']","['has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system( Nakano et al. , 1999 b ) , a video-recording programming system , a schedule management system( Nakano et al. , 1999 a ) , and a weather infomiation system( #AUTHOR_TAG ) .', '']",2
"['', 'WIT features an incremental understanding method( #AUTHOR_TAG b ) that makes it possible to build a robust and real-time system .', '']","['', 'WIT features an incremental understanding method( #AUTHOR_TAG b ) that makes it possible to build a robust and real-time system .', '']","['', 'WIT features an incremental understanding method( #AUTHOR_TAG b ) that makes it possible to build a robust and real-time system .', '']","['', 'WIT features an incremental understanding method( #AUTHOR_TAG b ) that makes it possible to build a robust and real-time system .', 'In addition, WIT compiles domain-dependent system specifications into internal knowledge sources so that building systems is easier.', '']",5
"['domain-dependent knowledge used in this module consists of a unification-based lexicon and phrase structure rules.', 'Disjunctive feature descriptions are also possible ; WIT incorporates an efficient method for handling disjunctions( #AUTHOR_TAG ) .', '']","['domain-dependent knowledge used in this module consists of a unification-based lexicon and phrase structure rules.', 'Disjunctive feature descriptions are also possible ; WIT incorporates an efficient method for handling disjunctions( #AUTHOR_TAG ) .', '']","['domain-dependent knowledge used in this module consists of a unification-based lexicon and phrase structure rules.', 'Disjunctive feature descriptions are also possible ; WIT incorporates an efficient method for handling disjunctions( #AUTHOR_TAG ) .', '']","['domain-dependent knowledge used in this module consists of a unification-based lexicon and phrase structure rules.', 'Disjunctive feature descriptions are also possible ; WIT incorporates an efficient method for handling disjunctions( #AUTHOR_TAG ) .', 'When a phrase boundary is detected, the feature structure for a phrase is computed using some built-in rules from the feature structure rules for the words in the phrase.', '']",5
"['), but we do not explain these constraints in detail in this paper.', 'The priorities are used for disambiguating interpretation in the incremental understanding method( #AUTHOR_TAG b ) .', '']","['is possible to add to the rules constraints that stipulate relationships that must hold among variables (Nakano,199 I), but we do not explain these constraints in detail in this paper.', 'The priorities are used for disambiguating interpretation in the incremental understanding method( #AUTHOR_TAG b ) .', '']","['), but we do not explain these constraints in detail in this paper.', 'The priorities are used for disambiguating interpretation in the incremental understanding method( #AUTHOR_TAG b ) .', '']","['', 'It is possible to add to the rules constraints that stipulate relationships that must hold among variables (Nakano,199 I), but we do not explain these constraints in detail in this paper.', 'The priorities are used for disambiguating interpretation in the incremental understanding method( #AUTHOR_TAG b ) .', '']",5
"['this end , several toolkits for building spoken dialogue systems have been developed( Barnett and Singh , 1997 ; #AUTHOR_TAG ) .', 'One is the CSLU']","['this end , several toolkits for building spoken dialogue systems have been developed( Barnett and Singh , 1997 ; #AUTHOR_TAG ) .', 'One is the CSLU Toolkit']","['this end , several toolkits for building spoken dialogue systems have been developed( Barnett and Singh , 1997 ; #AUTHOR_TAG ) .', 'One is the CSLU Toolkit']","['this end , several toolkits for building spoken dialogue systems have been developed( Barnett and Singh , 1997 ; #AUTHOR_TAG ) .', '']",0
"['', 'The understanding module utilizes ISSS ( Incremental Significant-utterance Sequence Search )( #AUTHOR_TAG b ) , which is an integrated parsing and discourse processing method .', 'ISSS enables the incremental understanding of user utterances that are not segmented into sentences prior to pars-ing by incrementally finding the most pl']","['', 'The understanding module utilizes ISSS ( Incremental Significant-utterance Sequence Search )( #AUTHOR_TAG b ) , which is an integrated parsing and discourse processing method .', 'ISSS enables the incremental understanding of user utterances that are not segmented into sentences prior to pars-ing by incrementally finding the most']","['', 'The understanding module utilizes ISSS ( Incremental Significant-utterance Sequence Search )( #AUTHOR_TAG b ) , which is an integrated parsing and discourse processing method .', 'ISSS enables the incremental understanding of user utterances that are not segmented into sentences prior to pars-ing by incrementally finding the most pl']","['', 'The understanding module utilizes ISSS ( Incremental Significant-utterance Sequence Search )( #AUTHOR_TAG b ) , which is an integrated parsing and discourse processing method .', 'ISSS enables the incremental understanding of user utterances that are not segmented into sentences prior to pars-ing by incrementally finding the most plausible sequence of sentences (or significant utterances in the ISSS terms) out of the possible sentence sequences for the input word sequence.', '']",5
"['common approach is term translation, e.g., via a bilingual lexicon.(Davis and Ogden, 1997; #AUTHOR_TAG ; Hull and Grefenstette, 1996) .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', '']","['common approach is term translation, e.g., via a bilingual lexicon.(Davis and Ogden, 1997; #AUTHOR_TAG ; Hull and Grefenstette, 1996) .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', '']","['common approach is term translation, e.g., via a bilingual lexicon.(Davis and Ogden, 1997; #AUTHOR_TAG ; Hull and Grefenstette, 1996) .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', '']","['common approach is term translation, e.g., via a bilingual lexicon.(Davis and Ogden, 1997; #AUTHOR_TAG ; Hull and Grefenstette, 1996) .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', '']",1
"['second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method( Ballesteros and Croft , 1998 ; Pirkola , 1998 ; #AUTHOR_TAG ) .', 'One such method is to treat different translations of the same term as synonyms.', 'Ball']","['second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method( Ballesteros and Croft , 1998 ; Pirkola , 1998 ; #AUTHOR_TAG ) .', 'One such method is to treat different translations of the same term as synonyms.', '']","['second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method( Ballesteros and Croft , 1998 ; Pirkola , 1998 ; #AUTHOR_TAG ) .', 'One such method is to treat different translations of the same term as synonyms.', 'Ball']","['second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method( Ballesteros and Croft , 1998 ; Pirkola , 1998 ; #AUTHOR_TAG ) .', 'One such method is to treat different translations of the same term as synonyms.', 'Ballesteros, for example, used the INQUERY(Callan et al, 1995) synonym operator to group translations of different query terms.', '']",1
"['results in Table 4 show that manual disambiguation improves performance by 17% on Trec5C, 4% on Trec4S, but not at all on Trec6C.', 'Furthermore, the improvement on Trec5C appears to be caused by big improvements for a small number of queries.', 'The one-sided t-test( #AUTHOR_TAG ) at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant']","['results in Table 4 show that manual disambiguation improves performance by 17% on Trec5C, 4% on Trec4S, but not at all on Trec6C.', 'Furthermore, the improvement on Trec5C appears to be caused by big improvements for a small number of queries.', 'The one-sided t-test( #AUTHOR_TAG ) at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant']","['results in Table 4 show that manual disambiguation improves performance by 17% on Trec5C, 4% on Trec4S, but not at all on Trec6C.', 'Furthermore, the improvement on Trec5C appears to be caused by big improvements for a small number of queries.', 'The one-sided t-test( #AUTHOR_TAG ) at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant']","['results in Table 4 show that manual disambiguation improves performance by 17% on Trec5C, 4% on Trec4S, but not at all on Trec6C.', 'Furthermore, the improvement on Trec5C appears to be caused by big improvements for a small number of queries.', 'The one-sided t-test( #AUTHOR_TAG ) at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant']",5
"['third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation , e.g latent semantic indexing ( LSI )( Littman et al , 1998 ) , or the General Vector space model ( GVSM ) ,( #AUTHOR_TAG ) .', 'We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in']","['third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation , e.g latent semantic indexing ( LSI )( Littman et al , 1998 ) , or the General Vector space model ( GVSM ) ,( #AUTHOR_TAG ) .', 'We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in']","['third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation , e.g latent semantic indexing ( LSI )( Littman et al , 1998 ) , or the General Vector space model ( GVSM ) ,( #AUTHOR_TAG ) .', 'We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in']","['third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation , e.g latent semantic indexing ( LSI )( Littman et al , 1998 ) , or the General Vector space model ( GVSM ) ,( #AUTHOR_TAG ) .', 'We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet inDiekema et al., 1999)']",1
['\x80¢ The transition probability a is 0.7 using the EM algorithm( #AUTHOR_TAG ) on the TREC4 ad-hoc query set'],['\x80¢ The transition probability a is 0.7 using the EM algorithm( #AUTHOR_TAG ) on the TREC4 ad-hoc query set'],['\x80¢ The transition probability a is 0.7 using the EM algorithm( #AUTHOR_TAG ) on the TREC4 ad-hoc query set'],['\x80¢ The transition probability a is 0.7 using the EM algorithm( #AUTHOR_TAG ) on the TREC4 ad-hoc query set'],5
"['', '#AUTHOR_TAG studied the issue of disambiguation for mono-lingual M']","['', '#AUTHOR_TAG studied the issue of disambiguation for mono-lingual M']","['', '#AUTHOR_TAG studied the issue of disambiguation for mono-lingual M']","['', '#AUTHOR_TAG studied the issue of disambiguation for mono-lingual M']",0
"['.', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', 'Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and deJong , 1999 ; #AUTHOR_TAG .', 'Sanderson, 1994  studied the issue of disarnbiguation for mono-lingual IR']","['.', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', 'Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and deJong , 1999 ; #AUTHOR_TAG .', 'Sanderson, 1994  studied the issue of disarnbiguation for mono-lingual IR']","['', '(Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and Grefenstette, 1996) .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', 'Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and deJong , 1999 ; #AUTHOR_TAG .', 'Sanderson, 1994  studied the issue of disarnbiguation for mono-lingual IR']","['', '(Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and Grefenstette, 1996) .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', 'Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and deJong , 1999 ; #AUTHOR_TAG .', 'Sanderson, 1994  studied the issue of disarnbiguation for mono-lingual IR']",0
"['approaches to cross-lingual IR have been published.', 'One common approach is using Machine Translation ( MT ) to translate the queries to the language of the documents or translate documents to the language of the queries( Gey et al , 1999 ; #AUTHOR_TAG ) .', 'For most']","['approaches to cross-lingual IR have been published.', 'One common approach is using Machine Translation ( MT ) to translate the queries to the language of the documents or translate documents to the language of the queries( Gey et al , 1999 ; #AUTHOR_TAG ) .', 'For most languages, there are no MT systems at all.', 'Our']","['approaches to cross-lingual IR have been published.', 'One common approach is using Machine Translation ( MT ) to translate the queries to the language of the documents or translate documents to the language of the queries( Gey et al , 1999 ; #AUTHOR_TAG ) .', 'For most languages, there are no MT systems at all.', 'Our']","['approaches to cross-lingual IR have been published.', 'One common approach is using Machine Translation ( MT ) to translate the queries to the language of the documents or translate documents to the language of the queries( Gey et al , 1999 ; #AUTHOR_TAG ) .', 'For most languages, there are no MT systems at all.', '']",1
"['second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method( Ballesteros and Croft , 1998 ; #AUTHOR_TAG ; Hull 1997 ) .', 'One such method is to treat different translations of the same term as synonyms.', 'Ball']","['second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method( Ballesteros and Croft , 1998 ; #AUTHOR_TAG ; Hull 1997 ) .', 'One such method is to treat different translations of the same term as synonyms.', '']","['second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method( Ballesteros and Croft , 1998 ; #AUTHOR_TAG ; Hull 1997 ) .', 'One such method is to treat different translations of the same term as synonyms.', 'Ball']","['second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method( Ballesteros and Croft , 1998 ; #AUTHOR_TAG ; Hull 1997 ) .', 'One such method is to treat different translations of the same term as synonyms.', '']",1
['the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur( #AUTHOR_TAG )'],['the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur( #AUTHOR_TAG )'],['the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur( #AUTHOR_TAG )'],"['', 'However , the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur( #AUTHOR_TAG )']",0
"['', 'A cooccurrence based stemmer( #AUTHOR_TAG ) was used to stem Spanish words .', '']","['', 'A cooccurrence based stemmer( #AUTHOR_TAG ) was used to stem Spanish words .', '']","['', 'A cooccurrence based stemmer( #AUTHOR_TAG ) was used to stem Spanish words .', '']","['', 'A cooccurrence based stemmer( #AUTHOR_TAG ) was used to stem Spanish words .', '']",5
"['studies which view lR as a query generation process includeMaron and Kuhns , 1960 ; Hiemstra and Kraaij , 1999 ; #AUTHOR_TAG ; Miller et al , 1999  .', 'Our work has focused on cross-lingual retrieval']","['studies which view lR as a query generation process includeMaron and Kuhns , 1960 ; Hiemstra and Kraaij , 1999 ; #AUTHOR_TAG ; Miller et al , 1999  .', 'Our work has focused on cross-lingual retrieval']","['studies which view lR as a query generation process includeMaron and Kuhns , 1960 ; Hiemstra and Kraaij , 1999 ; #AUTHOR_TAG ; Miller et al , 1999  .', 'Our work has focused on cross-lingual retrieval']","['studies which view lR as a query generation process includeMaron and Kuhns , 1960 ; Hiemstra and Kraaij , 1999 ; #AUTHOR_TAG ; Miller et al , 1999  .', 'Our work has focused on cross-lingual retrieval']",1
"['studies which view lR as a query generation process include#AUTHOR_TAG ; Hiemstra and Kraaij , 1999 ; Ponte and Croft , 1998 ; Miller et al , 1999  .', 'Our work has focused on cross-lingual retrieval']","['studies which view lR as a query generation process include#AUTHOR_TAG ; Hiemstra and Kraaij , 1999 ; Ponte and Croft , 1998 ; Miller et al , 1999  .', 'Our work has focused on cross-lingual retrieval']","['studies which view lR as a query generation process include#AUTHOR_TAG ; Hiemstra and Kraaij , 1999 ; Ponte and Croft , 1998 ; Miller et al , 1999  .', 'Our work has focused on cross-lingual retrieval']","['studies which view lR as a query generation process include#AUTHOR_TAG ; Hiemstra and Kraaij , 1999 ; Ponte and Croft , 1998 ; Miller et al , 1999  .', 'Our work has focused on cross-lingual retrieval']",1
"['technique is automatic discovery of translations from parallel or non-parallel corpora( #AUTHOR_TAG ) .', 'Since traditional lexicons are more or less static repositories of knowledge, techniques that discover translation from newly published materials can supplement them with corpus-specific vocabularies']","['technique is automatic discovery of translations from parallel or non-parallel corpora( #AUTHOR_TAG ) .', 'Since traditional lexicons are more or less static repositories of knowledge, techniques that discover translation from newly published materials can supplement them with corpus-specific vocabularies']","['technique is automatic discovery of translations from parallel or non-parallel corpora( #AUTHOR_TAG ) .', 'Since traditional lexicons are more or less static repositories of knowledge, techniques that discover translation from newly published materials can supplement them with corpus-specific vocabularies']","['technique is automatic discovery of translations from parallel or non-parallel corpora( #AUTHOR_TAG ) .', 'Since traditional lexicons are more or less static repositories of knowledge, techniques that discover translation from newly published materials can supplement them with corpus-specific vocabularies']",0
"['#AUTHOR_TAG , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) .', '']","['#AUTHOR_TAG , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) .', '']","['#AUTHOR_TAG , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) .', '']","['#AUTHOR_TAG , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) .', '']",5
"['nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( #AUTHOR_TAG ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( #AUTHOR_TAG ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( #AUTHOR_TAG ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'would be chunked as follows(Tjong Kim Sang and Buchholz, 2000) : While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information -by examining the pattern itself, its nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( #AUTHOR_TAG ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']",0
"['first is the one used in the chunking competition in CoNLL-2000 ( Tjong Kim#AUTHOR_TAG ) .', 'In this case, a full parse tree is represented in a flat form, producing a representation as in the example above.', 'The goal in this case is therefore to accurately predict a collection of ¢ £ ¢ different types of']","['first is the one used in the chunking competition in CoNLL-2000 ( Tjong Kim#AUTHOR_TAG ) .', 'In this case, a full parse tree is represented in a flat form, producing a representation as in the example above.', 'The goal in this case is therefore to accurately predict a collection of ¢ £ ¢ different types of phrases.', 'The chunk']","['first is the one used in the chunking competition in CoNLL-2000 ( Tjong Kim#AUTHOR_TAG ) .', 'In this case, a full parse tree is represented in a flat form, producing a representation as in the example above.', 'The goal in this case is therefore to accurately predict a collection of ¢ £ ¢ different types of']","['first is the one used in the chunking competition in CoNLL-2000 ( Tjong Kim#AUTHOR_TAG ) .', 'In this case, a full parse tree is represented in a flat form, producing a representation as in the example above.', 'The goal in this case is therefore to accurately predict a collection of ¢ £ ¢ different types of phrases.', 'The chunk types are based on the syntactic category part of the bracket label in the Treebank.', '']",5
"['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( #AUTHOR_TAG ; Abney , 1991 ; Greffenstette , 1993 ) .', '']","['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( #AUTHOR_TAG ; Abney , 1991 ; Greffenstette , 1993 ) .', '']","['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( #AUTHOR_TAG ; Abney , 1991 ; Greffenstette , 1993 ) .', '']","['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( #AUTHOR_TAG ; Abney , 1991 ; Greffenstette , 1993 ) .', '']",0
"['nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; #AUTHOR_TAG a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; #AUTHOR_TAG a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; #AUTHOR_TAG a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'would be chunked as follows(Tjong Kim Sang and Buchholz, 2000) : While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information -by examining the pattern itself, its nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; #AUTHOR_TAG a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']",0
"[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( Charniak , 1997 b ;Charniak , 1997 a ;#AUTHOR_TAG ; Ratnaparkhi , 1997 )']","[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( Charniak , 1997 b ;Charniak , 1997 a ;#AUTHOR_TAG ; Ratnaparkhi , 1997 )']","[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( Charniak , 1997 b ;Charniak , 1997 a ;#AUTHOR_TAG ; Ratnaparkhi , 1997 )']","[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( Charniak , 1997 b ;Charniak , 1997 a ;#AUTHOR_TAG ; Ratnaparkhi , 1997 )']",0
"['perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins( Collins , 1996 ; #AUTHOR_TAG ) -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After']","['perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins( Collins , 1996 ; #AUTHOR_TAG ) -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After']","['perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins( Collins , 1996 ; #AUTHOR_TAG ) -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After']","['perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins( Collins , 1996 ; #AUTHOR_TAG ) -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After that, it will choose the candidate parse tree with the highest probability as output.', '']",5
"[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( #AUTHOR_TAG b ;Charniak , 1997 a ;Collins , 1997 ; Ratnaparkhi , 1997 )']","[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( #AUTHOR_TAG b ;Charniak , 1997 a ;Collins , 1997 ; Ratnaparkhi , 1997 )']","[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( #AUTHOR_TAG b ;Charniak , 1997 a ;Collins , 1997 ; Ratnaparkhi , 1997 )']","[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( #AUTHOR_TAG b ;Charniak , 1997 a ;Collins , 1997 ; Ratnaparkhi , 1997 )']",0
"['', 'SNoW( #AUTHOR_TAG ; Roth , 1998 ) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '']","['', 'SNoW( #AUTHOR_TAG ; Roth , 1998 ) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '']","['shallow parser used is the SNoW-based CSCL parser(Punyakanok and Roth, 2001;Munoz et al., 1999) .', 'SNoW( #AUTHOR_TAG ; Roth , 1998 ) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '']","['shallow parser used is the SNoW-based CSCL parser(Punyakanok and Roth, 2001;Munoz et al., 1999) .', 'SNoW( #AUTHOR_TAG ; Roth , 1998 ) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '']",5
"['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( #AUTHOR_TAG ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( #AUTHOR_TAG ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","[', along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( #AUTHOR_TAG ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( #AUTHOR_TAG ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']",0
"['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; #AUTHOR_TAG ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; #AUTHOR_TAG ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","[', along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; #AUTHOR_TAG ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; #AUTHOR_TAG ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']",0
"['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( Harris , 1957 ; #AUTHOR_TAG ; Greffenstette , 1993 ) .', '']","['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( Harris , 1957 ; #AUTHOR_TAG ; Greffenstette , 1993 ) .', '']","['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( Harris , 1957 ; #AUTHOR_TAG ; Greffenstette , 1993 ) .', '']","['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( Harris , 1957 ; #AUTHOR_TAG ; Greffenstette , 1993 ) .', '']",0
"['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( Harris , 1957 ; Abney , 1991 ; #AUTHOR_TAG ) .', '']","['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( Harris , 1957 ; Abney , 1991 ; #AUTHOR_TAG ) .', '']","['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( Harris , 1957 ; Abney , 1991 ; #AUTHOR_TAG ) .', '']","['allow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text( Harris , 1957 ; Abney , 1991 ; #AUTHOR_TAG ) .', '']",0
"['noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization( Grishman , 1995 ; #AUTHOR_TAG ) .', '']","['noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization( Grishman , 1995 ; #AUTHOR_TAG ) .', '']","['that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization( Grishman , 1995 ; #AUTHOR_TAG ) .', '']","[', it has been noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization( Grishman , 1995 ; #AUTHOR_TAG ) .', '']",0
"['we do here , we also trained and tested it under the exact conditions of CoNLL-2000 ( Tjong Kim#AUTHOR_TAG ) to compare it to other shallow parsers .', 'Table 1 shows that it ranks among the top shallow parsers evaluated there 1']","['we do here , we also trained and tested it under the exact conditions of CoNLL-2000 ( Tjong Kim#AUTHOR_TAG ) to compare it to other shallow parsers .', 'Table 1 shows that it ranks among the top shallow parsers evaluated there 1']","['we do here , we also trained and tested it under the exact conditions of CoNLL-2000 ( Tjong Kim#AUTHOR_TAG ) to compare it to other shallow parsers .', 'Table 1 shows that it ranks among the top shallow parsers evaluated there 1']","['earlier versions of the SNoW based CSCL were used only to identify single phrases( Punyakanok and Roth , 2001 ; Munoz et al. , 1999 ) and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 ( Tjong Kim#AUTHOR_TAG ) to compare it to other shallow parsers .', 'Table 1 shows that it ranks among the top shallow parsers evaluated there 1']",5
"['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; #AUTHOR_TAG ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; #AUTHOR_TAG ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","[', along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; #AUTHOR_TAG ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; #AUTHOR_TAG ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']",0
"[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( Charniak , 1997 b ;Charniak , 1997 a ;Collins , 1997 ; #AUTHOR_TAG )']","[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( Charniak , 1997 b ;Charniak , 1997 a ;Collins , 1997 ; #AUTHOR_TAG )']","[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( Charniak , 1997 b ;Charniak , 1997 a ;Collins , 1997 ; #AUTHOR_TAG )']","[', the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time( Charniak , 1997 b ;Charniak , 1997 a ;Collins , 1997 ; #AUTHOR_TAG )']",0
"['shallow parser used is the SNoW-based CSCL parser( #AUTHOR_TAG ; Munoz et al. , 1999 ) .', 'SNoW(Carleson et al., 1999;Roth, 1998) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example']","['shallow parser used is the SNoW-based CSCL parser( #AUTHOR_TAG ; Munoz et al. , 1999 ) .', 'SNoW(Carleson et al., 1999;Roth, 1998) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', '']","['shallow parser used is the SNoW-based CSCL parser( #AUTHOR_TAG ; Munoz et al. , 1999 ) .', 'SNoW(Carleson et al., 1999;Roth, 1998) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', 'It works by learning a sparse network of linear functions over a pre-defined or increment']","['shallow parser used is the SNoW-based CSCL parser( #AUTHOR_TAG ; Munoz et al. , 1999 ) .', 'SNoW(Carleson et al., 1999;Roth, 1998) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', '']",5
"['by reporting the results in which we compare the full parser and the shallow parser on the ""clean"" WSJ data.', 'Table 2 shows the results on identifying all phrases -- chunking in CoNLL2000 ( Tjong Kim#AUTHOR_TAG ) terminology .', 'The results show that for the tasks of identifying phrases, learning directly, as done by the shallow parser outperforms the outcome from the full parser.', '']","['by reporting the results in which we compare the full parser and the shallow parser on the ""clean"" WSJ data.', 'Table 2 shows the results on identifying all phrases -- chunking in CoNLL2000 ( Tjong Kim#AUTHOR_TAG ) terminology .', 'The results show that for the tasks of identifying phrases, learning directly, as done by the shallow parser outperforms the outcome from the full parser.', '']","['start by reporting the results in which we compare the full parser and the shallow parser on the ""clean"" WSJ data.', 'Table 2 shows the results on identifying all phrases -- chunking in CoNLL2000 ( Tjong Kim#AUTHOR_TAG ) terminology .', 'The results show that for the tasks of identifying phrases, learning directly, as done by the shallow parser outperforms the outcome from the full parser.', '']","['start by reporting the results in which we compare the full parser and the shallow parser on the ""clean"" WSJ data.', 'Table 2 shows the results on identifying all phrases -- chunking in CoNLL2000 ( Tjong Kim#AUTHOR_TAG ) terminology .', 'The results show that for the tasks of identifying phrases, learning directly, as done by the shallow parser outperforms the outcome from the full parser.', 'Next, we compared the performance of the parsers on the task of identifying atomic phrases 2 .', '']",5
"['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; #AUTHOR_TAG ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; #AUTHOR_TAG ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","[', along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; #AUTHOR_TAG ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; #AUTHOR_TAG ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']",0
"['earlier versions of the SNoW based CSCL were used only to identify single phrases( Punyakanok and Roth , 2001 ; #AUTHOR_TAG ) and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000( Tjong Kim Sang and Buchholz , 2000 ) to compare it to other shallow parsers']","['earlier versions of the SNoW based CSCL were used only to identify single phrases( Punyakanok and Roth , 2001 ; #AUTHOR_TAG ) and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000( Tjong Kim Sang and Buchholz , 2000 ) to compare it to other shallow parsers']","['earlier versions of the SNoW based CSCL were used only to identify single phrases( Punyakanok and Roth , 2001 ; #AUTHOR_TAG ) and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000( Tjong Kim Sang and Buchholz , 2000 ) to compare it to other shallow parsers .', 'Table 1 shows']","['earlier versions of the SNoW based CSCL were used only to identify single phrases( Punyakanok and Roth , 2001 ; #AUTHOR_TAG ) and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000( Tjong Kim Sang and Buchholz , 2000 ) to compare it to other shallow parsers .', '']",2
"['on shallow parsing was inspired by psycholinguistics arguments( #AUTHOR_TAG ) that suggest that in many scenarios ( e.g. , conversational ) full parsing is not a realistic strategy for sentence processing and analysis , and was further motivated by several arguments from a natural language engineering viewpoint']","['on shallow parsing was inspired by psycholinguistics arguments( #AUTHOR_TAG ) that suggest that in many scenarios ( e.g. , conversational ) full parsing is not a realistic strategy for sentence processing and analysis , and was further motivated by several arguments from a natural language engineering viewpoint']","['on shallow parsing was inspired by psycholinguistics arguments( #AUTHOR_TAG ) that suggest that in many scenarios ( e.g. , conversational ) full parsing is not a realistic strategy for sentence processing and analysis , and was further motivated by several arguments from a natural language engineering viewpoint']","['on shallow parsing was inspired by psycholinguistics arguments( #AUTHOR_TAG ) that suggest that in many scenarios ( e.g. , conversational ) full parsing is not a realistic strategy for sentence processing and analysis , and was further motivated by several arguments from a natural language engineering viewpoint']",0
"['perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins( #AUTHOR_TAG ; Collins , 1997 ) -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After']","['perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins( #AUTHOR_TAG ; Collins , 1997 ) -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After']","['perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins( #AUTHOR_TAG ; Collins , 1997 ) -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After']","['perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins( #AUTHOR_TAG ; Collins , 1997 ) -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After that, it will choose the candidate parse tree with the highest probability as output.', '']",5
"['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; #AUTHOR_TAG ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; #AUTHOR_TAG ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","[', along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; #AUTHOR_TAG ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; #AUTHOR_TAG ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']",0
"['shallow parser used is the SNoW-based CSCL parser( Punyakanok and Roth , 2001 ; #AUTHOR_TAG ) .', 'SNoW(Carleson et al., 1999;Roth, 1998) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example']","['shallow parser used is the SNoW-based CSCL parser( Punyakanok and Roth , 2001 ; #AUTHOR_TAG ) .', 'SNoW(Carleson et al., 1999;Roth, 1998) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', '']","['shallow parser used is the SNoW-based CSCL parser( Punyakanok and Roth , 2001 ; #AUTHOR_TAG ) .', 'SNoW(Carleson et al., 1999;Roth, 1998) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', 'It works by learning a sparse network of linear functions over a pre-defined or increment']","['shallow parser used is the SNoW-based CSCL parser( Punyakanok and Roth , 2001 ; #AUTHOR_TAG ) .', 'SNoW(Carleson et al., 1999;Roth, 1998) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', '']",5
"['', 'SNoW( Carleson et al. , 1999 ; #AUTHOR_TAG ) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '']","['', 'SNoW( Carleson et al. , 1999 ; #AUTHOR_TAG ) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '']","['shallow parser used is the SNoW-based CSCL parser(Punyakanok and Roth, 2001;Munoz et al., 1999) .', 'SNoW( Carleson et al. , 1999 ; #AUTHOR_TAG ) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '']","['shallow parser used is the SNoW-based CSCL parser(Punyakanok and Roth, 2001;Munoz et al., 1999) .', 'SNoW( Carleson et al. , 1999 ; #AUTHOR_TAG ) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '']",5
"['�He reckons the current account deficit will narrow to only $ 1.8 billion in September .�', 'would be chunked as follows ( Tjong Kim#AUTHOR_TAG ) : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP to ] [NP only $ 1.8 billion ] [PP in ] [NP September]']","['�He reckons the current account deficit will narrow to only $ 1.8 billion in September .�', 'would be chunked as follows ( Tjong Kim#AUTHOR_TAG ) : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP to ] [NP only $ 1.8 billion ] [PP in ] [NP September]']","[', the sentence �He reckons the current account deficit will narrow to only $ 1.8 billion in September .�', 'would be chunked as follows ( Tjong Kim#AUTHOR_TAG ) : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP to ] [NP only $ 1.8 billion ] [PP in ] [NP September]']","['', 'A lot of recent work on shallow parsing has been influenced by Abney�s work(Abney, 1991) , who has suggested to �chunk� sentences to base level phrases.', 'For example, the sentence �He reckons the current account deficit will narrow to only $ 1.8 billion in September .�', 'would be chunked as follows ( Tjong Kim#AUTHOR_TAG ) : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP to ] [NP only $ 1.8 billion ] [PP in ] [NP September]']",0
"['noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization( #AUTHOR_TAG ; Appelt et al. , 1993 ) .', '']","['noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization( #AUTHOR_TAG ; Appelt et al. , 1993 ) .', '']","['that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization( #AUTHOR_TAG ; Appelt et al. , 1993 ) .', '']","[', it has been noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization( #AUTHOR_TAG ; Appelt et al. , 1993 ) .', '']",0
"['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; #AUTHOR_TAG ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; #AUTHOR_TAG ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","[', along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; #AUTHOR_TAG ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; #AUTHOR_TAG ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']",0
"['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; #AUTHOR_TAG ; Tjong Kim Sang and Buchholz , 2000 )']","['years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; #AUTHOR_TAG ; Tjong Kim Sang and Buchholz , 2000 )']","[', along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; #AUTHOR_TAG ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; #AUTHOR_TAG ; Tjong Kim Sang and Buchholz , 2000 )']",0
"['information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;#AUTHOR_TAG ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;#AUTHOR_TAG ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;#AUTHOR_TAG ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']","['', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers( Collins , 1997 ; Charniak , 1997 a ;Charniak , 1997 b ;#AUTHOR_TAG ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 )']",0
"['earlier versions of the SNoW based CSCL were used only to identify single phrases( #AUTHOR_TAG ; Munoz et al. , 1999 ) and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000( Tjong Kim Sang and Buchholz , 2000 ) to compare it to other shallow parsers']","['earlier versions of the SNoW based CSCL were used only to identify single phrases( #AUTHOR_TAG ; Munoz et al. , 1999 ) and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000( Tjong Kim Sang and Buchholz , 2000 ) to compare it to other shallow parsers']","['earlier versions of the SNoW based CSCL were used only to identify single phrases( #AUTHOR_TAG ; Munoz et al. , 1999 ) and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000( Tjong Kim Sang and Buchholz , 2000 ) to compare it to other shallow parsers .', 'Table 1 shows']","['earlier versions of the SNoW based CSCL were used only to identify single phrases( #AUTHOR_TAG ; Munoz et al. , 1999 ) and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000( Tjong Kim Sang and Buchholz , 2000 ) to compare it to other shallow parsers .', '']",2
"['was done on the Penn Treebank( #AUTHOR_TAG ) Wall Street Journal data , sections 02-21 .', '']","['was done on the Penn Treebank( #AUTHOR_TAG ) Wall Street Journal data , sections 02-21 .', '']","['was done on the Penn Treebank( #AUTHOR_TAG ) Wall Street Journal data , sections 02-21 .', '']","['was done on the Penn Treebank( #AUTHOR_TAG ) Wall Street Journal data , sections 02-21 .', '']",5
"['ateisi et al. also translated LTAG into HPSG( #AUTHOR_TAG ) .', 'However, their method depended on translator�s intuitive analy- sis of the original grammar.', 'Thus the transla- tion was manual and grammar dependent.', 'The manual translation demanded considerable efforts from the translator, and obscures the equiva- lence between the original and obtained gram- mars.', 'Other works']","['ateisi et al. also translated LTAG into HPSG( #AUTHOR_TAG ) .', 'However, their method depended on translator�s intuitive analy- sis of the original grammar.', 'Thus the transla- tion was manual and grammar dependent.', 'The manual translation demanded considerable efforts from the translator, and obscures the equiva- lence between the original and obtained gram- mars.', 'Other works']","['ateisi et al. also translated LTAG into HPSG( #AUTHOR_TAG ) .', 'However, their method depended on translator�s intuitive analy- sis of the original grammar.', 'Thus the transla- tion was manual and grammar dependent.', 'The manual translation demanded considerable efforts from the translator, and obscures the equiva- lence between the original and obtained gram- mars.', 'Other works(Kasper et al., 1995; Becker and Lopez, 2000) convert HPSG grammars into LTAG grammars.', '']","['ateisi et al. also translated LTAG into HPSG( #AUTHOR_TAG ) .', 'However, their method depended on translator�s intuitive analy- sis of the original grammar.', 'Thus the transla- tion was manual and grammar dependent.', 'The manual translation demanded considerable efforts from the translator, and obscures the equiva- lence between the original and obtained gram- mars.', 'Other works(Kasper et al., 1995; Becker and Lopez, 2000) convert HPSG grammars into LTAG grammars.', '']",1
"['have been many studies on parsing techniques( Poller and Becker , 1998 ; Flickinger et al. , 2000 ) , ones on disambiguation models( Chiang , 2000 ; #AUTHOR_TAG ) , and ones on programming/grammar-development environ -(Sarkar and Wintner, 1999;Doran et al., 2000;Makino et al., 1998) .', 'These works are restricted to each closed community, and the relation between them is not']","['have been many studies on parsing techniques( Poller and Becker , 1998 ; Flickinger et al. , 2000 ) , ones on disambiguation models( Chiang , 2000 ; #AUTHOR_TAG ) , and ones on programming/grammar-development environ -(Sarkar and Wintner, 1999;Doran et al., 2000;Makino et al., 1998) .', 'These works are restricted to each closed community, and the relation between them is not']","['have been many studies on parsing techniques( Poller and Becker , 1998 ; Flickinger et al. , 2000 ) , ones on disambiguation models( Chiang , 2000 ; #AUTHOR_TAG ) , and ones on programming/grammar-development environ -(Sarkar and Wintner, 1999;Doran et al., 2000;Makino et al., 1998) .', 'These works are restricted to each closed community, and the relation between them is not well discussed.', 'Invest']","['have been many studies on parsing techniques( Poller and Becker , 1998 ; Flickinger et al. , 2000 ) , ones on disambiguation models( Chiang , 2000 ; #AUTHOR_TAG ) , and ones on programming/grammar-development environ -(Sarkar and Wintner, 1999;Doran et al., 2000;Makino et al., 1998) .', 'These works are restricted to each closed community, and the relation between them is not well discussed.', '']",0
"['which is a large-scale FB-LTAG grammar.', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser( #AUTHOR_TAG ) .', 'This result implies that parsing techniques for HPSG are also beneficial for LTAG parsing.', 'We can say that the grammar conversion enables us to share HPSG parsing techniques in LTAG parsing']","['which is a large-scale FB-LTAG grammar.', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser( #AUTHOR_TAG ) .', 'This result implies that parsing techniques for HPSG are also beneficial for LTAG parsing.', 'We can say that the grammar conversion enables us to share HPSG parsing techniques in LTAG parsing']","['which is a large-scale FB-LTAG grammar.', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser( #AUTHOR_TAG ) .', 'This result implies that parsing techniques for HPSG are also beneficial for LTAG parsing.', 'We can say that the grammar conversion enables us to share HPSG parsing techniques in LTAG parsing']","['', 'We apply our system to the latest version of the XTAG English grammar (The XTAGResearch Group, 2001) , which is a large-scale FB-LTAG grammar.', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser( #AUTHOR_TAG ) .', 'This result implies that parsing techniques for HPSG are also beneficial for LTAG parsing.', 'We can say that the grammar conversion enables us to share HPSG parsing techniques in LTAG parsing']",1
"['2, lem refers to the LTAG parser , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing (vanNoord, 1994) without features (phase 1), and then executes feature unification (phase 2).', 'TNT refers to the HPSG parser( #AUTHOR_TAG ) , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG ( phase 1 ) and then executes feature unification ( phase 2 )']","['Table 2, lem refers to the LTAG parser , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing (vanNoord, 1994) without features (phase 1), and then executes feature unification (phase 2).', 'TNT refers to the HPSG parser( #AUTHOR_TAG ) , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG ( phase 1 ) and then executes feature unification ( phase 2 )']","['Table 2, lem refers to the LTAG parser , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing (vanNoord, 1994) without features (phase 1), and then executes feature unification (phase 2).', 'TNT refers to the HPSG parser( #AUTHOR_TAG ) , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG ( phase 1 ) and then executes feature unification ( phase 2 )']","['2 shows the average parsing time with the LTAG and HPSG parsers.', 'In Table 2, lem refers to the LTAG parser , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing (vanNoord, 1994) without features (phase 1), and then executes feature unification (phase 2).', 'TNT refers to the HPSG parser( #AUTHOR_TAG ) , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG ( phase 1 ) and then executes feature unification ( phase 2 ) .', 'Table 2 clearly shows that the HPSG parser is significantly faster than the LTAG parser.', '']",1
"['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay-Shanker , 1987 ;  Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG )( #AUTHOR_TAG ) by a method of grammar conversion .', 'The']","['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay-Shanker , 1987 ;  Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG )( #AUTHOR_TAG ) by a method of grammar conversion .', 'The']","['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay-Shanker , 1987 ;  Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG )( #AUTHOR_TAG ) by a method of grammar conversion .', '']","['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay-Shanker , 1987 ;  Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG )( #AUTHOR_TAG ) by a method of grammar conversion .', '']",0
"['(Figure 4).', 'FBLTAG( Vijay-Shanker , 1987 ; #AUTHOR_TAG ) is an extension of the LTAG formalism .', '']","['(Figure 4).', 'FBLTAG( Vijay-Shanker , 1987 ; #AUTHOR_TAG ) is an extension of the LTAG formalism .', '']","['onto an internal node of another tree with the same symbol Ü (Figure 4).', 'FBLTAG( Vijay-Shanker , 1987 ; #AUTHOR_TAG ) is an extension of the LTAG formalism .', '']","['', 'FBLTAG( Vijay-Shanker , 1987 ; #AUTHOR_TAG ) is an extension of the LTAG formalism .', '']",0
"['( #AUTHOR_TAG ; Doran et al. , 2000 ; Makino et al. , 1998 ) .', 'These works are re- stricted to each closed community, and the rela- tion between them is not well discussed.', 'Investi- gating the relation will be apparently valuable for both communities']","['( #AUTHOR_TAG ; Doran et al. , 2000 ; Makino et al. , 1998 ) .', 'These works are re- stricted to each closed community, and the rela- tion between them is not well discussed.', 'Investi- gating the relation will be apparently valuable for both communities']","['( #AUTHOR_TAG ; Doran et al. , 2000 ; Makino et al. , 1998 ) .', 'These works are re- stricted to each closed community, and the rela- tion between them is not well discussed.', 'Investi- gating the relation will be apparently valuable for both communities']","['( #AUTHOR_TAG ; Doran et al. , 2000 ; Makino et al. , 1998 ) .', 'These works are re- stricted to each closed community, and the rela- tion between them is not well discussed.', 'Investi- gating the relation will be apparently valuable for both communities']",0
"['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 )( Vijay-Shanker , 1987 ; #AUTHOR_TAG ) and Head-Driven Phrase Structure Grammar ( HPSG )( Pollard and Sag , 1994 ) by a method of grammar conversion .', 'The Ren']","['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 )( Vijay-Shanker , 1987 ; #AUTHOR_TAG ) and Head-Driven Phrase Structure Grammar ( HPSG )( Pollard and Sag , 1994 ) by a method of grammar conversion .', 'The RenTAL']","['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 )( Vijay-Shanker , 1987 ; #AUTHOR_TAG ) and Head-Driven Phrase Structure Grammar ( HPSG )( Pollard and Sag , 1994 ) by a method of grammar conversion .', 'The RenTAL system automatically']","['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 )( Vijay-Shanker , 1987 ; #AUTHOR_TAG ) and Head-Driven Phrase Structure Grammar ( HPSG )( Pollard and Sag , 1994 ) by a method of grammar conversion .', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar .', '']",0
['TAG( #AUTHOR_TAG ) is a grammar formalism that provides syntactic analyses for a sentence by composing elementary trees with two opera - Figure 6: Parsing with an HPSG gram'],['TAG( #AUTHOR_TAG ) is a grammar formalism that provides syntactic analyses for a sentence by composing elementary trees with two opera - Figure 6: Parsing with an HPSG gram'],['TAG( #AUTHOR_TAG ) is a grammar formalism that provides syntactic analyses for a sentence by composing elementary trees with two opera - Figure 6: Parsing with an HPSG gram'],['TAG( #AUTHOR_TAG ) is a grammar formalism that provides syntactic analyses for a sentence by composing elementary trees with two opera - Figure 6: Parsing with an HPSG gram'],0
"['', 'In practical context , German , English , and Japanese HPSG-based grammars are developed and used in the Verbmobil project( #AUTHOR_TAG ) .', '']","['', 'In practical context , German , English , and Japanese HPSG-based grammars are developed and used in the Verbmobil project( #AUTHOR_TAG ) .', '']","['', 'In practical context , German , English , and Japanese HPSG-based grammars are developed and used in the Verbmobil project( #AUTHOR_TAG ) .', '']","['', 'In practical context , German , English , and Japanese HPSG-based grammars are developed and used in the Verbmobil project( #AUTHOR_TAG ) .', '']",0
"['', 'Our group has developed a wide-coverage HPSG grammar for Japanese( #AUTHOR_TAG ) , which is used in a high-accuracy Japanese dependency analyzer( Kanayama et al. , 2000 )']","['', 'Our group has developed a wide-coverage HPSG grammar for Japanese( #AUTHOR_TAG ) , which is used in a high-accuracy Japanese dependency analyzer( Kanayama et al. , 2000 )']","['', 'Our group has developed a wide-coverage HPSG grammar for Japanese( #AUTHOR_TAG ) , which is used in a high-accuracy Japanese dependency analyzer( Kanayama et al. , 2000 )']","['', 'Our group has developed a wide-coverage HPSG grammar for Japanese( #AUTHOR_TAG ) , which is used in a high-accuracy Japanese dependency analyzer( Kanayama et al. , 2000 )']",0
"['', 'Other works( Kasper et al. , 1995 ; #AUTHOR_TAG ) convert HPSG grammars into LTAG grammars .', '']","['', 'Other works( Kasper et al. , 1995 ; #AUTHOR_TAG ) convert HPSG grammars into LTAG grammars .', '']","['', 'Other works( Kasper et al. , 1995 ; #AUTHOR_TAG ) convert HPSG grammars into LTAG grammars .', '']","['', 'Other works( Kasper et al. , 1995 ; #AUTHOR_TAG ) convert HPSG grammars into LTAG grammars .', 'However, given the greater expressive power of HPSG, it is impossible to convert an arbitrary HPSG grammar into an LTAG grammar.', '']",1
"['', 'Our group has developed a wide-coverage HPSG grammar for Japanese( Mitsuishi et al. , 1998 ) , which is used in a high-accuracy Japanese dependency analyzer( #AUTHOR_TAG )']","['', 'Our group has developed a wide-coverage HPSG grammar for Japanese( Mitsuishi et al. , 1998 ) , which is used in a high-accuracy Japanese dependency analyzer( #AUTHOR_TAG )']","['', 'Our group has developed a wide-coverage HPSG grammar for Japanese( Mitsuishi et al. , 1998 ) , which is used in a high-accuracy Japanese dependency analyzer( #AUTHOR_TAG )']","['', 'Our group has developed a wide-coverage HPSG grammar for Japanese( Mitsuishi et al. , 1998 ) , which is used in a high-accuracy Japanese dependency analyzer( #AUTHOR_TAG )']",0
"['HPSG grammar consists of lexical entries and ID grammar rules , each of which is described with typed feature structures( #AUTHOR_TAG ) .', 'A lexical entry for each word expresses the characteristics of the word, such as the subcategorization frame and the grammatical category.', 'An']","['HPSG grammar consists of lexical entries and ID grammar rules , each of which is described with typed feature structures( #AUTHOR_TAG ) .', 'A lexical entry for each word expresses the characteristics of the word, such as the subcategorization frame and the grammatical category.', 'An']","['HPSG grammar consists of lexical entries and ID grammar rules , each of which is described with typed feature structures( #AUTHOR_TAG ) .', 'A lexical entry for each word expresses the characteristics of the word, such as the subcategorization frame and the grammatical category.', 'An ID grammar rule']","['HPSG grammar consists of lexical entries and ID grammar rules , each of which is described with typed feature structures( #AUTHOR_TAG ) .', 'A lexical entry for each word expresses the characteristics of the word, such as the subcategorization frame and the grammatical category.', '']",0
"['', 'We apply our system to the latest version of the XTAG English grammar ( The XTAG Research#AUTHOR_TAG ) , which is a large-scale FB-LTAG grammar .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing L']","['', 'We apply our system to the latest version of the XTAG English grammar ( The XTAG Research#AUTHOR_TAG ) , which is a large-scale FB-LTAG grammar .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG']","['', 'We apply our system to the latest version of the XTAG English grammar ( The XTAG Research#AUTHOR_TAG ) , which is a large-scale FB-LTAG grammar .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser .', '']","['', 'We apply our system to the latest version of the XTAG English grammar ( The XTAG Research#AUTHOR_TAG ) , which is a large-scale FB-LTAG grammar .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser .', '']",5
"['', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAGResearch Group, 2001) .', 'The XTAG group( #AUTHOR_TAG ) at the University of Pennsylvania is also developing Korean , Chinese , and Hindi grammars .', 'Development of a large-scale French grammar (Abeillé andCandito, 2000) has also started at the University of Pennsylvania and is expanded at University of Paris 7']","['', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAGResearch Group, 2001) .', 'The XTAG group( #AUTHOR_TAG ) at the University of Pennsylvania is also developing Korean , Chinese , and Hindi grammars .', 'Development of a large-scale French grammar (Abeillé andCandito, 2000) has also started at the University of Pennsylvania and is expanded at University of Paris 7']","['', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAGResearch Group, 2001) .', 'The XTAG group( #AUTHOR_TAG ) at the University of Pennsylvania is also developing Korean , Chinese , and Hindi grammars .', 'Development of a large-scale French grammar (Abeillé andCandito, 2000) has also started at the University of Pennsylvania and is expanded at University of Paris 7']","['', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAGResearch Group, 2001) .', 'The XTAG group( #AUTHOR_TAG ) at the University of Pennsylvania is also developing Korean , Chinese , and Hindi grammars .', 'Development of a large-scale French grammar (Abeillé andCandito, 2000) has also started at the University of Pennsylvania and is expanded at University of Paris 7']",0
"['', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar( #AUTHOR_TAG ) .', '']","['', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar( #AUTHOR_TAG ) .', '']","['', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar( #AUTHOR_TAG ) .', '']","['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoin-ing Grammar (FB-LTAG 1 ) (Vijay-Shanker, 1987; Vijay-Shanker and Joshi, 1988) and Head-Driven Phrase Structure Grammar (HPSG)(Pollard and Sag, 1994) by a method of grammar conversion.', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar( #AUTHOR_TAG ) .', '']",0
"['2 shows the average parsing time with the LTAG and HPSG parsers.', 'In Table 2 , lem refers to the LTAG parser( #AUTHOR_TAG ) , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing ( vanNoord , 1994 ) without features ( phase 1 ) , and then executes feature unification ( phase 2 ) .', '']","['2 shows the average parsing time with the LTAG and HPSG parsers.', 'In Table 2 , lem refers to the LTAG parser( #AUTHOR_TAG ) , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing ( vanNoord , 1994 ) without features ( phase 1 ) , and then executes feature unification ( phase 2 ) .', 'TNT refers to the HPSG parser , C++ implementation of the two-phase parsing algorithm that performs filtering with a']","['2 shows the average parsing time with the LTAG and HPSG parsers.', 'In Table 2 , lem refers to the LTAG parser( #AUTHOR_TAG ) , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing ( vanNoord , 1994 ) without features ( phase 1 ) , and then executes feature unification ( phase 2 ) .', '']","['2 shows the average parsing time with the LTAG and HPSG parsers.', 'In Table 2 , lem refers to the LTAG parser( #AUTHOR_TAG ) , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing ( vanNoord , 1994 ) without features ( phase 1 ) , and then executes feature unification ( phase 2 ) .', 'TNT refers to the HPSG parser , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG (phase 1) and then executes feature unification (phase 2).', '']",1
"['(Figure 4).', 'FBLTAG( #AUTHOR_TAG ; Vijay-Shanker and Joshi , 1988 ) is an extension of the LTAG formalism .', '']","['(Figure 4).', 'FBLTAG( #AUTHOR_TAG ; Vijay-Shanker and Joshi , 1988 ) is an extension of the LTAG formalism .', '']","['onto an internal node of another tree with the same symbol Ü (Figure 4).', 'FBLTAG( #AUTHOR_TAG ; Vijay-Shanker and Joshi , 1988 ) is an extension of the LTAG formalism .', '']","['', 'FBLTAG( #AUTHOR_TAG ; Vijay-Shanker and Joshi , 1988 ) is an extension of the LTAG formalism .', '']",0
"['are a variety of works on efficient parsing with HPSG, which allow the use of HPSGbased processing in practical application contexts .', 'Stanford University is developing the English Resource Grammar , an HPSG grammar for English , as a part of the Linguistic Grammars Online ( LinGO ) project( #AUTHOR_TAG ) .', '']","['are a variety of works on efficient parsing with HPSG, which allow the use of HPSGbased processing in practical application contexts .', 'Stanford University is developing the English Resource Grammar , an HPSG grammar for English , as a part of the Linguistic Grammars Online ( LinGO ) project( #AUTHOR_TAG ) .', '']","['are a variety of works on efficient parsing with HPSG, which allow the use of HPSGbased processing in practical application contexts .', 'Stanford University is developing the English Resource Grammar , an HPSG grammar for English , as a part of the Linguistic Grammars Online ( LinGO ) project( #AUTHOR_TAG ) .', '']","['are a variety of works on efficient parsing with HPSG, which allow the use of HPSGbased processing in practical application contexts .', 'Stanford University is developing the English Resource Grammar , an HPSG grammar for English , as a part of the Linguistic Grammars Online ( LinGO ) project( #AUTHOR_TAG ) .', '']",0
"['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques(Poller and Becker, 1998; Flickinger et al., 2000) , ones on disambiguation models(Chiang, 2000; Kanayama et al., 2000) , and ones on programming/grammar-development environment( Sarkar and Wintner , 1999 ; #AUTHOR_TAG ; Makino et al. , 1998 ) .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques(Poller and Becker, 1998; Flickinger et al., 2000) , ones on disambiguation models(Chiang, 2000; Kanayama et al., 2000) , and ones on programming/grammar-development environment( Sarkar and Wintner , 1999 ; #AUTHOR_TAG ; Makino et al. , 1998 ) .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques(Poller and Becker, 1998; Flickinger et al., 2000) , ones on disambiguation models(Chiang, 2000; Kanayama et al., 2000) , and ones on programming/grammar-development environment( Sarkar and Wintner , 1999 ; #AUTHOR_TAG ; Makino et al. , 1998 ) .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques(Poller and Becker, 1998; Flickinger et al., 2000) , ones on disambiguation models(Chiang, 2000; Kanayama et al., 2000) , and ones on programming/grammar-development environment( Sarkar and Wintner , 1999 ; #AUTHOR_TAG ; Makino et al. , 1998 ) .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities']",0
"['RenTAL system is implemented in LiL-FeS(Makino et al., 1998) 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic , and efficient HPSG parsers have already been built on this system( Nishida et al. , 1999 ; #AUTHOR_TAG ) .', 'We applied our system to the XTAG English grammar (']","['RenTAL system is implemented in LiL-FeS(Makino et al., 1998) 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic , and efficient HPSG parsers have already been built on this system( Nishida et al. , 1999 ; #AUTHOR_TAG ) .', 'We applied our system to the XTAG English grammar (The']","['RenTAL system is implemented in LiL-FeS(Makino et al., 1998) 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic , and efficient HPSG parsers have already been built on this system( Nishida et al. , 1999 ; #AUTHOR_TAG ) .', 'We applied our system to the XTAG English grammar (']","['RenTAL system is implemented in LiL-FeS(Makino et al., 1998) 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic , and efficient HPSG parsers have already been built on this system( Nishida et al. , 1999 ; #AUTHOR_TAG ) .', '']",0
"['', 'Another paper( #AUTHOR_TAG ) describes the detailed analysis on the factor of the difference of parsing performance']","['', 'Another paper( #AUTHOR_TAG ) describes the detailed analysis on the factor of the difference of parsing performance']","['', 'Another paper( #AUTHOR_TAG ) describes the detailed analysis on the factor of the difference of parsing performance']","['', 'Another paper( #AUTHOR_TAG ) describes the detailed analysis on the factor of the difference of parsing performance']",0
"['', 'The original and the obtained grammar generated exactly the same number of derivation trees in the parsing experiment with 457 sentences from the ATIS corpus( #AUTHOR_TAG ) 6 ( the average length is 6.32 words ) .', 'This result empirically attested the strong equivalence of our algorithm']","['a large-scale FB-LTAG grammar for English.', 'The original and the obtained grammar generated exactly the same number of derivation trees in the parsing experiment with 457 sentences from the ATIS corpus( #AUTHOR_TAG ) 6 ( the average length is 6.32 words ) .', 'This result empirically attested the strong equivalence of our algorithm']","['', 'The original and the obtained grammar generated exactly the same number of derivation trees in the parsing experiment with 457 sentences from the ATIS corpus( #AUTHOR_TAG ) 6 ( the average length is 6.32 words ) .', 'This result empirically attested the strong equivalence of our algorithm']","['', 'We applied our system to the XTAG English grammar (The XTAGResearch Group, 2001) 3 , which is a large-scale FB-LTAG grammar for English.', 'The original and the obtained grammar generated exactly the same number of derivation trees in the parsing experiment with 457 sentences from the ATIS corpus( #AUTHOR_TAG ) 6 ( the average length is 6.32 words ) .', 'This result empirically attested the strong equivalence of our algorithm']",5
"['RenTAL system is implemented in LiLFeS( #AUTHOR_TAG ) 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic, and efficient HPSG parsers have already been built on this system(Nishida et al., 1999; .', 'We applied our system to the XTAG English grammar']","['RenTAL system is implemented in LiLFeS( #AUTHOR_TAG ) 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic, and efficient HPSG parsers have already been built on this system(Nishida et al., 1999; .', 'We applied our system to the XTAG English grammar']","['RenTAL system is implemented in LiLFeS( #AUTHOR_TAG ) 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic, and efficient HPSG parsers have already been built on this system(Nishida et al., 1999; .', 'We applied our system to the XTAG English grammar']","['RenTAL system is implemented in LiLFeS( #AUTHOR_TAG ) 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic, and efficient HPSG parsers have already been built on this system(Nishida et al., 1999; .', '']",5
"['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 )( #AUTHOR_TAG ; Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG )( Pollard and Sag , 1994 ) by a method of grammar conversion .', 'The Ren']","['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 )( #AUTHOR_TAG ; Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG )( Pollard and Sag , 1994 ) by a method of grammar conversion .', 'The RenTAL']","['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 )( #AUTHOR_TAG ; Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG )( Pollard and Sag , 1994 ) by a method of grammar conversion .', 'The RenTAL system automatically']","['paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 )( #AUTHOR_TAG ; Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG )( Pollard and Sag , 1994 ) by a method of grammar conversion .', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar .', '']",0
"['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques(Poller and Becker, 1998; Flickinger et al., 2000) , ones on disambiguation models(Chiang, 2000; Kanayama et al., 2000) , and ones on programming/grammar-development( Sarkar and Wintner , 1999 ; Doran et al. , 2000 ; #AUTHOR_TAG ) .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques(Poller and Becker, 1998; Flickinger et al., 2000) , ones on disambiguation models(Chiang, 2000; Kanayama et al., 2000) , and ones on programming/grammar-development( Sarkar and Wintner , 1999 ; Doran et al. , 2000 ; #AUTHOR_TAG ) .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques(Poller and Becker, 1998; Flickinger et al., 2000) , ones on disambiguation models(Chiang, 2000; Kanayama et al., 2000) , and ones on programming/grammar-development( Sarkar and Wintner , 1999 ; Doran et al. , 2000 ; #AUTHOR_TAG ) .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques(Poller and Becker, 1998; Flickinger et al., 2000) , ones on disambiguation models(Chiang, 2000; Kanayama et al., 2000) , and ones on programming/grammar-development( Sarkar and Wintner , 1999 ; Doran et al. , 2000 ; #AUTHOR_TAG ) .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities']",0
"['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques( #AUTHOR_TAG ; Flickinger et al. , 2000 ) , ones on disambiguation models( Chiang , 2000 ; Kanayama et al. , 2000 ) , and ones on programming/grammar-development environment(Sarkar and Wintner, 1999; Doran et al., 2000; Makino et al., 1998) .', 'These works are restricted to each closed community, and the relation']","['grammars and lexicons.', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques( #AUTHOR_TAG ; Flickinger et al. , 2000 ) , ones on disambiguation models( Chiang , 2000 ; Kanayama et al. , 2000 ) , and ones on programming/grammar-development environment(Sarkar and Wintner, 1999; Doran et al., 2000; Makino et al., 1998) .', 'These works are restricted to each closed community, and the relation']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques( #AUTHOR_TAG ; Flickinger et al. , 2000 ) , ones on disambiguation models( Chiang , 2000 ; Kanayama et al. , 2000 ) , and ones on programming/grammar-development environment(Sarkar and Wintner, 1999; Doran et al., 2000; Makino et al., 1998) .', 'These works are restricted to each closed community, and the relation']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques( #AUTHOR_TAG ; Flickinger et al. , 2000 ) , ones on disambiguation models( Chiang , 2000 ; Kanayama et al. , 2000 ) , and ones on programming/grammar-development environment(Sarkar and Wintner, 1999; Doran et al., 2000; Makino et al., 1998) .', 'These works are restricted to each closed community, and the relation between them is not well discussed.', '']",0
['grammar conversion from LTAG to HPSG( #AUTHOR_TAG ) is the core portion of the RenTAL system'],['grammar conversion from LTAG to HPSG( #AUTHOR_TAG ) is the core portion of the RenTAL system'],['grammar conversion from LTAG to HPSG( #AUTHOR_TAG ) is the core portion of the RenTAL system'],['grammar conversion from LTAG to HPSG( #AUTHOR_TAG ) is the core portion of the RenTAL system'],0
"['.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism , including the XTAG English grammar , a large-scale grammar for English ( The XTAG Research#AUTHOR_TAG ) .', 'The XTAG group(Doran et al., 2000) at the University of Pennsylvania is also developing Korean, Chinese, and Hindi grammars.', 'Development of a large-scale French grammar (Abeillé andCandito, 2000) has also started at the University of Pennsylvania and is expanded at University of Paris 7']","['on the node.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism , including the XTAG English grammar , a large-scale grammar for English ( The XTAG Research#AUTHOR_TAG ) .', 'The XTAG group(Doran et al., 2000) at the University of Pennsylvania is also developing Korean, Chinese, and Hindi grammars.', 'Development of a large-scale French grammar (Abeillé andCandito, 2000) has also started at the University of Pennsylvania and is expanded at University of Paris 7']","['a feature structure, containing grammatical constraints on the node.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism , including the XTAG English grammar , a large-scale grammar for English ( The XTAG Research#AUTHOR_TAG ) .', 'The XTAG group(Doran et al., 2000) at the University of Pennsylvania is also developing Korean, Chinese, and Hindi grammars.', 'Development of a large-scale French grammar (Abeillé andCandito, 2000) has also started at the University of Pennsylvania and is expanded at University of Paris 7']","['', 'In FB-LTAG, each node in the elementary trees has a feature structure, containing grammatical constraints on the node.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism , including the XTAG English grammar , a large-scale grammar for English ( The XTAG Research#AUTHOR_TAG ) .', 'The XTAG group(Doran et al., 2000) at the University of Pennsylvania is also developing Korean, Chinese, and Hindi grammars.', 'Development of a large-scale French grammar (Abeillé andCandito, 2000) has also started at the University of Pennsylvania and is expanded at University of Paris 7']",0
"['', 'We applied our system to the XTAG English grammar ( The XTAG Research#AUTHOR_TAG ) 3 , which is a large-scale FB-LTAG grammar for English .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser']","['', 'We applied our system to the XTAG English grammar ( The XTAG Research#AUTHOR_TAG ) 3 , which is a large-scale FB-LTAG grammar for English .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser']","['', 'We applied our system to the XTAG English grammar ( The XTAG Research#AUTHOR_TAG ) 3 , which is a large-scale FB-LTAG grammar for English .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser .', '']","['', 'We applied our system to the XTAG English grammar ( The XTAG Research#AUTHOR_TAG ) 3 , which is a large-scale FB-LTAG grammar for English .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser .', '']",5
"['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( #AUTHOR_TAG ; Krovetz , 1993 ; Hull , 1996 ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( #AUTHOR_TAG ; Krovetz , 1993 ; Hull , 1996 ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Empirical']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( #AUTHOR_TAG ; Krovetz , 1993 ; Hull , 1996 ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( #AUTHOR_TAG ; Krovetz , 1993 ; Hull , 1996 ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', '']",0
"['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; #AUTHOR_TAG )']","['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; #AUTHOR_TAG )']","['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; #AUTHOR_TAG )']","['', 'From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; #AUTHOR_TAG )']",0
"['efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers( #AUTHOR_TAG ; Porter , 1980 ) demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988;Choueka, 1990;Popovic and Willett, 1992; Ekmekçioglu et al., 1995;Hedlund et al., 2001;Pirkola, 2001) .', '']","['efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers( #AUTHOR_TAG ; Porter , 1980 ) demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988;Choueka, 1990;Popovic and Willett, 1992; Ekmekçioglu et al., 1995;Hedlund et al., 2001;Pirkola, 2001) .', '']","['efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers( #AUTHOR_TAG ; Porter , 1980 ) demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988;Choueka, 1990;Popovic and Willett, 1992; Ekmekçioglu et al., 1995;Hedlund et al., 2001;Pirkola, 2001) .', '']","['efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers( #AUTHOR_TAG ; Porter , 1980 ) demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988;Choueka, 1990;Popovic and Willett, 1992; Ekmekçioglu et al., 1995;Hedlund et al., 2001;Pirkola, 2001) .', '']",0
"['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; #AUTHOR_TAG ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; #AUTHOR_TAG ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Empirical']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; #AUTHOR_TAG ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; #AUTHOR_TAG ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', '']",0
"['efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers( Lovins , 1968 ; #AUTHOR_TAG ) demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988;Choueka, 1990;Popovic and Willett, 1992; Ekmekçioglu et al., 1995;Hedlund et al., 2001;Pirkola, 2001) .', '']","['efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers( Lovins , 1968 ; #AUTHOR_TAG ) demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988;Choueka, 1990;Popovic and Willett, 1992; Ekmekçioglu et al., 1995;Hedlund et al., 2001;Pirkola, 2001) .', '']","['efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers( Lovins , 1968 ; #AUTHOR_TAG ) demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988;Choueka, 1990;Popovic and Willett, 1992; Ekmekçioglu et al., 1995;Hedlund et al., 2001;Pirkola, 2001) .', '']","['efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers( Lovins , 1968 ; #AUTHOR_TAG ) demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988;Choueka, 1990;Popovic and Willett, 1992; Ekmekçioglu et al., 1995;Hedlund et al., 2001;Pirkola, 2001) .', '']",0
"['phological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system( Choueka , 1990 ;  J Â¨ appinen and Niemist Â¨ o , 1988 ;#AUTHOR_TAG ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '']","['phological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system( Choueka , 1990 ;  J Â¨ appinen and Niemist Â¨ o , 1988 ;#AUTHOR_TAG ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '']","['phological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system( Choueka , 1990 ;  J Â¨ appinen and Niemist Â¨ o , 1988 ;#AUTHOR_TAG ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '']","['phological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system( Choueka , 1990 ;  J Â¨ appinen and Niemist Â¨ o , 1988 ;#AUTHOR_TAG ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '']",0
"['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; #AUTHOR_TAG ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; #AUTHOR_TAG ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; #AUTHOR_TAG ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['', 'From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; #AUTHOR_TAG ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']",0
"['has been some controversy , at least for simple stemmers( Lovins , 1968 ; #AUTHOR_TAG ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .', 'The key for']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; #AUTHOR_TAG ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .', 'The key for']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; #AUTHOR_TAG ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .', 'The key for quality improvement seems']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; #AUTHOR_TAG ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .', '']",0
"['but at high ones its precision decreases almost dramatically.', 'Unless very high rates of misspellings are to be expected ( this explains the favorable results for trigram indexing in( #AUTHOR_TAG ) ) one can not really recommend this method']","['but at high ones its precision decreases almost dramatically.', 'Unless very high rates of misspellings are to be expected ( this explains the favorable results for trigram indexing in( #AUTHOR_TAG ) ) one can not really recommend this method']","['but at high ones its precision decreases almost dramatically.', 'Unless very high rates of misspellings are to be expected ( this explains the favorable results for trigram indexing in( #AUTHOR_TAG ) ) one can not really recommend this method']","['but at high ones its precision decreases almost dramatically.', 'Unless very high rates of misspellings are to be expected ( this explains the favorable results for trigram indexing in( #AUTHOR_TAG ) ) one can not really recommend this method']",1
"['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; #AUTHOR_TAG ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; #AUTHOR_TAG ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; #AUTHOR_TAG ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['', 'From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; #AUTHOR_TAG ; Dujols et al. , 1991 ; Baud et al. , 1998 )']",0
"['.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories( Krovetz , 1993 ; #AUTHOR_TAG ; Tzoukermann et al. , 1997 )']","['dictionary.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories( Krovetz , 1993 ; #AUTHOR_TAG ; Tzoukermann et al. , 1997 )']","['.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories( Krovetz , 1993 ; #AUTHOR_TAG ; Tzoukermann et al. , 1997 )']","['', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories( Krovetz , 1993 ; #AUTHOR_TAG ; Tzoukermann et al. , 1997 )']",0
"['', 'The retrieval process relies on the vector space model( #AUTHOR_TAG ) , with the cosine measure expressing the similarity between a query and a document .', '']","['', 'The retrieval process relies on the vector space model( #AUTHOR_TAG ) , with the cosine measure expressing the similarity between a query and a document .', '']","['', 'The retrieval process relies on the vector space model( #AUTHOR_TAG ) , with the cosine measure expressing the similarity between a query and a document .', '']","['', 'The retrieval process relies on the vector space model( #AUTHOR_TAG ) , with the cosine measure expressing the similarity between a query and a document .', '']",5
"['has been some controversy , at least for simple stemmers( #AUTHOR_TAG ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .', 'The key for']","['has been some controversy , at least for simple stemmers( #AUTHOR_TAG ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .', 'The key for']","['has been some controversy , at least for simple stemmers( #AUTHOR_TAG ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .', 'The key for quality improvement seems']","['has been some controversy , at least for simple stemmers( #AUTHOR_TAG ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .', '']",0
"['', 'While this is simply irrelevant for general-purpose morphological analyzers , dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting( #AUTHOR_TAG )']","['', 'While this is simply irrelevant for general-purpose morphological analyzers , dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting( #AUTHOR_TAG )']","[', medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language (e.g., German), often referred to as neo-classical compounding (Mc-Cray et al., 1988) .', 'While this is simply irrelevant for general-purpose morphological analyzers , dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting( #AUTHOR_TAG )']","[', medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language (e.g., German), often referred to as neo-classical compounding (Mc-Cray et al., 1988) .', 'While this is simply irrelevant for general-purpose morphological analyzers , dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting( #AUTHOR_TAG )']",0
"['and documents.', 'This will become even more interesting when mappings of our synonym identifiers to a large medical thesaurus ( MeSH ,( #AUTHOR_TAG ) ) are incorporated into our system .', '']","['and documents.', 'This will become even more interesting when mappings of our synonym identifiers to a large medical thesaurus ( MeSH ,( #AUTHOR_TAG ) ) are incorporated into our system .', '']","['and documents.', 'This will become even more interesting when mappings of our synonym identifiers to a large medical thesaurus ( MeSH ,( #AUTHOR_TAG ) ) are incorporated into our system .', '']","['', 'This will become even more interesting when mappings of our synonym identifiers to a large medical thesaurus ( MeSH ,( #AUTHOR_TAG ) ) are incorporated into our system .', '']",3
"['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; #AUTHOR_TAG ; Hull , 1996 ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; #AUTHOR_TAG ; Hull , 1996 ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Empirical']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; #AUTHOR_TAG ; Hull , 1996 ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['has been some controversy , at least for simple stemmers( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval( Harman , 1991 ; #AUTHOR_TAG ; Hull , 1996 ) .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', '']",0
"['mers(Lovins, 1968; Porter, 1980) demonstrably improve retrieval performance.', 'This has been reported for other languages , too , dependent on the generality of the chosen approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ;Choueka , 1990 ; #AUTHOR_TAG ; Ekmekc Â¸ ioglu et al. , 1995 ;Hedlund et al. , 2001 ; Pirkola , 2001 ) .', '']","['efforts required for performing morphologi- cal analysis vary from language to language.', 'For English, known for its limited number of inflection patterns, lexicon-free general-purpose stemmers(Lovins, 1968; Porter, 1980) demonstrably improve retrieval performance.', 'This has been reported for other languages , too , dependent on the generality of the chosen approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ;Choueka , 1990 ; #AUTHOR_TAG ; Ekmekc Â¸ ioglu et al. , 1995 ;Hedlund et al. , 2001 ; Pirkola , 2001 ) .', '']","['patterns, lexicon-free general-purpose stemmers(Lovins, 1968; Porter, 1980) demonstrably improve retrieval performance.', 'This has been reported for other languages , too , dependent on the generality of the chosen approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ;Choueka , 1990 ; #AUTHOR_TAG ; Ekmekc Â¸ ioglu et al. , 1995 ;Hedlund et al. , 2001 ; Pirkola , 2001 ) .', '']","['efforts required for performing morphologi- cal analysis vary from language to language.', 'For English, known for its limited number of inflection patterns, lexicon-free general-purpose stemmers(Lovins, 1968; Porter, 1980) demonstrably improve retrieval performance.', 'This has been reported for other languages , too , dependent on the generality of the chosen approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ;Choueka , 1990 ; #AUTHOR_TAG ; Ekmekc Â¸ ioglu et al. , 1995 ;Hedlund et al. , 2001 ; Pirkola , 2001 ) .', '']",0
"['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; #AUTHOR_TAG ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; #AUTHOR_TAG ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; #AUTHOR_TAG ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['', 'From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( Pacak et al. , 1980 ; #AUTHOR_TAG ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']",0
"['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( #AUTHOR_TAG ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( #AUTHOR_TAG ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( #AUTHOR_TAG ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']","['', 'From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition( #AUTHOR_TAG ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 )']",0
"[')) are incorporated into our system.', 'Alternatively , we may think of user-centered comparative studies( #AUTHOR_TAG )']","['are incorporated into our system.', 'Alternatively , we may think of user-centered comparative studies( #AUTHOR_TAG )']","[')) are incorporated into our system.', 'Alternatively , we may think of user-centered comparative studies( #AUTHOR_TAG )']","['', 'Alternatively , we may think of user-centered comparative studies( #AUTHOR_TAG )']",3
"['.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories( Krovetz , 1993 ; Kraaij and Pohlmann , 1996 ; #AUTHOR_TAG )']","['dictionary.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories( Krovetz , 1993 ; Kraaij and Pohlmann , 1996 ; #AUTHOR_TAG )']","['.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories( Krovetz , 1993 ; Kraaij and Pohlmann , 1996 ; #AUTHOR_TAG )']","['', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories( Krovetz , 1993 ; Kraaij and Pohlmann , 1996 ; #AUTHOR_TAG )']",0
"['documents.', 'Hence , enumerating morphological variants in a semi-automatically generated lexicon , such as proposed for French( #AUTHOR_TAG ) , turns out to be infeasible , at least for German and related languages']","['documents.', 'Hence , enumerating morphological variants in a semi-automatically generated lexicon , such as proposed for French( #AUTHOR_TAG ) , turns out to be infeasible , at least for German and related languages']","['relevant documents.', 'Hence , enumerating morphological variants in a semi-automatically generated lexicon , such as proposed for French( #AUTHOR_TAG ) , turns out to be infeasible , at least for German and related languages']","['', 'Hence , enumerating morphological variants in a semi-automatically generated lexicon , such as proposed for French( #AUTHOR_TAG ) , turns out to be infeasible , at least for German and related languages']",0
"['approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ;Choueka , 1990 ; Popovic and Willett , 1992 ;  Ekmekc Â¸ ioglu et al. , 1995 ;Hedlund et al. , 2001 ; #AUTHOR_TAG ) .', '']","['approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ;Choueka , 1990 ; Popovic and Willett , 1992 ;  Ekmekc Â¸ ioglu et al. , 1995 ;Hedlund et al. , 2001 ; #AUTHOR_TAG ) .', '']","['( J Â¨ appinen and Niemist Â¨ o , 1988 ;Choueka , 1990 ; Popovic and Willett , 1992 ;  Ekmekc Â¸ ioglu et al. , 1995 ;Hedlund et al. , 2001 ; #AUTHOR_TAG ) .', '']","['', 'This has been reported for other languages , too , dependent on the generality of the chosen approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ;Choueka , 1990 ; Popovic and Willett , 1992 ;  Ekmekc Â¸ ioglu et al. , 1995 ;Hedlund et al. , 2001 ; #AUTHOR_TAG ) .', '']",0
"['phological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system( #AUTHOR_TAG ; J Â¨ appinen and Niemist Â¨ o , 1988 ;Kraaij and Pohlmann , 1996 ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved']","['phological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system( #AUTHOR_TAG ; J Â¨ appinen and Niemist Â¨ o , 1988 ;Kraaij and Pohlmann , 1996 ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved']","['phological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system( #AUTHOR_TAG ; J Â¨ appinen and Niemist Â¨ o , 1988 ;Kraaij and Pohlmann , 1996 ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '']","['phological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system( #AUTHOR_TAG ; J Â¨ appinen and Niemist Â¨ o , 1988 ;Kraaij and Pohlmann , 1996 ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '']",0
"[', medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language ( e.g. , German ) , often referred to as neo-classical compounding( #AUTHOR_TAG ) .', 'While this is simply irrelevant for general-purpose morphological analyzers, dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting(Wolff, 1984)']","[', medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language ( e.g. , German ) , often referred to as neo-classical compounding( #AUTHOR_TAG ) .', 'While this is simply irrelevant for general-purpose morphological analyzers, dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting(Wolff, 1984)']","[', medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language ( e.g. , German ) , often referred to as neo-classical compounding( #AUTHOR_TAG ) .', 'While this is simply irrelevant for general-purpose morphological analyzers, dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting(Wolff, 1984)']","[', medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language ( e.g. , German ) , often referred to as neo-classical compounding( #AUTHOR_TAG ) .', 'While this is simply irrelevant for general-purpose morphological analyzers, dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting(Wolff, 1984)']",0
"['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( #AUTHOR_TAG ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( #AUTHOR_TAG ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( #AUTHOR_TAG ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( #AUTHOR_TAG ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']",0
"['correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) ,( #AUTHOR_TAG )']","['correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) ,( #AUTHOR_TAG )']","['structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) ,( #AUTHOR_TAG )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) ,( #AUTHOR_TAG )']",0
"['this paper , a flexible annotation schema called Structured String-Tree Correspondence ( SSTC )( #AUTHOR_TAG ) will be introduced to capture a natural language text , its corresponding abstract linguistic representation and the mapping ( correspondence ) between these two .', 'The correspondence between the string and its associated representation tree structure is defined in terms of the sub-correspondence between parts of the string (substrings) and parts of the tree structure (subtrees), which can']","['this paper , a flexible annotation schema called Structured String-Tree Correspondence ( SSTC )( #AUTHOR_TAG ) will be introduced to capture a natural language text , its corresponding abstract linguistic representation and the mapping ( correspondence ) between these two .', 'The correspondence between the string and its associated representation tree structure is defined in terms of the sub-correspondence between parts of the string (substrings) and parts of the tree structure (subtrees), which can']","['this paper , a flexible annotation schema called Structured String-Tree Correspondence ( SSTC )( #AUTHOR_TAG ) will be introduced to capture a natural language text , its corresponding abstract linguistic representation and the mapping ( correspondence ) between these two .', 'The correspondence between the string and its associated representation tree structure is defined in terms of the sub-correspondence between parts of the string (substrings) and parts of the tree structure (subtrees), which']","['this paper , a flexible annotation schema called Structured String-Tree Correspondence ( SSTC )( #AUTHOR_TAG ) will be introduced to capture a natural language text , its corresponding abstract linguistic representation and the mapping ( correspondence ) between these two .', 'The correspondence between the string and its associated representation tree structure is defined in terms of the sub-correspondence between parts of the string (substrings) and parts of the tree structure (subtrees), which can be interpreted for both analysis and generation.', '']",0
"['', 'These features are very much desired in the design of an annotation scheme , in particular for the treatment of linguistic phenomena , which are non-standard , e.g. crossed dependencies( #AUTHOR_TAG ) .', 'crossed dependencies(Tang & Zaharin, 1995)']","['', 'These features are very much desired in the design of an annotation scheme , in particular for the treatment of linguistic phenomena , which are non-standard , e.g. crossed dependencies( #AUTHOR_TAG ) .', 'crossed dependencies(Tang & Zaharin, 1995)']","['(Boitet & Zaharin, 1988) .', 'These features are very much desired in the design of an annotation scheme , in particular for the treatment of linguistic phenomena , which are non-standard , e.g. crossed dependencies( #AUTHOR_TAG ) .', 'crossed dependencies(Tang & Zaharin, 1995)']","['', 'These features are very much desired in the design of an annotation scheme , in particular for the treatment of linguistic phenomena , which are non-standard , e.g. crossed dependencies( #AUTHOR_TAG ) .', 'crossed dependencies(Tang & Zaharin, 1995)']",0
"['', 'Towards this aim , a flexible annotation structure called Structured String-Tree Correspondence ( SSTC ) was introduced in#AUTHOR_TAG to record the string of terms , its associated representation structure and the mapping between the two , which is expressed by the sub-correspondences recorded as part of a SSTC']","['', 'Towards this aim , a flexible annotation structure called Structured String-Tree Correspondence ( SSTC ) was introduced in#AUTHOR_TAG to record the string of terms , its associated representation structure and the mapping between the two , which is expressed by the sub-correspondences recorded as part of a SSTC']","['', 'Towards this aim , a flexible annotation structure called Structured String-Tree Correspondence ( SSTC ) was introduced in#AUTHOR_TAG to record the string of terms , its associated representation structure and the mapping between the two , which is expressed by the sub-correspondences recorded as part of a SSTC']","['', 'Towards this aim , a flexible annotation structure called Structured String-Tree Correspondence ( SSTC ) was introduced in#AUTHOR_TAG to record the string of terms , its associated representation structure and the mapping between the two , which is expressed by the sub-correspondences recorded as part of a SSTC']",0
"['', '#AUTHOR_TAG presented an approach for constructing a BKB based on the S-SSTC']","['', '#AUTHOR_TAG presented an approach for constructing a BKB based on the S-SSTC']","['', '#AUTHOR_TAG presented an approach for constructing a BKB based on the S-SSTC']","['', '#AUTHOR_TAG presented an approach for constructing a BKB based on the S-SSTC']",0
"[', such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( #AUTHOR_TAG ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","[', such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( #AUTHOR_TAG ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","[', such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( #AUTHOR_TAG ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( #AUTHOR_TAG ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']",0
"['', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by(Shieber & Schabes,1990) to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL( Shieber , 1994 ) ,( #AUTHOR_TAG ) .', '']","['', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by(Shieber & Schabes,1990) to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL( Shieber , 1994 ) ,( #AUTHOR_TAG ) .', '']","['', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by(Shieber & Schabes,1990) to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL( Shieber , 1994 ) ,( #AUTHOR_TAG ) .', '']","['', 'For example, synchronous Tree Adjoining Grammar (S-TAG) can be used to relate TAGs for two different languages, for example, for the purpose of immediate structural translation in machine translation (Abeillé et al.,1990),(Harbusch & Poller,1996) , or for relating a syntactic TAG and semantic one for the same language(Shieber & Schabes,1990) .', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by(Shieber & Schabes,1990) to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL( Shieber , 1994 ) ,( #AUTHOR_TAG ) .', 'As a result,Shieber (1994) propose a restricted definition for S-TAG, namely, the IS-TAG for isomorphic S-TAG.', '']",0
"['the Meaning-Text Theory ( MTT ) 1 point of view , Natural Language ( NL ) is considered as a correspondence between meanings and texts( #AUTHOR_TAG ) .', 'The MTT point of view, even if it has been introduced in different formulations, is more or less accepted by the whole linguistic community']","['the Meaning-Text Theory ( MTT ) 1 point of view , Natural Language ( NL ) is considered as a correspondence between meanings and texts( #AUTHOR_TAG ) .', 'The MTT point of view, even if it has been introduced in different formulations, is more or less accepted by the whole linguistic community']","['the Meaning-Text Theory ( MTT ) 1 point of view , Natural Language ( NL ) is considered as a correspondence between meanings and texts( #AUTHOR_TAG ) .', 'The MTT point of view, even if it has been introduced in different formulations, is more or less accepted by the whole linguistic community']","['the Meaning-Text Theory ( MTT ) 1 point of view , Natural Language ( NL ) is considered as a correspondence between meanings and texts( #AUTHOR_TAG ) .', 'The MTT point of view, even if it has been introduced in different formulations, is more or less accepted by the whole linguistic community']",0
"['or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( #AUTHOR_TAG ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( #AUTHOR_TAG ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( #AUTHOR_TAG ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( #AUTHOR_TAG ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']",0
"['mentioned earlier, there are some non-standard phenomena exist between different languages, that cause challenges for synchronized formalisms.', 'In this Section , we will describe some example cases , which are drawn from the problem of using synchronous formalisms to define translations between languages ( e.g.#AUTHOR_TAG cases ) .', '']","['mentioned earlier, there are some non-standard phenomena exist between different languages, that cause challenges for synchronized formalisms.', 'In this Section , we will describe some example cases , which are drawn from the problem of using synchronous formalisms to define translations between languages ( e.g.#AUTHOR_TAG cases ) .', '']","['mentioned earlier, there are some non-standard phenomena exist between different languages, that cause challenges for synchronized formalisms.', 'In this Section , we will describe some example cases , which are drawn from the problem of using synchronous formalisms to define translations between languages ( e.g.#AUTHOR_TAG cases ) .', '']","['mentioned earlier, there are some non-standard phenomena exist between different languages, that cause challenges for synchronized formalisms.', 'In this Section , we will describe some example cases , which are drawn from the problem of using synchronous formalisms to define translations between languages ( e.g.#AUTHOR_TAG cases ) .', '']",0
"['such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( #AUTHOR_TAG ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( #AUTHOR_TAG ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( #AUTHOR_TAG ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( #AUTHOR_TAG ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']",0
"['is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures( #AUTHOR_TAG ) , such as the relation between syntax and semantic']","['is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures( #AUTHOR_TAG ) , such as the relation between syntax and semantic']","['is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures( #AUTHOR_TAG ) , such as the relation between syntax and semantic']","['is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures( #AUTHOR_TAG ) , such as the relation between syntax and semantic']",0
"['', ""For instance, when building translation units in EBMT approaches( Richardson et al. , 2001 ) ,( Aramaki , 2001 ) , ( AlAdhaileh & Tang , 1999 ) ,( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( #AUTHOR_TAG ) , etc. , where S-SSTC can be used to represent the entries of the BKB or when S-SSTC used as an annotation schema to find the translation correspondences (lexical and structural correspondences) for transferrules' extraction from parallel parsed cor""]","['', ""For instance, when building translation units in EBMT approaches( Richardson et al. , 2001 ) ,( Aramaki , 2001 ) , ( AlAdhaileh & Tang , 1999 ) ,( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( #AUTHOR_TAG ) , etc. , where S-SSTC can be used to represent the entries of the BKB or when S-SSTC used as an annotation schema to find the translation correspondences (lexical and structural correspondences) for transferrules' extraction from parallel parsed cor""]","['', ""For instance, when building translation units in EBMT approaches( Richardson et al. , 2001 ) ,( Aramaki , 2001 ) , ( AlAdhaileh & Tang , 1999 ) ,( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( #AUTHOR_TAG ) , etc. , where S-SSTC can be used to represent the entries of the BKB or when S-SSTC used as an annotation schema to find the translation correspondences (lexical and structural correspondences) for transferrules' extraction from parallel parsed cor""]","['', ""For instance, when building translation units in EBMT approaches( Richardson et al. , 2001 ) ,( Aramaki , 2001 ) , ( AlAdhaileh & Tang , 1999 ) ,( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( #AUTHOR_TAG ) , etc. , where S-SSTC can be used to represent the entries of the BKB or when S-SSTC used as an annotation schema to find the translation correspondences (lexical and structural correspondences) for transferrules' extraction from parallel parsed cor""]",0
"['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( #AUTHOR_TAG ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( #AUTHOR_TAG ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['to realize additional power and flexibility in expressing structural correspondences at the level of language sentence pairs.', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( #AUTHOR_TAG ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( #AUTHOR_TAG ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']",0
"['is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures( #AUTHOR_TAG )']","['is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures( #AUTHOR_TAG )']","['is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures( #AUTHOR_TAG )']","['is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures( #AUTHOR_TAG )']",0
"['box up"".', 'For more details on the proprieties of SSTC , see#AUTHOR_TAG']","['box up"".', 'For more details on the proprieties of SSTC , see#AUTHOR_TAG']","['the box up"".', 'For more details on the proprieties of SSTC , see#AUTHOR_TAG']","['', 'For more details on the proprieties of SSTC , see#AUTHOR_TAG']",0
"['string in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in( #AUTHOR_TAG ) andBoitet & Zaharin ( 1988 ) .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree']","['', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in( #AUTHOR_TAG ) andBoitet & Zaharin ( 1988 ) .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree']","['', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in( #AUTHOR_TAG ) andBoitet & Zaharin ( 1988 ) .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree']","['', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in( #AUTHOR_TAG ) andBoitet & Zaharin ( 1988 ) .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree']",5
"[', 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( #AUTHOR_TAG ) , ( Al-Adhaileh & Tang , 1999 )']","[', 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( #AUTHOR_TAG ) , ( Al-Adhaileh & Tang , 1999 )']","['( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( #AUTHOR_TAG ) , ( Al-Adhaileh & Tang , 1999 )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( Sato , 1991 ) ,( #AUTHOR_TAG ) , ( Al-Adhaileh & Tang , 1999 )']",0
"['', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by(Shieber & Schabes,1990) to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL( #AUTHOR_TAG ) ,( Harbusch & Poller , 2000 )']","['', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by(Shieber & Schabes,1990) to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL( #AUTHOR_TAG ) ,( Harbusch & Poller , 2000 )']","['', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by(Shieber & Schabes,1990) to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL( #AUTHOR_TAG ) ,( Harbusch & Poller , 2000 ) .', '']","['', 'For example, synchronous Tree Adjoining Grammar (S-TAG) can be used to relate TAGs for two different languages, for example, for the purpose of immediate structural translation in machine translation (Abeillé et al.,1990),(Harbusch & Poller,1996) , or for relating a syntactic TAG and semantic one for the same language(Shieber & Schabes,1990) .', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by(Shieber & Schabes,1990) to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL( #AUTHOR_TAG ) ,( Harbusch & Poller , 2000 ) .', '']",0
"['structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( #AUTHOR_TAG ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( #AUTHOR_TAG ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( #AUTHOR_TAG ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning( Menezes & Richardson , 2001 ) ,( Aramaki et al. , 2001 ) ,( Watanabe et al. , 2000 ) ,( Meyers et al. , 2000 ) ,( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3( Sato & Nagao , 1990 ) ,( #AUTHOR_TAG ) ,( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 )']",0
"['', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in( Tang , 1994 ) and#AUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree']","['and (4-5) for ""up"".', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in( Tang , 1994 ) and#AUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree']","['', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in( Tang , 1994 ) and#AUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree']","['2 illustrates the sentence ""John picks the box up"" with its corresponding SSTC.', 'It contains a nonprojective correspondence.', 'An interval is assigned to each word in the sentence, i.e. (0-1) for ""John"", (1-2) for ""picks"", (2-3) for ""the"", (3-4) for ""box"" and (4-5) for ""up"".', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in( Tang , 1994 ) and#AUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree']",5
"[', the greatest increase is in the amount of raw text available to be processed , e.g. the English Gigaword Corpus ( Linguistic Data#AUTHOR_TAG ) .', 'Recent work(Banko and Brill, 2001;Curran and Moens, 2002) has suggested that some tasks will benefit from using significantly more data.', 'Also, many potential applications of NLP will involve processing very large text databases.', '']","[', the greatest increase is in the amount of raw text available to be processed , e.g. the English Gigaword Corpus ( Linguistic Data#AUTHOR_TAG ) .', 'Recent work(Banko and Brill, 2001;Curran and Moens, 2002) has suggested that some tasks will benefit from using significantly more data.', 'Also, many potential applications of NLP will involve processing very large text databases.', '']","[', the greatest increase is in the amount of raw text available to be processed , e.g. the English Gigaword Corpus ( Linguistic Data#AUTHOR_TAG ) .', 'Recent work(Banko and Brill, 2001;Curran and Moens, 2002) has suggested that some tasks will benefit from using significantly more data.', 'Also, many potential applications of NLP will involve processing very large text databases.', '']","[', the greatest increase is in the amount of raw text available to be processed , e.g. the English Gigaword Corpus ( Linguistic Data#AUTHOR_TAG ) .', 'Recent work(Banko and Brill, 2001;Curran and Moens, 2002) has suggested that some tasks will benefit from using significantly more data.', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '']",0
"['is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems( #AUTHOR_TAG ) and speech recognition( Hacioglu and Pellom , 2003 ) .', '']","['is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems( #AUTHOR_TAG ) and speech recognition( Hacioglu and Pellom , 2003 ) .', '']","['of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems( #AUTHOR_TAG ) and speech recognition( Hacioglu and Pellom , 2003 ) .', '']","['', 'This standardisation of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems( #AUTHOR_TAG ) and speech recognition( Hacioglu and Pellom , 2003 ) .', '']",0
"['discussed earlier, there are two main requirements of the system that are covered by ""high performance"": speed and state of the art accuracy.', 'Efficiency is required both in training and processing.', 'Efficient training is required because the amount of data available for training will increase significantly.', 'Also , advanced methods often require many training iterations , for example active learning( Dagan and Engelson ,1995 ) and co-training( #AUTHOR_TAG ) .', 'Processing text needs to be extremely efficient since many new applications will require very large quantities of text to be processed or many']","['discussed earlier, there are two main requirements of the system that are covered by ""high performance"": speed and state of the art accuracy.', 'Efficiency is required both in training and processing.', 'Efficient training is required because the amount of data available for training will increase significantly.', 'Also , advanced methods often require many training iterations , for example active learning( Dagan and Engelson ,1995 ) and co-training( #AUTHOR_TAG ) .', 'Processing text needs to be extremely efficient since many new applications will require very large quantities of text to be processed or many']","['discussed earlier, there are two main requirements of the system that are covered by ""high performance"": speed and state of the art accuracy.', 'Efficiency is required both in training and processing.', 'Efficient training is required because the amount of data available for training will increase significantly.', 'Also , advanced methods often require many training iterations , for example active learning( Dagan and Engelson ,1995 ) and co-training( #AUTHOR_TAG ) .', 'Processing text needs to be extremely efficient since many new applications will require very large quantities of text to be processed or']","['discussed earlier, there are two main requirements of the system that are covered by ""high performance"": speed and state of the art accuracy.', 'Efficiency is required both in training and processing.', 'Efficient training is required because the amount of data available for training will increase significantly.', 'Also , advanced methods often require many training iterations , for example active learning( Dagan and Engelson ,1995 ) and co-training( #AUTHOR_TAG ) .', 'Processing text needs to be extremely efficient since many new applications will require very large quantities of text to be processed or many smaller quantities of text to be processed very quickly']",0
"['are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE )( #AUTHOR_TAG ) and the Alembic Workbench( Day et al. , 1997 ) ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors(Cunningham et al., 2002) .', 'GATE goes beyond earlier systems by using a component-based infrastructure(Cunningham, 2000) which the GUI is built on top of.', '']","['are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE )( #AUTHOR_TAG ) and the Alembic Workbench( Day et al. , 1997 ) ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors(Cunningham et al., 2002) .', 'GATE goes beyond earlier systems by using a component-based infrastructure(Cunningham, 2000) which the GUI is built on top of.', '']","['are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE )( #AUTHOR_TAG ) and the Alembic Workbench( Day et al. , 1997 ) ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors(Cunningham et al., 2002) .', 'GATE goes beyond earlier systems by using a component-based infrastructure(Cunningham, 2000) which the GUI is built on top of.', '']","['are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE )( #AUTHOR_TAG ) and the Alembic Workbench( Day et al. , 1997 ) ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors(Cunningham et al., 2002) .', 'GATE goes beyond earlier systems by using a component-based infrastructure(Cunningham, 2000) which the GUI is built on top of.', '']",0
"['', 'This standardisation of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems( Bayer et al. , 2001 ) and speech recognition( #AUTHOR_TAG ) .', 'Web services will']","['', 'This standardisation of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems( Bayer et al. , 2001 ) and speech recognition( #AUTHOR_TAG ) .', 'Web services will']","['', 'This standardisation of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems( Bayer et al. , 2001 ) and speech recognition( #AUTHOR_TAG ) .', 'Web services will allow']","['', 'This standardisation of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems( Bayer et al. , 2001 ) and speech recognition( #AUTHOR_TAG ) .', '']",0
"['', 'For instance , implementing an efficient version of the MXPOST POS tagger( #AUTHOR_TAG ) will simply involve composing and configuring the appropriate text file reading component , with the sequential tagging component , the collection of feature extraction components and the maximum entropy model component']","['elemental components.', 'For instance , implementing an efficient version of the MXPOST POS tagger( #AUTHOR_TAG ) will simply involve composing and configuring the appropriate text file reading component , with the sequential tagging component , the collection of feature extraction components and the maximum entropy model component']","['many elemental components.', 'For instance , implementing an efficient version of the MXPOST POS tagger( #AUTHOR_TAG ) will simply involve composing and configuring the appropriate text file reading component , with the sequential tagging component , the collection of feature extraction components and the maximum entropy model component']","['Generative Programming approach to NLP infrastructure development will allow tools such as sentence boundary detectors, POS taggers, chunkers and named entity recognisers to be rapidly composed from many elemental components.', 'For instance , implementing an efficient version of the MXPOST POS tagger( #AUTHOR_TAG ) will simply involve composing and configuring the appropriate text file reading component , with the sequential tagging component , the collection of feature extraction components and the maximum entropy model component']",3
"['implementation has been inspired by experience in extracting information from very large corpora( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging( Curran and Clark , 2003 ; #AUTHOR_TAG ) .', 'We have']","['implementation has been inspired by experience in extracting information from very large corpora( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging( Curran and Clark , 2003 ; #AUTHOR_TAG ) .', 'We have']","['implementation has been inspired by experience in extracting information from very large corpora( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging( Curran and Clark , 2003 ; #AUTHOR_TAG ) .', 'We have already implemented a POS tagger, chunker, CCG supertagger and named entity recogniser using the infrastructure.', '']","['implementation has been inspired by experience in extracting information from very large corpora( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging( Curran and Clark , 2003 ; #AUTHOR_TAG ) .', 'We have already implemented a POS tagger, chunker, CCG supertagger and named entity recogniser using the infrastructure.', '']",4
"['implementation has been inspired by experience in extracting information from very large corpora( #AUTHOR_TAG ) and performing experiments on maximum entropy sequence tagging( Curran and Clark , 2003 ; Clark et al. , 2003 ) .', '']","['implementation has been inspired by experience in extracting information from very large corpora( #AUTHOR_TAG ) and performing experiments on maximum entropy sequence tagging( Curran and Clark , 2003 ; Clark et al. , 2003 ) .', '']","['implementation has been inspired by experience in extracting information from very large corpora( #AUTHOR_TAG ) and performing experiments on maximum entropy sequence tagging( Curran and Clark , 2003 ; Clark et al. , 2003 ) .', '']","['implementation has been inspired by experience in extracting information from very large corpora( #AUTHOR_TAG ) and performing experiments on maximum entropy sequence tagging( Curran and Clark , 2003 ; Clark et al. , 2003 ) .', 'We have already implemented a P O S tagger, chunker, C C G supertagger and named entity recogniser using the infrastructure.', '']",4
"['iciency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by#AUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly( Malouf , 2002 ) .', '']","['iciency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by#AUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly( Malouf , 2002 ) .', '']","['iciency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by#AUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly( Malouf , 2002 ) .', '']","['iciency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by#AUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly( Malouf , 2002 ) .', '']",0
"['', 'Other tools have been designed around particular techniques , such as finite state machines( Karttunen et al. , 1997 ; #AUTHOR_TAG ) .', '']","['', 'Other tools have been designed around particular techniques , such as finite state machines( Karttunen et al. , 1997 ; #AUTHOR_TAG ) .', 'However, the source code for these tools is not freely available, so they cannot be extended']","['', 'Other tools have been designed around particular techniques , such as finite state machines( Karttunen et al. , 1997 ; #AUTHOR_TAG ) .', '']","['', 'Other tools have been designed around particular techniques , such as finite state machines( Karttunen et al. , 1997 ; #AUTHOR_TAG ) .', 'However, the source code for these tools is not freely available, so they cannot be extended']",0
"['', 'Recent work( Banko and Brill , 2001 ; #AUTHOR_TAG ) has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web']","['', 'Recent work( Banko and Brill , 2001 ; #AUTHOR_TAG ) has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '']","[', the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus(Linguistic Data Consortium, 2003) .', 'Recent work( Banko and Brill , 2001 ; #AUTHOR_TAG ) has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '']","[', the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus(Linguistic Data Consortium, 2003) .', 'Recent work( Banko and Brill , 2001 ; #AUTHOR_TAG ) has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '']",0
"['', 'For example , 10 million words of the American National Corpus( Ide et al. , 2002 ) will have manually corrected POS tags , a tenfold increase over the Penn Treebank( #AUTHOR_TAG ) , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations']","['annotated.', 'For example , 10 million words of the American National Corpus( Ide et al. , 2002 ) will have manually corrected POS tags , a tenfold increase over the Penn Treebank( #AUTHOR_TAG ) , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations']","['', 'For example , 10 million words of the American National Corpus( Ide et al. , 2002 ) will have manually corrected POS tags , a tenfold increase over the Penn Treebank( #AUTHOR_TAG ) , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations']","['LP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annotated.', 'For example , 10 million words of the American National Corpus( Ide et al. , 2002 ) will have manually corrected POS tags , a tenfold increase over the Penn Treebank( #AUTHOR_TAG ) , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations']",0
['already been used to implement a framework for teaching NLP( #AUTHOR_TAG )'],['already been used to implement a framework for teaching NLP( #AUTHOR_TAG )'],['been used to implement a framework for teaching NLP( #AUTHOR_TAG )'],"['', 'It has already been used to implement a framework for teaching NLP( #AUTHOR_TAG )']",2
"['are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE )( Cunningham et al. , 1997 ) and the Alembic Workbench( #AUTHOR_TAG ) ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors(Cunningham et al., 2002) .', 'GATE goes beyond earlier systems by using a component-based infrastructure']","['are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE )( Cunningham et al. , 1997 ) and the Alembic Workbench( #AUTHOR_TAG ) ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors(Cunningham et al., 2002) .', 'GATE goes beyond earlier systems by using a component-based infrastructure']","['are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE )( Cunningham et al. , 1997 ) and the Alembic Workbench( #AUTHOR_TAG ) ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors(Cunningham et al., 2002) .', 'GATE goes beyond earlier systems by using a component-based infrastructure']","['are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE )( Cunningham et al. , 1997 ) and the Alembic Workbench( #AUTHOR_TAG ) ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors(Cunningham et al., 2002) .', 'GATE goes beyond earlier systems by using a component-based infrastructure(Cunningham, 2000) which the GUI is built on top of.', '']",0
"['.', 'For instance , GATE currently provides a POS tagger , named entity recogniser and gazetteer and ontology editors( #AUTHOR_TAG ) .', 'GATE goes beyond earlier systems by using a component-based infrastructure(Cunningham, 2000) which the GUI is built on top of.', '']","['', 'For instance , GATE currently provides a POS tagger , named entity recogniser and gazetteer and ontology editors( #AUTHOR_TAG ) .', 'GATE goes beyond earlier systems by using a component-based infrastructure(Cunningham, 2000) which the GUI is built on top of.', '']","['', 'For instance , GATE currently provides a POS tagger , named entity recogniser and gazetteer and ontology editors( #AUTHOR_TAG ) .', 'GATE goes beyond earlier systems by using a component-based infrastructure(Cunningham, 2000) which the GUI is built on top of.', '']","['', 'For instance , GATE currently provides a POS tagger , named entity recogniser and gazetteer and ontology editors( #AUTHOR_TAG ) .', 'GATE goes beyond earlier systems by using a component-based infrastructure(Cunningham, 2000) which the GUI is built on top of.', '']",0
"['engineering research on Generative Programming( #AUTHOR_TAG ) attempts to solve these problems by focusing on the development of configurable elementary components and knowledge to combine these components into complete systems .', 'Our infrastructure']","['engineering research on Generative Programming( #AUTHOR_TAG ) attempts to solve these problems by focusing on the development of configurable elementary components and knowledge to combine these components into complete systems .', 'Our infrastructure']","['engineering research on Generative Programming( #AUTHOR_TAG ) attempts to solve these problems by focusing on the development of configurable elementary components and knowledge to combine these components into complete systems .', 'Our infrastructure']","['engineering research on Generative Programming( #AUTHOR_TAG ) attempts to solve these problems by focusing on the development of configurable elementary components and knowledge to combine these components into complete systems .', '']",0
"['LP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annotated.', 'For example , 10 million words of the American National Corpus( #AUTHOR_TAG ) will have manually corrected POS tags , a tenfold increase over the Penn Treebank( Marcus et al. , 1993 ) , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations']","['LP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annotated.', 'For example , 10 million words of the American National Corpus( #AUTHOR_TAG ) will have manually corrected POS tags , a tenfold increase over the Penn Treebank( Marcus et al. , 1993 ) , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations']","['LP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annotated.', 'For example , 10 million words of the American National Corpus( #AUTHOR_TAG ) will have manually corrected POS tags , a tenfold increase over the Penn Treebank( Marcus et al. , 1993 ) , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations']","['LP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annotated.', 'For example , 10 million words of the American National Corpus( #AUTHOR_TAG ) will have manually corrected POS tags , a tenfold increase over the Penn Treebank( Marcus et al. , 1993 ) , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations']",0
"['number of stand-alone tools have also been developed.', 'For example , the suite of LT tools( Mikheev et al. , 1999 ; #AUTHOR_TAG ) perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files']","['number of stand-alone tools have also been developed.', 'For example , the suite of LT tools( Mikheev et al. , 1999 ; #AUTHOR_TAG ) perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '']","['number of stand-alone tools have also been developed.', 'For example , the suite of LT tools( Mikheev et al. , 1999 ; #AUTHOR_TAG ) perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '']","['number of stand-alone tools have also been developed.', 'For example , the suite of LT tools( Mikheev et al. , 1999 ; #AUTHOR_TAG ) perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '']",0
"['', 'To provide the required configurability in the static version of the code we will use policy templates( #AUTHOR_TAG ) , and for the dynamic version we will use configuration classes']","['', 'To provide the required configurability in the static version of the code we will use policy templates( #AUTHOR_TAG ) , and for the dynamic version we will use configuration classes']","['', 'To provide the required configurability in the static version of the code we will use policy templates( #AUTHOR_TAG ) , and for the dynamic version we will use configuration classes']","['', 'To provide the required configurability in the static version of the code we will use policy templates( #AUTHOR_TAG ) , and for the dynamic version we will use configuration classes']",5
"['', 'Recent work( #AUTHOR_TAG ; Curran and Moens , 2002 ) has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web']","['', 'Recent work( #AUTHOR_TAG ; Curran and Moens , 2002 ) has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '']","[', the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus(Linguistic Data Consortium, 2003) .', 'Recent work( #AUTHOR_TAG ; Curran and Moens , 2002 ) has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '']","[', the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus(Linguistic Data Consortium, 2003) .', 'Recent work( #AUTHOR_TAG ; Curran and Moens , 2002 ) has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '']",0
"['number of stand-alone tools have also been developed.', 'For example , the suite of LT tools( #AUTHOR_TAG ; Grover et al. , 2000 ) perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files']","['number of stand-alone tools have also been developed.', 'For example , the suite of LT tools( #AUTHOR_TAG ; Grover et al. , 2000 ) perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '']","['number of stand-alone tools have also been developed.', 'For example , the suite of LT tools( #AUTHOR_TAG ; Grover et al. , 2000 ) perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '']","['number of stand-alone tools have also been developed.', 'For example , the suite of LT tools( #AUTHOR_TAG ; Grover et al. , 2000 ) perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '']",0
"['learning methods should be interchangeable : Transformation-based learning ( TBL )( #AUTHOR_TAG ) and Memory-based learning ( MBL )( Daelemans et al. , 2002 ) have been applied to many different problems , so a single interchangeable component should be used to represent each method .', 'We will']","['learning methods should be interchangeable : Transformation-based learning ( TBL )( #AUTHOR_TAG ) and Memory-based learning ( MBL )( Daelemans et al. , 2002 ) have been applied to many different problems , so a single interchangeable component should be used to represent each method .', 'We will']","['learning methods should be interchangeable : Transformation-based learning ( TBL )( #AUTHOR_TAG ) and Memory-based learning ( MBL )( Daelemans et al. , 2002 ) have been applied to many different problems , so a single interchangeable component should be used to represent each method .', 'We will base these components on the design of Weka(Witten and Frank, 1999)']","['learning methods should be interchangeable : Transformation-based learning ( TBL )( #AUTHOR_TAG ) and Memory-based learning ( MBL )( Daelemans et al. , 2002 ) have been applied to many different problems , so a single interchangeable component should be used to represent each method .', 'We will base these components on the design of Weka(Witten and Frank, 1999)']",4
"['', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit( #AUTHOR_TAG ) which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging( Roche and Schabes , 1997 ) .', 'The T']","['', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit( #AUTHOR_TAG ) which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging( Roche and Schabes , 1997 ) .', 'The TNT POS']","['', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit( #AUTHOR_TAG ) which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging( Roche and Schabes , 1997 ) .', '']","['iciency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models, from simple iterative estimation algorithms used byRatnaparkhi (1998) that converge very slowly, to complex techniques from the optimisation literature that converge much more rapidly(Malouf, 2002) .', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit( #AUTHOR_TAG ) which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging( Roche and Schabes , 1997 ) .', '']",0
"['basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines( Curran and Clark , 2003 ; #AUTHOR_TAG ) .', 'An example']","['basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines( Curran and Clark , 2003 ; #AUTHOR_TAG ) .', 'An example']","['basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines( Curran and Clark , 2003 ; #AUTHOR_TAG ) .', 'An example']","['basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines( Curran and Clark , 2003 ; #AUTHOR_TAG ) .', 'An example of using the Python tagger interface is shown in Figure 1']",0
"['.', 'These tools use a highly optimised GIS implementation and provide sophisticated Gaussian smoothing( #AUTHOR_TAG ) .', '']","['', 'These tools use a highly optimised GIS implementation and provide sophisticated Gaussian smoothing( #AUTHOR_TAG ) .', '']","['', 'These tools use a highly optimised GIS implementation and provide sophisticated Gaussian smoothing( #AUTHOR_TAG ) .', '']","['', 'These tools use a highly optimised GIS implementation and provide sophisticated Gaussian smoothing( #AUTHOR_TAG ) .', '']",5
"['', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit( Ngai and Florian , 2001 ) which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging( #AUTHOR_TAG ) .', '']","['', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit( Ngai and Florian , 2001 ) which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging( #AUTHOR_TAG ) .', '']","['', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit( Ngai and Florian , 2001 ) which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging( #AUTHOR_TAG ) .', '']","['', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit( Ngai and Florian , 2001 ) which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging( #AUTHOR_TAG ) .', '']",0
"[', the Natural Language Toolkit ( NLTK ) is a package of NLP components implemented in Python( #AUTHOR_TAG ) .', 'Python scripting is extremely simple to learn']","[', the Natural Language Toolkit ( NLTK ) is a package of NLP components implemented in Python( #AUTHOR_TAG ) .', 'Python scripting is extremely simple to learn, read and write, and']","[', the Natural Language Toolkit ( NLTK ) is a package of NLP components implemented in Python( #AUTHOR_TAG ) .', 'Python scripting is extremely simple to learn']","[', the Natural Language Toolkit ( NLTK ) is a package of NLP components implemented in Python( #AUTHOR_TAG ) .', 'Python scripting is extremely simple to learn, read and write, and so using the existing components and designing new components is simple']",0
"['implementation has been inspired by experience in extracting information from very large corpora( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging( #AUTHOR_TAG ; Clark et al. , 2003 ) .', 'We have']","['implementation has been inspired by experience in extracting information from very large corpora( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging( #AUTHOR_TAG ; Clark et al. , 2003 ) .', 'We have']","['implementation has been inspired by experience in extracting information from very large corpora( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging( #AUTHOR_TAG ; Clark et al. , 2003 ) .', 'We have already implemented a POS tagger, chunker, CCG supertagger and named entity recogniser using the infrastructure.', '']","['implementation has been inspired by experience in extracting information from very large corpora( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging( #AUTHOR_TAG ; Clark et al. , 2003 ) .', 'We have already implemented a POS tagger, chunker, CCG supertagger and named entity recogniser using the infrastructure.', '']",4
"['iciency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used byRatnaparkhi ( 1998 ) that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly( #AUTHOR_TAG ) .', '']","['iciency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used byRatnaparkhi ( 1998 ) that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly( #AUTHOR_TAG ) .', '']","['iciency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used byRatnaparkhi ( 1998 ) that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly( #AUTHOR_TAG ) .', '']","['iciency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used byRatnaparkhi ( 1998 ) that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly( #AUTHOR_TAG ) .', '']",0
"['basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines( #AUTHOR_TAG ; Clark et al. , 2003 ) .', 'An example']","['basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines( #AUTHOR_TAG ; Clark et al. , 2003 ) .', 'An example']","['basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines( #AUTHOR_TAG ; Clark et al. , 2003 ) .', 'An example']","['basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines( #AUTHOR_TAG ; Clark et al. , 2003 ) .', 'An example of using the Python tagger interface is shown in Figure 1']",0
"['', 'The TNT POS tagger( #AUTHOR_TAG ) has also been designed to train and run very quickly , tagging between 30,000 and 60,000 words per second']","['', 'The TNT POS tagger( #AUTHOR_TAG ) has also been designed to train and run very quickly , tagging between 30,000 and 60,000 words per second']","['', 'The TNT POS tagger( #AUTHOR_TAG ) has also been designed to train and run very quickly , tagging between 30,000 and 60,000 words per second']","['', 'The TNT POS tagger( #AUTHOR_TAG ) has also been designed to train and run very quickly , tagging between 30,000 and 60,000 words per second']",0
"['', 'GATE goes beyond earlier systems by using a component-based infrastructure( #AUTHOR_TAG ) which the GUI is built on top of .', 'This allows components to be highly configurable and simplifies the addition of new components to the system']","['', 'GATE goes beyond earlier systems by using a component-based infrastructure( #AUTHOR_TAG ) which the GUI is built on top of .', 'This allows components to be highly configurable and simplifies the addition of new components to the system']","['', 'GATE goes beyond earlier systems by using a component-based infrastructure( #AUTHOR_TAG ) which the GUI is built on top of .', 'This allows components to be highly configurable and simplifies the addition of new components to the system']","['', 'GATE goes beyond earlier systems by using a component-based infrastructure( #AUTHOR_TAG ) which the GUI is built on top of .', 'This allows components to be highly configurable and simplifies the addition of new components to the system']",0
"['for instance ,( #AUTHOR_TAG ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']","['for instance ,( #AUTHOR_TAG ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']","['for instance ,( #AUTHOR_TAG ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']","['Semantic grammars"" already exist which describe not only the syntax but also the semantics of natural language.', 'Thus for instance ,( #AUTHOR_TAG ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']",0
"['ases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available( #AUTHOR_TAG ) .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', '']","['ases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available( #AUTHOR_TAG ) .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', '']","['ases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available( #AUTHOR_TAG ) .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', '']","['ases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available( #AUTHOR_TAG ) .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', '']",0
"['( Barzilay and Lee , 2003 ) and( #AUTHOR_TAG ) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', '']","['( Barzilay and Lee , 2003 ) and( #AUTHOR_TAG ) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', '']","['( Barzilay and Lee , 2003 ) and( #AUTHOR_TAG ) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', '']","['', 'Similarly ,( Barzilay and Lee , 2003 ) and( #AUTHOR_TAG ) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', '']",0
['( #AUTHOR_TAG ) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts'],['( #AUTHOR_TAG ) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts'],['( #AUTHOR_TAG ) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts'],"['', 'And( #AUTHOR_TAG ) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts']",0
"['.', 'To address this problem , we are currently working on developing a metagrammar in the sense of( #AUTHOR_TAG ) .', 'This metagrammar allows us to factorise both syntactic and semantic information.', 'Syntactic information is factorised in the usual way.', 'For instance, there will be a class NOVN1 which groups together all the initial trees representing the possible syntactic configurations in which a transitive verb with two nominal arguments can occur.', 'But additionnally there will be semantic classes such as, ""binary predicate of semantic type X"" which will be associated with the relevant syntactic']","['', 'To address this problem , we are currently working on developing a metagrammar in the sense of( #AUTHOR_TAG ) .', 'This metagrammar allows us to factorise both syntactic and semantic information.', 'Syntactic information is factorised in the usual way.', 'For instance, there will be a class NOVN1 which groups together all the initial trees representing the possible syntactic configurations in which a transitive verb with two nominal arguments can occur.', 'But additionnally there will be semantic classes such as, ""binary predicate of semantic type X"" which will be associated with the relevant syntactic']","['.', 'To address this problem , we are currently working on developing a metagrammar in the sense of( #AUTHOR_TAG ) .', 'This metagrammar allows us to factorise both syntactic and semantic information.', 'Syntactic information is factorised in the usual way.', 'For instance, there will be a class NOVN1 which groups together all the initial trees representing the possible syntactic configurations in which a transitive verb with two nominal arguments can occur.', 'But additionnally there will be semantic classes such as, ""binary predicate of semantic type X"" which will be associated with the relevant syntactic classes for instance, NOVN1 (the class of transitive verbs with nominal arguments), BINARY NPRED (the class of']","['', 'To address this problem , we are currently working on developing a metagrammar in the sense of( #AUTHOR_TAG ) .', 'This metagrammar allows us to factorise both syntactic and semantic information.', 'Syntactic information is factorised in the usual way.', 'For instance, there will be a class NOVN1 which groups together all the initial trees representing the possible syntactic configurations in which a transitive verb with two nominal arguments can occur.', 'But additionnally there will be semantic classes such as, ""binary predicate of semantic type X"" which will be associated with the relevant syntactic classes for instance, NOVN1 (the class of transitive verbs with nominal arguments), BINARY NPRED (the class of binary predicative nouns), NOVSUPNN1 , the class of support verb constructions taking two nominal arguments.', '']",3
"['', 'Similarly ,( #AUTHOR_TAG ) and( Shinyanma et al. , 2002 ) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', 'And(Glickman and Dagan, 2003)']","['', 'Similarly ,( #AUTHOR_TAG ) and( Shinyanma et al. , 2002 ) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', 'And(Glickman and Dagan, 2003)']","['', 'Similarly ,( #AUTHOR_TAG ) and( Shinyanma et al. , 2002 ) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', 'And(Glickman and Dagan, 2003)']","['', 'Similarly ,( #AUTHOR_TAG ) and( Shinyanma et al. , 2002 ) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', '']",0
"['represent the semantics of predicative units , we use FrameNet inventory of frames and frame elements ( C.#AUTHOR_TAG ) .', 'Johnson et al., 2002) .', 'FrameNet is an online lexical resource for English based on the principles of Frame Semantics.', 'In this']","['represent the semantics of predicative units , we use FrameNet inventory of frames and frame elements ( C.#AUTHOR_TAG ) .', 'Johnson et al., 2002) .', 'FrameNet is an online lexical resource for English based on the principles of Frame Semantics.', 'In this approach, a word evokes a frame i.e., a simple or a complex event, and each frame is associated with a']","['represent the semantics of predicative units , we use FrameNet inventory of frames and frame elements ( C.#AUTHOR_TAG ) .', 'Johnson et al., 2002) .', 'FrameNet is an online lexical resource for English based on the principles of Frame Semantics.', 'In this approach, a word evokes a frame i.e., a simple or a complex event, and each frame is associated with a number of frame elements that is']","['represent the semantics of predicative units , we use FrameNet inventory of frames and frame elements ( C.#AUTHOR_TAG ) .', 'Johnson et al., 2002) .', 'FrameNet is an online lexical resource for English based on the principles of Frame Semantics.', 'In this approach, a word evokes a frame i.e., a simple or a complex event, and each frame is associated with a number of frame elements that is, a number of participants fulfilling a given role in the frame.', 'Finally each frame is associated with a set of target words, the words that evoke that frame']",5
"['', 'For instance ,( #AUTHOR_TAG ) acquire two-argument templates ( inference rules ) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning .', '']","['', 'For instance ,( #AUTHOR_TAG ) acquire two-argument templates ( inference rules ) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning .', '']","['', 'For instance ,( #AUTHOR_TAG ) acquire two-argument templates ( inference rules ) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning .', '']","['', 'For instance ,( #AUTHOR_TAG ) acquire two-argument templates ( inference rules ) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning .', '']",0
"['aries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity( Pereira et al. , 1993 ; #AUTHOR_TAG ) .', '']","['ases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available(Ploux, 1997) .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity( Pereira et al. , 1993 ; #AUTHOR_TAG ) .', 'techniques']","['ases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available(Ploux, 1997) .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity( Pereira et al. , 1993 ; #AUTHOR_TAG ) .', '']","['ases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available(Ploux, 1997) .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity( Pereira et al. , 1993 ; #AUTHOR_TAG ) .', 'techniques']",3
"['', 'For english , there is for instance the 15 year old HewlettPackard test suite , a simple text file listing test sentences and grouping them according to linguistics phenomena( #AUTHOR_TAG ) ; and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information( Oepen and Flickinger , 1998 )']","['', 'For english , there is for instance the 15 year old HewlettPackard test suite , a simple text file listing test sentences and grouping them according to linguistics phenomena( #AUTHOR_TAG ) ; and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information( Oepen and Flickinger , 1998 )']","['', 'For english , there is for instance the 15 year old HewlettPackard test suite , a simple text file listing test sentences and grouping them according to linguistics phenomena( #AUTHOR_TAG ) ; and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information( Oepen and Flickinger , 1998 ) .', '']","['', 'For english , there is for instance the 15 year old HewlettPackard test suite , a simple text file listing test sentences and grouping them according to linguistics phenomena( #AUTHOR_TAG ) ; and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information( Oepen and Flickinger , 1998 ) .', '']",1
"['language chosen for semantic representation is a flat semantics along the line of( Bos , 1995 ; #AUTHOR_TAG ; Copestake et al. , 2001 ) .', '']","['language chosen for semantic representation is a flat semantics along the line of( Bos , 1995 ; #AUTHOR_TAG ; Copestake et al. , 2001 ) .', '']","['language chosen for semantic representation is a flat semantics along the line of( Bos , 1995 ; #AUTHOR_TAG ; Copestake et al. , 2001 ) .', '']","['language chosen for semantic representation is a flat semantics along the line of( Bos , 1995 ; #AUTHOR_TAG ; Copestake et al. , 2001 ) .', '']",1
"['pus driven efforts along the PARSEVAL lines( #AUTHOR_TAG ) are good at giving some measure of a grammar coverage , they are not suitable for finer grained analysis and in particular , for progress evaluation , regression testing and comparative report generation .', '']","['', 'While corpus driven efforts along the PARSEVAL lines( #AUTHOR_TAG ) are good at giving some measure of a grammar coverage , they are not suitable for finer grained analysis and in particular , for progress evaluation , regression testing and comparative report generation .', '']","['pus driven efforts along the PARSEVAL lines( #AUTHOR_TAG ) are good at giving some measure of a grammar coverage , they are not suitable for finer grained analysis and in particular , for progress evaluation , regression testing and comparative report generation .', '']","['', 'While corpus driven efforts along the PARSEVAL lines( #AUTHOR_TAG ) are good at giving some measure of a grammar coverage , they are not suitable for finer grained analysis and in particular , for progress evaluation , regression testing and comparative report generation .', '']",0
"['language chosen for semantic representation is a flat semantics along the line of( #AUTHOR_TAG ; Copestake et al. , 1999 ; Copestake et al. , 2001 ) .', '']","['language chosen for semantic representation is a flat semantics along the line of( #AUTHOR_TAG ; Copestake et al. , 1999 ; Copestake et al. , 2001 ) .', '']","['language chosen for semantic representation is a flat semantics along the line of( #AUTHOR_TAG ; Copestake et al. , 1999 ; Copestake et al. , 2001 ) .', '']","['language chosen for semantic representation is a flat semantics along the line of( #AUTHOR_TAG ; Copestake et al. , 1999 ; Copestake et al. , 2001 ) .', '']",1
"['', 'In particular ,( #AUTHOR_TAG ) lists the converses of some 3 500 predicative nouns']","['', 'In particular ,( #AUTHOR_TAG ) lists the converses of some 3 500 predicative nouns']","['', 'In particular ,( #AUTHOR_TAG ) lists the converses of some 3 500 predicative nouns']","['', 'In particular ,( #AUTHOR_TAG ) lists the converses of some 3 500 predicative nouns']",3
"['we shall briefly discuss in section 4, the grammar is developed with the help of a meta-grammar( #AUTHOR_TAG ) thus ensuring an additional level of abstraction .', 'The metagram']","['we shall briefly discuss in section 4, the grammar is developed with the help of a meta-grammar( #AUTHOR_TAG ) thus ensuring an additional level of abstraction .', 'The metagrammar is an abstract specification']","['we shall briefly discuss in section 4, the grammar is developed with the help of a meta-grammar( #AUTHOR_TAG ) thus ensuring an additional level of abstraction .', 'The metagrammar is an abstract specification']","['we shall briefly discuss in section 4, the grammar is developed with the help of a meta-grammar( #AUTHOR_TAG ) thus ensuring an additional level of abstraction .', 'The metagrammar is an abstract specification of the linguistic properties (phrase structure, valency, realisation of grammatical functions etc.) encoded in the grammar basic units.', '']",5
"['shuffling paraphrases, french alternations are partially described in (Saint-Dizier, 1999) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs.', 'For complementing this database and for converse constructions , the LADL tables( #AUTHOR_TAG ) can furthermore be resorted to , which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions .', 'In']","['shuffling paraphrases, french alternations are partially described in (Saint-Dizier, 1999) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs.', 'For complementing this database and for converse constructions , the LADL tables( #AUTHOR_TAG ) can furthermore be resorted to , which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions .', 'In particular,(Gross, 1989) lists the converses of some 3 500 predicative nouns']","['shuffling paraphrases, french alternations are partially described in (Saint-Dizier, 1999) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs.', 'For complementing this database and for converse constructions , the LADL tables( #AUTHOR_TAG ) can furthermore be resorted to , which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions .', 'In']","['shuffling paraphrases, french alternations are partially described in (Saint-Dizier, 1999) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs.', 'For complementing this database and for converse constructions , the LADL tables( #AUTHOR_TAG ) can furthermore be resorted to , which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions .', 'In particular,(Gross, 1989) lists the converses of some 3 500 predicative nouns']",3
"['and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information( #AUTHOR_TAG ) .', 'Yet because they do not take into account the semantic dimension, none of these tools are adequate for evaluating the paraphrastic power of a grammar.', '']","['and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information( #AUTHOR_TAG ) .', 'Yet because they do not take into account the semantic dimension, none of these tools are adequate for evaluating the paraphrastic power of a grammar.', '']","['and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information( #AUTHOR_TAG ) .', 'Yet because they do not take into account the semantic dimension, none of these tools are adequate for evaluating the paraphrastic power of a grammar.', '']",['( #AUTHOR_TAG )'],0
"['aries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity( #AUTHOR_TAG ; Lin , 1998 ) .', '']","['ases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available(Ploux, 1997) .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity( #AUTHOR_TAG ; Lin , 1998 ) .', 'techniques']","['ases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available(Ploux, 1997) .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity( #AUTHOR_TAG ; Lin , 1998 ) .', '']","['ases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available(Ploux, 1997) .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity( #AUTHOR_TAG ; Lin , 1998 ) .', 'techniques']",3
"['for instance ,( Copestake and Flickinger , 2000 ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( #AUTHOR_TAG ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']","['for instance ,( Copestake and Flickinger , 2000 ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( #AUTHOR_TAG ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']","['for instance ,( Copestake and Flickinger , 2000 ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( #AUTHOR_TAG ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']","['', 'Thus for instance ,( Copestake and Flickinger , 2000 ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( #AUTHOR_TAG ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']",0
['antic construction proceeds from the derived tree( #AUTHOR_TAG ) rather than -- as is more common in TAG -- from the derivation tree'],['antic construction proceeds from the derived tree( #AUTHOR_TAG ) rather than -- as is more common in TAG -- from the derivation tree'],"['antic construction proceeds from the derived tree( #AUTHOR_TAG ) rather than -- as is more common in TAG -- from the derivation tree .', '']","['antic construction proceeds from the derived tree( #AUTHOR_TAG ) rather than -- as is more common in TAG -- from the derivation tree .', '']",0
"['for instance ,( Copestake and Flickinger , 2000 ; #AUTHOR_TAG ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']","['for instance ,( Copestake and Flickinger , 2000 ; #AUTHOR_TAG ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']","['for instance ,( Copestake and Flickinger , 2000 ; #AUTHOR_TAG ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']","['Semantic grammars"" already exist which describe not only the syntax but also the semantics of natural language.', 'Thus for instance ,( Copestake and Flickinger , 2000 ; #AUTHOR_TAG ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics']",0
"['language chosen for semantic representation is a flat semantics along the line of( Bos , 1995 ; Copestake et al. , 1999 ; #AUTHOR_TAG ) .', '']","['language chosen for semantic representation is a flat semantics along the line of( Bos , 1995 ; Copestake et al. , 1999 ; #AUTHOR_TAG ) .', '']","['language chosen for semantic representation is a flat semantics along the line of( Bos , 1995 ; Copestake et al. , 1999 ; #AUTHOR_TAG ) .', '']","['language chosen for semantic representation is a flat semantics along the line of( Bos , 1995 ; Copestake et al. , 1999 ; #AUTHOR_TAG ) .', '']",1
"['shuffling paraphrases , french alternations are partially described in( #AUTHOR_TAG ) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs .', '']","['shuffling paraphrases , french alternations are partially described in( #AUTHOR_TAG ) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs .', '']","['shuffling paraphrases , french alternations are partially described in( #AUTHOR_TAG ) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs .', '']","['shuffling paraphrases , french alternations are partially described in( #AUTHOR_TAG ) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs .', '']",0
"['', 'In this work, we use the Arabic root extraction technique in(El Kourdi, 2004) .', 'It compares favorably to other stemming or root extraction algorithms( #AUTHOR_TAG ; Al-Shalabi and Evens , 1998 ; and Houmame , 1999 ) , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', 'In this work, we use the Arabic root extraction technique in(El Kourdi, 2004) .', 'It compares favorably to other stemming or root extraction algorithms( #AUTHOR_TAG ; Al-Shalabi and Evens , 1998 ; and Houmame , 1999 ) , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', 'In this work, we use the Arabic root extraction technique in(El Kourdi, 2004) .', 'It compares favorably to other stemming or root extraction algorithms( #AUTHOR_TAG ; Al-Shalabi and Evens , 1998 ; and Houmame , 1999 ) , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', 'In this work, we use the Arabic root extraction technique in(El Kourdi, 2004) .', 'It compares favorably to other stemming or root extraction algorithms( #AUTHOR_TAG ; Al-Shalabi and Evens , 1998 ; and Houmame , 1999 ) , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']",4
"['', 'In this work, we use the Arabic root extraction technique in(El Kourdi, 2004) .', 'It compares favorably to other stemming or root extraction algorithms( Yates and Neto , 1999 ; Al-Shalabi and Evens , 1998 ; and #AUTHOR_TAG ) , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', 'In this work, we use the Arabic root extraction technique in(El Kourdi, 2004) .', 'It compares favorably to other stemming or root extraction algorithms( Yates and Neto , 1999 ; Al-Shalabi and Evens , 1998 ; and #AUTHOR_TAG ) , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', 'In this work, we use the Arabic root extraction technique in(El Kourdi, 2004) .', 'It compares favorably to other stemming or root extraction algorithms( Yates and Neto , 1999 ; Al-Shalabi and Evens , 1998 ; and #AUTHOR_TAG ) , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', 'In this work, we use the Arabic root extraction technique in(El Kourdi, 2004) .', 'It compares favorably to other stemming or root extraction algorithms( Yates and Neto , 1999 ; Al-Shalabi and Evens , 1998 ; and #AUTHOR_TAG ) , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']",4
"['; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG )( #AUTHOR_TAG ) , minimum description length principal( Lang , 1995 ) , and the X2 statistic .', '']","['selection techniques have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG )( #AUTHOR_TAG ) , minimum description length principal( Lang , 1995 ) , and the X2 statistic .', '']","['ing with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG )( #AUTHOR_TAG ) , minimum description length principal( Lang , 1995 ) , and the X2 statistic .', '']","['selection techniques have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG )( #AUTHOR_TAG ) , minimum description length principal( Lang , 1995 ) , and the X2 statistic .', '']",0
"['', 'This work is a continuation of that initiated in( #AUTHOR_TAG ) , which reports an overall NB classification correctness of 75.6 % , in cross validation experiments , on a data set that consists of 100 documents for each of 12 categories ( the data set is collected from different Arabic portals ) .', 'A 50% overall classification accuracy is']","['', 'This work is a continuation of that initiated in( #AUTHOR_TAG ) , which reports an overall NB classification correctness of 75.6 % , in cross validation experiments , on a data set that consists of 100 documents for each of 12 categories ( the data set is collected from different Arabic portals ) .', 'A 50% overall classification accuracy is']","['', 'This work is a continuation of that initiated in( #AUTHOR_TAG ) , which reports an overall NB classification correctness of 75.6 % , in cross validation experiments , on a data set that consists of 100 documents for each of 12 categories ( the data set is collected from different Arabic portals ) .', 'A 50% overall classification accuracy is also reported when testing with a separately collected evaluation set (3 documents for each of the 12 categories).', '']","['', 'This work is a continuation of that initiated in( #AUTHOR_TAG ) , which reports an overall NB classification correctness of 75.6 % , in cross validation experiments , on a data set that consists of 100 documents for each of 12 categories ( the data set is collected from different Arabic portals ) .', 'A 50% overall classification accuracy is also reported when testing with a separately collected evaluation set (3 documents for each of the 12 categories).', '']",2
"['sum up , this work has been carried out to automatically classify Arabic documents using the NB algorithm , with the use of a different data set , a different number of categories , and a different root extraction algorithm from those used in( #AUTHOR_TAG ) .', '']","['sum up , this work has been carried out to automatically classify Arabic documents using the NB algorithm , with the use of a different data set , a different number of categories , and a different root extraction algorithm from those used in( #AUTHOR_TAG ) .', '']","['sum up , this work has been carried out to automatically classify Arabic documents using the NB algorithm , with the use of a different data set , a different number of categories , and a different root extraction algorithm from those used in( #AUTHOR_TAG ) .', '']","['sum up , this work has been carried out to automatically classify Arabic documents using the NB algorithm , with the use of a different data set , a different number of categories , and a different root extraction algorithm from those used in( #AUTHOR_TAG ) .', '']",1
"['good study comparing document categorization algorithms can be found in( #AUTHOR_TAG ) .', 'More recently,(Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in(Joachims, 2002) ,(Crammer and Singer, 2003) , and(Lewis et al., 2004)']","['good study comparing document categorization algorithms can be found in( #AUTHOR_TAG ) .', 'More recently,(Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in(Joachims, 2002) ,(Crammer and Singer, 2003) , and(Lewis et al., 2004)']","['good study comparing document categorization algorithms can be found in( #AUTHOR_TAG ) .', 'More recently,(Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in(Joachims, 2002) ,(Crammer and Singer, 2003) , and(Lewis et al., 2004)']","['good study comparing document categorization algorithms can be found in( #AUTHOR_TAG ) .', 'More recently,(Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in(Joachims, 2002) ,(Crammer and Singer, 2003) , and(Lewis et al., 2004)']",0
"['Arabic, however, the use of stems will not yield satisfactory categorization.', 'This is mainly due to the fact that Arabic is a non-concatenative language( #AUTHOR_TAG ) , and that the stem/infix obtained by suppression of infix and prefix add-ons is not the same for words derived from the same origin called the']","['Arabic, however, the use of stems will not yield satisfactory categorization.', 'This is mainly due to the fact that Arabic is a non-concatenative language( #AUTHOR_TAG ) , and that the stem/infix obtained by suppression of infix and prefix add-ons is not the same for words derived from the same origin called the']","['Arabic, however, the use of stems will not yield satisfactory categorization.', 'This is mainly due to the fact that Arabic is a non-concatenative language( #AUTHOR_TAG ) , and that the stem/infix obtained by suppression of infix and prefix add-ons is not the same for words derived from the same origin called']","['Arabic, however, the use of stems will not yield satisfactory categorization.', 'This is mainly due to the fact that Arabic is a non-concatenative language( #AUTHOR_TAG ) , and that the stem/infix obtained by suppression of infix and prefix add-ons is not the same for words derived from the same origin called the root .', '']",0
"['ious feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG)(Tzeras and Hartman, 1993) , minimum description length principal(Lang, 1995) , and the χ 2 statistic.', '( #AUTHOR_TAG ) has found strong correlations between DF , IG and the X2 statistic for a term .', '']","['', 'Various feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG)(Tzeras and Hartman, 1993) , minimum description length principal(Lang, 1995) , and the χ 2 statistic.', '( #AUTHOR_TAG ) has found strong correlations between DF , IG and the X2 statistic for a term .', '']","['ious feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG)(Tzeras and Hartman, 1993) , minimum description length principal(Lang, 1995) , and the χ 2 statistic.', '( #AUTHOR_TAG ) has found strong correlations between DF , IG and the X2 statistic for a term .', '']","['', 'Various feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG)(Tzeras and Hartman, 1993) , minimum description length principal(Lang, 1995) , and the χ 2 statistic.', '( #AUTHOR_TAG ) has found strong correlations between DF , IG and the X2 statistic for a term .', '']",0
"['good study comparing document categorization algorithms can be found in(Yang and Liu, 1999) .', 'More recently ,( #AUTHOR_TAG ) has performed a good survey of document categorization ; recent works can also be found in( Joachims , 2002 ) ,( Crammer and Singer , 2003 ) , and( Lewis et al. , 2004 )']","['good study comparing document categorization algorithms can be found in(Yang and Liu, 1999) .', 'More recently ,( #AUTHOR_TAG ) has performed a good survey of document categorization ; recent works can also be found in( Joachims , 2002 ) ,( Crammer and Singer , 2003 ) , and( Lewis et al. , 2004 )']","['good study comparing document categorization algorithms can be found in(Yang and Liu, 1999) .', 'More recently ,( #AUTHOR_TAG ) has performed a good survey of document categorization ; recent works can also be found in( Joachims , 2002 ) ,( Crammer and Singer , 2003 ) , and( Lewis et al. , 2004 )']","['good study comparing document categorization algorithms can be found in(Yang and Liu, 1999) .', 'More recently ,( #AUTHOR_TAG ) has performed a good survey of document categorization ; recent works can also be found in( Joachims , 2002 ) ,( Crammer and Singer , 2003 ) , and( Lewis et al. , 2004 )']",0
"['related documents, and the classification of documents into pre-specified subject themes.', 'Automatic text categorization has been used in search engines , digital library systems , and document management systems( #AUTHOR_TAG ) .', '']","['related documents, and the classification of documents into pre-specified subject themes.', 'Automatic text categorization has been used in search engines , digital library systems , and document management systems( #AUTHOR_TAG ) .', '']","['related documents, and the classification of documents into pre-specified subject themes.', 'Automatic text categorization has been used in search engines , digital library systems , and document management systems( #AUTHOR_TAG ) .', '']","['', 'As such, one of the primary objectives of automatic text categorization has been the enhancement and the support of information retrieval tasks to tackle problems, such as information filtering and routing, clustering of related documents, and the classification of documents into pre-specified subject themes.', 'Automatic text categorization has been used in search engines , digital library systems , and document management systems( #AUTHOR_TAG ) .', '']",0
"['', 'In this paper , we use TF-IDF ( a kind of augmented DF ) as a feature selection criterion , in order to ensure results are comparable with those in( #AUTHOR_TAG ) .', 'TF-ID']","['', 'In this paper , we use TF-IDF ( a kind of augmented DF ) as a feature selection criterion , in order to ensure results are comparable with those in( #AUTHOR_TAG ) .', 'TF-IDF (term frequency-inverse document frequency)']","['', 'In this paper , we use TF-IDF ( a kind of augmented DF ) as a feature selection criterion , in order to ensure results are comparable with those in( #AUTHOR_TAG ) .', 'TF-ID']","['', 'In this paper , we use TF-IDF ( a kind of augmented DF ) as a feature selection criterion , in order to ensure results are comparable with those in( #AUTHOR_TAG ) .', '']",1
"['( #AUTHOR_TAG ) proposed the combination of TF and IDF as weighting schemes , and it has been shown that their product gave better performance .', '']","['( #AUTHOR_TAG ) proposed the combination of TF and IDF as weighting schemes , and it has been shown that their product gave better performance .', 'Thus, the weight of each term/root in a document is given by w D,t']","['( #AUTHOR_TAG ) proposed the combination of TF and IDF as weighting schemes , and it has been shown that their product gave better performance .', '']",['( #AUTHOR_TAG )'],4
"['; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG )( Tzeras and Hartman , 1993 ) , minimum description length principal( #AUTHOR_TAG ) , and the X2 statistic .', '']","['have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG )( Tzeras and Hartman , 1993 ) , minimum description length principal( #AUTHOR_TAG ) , and the X2 statistic .', '']","['ing with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG )( Tzeras and Hartman , 1993 ) , minimum description length principal( #AUTHOR_TAG ) , and the X2 statistic .', '']","['selection techniques have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG )( Tzeras and Hartman , 1993 ) , minimum description length principal( #AUTHOR_TAG ) , and the X2 statistic .', '']",0
"['machine learning algorithms have been applied for many years to text categorization.', 'include decision tree learning and Bayesian learning , nearest neighbor learning , and artificial neural networks , early such works may be found in( #AUTHOR_TAG ) ,( Creecy and Masand , 1992 ) and( Wiene and Pedersen , 1995 ) , respectively']","['machine learning algorithms have been applied for many years to text categorization.', 'include decision tree learning and Bayesian learning , nearest neighbor learning , and artificial neural networks , early such works may be found in( #AUTHOR_TAG ) ,( Creecy and Masand , 1992 ) and( Wiene and Pedersen , 1995 ) , respectively']","['machine learning algorithms have been applied for many years to text categorization.', 'include decision tree learning and Bayesian learning , nearest neighbor learning , and artificial neural networks , early such works may be found in( #AUTHOR_TAG ) ,( Creecy and Masand , 1992 ) and( Wiene and Pedersen , 1995 ) , respectively']","['machine learning algorithms have been applied for many years to text categorization.', 'include decision tree learning and Bayesian learning , nearest neighbor learning , and artificial neural networks , early such works may be found in( #AUTHOR_TAG ) ,( Creecy and Masand , 1992 ) and( Wiene and Pedersen , 1995 ) , respectively']",0
"['', 'TF-IDF ( term frequency-inverse document frequency ) is one of the widely used feature selection techniques in information retrieval( #AUTHOR_TAG ) .', '']","['', 'TF-IDF ( term frequency-inverse document frequency ) is one of the widely used feature selection techniques in information retrieval( #AUTHOR_TAG ) .', '']","['', 'TF-IDF ( term frequency-inverse document frequency ) is one of the widely used feature selection techniques in information retrieval( #AUTHOR_TAG ) .', '']","['', 'TF-IDF ( term frequency-inverse document frequency ) is one of the widely used feature selection techniques in information retrieval( #AUTHOR_TAG ) .', '']",0
"['good study comparing document categorization algorithms can be found in(Yang and Liu, 1999) .', 'More recently ,( Sebastiani , 2002 ) has performed a good survey of document categorization ; recent works can also be found in( #AUTHOR_TAG ) ,( Crammer and Singer , 2003 ) , and( Lewis et al. , 2004 )']","['good study comparing document categorization algorithms can be found in(Yang and Liu, 1999) .', 'More recently ,( Sebastiani , 2002 ) has performed a good survey of document categorization ; recent works can also be found in( #AUTHOR_TAG ) ,( Crammer and Singer , 2003 ) , and( Lewis et al. , 2004 )']","['good study comparing document categorization algorithms can be found in(Yang and Liu, 1999) .', 'More recently ,( Sebastiani , 2002 ) has performed a good survey of document categorization ; recent works can also be found in( #AUTHOR_TAG ) ,( Crammer and Singer , 2003 ) , and( Lewis et al. , 2004 )']","['good study comparing document categorization algorithms can be found in(Yang and Liu, 1999) .', 'More recently ,( Sebastiani , 2002 ) has performed a good survey of document categorization ; recent works can also be found in( #AUTHOR_TAG ) ,( Crammer and Singer , 2003 ) , and( Lewis et al. , 2004 )']",0
"[',( #AUTHOR_TAG ) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces']","[',( #AUTHOR_TAG ) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces']","[',( #AUTHOR_TAG ) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces']","['bulk of the text categorization work has been devoted to cope with automatic categorization of English and Latin character documents.', 'For example ,( #AUTHOR_TAG ) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces']",0
"['the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques(Church and Hanks, 1990 ) , on linguisitic acquisition ( by the use of Part-of-Speech filters hand-crafted by a linguist )( Oueslati , 1999 ) or , more frequently , on a combination of the two( Smadja , 1993 ; #AUTHOR_TAG , for example ) .', 'It']","['the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques(Church and Hanks, 1990 ) , on linguisitic acquisition ( by the use of Part-of-Speech filters hand-crafted by a linguist )( Oueslati , 1999 ) or , more frequently , on a combination of the two( Smadja , 1993 ; #AUTHOR_TAG , for example ) .', 'It']","['the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques(Church and Hanks, 1990 ) , on linguisitic acquisition ( by the use of Part-of-Speech filters hand-crafted by a linguist )( Oueslati , 1999 ) or , more frequently , on a combination of the two( Smadja , 1993 ; #AUTHOR_TAG , for example ) .', 'It is']","['the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques(Church and Hanks, 1990 ) , on linguisitic acquisition ( by the use of Part-of-Speech filters hand-crafted by a linguist )( Oueslati , 1999 ) or , more frequently , on a combination of the two( Smadja , 1993 ; #AUTHOR_TAG , for example ) .', '']",1
"['', 'The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde , composed of newspaper articles( #AUTHOR_TAG ) .', '']","['and called TermoStat.', 'The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde , composed of newspaper articles( #AUTHOR_TAG ) .', '']","['', 'The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde , composed of newspaper articles( #AUTHOR_TAG ) .', '']","['', 'The terms have been identified as the most specific to our corpus by a program developed byDrouin (2003) and called TermoStat.', 'The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde , composed of newspaper articles( #AUTHOR_TAG ) .', '']",5
"['number of applications have relied on distributional analysis(Harris, 1971) in order to build classes of semantically related terms.', 'This approach , which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness( #AUTHOR_TAG , for example ) , does not specify the relationship itself .', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not di\x1berentiated']","['number of applications have relied on distributional analysis(Harris, 1971) in order to build classes of semantically related terms.', 'This approach , which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness( #AUTHOR_TAG , for example ) , does not specify the relationship itself .', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not di\x1berentiated']","['number of applications have relied on distributional analysis(Harris, 1971) in order to build classes of semantically related terms.', 'This approach , which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness( #AUTHOR_TAG , for example ) , does not specify the relationship itself .', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not di\x1berentiated']","['number of applications have relied on distributional analysis(Harris, 1971) in order to build classes of semantically related terms.', 'This approach , which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness( #AUTHOR_TAG , for example ) , does not specify the relationship itself .', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not di\x1berentiated']",0
"['recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms :#AUTHOR_TAG uses derivational morphology ;Grabar and Zweigenbaum ( 2002 ) use , as a']","['recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms :#AUTHOR_TAG uses derivational morphology ;Grabar and Zweigenbaum ( 2002 ) use , as a']","['recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms :#AUTHOR_TAG uses derivational morphology ;Grabar and Zweigenbaum ( 2002 ) use , as a starting point , a number of identical characters']","['recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms :#AUTHOR_TAG uses derivational morphology ;Grabar and Zweigenbaum ( 2002 ) use , as a starting point , a number of identical characters']",0
"['), utilisateur (user ).', 'The terms have been identified as the most specific to our corpus by a program developed by#AUTHOR_TAG and called TER1vloSTAT .', 'The ten most speci c nouns have been produced by comparing our corpus of computing to the French corpus Le']","['(system), utilisateur (user ).', 'The terms have been identified as the most specific to our corpus by a program developed by#AUTHOR_TAG and called TER1vloSTAT .', 'The ten most speci c nouns have been produced by comparing our corpus of computing to the French corpus Le']","['), utilisateur (user ).', 'The terms have been identified as the most specific to our corpus by a program developed by#AUTHOR_TAG and called TER1vloSTAT .', 'The ten most speci c nouns have been produced by comparing our corpus of computing to the French corpus Le Monde,']","['', 'The terms have been identified as the most specific to our corpus by a program developed by#AUTHOR_TAG and called TER1vloSTAT .', 'The ten most speci c nouns have been produced by comparing our corpus of computing to the French corpus Le Monde, composed of newspaper articles(Lemay et al., 2004) .', '']",5
"['recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms :Daille ( 2003 ) uses derivational morphology ;#AUTHOR_TAG use , as a starting point , a number of identical characters']","['recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms :Daille ( 2003 ) uses derivational morphology ;#AUTHOR_TAG use , as a starting point , a number of identical characters']","['recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms :Daille ( 2003 ) uses derivational morphology ;#AUTHOR_TAG use , as a starting point , a number of identical characters']","['recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms :Daille ( 2003 ) uses derivational morphology ;#AUTHOR_TAG use , as a starting point , a number of identical characters']",0
"['the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques(Church and Hanks, 1990) , on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist)( #AUTHOR_TAG ) or, more frequently, on a combination of the two(Smadja, 1993;  Kilgarri\x1b andTugwell, 2001,  for example).', 'It']","['the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques(Church and Hanks, 1990) , on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist)( #AUTHOR_TAG ) or, more frequently, on a combination of the two(Smadja, 1993;  Kilgarri\x1b andTugwell, 2001,  for example).', 'It']","['the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques(Church and Hanks, 1990) , on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist)( #AUTHOR_TAG ) or, more frequently, on a combination of the two(Smadja, 1993;  Kilgarri\x1b andTugwell, 2001,  for example).', 'It is']","['the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques(Church and Hanks, 1990) , on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist)( #AUTHOR_TAG ) or, more frequently, on a combination of the two(Smadja, 1993;  Kilgarri\x1b andTugwell, 2001,  for example).', '']",1
"['SARES is based on a Machine Learning technique , Inductive Logic Programming ( ILP )( #AUTHOR_TAG ) , which infers general morpho-syntactic patterns from a set of examples ( this set is noted E + hereafter ) and counter-examples ( E â\x88\x92 ) of the elements one wants to acquire and their context.', 'The contextual patterns produced can then be applied to the corpus in order to retrieve new elements.', 'The acquisition process can be summarized in 3 steps']","['SARES is based on a Machine Learning technique , Inductive Logic Programming ( ILP )( #AUTHOR_TAG ) , which infers general morpho-syntactic patterns from a set of examples ( this set is noted E + hereafter ) and counter-examples ( E â\x88\x92 ) of the elements one wants to acquire and their context.', 'The contextual patterns produced can then be applied to the corpus in order to retrieve new elements.', 'The acquisition process can be summarized in 3 steps']","['SARES is based on a Machine Learning technique , Inductive Logic Programming ( ILP )( #AUTHOR_TAG ) , which infers general morpho-syntactic patterns from a set of examples ( this set is noted E + hereafter ) and counter-examples ( E â\x88\x92 ) of the elements one wants to acquire and their context.', 'The contextual patterns produced can then be applied to the corpus in order to retrieve new elements.', 'The acquisition process can be summarized in 3 steps']","['SARES is based on a Machine Learning technique , Inductive Logic Programming ( ILP )( #AUTHOR_TAG ) , which infers general morpho-syntactic patterns from a set of examples ( this set is noted E + hereafter ) and counter-examples ( E â\x88\x92 ) of the elements one wants to acquire and their context.', 'The contextual patterns produced can then be applied to the corpus in order to retrieve new elements.', 'The acquisition process can be summarized in 3 steps']",0
"[', most strategies are based on `` internal or `` external methods( #AUTHOR_TAG ) , i.e. methods that rely on the form of terms or on the information gathered from contexts .', '(In some cases, an additional resource, such as a dictionary or a thes']","[', most strategies are based on `` internal or `` external methods( #AUTHOR_TAG ) , i.e. methods that rely on the form of terms or on the information gathered from contexts .', '(In some cases, an additional resource, such as a dictionary or a thesaurus, is used during the']","[', most strategies are based on `` internal or `` external methods( #AUTHOR_TAG ) , i.e. methods that rely on the form of terms or on the information gathered from contexts .', '(In some cases, an additional resource, such as a dictionary or a thesaurus, is used during']","[', most strategies are based on `` internal or `` external methods( #AUTHOR_TAG ) , i.e. methods that rely on the form of terms or on the information gathered from contexts .', '(In some cases, an additional resource, such as a dictionary or a thesaurus, is used during the identification process.)', '']",1
"['this paper, the method is applied to a French corpus on computing to and noun-verb combinations in which verbs convey a meaning of realization.', 'The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information( #AUTHOR_TAG )']","['this paper, the method is applied to a French corpus on computing to and noun-verb combinations in which verbs convey a meaning of realization.', 'The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information( #AUTHOR_TAG )']","['this paper, the method is applied to a French corpus on computing to and noun-verb combinations in which verbs convey a meaning of realization.', 'The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information( #AUTHOR_TAG )']","['this paper, the method is applied to a French corpus on computing to and noun-verb combinations in which verbs convey a meaning of realization.', 'The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information( #AUTHOR_TAG )']",4
"['addition to its explanatory capacity , this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques( #AUTHOR_TAG )']","['addition to its explanatory capacity , this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques( #AUTHOR_TAG )']","['addition to its explanatory capacity , this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques( #AUTHOR_TAG )']","['addition to its explanatory capacity , this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques( #AUTHOR_TAG )']",4
"['SARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework( #AUTHOR_TAG ) and called qualia relations( Bouillon et al. , 2001 ) .', '']","['SARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework( #AUTHOR_TAG ) and called qualia relations( Bouillon et al. , 2001 ) .', '']","['SARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework( #AUTHOR_TAG ) and called qualia relations( Bouillon et al. , 2001 ) .', '']","['SARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework( #AUTHOR_TAG ) and called qualia relations( Bouillon et al. , 2001 ) .', 'Here, we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']",0
['can be used to extend indices or reformulate queries ( similar to the work by#AUTHOR_TAG with WoRDNET relations )'],['can be used to extend indices or reformulate queries ( similar to the work by#AUTHOR_TAG with WoRDNET relations )'],['such rich semantic links can be used to extend indices or reformulate queries ( similar to the work by#AUTHOR_TAG with WoRDNET relations )'],"['', 'Indeed , such rich semantic links can be used to extend indices or reformulate queries ( similar to the work by#AUTHOR_TAG with WoRDNET relations )']",1
"['SARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework( Pustejovsky , 1995 ) and called qualia relations( #AUTHOR_TAG ) .', 'Here, we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']","['SARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework( Pustejovsky , 1995 ) and called qualia relations( #AUTHOR_TAG ) .', 'Here, we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']","['SARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework( Pustejovsky , 1995 ) and called qualia relations( #AUTHOR_TAG ) .', 'Here, we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']","['SARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework( Pustejovsky , 1995 ) and called qualia relations( #AUTHOR_TAG ) .', 'Here, we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']",0
"['main benefits of this acquisition technique lie in the inferred patterns.', 'Indeed , contrary to the more classical statistical methods ( Mutual Information , Loglike ... , see below ) used for collocation acquisition ( see( #AUTHOR_TAG ) for a review ) , these patterns allow']","['main benefits of this acquisition technique lie in the inferred patterns.', 'Indeed , contrary to the more classical statistical methods ( Mutual Information , Loglike ... , see below ) used for collocation acquisition ( see( #AUTHOR_TAG ) for a review ) , these patterns allow']","['main benefits of this acquisition technique lie in the inferred patterns.', 'Indeed , contrary to the more classical statistical methods ( Mutual Information , Loglike ... , see below ) used for collocation acquisition ( see( #AUTHOR_TAG ) for a review ) , these patterns allow']","['main benefits of this acquisition technique lie in the inferred patterns.', 'Indeed , contrary to the more classical statistical methods ( Mutual Information , Loglike ... , see below ) used for collocation acquisition ( see( #AUTHOR_TAG ) for a review ) , these patterns allow']",0
"['method used for the acquisition of N-V pairs relies mainly on asares, a pattern inference tool.', 'ASARES is presented in detail in( #AUTHOR_TAG ) .', 'We simply give a short account of its basic principles herein']","['method used for the acquisition of N-V pairs relies mainly on asares, a pattern inference tool.', 'ASARES is presented in detail in( #AUTHOR_TAG ) .', 'We simply give a short account of its basic principles herein']","['method used for the acquisition of N-V pairs relies mainly on asares, a pattern inference tool.', 'ASARES is presented in detail in( #AUTHOR_TAG ) .', 'We simply give a short account of its basic principles herein']","['method used for the acquisition of N-V pairs relies mainly on asares, a pattern inference tool.', 'ASARES is presented in detail in( #AUTHOR_TAG ) .', 'We simply give a short account of its basic principles herein']",5
"['number of applications have relied on distributional analysis( #AUTHOR_TAG ) in order to build classes of semantically related terms .', 'This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness(Habert et al., 1996,  for example), does not']","['number of applications have relied on distributional analysis( #AUTHOR_TAG ) in order to build classes of semantically related terms .', 'This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness(Habert et al., 1996,  for example), does not']","['number of applications have relied on distributional analysis( #AUTHOR_TAG ) in order to build classes of semantically related terms .', 'This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness(Habert et al., 1996,  for example), does not']","['number of applications have relied on distributional analysis( #AUTHOR_TAG ) in order to build classes of semantically related terms .', 'This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness(Habert et al., 1996,  for example), does not specify the relationship itself.', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not differentiated']",0
"['different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging( #AUTHOR_TAG ; Xu et al. , 2002 )']","['different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging( #AUTHOR_TAG ; Xu et al. , 2002 )']","['the different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging( #AUTHOR_TAG ; Xu et al. , 2002 )']","['', 'In addition to the different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging( #AUTHOR_TAG ; Xu et al. , 2002 )']",0
"['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; #AUTHOR_TAG ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; #AUTHOR_TAG ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; #AUTHOR_TAG ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; #AUTHOR_TAG ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']",0
"['we will adopt the nomenclature of the Automatic Content Extraction program( #AUTHOR_TAG ) : we will call the instances of textual references to objects/abstractions mentions , which']","['we will adopt the nomenclature of the Automatic Content Extraction program( #AUTHOR_TAG ) : we will call the instances of textual references to objects/abstractions mentions , which']","['we will adopt the nomenclature of the Automatic Content Extraction program( #AUTHOR_TAG ) : we will call the instances of textual references to objects/abstractions mentions , which']","['', 'Instead , we will adopt the nomenclature of the Automatic Content Extraction program( #AUTHOR_TAG ) : we will call the instances of textual references to objects/abstractions mentions , which can be either named ( e.g. John Mayor ) , nominal ( the president ) or pronominal ( she , it ) .', '']",5
"['addition to the model based upon a dictionary of stems and words , we also experimented with models based upon character n-grams , similar to those used for Chinese segmentation( #AUTHOR_TAG ) .', '']","['addition to the model based upon a dictionary of stems and words , we also experimented with models based upon character n-grams , similar to those used for Chinese segmentation( #AUTHOR_TAG ) .', '']","['addition to the model based upon a dictionary of stems and words , we also experimented with models based upon character n-grams , similar to those used for Chinese segmentation( #AUTHOR_TAG ) .', '']","['addition to the model based upon a dictionary of stems and words , we also experimented with models based upon character n-grams , similar to those used for Chinese segmentation( #AUTHOR_TAG ) .', '']",1
"['types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the#AUTHOR_TAG Arabic data .', 'The experiments are performed on a clearly specified partition']","['types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the#AUTHOR_TAG Arabic data .', 'The experiments are performed on a clearly specified partition']","['types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the#AUTHOR_TAG Arabic data .', 'The experiments are performed on a clearly specified partition']","['types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the#AUTHOR_TAG Arabic data .', '']",5
"['', 'Each punctuation symbol is considered a separate token.', 'Character classes , such as punctuation , are defined according to the Unicode Standard( #AUTHOR_TAG )']","['', 'Each punctuation symbol is considered a separate token.', 'Character classes , such as punctuation , are defined according to the Unicode Standard( #AUTHOR_TAG )']","['', 'Each punctuation symbol is considered a separate token.', 'Character classes , such as punctuation , are defined according to the Unicode Standard( #AUTHOR_TAG )']","['', 'Each punctuation symbol is considered a separate token.', 'Character classes , such as punctuation , are defined according to the Unicode Standard( #AUTHOR_TAG )']",5
"['different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging( Xu et al. , 2001 ; #AUTHOR_TAG )']","['different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging( Xu et al. , 2001 ; #AUTHOR_TAG )']","['the different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging( Xu et al. , 2001 ; #AUTHOR_TAG )']","['', 'In addition to the different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging( Xu et al. , 2001 ; #AUTHOR_TAG )']",0
['coreference system system is similar to the Bell tree algorithm as described by( #AUTHOR_TAG )'],['coreference system system is similar to the Bell tree algorithm as described by( #AUTHOR_TAG )'],['coreference system system is similar to the Bell tree algorithm as described by( #AUTHOR_TAG )'],['coreference system system is similar to the Bell tree algorithm as described by( #AUTHOR_TAG )'],1
"['ic has two kinds of plurals : broken plurals and sound plurals( #AUTHOR_TAG ; Chen and Gey , 2002 ) .', 'The formation of broken plurals is common, more']","['ic has two kinds of plurals : broken plurals and sound plurals( #AUTHOR_TAG ; Chen and Gey , 2002 ) .', 'The formation of broken plurals is common, more']","['ic has two kinds of plurals : broken plurals and sound plurals( #AUTHOR_TAG ; Chen and Gey , 2002 ) .', 'The formation of broken plurals is common, more']","['ic has two kinds of plurals : broken plurals and sound plurals( #AUTHOR_TAG ; Chen and Gey , 2002 ) .', 'The formation of broken plurals is common, more complex and often irregular.', '']",0
"['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; #AUTHOR_TAG ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; #AUTHOR_TAG ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; #AUTHOR_TAG ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; #AUTHOR_TAG ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']",0
"['', 'We use a maximum entropy Markov model (MEMM) classifier.', 'The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model )( #AUTHOR_TAG ) .', '']","['', 'We use a maximum entropy Markov model (MEMM) classifier.', 'The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model )( #AUTHOR_TAG ) .', '']","['', 'We use a maximum entropy Markov model (MEMM) classifier.', 'The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model )( #AUTHOR_TAG ) .', '']","['', 'We use a maximum entropy Markov model (MEMM) classifier.', 'The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model )( #AUTHOR_TAG ) .', '']",0
"['mention sub-type , which is a sub-category of the mention type( #AUTHOR_TAG ) ( e.g. OrgGovernmental , FacilityPath , etc. )']","['mention sub-type , which is a sub-category of the mention type( #AUTHOR_TAG ) ( e.g. OrgGovernmental , FacilityPath , etc. )']","['mention sub-type , which is a sub-category of the mention type( #AUTHOR_TAG ) ( e.g. OrgGovernmental , FacilityPath , etc. )']","['mention sub-type , which is a sub-category of the mention type( #AUTHOR_TAG ) ( e.g. OrgGovernmental , FacilityPath , etc. )']",5
"['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; #AUTHOR_TAG ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; #AUTHOR_TAG ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; #AUTHOR_TAG ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; #AUTHOR_TAG ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']",0
"['demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation .', 'A trigram language model was used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules']","['demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation .', 'A trigram language model was used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules']","['demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation .', 'A trigram language model was used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules']","['demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation .', 'A trigram language model was used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules']",5
"['the mention detection system is similar to the one presented in(Florian et al., 2004) and the coreference resolution system is similar to the one described in .', 'Both systems are built around from the maximum-entropy technique( #AUTHOR_TAG ) .', '']","['tasks are performed with a statistical framework: the mention detection system is similar to the one presented in(Florian et al., 2004) and the coreference resolution system is similar to the one described in .', 'Both systems are built around from the maximum-entropy technique( #AUTHOR_TAG ) .', '']","['tasks are performed with a statistical framework: the mention detection system is similar to the one presented in(Florian et al., 2004) and the coreference resolution system is similar to the one described in .', 'Both systems are built around from the maximum-entropy technique( #AUTHOR_TAG ) .', '']","['tasks are performed with a statistical framework: the mention detection system is similar to the one presented in(Florian et al., 2004) and the coreference resolution system is similar to the one described in .', 'Both systems are built around from the maximum-entropy technique( #AUTHOR_TAG ) .', '']",5
"['tasks are performed with a statistical framework : the mention detection system is similar to the one presented in( #AUTHOR_TAG ) and the coreference resolution system is similar to the one described in( Luo et al. , 2004 ) .', '']","['tasks are performed with a statistical framework : the mention detection system is similar to the one presented in( #AUTHOR_TAG ) and the coreference resolution system is similar to the one described in( Luo et al. , 2004 ) .', '']","['tasks are performed with a statistical framework : the mention detection system is similar to the one presented in( #AUTHOR_TAG ) and the coreference resolution system is similar to the one described in( Luo et al. , 2004 ) .', '']","['tasks are performed with a statistical framework : the mention detection system is similar to the one presented in( #AUTHOR_TAG ) and the coreference resolution system is similar to the one described in( Luo et al. , 2004 ) .', '']",1
"['context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not( #AUTHOR_TAG ) .', 'We denote these features as backward token tri-grams and forward token tri-grams for the previous and next context of t i respectively.', 'For a token t i , the backward token n-gram feature will contains the previous n − 1 tokens in the']","['context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not( #AUTHOR_TAG ) .', 'We denote these features as backward token tri-grams and forward token tri-grams for the previous and next context of t i respectively.', 'For a token t i , the backward token n-gram feature will contains the previous n − 1 tokens in the']","['context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not( #AUTHOR_TAG ) .', 'We denote these features as backward token tri-grams and forward token tri-grams for the previous and next context of t i respectively.', 'For a token t i , the backward token n-gram feature will contains the previous n − 1 tokens in the history (t i−n+1']","['context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not( #AUTHOR_TAG ) .', 'We denote these features as backward token tri-grams and forward token tri-grams for the previous and next context of t i respectively.', 'For a token t i , the backward token n-gram feature will contains the previous n − 1 tokens in the history (t i−n+1 , . . .', 't i−1 ) and the forward token n-gram feature will contains the next n − 1 tokens (t i+1 , . . .', '']",0
"['using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution( #AUTHOR_TAG ) .', 'For Arabic, since words are morphologically derived from a list of']","['using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution( #AUTHOR_TAG ) .', 'For Arabic, since words are morphologically derived from a list of']","['using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution( #AUTHOR_TAG ) .', 'For Arabic, since words are morphologically derived from a list of']","['using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution( #AUTHOR_TAG ) .', '']",5
"['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; #AUTHOR_TAG ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; #AUTHOR_TAG ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; #AUTHOR_TAG ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; #AUTHOR_TAG ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']",0
"['', 'We seeked to exploit this ability to generalize to improve the dictionary based model.', 'As in( #AUTHOR_TAG ) , we used unsupervised training data which is automatically segmented to discover previously unseen stems .', '']","['', 'We seeked to exploit this ability to generalize to improve the dictionary based model.', 'As in( #AUTHOR_TAG ) , we used unsupervised training data which is automatically segmented to discover previously unseen stems .', '']","['', 'We seeked to exploit this ability to generalize to improve the dictionary based model.', 'As in( #AUTHOR_TAG ) , we used unsupervised training data which is automatically segmented to discover previously unseen stems .', '']","['', 'We seeked to exploit this ability to generalize to improve the dictionary based model.', 'As in( #AUTHOR_TAG ) , we used unsupervised training data which is automatically segmented to discover previously unseen stems .', '']",5
"['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; #AUTHOR_TAG ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; #AUTHOR_TAG ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; #AUTHOR_TAG ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; #AUTHOR_TAG ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']",0
"['', 'We introduce here a clearly defined and replicable split of the#AUTHOR_TAG data , so that future investigations can accurately and correctly compare against the results presented here']","['', 'We introduce here a clearly defined and replicable split of the#AUTHOR_TAG data , so that future investigations can accurately and correctly compare against the results presented here']","['', 'We introduce here a clearly defined and replicable split of the#AUTHOR_TAG data , so that future investigations can accurately and correctly compare against the results presented here']","['', 'We introduce here a clearly defined and replicable split of the#AUTHOR_TAG data , so that future investigations can accurately and correctly compare against the results presented here']",5
"['', 'The final machine is a trigram language model , specifically a Kneser-Ney( #AUTHOR_TAG ) based backoff language model .', '']","['', 'The final machine is a trigram language model , specifically a Kneser-Ney( #AUTHOR_TAG ) based backoff language model .', '']","['', 'The final machine is a trigram language model , specifically a Kneser-Ney( #AUTHOR_TAG ) based backoff language model .', '']","['', 'The final machine is a trigram language model , specifically a Kneser-Ney( #AUTHOR_TAG ) based backoff language model .', '']",5
"['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; #AUTHOR_TAG ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; #AUTHOR_TAG ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; #AUTHOR_TAG ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( Bikel et al. , 1997 ; #AUTHOR_TAG ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']",0
"['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( #AUTHOR_TAG ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( #AUTHOR_TAG ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( #AUTHOR_TAG ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']","['this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations( #AUTHOR_TAG ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '']",0
"['', 'We report results with two metrics: ECM-F and ACE- Value.', 'ECM-F is an entity-constrained mention Fmeasure ( cfXXX( #AUTHOR_TAG ) for how ECM-F is computed ) , and A']","['', 'We report results with two metrics: ECM-F and ACE- Value.', 'ECM-F is an entity-constrained mention Fmeasure ( cfXXX( #AUTHOR_TAG ) for how ECM-F is computed ) , and']","['', 'We report results with two metrics: ECM-F and ACE- Value.', 'ECM-F is an entity-constrained mention Fmeasure ( cfXXX( #AUTHOR_TAG ) for how ECM-F is computed ) , and A']","['', 'We report results with two metrics: ECM-F and ACE- Value.', 'ECM-F is an entity-constrained mention Fmeasure ( cfXXX( #AUTHOR_TAG ) for how ECM-F is computed ) , and ACE-Value is the official ACE evaluation metric .', '']",5
"['ic has two kinds of plurals : broken plurals and sound plurals( Wightwick and Gaafar , 1998 ; #AUTHOR_TAG ) .', 'The formation of broken plurals is common, more']","['ic has two kinds of plurals : broken plurals and sound plurals( Wightwick and Gaafar , 1998 ; #AUTHOR_TAG ) .', 'The formation of broken plurals is common, more']","['ic has two kinds of plurals : broken plurals and sound plurals( Wightwick and Gaafar , 1998 ; #AUTHOR_TAG ) .', 'The formation of broken plurals is common, more']","['ic has two kinds of plurals : broken plurals and sound plurals( Wightwick and Gaafar , 1998 ; #AUTHOR_TAG ) .', 'The formation of broken plurals is common, more complex and often irregular.', '']",0
"['tasks are performed with a statistical framework : the mention detection system is similar to the one presented in( Florian et al. , 2004 ) and the coreference resolution system is similar to the one described in( #AUTHOR_TAG ) .', 'Both systems are built around from the maximum-entropy technique(Berger et al., 1996)']","['tasks are performed with a statistical framework : the mention detection system is similar to the one presented in( Florian et al. , 2004 ) and the coreference resolution system is similar to the one described in( #AUTHOR_TAG ) .', 'Both systems are built around from the maximum-entropy technique(Berger et al., 1996)']","['tasks are performed with a statistical framework : the mention detection system is similar to the one presented in( Florian et al. , 2004 ) and the coreference resolution system is similar to the one described in( #AUTHOR_TAG ) .', 'Both systems are built around from the maximum-entropy technique(Berger et al., 1996) .', '']","['tasks are performed with a statistical framework : the mention detection system is similar to the one presented in( Florian et al. , 2004 ) and the coreference resolution system is similar to the one described in( #AUTHOR_TAG ) .', 'Both systems are built around from the maximum-entropy technique(Berger et al., 1996) .', '']",1
"['want to investigate the usefulness of stem n- gram features in the mention detection system.', ""As stated before , the experiments are run in the ACE '04 framework( #AUTHOR_TAG ) where the system will identify mentions and will label them ( cfXXX Section 4 ) with a type ( person , organization , etc ) , a sub-type ( OrgCommercial , OrgGovernmental , etc ) , a mention level ( named , nominal , etc ) , and a class ( specific , generic , etc ) ."", 'Detecting the mention']","['want to investigate the usefulness of stem n- gram features in the mention detection system.', ""As stated before , the experiments are run in the ACE '04 framework( #AUTHOR_TAG ) where the system will identify mentions and will label them ( cfXXX Section 4 ) with a type ( person , organization , etc ) , a sub-type ( OrgCommercial , OrgGovernmental , etc ) , a mention level ( named , nominal , etc ) , and a class ( specific , generic , etc ) ."", 'Detecting the mention']","['want to investigate the usefulness of stem n- gram features in the mention detection system.', ""As stated before , the experiments are run in the ACE '04 framework( #AUTHOR_TAG ) where the system will identify mentions and will label them ( cfXXX Section 4 ) with a type ( person , organization , etc ) , a sub-type ( OrgCommercial , OrgGovernmental , etc ) , a mention level ( named , nominal , etc ) , and a class ( specific , generic , etc ) ."", 'Detecting the mention']","['want to investigate the usefulness of stem n- gram features in the mention detection system.', ""As stated before , the experiments are run in the ACE '04 framework( #AUTHOR_TAG ) where the system will identify mentions and will label them ( cfXXX Section 4 ) with a type ( person , organization , etc ) , a sub-type ( OrgCommercial , OrgGovernmental , etc ) , a mention level ( named , nominal , etc ) , and a class ( specific , generic , etc ) ."", '']",5
"['mk is one mention in entity e , and the basic model building block PL ( L = 1 | e , mk , m ) is an exponential or maximum entropy model( #AUTHOR_TAG )']","['mk is one mention in entity e , and the basic model building block PL ( L = 1 | e , mk , m ) is an exponential or maximum entropy model( #AUTHOR_TAG )']","['mk is one mention in entity e , and the basic model building block PL ( L = 1 | e , mk , m ) is an exponential or maximum entropy model( #AUTHOR_TAG )']","['mk is one mention in entity e , and the basic model building block PL ( L = 1 | e , mk , m ) is an exponential or maximum entropy model( #AUTHOR_TAG )']",5
"['experiment.', '#AUTHOR_TAG observed that some annotators were not familiar with the exact definition of semantic relatedness .', 'Their results differed particularly in cases of antonymy or distributionally related pairs.', 'We']","['experiment.', '#AUTHOR_TAG observed that some annotators were not familiar with the exact definition of semantic relatedness .', 'Their results differed particularly in cases of antonymy or distributionally related pairs.', 'We']","['the experiment.', '#AUTHOR_TAG observed that some annotators were not familiar with the exact definition of semantic relatedness .', 'Their results differed particularly in cases of antonymy or distributionally related pairs.', 'We created']","['', '#AUTHOR_TAG observed that some annotators were not familiar with the exact definition of semantic relatedness .', 'Their results differed particularly in cases of antonymy or distributionally related pairs.', 'We created a manual with a detailed introduction to SR stressing the crucial points.', '']",4
"['correction.', 'It is defined on different kinds of textual units, e.g.', 'documents, parts of a document (e.g.', 'words and their surrounding context), words or concepts( #AUTHOR_TAG ) .']","['spelling correction.', 'It is defined on different kinds of textual units, e.g.', 'documents, parts of a document (e.g.', 'words and their surrounding context), words or concepts( #AUTHOR_TAG ) .']","['spelling correction.', 'It is defined on different kinds of textual units, e.g.', 'documents, parts of a document (e.g.', 'words and their surrounding context), words or concepts( #AUTHOR_TAG ) .']",['( #AUTHOR_TAG )'],0
"['', 'In psycholinguistics , relatedness of words can also be determined through association tests ( Schulte im#AUTHOR_TAG ) . Table 1: Comparison of previous experiments.', 'R/G=Rubenstein and Goodenough, M/C=Miller and Charles, Res=Resnik, Fin=Finkelstein, Gur=Gurevych, Z/G=Zesch and Gurevych similarity from']","['', 'In psycholinguistics , relatedness of words can also be determined through association tests ( Schulte im#AUTHOR_TAG ) . Table 1: Comparison of previous experiments.', 'R/G=Rubenstein and Goodenough, M/C=Miller and Charles, Res=Resnik, Fin=Finkelstein, Gur=Gurevych, Z/G=Zesch and Gurevych similarity from']","['', 'In psycholinguistics , relatedness of words can also be determined through association tests ( Schulte im#AUTHOR_TAG ) . Table 1: Comparison of previous experiments.', 'R/G=Rubenstein and Goodenough, M/C=Miller and Charles, Res=Resnik, Fin=Finkelstein, Gur=Gurevych, Z/G=Zesch and Gurevych similarity from']","['', 'In psycholinguistics , relatedness of words can also be determined through association tests ( Schulte im#AUTHOR_TAG ) . Table 1: Comparison of previous experiments.', 'R/G=Rubenstein and Goodenough, M/C=Miller and Charles, Res=Resnik, Fin=Finkelstein, Gur=Gurevych, Z/G=Zesch and Gurevych similarity from ""not similar"" to ""synonymous"".', '']",0
"['to#AUTHOR_TAG , there are three prevalent approaches for evaluating SR measures : mathematical analysis , applicationspecific evaluation and comparison with human judgments']","['to#AUTHOR_TAG , there are three prevalent approaches for evaluating SR measures : mathematical analysis , applicationspecific evaluation and comparison with human judgments']","['to#AUTHOR_TAG , there are three prevalent approaches for evaluating SR measures : mathematical analysis , applicationspecific evaluation and comparison with human judgments']","['to#AUTHOR_TAG , there are three prevalent approaches for evaluating SR measures : mathematical analysis , applicationspecific evaluation and comparison with human judgments']",0
"['even with the present setup, automatic extraction of concept pairs performs remarkably well and can be used to quickly create balanced test datasets.', '#AUTHOR_TAG pointed out that distribution plots of judgments for the word pairs used by Rubenstein and Goodenough display an empty horizontal band that could be used to separate related and unrelated pairs .', 'This empty band is not observed here']","['even with the present setup, automatic extraction of concept pairs performs remarkably well and can be used to quickly create balanced test datasets.', '#AUTHOR_TAG pointed out that distribution plots of judgments for the word pairs used by Rubenstein and Goodenough display an empty horizontal band that could be used to separate related and unrelated pairs .', 'This empty band is not observed here.', 'However, Figure 4 shows the distribution of averaged judgments with the highest agreement between annotators (standard deviation < 0.8).', 'The plot clearly shows an empty horizontal band with']","['even with the present setup, automatic extraction of concept pairs performs remarkably well and can be used to quickly create balanced test datasets.', '#AUTHOR_TAG pointed out that distribution plots of judgments for the word pairs used by Rubenstein and Goodenough display an empty horizontal band that could be used to separate related and unrelated pairs .', 'This empty band is not observed here']","['', 'However, even with the present setup, automatic extraction of concept pairs performs remarkably well and can be used to quickly create balanced test datasets.', '#AUTHOR_TAG pointed out that distribution plots of judgments for the word pairs used by Rubenstein and Goodenough display an empty horizontal band that could be used to separate related and unrelated pairs .', 'This empty band is not observed here.', 'However, Figure 4 shows the distribution of averaged judgments with the highest agreement between annotators (standard deviation < 0.8).', 'The plot clearly shows an empty horizontal band with no judgments.', 'The connection between averaged judgments and standard deviation is plotted in Figure 5']",1
"['', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'This setup is also scalable to a higher number of word pairs ( 350 ) as was shown in#AUTHOR_TAG .', '']","['', 'Gurevych (2005) replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German.', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'This setup is also scalable to a higher number of word pairs ( 350 ) as was shown in#AUTHOR_TAG .', '']","['', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'This setup is also scalable to a higher number of word pairs ( 350 ) as was shown in#AUTHOR_TAG .', '']","['', 'Furthermore, semantic relatedness is an intuitive concept and being forced to assign fine-grained continuous values is felt to overstrain the test subjects.', 'Gurevych (2005) replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German.', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'This setup is also scalable to a higher number of word pairs ( 350 ) as was shown in#AUTHOR_TAG .', '']",0
"['', 'This experiment was again replicated by#AUTHOR_TAG with 10 subjects .', 'Table ']","['', 'This experiment was again replicated by#AUTHOR_TAG with 10 subjects .', 'Table ']","['', 'This experiment was again replicated by#AUTHOR_TAG with 10 subjects .', 'Table ']","['', 'This experiment was again replicated by#AUTHOR_TAG with 10 subjects .', 'Table ']",0
"['extracted word pairs from three different domain-specific corpora (see Table 2).', 'This is motivated by the aim to enable research in information retrieval incorporating SR measures.', ""In particular , the `` Semantic Information Retrieval '' project ( SIR#AUTHOR_TAG ) systematically investigates the use of lexical-semantic relations between words or concepts for improving the performance of information retrieval systems""]","['extracted word pairs from three different domain-specific corpora (see Table 2).', 'This is motivated by the aim to enable research in information retrieval incorporating SR measures.', ""In particular , the `` Semantic Information Retrieval '' project ( SIR#AUTHOR_TAG ) systematically investigates the use of lexical-semantic relations between words or concepts for improving the performance of information retrieval systems""]","['extracted word pairs from three different domain-specific corpora (see Table 2).', 'This is motivated by the aim to enable research in information retrieval incorporating SR measures.', ""In particular , the `` Semantic Information Retrieval '' project ( SIR#AUTHOR_TAG ) systematically investigates the use of lexical-semantic relations between words or concepts for improving the performance of information retrieval systems""]","['extracted word pairs from three different domain-specific corpora (see Table 2).', 'This is motivated by the aim to enable research in information retrieval incorporating SR measures.', ""In particular , the `` Semantic Information Retrieval '' project ( SIR#AUTHOR_TAG ) systematically investigates the use of lexical-semantic relations between words or concepts for improving the performance of information retrieval systems""]",4
"['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( #AUTHOR_TAG ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( #AUTHOR_TAG ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( #AUTHOR_TAG ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( #AUTHOR_TAG ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']",0
"[', 15% noun-verb pairs and so on.', 'Word pairs containing polysemous words are expanded to concept pairs using GermaNet( #AUTHOR_TAG ) , the German equivalent to WordNet , as a sense inventory for each word .', 'It is the most complete resource of this type for German']","['were noun-noun pairs, 15% noun-verb pairs and so on.', 'Word pairs containing polysemous words are expanded to concept pairs using GermaNet( #AUTHOR_TAG ) , the German equivalent to WordNet , as a sense inventory for each word .', 'It is the most complete resource of this type for German']","['were noun-noun pairs, 15% noun-verb pairs and so on.', 'Word pairs containing polysemous words are expanded to concept pairs using GermaNet( #AUTHOR_TAG ) , the German equivalent to WordNet , as a sense inventory for each word .', 'It is the most complete resource of this type for German']","['', 'We used the following parameters: were noun-noun pairs, 15% noun-verb pairs and so on.', 'Word pairs containing polysemous words are expanded to concept pairs using GermaNet( #AUTHOR_TAG ) , the German equivalent to WordNet , as a sense inventory for each word .', 'It is the most complete resource of this type for German']",5
"['ical analysis can assess a measure with respect to some formal properties , e.g. whether a measure is a metric( #AUTHOR_TAG ) .4', 'However, mathematical analysis cannot tell us whether a measure closely resembles human judgments or whether it performs best when used in a certain application']","['ical analysis can assess a measure with respect to some formal properties , e.g. whether a measure is a metric( #AUTHOR_TAG ) .4', 'However, mathematical analysis cannot tell us whether a measure closely resembles human judgments or whether it performs best when used in a certain application']","['ical analysis can assess a measure with respect to some formal properties , e.g. whether a measure is a metric( #AUTHOR_TAG ) .4', 'However, mathematical analysis cannot tell us whether a measure closely resembles human judgments or whether it performs best when used in a certain application']","['ical analysis can assess a measure with respect to some formal properties , e.g. whether a measure is a metric( #AUTHOR_TAG ) .4', 'However, mathematical analysis cannot tell us whether a measure closely resembles human judgments or whether it performs best when used in a certain application']",0
"['', '#AUTHOR_TAG reported an intra-subject correlation of r = .85 for 15 subjects judging the similarity of a subset ( 36 ) of the original 65 word pairs .', 'The values may again not be compared directly.', '']","['', '#AUTHOR_TAG reported an intra-subject correlation of r = .85 for 15 subjects judging the similarity of a subset ( 36 ) of the original 65 word pairs .', 'The values may again not be compared directly.', 'Furthermore, we cannot generalize from these results,']","['', '#AUTHOR_TAG reported an intra-subject correlation of r = .85 for 15 subjects judging the similarity of a subset ( 36 ) of the original 65 word pairs .', 'The values may again not be compared directly.', '']","['', '#AUTHOR_TAG reported an intra-subject correlation of r = .85 for 15 subjects judging the similarity of a subset ( 36 ) of the original 65 word pairs .', 'The values may again not be compared directly.', 'Furthermore, we cannot generalize from these results, because the number of participants which repeated our experiment was too low']",1
"['', 'We used the revised experimental setup( #AUTHOR_TAG ) , based on discrete relatedness scores and presentation of word pairs in isolation , that is scalable to the higher number of pairs .', '']","['', 'We used the revised experimental setup( #AUTHOR_TAG ) , based on discrete relatedness scores and presentation of word pairs in isolation , that is scalable to the higher number of pairs .', '']","['', 'We used the revised experimental setup( #AUTHOR_TAG ) , based on discrete relatedness scores and presentation of word pairs in isolation , that is scalable to the higher number of pairs .', '']","['', 'We used the revised experimental setup( #AUTHOR_TAG ) , based on discrete relatedness scores and presentation of word pairs in isolation , that is scalable to the higher number of pairs .', '']",5
"['our experiment , we annotated a high number of pairs similar in size to the test sets byFinkelstein ( 2002 ) and#AUTHOR_TAG .', 'We used the rev']","['our experiment , we annotated a high number of pairs similar in size to the test sets byFinkelstein ( 2002 ) and#AUTHOR_TAG .', 'We used the revised']","['our experiment , we annotated a high number of pairs similar in size to the test sets byFinkelstein ( 2002 ) and#AUTHOR_TAG .', 'We used']","['our experiment , we annotated a high number of pairs similar in size to the test sets byFinkelstein ( 2002 ) and#AUTHOR_TAG .', '']",1
"['ious approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; #AUTHOR_TAG ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; #AUTHOR_TAG ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; #AUTHOR_TAG ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; #AUTHOR_TAG ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']",0
"['3', 'Dissimilar words can be semantically related, e.g.', 'via functional relationships (night -dark) or when they are antonyms (high -low).', 'Many NLP applications require knowledge about semantic relatedness rather than just similarity( #AUTHOR_TAG )']","['3', 'Dissimilar words can be semantically related, e.g.', 'via functional relationships (night -dark) or when they are antonyms (high -low).', 'Many NLP applications require knowledge about semantic relatedness rather than just similarity( #AUTHOR_TAG )']","['3', 'Dissimilar words can be semantically related, e.g.', 'via functional relationships (night -dark) or when they are antonyms (high -low).', 'Many NLP applications require knowledge about semantic relatedness rather than just similarity( #AUTHOR_TAG )']","['antic similarity is typically defined via the lexical relations of synonymy (automobile -car) and hypernymy (vehicle -car), while semantic relatedness (SR) is defined to cover any kind of lexical or functional association that may exist be-tween two words(Gurevych, 2005) . 3', 'Dissimilar words can be semantically related, e.g.', 'via functional relationships (night -dark) or when they are antonyms (high -low).', 'Many NLP applications require knowledge about semantic relatedness rather than just similarity( #AUTHOR_TAG )']",0
"['the seminal work by#AUTHOR_TAG , similarity judgments were obtained from 51 test subjects on 65 noun pairs written on paper cards .', 'Test subjects were instructed to order the cards according to the ""similarity of meaning"" and then assign a continuous similarity value (0.0 -4.0) to each card.', '']","['the seminal work by#AUTHOR_TAG , similarity judgments were obtained from 51 test subjects on 65 noun pairs written on paper cards .', 'Test subjects were instructed to order the cards according to the ""similarity of meaning"" and then assign a continuous similarity value (0.0 -4.0) to each card.', '']","['the seminal work by#AUTHOR_TAG , similarity judgments were obtained from 51 test subjects on 65 noun pairs written on paper cards .', 'Test subjects were instructed to order the cards according to the ""similarity of meaning"" and then assign a continuous similarity value (0.0 -4.0) to each card.', '']","['the seminal work by#AUTHOR_TAG , similarity judgments were obtained from 51 test subjects on 65 noun pairs written on paper cards .', 'Test subjects were instructed to order the cards according to the ""similarity of meaning"" and then assign a continuous similarity value (0.0 -4.0) to each card.', '']",0
"['latter question is tackled by applicationspecific evaluation , where a measure is tested within the framework of a certain application , e.g. word sense disambiguation( #AUTHOR_TAG ) or malapropism detection( Budanitsky and Hirst , 2006 ) .']","['latter question is tackled by applicationspecific evaluation , where a measure is tested within the framework of a certain application , e.g. word sense disambiguation( #AUTHOR_TAG ) or malapropism detection( Budanitsky and Hirst , 2006 ) .']","['latter question is tackled by applicationspecific evaluation , where a measure is tested within the framework of a certain application , e.g. word sense disambiguation( #AUTHOR_TAG ) or malapropism detection( Budanitsky and Hirst , 2006 ) .']","['latter question is tackled by applicationspecific evaluation , where a measure is tested within the framework of a certain application , e.g. word sense disambiguation( #AUTHOR_TAG ) or malapropism detection( Budanitsky and Hirst , 2006 ) .Lebart and Rajman (2000) argue for application-specific evaluation of similarity measures, because measures are always used for some task.', '']",0
"['', '#AUTHOR_TAG argue for application-specific evaluation of similarity measures , because measures are always used for some task .', '']","['', '#AUTHOR_TAG argue for application-specific evaluation of similarity measures , because measures are always used for some task .', '']","['apropism detection(Budanitsky and Hirst, 2006) .', '#AUTHOR_TAG argue for application-specific evaluation of similarity measures , because measures are always used for some task .', '']","['latter question is tackled by applicationspecific evaluation, where a measure is tested within the framework of a certain application, e.g.', 'word sense disambiguation(Patwardhan et al., 2003) or malapropism detection(Budanitsky and Hirst, 2006) .', '#AUTHOR_TAG argue for application-specific evaluation of similarity measures , because measures are always used for some task .', 'But they also note that evaluating a measure as part of a usually complex application only indirectly assesses its quality.', '']",0
"['', ""The resulting list of POS-tagged lemmas is weighted using the SMART ` ltc ' 8 tf.idf-weighting scheme( #AUTHOR_TAG )""]","['', ""The resulting list of POS-tagged lemmas is weighted using the SMART ` ltc ' 8 tf.idf-weighting scheme( #AUTHOR_TAG )""]","['three preprocessing steps (tokenization, POS-tagging, lemmatization) are performed using TreeTagger(Schmid, 1995) .', ""The resulting list of POS-tagged lemmas is weighted using the SMART ` ltc ' 8 tf.idf-weighting scheme( #AUTHOR_TAG )""]","['three preprocessing steps (tokenization, POS-tagging, lemmatization) are performed using TreeTagger(Schmid, 1995) .', ""The resulting list of POS-tagged lemmas is weighted using the SMART ` ltc ' 8 tf.idf-weighting scheme( #AUTHOR_TAG )""]",5
"['for their larger dataset.', '#AUTHOR_TAG reported a correlation of r = .69 .', 'Test subjects were trained students of computational linguistics, and word pairs were selected analytically']","['for their larger dataset.', '#AUTHOR_TAG reported a correlation of r = .69 .', 'Test subjects were trained students of computational linguistics, and word pairs were selected analytically']","['for their larger dataset.', '#AUTHOR_TAG reported a correlation of r = .69 .', 'Test subjects were trained students of computational linguistics, and word pairs were selected analytically']","['', '#AUTHOR_TAG reported a correlation of r = .69 .', 'Test subjects were trained students of computational linguistics, and word pairs were selected analytically']",1
"['maNet contains only a few conceptual glosses.', 'As they are required to enable test subjects to distinguish between senses , we use artificial glosses composed from synonyms and hypernyms as a surrogate , e.g. for brother : `` brother , male sibling vs. `` brother , comrade , friend( #AUTHOR_TAG ) .', 'We']","['maNet contains only a few conceptual glosses.', 'As they are required to enable test subjects to distinguish between senses , we use artificial glosses composed from synonyms and hypernyms as a surrogate , e.g. for brother : `` brother , male sibling vs. `` brother , comrade , friend( #AUTHOR_TAG ) .', 'We']","['maNet contains only a few conceptual glosses.', 'As they are required to enable test subjects to distinguish between senses , we use artificial glosses composed from synonyms and hypernyms as a surrogate , e.g. for brother : `` brother , male sibling vs. `` brother , comrade , friend( #AUTHOR_TAG ) .', 'We removed']","['maNet contains only a few conceptual glosses.', 'As they are required to enable test subjects to distinguish between senses , we use artificial glosses composed from synonyms and hypernyms as a surrogate , e.g. for brother : `` brother , male sibling vs. `` brother , comrade , friend( #AUTHOR_TAG ) .', 'We removed words which had more than three senses']",5
"['', '#AUTHOR_TAG pointed out that many relations between words in a text are non-classical ( i.e. other than typical taxonomic relations like synonymy or hypernymy ) and therefore not covered by semantic similarity']","['lexical-semantic relations.', '#AUTHOR_TAG pointed out that many relations between words in a text are non-classical ( i.e. other than typical taxonomic relations like synonymy or hypernymy ) and therefore not covered by semantic similarity']","['-semantic relations.', '#AUTHOR_TAG pointed out that many relations between words in a text are non-classical ( i.e. other than typical taxonomic relations like synonymy or hypernymy ) and therefore not covered by semantic similarity']","['', '#AUTHOR_TAG pointed out that many relations between words in a text are non-classical ( i.e. other than typical taxonomic relations like synonymy or hypernymy ) and therefore not covered by semantic similarity']",0
"['', '#AUTHOR_TAG annotated a larger set of word pairs ( 353 ) , too .', 'They used a 0-10 range of relatedness scores, but did not give further details about their experimental setup.', '']","['', '#AUTHOR_TAG annotated a larger set of word pairs ( 353 ) , too .', 'They used a 0-10 range of relatedness scores, but did not give further details about their experimental setup.', '']","['', '#AUTHOR_TAG annotated a larger set of word pairs ( 353 ) , too .', 'They used a 0-10 range of relatedness scores, but did not give further details about their experimental setup.', '']","['', '#AUTHOR_TAG annotated a larger set of word pairs ( 353 ) , too .', 'They used a 0-10 range of relatedness scores, but did not give further details about their experimental setup.', '']",0
"['three preprocessing steps ( tokenization , POS-tagging , lemmatization ) are performed using TreeTagger( #AUTHOR_TAG ) .', 'The resulting list of POS-tagged lemmas is weighted using the SM']","['three preprocessing steps ( tokenization , POS-tagging , lemmatization ) are performed using TreeTagger( #AUTHOR_TAG ) .', ""The resulting list of POS-tagged lemmas is weighted using the SMART 'ltc' 8""]","['three preprocessing steps ( tokenization , POS-tagging , lemmatization ) are performed using TreeTagger( #AUTHOR_TAG ) .', ""The resulting list of POS-tagged lemmas is weighted using the SMART 'ltc""]","['three preprocessing steps ( tokenization , POS-tagging , lemmatization ) are performed using TreeTagger( #AUTHOR_TAG ) .', ""The resulting list of POS-tagged lemmas is weighted using the SMART 'ltc' 8 tf.idf-weighting scheme(Salton, 1989)""]",5
"['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( #AUTHOR_TAG ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( #AUTHOR_TAG ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( #AUTHOR_TAG ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( #AUTHOR_TAG ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']",0
"['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( #AUTHOR_TAG ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( #AUTHOR_TAG ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( #AUTHOR_TAG ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( #AUTHOR_TAG ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']",0
"['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( #AUTHOR_TAG ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( #AUTHOR_TAG ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( #AUTHOR_TAG ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based( #AUTHOR_TAG ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']",0
"['differences in meaning between senses are very fine-grained , distinguishing between them is hard even for humans( #AUTHOR_TAG ) . 6', 'Pairs containing such words are not suitable for evaluation.', '']","['differences in meaning between senses are very fine-grained , distinguishing between them is hard even for humans( #AUTHOR_TAG ) . 6', 'Pairs containing such words are not suitable for evaluation.', '']","['differences in meaning between senses are very fine-grained , distinguishing between them is hard even for humans( #AUTHOR_TAG ) . 6', 'Pairs containing such words are not suitable for evaluation.', '']","['differences in meaning between senses are very fine-grained , distinguishing between them is hard even for humans( #AUTHOR_TAG ) . 6', 'Pairs containing such words are not suitable for evaluation.', '']",0
"['', 'Furthermore , manually selected word pairs are often biased towards highly related pairs( #AUTHOR_TAG ) , because human annotators tend to select only highly related pairs connected by relations they are aware of .', 'Automatic cor']","['', 'Furthermore , manually selected word pairs are often biased towards highly related pairs( #AUTHOR_TAG ) , because human annotators tend to select only highly related pairs connected by relations they are aware of .', 'Automatic corpus-based selection of word pairs is more objective,']","['', 'Furthermore , manually selected word pairs are often biased towards highly related pairs( #AUTHOR_TAG ) , because human annotators tend to select only highly related pairs connected by relations they are aware of .', 'Automatic corpus-based selection of word pairs is more']","['', 'Furthermore , manually selected word pairs are often biased towards highly related pairs( #AUTHOR_TAG ) , because human annotators tend to select only highly related pairs connected by relations they are aware of .', 'Automatic corpus-based selection of word pairs is more objective, leading to a balanced dataset with pairs connected by all kinds of lexical-semantic relations.', '']",0
"['.', '#AUTHOR_TAG did not report inter-subject correlation for their larger dataset .', '']","['of semantic relatedness.', '#AUTHOR_TAG did not report inter-subject correlation for their larger dataset .', '']","['of semantic relatedness.', '#AUTHOR_TAG did not report inter-subject correlation for their larger dataset .', '']","['', '#AUTHOR_TAG did not report inter-subject correlation for their larger dataset .', '']",1
"['10', '#AUTHOR_TAG reported a correlation of r = .9026.10 The results are not directly comparable , because he only used noun-noun pairs , words instead of concepts , a much smaller dataset , and measured semantic similarity instead of semantic relatedness']","['reported a correlation of r=.9026. 10', '#AUTHOR_TAG reported a correlation of r = .9026.10 The results are not directly comparable , because he only used noun-noun pairs , words instead of concepts , a much smaller dataset , and measured semantic similarity instead of semantic relatedness']","['9026. 10', '#AUTHOR_TAG reported a correlation of r = .9026.10 The results are not directly comparable , because he only used noun-noun pairs , words instead of concepts , a much smaller dataset , and measured semantic similarity instead of semantic relatedness .', '']","['summarized inter-subject correlation between 21 subjects was r=.478 (cf. is statistically significant at p < .05.', 'This correlation coefficient is an upper bound of performance for automatic SR measures applied on the same dataset.', 'Resnik (1995) reported a correlation of r=.9026. 10', '#AUTHOR_TAG reported a correlation of r = .9026.10 The results are not directly comparable , because he only used noun-noun pairs , words instead of concepts , a much smaller dataset , and measured semantic similarity instead of semantic relatedness .', '']",1
"['', '#AUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German .', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', '']","['subjects.', '#AUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German .', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', '']","['ain the test subjects.', '#AUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German .', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'This setup']","['', 'Furthermore, semantic relatedness is an intuitive concept and being forced to assign fine-grained continuous values is felt to overstrain the test subjects.', '#AUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German .', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', '']",0
['inter-subject correlation is lower than the results obtained by#AUTHOR_TAG'],['inter-subject correlation is lower than the results obtained by#AUTHOR_TAG'],['inter-subject correlation is lower than the results obtained by#AUTHOR_TAG'],"['', 'Due to the corpusbased approach, many domain-specific concept pairs are introduced into the test set.', 'Therefore , inter-subject correlation is lower than the results obtained by#AUTHOR_TAG']",1
"['ious approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; #AUTHOR_TAG ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; #AUTHOR_TAG ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; #AUTHOR_TAG ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']","['ious approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based( Lesk , 1986 ) , ontology-based( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based( Resnik , 1995 ; #AUTHOR_TAG ) or distributional( Weeds and Weir , 2005 ) .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora']",0
"['ly , we need to investigate techniques for identifying identical documents , virtually identical documents and highly repetitive documents , such as those pioneered by#AUTHOR_TAG b ) and shingling techniques described byChakrabarti ( 2002 )']","['', 'Secondly , we need to investigate techniques for identifying identical documents , virtually identical documents and highly repetitive documents , such as those pioneered by#AUTHOR_TAG b ) and shingling techniques described byChakrabarti ( 2002 )']","['ly , we need to investigate techniques for identifying identical documents , virtually identical documents and highly repetitive documents , such as those pioneered by#AUTHOR_TAG b ) and shingling techniques described byChakrabarti ( 2002 )']","['', 'Secondly , we need to investigate techniques for identifying identical documents , virtually identical documents and highly repetitive documents , such as those pioneered by#AUTHOR_TAG b ) and shingling techniques described byChakrabarti ( 2002 )']",3
"['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( Fletcher , 2004 a ) and the Linguist 's Search Engine( #AUTHOR_TAG ; Resnik and Elkiss , 2003 )""]","['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( Fletcher , 2004 a ) and the Linguist 's Search Engine( #AUTHOR_TAG ; Resnik and Elkiss , 2003 )""]","['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( Fletcher , 2004 a ) and the Linguist 's Search Engine( #AUTHOR_TAG ; Resnik and Elkiss , 2003 )""]","['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( Fletcher , 2004 a ) and the Linguist 's Search Engine( #AUTHOR_TAG ; Resnik and Elkiss , 2003 )""]",0
"['corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible( Kennedy , 1998  : 56 ) unless the web is used as a corpus( #AUTHOR_TAG ) .', '']","['corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible( Kennedy , 1998  : 56 ) unless the web is used as a corpus( #AUTHOR_TAG ) .', '']","['corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible( Kennedy , 1998  : 56 ) unless the web is used as a corpus( #AUTHOR_TAG ) .', '']","['corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible( Kennedy , 1998  : 56 ) unless the web is used as a corpus( #AUTHOR_TAG ) .', 'Increasingly, corpus researchers are tapping the Web to overcome the sparse data problem(Keller et al., 2002) .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', '']",0
"['the areas of Natural Language Processing ( NLP ) and computational linguistics , proposals have been made for using the computational Grid for data-intensive NLP and text-mining for eScience( #AUTHOR_TAG ; Hughes et al , 2004 ) .', 'While']","['the areas of Natural Language Processing ( NLP ) and computational linguistics , proposals have been made for using the computational Grid for data-intensive NLP and text-mining for eScience( #AUTHOR_TAG ; Hughes et al , 2004 ) .', 'While']","['the areas of Natural Language Processing ( NLP ) and computational linguistics , proposals have been made for using the computational Grid for data-intensive NLP and text-mining for eScience( #AUTHOR_TAG ; Hughes et al , 2004 ) .', 'While such an approach promises much in']","['the areas of Natural Language Processing ( NLP ) and computational linguistics , proposals have been made for using the computational Grid for data-intensive NLP and text-mining for eScience( #AUTHOR_TAG ; Hughes et al , 2004 ) .', 'While such an approach promises much in terms of emerging infrastructure, we wish to exploit existing computing infrastructure that is more accessible to linguists via a P2P approach.', '']",0
"['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( Fletcher , 2004 a ) and the Linguist 's Search Engine( Kilgarriff , 2003 ; #AUTHOR_TAG )""]","['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( Fletcher , 2004 a ) and the Linguist 's Search Engine( Kilgarriff , 2003 ; #AUTHOR_TAG )""]","['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( Fletcher , 2004 a ) and the Linguist 's Search Engine( Kilgarriff , 2003 ; #AUTHOR_TAG )""]","['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( Fletcher , 2004 a ) and the Linguist 's Search Engine( Kilgarriff , 2003 ; #AUTHOR_TAG )""]",0
"['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( #AUTHOR_TAG a ) and the Linguist 's Search Engine( Kilgarriff , 2003 ; Resnik and Elkiss , 2003 )""]","['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( #AUTHOR_TAG a ) and the Linguist 's Search Engine( Kilgarriff , 2003 ; Resnik and Elkiss , 2003 )""]","['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( #AUTHOR_TAG a ) and the Linguist 's Search Engine( Kilgarriff , 2003 ; Resnik and Elkiss , 2003 )""]","['', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp( Kehoe and Renouf , 2002 ) , KWiCFinder( #AUTHOR_TAG a ) and the Linguist 's Search Engine( Kilgarriff , 2003 ; Resnik and Elkiss , 2003 )""]",0
"['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; #AUTHOR_TAG , 2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; #AUTHOR_TAG , 2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; #AUTHOR_TAG , 2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; #AUTHOR_TAG , 2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']",0
"['key concern in corpus linguistics and related disciplines is verifiability and replicability of the results of studies.', 'Word frequency counts in internet search engines are inconsistent and unreliable( #AUTHOR_TAG ) .', 'Tools based on static corpora']","['key concern in corpus linguistics and related disciplines is verifiability and replicability of the results of studies.', 'Word frequency counts in internet search engines are inconsistent and unreliable( #AUTHOR_TAG ) .', 'Tools based on static corpora']","['key concern in corpus linguistics and related disciplines is verifiability and replicability of the results of studies.', 'Word frequency counts in internet search engines are inconsistent and unreliable( #AUTHOR_TAG ) .', 'Tools based on static corpora do not suffer from']","['key concern in corpus linguistics and related disciplines is verifiability and replicability of the results of studies.', 'Word frequency counts in internet search engines are inconsistent and unreliable( #AUTHOR_TAG ) .', 'Tools based on static corpora do not suffer from this problem, e.g.', 'BNCweb 7 , developed at the University of Zurich, and View 8 (Variation in English Words and Phrases, developed at Brigham Young University) are both based on the British National Corpus.', '']",0
"['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; #AUTHOR_TAG ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; #AUTHOR_TAG ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; #AUTHOR_TAG ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; #AUTHOR_TAG ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']",0
"['', 'In addition , the advantages of using linguistically annotated data over raw data are well documented( Mair , 2005 ; #AUTHOR_TAG ) .', '']","['at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented( Mair , 2005 ; #AUTHOR_TAG ) .', '']","['at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented( Mair , 2005 ; #AUTHOR_TAG ) .', '']","['', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented( Mair , 2005 ; #AUTHOR_TAG ) .', '']",0
"['corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible( #AUTHOR_TAG : 56 ) unless the web is used as a corpus( Kilgarriff and Grefenstette , 2003 ) .', '']","['corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible( #AUTHOR_TAG : 56 ) unless the web is used as a corpus( Kilgarriff and Grefenstette , 2003 ) .', '']","['corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible( #AUTHOR_TAG : 56 ) unless the web is used as a corpus( Kilgarriff and Grefenstette , 2003 ) .', '']","['corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible( #AUTHOR_TAG : 56 ) unless the web is used as a corpus( Kilgarriff and Grefenstette , 2003 ) .', '']",0
"['', 'We have designed this environment so that specific application functionality can be captured within plugins that can then integrate with the environment and utilise its functionality.', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding( #AUTHOR_TAG ) , distributed virtual worlds( Hughes et al. , 2005 ) and digital library management( Walkerdine and Rayson , 2004 ) .', 'It']","['', 'We have designed this environment so that specific application functionality can be captured within plugins that can then integrate with the environment and utilise its functionality.', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding( #AUTHOR_TAG ) , distributed virtual worlds( Hughes et al. , 2005 ) and digital library management( Walkerdine and Rayson , 2004 ) .', 'It']","['', 'We have designed this environment so that specific application functionality can be captured within plugins that can then integrate with the environment and utilise its functionality.', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding( #AUTHOR_TAG ) , distributed virtual worlds( Hughes et al. , 2005 ) and digital library management( Walkerdine and Rayson , 2004 ) .', 'It is']","['', 'We have designed this environment so that specific application functionality can be captured within plugins that can then integrate with the environment and utilise its functionality.', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding( #AUTHOR_TAG ) , distributed virtual worlds( Hughes et al. , 2005 ) and digital library management( Walkerdine and Rayson , 2004 ) .', '']",0
"['via a P2P approach.', 'In simple terms , P2P is a technology that takes advantage of the resources and services available at the edge of the Internet( #AUTHOR_TAG ) .', '']","['to linguists via a P2P approach.', 'In simple terms , P2P is a technology that takes advantage of the resources and services available at the edge of the Internet( #AUTHOR_TAG ) .', '']","['via a P2P approach.', 'In simple terms , P2P is a technology that takes advantage of the resources and services available at the edge of the Internet( #AUTHOR_TAG ) .', '']","['', 'In simple terms , P2P is a technology that takes advantage of the resources and services available at the edge of the Internet( #AUTHOR_TAG ) .', 'Better known for file-sharing and Instant Messenger applications, P2P has increasingly been applied in distributed computational systems.', 'Examples include SETI@home (looking for radio evidence of extraterrestrial life), ClimatePrediction.net (studying climate change), Predictor@home (investigating protein-related diseases) and Einstein@home (searching for gravitational signals']",0
"['', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding( Hughes and Walkerdine , 2005 ) , distributed virtual worlds( Hughes et al. , 2005 ) and digital library management( #AUTHOR_TAG ) .', '']","['', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding( Hughes and Walkerdine , 2005 ) , distributed virtual worlds( Hughes et al. , 2005 ) and digital library management( #AUTHOR_TAG ) .', '']","['', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding( Hughes and Walkerdine , 2005 ) , distributed virtual worlds( Hughes et al. , 2005 ) and digital library management( #AUTHOR_TAG ) .', '']","['', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding( Hughes and Walkerdine , 2005 ) , distributed virtual worlds( Hughes et al. , 2005 ) and digital library management( #AUTHOR_TAG ) .', '']",0
"['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; #AUTHOR_TAG ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; #AUTHOR_TAG ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; #AUTHOR_TAG ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; #AUTHOR_TAG ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']",0
"['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( #AUTHOR_TAG ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( #AUTHOR_TAG ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( #AUTHOR_TAG ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( #AUTHOR_TAG ) .', 'Studies have used several different methods to mine web data.', '']",0
"['', '#AUTHOR_TAG built a corpus by iteratively searching Google for a small set of seed terms .', 'Prototypes of Internet search engines for linguists, corpus linguists and lexicographers have been proposed: Web']","['web crawler.', '#AUTHOR_TAG built a corpus by iteratively searching Google for a small set of seed terms .', ""Prototypes of Internet search engines for linguists, corpus linguists and lexicographers have been proposed: WebCorp(Kehoe and Renouf, 2002) , KWiCFinder(Fletcher, 2004 a) and the Linguist's Search Engine(Kilgarriff, 2003;Resnik and Elkiss, 2003)""]","['a web crawler.', '#AUTHOR_TAG built a corpus by iteratively searching Google for a small set of seed terms .', 'Prototypes of Internet search engines for linguists, corpus linguists and lexicographers have been proposed: WebCorp(Kehoe and Renouf, 2002) , KWiCF']","['', '#AUTHOR_TAG built a corpus by iteratively searching Google for a small set of seed terms .', ""Prototypes of Internet search engines for linguists, corpus linguists and lexicographers have been proposed: WebCorp(Kehoe and Renouf, 2002) , KWiCFinder(Fletcher, 2004 a) and the Linguist's Search Engine(Kilgarriff, 2003;Resnik and Elkiss, 2003)""]",0
"['key aspect of our case study research will be to investigate extending corpus collection to new document types.', 'Most web-derived corpora have exploited raw text or HTML pages , so efforts have focussed on boilerplate removal and cleanup of these formats with tools like Hyppia-BTE , Tidy and Parcels3( #AUTHOR_TAG )']","['key aspect of our case study research will be to investigate extending corpus collection to new document types.', 'Most web-derived corpora have exploited raw text or HTML pages , so efforts have focussed on boilerplate removal and cleanup of these formats with tools like Hyppia-BTE , Tidy and Parcels3( #AUTHOR_TAG )']","['key aspect of our case study research will be to investigate extending corpus collection to new document types.', 'Most web-derived corpora have exploited raw text or HTML pages , so efforts have focussed on boilerplate removal and cleanup of these formats with tools like Hyppia-BTE , Tidy and Parcels3( #AUTHOR_TAG )']","['key aspect of our case study research will be to investigate extending corpus collection to new document types.', 'Most web-derived corpora have exploited raw text or HTML pages , so efforts have focussed on boilerplate removal and cleanup of these formats with tools like Hyppia-BTE , Tidy and Parcels3( #AUTHOR_TAG )']",0
"['', 'Increasingly , corpus researchers are tapping the Web to overcome the sparse data problem( #AUTHOR_TAG ) .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July ']","['', 'Increasingly , corpus researchers are tapping the Web to overcome the sparse data problem( #AUTHOR_TAG ) .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', '']","['', 'Increasingly , corpus researchers are tapping the Web to overcome the sparse data problem( #AUTHOR_TAG ) .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', '']","['corpus linguistics building such megacorpora is beyond the scope of individual researchers, and they are not easily accessible(Kennedy, 1998 : 56) unless the web is used as a corpus(Kilgarriff and Grefenstette, 2003) .', 'Increasingly , corpus researchers are tapping the Web to overcome the sparse data problem( #AUTHOR_TAG ) .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', '']",0
"['', 'The Gsearch system( #AUTHOR_TAG ) also selects sentences by syntactic criteria from large on-line text collections .', 'Gsearch annotates corpora with a fast chart parser to obviate the need for corpora with pre-existing syntactic mark-up']","['', 'The Gsearch system( #AUTHOR_TAG ) also selects sentences by syntactic criteria from large on-line text collections .', 'Gsearch annotates corpora with a fast chart parser to obviate the need for corpora with pre-existing syntactic mark-up.', '']","['', 'The Gsearch system( #AUTHOR_TAG ) also selects sentences by syntactic criteria from large on-line text collections .', 'Gsearch annotates corpora with a fast chart parser to obviate the need for corpora with pre-existing syntactic mark-up.', '']","['', 'The Gsearch system( #AUTHOR_TAG ) also selects sentences by syntactic criteria from large on-line text collections .', 'Gsearch annotates corpora with a fast chart parser to obviate the need for corpora with pre-existing syntactic mark-up.', '']",0
"['inguistic annotation of corpora contributes crucially to the study of language at several levels: morphology, syntax, semantics, and discourse.', 'Its significance is reflected both in the growing interest in annotation software for word sense tagging( #AUTHOR_TAG ) and in the long-standing use of part-of-speech taggers , parsers and morphological analysers for data from English and many other languages']","['inguistic annotation of corpora contributes crucially to the study of language at several levels: morphology, syntax, semantics, and discourse.', 'Its significance is reflected both in the growing interest in annotation software for word sense tagging( #AUTHOR_TAG ) and in the long-standing use of part-of-speech taggers , parsers and morphological analysers for data from English and many other languages']","['inguistic annotation of corpora contributes crucially to the study of language at several levels: morphology, syntax, semantics, and discourse.', 'Its significance is reflected both in the growing interest in annotation software for word sense tagging( #AUTHOR_TAG ) and in the long-standing use of part-of-speech taggers , parsers and morphological analysers for data from English and many other languages']","['inguistic annotation of corpora contributes crucially to the study of language at several levels: morphology, syntax, semantics, and discourse.', 'Its significance is reflected both in the growing interest in annotation software for word sense tagging( #AUTHOR_TAG ) and in the long-standing use of part-of-speech taggers , parsers and morphological analysers for data from English and many other languages']",0
"['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( #AUTHOR_TAG ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( #AUTHOR_TAG ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( #AUTHOR_TAG ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']","['', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times( #AUTHOR_TAG ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 ,  2004b ) and received a special issue of the journal Computational Linguistics( Kilgarriff and Grefenstette , 2003 ) .', '']",0
"['', '#AUTHOR_TAG extracts word co-occurrence probabilities from unlabelled text collected from a web crawler .', 'Baroni and Bernardini (2004)']","['mine web data.', '#AUTHOR_TAG extracts word co-occurrence probabilities from unlabelled text collected from a web crawler .', 'Baroni and Bernardini (2004)']","['mine web data.', '#AUTHOR_TAG extracts word co-occurrence probabilities from unlabelled text collected from a web crawler .', 'Baroni and Bernardini (2004)']","['', '#AUTHOR_TAG extracts word co-occurrence probabilities from unlabelled text collected from a web crawler .', '']",0
"['given the dynamic nature of the web, this is not sufficiently robust.', 'Other solutions such as complete caching of the corpora are not typically adopted due to legal concerns over copyright and redistribution of web data , issues considered at length by#AUTHOR_TAG a ) .', '']","['given the dynamic nature of the web, this is not sufficiently robust.', 'Other solutions such as complete caching of the corpora are not typically adopted due to legal concerns over copyright and redistribution of web data , issues considered at length by#AUTHOR_TAG a ) .', '']","['given the dynamic nature of the web, this is not sufficiently robust.', 'Other solutions such as complete caching of the corpora are not typically adopted due to legal concerns over copyright and redistribution of web data , issues considered at length by#AUTHOR_TAG a ) .', '']","['', 'Current practise elsewhere includes the distribution of URL lists, but given the dynamic nature of the web, this is not sufficiently robust.', 'Other solutions such as complete caching of the corpora are not typically adopted due to legal concerns over copyright and redistribution of web data , issues considered at length by#AUTHOR_TAG a ) .', '']",0
"['', 'In addition , the advantages of using linguistically annotated data over raw data are well documented( #AUTHOR_TAG ; Granger and Rayson , 1998 ) .', '']","['at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented( #AUTHOR_TAG ; Granger and Rayson , 1998 ) .', '']","['at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented( #AUTHOR_TAG ; Granger and Rayson , 1998 ) .', '']","['', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented( #AUTHOR_TAG ; Granger and Rayson , 1998 ) .', '']",0
[''],[''],[''],[''],0
"['.', 'We consider the Creative Commons model as the most suitable one to let each author choose the rights to reserve( #AUTHOR_TAG ) .', 'Narrative']","['work.', 'We consider the Creative Commons model as the most suitable one to let each author choose the rights to reserve( #AUTHOR_TAG ) .', 'Narrative writings or essays are creative works and they generally treat ownership as authorship, even for the most enthusiastic fellows of free culture(Stallman, 2001)']","['.', 'We consider the Creative Commons model as the most suitable one to let each author choose the rights to reserve( #AUTHOR_TAG ) .', 'Narrative writings or essays are creative works and they generally treat ownership as authorship, even for the most enthusiastic fellows of free culture(Stallman, 2001)']","['believe that ownership has an important role and we do not want to force our users to take a non-attributive copyright licence to their work.', 'We consider the Creative Commons model as the most suitable one to let each author choose the rights to reserve( #AUTHOR_TAG ) .', 'Narrative writings or essays are creative works and they generally treat ownership as authorship, even for the most enthusiastic fellows of free culture(Stallman, 2001)']",5

id,citing_title,citing_year,citing_authors,cited_title,cited_year,cited_authors,citation_type,paragraph,target_reference_location,context_location_1,context_location_2
087922a2-e3ce-415a-8149-d146175ee6de,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,"['unknown', 'Learning to translate in real-time with neural machine translation']","['2018', '2017']","['Mingbo Ma;Liang Huang;Hao Xiong;Renjie Zheng;Kaibo Liu;Baigong Zheng;Chuanqiang Zhang;Zhongjun He;Hairong Liu;Xing Li', 'Jiatao Gu;Graham Neubig;Kyunghyun Cho;O Victor;unk Li']",group,"['Simultaneous', 'translation', '<ref type=""group"">(Gu et al., 2017, Ma et al., 2018)</ref>', 'consists', 'in', 'generating', 'a', 'translation', 'before', 'the', 'source', 'speaker', 'finishes', 'speaking.', 'It', 'is', 'widely', 'used', 'in', 'many', 'real-time', 'scenarios', 'such', 'as', 'international', 'conferences,', 'business', 'negotiations', 'and', 'legal', 'proceedings.', 'The', 'challenge', 'of', 'Simultaneous', 'machine', 'translation', 'is', 'to', 'find', 'a', 'read-write', 'policy', 'that', 'balances', 'translation', 'quality', 'and', 'latency.', 'The', 'translation', 'quality', 'will', 'decline', 'if', 'the', 'machine', 'translation', 'system', 'reads', 'insufficient', 'source', 'information.', 'When', 'reading', 'wider', 'source', 'text,', 'latency', 'will', 'increase.']",2,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0]","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
08d9477e-5f02-460b-b714-8ad20a125568,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,['Analyzing co-occurrence data'],['2020'],['Stefan Th;Gries unk;Philip Durrant'],single,"['Word', 'co-occurrence', 'probabilities', 'are', 'a', 'key', 'ingredient', 'in', 'usage-based', 'cognitive', 'models', 'of', 'language.', 'By', 'word', 'co-occurrence', 'probabilities,', 'I', 'mean', 'the', 'probability', 'of', 'a', 'word', 'w', 'given', 'some', 'other', 'single', 'word', 'c,', 'p(w', '|', 'c),', 'where', 'words', 'w', 'and', 'c', 'have', 'some', 'specific', 'relationship,', 'for', 'example', 'adjectives', 'that', 'attributively', 'modify', 'nouns', 'or', 'nouns', 'serving', 'as', 'direct', 'objects', 'of', 'verbs', '<ref type=""single"">(Gries and Durrant, 2020).</ref>']",58,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
0906419b-3006-4f1b-a13b-312845a3ba6f,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['Clause Reduction in Spanish'],['1976'],['J Aissen;D Perlmutter'],single,"['In', 'this', 'Spanish-English', 'example,', 'the', 'clitic', 'can', 'climb', 'over', 'an', 'unlimited', 'number', 'of', ""'trigger"", ""verbs'"", '<ref type=""single"">(Aissen and Perlmutter, 1976)</ref>', '(indicated', 'by', 'the', 'ellipses', 'in', 'the', 'example),', 'and', 'for', 'certain', 'TAG', 'grammars', 'this', 'can', 'correspond', 'to', 'a', 'pair', 'of', 'derivation', 'trees', 'as', 'in', 'Figure', '2.', 'In', 'this', 'pair', 'of', 'trees,', 'his', 'corresponds', 'to', 'both', 'los', 'and', 'the', 'clitic', 'le.', 'Both', 'his', 'and', 'los', 'are', 'fixed', 'in', 'relation', 'to', 'the', 'root', 'of', 'the', 'tree,', 'but', 'le', 'is', 'an', 'unbounded', 'distance', 'from', 'it,', 'so', 'it', 'is', 'not', 'possible', 'to', 'form', 'a', 'gCN', 'in', 'the', 'Spanish', 'tree', 'for', 'pairing', 'without', 'the', 'unbounded', 'and', 'unrelated', 'recursively-inserted', 'verbs,', 'hence', 'requiring', 'infinitely', 'many', 'transfer', 'rules.']",15,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0a3cdb38-7e4a-457c-af09-dc5cd15126f2,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['Smote: synthetic minority over-sampling technique'],['2002'],['V Nitesh;Kevin Chawla;Lawrence Bowyer;W Philip Hall;unk Kegelmeyer'],single,"['Sampled', 'Curriculums.', 'Inspired', 'by', '<ref type=""single"">Chawla et al. (2002),</ref>', 'Graves', 'et', 'al.', '(2017),', 'we', 'explore', 'an', 'alternate', 'method', 'of', 'creating', 'curriculums', 'by', 'simply', 'oversampling', 'the', 'same', 'rare', 'quests', 'found', 'in', 'the', 'tails', 'of', 'the', 'distributions.']",4,"[0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
0a49f3d6-b7c3-427d-9b43-ca9b3427cddf,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Rouge: A package for automatic evaluation of summaries'],['2004'],['Chin-Yew Lin'],single,"['The', 'quality', 'is', 'measured', 'by', 'standard', 'N-gram', 'based', 'metrics,', 'including', 'the', 'BLEU', 'score', '<ref type=""single"">(Papineni et al., 2002)</ref>', 'and', 'the', 'ROUGE', 'score', '<ref type=""single"">(Lin, 2004).</ref>', 'This', 'measures', 'the', 'highest', 'accuracy', 'comparing', 'the', 'best', 'hypothesis', 'among', 'the', 'top-K', 'with', 'the', 'target', '<ref type=""single"">(Vijayakumar et al., 2018).</ref>', 'Concretely,', 'we', 'generate', 'hypotheses', '{Ŷ', '(1),', 'Ŷ', '(K)}', 'from', 'each', 'source', 'X', 'and', 'keep', 'the', 'hypothesis', 'Ŷ', 'best', 'that', 'achieves', 'the', 'best', 'sentencelevel', 'metric', 'with', 'the', 'target', 'Y.', 'Then', 'we', 'calculate', 'a', 'corpus-level', 'metric', 'with', 'the', 'greedily-selected', 'hypotheses', '{Y', '(i),best}', 'N', 'i=1', 'and', 'references', '{Y', '(i)}', 'N', 'i=1.', 'The', 'diversity', 'of', 'evaluated', 'by', 'three', 'aspects:', 'concept,', 'pairwise', 'and', 'corpus', 'diversity.']",18,"[0, 0, 0, 0, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0bac0ead-4c41-4b6b-b157-3853a8050936,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['Learning transferable visual models from natural language supervision'],['2021'],['Alec Radford;Jong Kim;Chris Hallacy;Aditya Ramesh;Gabriel Goh;Sandhini Agarwal;Girish Sastry;Amanda Askell;Pamela Mishkin;Jack Clark'],single,"['We', 'use', ""AI4Bharat's"", 'IndicTrans', '2', '<ref type=""single"">(Ramesh et al., 2021)</ref>', 'for', 'translation,', 'which', 'is', 'a', 'Transformer-4X', 'model', 'trained', 'on', 'Samanantar', 'dataset', '<ref type=""single"">(Ramesh et al., 2021).</ref>', 'In', 'IndicTrans,', 'translation', 'can', 'be', 'done', 'from', 'Indian', 'languages', 'to', 'English', 'and', 'vice', 'versa.', 'Available', 'Indian', 'languages', 'include', 'Assamese,', 'Bengali,', 'Gujarati,', 'Hindi,', 'Kannada,', 'Malayalam,', 'Marathi,', 'Oriya,', 'Punjabi,', 'Tamil,', 'and', 'Telugu.', 'At', 'first,', 'we', 'translate', 'the', 'ChAII', 'dataset', 'from', 'Hindi', 'and', 'Tamil', 'to', 'English', 'and', 'then', 'to', 'Bengali,', 'Marathi,', 'Malayalam,', 'and', 'Telugu.', 'In', 'the', 'FLORES', 'devset', 'benchmark', '<ref type=""single"">(Goyal et al., 2021),</ref>', 'the', 'BLEU', 'scores', 'of', 'IndicTrans', 'for', 'translating', 'Hindi', 'and', 'Tamil', 'to', 'English', 'are', '37.9', 'and', '28.6,', 'respectively.', 'The', 'scores', '<ref type=""single"">(Radford et al., 2021)</ref>', 'for', 'translating', 'English', 'to', 'Bengali,', 'Marathi,', '<ref type=""group"">Malayalam, and Telugu are 20.3, 16.1, 16.3, and 22</ref>', '.0,', 'respectively.', 'We', 'were', 'not', 'able', 'to', 'translate', 'nearly', '500', 'of', 'the', 'ChAII', 'instances', 'to', 'English', 'as', 'the', 'automatic', 'search', 'for', 'the', 'translated', 'answers', 'in', 'the', 'translated', 'contexts', 'failed.', 'This', 'happened', 'because', 'the', 'same', 'word', 'got', 'translated', 'differently', 'in', 'the', 'context', 'and', 'the', 'answer.', 'For', 'the', 'same', 'reason,', 'we', 'lost', 'nearly', 'another', '200', 'instances', 'when', 'translating', 'from', 'English', 'to', 'other', 'Indian', 'languages.']",94,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0c6d5458-1e92-4403-9f91-e713d999af9f,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,"['Controlled crowdsourcing for high-quality QA-SRL annotation', 'Large-scale QA-SRL parsing', 'unknown']","['2020', '2018', 'unknown']","['Paul Roit;Ayal Klein;Daniela Stepanov;Jonathan Mamou;Julian Michael;Gabriel Stanovsky;Luke Zettlemoyer;Ido Dagan', 'Nicholas Fitzgerald;Julian Michael;Luheng He;Luke Zettlemoyer', 'unknown']",group,"['We', 'chose', 'to', 'use', 'prepositions', 'as', 'relation', 'labels,', 'despite', 'this', 'ambiguity.', 'This', 'follows', 'a', 'line', 'of', 'annotation', 'work', 'that', 'aims', 'to', 'express', 'semantic', 'relations', 'using', 'natural', 'language', '<ref type=""group"">(FitzGerald et al., 2018, Roit et al., 2020, Klein et al., 2020, Pyatkin et al., 2020),</ref>', 'as', 'opposed', 'to', 'works', 'that', 'used', 'formal', 'linguistic', 'terms,', 'traditionally', 'relying', 'on', 'expert-defined', 'taxonomies', 'of', 'semantic', 'roles', 'and', 'discourse', 'relations.', 'The', 'aforementioned', 'works', 'label', 'predicateargument', 'relations', 'using', 'restricted', 'questions.', 'In', 'the', 'same', 'vein,', 'we', 'label', 'nominal', 'relations', 'using', 'prepositions.']",27,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0ed5f699-3e87-4e59-b43a-0a2d38c6865f,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,"['Adversarial filters of dataset biases', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'unknown']","['2020', '2018', 'unknown']","['Swabha Ronan Le Bras;Chandra Swayamdipta;Rowan Bhagavatula;Matthew Zellers;Ashish Peters;Yejin Sabharwal;unk Choi', 'Zhilin Yang;Peng Qi;Saizheng Zhang;Yoshua Bengio;William Cohen;Ruslan Salakhutdinov;Christopher Manning', 'unknown']",group,"['There', 'are', 'two', 'general', 'approaches', 'to', 'tackle', 'such', 'artifacts:', '(1)', 'adversarial', 'filtering', 'of', 'biased', 'examples,', 'i.e.,', 'examples', 'that', 'contain', 'artifacts,', 'and', '(2)', 'debiasing', 'methods.', 'In', 'the', 'first', 'approach,', 'potentially', 'biased', 'examples', 'are', 'discarded', 'from', 'the', 'dataset,', 'either', 'after', 'the', 'dataset', 'creation', '<ref type=""group"">(Zellers et al., 2018, Yang et al., 2018a, Le Bras et al., 2020, Bartolo et al., 2020),</ref>', 'or', 'while', 'creating', 'the', 'dataset', '<ref type=""group"">(Dua et al., 2019, Chen et al., 2019, Nie et al., 2020).</ref>']",41,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3]"
1004ac9f-126d-4e87-ab1d-6684e27aa93a,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity'],['2021'],['W Fedus;Barret Zoph;Noam Shazeer'],single,"['Feed-forward', 'layer', 'While', 'considerable', 'effort', 'has', 'been', 'dedicated', 'to', 'devising', 'efficient', 'models', 'for', 'long', 'contexts,', 'a', 'large', 'feed-forward', 'dimension', 'is', 'useful', 'for', 'knowledge-intensive', 'tasks', 'such', 'as', 'opendomain', 'QA', '<ref type=""group"">(Roberts et al., 2020, Brown et al., 2020),</ref>', 'and', 'efforts', 'have', 'been', 'made', 'to', 'reduce', 'its', 'complexity', '<ref type=""single"">(Fedus et al., 2021).</ref>', 'We', 'benchmark', 'the', 'resource', 'usage', 'of', 'top-k', 'attention', 'at', 'a', 'single', 'feed-forward', 'layer', 'for', 'different', 'feed-forward', 'dimensions', 'using', 'batch', 'size', '512', 'and', 'input', 'length', '512,', 'which', 'results', 'in', '2', '18', 'queries', 'per', 'batch.']",38,"[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
13d638f7-eee6-432f-88e8-783d7fee010a,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['ROUGE: A package for automatic evaluation of summaries'],['2004'],['Chin-Yew Lin'],single,"['We', 'use', 'the', 'standard', 'ROUGE', '<ref type=""single"">(Lin, 2004)</ref>', 'Perl', 'package', '15', 'for', 'evaluation.', 'The', 'command', 'line', 'parameters', 'are', ""'-c"", '95', '-r', '1000', '-n', '2', ""-m'."", 'Before', 'the', 'Datasets', 'λ', '(Eq.', '8)', 'α', '(Eq.', '9)', 'γ', '(Eq.', '10)', 'CNNDM', '0.001', '2.0', '100', 'XSum', '0.1', '0.6', '100', 'NYT', '0.001', '2.0', '100']",5,"[2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1430bd67-9452-4e66-b50b-386a57dbf0e4,Comparison of post-editing productivity between professional translators and lay users,2014,Nora Aranberri;Gorka Labaka,['Perplexity of n-Gram and Dependency Language Models'],['2010'],['M Popel;D Mareček'],single,"['Finally,', 'to', 'test', 'whether', 'the', 'MT', 'engine', 'was', 'better', 'prepared', 'to', 'address', 'Text', 'A', 'or', 'Text', 'B,', 'we', 'calculated', 'perplexity', 'and', 'out-of-vocabulary', '(OOV)', 'words.', 'Perplexity', 'is', 'used', 'as', 'a', 'mea-surement', 'of', 'how', 'well', 'the', 'language', 'model', 'predicts', 'the', 'reference', 'translations.', 'The', 'smaller', 'the', 'perplexity,', 'the', 'more', 'and', 'longer', 'overlap', 'exists', 'between', 'the', 'reference', 'and', 'the', 'language', 'model', 'in', 'the', 'MT', 'system.', 'This', 'measurement', 'shows', 'that', 'the', 'MT', 'engine', 'is', 'better', 'suited', 'to', 'output', 'a', 'correct', 'version', 'for', 'Text', 'A', 'than', 'for', 'Text', 'B', '(see', 'Table', '10).', 'Note', 'that', 'the', 'high', 'perplexity', 'values,', 'calculated', 'per', 'word,', 'are', 'in', 'line', 'with', 'those', 'reported', 'for', 'morphologically', 'rich', 'languages', '(see', '<ref type=""single"">Popel and Mareček, 2010).</ref>', 'Table', '10.', 'Perplexity', 'calculated', 'on', '5-grams.']",106,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3]"
1982fc86-d8b3-4338-91a5-ad9ea59447ff,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['Neural machine translation of rare words with subword units'],['2016'],['Rico Sennrich;Barry Haddow;Alexandra Birch'],single,"['Byte-pair-encoding', '(BPE)', '<ref type=""single"">(Sennrich et al., 2016)</ref>', '6:', 'For', 'both', 'the', 'Chinese', 'and', 'English', 'sides,', 'we', 'use', 'BPE', 'with', '32K', 'operations.']",2,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1]","[1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]"
1c34f6c2-bcc3-48d1-bf3e-17831ef4572f,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,"['The gem benchmark: Natural language generation, its evaluation and metrics']",['2021'],['Sebastian Gehrmann;Tosin Adewumi;Karmanya Aggarwal;Pawan Sasanka Ammanamanchi;Anuoluwapo Aremu;Antoine Bosselut;Miruna-Adriana Khyathi Raghavi Chandu;Dipanjan Clinciu;Kaustubh Das;unk Dhole'],single,"['All', 'baseline', 'methods', 'were', 'built', 'on', 'the', 'Transformer', 'architecture', 'with', '6-layer', 'encoder', 'and', 'decoder,', 'and', 'initialized', 'with', 'pre-trained', 'parameters', 'from', 'BARTbase', '<ref type=""single"">(Lewis et al., 2020),</ref>', 'which', 'is', 'one', 'of', 'the', 'stateof-the-art', 'pre-trained', 'Transformer', 'models', 'for', 'natural', 'language', 'generation', '<ref type=""single"">(Gehrmann et al., 2021).</ref>', 'In', 'our', 'MoKGE,', 'the', 'Transformer', 'parameters', 'were', 'also', 'initialized', 'by', 'BART-base,', 'in', 'order', 'to', 'make', 'fair', 'comparison', 'with', 'all', 'baseline', 'methods.', 'The', 'R-GCN', 'parameters', 'were', 'random', 'initialized.']",35,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1ffab4bb-2188-4f90-8029-fdc2f472e1d8,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,"[""Discussion on the Definitions in Chinese Learner's Dictionaries: Comparative Study of Domestic and Foreign Learner Dictionaries (Translated from Chinese)""]",['2011'],['Yihua Zhang'],single,"['The', 'goal', 'of', 'SDG', 'task', 'is', 'to', 'generate', 'simple', 'definitions', 'for', 'languages', 'that', 'lack', ""learner's"", 'dictionary.', 'For', 'example,', 'Chinese', 'as', 'Second', 'Language', '(CSL)', 'learners', 'do', 'not', 'have', 'suitable', 'dictionaries.', 'As', '<ref type=""single"">Zhang (2011)</ref>', 'pointed', 'out,', 'since', 'the', 'difficulty', 'of', 'definitions', 'is', 'not', 'considered,', 'the', 'existing', 'dictionary', 'cannot', 'meet', 'CSL', ""learner's"", 'needs.']",30,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
22c0a872-f553-438b-a298-1c649989c712,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Explaining explanations: An overview of interpretability of machine learning'],['2018'],['L Gilpin;D Bau;B Yuan;A Bajwa;M Specter;L Kagal'],single,"['Consequently,', 'explainability', 'has', 'a', 'bigger', 'role', 'to', 'play', 'here', 'than', 'simply', 'being', 'a', 'tool', 'that', 'provides', 'interpretability', 'to', 'designers', 'or', 'offers', 'justifications', 'to', 'users.', 'Operationalizing', 'explainability', 'in', 'a', 'manner', 'that', 'spreads', 'awareness', 'about', 'existing', 'stereotypes', 'and', 'fills', 'the', 'information', 'gap', 'can', 'be', 'very', 'effective', '<ref type=""group"">(Miller, 2018, Sap et al., 2020).</ref>', 'One', 'way', 'to', 'achieve', 'this', 'is', 'by', 'having', 'generative', 'explanations', 'in', 'conjunction', 'with', 'information', 'retrieval', 'techniques', 'that', 'fulfill', 'the', 'property', 'of', 'elucidating', 'stereotypes', 'in', 'a', 'human-understandable', 'way', '<ref type=""single"">(Gilpin et al., 2018)</ref>', 'while', 'offering', 'references', 'to', 'reliable', 'sources', 'on', 'the', 'stereotypes.', 'In', 'fact,', 'such', 'an', 'operationalization', 'that', 'elucidates', 'stereotypes', 'or', 'frames', 'of', 'bias', '<ref type=""single"">(Sap et al., 2020)</ref>', 'in', 'abusive', 'comments', 'at', 'a', 'community', 'level,', 'while', 'providing', 'information', 'to', 'debunk', 'the', 'stereotypes', 'themselves,', 'can', 'offer', 'validation', 'to', 'the', 'victims', 'of', 'abuse', 'by', 'communities,', 'e.g.,', 'minority', 'groups,', 'and', 'help', 'them', 'feel', 'safer', 'on', 'the', 'platform.']",72,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
23f5ee5c-e55e-45ec-a317-47416da47104,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,"['unknown', 'Learning to Denoise Distantly-Labeled Data for Entity Typing']","['unknown', '2019']","['unknown', 'Yasumasa Onoe;Greg Durrett']",group,"['We', 'use', 'the', 'entity', 'typing', 'model', 'trained', 'on', 'the', 'Wiki-Context', 'data', '(see', 'Section', '4)', 'to', 'get', 'the', 'mention', 'and', 'context', 'representation', 't.', 'In', 'the', 'CoNLL-YAGO', 'setting,', 'similar', 'to', 'past', 'work', '<ref type=""group"">(Onoe and Durrett, 2019, Févry et al., 2020),</ref>', 'we', 'prepend', 'the', 'document', 'title', 'and', 'the', 'first', 'sentence', 'to', 'the', 'input', 'to', 'enrich', 'the', 'context', 'information.', 'To', 'obtain', 'the', 'candidate', 'representations', '{c', '1,', 'c', '2,', '...,', 'c', 'j,', '...},', 'we', 'use', 'the', 'model', 'trained', 'on', 'the', 'Wiki-Description', 'data,', 'which', 'is', 'specialized', 'for', 'entity', 'descriptions', '(see', 'Section', '4)', 'similar', 'to', '<ref type=""single"">Gillick et al. (2019).</ref>', 'We', 'choose', 'Wikipedia', 'datasets', 'here', 'because', 'UFET', 'does', 'not', 'support', 'entity', 'descriptions.', 'We', 'rank', 'the', 'candidate', 'entities', 'based', 'on', 'cosine', 'similarity', 'between', 't', 'and', 'c', 'j,', 'and', 'the', 'entity', 'with', 'the', 'highest', 'score', 'is', 'our', ""model's"", 'prediction.']",30,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2849b2a0-f4e6-4eb9-80c4-a193ca0af6a2,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,['On using very large target vocabulary for neural machine translation'],['unknown'],['S Jean;K Cho;R Memisevic;Y Bengio'],single,"['The', 'first', 'assumption', 'we', 'made', 'is', 'highly', 'dependent', 'on', 'the', 'design', 'of', 'the', 'considered', 'factors,', 'i.e.', 'the', 'lemmas', 'are', 'the', 'most', 'informative', 'factors', 'among', 'all.', 'Then,', 'we', 'tried', 'using', 'only', 'the', 'lemma', 'embedding', 'as', 'feedback', '(see', 'equation', '5).', 'fb(y', 't−1)', '=', 'y', 'L', 't−1', '<ref type=""single"">(5)</ref>', 'where', 'y', 'L', 't−1', 'is', 'the', 'embedding', 'of', 'the', 'lemma', 'generated', 'at', 'previous', 'timestep.']",44,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
299df407-c7f9-4850-8c77-9be4383b31a2,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['Sparse, dense, and attentional representations for text retrieval. CoRR, abs', 'Learning dense representations for entity retrieval', 'unknown']","['unknown', '2019', 'unknown']","['Yi Luan;Jacob Eisenstein;Kristina Toutanova;Michael Collins', 'Daniel Gillick;Sayali Kulkarni;Larry Lansing;Alessandro Presta;Jason Baldridge;Eugene Ie;Diego García-Olano', 'unknown']",group,"['Cross-batch', 'Negatives', 'When', 'training', 'the', 'dualencoder,', 'the', 'trick', 'of', 'in-batch', 'negatives', 'has', 'been', 'widely', 'used', 'in', 'previous', 'work', '<ref type=""group"">(Henderson et al., 2017, Gillick et al., 2019, Wu et al., 2020, Karpukhin et al., 2020, Luan et al., 2020).</ref>', 'Assume', 'that', 'there', 'are', 'B', 'questions', 'in', 'a', 'mini-batch', 'on', 'a', 'single', 'GPU,', 'and', 'each', 'question', 'has', 'one', 'positive', 'passage.', 'With', 'the', 'in-batch', 'negative', 'trick,', 'each', 'question', 'can', 'be', 'further', 'paired', 'with', 'B', '−', '1', 'negatives', '(i.e.,', 'positive', 'passages', 'of', 'the', 'rest', 'questions)', 'without', 'sampling', 'additional', 'negatives.', 'In-batch', 'negative', 'training', 'is', 'a', 'memory-efficient', 'way', 'to', 'reuse', 'the', 'examples', 'already', 'loaded', 'in', 'a', 'mini-batch', 'rather', 'than', 'sampling', 'new', 'negatives,', 'which', 'increases', 'the', 'number', 'of', 'negatives', 'for', 'each', 'question.', 'As', 'illustrated', 'at', 'the', 'top', 'of', 'Figure', '2,', 'we', 'present', 'an', 'example', 'for', 'in-batch', 'negatives', 'when', 'training', 'on', 'A', 'GPUs', 'in', 'a', 'data', 'parallel', 'way.', 'To', 'further', 'optimize', 'the', 'training', 'with', 'more', 'negatives,', 'we', 'propose', 'to', 'use', 'cross-batch', 'negatives', 'when', 'training', 'on', 'multiple', 'GPUs,', 'as', 'illustrated', 'at', 'the', 'bottom', 'of', 'Figure', '2.', 'Specifically,', 'we', 'first', 'compute', 'the', 'passage', 'embeddings', 'within', 'each', 'single', 'GPU,', 'and', 'then', 'share', 'these', 'passage', 'embeddings', 'among', 'all', 'the', 'GPUs.', 'Besides', 'the', 'in-batch', 'negatives,', 'we', 'collect', 'all', 'passages', '(i.e.,', 'their', 'dense', 'representations)', 'from', 'other', 'GPUs', 'as', 'the', 'additional', 'negatives', 'for', 'each', 'question.', 'Hence,', 'with', 'A', 'GPUs', '(or', 'mini-batches)', '2,', 'we', 'can', 'indeed', 'obtain', 'A×B', '−1', 'negatives', 'for', 'a', 'given', 'question,', 'which', 'is', 'approximately', 'A', 'times', 'as', 'many', 'as', 'the', 'original', 'number', 'of', 'in-batch', 'negatives.', 'In', 'this', 'way,', 'we', 'can', 'use', 'more', 'negatives', 'in', 'the', 'training', 'objective', 'of', 'Equation', '2,', 'so', 'that', 'the', 'results', 'are', 'expected', 'to', 'be', 'improved.', 'Denoised', 'Hard', 'Negatives', 'Although', 'the', 'above', 'strategy', 'can', 'increase', 'the', 'number', 'of', 'negatives,', 'most', 'of', 'negatives', 'are', 'easy', 'ones,', 'which', 'can', 'be', 'easily', 'discriminated.', 'While,', 'hard', 'negatives', 'are', 'shown', 'to', 'be', 'important', 'to', 'train', 'a', 'dual-encoder', '<ref type=""group"">(Gillick et al., 2019, Wu et al., 2020, Karpukhin et al., 2020, Luan et al., 2020, Xiong et al., 2020).</ref>', 'To', 'obtain', 'hard', 'negatives,', 'a', 'straightforward', 'method', 'is', 'to', 'select', 'the', 'top-ranked', 'passages', '(excluding', 'the', 'labeled', 'positive', 'passages)', 'as', 'negative', 'samples.', 'However,', 'it', 'is', 'likely', 'to', 'bring', 'false', 'negatives', '(i.e.,', 'unlabeled', 'positives),', 'since', 'the', 'annotators', 'can', 'only', 'annotate', 'a', 'few', 'top-retrieved', 'passages', '(as', 'discussed', 'in', 'Section', '1).', 'Another', 'note', 'is', 'that', 'previous', 'work', 'mainly', 'focuses', 'on', 'factoid', 'questions,', 'to', 'which', 'the', 'answers', 'are', 'short', 'and', 'concise.', 'Hence,', 'it', 'is', 'not', 'challenging', 'to', 'filter', 'false', 'negatives', 'by', 'using', 'the', 'short', 'answers', '<ref type=""single"">(Karpukhin et al., 2020).</ref>', 'However,', 'it', 'cannot', 'apply', 'to', 'non-factoid', 'questions.', 'In', 'this', 'paper,', 'we', 'aim', 'to', 'learn', 'dense', 'passage', 'retrieval', 'for', 'both', 'factoid', 'questions', 'and', 'non-factoid', 'questions,', 'which', 'needs', 'a', 'more', 'effective', 'way', 'for', 'denoising', 'hard', 'negatives.']",283,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2c0bd06e-dc90-4200-8aa4-cc6bfeabe833,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Reformer: The efficient transformer'],['2020'],['Nikita Kitaev;Lukasz Kaiser;Anselm Levskaya'],single,"['Other', 'architectural', 'improvements', 'highlighted', 'with', 'the', 'introduction', 'of', 'the', 'ALBERT', 'model', '<ref type=""single"">(Lan et al., 2020)</ref>', 'such', 'as', 'the', 'factorization', 'of', 'the', 'attention', 'matrix', 'or', 'parameter', 'sharing.', 'Indeed,', 'the', 'most', 'time-consuming', 'and', 'memory-intensive', 'operations', 'concerns', 'the', 'forward', 'propagation', 'and', 'attention', 'computation', 'operations.', 'The', 'self-attention', 'layer', 'of', 'BERT', 'pretrained', 'models', 'grows', 'quadratically', 'in', 'respect', 'to', 'the', 'input', 'sequence', 'length.', 'One', 'common', 'approach', 'to', 'this', 'issue', 'consists', 'of', 'approximating', 'the', 'dot-product', 'attention', 'for', 'example', 'by', 'using', 'hashing', 'techniques', '<ref type=""single"">(Kitaev et al., 2020)</ref>', 'to', 'accelerate', 'the', 'training', 'and', 'inference', 'phases', 'when', 'long', 'sequence', 'lengths', 'are', 'used.', 'However', 'these', 'solutions', 'have', 'demonstrated', 'they', 'suffer', 'from', 'important', 'computational', 'overheads', 'for', 'tasks', 'with', 'smaller', 'lengths,', 'such', 'as', 'question-answering.']",72,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3]"
3106ddaf-ae84-415b-85ab-2c5a462e567d,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['Learning transferable visual models from natural language supervision'],['2021'],['Alec Radford;Jong Kim;Chris Hallacy;Aditya Ramesh;Gabriel Goh;Sandhini Agarwal;Girish Sastry;Amanda Askell;Pamela Mishkin;Jack Clark'],single,"['The', 'choice', 'of', 'languages', 'used', 'for', 'translation', 'and', 'transliteration', 'is', 'critical.', '<ref type=""single"">Kudugunta et al. (2019)</ref>', 'showed', 'that', 'languages', 'under', 'the', 'same', 'family', 'have', 'similar', 'representations', 'in', 'multilingual', 'models.', 'Hence,', 'we', 'put', 'together', 'translations', 'and', 'transliterations', 'from', 'related', 'languages', 'within', 'the', 'same', 'language', 'family', 'to', 'achieve', 'better', 'performance.', 'This', 'will', 'also', 'help', 'with', 'better', 'use', 'of', 'the', 'vo-cabulary', 'corpora', 'from', 'the', 'low-resource', 'languages.', 'We', 'also', 'study', 'the', 'impact', 'of', 'translation', 'and', 'transliteration', 'on', 'languages', 'outside', 'the', 'family', 'of', 'the', 'target', 'language.', 'Since', 'the', 'cross-family', 'language', 'transfer', 'degraded', 'the', 'QA', 'performance,', 'we', 'introduce', 'a', 'contrastive', 'loss', '<ref type=""single"">(Radford et al., 2021)</ref>', 'between', 'the', 'translated', 'pairs', 'to', 'help', 'retain', 'or', 'improve', 'the', 'original', 'performance', 'by', 'encouraging', 'the', 'embeddings', 'from', 'all', 'languages', 'to', 'be', 'similar', 'regardless', 'of', 'the', 'family', 'group.', 'Thus,', 'the', 'contributions', 'of', 'the', 'paper', 'are', 'three-fold:']",91,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0]"
31968bed-8257-4056-b1ea-a0b5773db033,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,"['To test machine comprehension, start by defining comprehension']",['2020'],['Jesse Dunietz;Greg Burnham;Akash Bharadwaj;Owen Rambow;Jennifer Chu-Carroll;Dave Ferrucci'],single,"['While', 'reading', 'comprehension', '(RC)', 'and', 'question', 'answering', '(QA)', 'are', 'often', 'used', 'interchangeably', 'in', 'the', 'literature,', 'measuring', 'the', 'reading', 'comprehension', 'capacity', 'of', 'models', 'via', 'question', 'answering,', 'as', 'implemented', 'in', 'benchmarks', 'such', 'as', 'SQuAD', '<ref type=""single"">(Rajpurkar et al., 2016),</ref>', 'BoolQ', '<ref type=""single"">(Clark et al., 2019)</ref>', 'and', 'others,', 'has', 'several', 'well-documented', 'problems', '<ref type=""single"">(Dunietz et al., 2020).</ref>', 'We', 'argue', 'that', 'the', 'TNE', 'task', 'we', 'propose', 'herein', 'has', 'properties', 'that', 'make', 'it', 'appealing', 'for', 'assessing', 'RC,', 'more', 'than', 'QA', 'is.', 'First,', 'benchmarks', 'for', 'extractive', '(span-marking)', 'QA', 'are', 'sensitive', 'to', 'the', 'span-boundary', 'selection,', 'on', 'the', 'other', 'hand,', 'benchmarks', 'for', 'yes/no,', 'multiple', 'choice,', 'or', 'generative', 'questions', 'can', 'in', 'principle', 'be', 'answered', 'in', 'a', 'way', 'that', 'is', 'completely', 'divorced', 'from', 'the', 'text.', 'On', 'a', 'more', 'fundamental', 'level,', 'all', 'QA', 'benchmarks', 'are', 'very', 'sensitive', 'to', 'lexical', 'choices', 'in', 'the', 'question', 'and', 'its', 'similarity', 'to', 'the', 'text.', 'Furthermore,', 'QA', 'benchmarks', 'rely', 'on', 'human', 'authored', 'questions', 'that', 'are', 'easy', 'to', 'solve', 'based', 'on', 'surface', 'artifacts.', 'Finally,', 'in', 'many', 'cases,', 'the', 'existence', 'of', 'the', 'question', 'itself', 'provides', 'a', 'huge', 'hint', 'towards', 'the', 'answer', '<ref type=""single"">(Kaushik and Lipton, 2018).</ref>']",41,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
349ee356-3282-4903-94ac-2c836daa2aab,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['Hierarchical sparse variational autoencoder for text encoding'],['2020'],['Victor Prokhorov;Yingzhen Li;Ehsan Shareghi;Nigel Collier'],single,"['As', 'demonstrated', 'in', '(1)', 'the', 'positive', 'correlation', 'of', 'C', 'with', 'AU', 'which', 'intuitively', 'means', 'the', 'increase', 'of', 'channel', 'capacity', 'demands', 'more', 'dimensions', 'of', 'the', 'representation', 'to', 'carry', 'information', 'which', 'then', 'translates', 'into', 'having', 'a', 'better', 'reconstruction', 'of', 'data,', '(2)', 'the', 'negative', 'correlation', 'between', 'the', 'increase', 'of', 'β', 'and', 'decrease', 'of', 'reconstruction', 'loss,', '(3)', 'the', 'best', 'Rec.', 'and', 'AU', 'are', 'achieved', 'by', 'AE', 'and', 'MAT-VAE', 'whereas', 'the', 'worst', 'one', 'is', 'achieved', 'by', 'the', '(collapsed)', 'vanilla-VAE,', '(4)', 'the', 'MAT-VAE', '(β', '=', '0.01,', 'λ', '=', '0.1)', 'model', 'which', 'induces', 'more', 'sparse', 'representations', '6', 'performs', 'the', 'best', 'on', 'both', 'datasets,', 'indicating', 'the', 'positive', 'impact', 'of', 'representation', 'sparsity', 'as', 'an', 'inductive', 'bias.', 'As', 'illustrated', 'in', 'Figure', '1,', 'the', 'difference', 'between', 'means', 'of', 'each', 'disentanglement', 'score', 'on', 'various', 'models', 'is', 'relatively', 'small,', 'and', 'due', 'to', 'large', 'standard', 'deviation', 'on', 'metrics,', 'it', 'is', 'difficult', 'to', 'single', 'out', 'a', 'superior', 'model.', 'This', 'verifies', 'findings', 'of', 'Lo-6', 'Sparsity', 'is', 'measured', 'using', 'Hoyer', '<ref type=""single"">(Hurley and Rickard, 2009).</ref>', 'In', 'this', 'paper', 'we', 'report', 'this', 'as', 'the', 'average', 'Hoyer', 'over', 'data', ""points'"", 'posterior', 'means.', 'Hoyer', 'for', 'data', 'point', 'xi', 'with', 'posterior', 'mean', 'µi', 'is', 'calculated', 'as√', 'd−||', 'μi', '||', '1', '/||', 'μi', '||', '2', '√', 'd−1,', 'where', 'd', 'is', 'the', 'dimensionality', 'of', 'the', 'representations', 'and', 'μi', '=', 'µi/σ(µ),', 'where', 'µ', '=', '{µ1,', '...,', 'µn},', 'and', 'σ(.)', 'is', 'the', 'standard', 'deviation.', 'catello', 'et', 'al.', '(2019)', 'on', 'image', 'domain.', 'In', 'Table', '3', '(Top-3', 'column)', 'we', 'report', 'the', 'number', 'of', 'appearances', 'of', 'a', 'model', 'among', 'the', 'top', '3', 'highest', 'scoring', 'models', 'on', 'at', 'least', 'one', 'disentanglement', 'metric.', 'The', 'ranking', 'suggests', 'that', 'β-VAE', 'with', 'smaller', 'β', 'values', 'reach', 'better', 'disentangled', 'representations,', 'and', 'MAT-VAE', 'performing', 'superior', 'on', 'YNOC', 'and', 'poorly', 'on', 'POS,', 'highlighting', 'its', 'more', 'challenging', 'nature.', 'For', 'MAT-VAE', 'we', 'also', 'observe', 'an', 'interesting', 'correlation', 'between', 'sparsity', 'and', 'disentanglement:', 'for', 'instance', 'on', 'YNOC,', 'MAT-VAE', '(β', '=', '0.01,', 'λ', '=', '0.1)', 'achieves', 'the', 'highest', 'Hoyer', '(See', 'Table', '4)', 'and', 'occurs', '7', 'times', 'among', 'Top-3', '(see', 'Table', '3).', 'Interestingly,', 'the', 'success', 'of', 'MAT-VAE', 'does', 'not', 'translate', 'to', 'POS', 'dataset,', 'where', 'it', 'underperforms', 'AE.', 'These', 'two', 'observations', 'suggest', 'that', 'sparsity', 'could', 'be', 'a', 'facilitator', 'for', 'disentanglement,', 'but', 'achieving', 'a', 'stable', 'level', 'of', 'sparsity', 'remains', 'as', 'a', 'challenge.', 'The', 'more', 'recent', 'development', 'in', 'the', 'direction', 'of', 'sparsity,', 'HSVAE', '<ref type=""single"">(Prokhorov et al., 2020),</ref>', 'addresses', 'the', 'stability', 'issue', 'of', 'MAT-VAE', 'but', 'we', 'leave', 'its', 'exploration', 'to', 'future', 'work.']",364,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]"
37d5b13b-af3c-43ce-abcb-48797993be90,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['We', 'use', 'a', 'three-layer', 'transformer', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'with', 'a', 'hidden', 'size', 'of', '128', 'and', '4', 'heads', 'as', 'our', 'base', 'model', 'for', 'content', 'planning', 'and', 'response', 'generation,', 'i.e.,', 'p', 'l', '(a|c)', 'and', 'p', 'r', '(a,', 'c),', 'respectively.', 'We', 'use', 'grid', 'search', 'to', 'find', 'the', 'best', 'hyperparameters', 'for', 'the', 'models', 'based', 'on', 'validation', 'performance,', 'which', 'we', 'use', 'a', 'combination', 'of', 'Inform,', 'Success', 'and', 'BLEU', 'scores', 'to', 'measure.', 'We', 'choose', 'the', 'embedding', 'dimensionality', 'd', 'among', '{50,', '75,', '100,', '150,', '200},', 'the', 'hyperparameters', 'α', 'and', 'β', 'in', '[0.01,', '1.0].']",5,"[2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3a0eace8-ed7b-4f21-8907-47cc4c813de0,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Machine translation and monolingual postediting: The AFRL WMT-14 system'],['2014'],['L Schwartz;T Anderson;J Gwinnup;K Young'],single,"['We', 'examine', 'the', 'effect', 'that', 'alignment', 'link', 'visualization', 'has', 'on', 'each', 'bilingual', 'post-editor', 'in', 'Figure', '5', 'on', 'the', 'next', 'page.', 'In', 'the', 'Russian-English', 'condition,', 'where', 'overall', 'MT', 'quality', 'is', 'poor,', 'we', 'observe', 'that', 'post-editing', 'quality', 'varies', 'widely', 'between', 'post-editors', '(with', 'PE2', 'and', 'PE3', 'performing', 'best).', 'For', 'all', 'six', 'bilingual', 'post-editors,', 'we', 'observe', 'higher', 'mean', 'adequacy', 'scores', 'when', 'alignment', 'links', 'were', 'presented', 'than', 'when', 'they', 'were', 'omitted', 'from', 'the', 'post-editing', 'tool.', 'We', 'also', 'note', 'that', 'when', 'alignment', 'links', 'were', 'absent,', 'one', 'bilingual', 'post-editor', '(PE5)', 'performed', 'worse', 'than', 'the', 'monolingual', 'post-editor', '(PE0)', 'from', '<ref type=""single"">Schwartz et al. (2014).</ref>', 'On', 'the', 'other', 'hand,', 'in', 'the', 'Spanish-English', 'condition,', 'where', 'overall', 'MT', 'quality', 'is', 'good,', 'we', 'observe', 'relatively', 'little', 'variation', 'in', 'quality', 'between', 'the', 'ten', 'post-editors.', 'When', 'compared', 'to', 'the', 'unedited', 'machine', 'trans-PE0', 'PE1', 'PE2', 'PE3', 'PE4', 'PE5', 'PE6', 'lations,', 'post-editing', 'resulted', 'in', 'improved', 'mean', 'adequacy', 'for', 'all', 'post-editors,', 'both', 'bilingual', 'and', 'monolingual.']",91,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3b1198ad-371f-4d9f-acc3-fccfac15a4d2,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['UNIFIEDQA: Crossing format boundaries with a single QA system'],['2020'],['Daniel Khashabi;Sewon Min;Tushar Khot;Ashish Sabharwal;Oyvind Tafjord;Peter Clark;Hannaneh Hajishirzi'],single,"['First,', 'we', 'compare', 'the', 'performance', 'of', 'UNI-FIEDQA', '<ref type=""single"">(Khashabi et al., 2020)</ref>', 'before', 'and', 'after', 'replacing', 'its', 'feed-forward', 'layers', 'with', 'our', 'implementation', 'of', 'top-k', 'attention', 'and', 'directly', 'performing', 'inference', 'on', '12', 'different', 'question', 'answering', '(QA)', 'datasets', 'without', 'any', 'training.', 'UNIFIEDQA', 'is', 'a', 'T5-based', '<ref type=""single"">(Raffel et al., 2020)</ref>', 'model', 'with', '11B', 'parameters', '<ref type=""single"">(Raffel et al., 2020),</ref>', 'fine-tuned', 'on', 'a', 'weighted', 'mixture', 'of', 'QA', 'datasets.', 'The', '12', 'datasets', 'include', 'diverse', 'domains,', 'such', 'as', 'science', 'questions,', 'factoid', 'questions', 'over', 'Wikipedia,', 'commonsense', 'questions,', 'etc.', 'Details', 'regarding', 'the', 'datasets', 'and', 'metrics', 'can', 'be', 'found', 'in', '§A.2.']",7,"[0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
3bdcf8da-ac96-44d2-bdef-7a0f626588d1,Associating semantic components with intersective Levin classes,1997,Hoa Dang;Joseph Rosenzweig;Martha Palmer,['Five papers on wordnet'],['1990'],['G Miller;R Beckwith;C Fellbaum;D Gross;K Miller'],single,"['This', 'paper', 'examines', 'the', 'question', 'of', 'differences', 'between', 'a', 'traditional', 'interlingua', 'approach', 'and', 'a', 'transferbased', 'approach', 'that', 'uses', 'cross-linguistic', 'semantic', 'features', 'to', 'generalize', 'its', 'transfer', 'lexicon', 'entries,', 'and', 'concludes', 'that', 'the', 'two', 'approaches', 'share', 'a', 'common', 'interest', 'in', 'lexical', 'classifications', 'that', 'can', 'be', 'distinguished', 'by', 'cross-linguistic', 'semantic', 'features.', 'The', 'paper', 'goes', 'on', 'to', 'discuss', 'current', 'approaches', 'to', 'English', 'classification,', 'Levin', 'classes', '<ref type=""single"">[8]</ref>', 'and', 'WordNet', '<ref type=""single"">[9].</ref>', 'We', 'present', 'a', 'refinement', 'of', 'Levin', 'classes', '-Intersective', 'Classes', '-that', 'shows', 'interesting', 'correlations', 'to', 'WordNet', 'and', 'that', 'makes', 'more', 'explicit', 'the', 'semantic', 'components', 'that', 'serve', 'to', 'distinguish', 'different', 'classes.']",64,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
42961dcc-aa43-4df6-9dd7-c1c5416b5712,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,['Neural speaker diarization with speaker-wise chain rule'],['2020'],['Y Fujita;S Watanabe;S Horiguchi;Y Xue;J Shi;K Nagamatsu'],single,"['In', 'O2M', 'models', 'shown', 'in', 'Fig.', '1(a),', 'a', 'multitask', 'objective', 'is', 'used', 'in', 'which', 'an', 'extra', 'branch', 'is', 'tasked', 'with', 'estimating', 'the', 'secondary', 'label', 'sequence.', 'For', 'example,', 'in', '<ref type=""single"">(Kubo and Bacchiani, 2020),</ref>', 'the', 'phonemic', 'transcript', 'is', 'produced', 'in', 'addition', 'to', 'the', 'graphemic', 'transcript.', 'The', 'O2M', 'model', 'can', 'estimate', 'each', 'sequence', 'more', 'accurately', 'than', 'separate', 'models', 'responsible', 'for', 'producing', 'phonemic', 'and', 'graphemic', 'transcripts', 'independently.', 'We', 'can', 'implement', 'this', 'approach', 'with', 'less', 'effort', 'by', 'attaching', 'multiple', 'loss', 'functions', 'to', 'the', 'base', 'architecture.', 'However,', 'this', 'O2M', 'model', 'does', 'not', 'explicitly', 'consider', 'dependencies', 'between', 'phonemic', 'and', 'graphemic', 'transcripts.', 'Furthermore,', 'aligning', 'phoneme', 'and', 'grapheme', 'sub-sequences', 'requires', 'additional', 'post-processing', 'based', 'on', 'time', 'alignment', 'or', 'alignment', 'across', 'the', 'multiple', 'sequences', 'during', 'inference.', 'Performance', 'of', 'downstream', 'NLP', 'tasks', 'built', 'on', 'top', 'of', 'ASR', 'outputs', 'will', 'suffer', 'if', 'this', 'post-processing', 'fails', 'to', 'generate', 'alignment.', '<ref type=""single"">Fig. 1(b)</ref>', 'shows', 'an', 'O2O', 'model', 'with', 'a', 'conditional', 'chain', 'mapping.', 'This', 'method', 'for', 'multiple', 'sequence', 'modeling', 'has', 'been', 'applied', 'to', 'dialog', 'modeling', '<ref type=""single"">(Liang et al., 2020),</ref>', 'speaker', 'diarization', '<ref type=""single"">(Fujita et al., 2020a),</ref>', 'and', 'multi-speaker', 'ASR', '<ref type=""single"">(Shi et al., 2020).</ref>', 'Unlike', 'the', 'O2M', 'model,', 'this', 'model', 'can', 'predict', 'a', 'variable', 'number', 'of', 'output', 'sequences', 'while', 'explicitly', 'considering', 'dependencies', 'between', 'the', 'multiple', 'sequences', 'based', 'on', 'the', 'probabilistic', 'chain', 'rule.', 'However,', 'modeling', 'these', 'inter-sequence', 'dependencies', 'requires', 'more', 'complicated', 'neural', 'architectures,', 'and', 'alignment', 'of', 'the', 'sequences', 'still', 'requires', 'post-processing', 'during', 'inference.']",157,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
44888512-408c-4b10-b33c-2727c485a682,Corpora and Machine Translation,1993,Yorick Wilks,['A new version of the machine translation system LMT'],['1989'],['M Mccord'],single,"['An', 'important', 'note', 'before', 'continuing:', 'when', 'I', 'refer', 'to', 'IBM', 'machine', 'translation', 'I', 'mean', 'only', 'the', 'systems', 'referred', 'to', 'at', 'the', 'end', 'by', 'Brown', 'et', 'al.', 'IBM', 'as', 'a', 'whole', 'supports', 'many', 'approaches', 'to', 'MT,', 'including', '<ref type=""single"">McCord\'s (1989)</ref>', 'Prolog-based', 'symbolic', 'approach,', 'as', 'well', 'as', 'symbolic', 'systems', 'in', 'Germany', 'and', 'Japan.']",36,"[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
46562612-2587-482e-a6a4-b1fa0e605ef7,Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure,1999,Nicoletta Calzolari;Antonio Zampolli,['Analogy-based Extraction of Lexical Knowledge from Corpora: The SPARKLE Experience'],['1998'],['S Federici;S Montemagni;V Pirrelli;N Calzolari'],single,"['Among', 'the', 'EC', 'projects', 'working', 'in', 'this', 'direction', 'we', 'mention', 'LE', 'SPARKLE', '(Shallow', 'PARsing', 'and', 'Knowledge', 'extraction', 'for', 'Language', 'Engineering', '2', '),', 'combining', 'shallow', 'parsing', 'and', 'lexical', 'acquisition', 'techniques', 'capable', 'of', 'learning', '(from', 'large', 'corpora)', 'aspects', 'of', 'word', 'knowledge', 'required', 'for', 'LE', 'applications', '<ref type=""single"">(Federici et al. 1998).</ref>', 'The', 'project', '(http://www.ilc.pi.cnr.it/sparkle.html)', 'is', 'positioned', 'as', 'research', 'on', 'the', 'development', 'of', 'methodologies', 'and', 'techniques', 'for', 'application-or', 'domaindependent', 'lexical', 'resources', 'to', 'be', 'acquired', '(semi)automatically', 'from', 'texts,', 'an', 'area', 'which', 'is', 'crucial', 'to', 'most', 'NLP', 'applications.', 'Economically', 'feasible', 'development', 'of', 'language', 'models', 'and', 'of', 'substantial', 'lexical', 'resources', 'for', 'real-world', 'NLP', 'applications', 'needs', 'to', 'be', 'based', 'on', 'substantially', '(semi)-automated', 'techniques', 'and', 'flexible', 'tools', 'for', 'analysing', 'and', 'extracting', 'lexical', 'information', 'from', 'textual', 'corpora,', 'otherwise', 'coverage', 'and/or', 'accuracy', 'will', 'remain', 'inadequate.']",43,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
484fd32f-9ef0-4263-9fe2-4c51601a1246,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['CorefQA: Coreference resolution as query-based span prediction'],['2020'],['Wei Wu;Fei Wang;Arianna Yuan;Fei Wu;Jiwei Li'],single,"['There', 'are', 'a', 'few', 'studies', 'on', 'the', 'joint', 'understanding', 'of', 'coreference', 'relations', 'and', 'reading', 'comprehension.', '<ref type=""single"">Wu et al. (2020b)</ref>', 'propose', 'to', 'formulate', 'coreference', 'resolution', 'as', 'a', 'span-prediction', 'task', 'by', 'generating', 'a', 'query', 'for', 'each', 'mention', 'using', 'the', 'surrounding', 'context,', 'thus', 'converting', 'coreference', 'resolution', 'to', 'a', 'reading', 'comprehension', 'problem.', 'They', 'leverage', 'the', 'plethora', 'of', 'existing', 'MRC', 'datasets', 'for', 'data', 'augmentation', 'and', 'improve', 'the', 'generalization', 'of', 'the', 'coreference', 'model.', 'In', 'parallel', 'to', '<ref type=""single"">Wu et al. (2020b),</ref>', '<ref type=""single"">Aralikatte et al. (2019)</ref>', 'also', 'cast', 'ellipsis', 'and', 'coreference', 'resolution', 'as', 'reading', 'comprehension', 'tasks.', 'They', 'leverage', 'the', 'existing', 'neural', 'archi-tectures', 'designed', 'for', 'MRC', 'for', 'ellipsis', 'resolution', 'and', 'outperform', 'the', 'previous', 'best', 'results.', 'In', 'a', 'similar', 'direction,', '<ref type=""single"">Hou (2020)</ref>', 'propose', 'to', 'cast', 'bridging', 'anaphora', 'resolution', 'as', 'question', 'answering', 'and', 'present', 'a', 'question', 'answering', 'framework', 'for', 'this', 'task.', 'However,', 'none', 'of', 'the', 'above', 'works', 'investigate', 'the', 'impact', 'of', 'using', 'coreference', 'data', 'on', 'QA.', '<ref type=""single"">Dua et al. (2020)</ref>', 'use', 'Amazon', 'Mechanical', 'Turkers', 'to', 'annotate', 'the', 'corresponding', 'coreference', 'chains', 'of', 'the', 'answers', 'in', 'the', 'passages', 'of', 'Quoref', 'for', '2,000', 'QA', 'pairs.', 'They', 'then', 'use', 'this', 'additional', 'coreference', 'annotation', 'for', 'training', 'a', 'model', 'on', 'Quoref.', 'They', 'show', 'that', 'including', 'these', 'additional', 'coreference', 'annotations', 'improves', 'the', 'overall', 'performance', 'on', 'Quoref.', 'The', 'proposed', 'method', 'by', '<ref type=""single"">Dua et al. (2020)</ref>', 'requires', 'annotating', 'additional', 'coreference', 'relations', 'on', 'every', 'new', 'coreference-aware', 'QA', 'dataset.', 'Contrary', 'to', 'this,', 'our', 'approach', 'uses', 'existing', 'coreference', 'resolution', 'datasets,', 'and', 'therefore,', 'applies', 'to', 'any', 'new', 'QA', 'dataset', 'without', 'introducing', 'any', 'additional', 'cost.']",15,"[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
48ae5a79-6288-4d1b-bdf5-1f95f38e6f9c,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Layers of interpretation: On grammar and compositionality'],['2015'],['Emily Bender;Dan Flickinger;Stephan Oepen;Woodley Packard;Ann Copestake'],single,"['Our', 'parser', 'also', 'consistently', 'fails', 'to', 'recognize', 'generic', 'you', 'as', 'opposed', 'to', 'deictic', 'you', '(cf.', 'Appendix,', 'Figure', '8),', 'which', 'points', 'to', 'the', 'importance', 'of', 'discourse', 'context', 'for', 'understanding', 'the', '(speaker)', 'meaning', 'of', 'even', 'a', 'single', 'word,', 'and', 'perhaps', 'to', 'something', 'that', 'all', 'current', 'DRS', 'parsers', 'lack:', 'an', 'explicit', 'distinction', 'between', 'sentence', 'meaning', 'and', 'speaker', 'meaning', '(cf.', '<ref type=""single"">Bender et al., 2015).</ref>']",56,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
4b74881a-d12e-4073-9a33-229b6c09ad85,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['Generalised probabilistic LR parsing for unification-based grammars'],['1993'],['E Briscoe;J Carroll'],single,"['In', 'order', 'to', 'assess', 'the', 'contribution', 'of', 'punctuation', 'to', 'the', 'selection', 'of', 'the', 'correct', 'analysis,', 'w�', 'applied', 'the', 'same', 'trained', 'version', 'of', 'the', 'integrated', 'grammar', 'to', 'the', '106', 'sentences', 'from', 'the', 'test', 'set', 'which', 'contain', 'internal', 'punctuation,', 'both', 'with', 'and', 'without', 'the', 'punctuation', 'marks', 'in', 'the', 'input.', 'A', 'comparison', 'of', 'the', 'GEIG', 'evaluation', 'metrics', 'for', 'this', 'set', 'of', 'sentences', 'punctuated', 'and', 'unpunctuated', 'gives', 'a', 'measure', 'of', 'the', 'contribution', 'of', 'punctuation', 'to', 'parse', 'selection', 'on', 'this', 'data.', '(The', 'results', 'for', 'the', 'unpunctuated', 'set', 'were', 'computed', 'against', 'a', 'version', 'of', 'the', 'Susanne', 'tree', 'bank', 'from', 'which', 'punctuation', 'had', 'also', 'been', '�', 'emoved.)', 'As', 'table', '3', 'shows,', 'recall', 'declines', 'by', '10%,', 'precision', 'by', '5%', 'and', 'there', 'are', 'an', 'average', 'of', '1.27', 'more', 'crossing', 'brackets', 'per', 'sentence.', '6', 'Conclusions', '<ref type=""single"">Briscoe and Carroll (1993)</ref>', 'and', '<ref type=""single"">Carroll (1993)</ref>', 'showed', 'that', 'the', 'LR', 'model,', 'combined', 'with', 'a', 'gram', 'mar', 'exploiting', 'subcategorisation', 'constraints,', 'could', 'achieve', 'good', 'parse', 'selection', 'accuracy', 'bu�', 'at', 'the', 'expense', 'of', 'poor', 'coverage', 'of', 'free', 'text.', 'The', 'results', 'reported', 'here', 'suggest', 'that', 'improved', 'coverage', 'of', 'heterogeneous', 'text', 'can', 'be', 'achieved', 'by', 'exploiting', 'textual', 'and', 'grammatical', 'con', 'straints', 'on', 'PoS', 'and', 'punctuation', 'sequences.', 'The', 'experiments', 'show', 'that', 'grammatical', 'coverage', 'can', 'be', 'greatly', 'increased', 'by', 'relaxing', 'subcategorisation', 'constraints,', 'and', 'that', 'text', 'grammatical', 'or', 'punctuation-cued', 'constraints', 'can', 'reduce', 'ambiguity', 'and', 'increase', 'coverage', 'during', 'parsing.']",125,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4db24651-9033-430b-9445-cdb55aec81fc,On the weak link between importance and prunability of attention heads,2020,Aakriti Budhraja;Madhura Pande;Preksha Nema;Pratyush Kumar;Mitesh Khapra,"[""Poor man's bert: Smaller and faster transformer models""]",['2020'],['Hassan Sajjad;Fahim Dalvi;Nadir Durrani;Preslav Nakov'],single,"['i.e.', 'we', 'prune', 'all', 'the', 'attention', 'heads', 'of', 'particular', 'layers.', 'When', 'all', 'the', 'self-attention', 'heads', 'of', 'a', 'layer', 'l', 'are', 'pruned,', 'only', 'the', 'feed-forward', 'network', 'of', 'that', 'layer', 'will', 'be', 'active', 'whose', 'input', 'will', 'just', 'be', 'the', 'output', 'from', 'the', 'previous', 'layer', 'l-1.', 'Bottom', 'layers', 'of', 'BERT', 'have', 'been', 'identified', 'to', 'model', 'word', 'morphology', '<ref type=""group"">(Liu et al., 2019, Belinkov et al., 2017)</ref>', 'and', 'are', 'considered', 'to', 'be', 'important', '<ref type=""single"">(Sajjad et al., 2020).</ref>', 'Further,', 'recent', 'work', 'has', 'identified', 'high', 'cosine-similarity', 'between', 'output', 'vectors', 'of', 'the', 'top', 'layers,', 'indicating', 'reduced', 'importance', 'of', 'top', 'layers', '<ref type=""single"">(Goyal et al., 2020).</ref>', 'We', 'relate', 'these', 'studies', 'to', 'pruning', 'by', 'comparing', 'the', 'pruning', 'of', 'the', 'same', 'number', 'of', 'top', 'and', 'bottom', 'layers', '(rows', '2-9', 'in', 'Table', '5).', 'Amongst', 'the', 'four', 'cases,', 'two', 'cases', 'each', 'favor', 'pruning', 'top', 'layers', 'and', 'bottom', 'layers,', 'revealing', 'no', 'preference', 'in', 'pruning.']",61,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4ec4d2d2-b35b-4d10-97c3-f1dd7ebf28ef,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Charformer: Fast character transformers via gradientbased subword tokenization'],['2021'],['Yi Tay;Vinh Tran;Sebastian Ruder;Jai Gupta;unk Hyung Won;Dara Chung;Zhen Bahri;Simon Qin;Cong Baumgartner;Donald Yu;unk Metzler'],single,"['Borrowing', 'from', 'techniques', 'used', 'on', 'languages', 'that', 'do', 'not', 'indicate', 'word', 'boundaries', 'by', 'the', 'use', 'of', 'whitespace,', 'we', 'address', 'the', 'problem', 'by', 'removing', 'all', 'whitespace', 'from', 'our', 'data', 'sets', 'after', 'phone', 'transliteration.', 'We', 'train', 'character-based', 'language', 'models', 'over', 'the', 'resulting', 'data.', 'Character-based', 'models', 'such', 'as', 'CharFormer', '<ref type=""single"">(Tay et al., 2021)</ref>', 'or', 'ByT5', '<ref type=""single"">(Xue et al., 2021)</ref>', 'have', 'shown', 'promise', 'in', 'recent', 'years', 'for', 'language', 'modeling,', 'even', 'if', 'this', 'approach', 'is', 'known', 'to', 'have', 'some', 'trade', 'offs', 'related', 'to', 'shorter', 'context', 'windows.']",46,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
4f94e045-70a9-4713-bf5c-7d10a84a0150,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Findings of the 2014 workshop on statistical machine translation'],['2014'],['O Bojar;C Buck;C Federmann;B Haddow;P Koehn;J Leveling;C Monz;P Pecina;M Post;H Saint-Amand;R Soricut;L Specia;A Tamchyna'],single,"['For', 'the', 'Russian-English', 'portion', 'of', 'this', 'study,', 'we', 'selected', 'as', 'source', 'texts', 'a', 'subset', 'of', 'the', 'texts', 'from', 'the', '2014', 'Workshop', 'on', 'Statistical', 'Machine', 'Translation', '(WMT-14)', 'shared', 'translation', 'task', '<ref type=""single"">(Bojar et al., 2014).</ref>', 'Source', 'texts', 'were', 'news', 'articles', 'covering', 'world', 'news', 'events', 'in', 'late', '2013.']",29,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
5088259d-1bf8-4197-b79a-0289c2f545be,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Ternary-BERT: Distillation-aware ultra-low bit BERT'],['2020'],['Wei Zhang;Lu Hou;Yichun Yin;Lifeng Shang;Xiao Chen;Xin Jiang;Qun Liu'],single,"['ALBERT', 'is', 'based', 'on', 'parameter', 'sharing/reduction', 'techniques', 'that', 'allows', 'to', 'reduce', 'the', 'computational', 'complexity', 'and', 'speed', 'up', 'training', 'and', 'inference', 'phases.', 'Compared', 'to', 'previous', 'compact', 'models', 'such', 'as', 'DistilBERT', '<ref type=""single"">(Sanh et al., 2019),</ref>', 'Q-BERT', '<ref type=""single"">(Shen et al., 2020)</ref>', 'or', 'TernaryBERT', '<ref type=""single"">(Zhang et al., 2020),</ref>', 'ALBERT', 'is', 'to', 'the', 'date', 'the', 'smallest', 'pre-trained', 'models', 'with', '12', 'million', 'parameters', 'and', '&lt,50', 'megabyte', '(MB)', 'model', 'size.']",34,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
545da3ef-a749-4bf7-8a57-23b32d90f71f,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['A process study of computer aided translation'],['2009'],['P Koehn'],single,"['Post-editing', 'is', 'the', 'process', 'whereby', 'a', 'human', 'user', 'corrects', 'the', 'output', 'of', 'a', 'machine', 'translation', 'system.', 'The', 'use', 'of', 'basic', 'post-editing', 'tools', 'by', 'bilingual', 'human', 'translators', 'has', 'been', 'shown', 'to', 'yield', 'substantial', 'increases', 'in', 'terms', 'of', 'productivity', '<ref type=""single"">(Plitt and Masselot, 2010)</ref>', 'as', 'well', 'as', 'improvements', 'in', 'translation', 'quality', '<ref type=""single"">(Green et al., 2013)</ref>', 'when', 'compared', 'to', 'bilingual', 'human', 'translators', 'working', 'without', 'assistance', 'from', 'machine', 'translation', 'and', 'post-editing', 'tools.', 'More', 'sophisticated', 'interactive', 'interfaces', '<ref type=""group"">(Langlais et al., 2000, Barrachina et al., 2009, Koehn, 2009b, Denkowski and Lavie, 2012)</ref>', 'may', 'also', 'provide', 'benefit', '<ref type=""single"">(Koehn, 2009a).</ref>']",70,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 1]"
5a178e8d-62f9-4440-9c59-984c867ab001,Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure,1999,Nicoletta Calzolari;Antonio Zampolli,"['The generative lexicon', 'The Generative Lexicon. Cambridge', 'Acquiring and Representing Semantic Information in a Lexical Knowledge Base']","['1991', '1995', '1991']","['J Pustejovsky', 'J Pustejovsky', 'N Calzolari']",group,"['A', 'coherent', 'development', 'of', 'semantic', 'lexical', 'resources', 'must', 'be', 'guided', 'by', 'an', 'underlying', 'theoretical', 'framework', 'for', 'structuring', 'word', 'meaning', 'and', 'generating', 'concepts', 'which', 'satisfies', 'both', 'ontological', 'considerations', 'as', 'well', 'as', 'the', 'need', 'to', 'capture', 'linguistic', 'generalisations.', 'The', 'SIMPLE', 'model', 'is', 'a', 'concrete', 'major', 'step', 'towards', 'this', 'objective.', 'It', 'is', 'based', 'on', 'EAGLES', 'Lexicon/Semantics', 'Working', 'Group', 'recommendations', '<ref type=""single"">(Sanfilippo et al. 1999)</ref>', 'and', 'on', 'extensions', 'of', 'Generative', 'Lexicon', '(GL)', 'theory', '<ref type=""single"">(Pustejovsky 1998</ref>', ').', 'An', 'essential', 'characteristicswhich', 'makes', 'it', 'basically', 'different', 'from', 'EuroWordNet', '(where', 'the', 'main', 'structuring', 'semantic', 'relations', 'are', 'synon-ymy', 'and', 'hyponymy)', '-is', 'its', 'ability', 'to', 'capture', 'the', 'various', 'dimensions', 'of', 'word', 'meaning', 'which', 'are', 'equally', 'important', 'in', 'language', 'and', 'therefore', 'in', 'the', 'development', 'of', 'a', 'computational', 'lexicon.', 'The', 'basic', 'vocabulary', 'relies', 'on', 'an', 'extension', 'of', '""qualia', 'structure""', 'for', 'structuring', 'the', 'semantic/conceptual', 'types,', 'which', 'is', 'understood', 'as', 'a', 'representational', 'tool', 'for', 'expressing', 'the', 'componential', 'multidimensional', 'aspect', 'of', 'word', 'meaning', '<ref type=""group"">(Pustejovsky 1991 (Pustejovsky , 1995,, Calzolari 1991).</ref>']",143,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
5a8d81f9-5820-4c24-9239-f61a6b8a36a6,Situation-Specific Multimodal Feature Adaptation,2021,Özge Alac,['Underspecification of cognitive status in reference production: Some empirical predictions'],['2012'],['Jeanette Gundel;Nancy Hedberg;Ron Zacharski'],single,"['In', 'many', 'cases,', 'even', 'the', 'object', 'names', 'are', 'verbally', 'omitted', 'in', 'spoken', 'utterances.', 'This', 'kind', 'of', 'implicit', 'commands', 'like', '""I', 'prefer', 'red,', 'can', 'you', 'open', 'a', 'bottle', 'and', 'bring', 'it', 'to', 'me?"",', 'require', 'the', 'hearer', 'to', 'reconstruct', 'the', 'underlying', 'intention', '""Open', 'a', 'bottle', 'of', 'red', 'wine,', 'and', 'bring', 'the', 'bottle""', '<ref type=""single"">(Gundel et al., 2012).</ref>', 'Alternatively,', 'depending', 'on', 'the', 'spatial', 'arrangements', 'of', 'the', 'agents', 'and', 'the', 'objects', 'in', 'the', 'room,', 'the', 'intention', 'of', 'the', 'speaker', 'might', 'be', 'slightly', 'different', 'and', 'more', 'complex.', 'For', 'example,', 'when', 'the', 'empty', 'glasses', 'are', 'closer', 'to', 'the', 'listener', 'than', 'the', 'speaker,', 'the', 'interpretation', 'might', 'be:', '""Open', 'a', 'bottle', 'of', 'red', 'wine,', 'pour', 'the', 'wine', 'into', 'one', 'of', 'the', 'empty', 'wine', 'glasses', 'and', 'bring', 'the', 'glass', 'of', 'wine', 'to', 'me"".', 'Expressing', 'this', 'intention', 'explicitly', 'most', 'often', 'results', 'in', 'unwieldy', 'utterances.']",50,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5acbdf1e-89de-4a5f-89de-2184a4337623,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['On the power and limitations of random features for understanding neural networks'],['2019'],['Gilad Yehudai;Ohad Shamir'],single,"['Top-k', 'attention', 'also', 'reduces', 'memory', 'consumption', 'in', 'Transformer', 'feed-forward', 'layers,', 'by', 'casting', 'this', 'layer', 'into', 'the', 'familiar', 'query-key-value', 'framework', 'using', 'ReLU', 'instead', 'of', 'the', 'row-wise', 'softmax', '<ref type=""single"">(Sukhbaatar et al., 2019).</ref>', 'This', 'is', 'specifically', 'appealing', 'in', 'models', 'such', 'as', 'T5', '<ref type=""single"">(Raffel et al., 2020)</ref>', 'and', 'GPT-3', '<ref type=""single"">(Brown et al., 2020),</ref>', 'where', 'for', 'short', 'inputs,', 'the', 'memory', 'consumption', 'is', 'dominated', 'by', 'the', 'feed-forward', 'layers,', 'as', 'the', 'number', 'of', 'keys,', 'corresponding', 'to', 'the', 'feedforward', 'hidden', 'dimension', 'size,', 'is', 'as', 'large', 'as', '65K.', 'Conversely,', 'methods', 'that', 'rely', 'on', 'random', 'feature', 'approximations', 'of', 'attention,', 'such', 'as', 'Performer', '<ref type=""single"">(Choromanski et al., 2021)</ref>', 'and', 'RFA', '<ref type=""single"">(Peng et al., 2021)</ref>', 'do', 'not', 'admit', 'an', 'efficient', 'approximation', 'for', 'the', 'ReLU', 'activation', '<ref type=""single"">(Yehudai and Shamir, 2019).</ref>']",97,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1]"
5b8676d6-a422-4307-8bde-f035eefc3119,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['unknown'],['unknown'],['unknown'],single,"['Sorry', '(adjective)', '-is', 'a', 'kind', 'of', 'feeling,', 'with', 'a', 'high', 'negative', 'score', 'and', 'emotion', 'label', 'of', 'regret-sorrow.', 'This', 'keyword', 'can', 'be', 'effective', 'in', 'situations', 'where', 'emotions', 'and', 'sentiments', 'are', 'strongly', 'involved.', 'Its', 'use', 'can', 'also', 'make', 'the', 'communication', 'sound', 'like', 'a', 'heartfelt', 'apology.', 'Also,', 'to', 'be', 'noted', 'is', 'the', 'fact', 'that', 'though', 'the', 'adjective', 'sorry', 'is', 'found', 'to', 'be', 'the', 'most', 'commonly-used', 'form', 'in', 'different', 'spoken', 'corpora.', '<ref type=""single"">(Harrison, 2013</ref>', '),', 'yet', 'in', 'our', 'data,', 'the', 'word', 'sorry', 'has', 'a', 'higher', 'occurrence', 'in', 'written', 'apologies', 'given', 'by', 'individuals-in-a', 'role', 'and', 'organizations.']",67,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]"
60abda72-59f6-450f-a0cf-255eac9bfca8,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,"['Controllable sentence simplification. CoRR, abs']",['1910'],['Louis Martin;Benoît Sagot'],single,"['Baselines', 'We', 'compare', 'the', 'SimpDefiner', 'with', 'generation-simplification', 'pipelines.', 'We', 'first', 'employ', 'LOG-CaD', '<ref type=""single"">(Ishiwatari et al., 2019)</ref>', 'and', 'MASS', '<ref type=""single"">(Song et al., 2019)</ref>', 'models', 'to', 'generate', 'definitions,', 'and', 'then', 'employ', 'ACCESS', '<ref type=""single"">(Martin et al., 2019)</ref>', 'and', 'MUSS', '<ref type=""single"">(Martin et al., 2020)</ref>', 'models', 'to', 'simplify', 'them.', 'Thus,', 'we', 'have', 'four', 'different', 'pipeline', 'baselines.', 'Since', 'these', 'models', 'are', 'not', 'available', 'in', 'Chinese,', 'we', 'only', 'apply', 'these', 'pipelines', 'to', 'English', 'datasets.', 'For', 'the', 'Chinese', 'SDG', 'task,', 'we', 'specially', 'pretrained', 'a', 'MASS-ZH', 'model', 'from', 'scratch', 'using', 'the', 'Chinese', 'Gigaword', 'Fifth', 'Edition', '3', 'corpus.', 'Note', 'that', 'we', 'set', 'the', 'learning', 'rate', 'to', '3e-4,', 'warmup', 'steps', 'to', '500', 'when', 'fine-tuning', 'both', 'MASS', 'and', 'MASS-ZH.']",24,"[0, 3, 3, 3, 3, 3, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 3, 3, 3, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
64b186ee-8965-47e8-a244-f0c237228eec,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['Principles and implementation of deductive parsing'],['1995'],['S Shieber;Y Schabes;F Pereira'],single,"['Parsing', 'schemata', 'are', 'closely', 'related', 'to', 'grammatical', 'deduction', 'systems', '<ref type=""single"">[14],</ref>', 'where', 'items', 'are', 'called', 'formula', 'schemata,', 'deduction', 'steps', 'are', 'inference', 'rules,', 'hypothesis', 'are', 'axioms', 'and', 'final', 'items', 'are', 'goal', 'formulas.']",9,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
69496a23-0c09-45fb-80db-03c33b2816f1,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['The', 'Transformer', 'architecture', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'is', 'based', 'on', 'a', 'stack', 'of', 'encoder-decoder', 'blocks,', 'composed', 'at', 'a', 'high', 'level', 'of', 'forward', 'propagation', 'networks', 'and', 'multi-headed', 'self-attention', 'operations.']",3,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
6bdc9ad7-e9a6-43fb-8d13-3644f54f8271,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['An empirical comparison of domain adaptation methods for neural machine translation'],['2017'],['Chenhui Chu;Raj Dabre;Sadao Kurohashi'],single,"['In', 'this', 'paper', 'we', 'describe', 'our', 'Chinese-to-English', 'simultaneous', 'translation', 'system,', 'which', 'uses', 'a', 'deep', 'Transformer', 'to', 'improve', 'translation', 'quality', 'and', 'adopts', 'wait-k', 'policy', '<ref type=""single"">(Ma et al., 2018)</ref>', 'to', 'reduce', 'latency.', 'Besides,', 'for', 'better', 'domain', 'adaption,', 'we', 'combined', 'mixed', 'fine-tuning', '<ref type=""single"">(Chu et al., 2017)</ref>', 'with', 'in-domain', 'data', 'filtering', '(Moore', 'and', 'Lewis,', '2010,', '<ref type=""single"">Ng et al., 2019)</ref>', 'and', 'proposed', 'a', 'new', 'domain', 'adaption', 'method', 'called', '""in-domain', 'mixed', 'fine-tuning"",', 'which', 'is', 'empirically', 'more', 'effective', 'than', 'fine-tuning', 'and', 'mixed', 'fine-tuning.']",36,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
72f9e739-6b8b-4216-b7fb-3e7fbef45a94,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,"['Do attention heads in bert track syntactic dependencies? ArXiv, abs']",['1911'],['Jason Phu Mon Htut;Shikha Phang;Samuel Bordia;unk Bowman'],single,"['What,', 'then,', 'is', 'known', 'about', 'BERT,', 'and', 'its', 'syntactic', 'and', 'semantic', 'capabilities?', 'Of', 'the', 'two,', 'it', 'is', 'syntax', 'that', 'BERT', 'is', 'most', 'widely', 'claimed', 'to', 'capture', 'within', 'its', 'internal', 'representations:', '<ref type=""single"">Hewitt and Manning (2019)</ref>', 'use', 'structural', 'probing', 'to', 'find', 'dependency', 'trees', 'in', ""BERT's"", 'vector', 'geometry,', 'while', '<ref type=""single"">Tenney et al. (2019)</ref>', 'use', 'probing', 'to', 'find', 'part', 'of', 'speech', 'tags', 'and', 'dependency', 'arc', 'labels,', 'among', 'other', 'types', 'of', 'syntactic', 'information.', 'Analysis', 'of', ""BERT's"", 'attention', 'has', 'shown', 'that', 'certain', 'heads', 'attend', 'to', 'not', 'only', 'relevant', 'linguistic', 'units', 'such', 'as', 'determiners', 'of', 'nouns', 'and', 'coreferent', 'mentions', '<ref type=""single"">(Clark et al., 2019),</ref>', 'but', 'also', 'dependency', 'relations', '<ref type=""single"">(Htut et al., 2019).</ref>']",91,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 1]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1]"
74828d16-0dbc-4e66-a58e-df907b875e27,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['A survey of arabic named entity recognition and classification'],['2014'],['Khaled Shaalan'],single,"['As', 'discussed', 'elsewhere,', 'e.g.,', 'by', '<ref type=""single"">Farghaly and Shaalan (2009),</ref>', 'Arabic', 'is', 'rich', 'morphology', 'language', 'with', 'complex', 'grammar', 'structure', 'which', 'poses', 'extra', 'challenges', 'to', 'systems', 'when', 'considering', 'Arabic', 'text', 'as', 'input.', '<ref type=""single"">Habash (2010)</ref>', 'discussed', 'the', 'script', 'differences', 'such', 'as', 'letter', 'shaping,', 'script', 'direction', '(right', 'to', 'left)', 'and', 'obligatory', 'ligatures.', 'Also', '<ref type=""single"">Habash et al. (2013)</ref>', 'discussed', 'the', 'lack', 'of', 'standard', 'orthographies:', 'e.g.,', 'and', 'both', 'mean', '(gram).', 'One', 'of', 'the', 'major', 'challenges', 'in', 'Arabic', 'NER', 'is', 'the', 'lack', 'of', 'capitalization', '<ref type=""group"">(Shaalan, 2014, Benajiba et al., 2008a).</ref>', '<ref type=""single"">Shaalan (2014)</ref>', 'also', 'discussed', 'the', 'agglutinative', 'nature', 'of', 'the', 'Arabic', 'language', 'where', 'new', 'words', 'and', 'sometimes', 'even', 'sentences', 'can', 'be', 'derived', 'by', 'adding', 'affixes', 'and', 'clitics', 'to', 'Arabic', 'words,', 'making', 'Arabic', 'a', 'morphologically', 'rich', 'language.']",71,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
74eadcdf-52d9-4017-a121-fa0f4bcb8a4a,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,['LIBSVM: A library for support vector machines'],['2011'],['Chih-Chung Chang;Chih-Jen Lin'],single,"['The', 'decoding', 'analyses', 'used', 'linear', 'support', 'vector', 'machines', '(SVM)', '<ref type=""single"">(Chang and Lin, 2011)</ref>', 'and', 'Transformers,', 'which', 'can', 'capture', 'complex', 'interactions', 'of', 'EEG', 'data', 'across', 'time', 'points.', 'All', 'classifiers', 'were', 'trained', 'on', 'the', 'EEG', 'training', 'data,', 'assessed', 'on', 'the', 'dev', 'set', 'and', 'scored', 'on', 'the', 'independent', 'test', 'set.', 'Hyperparameters', 'and', 'early', 'stopping', 'were', 'selected', 'based', 'on', 'the', 'dev', 'set.', 'We', 'assessed', 'linear', 'SVMs', 'and', 'Transformers', 'on', 'the', 'dev', 'set', 'using', '10', 'different', 'random', 'seed', 'points.', 'We', 'show', 'mean', 'classification', 'accuracy', 'with', '68%', 'confidence', 'intervals', '(CI)', 'over', 'those', '10', 'replications', 'on', 'the', 'dev', '(Table', '4,', 'Figure', '3)', 'resp.', 'test', 'set', '(Figure', '2,', '4,', '5).', 'We', 'compute', 'statistics', 'on', 'test', 'set', 'classification', 'responses', 'from', 'the', 'model', 'that', 'scored', 'the', 'highest', 'on', 'the', 'dev', 'set', '(e.g.', 'binomial', 'or', 'Wilcoxon', 'signed', 'rank', 'tests).']",9,"[2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
75495dd6-da3f-4e54-9af8-66e4f201c6f6,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,['Differences in brain potentials to open and closed class words: class and frequency effects'],['2001'],['unk Thomas F Münte;M Bernardina;Helga Wieringa;Andras Weyerts;Mike Szentkuti;Sönke Matzke;unk Johannes'],single,"['We', 'performed', 'decoding', 'based', 'on', '(i)', 'EEG', 'for', 'single-trials', '(i.e.', 'no', 'averaging),', '(ii)', 'EEG', 'averaged', 'across', 'three', 'and', '(iii)', 'ten', 'trials.', 'Averaging', 'EEG', 'signals', 'across', 'trials', 'increases', 'the', 'signal', 'to', 'noise', 'ratio', 'of', 'the', ""'samples'"", '<ref type=""group"">(Grootswagers et al., 2017, Guggenmos et al., 2018, Roy et al., 2019, Tuckute et al., 2019),</ref>', 'but', 'ignores', 'true', 'variability', 'across', 'EEG', 'data', 'from', 'different', 'words', 'of', 'the', 'same', 'category', '<ref type=""single"">(Münte et al., 2001).</ref>', 'For', 'training', '(resp.', 'dev)', 'set', 'we', 'generated', 'the', 'same', 'number', 'of', 'samples', 'for', '3', 'and', '10', 'trial', 'averages', 'as', 'for', 'the', 'single', 'trial', 'test', '(resp.', 'dev)', 'sets', 'via', 'boostrapping.', 'For', 'the', 'test', 'set,', 'we', 'averaged', 'data', 'without', 'replacement,', 'so', 'that', 'examples', 'can', 'be', 'entered', 'as', 'independent', 'data', 'points', 'in', 'statistical', 'tests.', 'Hence,', 'the', 'number', 'of', 'samples', 'in', 'the', 'test', 'set', '(but', 'not', 'in', 'the', 'training', 'or', 'dev', 'sets)', 'is', 'smaller', 'for', '3', 'and', '10', 'trial', 'averages', 'than', 'single', 'trials', '(Table', '3).']",50,"[2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
76f07cfc-82b7-40a5-8a9b-0a6229571ee3,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Hinge-Loss Markov random fields and probabilistic soft logic'],['2017'],['H Stephen;Matthias Bach;Bert Broecheler;Lise Huang;unk Getoor'],single,"['We', 'first', 'compile', 'rules', 'that', 'specify', 'evidence', 'for', 'the', 'support', 'and', 'attack', 'relations', 'between', 'claim', 'C', 'and', 'statement', 'S', '(Table', '1).', '2', 'These', 'rules', 'are', 'combined', 'via', 'PSL', '<ref type=""single"">(Bach et al., 2017)</ref>', 'to', 'estimate', 'the', 'optimal', 'relation', 'between', 'C', 'and', 'S.', '3', 'We', 'will', 'describe', 'individual', 'rules', 'in', 'four', 'categories:', 'factual', 'consistency,', 'sentiment', 'coherence,', 'causal', 'relation,', 'and', 'normative', 'relation,', 'followed', 'by', 'additional', 'chain', 'rules.']",28,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7883a3d7-869f-4a49-bea3-d25a6ea43a6a,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['unknown'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Lukasz Kaiser;Illia Polosukhin'],single,"['Our', 'approach', 'is', 'inspired', 'by', 'the', 'fact', 'that', 'many', 'languages', 'are', 'primarily', 'oral,', 'with', 'writing', 'systems', 'that', 'represent', 'spoken', 'sounds.', 'We', 'convert', 'both', 'text', 'and', 'audio', 'into', 'single', 'common', 'representation', 'of', 'sounds,', 'or', '""phones,""', 'represented', 'using', 'the', 'International', 'Phonetic', 'Alphabet,', 'or', 'IPA.', 'Then,', 'we', 'perform', 'both', 'language', 'model', 'pre-training', 'and', 'the', 'training', 'of', 'models', 'for', 'downstream', 'tasks', 'in', 'this', 'phonetic', 'representation.', 'Well-tested', 'architectures,', 'such', 'as', 'BERT-style', 'transformer', 'models', '<ref type=""single"">(Vaswani et al., 2017),</ref>', 'are', 'thus', 'flexibly', 'extended', 'to', 'either', 'speech', 'or', 'audio', 'data.']",68,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
836b2436-e729-4470-8a35-8272c2525557,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Playing codenames with language graphs and word embeddings'],['2021'],['Divya Koyyalagunta;Anna Sun;Rachel Draelos;Cynthia Rudin'],single,"['Among', 'the', 'similarity', 'measures', 'of', '<ref type=""single"">Koyyalagunta et al. (2021),</ref>', 'generally', 'FastText', 'seems', 'to', 'be', 'the', 'best', 'model.', 'So,', 'following', 'the', 'cited', 'work,', 'we', 'create', 'a', 'relatedness', 'matrix', 'based', 'on', 'the', 'cosine', 'similarity', 'of', 'FastText', 'vectors.', 'That', 'is,', 'if', 'v', 'i,', 'v', 'j', 'are', 'vectors', 'corresponding', 'to', 'words', 'w', 'i,', 'w', 'j,', 'thens', 'F', '(w', 'i,', 'w', 'j)', '=', 'cos(v', 'i,', 'v', 'j', ').For', 'comparability', 'with', 'the', 'other', 'methods,', 'we', 'train', 'our', 'FastText', 'models', 'on', 'the', 'above', 'corpora', 'for', 'English', 'and', 'Hungarian', 'in', '300', 'dimensions,', 'using', 'window', 'size', '10.']",5,"[2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
85111c6c-80fe-427f-9bf8-53684b3edb0d,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['i', '[CLS]', 'Strategy', '-This', 'is', 'the', 'default', 'sentence', 'pair', 'classification', 'architecture', 'with', 'transformers', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'where', 'the', 'two', 'sentences', 'are', 'concatenated', 'with', 'a', '[SEP]', 'token', 'and', 'passed', 'through', 'a', 'transformer', 'model.', 'Then', 'the', 'output', 'of', 'the', '<ref type=""single"">[CLS]</ref>', 'token', 'is', 'fed', 'into', 'a', 'softmax', 'layer', 'to', 'predict', 'the', 'labels', '(Figure', '1).']",13,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
8512c562-6e19-44ac-80db-6318b1dd292b,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['unknown'],['1994'],['Mark Aronoff'],single,"['The', 'central', 'position', 'in', 'the', 'bow-tie', 'model', 'is', 'taken', 'by', 'the', 'lexeme.', 'The', 'notion', 'of', 'lexeme', 'in', 'WM', 'is', 'similar', 'to', 'the', 'one', 'adopted', 'by', '<ref type=""single"">Matthews (1974),</ref>', '<ref type=""single"">Aronoff (1994)</ref>', 'and', 'others.', 'A', 'lexeme', 'is', 'a', 'word', 'considered', 'as', 'an', 'inflectional', 'paradigm.', 'Fig.', '1', 'highlights', 'two', 'mappings', 'involving', 'the', 'lexeme:']",26,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0]"
8b4e05f4-a98c-46df-a9e9-e123868ea8d1,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['Models.', 'We', 'use', 'the', 'attention', 'scores', 'over', 'BERT', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'based', 'classification', 'models', 'as', 'they', 'have', 'achieved', 'the', 'state-of-art', 'performance.', 'Note', 'that', 'our', 'proposed', 'framework', 'can', 'also', 'be', 'easily', 'extended', 'to', 'models', 'with', 'different', 'architectures.']",8,"[0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8d948e21-1df7-4913-a73f-050de2c7758a,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['Understanding disentangling in β-vae'],['2018'],['Christopher Burgess;Irina Higgins;Arka Pal;Loïc Matthey;Nick Watters;Guillaume Desjardins;Alexander Lerchner'],single,"['β-VAE', '<ref type=""single"">(Higgins et al., 2017)</ref>', 'adds', 'a', 'hyperparameter', 'β', 'to', 'control', 'the', 'regularisation', 'from', 'the', 'KL-term', 'via', 'the', 'following', 'objective', 'function:E', 'q', 'φ', '(z|x)', 'log', 'p', 'θ', '(x|z)', '−', 'βD', 'KL', '(q', 'φ', '(z|x),', 'p(z))Reconstructing', 'under', 'β-VAE', '(with', 'the', 'right', 'value', 'of', 'β)', 'framework', 'encourages', 'encoding', 'data', 'points', 'on', 'a', 'set', 'of', 'representational', 'axes', 'on', 'which', 'nearby', 'points', 'along', 'those', 'dimensions', 'are', 'also', 'close', 'in', 'original', 'data', 'space', '<ref type=""single"">(Burgess et al., 2018).</ref>', '<ref type=""single"">(Burgess et al., 2018)</ref>', 'extends', 'β-VAE', 'via', 'constraint', 'optimisation:']",65,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]"
95562879-f0de-43b1-a980-2e65636dba80,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Statistical phrasebased translation'],['2003'],['P Koehn;F Och;D Marcu'],single,"['First,', 'each', 'target-side', 'sentence', 'from', 'the', 'parallel', 'corpus', 'is', 'supertagged', 'by', 'assigning', 'the', 'best', 'sequence', 'of', 'CCG', 'supertags', 'to', 'its', 'words.', 'Next,', 'phrase', 'pairs', 'are', 'extracted', 'from', 'the', 'parallel', 'corpus', 'according', 'to', 'the', 'PBSMT', 'phrase', 'extraction', 'method', '<ref type=""single"">[2].</ref>', 'Then,', 'each', 'phrase', 'pair', 'is', 'assigned', 'a', 'CCG', 'category', 'that', 'results', 'from', 'combining', 'the', 'supertags', 'of', 'the', 'words', 'of', 'the', 'target-side', 'phrase', 'using', 'CCG', 'combinatory', 'operators.', 'In', 'case', 'phrase', 'parsing', 'fails', 'to', 'find', 'a', 'single', 'CCG', 'category', 'for', 'the', 'phrase,', 'a', 'general', 'X', 'label', 'is', 'assigned', 'to', 'the', 'phrase.', 'Finally,', 'hierarchical', 'rules', 'are', 'extracted', 'from', 'sentencepairs', 'according', 'to', 'the', 'same', 'basic', 'HPB', 'SMT', 'rule', 'extraction', 'method', '<ref type=""single"">[3].</ref>']",37,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
982fa80a-c8de-4a55-953f-e0f7c47a75b1,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['Minimum error rate training in statistical machine translation'],['2003'],['F Och'],single,"['We', 'further', 'perform', 'some', 'in-depth', 'analyses', 'from', 'diverse', 'perspectives', 'on', 'the', 'CNNDM', 'dataset', 'to', 'gain', 'more', 'insights', 'into', 'our', 'proposed', 'method.', '3:', 'Model', 'performance', 'with', 'different', 'γ', 'coefficients', 'weighting', 'the', 'contrastive', 'loss', '(Eq.', '10)', 'on', 'CNNDM.', 'BRIO-Ctr', 'is', 'trained', 'with', 'the', 'contrastive', 'loss', 'only,', 'which', 'no', 'longer', 'preserves', 'its', 'generation', 'ability.', 'We', 'report', 'its', 'performance', 'when', 'it', 'is', 'used', 'as', 'an', 'evaluation', 'model', 'to', 'select', 'from', 'candidate', 'summaries.', 'R-1/2/L', 'are', 'the', 'ROUGE-1/2/L', 'F1', 'scores.', 'Coefficients', 'of', 'the', 'Multi-Task', 'Loss', 'The', 'multitask', 'loss', '(Eq.', '10)', 'used', 'to', 'train', 'our', 'model', 'contains', 'two', 'parts:', 'the', 'cross-entropy', 'loss', 'and', 'the', 'contastive', 'loss.', 'As', 'shown', 'in', 'Tab.', '3,', 'as', 'the', 'weight', 'of', 'the', 'contrastive', 'loss', '(γ)', 'increases,', 'the', ""model's"", 'performance', 'improves.', 'However,', 'the', 'cross-entropy', 'loss', 'is', 'still', 'necessary', 'to', 'preserve', 'the', ""model's"", 'ability', 'as', 'a', 'generation', 'model.', 'We', 'argue', 'that', 'this', 'is', 'because', 'the', 'token', 'level', 'accuracy', 'is', 'still', 'important', 'during', 'the', 'autoregressive', 'generation', 'process,', 'where', 'the', 'individual', 'tokens', 'are', 'predicted', 'sequentially.', 'In', 'addition,', 'we', 'also', 'found', 'that', 'the', 'model', 'tends', 'to', 'achieve', 'the', 'best', 'performance', '(w.r.t', 'the', 'ROUGE', 'scores', 'on', 'the', 'development', 'set)', 'faster', 'with', 'a', 'higher', 'γ.', 'Specifically,', 'it', 'requires', 'less', 'than', 'one', 'entire', 'epoch', 'to', 'achieve', 'the', 'best', 'performance', 'on', 'CNNDM,', 'making', 'our', 'approach', 'an', 'efficient', 'fine-tuning', 'method.Coefficient', '(γ)', 'R-1', 'R-2', 'R-L', '0', '(Generation-Finetuning', 'as', 'a', 'Loop', 'Since', 'the', 'fine-tuned', 'model', '(BRIO-Mul)', 'is', 'still', 'able', 'to', 'gen-', 'erate,', 'we', 'can', 'use', 'it', 'to', 'generate', 'a', 'new', 'set', 'of', 'candidates', 'in', 'the', 'same', 'way', 'as', 'we', 'used', 'the', 'pre-trained', 'BART', 'model,', 'and', 'continue', 'fine-tuning', 'it', 'on', 'this', 'newly', 'created', 'set', 'of', 'candidates', '<ref type=""single"">(Och, 2003).</ref>', 'Fig.', '2', 'illustrates', 'this', 'iterative', 'process.', 'The', 'results', 'shown', 'in', 'Tab.', '4', 'illustrate', 'that', 'this', 'new', 'model', '(BRIO-Loop)', 'outperforms', 'BRIO-Mul.', 'Besides,', 'the', 'model', 'reached', 'the', 'best', 'performance', 'very', 'quickly,', 'showing', 'the', 'potential', 'of', 'adopting', 'our', 'method', 'in', 'an', 'online', 'framework', 'where', 'the', 'new', 'candidates', 'are', 'dynamically', 'generated', 'from', 'the', 'current', 'model.', 'We', 'leave', 'this', 'direction', 'for', 'future', 'work.']",260,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
993825f3-a8eb-427e-a7e4-b290611d5dca,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['Psychological models of emotion. The neuropsychology of emotion'],['2000'],['R Klaus;unk Scherer'],single,"['Of', 'particular', 'interest', 'to', 'us', 'were', 'the', 'keywords', 'apology', '(noun)', 'and', 'regret', '(verb).', 'We', 'compare', 'the', 'SentiWordNet', 'scores', 'and', 'the', 'WordNet-Affect', 'labels', 'of', 'these', 'two', 'keywords.', 'While', 'emotion', 'is', 'defined', 'as', 'a', 'relatively', 'brief', 'episode', 'of', 'response', 'to', 'the', 'evaluation', 'of', 'an', 'external', 'or', 'internal', 'event', 'as', 'being', 'of', 'major', 'significance.', '(such', 'as', 'angry,', 'sad,', 'joyful,', 'fearful,', 'ashamed,', 'proud,', 'elated,', 'desperate),', 'a', 'sentiment', 'is', 'the', 'positive', 'or', 'negative', 'orientation', 'that', 'a', 'person', 'expresses', 'toward', 'some', 'object', 'or', 'situation', '<ref type=""single"">(Scherer, 2000).</ref>', 'Thus,', 'we', 'can', 'posit', 'that', 'the', 'word', 'apology', 'which', 'has', 'no', 'emotion', 'label,', 'has', 'no', 'or', 'weak', 'emotional', 'connect,', 'which', 'also', 'aligns', 'with', 'our', 'conclusion', 'about', 'the', 'keyword', 'apologize.', 'In', 'contrast,', 'the', 'verb', 'regret', 'helps', 'to', 'effectively', 'communicate', 'the', 'emotion', 'of', 'repentance.', 'Looking', 'at', 'the', 'sentiment', 'associated', 'with', 'these', 'words,', 'we', 'conclude', 'that', 'the', 'mental', 'attitude', 'of', 'the', 'writer', 'is', 'more', 'objective', 'to', 'the', 'situation', 'in', 'using', 'the', 'verb', 'regret', 'while', 'it', 'is', 'highly', 'negative', 'in', 'the', 'case', 'of', 'the', 'usage', 'of', 'the', 'word', 'apology.', 'This', 'further', 'implies', 'that', 'a', 'high', 'negative', 'sentiment', 'score', 'means', 'that', 'the', 'writer', 'of', 'the', 'apology', 'realizes', 'the', 'gravity', 'of', 'the', 'transgression', 'and', 'to', 'some', 'extent', 'admits', 'to', 'the', 'wrong', 'done.', 'However,', 'a', 'high', 'objective', 'score', 'implies', 'the', 'writer', 'taking', 'a', 'neutral', 'stance', 'to', 'the', 'situation', 'and', 'not', 'necessarily', 'admitting', 'to', 'any', 'wrongdoing.']",78,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9991da19-0609-4fa7-966e-fa092df74c41,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['Part-of-speech tagging with bidirectional long short-term memory recurrent neural network'],['2015'],['Peilu Wang;Yao Qian;K Frank;Lei Soong;Hai He;unk Zhao'],single,"['Similar', 'to', 'other', 'NLP', 'applications,', 'the', 'most', 'recent', 'attention', 'in', 'this', 'area', 'has', 'been', 'on', 'neural', 'approaches.', '<ref type=""single"">Wang et al. (2015)</ref>', 'demonstrated', 'an', 'effective', 'way', 'of', 'applying', 'a', 'Bi-LSTM', 'to', 'the', 'POS', 'tagging', 'task,', 'achieving', '97.4%', 'on', 'the', 'English', 'Penn', 'Treebank.', '<ref type=""single"">Darwish et al. (2017)</ref>', 'used', 'a', 'Bi-LSTM', 'in', 'their', 'work', 'on', 'Arabic', 'POS', 'tagging,', 'achieving', '95.50%.', '<ref type=""single"">Alrajhi and ELAffendi (2019)</ref>', 'used', 'the', 'LSTM-RNN', 'model', 'on', 'the', 'Quranic', 'Arabic', 'Corpus', '(QAC).', 'They', 'reported', 'accuracy', 'of', '99.76%', 'at', 'the', 'word', 'level', 'and', '99.18%', 'at', 'the', 'morpheme', 'level.', 'They', 'also', 'compared', 'their', 'system', 'against', 'the', 'Word2Vec', 'POS', 'tagger,', 'for', 'which', 'they', 'reported', 'accuracy', 'levels', 'of', '97.33%', 'and', '99.55%', 'for', 'words', 'and', 'morphemes', 'respectively.']",17,"[0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9f9b269e-0777-498f-90d8-6fb8618b6127,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['Using suffix arrays to compute term frequency and document frequency for all substrings in a corpus'],['2001'],['M Yamamoto;K Church'],single,"['To', 'score', 'translation', 'candidates', 'we', 'will', 'compute', 'global', 'and', 'local', 'frequencies', 'of', 'occurrence', 'of', 'substrings', 'using', 'the', 'method', 'described', 'by', '<ref type=""single"">Yamamoto and Church (2001)</ref>', 'which', 'is', 'based', 'on', 'suffix', 'arrays', 'and', 'longest', 'common', 'prefix', 'arrays.']",20,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
9fb94bb8-ea71-467f-8b4d-5c0c747db6ab,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['unknown'],['2019'],['Gemma Bel-Enguix;Helena Gómez-Adorno;Jorge Reyes-Magaña;Gerardo Sierra'],single,"['One', 'can', 'create', 'a', 'graph', '(Bel-Enguix,', '2014),', 'and', 'its', 'transformation', 'to', 'a', 'word', 'embedding', 'model', '<ref type=""single"">(Bel-Enguix et al., 2019),</ref>', 'specifically', 'for', 'modeling', 'associations,', 'but', 'these', 'require', 'difficult-to-obtain', 'association', 'data.', 'This', 'would', 'be', 'a', 'high', 'resource', 'requirement', 'and', 'would', 'make', 'it', 'difficult', 'to', 'apply', 'such', 'methods', 'in', 'various', 'languages.']",15,"[2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
a1020816-710e-453b-8815-1353eec5dce3,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['Heterogeneous graph neural network'],['2019'],['Chuxu Zhang;Dongjin Song;Chao Huang;Ananthram Swami;Nitesh Chawla'],single,"['We', 'modeled', 'toxic', 'comments', 'detection', 'as', 'a', 'heterogeneous', 'network', 'since', 'this', 'network', 'type', 'contains', 'abundant', 'information', 'with', 'structural', 'relations', '(edges)', 'among', 'multi-typed', 'nodes', 'as', 'well', 'as', 'unstructured', 'content', 'associated', 'with', 'each', 'node', '<ref type=""single"">(Zhang et al., 2019).</ref>', 'Graph', 'structures', 'have', 'been', 'used', 'for', 'several', 'tasks,', 'such', 'as:', 'topic', 'model,', 'name', 'disambiguation,', 'scientific', 'impact', 'measurement,', 'and', 'others,', 'obtaining', 'good', 'results', '<ref type=""single"">(King et al., 2014).</ref>', 'We', 'defined', 'a', 'undirected', 'and', 'weighted', 'graph', 'as', 'G', '=', '(V,', 'E,', 'W', '),', 'where', 'V', 'is', 'a', 'set', 'of', 'vertices', 'V', '=', '{v', '1,', '...,', 'v', 'n', '},', 'E', 'indicates', 'a', 'set', 'of', 'edges', 'E', '=', '{e', '1,', '...,', 'e', 'n', '},', 'and', 'W', 'is', 'a', 'weighted', 'adjacency', 'matrix,', 'in', 'which', 'W', 'i,j', 'denotes', 'the', 'weight', 'of', 'an', 'edge', 'between', 'nodes', 'i', 'and', 'j.', 'We', 'defined', 'two', 'node', 'types:', 'token', 'and', 'sentence', 'and', 'two', 'constraints', 'not', 'allowing', 'link', 'among', 'tokens', 'nodes', 'or', 'among', 'sentences', 'nodes.']",32,"[2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
a4c86e92-5840-4f85-83fd-9f7d187e0e95,Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure,1999,Nicoletta Calzolari;Antonio Zampolli,"['Morphosyntactic annotation', 'Synopsis and comparison of morphosyntactic phenomena encoded in lexicons and corpora. A common proposal and applications to European languages']","['1996', '1996']","['G Leech;A Wilson', 'M Monachini;N Calzolari']",group,"['Encoding:', 'All', 'the', 'information', 'explicitly', 'represented', 'in', 'the', 'source', 'texts', 'is', 'encoded', 'following', 'essentially', 'the', 'CES', '(Corpus', 'Encoding', 'Standard)', 'designed', 'by', 'EAGLES,', 'on', 'the', 'basis', 'of', 'the', 'Text', 'Encoding', 'Initiative', '(TEI)', 'guidelines', '<ref type=""single"">(Ide et al. 1996).</ref>', '250,000', 'running', 'words', 'are', 'tagged', 'at', 'the', 'morphosyntactic', 'level,', 'following', 'the', 'EAGLES', 'guidelines', '<ref type=""group"">(Leech, Wilson 1996 : Monachini, Calzolari 1996),</ref>', 'instantiated', 'by', 'each', 'PAROLE', 'partner', 'for', 'his', 'own', 'language.']",46,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
abc5c219-9a85-44b7-9201-b68b00b40c41,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,"['unknown', 'A Study of Automatically Acquiring Explanatory Inference Patterns from Corpora of Explanations: Lessons from Elementary Science Exams']","['unknown', '2017']","['unknown', 'Peter Jansen']",group,"['Similarly', 'to', 'the', 'previous', 'editions', 'of', 'the', 'shared', 'task', '<ref type=""group"">(Jansen and Ustalov, 2019, 2020)</ref>', 'The', 'percentage', 'of', 'overlap', 'is', 'computed', 'by', 'dividing', 'the', 'number', 'of', 'shared', 'terms', 'between', 'question-answer', 'pair', 'and', 'a', 'fact', 'by', 'the', 'total', 'number', 'of', 'unique', 'terms.', 'To', 'evaluate', 'the', 'systems', 'in', 'the', 'most', 'challenging', 'setting,', 'we', 'gradually', 'decrease', 'the', 'value', 'of', 'T', 'down', 'to', '0.']",9,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ae7944d0-f7a8-48a5-8943-b7b6eb97ba78,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['On not being let up with the garden path: the use of context by the psychological syntax processor'],['1985'],['S Steedman ; Crain;M Steedman'],single,"['Structural', 'ambiguity', 'is', 'resolved', 'by', 'the', 'cost-based', 'ambiguity', 'resolution', 'method', '<ref type=""single"">[Kitano et al., 1989</ref>', '].', 'The', 'cost-based', 'ambiguity', 'resolution', 'takes', 'into', 'account', 'various', 'psycholinguistic', 'studies', 'such', 'as', '<ref type=""single"">[Crain and Steedman, 1985]</ref>', 'and', '<ref type=""single"">[Ford et al., 1981].</ref>']",24,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 3, 3]"
b34020a5-aac4-4f26-b33f-0f616137ded0,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Maximum likelihood from incomplete data via the EM algorithm'],['1977'],['A Dempster;N Laird;D Rubin'],single,"[')where', 'k', 'is', 'the', 'number', 'of', 'language', 'models', 'which', 'are', 'being', 'interpolated,', 'µ', 'i', 'the', 'interpolation', 'weights', 'and', 'V', 'is', 'the', 'vocabulary', 'of', 'the', 'specific', 'language', 'model.', 'The', 'interpolation', 'weights', 'are', 'estimated', 'using', 'Expectation', 'Maximization', '(EM)', '<ref type=""single"">[10]</ref>', 'over', 'the', 'log-likelihood', 'in', '<ref type=""single"">(6)</ref>', ':N', 't=1', 'log', 'k', 'i=1', 'µ', 'i', '(f', '*', 'i', '(w', 't', '|h', 't)', '+', 'λ', 'i', '(h', 't', ')P', 'r', 'mix', '(w', 't', '|', 'ht', '))', '(6)where', 'the', 'index', 't', 'scans', 'over', 'all', 'the', 'n-grams', 'in', 'the', 'training', 'corpora.', 'This', 'mixture', 'model', 'was', 'used', 'to', 'combine', 'the', ""'in-domain'"", 'language', 'model', 'with', 'an', ""'out-of-domain'"", 'one,', 'with', 'the', 'mixture', 'weights', 'being', 'estimated', 'on', 'the', ""'in-domain'"", 'training', 'data', 'by', 'applying', 'a', 'cross-validation', 'scheme.', 'Further', 'improvements', 'on', 'this', 'mixture', 'models', 'were', 'achieved', 'using', 'parameter', 'tying', 'to', 'the', 'most-recent', 'context', 'words', '<ref type=""single"">[4].</ref>']",36,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b425429a-debe-4e6b-b9ed-e1e5856718c8,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,['unknown'],['2018'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['Finally,', 'denoting', 'the', 'mask', 'set', 'M', '=', '{m', 'n}', 'N', 'n=1,', 'we', 'have', 'the', 'overall', 'PRA', 'loss', 'function', 'as', 'follows:L', 'PRA', '=', 'E', '(I,D)∼X', 'L', 'PRA', '({α', 'z,n}', '|P|,N', 'z,n=1,', 'M,', 'P,', 'V,', 'W)', '(5)Masked', 'Language', 'Modeling', '(MLM)', 'We', 'take', 'the', 'same', 'masking', 'strategy', '(15%', 'prob.', 'to', 'mask)', 'as', 'in', 'BERT', '<ref type=""single"">(Devlin et al., 2018)</ref>', 'to', 'randomly', 'mask', 'out', 'the', 'input', 'word', 'tokens.', 'Here,', 'MLM', 'aims', 'to', 'predict', 'the', 'original', 'word', 'index', 'in', 'vocabulary', 'space', 'for', 'each', 'masked', 'token', 'based', 'on', 'the', 'whole', 'image', 'and', 'its', 'surrounding', 'language', 'context', 'via', 'the', 'Transformer.', 'Hence', 'a', 'cross-entropy', 'loss', 'is', 'adopted:L', 'MLM', '=', '−E', '(I,D)∼X', 'logP', '(w', 'j', '|V,', 'W', '\\j)', '(6)Image-Text', 'Matching', '(ITM)', 'In', 'ITM,', 'the', 'multilayer', 'Transformer', 'is', 'trained', 'to', 'distinguish', 'whether', 'the', 'input', 'image-text', 'pairs', 'are', 'semantically', 'matched', 'based', 'on', 'the', 'final', 'layer', '[cls]', 'token', 'representation', 'h', 'cls.', 'To', 'construct', 'the', 'training', 'samples,', 'we', 'randomly', 'replace', 'the', 'text', 'for', 'each', 'image-text', 'pair', 'with', 'another', 'text', 'from', 'dataset', 'with', 'a', 'probability', 'of', '0.5.', 'Thus,', 'the', 'output', 'label', 'can', 'be', 'defined', 'as', 'y', '∈', '{0,', '1}', 'where', 'y', '=', '1', 'indicates', 'matched', 'pair.', 'The', 'training', 'objective', 'for', 'the', 'ITM', 'task', 'is', 'to', 'minimize', 'binary', 'cross-entropy', 'loss:L', 'ITM', '=', '−E', '(I,D)∼X', 'logP', '(y|V,', 'W)', '(7)4', 'Experiments']",51,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b8666443-5bac-4f56-aa9a-e89e7e2f0c9d,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['unknown'],['unknown'],['unknown'],single,"['Natural', 'Question', '(NQ)', 'Kwiatkowski', 'et', 'al.', '(2019)', 'introduces', 'a', 'large', 'dataset', 'for', 'open-domain', 'QA.', 'The', 'original', 'dataset', 'contains', 'more', 'than', '300,', '000', 'questions', 'collected', 'from', 'Google', 'search', 'logs.', 'In', '<ref type=""single"">Karpukhin et al. (2020),</ref>', 'around', '62,', '000', 'factoid', 'questions', 'are', 'selected,', 'and', 'all', 'the', 'Wikipedia', 'articles', 'are', 'processed', 'as', 'the', 'collection', 'of', 'passages.', 'There', 'are', 'more', 'than', '21', 'million', 'passages', 'in', 'the', 'corpus.', 'In', 'our', 'experiments,', 'we', 'reuse', 'the', 'version', 'of', 'NQ', 'created', 'by', '<ref type=""single"">Karpukhin et al. (2020).</ref>', 'Note', 'that', 'the', 'dataset', 'used', 'in', 'DPR', 'contains', 'empty', 'negatives,', 'and', 'we', 'discarded', 'the', 'empty', 'ones.']",29,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c31724d2-3dc4-4d08-bef1-722f91d30ac2,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,"['Ethnologue: Languages of the World, twenty-fourth edition']",['2021'],['David Eberhard;Gary Simons;Charles Fennig'],single,"['Pre-trained', 'language', 'models', 'are', 'increasingly', 'applied', 'in', 'ways', 'that', 'are', 'agnostic', 'to', 'targeted', 'downstream', 'tasks', '<ref type=""single"">(Brown et al., 2020).</ref>', 'This', 'usage', 'has', 'led', 'to', 'a', 'proliferation', 'of', 'large', 'language', 'models', 'trained', 'on', 'enormous', 'amounts', 'of', 'data.', 'For', 'example,', 'the', 'recent', 'Megatron-Turing', 'NLG', '530B', 'model', 'was', 'trained', 'on', 'the', 'Pile,', 'which', 'includes', '800GB+', 'of', 'text', '<ref type=""single"">(Gao et al., 2021),</ref>', 'and', 'other', 'large', 'language', 'models', 'utilize', 'large', 'portions', 'of', 'the', '200TB+', 'common', 'crawl', 'data.', '1', 'These', 'large', 'data', 'sets', 'include', 'impressive', 'amounts', 'of', 'text,', 'but', 'all', 'languages', 'are', 'not', 'represented', 'equally', '(or', 'at', 'all)', 'in', 'that', 'text.', 'The', 'reality', 'is', 'that', 'only', 'a', 'negligible', 'fraction', 'of', 'the', '7000+', 'currently', 'spoken', 'languages', '<ref type=""single"">(Eberhard et al., 2021)</ref>', 'have', 'sufficient', 'text', 'corpora', 'to', 'train', 'state-of-theart', 'language', 'models.', 'This', 'data', 'scarcity', 'results', 'in', 'systematic', 'inequalities', 'in', 'the', 'performance', 'of', 'NLP', 'tasks', 'across', 'the', ""world's"", 'languages', '<ref type=""single"">(Blasi et al., 2021).</ref>']",103,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
c498a02a-8fc1-4de9-844d-827648f2d1e8,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Round Up The Usual Suspects: Knowledge-Based Metaphor Generation'],['2016'],['Tony Veale'],single,"['n', 'biased', 'words', 'n', 'words', 'Superlative', 'Prevalence', 'This', 'measure', 'is', 'based', 'on', 'a', 'correlation', 'identified', 'between', '""standout""', 'words', 'to', 'describe', 'a', 'job', 'candidate', 'and', 'research', 'skill', 'when', 'describing', 'that', 'candidate', '<ref type=""single"">(Schmader et al., 2007).</ref>', 'A', 'particular', 'distinction', 'is', 'made', 'between', 'positive', '(standout)', 'superlatives', 'and', 'negative', '(grindstone)', 'superlatives', 'and', 'their', 'differential', 'use', 'to', 'describe', 'men', 'and', 'women.', 'In', 'our', 'experiment,', 'we', 'measure', 'the', 'prevalence', 'of', 'a', 'set', 'of', 'superlatives', 'provided', 'by', '<ref type=""single"">Veale (2016).</ref>', 'The', 'calculation', 'is:', 'Gender-Laden', 'Scoring', 'A', 'previous', 'study', 'provides', 'a', 'list', 'of', '2,311', 'words,', 'based', 'on', 'an', 'analysis', 'of', '32', 'properties', 'related', 'to', 'a', 'set', 'of', 'norms', '<ref type=""single"">(Sap et al., 2017).</ref>', 'In', 'this', 'study,', 'words', 'are', 'scored', 'for', 'their', '""gender-ladenness""', 'and', '""gender', 'replication"".', 'Our', 'study', 'takes', 'a', 'count', 'of', 'the', 'former,', 'measuring', 'their', 'unweighted', 'prevalence', 'to', 'make', 'it', 'comparable', 'to', 'the', 'other', 'bias', 'measures.', 'The', 'calculation', 'is:n', 'biased', 'words', 'n', 'wordsConnotation', 'Frames', 'This', 'measure', 'is', 'based', 'on', 'the', 'concept', 'of', 'power', 'and', 'agency', 'connotation', 'frames', '<ref type=""single"">(Sap et al., 2017).</ref>', 'Power', 'differentials', 'are', 'based', 'on', 'predicates,', 'such', 'as', '""dominates""', 'or', '""honours""', 'which', 'imply', 'a', 'certain', 'power', 'dynamic', 'between', 'the', 'subject', 'and', 'object.', 'Agency', 'is', 'attributed', 'to', 'the', 'agent', 'of', 'the', 'verb.', 'A', 'set', 'of', 'transitive', 'verbs', '(1,700', 'for', 'power', 'differentials', 'and', '2,000', 'for', 'agency)', 'have', 'been', 'annotated', 'in', 'a', 'previous', 'study', 'on', 'modern', 'films', 'and', 'operationalised', 'in', 'our', 'scoring', '<ref type=""single"">(Sap et al., 2017).</ref>', 'For', 'unweighted', 'word', 'counts,', 'we', 'only', 'take', 'into', 'account', 'positive', 'signifiers', 'of', 'power', 'and', 'agency', 'and,', 'given', 'their', 'large', 'overlap', 'of', '64%,', 'combined', 'them', 'into', 'a', 'single', 'word', 'list.', 'The', 'calculation', 'is:']",67,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c59434c1-4177-4d2a-a49a-f7cd67eb63b4,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['Sequence to sequence learning with neural networks'],['2014'],['Ilya Sutskever;Oriol Vinyals;Quoc V Le'],single,"['Lately,', 'many', 'works', 'built', 'upon', 'the', 'Seq2Seq', 'MT', 'model', '<ref type=""single"">(Sutskever et al., 2014)</ref>', 'performed', 'well.', 'First', 'attempted', 'by', '<ref type=""single"">Nisioi et al. (2017),</ref>', 'the', 'Seq2Seq', 'models', 'for', 'this', 'task', 'are', 'able', 'to', 'perform', 'lexical', 'simplification', 'and', 'content', 'reduction', 'simultaneously', 'by', 'training', 'on', 'complex-simple', 'sentence', 'pairs.', 'This', 'method', 'was', 'inherited', 'and', 'improved', 'by', 'many', 'subsequent', 'works,', 'such', 'as', 'combining', 'with', 'the', 'reinforcement', 'learning', 'method', 'by', 'setting', 'a', 'simplification', 'reward', '<ref type=""single"">(Zhang and Lapata, 2017),</ref>', 'augmenting', 'memory', 'capacities', '<ref type=""single"">(Vu et al., 2018)</ref>', 'or', 'training', 'with', 'multitasking', 'on', 'entailment', 'and', 'paraphrase', 'generation', '<ref type=""single"">(Guo et al., 2018).</ref>', '<ref type=""single"">Martin et al. (2019)</ref>', 'proposed', 'to', 'prepend', 'additional', 'prompt', 'tokens', 'to', 'source', 'sentences', 'at', 'train', 'time,', 'which', 'enables', 'the', 'end-users', 'to', 'condition', 'the', 'simplifications', 'returned', 'by', 'the', 'model', 'on', 'attributes', 'like', 'length,', 'lexical', 'complexity,', 'and', 'syntactic', 'complexity.', 'This', 'controllable', 'simplification', 'system', '(called', 'ACCESS)', 'and', 'its', 'improved', 'version', 'MUSS', '<ref type=""single"">(Martin et al., 2020)</ref>', 'achieved', 'SOTA', 'results', 'on', 'the', 'Turk', 'corpus', 'in', 'terms', 'of', 'the', 'SARI', 'metric', '<ref type=""single"">(Xu et al., 2016).</ref>']",9,"[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c6e387bd-8212-45eb-8718-bb45b139473c,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,"['Rethinking action spaces for reinforcement learning in end-to-end dialog agents with latent variable models', 'Mala: Cross-domain dialogue generation with action learning']","['2019', '2020']","['Tiancheng Zhao;Kaige Xie;Maxine Eskenazi', 'Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang']",group,"['Let', '{d', 'i', '|1', '≤', 'i', '≤', 'N}', 'be', 'a', 'set', 'of', 'dialogues,', 'and', 'each', 'dialogue', 'contains', 'n', 'd', 'turns:d', 'i', '=', '{(c', 't,', 'a', 't,', 'x', 't', ')|1', '≤', 't', '≤', 'n', 'd', '},', 'where', 'c', 't', 'is', 'the', 'context', 'at', 'turn', 't,', 'and', 'a', 't', 'is', 'the', 'dialogue', 'action', 'of', 'system', 'utterance', 'x', 't.', 'The', 'context', 'c', 't', '=', '{u', '1,', 'x', '1,', '...,', 'u', 't}', 'consists', 'of', 'the', 'dialogue', 'history', 'of', 'user', 'utterances', 'u', 'and', 'system', 'utterances', 'x.', 'Conditioned', 'response', 'generation', 'tackles', 'the', 'context-to-response', 'generation', 'problem', 'p(x|c)', 'via', 'two', 'consecutive', 'steps:', 'a', 'content', 'planning', 'step', 'decides', 'a', 'dialogue', 'action', 'to', 'proceed', 'the', 'dialogues', 'p', 'l', '(a|c),', 'and', 'a', 'surface', 'realization', 'step', 'further', 'trans-forms', 'the', 'decided', 'action', 'into', 'naturally', 'sound', 'utterances', 'p', 'r', '(x|a,', 'c).', 'Using', 'the', 'two-step', 'process,', 'response', 'generation', 'could', 'be', 'optimized', 'towards', 'better', 'task', 'completion', 'while', 'maintaining', 'high-quality', 'language', 'quality', '<ref type=""group"">(Huang et al., 2020a, Zhao et al., 2019).</ref>', 'The', 'optimization', 'process', 'also', 'consists', 'of', 'two', 'parts.', 'Firstly,', 'context-action', 'pairs', 'are', 'used', 'to', 'train', 'the', 'content', 'planning', 'model', 'p', 'l', '(a|c)', 'using', 'the', 'cross-entropy', 'loss.L', 'act', '=', 'd', 'i', 't=1:n', 'd', '−', 'log(a', 't', 'p', 'l', '(a|c', 't', '))', '(1)Then,', 'the', 'surface', 'realization', 'model', 'p', 'r', '(x|a,', 'c)', 'is', 'optimized', 'from', 'the', '(c', 't,', 'a', 't,', 'x', 't)', 'triples', 'to', 'maximize', 'the', 'likelihood', 'of', 'ground-truth', 'responses']",145,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c89d4888-3f9f-4a14-99cb-85aba4cfd78a,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Evaluating scoped meaning representations'],['2018'],['Rik Van Noord;Lasha Abzianidze;Hessel Haagsma;Johan Bos'],single,"['BERT', 'has', '12', 'layers,', 'each', 'of', 'which', 'has', 'a', '768-dimensional', 'output', 'embedding', 'per', 'wordpiece.', 'There', 'is', 'some', 'mixed', 'information', 'in', 'the', 'literature', 'as', 'to', 'which', ""layer's"", 'output', 'is', 'most', 'suitable', 'for', 'seman-', 'Evaluation', 'We', 'evaluate', 'the', 'performance', 'of', 'our', 'parser', 'using', 'Counter', '<ref type=""single"">(van Noord et al., 2018a),</ref>', 'an', 'extension', 'of', 'the', 'Smatch', 'evaluation', 'metric', '<ref type=""single"">(Cai and Knight, 2013).</ref>', 'Counter', 'approximates', 'an', 'optimal', 'mapping', 'between', 'the', 'referents', 'in', 'the', 'gold', 'DRS', 'and', 'the', 'predicted', 'DRS', 'using', 'hill-climbing,', 'then', 'outputs', 'recall,', 'precision,', 'and', 'f-score', 'for', 'the', 'predicted', 'clauses', 'compared', 'to', 'the', 'gold', 'clauses.']",42,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
cac87218-24d4-4168-b206-ed770d23337d,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Playing codenames with language graphs and word embeddings'],['2021'],['Divya Koyyalagunta;Anna Sun;Rachel Draelos;Cynthia Rudin'],single,"['We', 'randomly', 'create', '100', 'boards,', 'with', 'each', 'containing', '10', 'good', 'and', '10', 'bad', 'words.', 'For', 'each', 'board,', 'we', 'generate', 'clues', 'with', 'the', '32', 'configurations', 'detailed', 'above.', 'This', 'results', 'in', '1304', 'distinct', 'clues', 'in', 'English,', 'and', '1399', 'in', 'Hungarian.', 'For', 'evaluation,', 'we', 'create', 'an', 'online', 'game,', 'where', 'human', 'players', 'get', 'a', 'board', 'with', 'one', 'of', 'the', 'corresponding', 'clues', 'randomly,', 'and', 'have', 'to', 'choose', 'the', 'given', 'number', 'of', 'words', 'from', 'the', 'board', 'which', 'they', 'think', 'the', 'clue', 'refers', 'to.', 'The', 'players', 'do', 'not', 'know', 'how', 'the', 'agents', 'work,', 'and', 'to', 'avoid', 'that', 'through', 'the', 'game', 'they', 'learn', 'it', 'at', 'the', 'end', 'of', 'the', 'round', 'they', 'only', 'see', 'the', 'color', 'of', 'their', 'chosen', 'words.', 'We', 'collected', '443', 'rounds', 'played', 'in', 'English,', 'and', '1365', 'in', 'Hungarian.', 'This', 'way,', 'we', 'have', '31.5', 'rounds', 'on', 'average', 'to', 'evaluate', 'English', 'configurations,', 'and', '64', 'rounds', 'for', 'Hungarian.', 'For', 'one', 'board,', 'players', 'on', 'average', 'spent', '39', 'seconds', 'on', 'guessing', 'in', 'English,', 'while', '37', 'seconds', 'in', 'Hungarian.', 'We', 'note', 'that', 'the', 'players', 'of', 'the', 'Hungarian', 'game', 'were', 'most', 'likely', 'Hungarian', 'native', 'speakers,', 'while', 'the', 'same', 'cannot', 'be', 'said', 'about', 'the', 'English', 'game,', 'therefore', 'we', 'consider', 'the', 'Hungarian', 'data', 'more', 'reliable.', 'Similar', 'to', '<ref type=""single"">Koyyalagunta et al. (2021),</ref>', 'we', 'compute', 'the', 'precision', 'of', 'the', 'agents', 'asP@targets', '=', '|I', 'n', '∩', 'U', '|', 'n', ',where', 'I', 'n', 'is', 'the', 'set', 'of', 'the', 'targeted', 'words,', 'and', 'U', 'is', 'the', 'set', 'of', 'words', 'chosen', 'by', 'the', 'players.', 'However,', 'the', 'scoring', 'functions', 'optimize', 'clue', 'words', 'to', 'stay', 'away', 'from', 'red', 'words,', 'but', 'not', 'from', 'non-targeted', 'blue', 'words,', 'which', 'might', 'be', 'almost', 'as', 'related', 'to', 'the', 'clue', 'as', 'the', 'targeted', 'ones.', 'If', 'the', 'user', 'chooses', 'such', 'an', 'untargeted', 'word,', 'the', 'agent', 'still', 'performs', 'well.', 'So', 'we', 'define', 'P@all,P@all', '=', '|A', '∩', 'U', '|', 'n', ',where', 'A', 'is', 'the', 'set', 'of', 'all', 'good', '(blue)', 'words.', 'In', 'Table', '3', 'and', 'Table', '4,', 'we', 'show', 'the', 'mean', 'precision', 'of', 'the', ""players'"", 'guesses', 'on', 'the', 'clues', 'of', 'each', 'agent.']",192,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cb8646a2-174e-4e9d-bab5-ac7cda05c591,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['unknown'],['unknown'],['unknown'],single,"['Contrast', 'set:', 'the', 'evaluation', 'set', 'by', '<ref type=""single"">Gardner et al. (2020)</ref>', 'that', 'is', 'created', 'based', 'on', 'the', 'official', 'Quoref', 'test', 'set.', 'For', 'creating', 'this', 'evaluation', 'set,', 'the', 'authors', 'manually', 'performed', 'small', 'but', 'meaningful', 'perturbations', 'to', 'the', 'test', 'examples', 'in', 'a', 'way', 'that', 'it', 'changes', 'the', 'gold', 'label.', 'This', 'dataset', 'is', 'constructed', 'to', 'evaluate', 'whether', 'models', 'decision', 'boundaries', 'align', 'to', 'true', 'decision', 'boundaries', 'when', 'they', 'are', 'measured', 'around', 'the', 'same', 'point.']",6,"[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
ccd79bd6-f7b3-45c8-9524-bcbec77c7e09,Can Semantic Role Labeling Improve SMT?,2009,Dekai Wu;Pascale Fung,['Shallow semantic parsing of chinese'],['2004'],['Honglin Sun;Daniel Jurafsky'],single,"['Systems', 'that', 'perform', 'shallow', 'semantic', 'parsing', 'on', 'Chinese', 'texts', 'are', 'likewise', 'based', 'on', 'classifiers', 'and', 'trained', 'on', 'the', 'Chinese', 'PropBank', 'and', 'the', 'bilingual', 'Chinese-English', 'Parallel', 'PropBank', '<ref type=""single"">(Sun and Jurafsky (2004),</ref>', '<ref type=""single"">Xue (2006),</ref>', '<ref type=""single"">Fung et al. (2006)</ref>', ').', 'It', 'is', 'interesting', 'to', 'note', 'that,', 'despite', 'the', 'very', 'different', 'characteristics', 'of', 'Chinese', 'verbs', '<ref type=""single"">(Xue and Palmer, 2005)</ref>', 'from', 'those', 'in', 'English,', 'the', 'core', 'algorithm', 'of', 'a', 'shallow', 'semantic', 'parser', 'remains', 'the', 'same.', 'As', 'was', 'found', 'to', 'be', 'the', 'case', 'in', 'English,', 'SVM', 'classifiers', 'have', 'been', 'found', 'to', 'outperform', 'maximum', 'entropy', 'classifiers', 'for', 'this', 'task', '<ref type=""single"">(Fung et al., 2006).</ref>', 'The', 'primary', 'difference', 'lies', 'in', 'the', 'feature', 'set', 'chosen', 'to', 'represent', 'semantic', 'information.']",26,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cd29c8d8-9bd1-4ca2-b9c1-66ae748afa0b,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,"['STFU NOOB! Predicting crowdsourced decisions on toxic behavior in online games', 'Relating conversational topics and toxic behavior effects in a moba game']","['2014', '2018']","['Jeremy Blackburn;Haewoon Kwak', 'Joaquim Alvino De Mesquita Neto;Karin Becker']",group,"['Toxicity', 'Datasets', 'in', 'Online', 'Games', 'In', 'multiplayer', 'online', 'games,', 'prior', 'research', 'focused', 'on', 'analysis', 'of', 'anti-social', 'or', 'disruptive', 'behavior,', 'socalled', 'toxic', 'behavior', '<ref type=""group"">(Blackburn and Kwak, 2014, de Mesquita Neto and Becker, 2018)</ref>', 'including', 'cyberbullying', '<ref type=""single"">(Kwak et al., 2015)</ref>', 'and', 'griefing', '<ref type=""single"">(Murnion et al., 2018).</ref>', 'Although', 'these', 'terms', 'contain', 'similar', 'elements,', 'a', 'single', 'definition', 'of', 'toxic', 'behavior', 'is', 'yet', 'to', 'emerge.', 'Some', 'studies', 'have', 'conducted', 'data', 'annotation', 'using', 'pre-defined', 'lexicon', 'categories', '<ref type=""single"">(Märtens et al., 2015)</ref>', 'or', 'toxic', 'player', 'information', '<ref type=""single"">(Stoop et al., 2019).</ref>', 'These', 'annotation', 'methods', 'are', 'not', 'robust', 'enough', 'to', 'handle', 'unlabelled', 'toxicity', 'words', 'or', 'unreported', 'toxic', 'players.']",22,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cde5ca45-b309-4a6e-836e-1f77ce208959,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['Do sequence-tosequence VAEs learn global features of sentences?'],['2020'],['Tom Bosc;Pascal Vincent'],single,"['A', 'confounding', 'factor', 'which', 'could', 'pollute', 'this', 'analysis', 'is', 'the', 'role', 'of', 'strong', 'auto-regressive', 'decoding', 'of', 'VAEs', 'and', 'the', 'type', 'of', 'information', 'captured', 'by', 'the', 'decoder', 'in', 'such', 'scenario.', 'While', 'a', 'preliminary', 'analysis', 'has', 'been', 'provided', 'recently', '<ref type=""single"">(Bosc and Vincent, 2020),</ref>', 'this', 'has', 'been', 'vastly', 'underexplored', 'and', 'requires', 'more', 'explicit', 'attempts.', 'We', 'leave', 'deeper', 'investigation', 'of', 'this', 'to', 'future', 'work.']",37,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cfb94a5b-e884-4d58-b31d-60d4603fbc8d,Controlled Text Generation with Adversarial Learning,2020,Federico Betti;Giorgia Ramponi;Massimo Piccardi,['Categorical reparameterization with gumbel-softmax'],['2016'],['Eric Jang;Shixiang Gu;Ben Poole'],single,"['The', 'distribution', 'over', 'the', 'vocabulary', 'of', 'the', 'next', 'word', 'is', 'evaluated', 'using', 'the', 'memory', 'output', 'o', 't', 'as', 'in', 'Eq.', '3', 'with', 'a', 'feed-forward', 'layer.', 'Then,', 'the', 'next', 'soft', 'word,', 'ŷt,', 'is', 'sampled', 'using', 'the', 'Gumbelsoftmax', 'relaxation', '<ref type=""single"">[11]</ref>', 'with', 'temperature', 'T', '(Eq.', '4).', 'The', 'temperature', 'value', 'greatly', 'influences', 'the', 'quality-diversity', 'trade-off,', 'more', 'details', 'on', 'these', 'parameters', 'are', 'provided', 'in', 'Appendix', 'D.']",37,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
d036cda3-119f-468c-b5c9-a877833cebba,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['CCG augmented hierarchical phrase-based machine translation'],['2010'],['H Almaghout;J Jiang;A Way'],single,"['Following', 'the', 'SAMT', 'approach,', 'CCG-augmented', 'HPB', 'SMT', '<ref type=""single"">[12]</ref>', 'uses', 'CCG', '<ref type=""single"">[5]</ref>', 'to', 'label', 'non-terminals.', 'CCG', 'has', 'distinct', 'advantages', 'over', 'phrase-structure', 'grammar', 'in', 'the', 'general', 'SMT', 'context,', 'particularly', 'in', 'extracting', 'non-terminal', 'labels', 'in', 'HPB', 'SMT.', 'This', 'section', 'gives', 'a', 'brief', 'introduction', 'to', 'CCG', 'followed', 'by', 'a', 'description', 'of', 'the', 'approach', 'of', 'extracting', 'non-terminal', 'labels', 'using', 'the', 'same.']",7,"[2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d81bb000-e526-40aa-a6a0-4eea1fbd01a3,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,['Document vector representations for feature extraction in multistage document ranking'],['2013'],['Nima Asadi;Jimmy Lin'],single,"['Table', '3', 'shows', 'the', 'query', 'latency', 'breakdown', 'for', 'a', 'few', 'representative', 'models.', 'Note', 'that', 'latency', 'is', 'dominated', 'by', 'final-stage', 'neural', 'reranking', 'latency,', 'which', 'scales', 'linearly,', 'so', 'smaller', 'N', 'values', '(in', 'Table', '2)', 'are', 'more', 'desirable.', 'However,', 'this', 'is', 'balanced', 'by', 'the', 'introduction', 'of', 'LTR', 'overhead,', 'both', 'feature', 'extraction', 'as', 'well', 'as', 'the', 'prediction', 'latency', 'itself.', 'Nevertheless,', 'this', 'is', 'a', 'worthwhile', 'tradeoff', 'as', 'we', 'observe', 'large', 'speedups', 'overall.', 'Since', 'T5-base', 'is', 'faster', 'than', 'BERT-large,', 'the', 'effect', 'of', 'the', 'LTR', 'overhead', 'is', 'relatively', 'larger', 'and', 'thus', 'the', 'speedup', 'is', 'lower.', 'We', 'can', 'see', 'that', 'increasing', 'the', 'initial', 'k', '0', 'for', 'BoW', 'from', '1k', 'to', '10k', 'is', 'acceptable', 'as', 'LTR', 'overhead', 'remains', 'modest.', 'dex', 'for', 'each', 'document', 'is', 'the', 'most', 'expensive', 'single', 'step.', 'Our', 'experiments', 'show', 'that', 'the', 'number', 'of', 'features', 'does', 'not', 'affect', 'latency', 'substantially', 'because', 'we', 'only', 'need', 'to', 'load', 'the', 'document', 'once,', 'once', 'in', 'cache,', 'individual', 'feature', 'extraction', 'is', 'very', 'fast.', 'Note', 'that', 'we', 'have', 'not', 'spent', 'much', 'effort', 'optimizing', 'feature', 'extraction', '(which', 'is', 'relatively', 'inefficient', 'Java', 'code)', 'and', 'that', 'more', 'engineering', 'effort,', 'for', 'example,', 'optimizations', 'proposed', 'by', '<ref type=""single"">Asadi and Lin (2013),</ref>', 'are', 'likely', 'to', 'further', 'increase', 'speedups.']",178,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2]"
d92d28e8-1c99-4afc-9927-7dd0f928db1e,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Minimum error rate training in statistical machine translation'],['2003'],['F Och'],single,"['where,', 'h', 'i', '(f,', 'e)', 'denotes', 'the', 'different', 'components', 'for', 'translating', 'the', 'source', 'sentence', 'f', 'into', 'the', 'target', 'sentence', 'e.', 'K', 'is', 'the', 'number', 'of', 'components', '(or', 'features)', 'used', 'and', 'λ', 'i', 'are', 'the', 'corresponding', 'weights', 'of', 'the', 'components.', 'The', 'Moses', 'SMT', 'system', '<ref type=""single"">[6],</ref>', 'which', 'implements', 'this', 'particular', 'model,', 'was', 'used', 'for', 'all', 'our', 'PBSMT', 'translation', 'experiments.', 'Different', 'component', 'weights', '(λ', 'i)', 'were', 'estimated', 'using', 'a', 'discriminative', 'training', 'method', 'known', 'as', 'Minimum', 'Error', 'Rate', 'Training', '(MERT)', '<ref type=""single"">[7],</ref>', 'on', 'a', 'held', 'out', 'development', 'set', '(devset).']",76,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]"
dcb05e48-437b-4766-a9da-016242fbd9a7,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,"['Abusive language detection in online user content', 'Large scale crowdsourcing and characterization of twitter abusive behavior']","['2016', '2018']","['Chikashi Nobata;Joel Tetreault;Achint Thomas;Yashar Mehdad;Yi Chang', 'Antigoni Founta;Constantinos Djouvas;Despoina Chatzakou;Ilias Leontiadis;Jeremy Blackburn;Gianluca Stringhini;Athena Vakali']",group,"['Toxicity', 'Datasets', 'in', 'Online', 'Community', 'An', 'extensive', 'body', 'of', 'work', 'has', 'focused', 'on', 'datasets', 'to', 'detect', 'toxicity', 'including', 'hate', 'speech', '<ref type=""group"">(Waseem and Hovy, 2016, Davidson et al., 2017, ElSherief et al., 2018)</ref>', 'and', 'abusive', 'language', '<ref type=""group"">(Nobata et al., 2016, Founta et al., 2018).</ref>', 'However,', 'the', 'majority', 'of', 'toxicity', 'datasets', 'do', 'not', 'consider', 'the', 'context', 'of', 'a', 'conversation,', 'instead', 'simply', 'analysing', 'a', 'single', 'utterance.', 'Even', 'if', 'a', 'model', 'uses', 'contextual', 'information', '<ref type=""single"">(Gao and Huang, 2017),</ref>', 'it', 'is', 'limited', 'to', 'metainformation', '(e.g.', 'news', 'title', 'or', 'user', 'name)', 'which', 'is', 'not', 'sufficient', 'to', 'understand', 'a', 'conversation.', 'In', 'our', 'research,', 'context', 'is', 'defined', 'as', 'linguistic', 'contextual', 'information,', 'particularly', 'previous', 'single', 'or', 'multiple', 'utterances.', 'Along', 'similar', 'lines,', 'recent', 'studies', 'have', 'focused', 'on', 'conversation', 'aiming', 'to', 'discover', 'warning', 'signals', '<ref type=""single"">(Zhang et al., 2018),</ref>', 'to', 'generate', 'intervention', 'responses', '<ref type=""single"">(Qian et al., 2019),</ref>', 'or', 'to', 'measure', 'the', 'importance', 'of', 'context', '<ref type=""single"">(Pavlopoulos et al., 2020).</ref>', 'Existing', 'toxicity', 'datasets', 'mainly', 'focus', 'on', 'annotating', 'at', 'utterance-level,', 'whereas', 'ours', 'conducts', 'a', 'dual-level', 'annotation', 'at', 'utterance', 'and', 'token-level,', 'while', 'also', 'providing', 'a', 'conversation', 'history', '(see', 'Table', '1).', 'These', 'extra', 'features', 'are', 'what', 'distinguish', 'CONDA.']",24,"[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e1dde46b-be53-4789-afd6-00dfff219692,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,"['Understanding abuse: A typology of abusive language detection subtasks', 'Hateful symbols or hateful people? predictive features for hate speech detection on Twitter', 'A lexicon-based approach for hate speech detection', 'A survey on hate speech detection using natural language processing']","['2017', '2016', '2015', '2017']","['Zeerak Waseem;Thomas Davidson;Dana Warmsley;Ingmar Weber', 'Zeerak Waseem;Dirk Hovy', 'Njagi Dennis Gitari;Zhang Zuping;Hanyurwimfura Damien;Jun Long', 'Anna Schmidt;Michael Wiegand']",group,"['Most', 'of', 'the', 'works', 'that', 'study', 'this', 'task', 'commonly', 'point', 'first', 'to', 'surface-level', 'features,', 'such', 'as', 'bag', 'of', 'words', 'and', 'lexicon-based', 'approaches,', 'with', 'negative', 'words', 'as', 'features', '<ref type=""group"">(Gitari et al., 2015, Waseem and Hovy, 2016, Waseem et al., 2017, Schmidt and Wiegand, 2017).</ref>']",27,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]"
e2055f77-5542-4603-b5fe-f8349c3fd893,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,['Fabulous: Fact-checking based on understanding of language over unstructured and structured information'],['2021'],['Mostafa Bouziane;Hugo Perrin;Amine Sadeq;Thanh Nguyen;Aurélien Cluzeau;Julien Mardas'],single,"['Previous', 'works', 'on', 'FEVEROUS', 'generally', 'convert', 'all', 'evidence', 'pieces', 'into', 'either', 'plain', 'text', '<ref type=""group"">(Aly et al., 2021, Saeed et al., 2021, Malon, 2021)</ref>', 'or', 'several', 'tables', '<ref type=""single"">(Bouziane et al., 2021).</ref>', 'However,', 'format', 'conversions', 'inevitably', 'lose', 'rich', 'context', 'information', 'for', 'the', 'converted', 'evidence,', 'thus', 'may', 'mislead', 'the', 'subsequent', 'encoding', 'and', 'interaction', 'steps.', 'For', 'example,', 'in', 'Figure', '1,', 'the', 'entire', 'top', 'two', 'rows', 'are', 'indispensable', 'to', 'understand', 'the', 'table', 'cell', 'Won.', 'It', 'is', 'difficult', 'to', 'identify', 'all', 'related', 'context', 'cells', 'and', 'design', 'a', 'general', 'conversion', 'method', 'to', 'render', 'them', 'into', 'sentences,', 'but', 'these', 'connections', 'can', 'be', 'easily', 'caught', 'by', 'pre-trained', 'table', 'models', '<ref type=""group"">(Herzig et al., 2020, Yin et al., 2020).</ref>', 'On', 'the', 'other', 'side,', 'identifying/re-organizing', 'crucial', 'elements', 'in', 'a', 'sentence', 'to', 'construct', 'a', 'table', 'is', 'also', 'challenging.', 'Simply', 'inserting', 'a', 'whole', 'sentence', 'in', 'a', 'table', 'cell', '<ref type=""single"">(Bouziane et al., 2021)</ref>', 'will', 'make', 'the', 'new', 'cells', 'much', 'larger', '(and', 'unique)', 'than', 'normal', 'ones,', 'thus', 'can', 'not', 'make', 'the', 'most', 'of', 'general', 'pre-trained', 'table', 'models', '<ref type=""group"">(Herzig et al., 2020, Yin et al., 2020)</ref>', 'as', 'we', 'expect.']",17,"[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 0, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
e2e03983-c35f-4895-9198-86e973a3cca5,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Learning to deceive with attention-based explanations'],['2020'],['Danish Pruthi;Mansi Gupta;Bhuwan Dhingra;Graham Neubig;Zachary Lipton'],single,"['Pruthi', 'et', 'al.', '(2020)', 'derived', 'an', 'occupation', 'dataset', 'to', 'study', 'the', 'gender', 'bias', 'in', 'NLP', 'classification', 'tasks.', 'The', 'task', 'is', 'framed', 'as', 'a', 'binary', 'classification', 'task', 'to', 'distinguish', 'between', '""surgeons""', 'and', '""physicians"".', 'These', 'two', 'occupations', 'are', 'chosen', 'because', 'they', 'share', 'similar', 'words', 'in', 'their', 'biographies', 'and', 'a', 'majority', 'of', 'surgeons', 'are', 'male.', 'The', 'dataset', 'is', 'further', 'tuned', '-downsample', 'minority', 'classes', '(female', 'surgeons', 'and', 'male', 'physicians)', 'by', 'a', 'factor', 'of', 'ten', 'to', 'encourage', 'the', 'model', 'to', 'rely', 'on', 'gendered', 'words', 'to', 'make', 'predictions.', '<ref type=""single"">Pruthi et al. (2020)</ref>', 'also', 'provides', 'a', 'pre-specified', 'list', 'of', 'impermissible', 'tokens', '8', 'that', 'a', 'robust', 'model', 'should', 'assign', 'low', 'attention', 'scores', 'to.', 'We', 'instead', 'treat', 'this', 'list', 'of', 'tokens', 'as', 'shortcuts', 'and', 'analyze', 'the', 'efficacy', 'of', 'our', 'proposed', 'framework', 'on', 'identifying', 'these', 'tokens.', 'These', 'impermissible', 'tokens', 'can', 'be', 'regarded', 'as', 'shortcuts', 'because', 'they', 'only', 'reflect', 'the', 'gender', 'of', 'the', 'person,', 'thus', 'by', 'definition', 'should', 'not', 'affect', 'the', 'decision', 'of', 'a', 'occupation', 'classification', 'model.', 'Table', '6', 'presents', 'the', 'result', 'on', 'identifying', 'the', 'list', 'of', 'impermissible', 'tokens.', 'Among', 'the', 'top', 'ten', 'tokens', 'selected', 'by', 'our', 'method,', '6', 'of', 'them', 'are', 'shortcuts.', 'Furthermore,', '9', 'out', 'of', '12', 'impermissible', 'tokens', 'are', 'captured', 'in', 'the', 'top', '50', 'tokens', 'selected', 'by', 'our', 'method.', 'This', 'further', 'demonstrates', 'that', 'our', 'method', 'can', 'effectively', 'find', 'shortcuts', 'in', 'this', 'occupation', 'classification', 'task,', 'in', 'a', 'more', 'automated', 'way', 'compared', 'to', 'existing', 'approaches', 'that', 'rely', 'on', 'pre-defined', 'lists.']",82,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e64b92f3-af62-4ec1-a9f1-e03ce08fb7fd,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['REALM: retrievalaugmented language model pre-training'],['2002'],['Kelvin Guu;Kenton Lee;Zora Tung;Panupong Pasupat;Ming-Wei Chang'],single,"['Previous', 'experiments', 'have', 'shown', 'the', 'effectiveness', 'of', 'RocketQA', 'on', 'passage', 'retrieval.', 'Next,', 'we', 'verify', 'whether', 'the', 'retrieval', 'results', 'of', 'RocketQA', 'can', 'improve', 'the', 'performance', 'of', 'passage', 'reading', 'for', 'extracting', 'correct', 'answers.', 'We', 'implement', 'an', 'end-to-end', 'QA', 'system', 'in', 'which', 'we', 'have', 'an', 'extractive', 'reader', 'stacked', 'on', 'our', 'RocketQA', 'retriever.', 'For', 'a', 'fair', 'comparison,', 'we', 'first', 're-use', 'the', 'released', 'model', '6', 'of', 'the', 'extractive', 'reader', 'in', 'DPR', '<ref type=""single"">(Karpukhin et al., 2020),</ref>', 'and', 'take', '100', 'retrieved', 'passages', 'during', 'inference', '(the', 'same', 'setting', 'used', 'in', 'DPR).', 'Besides,', '6', 'https://github.com/facebookresearch/', 'DPR', 'Model', 'EM', 'BM25+BERT', '<ref type=""single"">(Lee et al., 2019)</ref>', '26.5', 'HardEM', '<ref type=""single"">(Min et al., 2019a)</ref>', '28.1', 'GraphRetriever', '<ref type=""single"">(Min et al., 2019b) 34.5</ref>', 'PathRetriever', '<ref type=""single"">(Asai et al., 2020)</ref>', '32.6', 'ORQA', '<ref type=""single"">(Lee et al., 2019)</ref>', '33.3', 'REALM', '<ref type=""single"">(Guu et al., 2020)</ref>', '40.4', 'DPR', '<ref type=""single"">(Karpukhin et al., 2020)</ref>', '41.5', 'GAR', '<ref type=""single"">(Mao et al., 2020)</ref>', '41.6', 'RocketQA', '+', 'DPR', 'reader', '42.0', 'RocketQA', '+', 're-trained', 'DPR', 'reader', '42.8']",101,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
e6e3f8ad-213a-4c65-8e5e-fee6618be60a,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,"['Word association norms, mutual information, and lexicography']",['1990'],['Kenneth Church;Patrick Hanks'],single,"['We', 'achieved', 'the', 'best', 'result', 'with', 'the', 'Gradient', 'Boosting', 'classifier', '5', 'using', 'only', '10%', 'of', 'the', 'prelabeled', 'nodes', 'i.e.,', 'the', 'classification', 'does', 'not', 'improve', 'after', 'this', 'percentage.', 'Table', '3', 'Besides', 'our', 'approach,', 'we', 'evaluated', 'other', 'graph', 'models', 'of', 'different', 'structures.', 'First,', 'we', 'used', 'the', 'network', 'graph', 'developed', 'by', '<ref type=""single"">Anchiêta et al. (2020).</ref>', 'That', 'graph', 'does', 'not', 'use', 'weight', 'between', 'the', 'nodes.', 'Second,', 'we', 'used', 'the', 'Term', 'Frequency-Inverse', 'Document', 'Frequency', '(TF-IDF)', 'as', 'weight', 'instead', 'of', 'the', 'average', 'of', 'embeddings.', 'Third,', 'we', 'used', 'bigrams', 'and', 'trigrams', 'as', 'nodes', 'rather', 'than', 'token', 'nodes.', 'Finally,', 'we', 'used', 'the', 'Pointwise', 'Mutual', 'Information', '(PMI)', 'measure', '<ref type=""single"">(Church and Hanks, 1990)</ref>', 'as', 'the', 'weight', 'between', 'the', 'bi', 'and', 'trigrams', 'nodes.', 'For', 'these', 'approaches,', 'we', 'adopted', 'the', 'same', 'regularization', 'algorithm,', 'ranging', 'the', 'pre-labeled', 'nodes', 'from', '5%', 'to', '30%.', 'In', 'Table', '4,', 'we', 'present', 'the', 'bestachieved', 'results.', 'From', 'this', 'table,', 'our', 'graph', 'modeling', 'and', 'the', 'gradient', 'boosting', 'classifier', 'achieved', 'better', 'results', 'than', 'these', 'other', 'graphs,', 'as', 'well', 'as', 'classifier', 'variations.', 'This,', 'we', 'think,', 'is', 'because', 'of', 'the', 'embedding', 'value', 'among', 'the', 'graph', 'nodes', 'since', 'it', 'is', 'able', 'to', 'capture', 'morphological,', 'syntactic,', 'and', 'semantic', 'knowledge', 'of', 'a', 'word.', 'As', 'we', 'used', 'the', 'average', 'word', 'embedding', 'value,', 'it', 'includes', 'information', 'from', 'all', 'of', 'the', 'individual', 'vector', 'values,', 'working', 'as', 'an', 'overall', 'summary', 'of', 'all', 'vector', 'values.']",96,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e7bf43a4-01bd-4918-89b7-279ee02a9b0d,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Rethinking the inception architecture for computer vision'],['2016'],['C Szegedy;V Vanhoucke;S Ioffe;J Shlens;Z Wojna'],single,"['Caption', 'Decoder', 'Caption', 'decoder', 'combines', 'vision', 'and', 'trace', 'information', 'using', 'cross', 'attention', 'connected', 'to', 'the', 'hidden', 'states', 'of', 'Vision-Trace', ""Encoder's"", 'last', 'layer.', 'Using', 'a', 'casual', 'mask', 'to', 'encode', 'generated', 'token', 'progressively,', 'the', 'transformer', 'decoder', 'ensures', 'that', 'the', 'predictions', 'for', 'position', 'i', 'can', 'depend', 'only', 'on', 'the', 'known', 'outputs', 'at', 'positions', 'less', 'than', 'i.', 'During', 'training,', 'the', 'ground', 'truth', 'caption', 'tokens', 'are', 'shifted', 'right,', 'and', 'a', 'special', 'token', 'BOS', '(begin', 'of', 'the', 'sentence)', 'is', 'inserted', 'into', 'the', 'first', 'position.', 'A', 'cross-entropy', 'generation', 'loss', 'L', 'gen', 'is', 'then', 'computed', 'with', 'the', 'logits', 'transformed', 'from', 'the', 'last', 'decoder', ""layer's"", 'hidden', 'states', 'and', 'un-shifted', 'ground', 'truth', 'caption', 'token', 'ids', 'with', 'a', 'special', 'token', 'EOS', '(end', 'of', 'the', 'sentence)', 'appended.L', 'gen', '=', '−', 'E', 'ŷi', '∼ŷ', 'log', 'p', 'ŷi', '|', 'ŷ&lt,i,', 'T,', 'Ṽ,', 'θ.', '(3)It', 'is', 'noted', 'that', 'ŷ', 'is', 'the', 'masked', 'version', 'of', 'the', 'ground-truth', 'caption', 'y.', 'To', 'make', 'a', 'fair', 'comparison', 'with', 'the', 'baseline', '(Pont-Tuset', 'et', 'al.,', '2020),', 'we', 'apply', 'the', 'same', 'setting', 'and', 'do', 'not', 'employ', 'common', 'techniques', 'such', 'as', 'label', 'smoothing', '<ref type=""single"">(Szegedy et al., 2016)</ref>', 'or', 'self-critical', 'training', '<ref type=""single"">(Rennie et al., 2017).</ref>']",170,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3]"
e9e03e53-206d-40bd-b689-3bcd548d5168,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,['An Introduction to Machine Translation'],['1992'],['W Hutchins;H Somers'],single,"['The', 'second', 'problem', 'of', 'coverage', 'can', 'be', 'paraphrased', 'as', '""Are', 'there', 'any', 'examples', 'in', 'the', 'database', 'which', 'match', 'this', 'input', 'at', 'all?"",', 'and', 'is', 'the', 'basic', 'problem', 'with', 'EBMT', 'in', 'that,', 'in', 'the', 'extreme,', 'EBMT', 'ignores', 'the', 'relevance', 'of', 'linguistic', 'generalities.', 'It', 'can', 'be', 'overcome', 'by', 'making', 'the', 'source', 'text', 'and', 'target', 'text', 'composition', 'process', ""'recombinant'"", '<ref type=""group"">([18, 37]</ref>', ').', 'This', 'recombination', 'of', 'partially', 'matching', 'examples', 'is', 'significantly', 'different', 'from', 'the', 'corresponding', 'technique', 'of', 'target', 'text', 'generation', 'in', 'standard', 'MT', 'systems,', 'which', 'is', 'essentially', 'rule-driven', ""'direct"", ""replacement'"", '(cf.', '<ref type=""single"">[27],</ref>', 'pp.', '200f)', 'of', 'an', 'abstract', 'representation', 'with', 'the', 'corresponding', 'text,', 'based', 'on', 'pre-determined', 'choices', '(cf.', '<ref type=""single"">[15],</ref>', 'pp.137f).', 'In', 'recombination', 'of', 'examples,', 'it', 'is', 'necessary', 'to', 'locate', 'the', 'partially', 'matched', 'examples', 'in', 'a', 'broader', 'rhetorical', 'structure:', 'in', 'order', 'to', 'accomplish', 'this', 'the', 'representations', 'and', 'the', 'contextual', 'relation', 'definitions', 'of', 'the', 'examples,', 'and', 'the', 'global', 'intentional', 'model', 'all', 'play', 'their', 'part.', 'It', 'is', 'important', 'to', 'ascertain', 'the', 'grammatical,', 'pragmatic', 'and', 'stylistic', 'legality', 'of', 'recombining', 'examples', 'and', 'to', 'maintain', 'textual', 'cohesion.', 'In', 'some', '(extreme)', 'cases,', 'the', 'system', 'may', 'require', 'the', 'user', 'to', 'rephrase', 'the', 'input', 'so', 'as', 'to', 'match', 'more', 'closely', 'the', 'expected', 'input.']",102,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
edf245db-d026-4dfc-b6d0-32acdb95c8a8,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,['A joint model of intent determination and slot filling for spoken language understanding'],['2016'],['Xiaodong Zhang;Houfeng Wang'],single,"['In-game', 'chat', 'has', 'similar', 'characteristics', 'to', 'multi-turn', 'dialogue', 'in', 'NLU.', 'The', 'approaches', 'used', 'in', 'multi-turn', 'dialogue', 'analysis', 'have', 'not', 'yet', 'been', 'observed', 'in', 'toxicity', 'datasets.', 'In', 'NLU,', 'generally,', 'intent', 'classification', '(IC)', 'is', 'treated', 'as', 'a', 'semantic', 'utterance', 'classification', 'task', 'and', 'slot', 'filling', '(SF)', 'is', 'treated', 'as', 'a', 'sequential', 'token', 'labelling', 'task', '<ref type=""single"">(Zhang and Wang, 2016).</ref>']",51,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
ef2c52e6-8135-470f-86a7-2e43e7dd9176,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,"['Mining coreference relations between formulas and text using Wikipedia', 'Entity linking for mathematical expressions in scientific documents']","['2010', '2016']","['Minh Nghiem Quoc;Keisuke Yokoi', 'Giovanni Kristianto;Goran Topić;Akiko Aizawa']",group,"['Early', 'studies', 'for', 'scientific', 'literature', 'link', 'formulae', 'to', 'Wikipedia', 'page', '<ref type=""group"">(Nghiem Quoc et al., 2010, Kristianto et al., 2016).</ref>', 'Even', 'though', 'this', 'can', 'provide', 'additional', 'information', 'regarding', 'the', 'mathematical', 'expression,', 'a', 'reader', 'might', 'find', 'it', 'harder', 'to', 'understand', 'the', 'Wikipedia', 'page', 'as', 'it', 'is', 'presented', 'in', 'many', 'unrelated', 'forms.', 'Linking', 'to', 'the', 'description', 'in', 'the', 'same', 'document', 'is', 'more', 'practical', '<ref type=""group"">(Kristianto et al., 2014, Alexeeva et al., 2020)</ref>', 'as', 'the', 'descriptions', 'are', 'dedicated', 'to', 'the', 'symbols', 'and', 'the', 'context', 'presented', 'in', 'the', 'document.']",10,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f4c66f82-ab58-4bce-b883-cc43eaa9b6cf,NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques,2021,Gunjan Chhablani;Abheesht Sharma;Harshit Pandey;Yash Bhartia;Shan Suthaharan,['MRQA 2019 shared task: Evaluating generalization in reading comprehension'],['2019'],['Adam Fisch;Alon Talmor;Robin Jia;Minjoon Seo;Eunsol Choi;Danqi Chen'],single,"['We', 'use', 'the', 'BERT-based', 'Span', 'Prediction', '(Figure', '1c)', 'models', 'based', 'on', 'Extractive', 'Question', 'Answering', 'systems', 'similar', 'to', 'work', 'on', 'SQuAD', '<ref type=""single"">(Rajpurkar et al., 2016)</ref>', 'and', 'MRQA', '<ref type=""single"">(Fisch et al., 2019).</ref>', 'In', 'these', 'systems,', 'the', 'output', 'at', 'each', 'token', 'is', 'a', 'start', 'logit', 'and', 'an', 'end', 'logit', 'denoting', 'whether', 'that', 'token', 'is', 'a', 'start', 'token', 'or', 'an', 'end', 'token', 'of', 'the', 'span,', 'depending', 'on', 'the', 'softmax', 'value.', 'Since', 'the', 'Toxic', 'Spans', 'text', 'can', 'have', 'multiple', 'toxic', 'spans,', 'we', 'take', 'different', 'contiguous', 'spans', 'from', 'the', 'given', 'offsets,', 'and', 'make', 'several', ""'samples'"", 'out', 'of', 'the', 'example.', 'Each', 'span', 'becomes', 'an', ""'answer'"", 'for', 'the', 'particular', 'text', 'sample.', 'We', 'use', 'the', 'word', ""'offense'"", 'as', 'a', 'dummy', 'question.', 'Thus,', 'each', 'contiguous', 'span', 'leads', 'to', 'one', ""'sample'"", 'for', 'every', 'example', '(Table', '1).', 'We', 'store', 'the', 'start', 'index', 'of', 'the', 'text,', 'similar', 'to', 'the', 'SQuAD', '<ref type=""single"">(Rajpurkar et al., 2016)</ref>', 'dataset,', 'and', 'process', 'the', 'data', 'to', 'provide', 'start', 'and', 'end', 'token', 'positions', 'during', 'training.', 'The', 'classifier', 'layer', 'on', 'top', 'of', 'the', 'encoder', 'embeddings', 'performs', 'a', 'binary', 'classification', 'task', 'for', 'start', 'and', 'end', 'positions.', 'A', 'span', 'is', 'scored', 'using', 'the', 'sum', 'of', 'predicted', 'start', 'and', 'end', 'logits.', 'From', 'top-K', 'start', 'and', 'end', 'logits,', 'valid', 'predicted', 'answer', 'spans', '4', 'are', 'chosen', 'during', 'postprocessing.', 'A', 'union', 'of', 'all', 'the', 'corresponding', 'offsets', 'is', 'taken', 'to', 'give', 'the', 'final', 'prediction', 'for', 'the', 'example.', 'A', 'threshold', 'is', 'learned', 'on', 'the', 'span', 'scores', 'using', 'the', 'resulting', 'dev', 'set', 'F', '1', 'score', 'on', 'offsets,', 'which', 'is', 'then', 'used', 'for', 'test', 'set', 'prediction.', 'All', 'spans', 'with', 'score', 'above', 'threshold', 'are', 'considered', 'to', 'be', 'toxic', 'spans.BERT-based', 'Model', '[EMB]', 'you', 'pathetic', 'troll', '[SEP]', '[CLS]', '[EMB]', '[EMB]', 'CLFR', 'NT', 'T', '[EMB]', '[EMB]', '1', '0', 'CLFR', 'NT', 'T', '1', '0', 'CLFR', 'NT', 'T', '0', '1', 'CLFR', 'NT', 'T', '0', '1', 'CLFR', 'NT', 'T', 'X', 'X', '(a)', 'Token', 'Classification', 'BERT-based', 'Model', '[EMB]', '[EMB]', '[EMB]', 'CLFR', 'S', 'E', '[EMB]', '[EMB]', '0', '0', 'CLFR', '0', '0', 'CLFR', '1', '0', 'CLFR', '0', '1', 'CLFR', '0', '0', 'S', 'E', 'S', 'E', 'S', 'E', 'S', 'E', 'CLFR', 'NT', 'T', '1', '0', 'CLFR', 'NT', 'T', '1', '0', 'CLFR', 'NT', 'T', '0', '1', 'CLFR', 'NT', 'T', '0', '1', 'CLFR', 'NT', 'T', 'X', 'X', 'you', 'pathetic', 'troll', '[SEP]', '[CLS]', '(b)', 'Span+Token', 'BERT-based', 'Model', '[EMB]', '[EMB]', '[EMB]', 'CLFR', 'S', 'E', '[EMB]', '[EMB]', '0', '0', 'CLFR', '0', '0', 'CLFR', '1', '0', 'CLFR', '0', '1', 'CLFR', '0', '0', 'S', 'E', 'S', 'E', 'S', 'E', 'S', 'E', 'you', 'pathetic', 'troll', '[SEP]', '[CLS]', '(c)', 'Span', 'Prediction', 'BERT-based', 'Model', '[EMB]', 'CLFR', '1', '0', 'S', 'E', '[EMB]', 'CLFR', '0', '1', 'S', 'E', '[EMB]', 'CLFR', '0', '0', 'S', 'E', '[EMB]', 'CLFR', '1', '0', 'S', 'E', '[EMB]', 'CLFR', '0', '1', 'S', 'E', '[EMB]', 'CLFR', '0', '0', 'S', 'E', '[EMB]', 'CLFR', '0', '0', 'S', 'E', '[CLS]', 'dumb', 'ignorant', 'boy', 'pathetic', 'troll', '[SEP]', '(d)', 'Multi-Spans', 'BERT-based', 'Model', '[EMB]', '[EMB]', '[EMB]', 'BiLSTM', 'NT', 'T', '[EMB]', '[EMB]', '0', '0', 'BiLSTM', 'BiLSTM', 'BiLSTM', 'BiLSTM', 'CRF', 'D', '1', 'NT', 'T', '1', '0', '0', 'D', 'NT', 'T', '0', '1', '0', 'D', 'NT', 'T', '0', '1', '0', 'D', 'NT', 'T', 'X', 'X', 'X', 'D', 'you', 'pathetic', 'troll', '[SEP]', '[CLS]', '(e)', 'LSTM-CRF']",23,"[2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]","[2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f561ba37-4846-443c-97ba-9284e03bdb71,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['unknown'],['unknown'],['unknown'],single,"['FrALBERT', 'Crawl', 'projects', 'such', 'as', 'OSCAR', '<ref type=""single"">(Ortiz Suárez et al., 2020)</ref>', 'or', 'CCNet', '<ref type=""single"">(Wenzek et al., 2020)</ref>', 'corpora,', 'and', 'because', 'we', 'focus', 'on', 'factual', 'QA,', 'we', 'decide', 'to', 'use', 'only', 'Wikipedia', 'as', 'our', 'primary', 'source', 'of', 'knowledge.', 'We', 'used', 'the', 'same', 'learning', 'configuration', 'as', 'the', 'original', 'model', 'with', 'a', 'batch', 'size', 'of', '128', 'and', 'a', 'initial', 'learning', 'rate', 'set', 'to', '3.125', '×', '10', '-4.']",9,"[1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]","[0, 0, 0, 3, 3, 3, 3, 3, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f5bb6807-976e-432f-835f-192282a0f942,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['FlauBERT: Unsupervised language model pre-training for French'],['2020'],['Hang Le;Loïc Vial;Jibril Frej;Vincent Segonne;Maximin Coavoux;Benjamin Lecouteux;Alexandre Allauzen;Benoit Crabbé;Laurent Besacier;Didier Schwab'],single,"['French', 'is', 'a', 'poorly', 'endowed', 'language', 'since', 'we', 'do', 'not', 'have', 'enough', 'annotated', 'data', 'to', 'train', 'a', 'deep', 'learning', 'model', 'on', 'QA', 'tasks.', 'Moreover,', 'unlike', 'the', 'only', 'two', 'large', 'monolingual', 'French', 'models:', 'CamemBERT', '<ref type=""single"">(Martin et al., 2020)</ref>', 'and', 'FlauBERT', '<ref type=""single"">(Le et al., 2020),</ref>', 'the', 'English', 'BERT', 'model', 'has', 'become', 'a', 'branching', 'point', 'from', 'which', 'a', 'growing', 'number', 'of', 'large', 'and', 'compact', 'English', 'pre-trained', 'models', 'have', 'emerged.', 'These', 'French', 'monolingual', 'models,', 'although', 'they', 'provide', 'good', 'performances,', 'do', 'not', 'reflect', 'the', 'rapid', 'evolution', 'of', 'the', 'field.']",36,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]","[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
fed0077b-fbdb-45ad-b1bb-0ca1697e60a1,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,['Attention-based recurrent neural network models for joint intent detection and slot filling'],['2016'],['Bing Liu;Ian Lane'],single,"['RNN-NLU', '<ref type=""single"">(Liu and Lane, 2016)</ref>', 'is', 'an', 'attention-based', 'bi-directional', 'recurrent', 'neural', 'network', 'model', 'that', 'jointly', 'predicts', 'the', 'current', 'slot', 'and', 'the', 'intent', 'at', 'each', 'time', 'step', 'using', 'shared', 'hidden', 'states', 'and', 'attention.']",1,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"

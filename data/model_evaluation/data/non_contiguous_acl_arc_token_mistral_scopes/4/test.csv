token_context,word_context,seg_context,sent_cotext,label
"['Apart from wikis, blogs, and cognitive mapping, we were also inspired by the experiences of early hypertext writing tools, in particular Intermedia and Storyspace.', 'In fact, they were used expecially in academic writing with some success.', 'Intermedia is no more developed and nobody of us had the opportunity to try it #TAUTHOR_TAG .', 'Story', '', '', '', '']","['Apart from wikis, blogs, and cognitive mapping, we were also inspired by the experiences of early hypertext writing tools, in particular Intermedia and Storyspace.', 'In fact, they were used expecially in academic writing with some success.', 'Intermedia is no more developed and nobody of us had the opportunity to try it #TAUTHOR_TAG .', 'Storyspace', '', '', '', '']","['Apart from wikis, blogs, and cognitive mapping, we were also inspired by the experiences of early hypertext writing tools, in particular Intermedia and Storyspace.', 'In fact, they were used expecially in academic writing with some success.', 'Intermedia is no more developed and nobody of us had the opportunity to try it #TAUTHOR_TAG .', 'Story', '', '', '', '']","['Apart from wikis, blogs, and cognitive mapping, we were also inspired by the experiences of early hypertext writing tools, in particular Intermedia and Storyspace.', 'In fact, they were used expecially in academic writing with some success.', 'Intermedia is no more developed and nobody of us had the opportunity to try it #TAUTHOR_TAG .', '', '', '', '', '']",0
"[""Following the example of #TAUTHOR_TAG , we will call the autonomous units of a hypertext lexias ( from ` lexicon ' ) , a word coined by #AUTHOR_TAG ."", 'hyper lex', 'le navig', '']","[""Following the example of #TAUTHOR_TAG , we will call the autonomous units of a hypertext lexias ( from ` lexicon ' ) , a word coined by #AUTHOR_TAG ."", 'hypertext', '', '']","[""Following the example of #TAUTHOR_TAG , we will call the autonomous units of a hypertext lexias ( from ` lexicon ' ) , a word coined by #AUTHOR_TAG ."", 'lex', 'navig', '']","[""Following the example of #TAUTHOR_TAG , we will call the autonomous units of a hypertext lexias ( from ` lexicon ' ) , a word coined by #AUTHOR_TAG ."", '', '', '']",5
"['', ""'less"", '', '', '', 'use computers for writing has drammatically changed, expecially after their interconnection via the internet, since at least the foundation of the web (B-', ""For example , a ` web page ' is more similar to an infinite canvas than a written page #TAUTHOR_TAG ."", '', '', '', '', '', '', '', '']","['', 'meaningless', '', '', '', 'use computers for writing has drammatically changed, expecially after their interconnection via the internet, since at least the foundation of the web (Berners- #AUTHOR_TAG', ""For example , a ` web page ' is more similar to an infinite canvas than a written page #TAUTHOR_TAG ."", '', '', '', '', '', '', '', '']","['', '', '', '', '', 'computers for writing has drammatically changed, expecially after their interconnection via the internet, since at least the foundation of the web (B-', ""For example , a ` web page ' is more similar to an infinite canvas than a written page #TAUTHOR_TAG ."", '', '', '', '', '', '', '', '']","['', '', '', '', '', 'Nowadays the use of computers for writing has drammatically changed, expecially after their interconnection via the internet, since at least the foundation of the web (Berners- #AUTHOR_TAG .', ""For example , a ` web page ' is more similar to an infinite canvas than a written page #TAUTHOR_TAG ."", '', '', '', '', '', '', '', '']",0
"['want to', 'We consider Commons model to let author', 'Narrative writings or essays are creative works and they generally treat ownership as authorship , even for the most enthusiastic fellows of free culture #TAUTHOR_TAG .']","['want to', 'We consider Commons model to let author', 'Narrative writings or essays are creative works and they generally treat ownership as authorship , even for the most enthusiastic fellows of free culture #TAUTHOR_TAG .']","['want to', 'We consider the Creative Commons model to let each author', 'Narrative writings or essays are creative works and they generally treat ownership as authorship , even for the most enthusiastic fellows of free culture #TAUTHOR_TAG .']","['', '', 'Narrative writings or essays are creative works and they generally treat ownership as authorship , even for the most enthusiastic fellows of free culture #TAUTHOR_TAG .']",0
"['the of blogs asaries on the still the main interpretation', 'that andis are subjected to the', 'jour', '', 'the other side , wikis started as collective works where each entry is not owned by a single author e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG', '', '']","['the of blogs as diaries on the still the main interpretation', 'that and are subjected to the', '', '', 'the other side , wikis started as collective works where each entry is not owned by a single author e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG', '', '']","['the use of blogs as on is still the main current interpretation', 'that andis are currently subjected to', 'jour', '', 'the other side , wikis started as collective works where each entry is not owned by a single author e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', '', '']","['', '', '', '', 'On the other side , wikis started as collective works where each entry is not owned by a single author e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', '', '']",0
"['', '', '', '(see Figure 2).', 'Authors may choose this right with the No-Deriv option of the Creative Commons licences #TAUTHOR_TAG .', 'If nobody claims the for himself, it will fall in the public domain', 'le', '', '', '', '', '', '', '', '', '', '']","['', '', '', '(see Figure 2).', 'Authors may choose this right with the No-Deriv option of the Creative Commons licences #TAUTHOR_TAG .', 'If nobody claims the for himself, it will fall in the public domain.', '', '', '', '', '', '', '', '', '', '', '']","['', '', '', '(see Figure 2).', 'Authors may choose this right with the No-Deriv option of the Creative Commons licences #TAUTHOR_TAG .', 'If nobody claims the document for himself, it will fall in the public domain.', 'le', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'Authors may choose this right with the No-Deriv option of the Creative Commons licences #TAUTHOR_TAG .', 'If nobody claims the document for himself, it will fall in the public domain.', '', '', '', '', '', '', '', '', '', '', '']",0
"['The main source of Novelle are wikis and blogs.', 'While wikis have spread from a detailed design #TAUTHOR_TAG , unfortunately blogs have not been designed under a model .', 'So we have tested and compared the most used tools available for blogging']","['The main source of Novelle are wikis and blogs.', 'While wikis have spread from a detailed design #TAUTHOR_TAG , unfortunately blogs have not been designed under a model .', 'So we have tested and compared the most used tools available for blogging:']","['The main source of Novelle are wikis and blogs.', 'While wikis have spread from a detailed design #TAUTHOR_TAG , unfortunately blogs have not been designed under a model .', 'So we have tested and compared the most used tools available for blogging']","['The main source of Novelle are wikis and blogs.', 'While wikis have spread from a detailed design #TAUTHOR_TAG , unfortunately blogs have not been designed under a model .', 'So we have tested and compared the most used tools available for blogging: Bloggers, WordPress, MovableType and LiveJournal.']",0
"['our typ of, we aim to solve the framing problem as defined in Section 1.', 'want to model views of still', 'We would also provide a user facility for choosing the right licence for every lexia , following the model of Creative Commons licences #TAUTHOR_TAG .']","['our typology of links, we aim to solve the framing problem as defined in Section 1.2.', 'want to model views of still', 'We would also provide a user facility for choosing the right licence for every lexia , following the model of Creative Commons licences #TAUTHOR_TAG .']","['our typ of, we aim to solve the framing problem as defined in Section 1.2.', 'We want to model views of', 'We would also provide a user facility for choosing the right licence for every lexia , following the model of Creative Commons licences #TAUTHOR_TAG .']","['With our typology of links, we aim to solve the framing problem as defined in Section 1.2.', '', 'We would also provide a user facility for choosing the right licence for every lexia , following the model of Creative Commons licences #TAUTHOR_TAG .']",5
"['Generally speaking , we find that the personal public diary metaphor behind blogs #TAUTHOR_TAG may bring to an unsatisfactory representation of the context .', ""way to retrieve information is through a search engine a,e. the of the 'post -xia in the j of bloggers.""]","['Generally speaking , we find that the personal public diary metaphor behind blogs #TAUTHOR_TAG may bring to an unsatisfactory representation of the context .', ""way to retrieve information is through a search engine a calendar, i.e. the of the 'post' -a lexia in the of bloggers.""]","['Generally speaking , we find that the personal public diary metaphor behind blogs #TAUTHOR_TAG may bring to an unsatisfactory representation of the context .', ""to retrieve information is through a search engine a calendar, i.e. the date of the 'post' -a lexia in the jargon of bloggers.""]","['Generally speaking , we find that the personal public diary metaphor behind blogs #TAUTHOR_TAG may bring to an unsatisfactory representation of the context .', ""The only way to retrieve information is through a search engine or a calendar, i.e. the date of the 'post' -a lexia in the jargon of bloggers.""]",0
"['The emphasis on narrativity takes into account the use of blogs as public diaries on the web , that is still the main current interpretation of this literary genre , or metagenre #TAUTHOR_TAG .', 'Furthermore we noticed that blogs and wikis are currently subjected to osmosis, because they have in common the underlying core technology.', 'agen jour', '', '', '', '', '']","['The emphasis on narrativity takes into account the use of blogs as public diaries on the web , that is still the main current interpretation of this literary genre , or metagenre #TAUTHOR_TAG .', 'Furthermore we noticed that blogs and wikis are currently subjected to osmosis, because they have in common the underlying core technology.', '', '', '', '', '', '']","['The emphasis on narrativity takes into account the use of blogs as public diaries on the web , that is still the main current interpretation of this literary genre , or metagenre #TAUTHOR_TAG .', 'Furthermore we noticed that blogs and wikis are currently subjected to osmosis, because they have in common the underlying core technology.', 'jour', '', '', '', '', '']","['The emphasis on narrativity takes into account the use of blogs as public diaries on the web , that is still the main current interpretation of this literary genre , or metagenre #TAUTHOR_TAG .', 'Furthermore we noticed that blogs and wikis are currently subjected to osmosis, because they have in common the underlying core technology.', '', '', '', '', '', '']",0
"['', '� orfoot� simply become meaningless in the texts, or they highly change meaning', '', 'criticism -- unlike in the previous times #TAUTHOR_TAG .', 'computers for writing has drammatically expec after their interconnection via the internet', '', '', '', '', '', '', '']","['', 'or note� simply become meaningless in the texts, or they highly change meaning.', '', 'criticism -- unlike in the previous times #TAUTHOR_TAG .', 'computers for writing has drammatically expecially after their interconnection via the internet,', '', '', '', '', '', '', '']","['', 'orfoot simply become meaningless in the new texts, or they highly change meaning', '', '-- unlike in the previous times #TAUTHOR_TAG .', 'computers for writing has drammatically, expecially after their interconnection via the internet,', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '']",0
"['1 Hypertext as a New Writing Space #TAUTHOR_TAG was the first scholar who stressed the impact of the digital revolution to the medium of writing.', ""Terms as 'chapter 'page' or 'footnote' simply become meaningless in the new texts, or they highly change meaning"", '', '', '', '', '', '', '', '', '', '', '', '', '']","['Hypertext as a New Writing Space #TAUTHOR_TAG was the first scholar who stressed the impact of the digital revolution to the medium of writing.', ""Terms as 'chapter', 'page' or 'footnote' simply become meaningless in the new texts, or they highly change meaning."", '', '', '', '', '', '', '', '', '', '', '', '', '']","['1 Hypertext as a New Writing Space #TAUTHOR_TAG was the first scholar who stressed the impact of the digital revolution to the medium of writing.', ""Terms as 'chapter 'page' or 'footnote' simply become meaningless in the new texts, or they highly change meaning"", '', '', '', '', '', '', '', '', '', '', '', '', '']","['1.1 Hypertext as a New Writing Space #TAUTHOR_TAG was the first scholar who stressed the impact of the digital revolution to the medium of writing.', ""Terms as 'chapter', 'page' or 'footnote' simply become meaningless in the new texts, or they highly change their meaning."", '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['term refers group', 'AX a web development technique for creating interactive web applications a DOM ) , the XMLHTTPRequest object #TAUTHOR_TAG .']","['term refers group', 'a web development technique for creating interactive web applications a DOM ) , the XMLHTTPRequest object #TAUTHOR_TAG .']","['a term refers a group', 'a web development technique for creating interactive web applications using a combination DOM ) , the XMLHTTPRequest object #TAUTHOR_TAG .']","['', '']",0
"[""Concept mapping has been used at least in education for over thirty years, in particular at the Cornell University, where Piaget's ideas gave the roots to the assimilation theory by David Ausubel."", 'Very briefly, concept maps show the relationships between concepts labelling both nodes and arcs.', 'Every arc always has a definite direction , i.e. arcs are arrows #TAUTHOR_TAG .']","[""Concept mapping has been used at least in education for over thirty years, in particular at the Cornell University, where Piaget's ideas gave the roots to the assimilation theory by David Ausubel."", 'Very briefly, concept maps show the relationships between concepts labelling both nodes and arcs.', 'Every arc always has a definite direction , i.e. arcs are arrows #TAUTHOR_TAG .']","[""Concept mapping has been used at least in education for over thirty years, in particular at the Cornell University, where Piaget's ideas gave the roots to the assimilation theory by David Ausubel."", 'Very briefly, concept maps show the relationships between concepts labelling both nodes and arcs.', 'Every arc always has a definite direction , i.e. arcs are arrows #TAUTHOR_TAG .']","[""Concept mapping has been used at least in education for over thirty years, in particular at the Cornell University, where Piaget's ideas gave the roots to the assimilation theory by David Ausubel."", 'Very briefly, concept maps show the relationships between concepts labelling both nodes and arcs.', 'Every arc always has a definite direction , i.e. arcs are arrows #TAUTHOR_TAG .']",0
['The Ruby on #TAUTHOR_TAG framework permits us to quickly develop web applications without rewriting common functions and classes .'],['The Ruby on #TAUTHOR_TAG framework permits us to quickly develop web applications without rewriting common functions and classes .'],['The Ruby on #TAUTHOR_TAG framework permits us to quickly develop web applications without rewriting common functions and classes .'],['The Ruby on #TAUTHOR_TAG framework permits us to quickly develop web applications without rewriting common functions and classes .'],5
"['In wikis every track of to start a a to move move back onto the', ', a sandbox is a temporary view of a document itself i.e. a sandbox can not cause a change in the history #TAUTHOR_TAG .', 'Figure1 shows the model', 'History snapshots', '', 'Nov']","['In wikis every track of to start a a to move move back onto the', ', a sandbox is a temporary view of a document itself i.e. a sandbox can not cause a change in the history #TAUTHOR_TAG .', 'Figure 1 shows the model.', 'History snapshots', '', 'Novelle']","['In wikis every document track of to start a document to move back onto', ', a sandbox is a temporary view of a document itself i.e. a sandbox can not cause a change in the history #TAUTHOR_TAG .', 'Figure 1 shows the model.', 'History snapshots', '', 'Nov']","['', 'Moreover , a sandbox is a temporary view of a document itself i.e. a sandbox can not cause a change in the history #TAUTHOR_TAG .', 'Figure 1 shows the model.', '', '', '']",0
"['', ""'less"", '', '', '', '', '', '', 'open', 'a more pessimistic one, an author may feel to have lost power in this openness.', 'Henceforth the collaborative traits of blogs and wikis #TAUTHOR_TAG emphasize annotation , comment , and strong editing .', 'They give more power to readers, eventually filling the gap -the so-called active readers become authors as well.', 'This could', '', 'Nov']","['', 'meaningless', '', '', '', '', '', '', '(open', 'a more pessimistic one, an author may feel to have lost power in this openness.', 'Henceforth the collaborative traits of blogs and wikis #TAUTHOR_TAG emphasize annotation , comment , and strong editing .', 'They give more power to readers, eventually filling the gap -the so-called active readers become authors as well.', 'This could', '', '']","['', '', '', '', '', '', '', '', '', 'a more pessimistic one, an author may feel to have lost power in this openness.', 'Henceforth the collaborative traits of blogs and wikis #TAUTHOR_TAG emphasize annotation , comment , and strong editing .', 'They give more power to readers, eventually filling the gap -the so-called active readers become authors as well.', 'This situation could make', '', 'Nov']","['', '', '', '', '', '', '', '', '', 'From a more pessimistic one, an author may feel to have lost power in this openness.', 'Henceforth the collaborative traits of blogs and wikis #TAUTHOR_TAG emphasize annotation , comment , and strong editing .', 'They give more power to readers, eventually filling the gap -the so-called active readers become authors as well.', '', '', '']",0
"['inik no lexia is authored and is hierarchy lex', '', 'Gener people avoid prefer to edit each', 'The paradigm is ""write many , read many"" #TAUTHOR_TAG .']","['in no lexia is authored and is hierarchy lexias.', '', 'people avoid preferring to edit each', 'The paradigm is ""write many , read many"" #TAUTHOR_TAG .']","['inikis no lexia is authored and is no hierarchy lex', '', 'Gener, people avoid to edit', 'The paradigm is ""write many , read many"" #TAUTHOR_TAG .']","['On the contrary, in wikis no lexia is authored and there is no hierarchy between lexias.', '', '', 'The paradigm is ""write many , read many"" #TAUTHOR_TAG .']",0
"['We used the Asyncronous J AAX) paradigm to create the graphical user interface.', 'AJAX function lets the communication works asyncronously between a client and a server through a set of messages based on HTTP protocol and XML #TAUTHOR_TAG .']","['We used the Asyncronous AJAX) paradigm to create the graphical user interface.', 'AJAX function lets the communication works asyncronously between a client and a server through a set of messages based on HTTP protocol and XML #TAUTHOR_TAG .']","['We used the Asyncronous Javascriptor AJAX) paradigm to create the graphical user interface.', 'AJAX function lets the communication works asyncronously between a client and a server through a set of messages based on HTTP protocol and XML #TAUTHOR_TAG .']","['We used the Asyncronous Javascript And XML (or AJAX) paradigm to create the graphical user interface.', 'AJAX function lets the communication works asyncronously between a client and a server through a set of messages based on HTTP protocol and XML #TAUTHOR_TAG .']",0
"['A is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #AUTHOR_TAG and Portuguese #TAUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 7 % and 41 % , respectively , and root recall is affected negatively', '', '', '']","['A is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #AUTHOR_TAG and Portuguese #TAUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is affected negatively', '', '', '']","['is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #AUTHOR_TAG and Portuguese #TAUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively .', '', '', '']","['A second observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #AUTHOR_TAG and Portuguese #TAUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively .', '', '', '']",1
"['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', 'Graph transformations for recovering nonprojective structures #TAUTHOR_TAG .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', 'Graph transformations for recovering nonprojective structures #TAUTHOR_TAG .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', '¢ Graph transformations for recovering nonprojective structures #TAUTHOR_TAG .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', 'â\x80¢ Graph transformations for recovering nonprojective structures #TAUTHOR_TAG .']",5
"['A observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #TAUTHOR_TAG and Portuguese #AUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively', 'accur', '', '']","['A observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #TAUTHOR_TAG and Portuguese #AUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively', '', '', '']","['A second observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #TAUTHOR_TAG and Portuguese #AUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively .', 'accur', '', '']","['A second observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #TAUTHOR_TAG and Portuguese #AUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively .', '', '', '']",1
['The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by #AUTHOR_TAG and extended to labeled dependency parsing by #TAUTHOR_TAG .'],['The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by #AUTHOR_TAG and extended to labeled dependency parsing by #TAUTHOR_TAG .'],['The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by #AUTHOR_TAG and extended to labeled dependency parsing by #TAUTHOR_TAG .'],['The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by #AUTHOR_TAG and extended to labeled dependency parsing by #TAUTHOR_TAG .'],5
"['specific of feature and learning algorithm parameters can be onalt', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #TAUTHOR_TAG .', 'Japanese #AUTHOR_TAG attachment score drops from 98%']","['specifications of feature and learning algorithm parameters can be on', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #TAUTHOR_TAG .', 'Japanese #AUTHOR_TAG attachment score drops from 98%']","['of and learning algorithm parameters can be found on', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #TAUTHOR_TAG .', 'Japanese #AUTHOR_TAG that attachment score drops from 98%']","['', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #TAUTHOR_TAG .', '']",0
"['of learning algorithm parameters can bealt', '', '.', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['of learning algorithm parameters can be', '', '', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['of learning algorithm parameters can be found', '', '.', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['', '', '', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']",0
"['general observations specific of the feature models and learning algorithm parameters can be onalt', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #TAUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['general observations specifications of the feature models and learning algorithm parameters can be on', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #TAUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['of the feature models and learning algorithm parameters can be found on', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #TAUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #TAUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']",0
"['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', 'â\x80¢ History-based feature models for predicting the next parser action #TAUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', '• Graph transformproject structures']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', 'â\x80¢ History-based feature models for predicting the next parser action #TAUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', '• Graph transformations structures']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', 'â\x80¢ History-based feature models for predicting the next parser action #TAUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', '• Graph transformations']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', 'â\x80¢ History-based feature models for predicting the next parser action #TAUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', '']",5
"['All experiments have been performed using MaltParser #TAUTHOR_TAG , version 0.4 , which is made available together with the suite of programs used for preand post-processing .1']","['All experiments have been performed using MaltParser #TAUTHOR_TAG , version 0.4 , which is made available together with the suite of programs used for preand post-processing .1']","['All experiments have been performed using MaltParser #TAUTHOR_TAG , version 0.4 , which is made available together with the suite of programs used for preand post-processing .1']","['All experiments have been performed using MaltParser #TAUTHOR_TAG , version 0.4 , which is made available together with the suite of programs used for preand post-processing .1']",5
"['We use support vector machines to predict the next parser action from a feature vector representing the history.', 'More specifically , we use LIBSVM #TAUTHOR_TAG with a quadratic kernel K ( xZ , xj ) = ( - yxT xj + r ) 2 and the built-in one-versus-all strategy for multi-class classification .', '', '', '']","['We use support vector machines to predict the next parser action from a feature vector representing the history.', 'More specifically , we use LIBSVM #TAUTHOR_TAG with a quadratic kernel K ( xZ , xj ) = ( - yxT xj + r ) 2 and the built-in one-versus-all strategy for multi-class classification .', '', '', '']","['We use support vector machines to predict the next parser action from a feature vector representing the history.', 'More specifically , we use LIBSVM #TAUTHOR_TAG with a quadratic kernel K ( xZ , xj ) = ( - yxT xj + r ) 2 and the built-in one-versus-all strategy for multi-class classification .', '', '', '']","['We use support vector machines to predict the next parser action from a feature vector representing the history.', 'More specifically , we use LIBSVM #TAUTHOR_TAG with a quadratic kernel K ( xZ , xj ) = ( - yxT xj + r ) 2 and the built-in one-versus-all strategy for multi-class classification .', '', '', '']",5
['6The analysis is reminiscent of the treatment of coordination in the Collins parser #TAUTHOR_TAG .'],['6The analysis is reminiscent of the treatment of coordination in the Collins parser #TAUTHOR_TAG .'],['6The analysis is reminiscent of the treatment of coordination in the Collins parser #TAUTHOR_TAG .'],['6The analysis is reminiscent of the treatment of coordination in the Collins parser #TAUTHOR_TAG .'],1
"['Although the parser only derives projective graphs , the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of #TAUTHOR_TAG .']","['Although the parser only derives projective graphs , the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of #TAUTHOR_TAG .']","['Although the parser only derives projective graphs , the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of #TAUTHOR_TAG .']","['Although the parser only derives projective graphs , the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of #TAUTHOR_TAG .']",0
"['For some languages , we divide the training data into smaller sets , based on some feature s ( normally the CPOS or POS of the next input token ) , which may reduce training times without a significant loss in accuracy #TAUTHOR_TAG .', '']","['For some languages , we divide the training data into smaller sets , based on some feature s ( normally the CPOS or POS of the next input token ) , which may reduce training times without a significant loss in accuracy #TAUTHOR_TAG .', '']","['For some languages , we divide the training data into smaller sets , based on some feature s ( normally the CPOS or POS of the next input token ) , which may reduce training times without a significant loss in accuracy #TAUTHOR_TAG .', '']","['For some languages , we divide the training data into smaller sets , based on some feature s ( normally the CPOS or POS of the next input token ) , which may reduce training times without a significant loss in accuracy #TAUTHOR_TAG .', '']",0
"['of learning algorithm parameters can bealt', '', '.', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['of learning algorithm parameters can be', '', '', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['of learning algorithm parameters can be found', '', '.', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['', '', '', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']",0
"['', '', '', 'Dan Swedish', 'Japanese #TAUTHOR_TAG , despite a very high accuracy , is different in that attachment score drops from 98 % to 85 % , as we go from length 1 to 2 , which may have something to do with the data consisting of transcribed speech with very short utterances .']","['', '', '', 'Danish Swedish', 'Japanese #TAUTHOR_TAG , despite a very high accuracy , is different in that attachment score drops from 98 % to 85 % , as we go from length 1 to 2 , which may have something to do with the data consisting of transcribed speech with very short utterances .']","['', '', '', 'Dan Swedish .', 'Japanese #TAUTHOR_TAG , despite a very high accuracy , is different in that attachment score drops from 98 % to 85 % , as we go from length 1 to 2 , which may have something to do with the data consisting of transcribed speech with very short utterances .']","['', '', '', '', 'Japanese #TAUTHOR_TAG , despite a very high accuracy , is different in that attachment score drops from 98 % to 85 % , as we go from length 1 to 2 , which may have something to do with the data consisting of transcribed speech with very short utterances .']",1
"['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', 'Support vector machines for mapping histories to parser actions #TAUTHOR_TAG .', '• Graph transformations foring nonprojective structures .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', 'Support vector machines for mapping histories to parser actions #TAUTHOR_TAG .', '• Graph transformations for recovering nonprojective structures .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', 'Support vector machines for mapping histories to parser actions #TAUTHOR_TAG .', '• Graph transformations foring nonprojective structures .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', 'Support vector machines for mapping histories to parser actions #TAUTHOR_TAG .', '• Graph transformations for recovering nonprojective structures .']",5
"['results are characterized low accuracy as well as a de of score with arc lengthfrom3 to6', 'By contrast , Turkish #TAUTHOR_TAG exhibits high root accuracy but consistently low attachment scores ( about 88 % for length 1 and 68 % for length 2 ) .', 'It Turkishtyp']","['results are characterized low accuracy as well as a of score with arc length (from to', 'By contrast , Turkish #TAUTHOR_TAG exhibits high root accuracy but consistently low attachment scores ( about 88 % for length 1 and 68 % for length 2 ) .', 'It Turkish,']","['The results are characterized low root accuracy as well as of attachment score with arc lengthfrom3 to6', 'By contrast , Turkish #TAUTHOR_TAG exhibits high root accuracy but consistently low attachment scores ( about 88 % for length 1 and 68 % for length 2 ) .', 'It is Turkishtyp']","['', 'By contrast , Turkish #TAUTHOR_TAG exhibits high root accuracy but consistently low attachment scores ( about 88 % for length 1 and 68 % for length 2 ) .', '']",1
"['', '', '', '', '', '', '', '', '', '', '', 'the availabilityRep a studying the of semantics in various tasks', ' #TAUTHOR_TAG have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques .', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availability SemRep a studying the of semantics in various tasks.', ' #TAUTHOR_TAG have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques .', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availabilityRep studying the role of semantics in various tasks.', ' #TAUTHOR_TAG have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques .', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques .', '', '', '']",0
"['', '', '', '', 'For example #TAUTHOR_TAG experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4 % improvement in F-score .', 'found a correlation between the quality and strength of conclusions in the full article texts and abstracts.', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'For example #TAUTHOR_TAG experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4 % improvement in F-score .', 'found a correlation between the quality and strength of conclusions in the full article texts and abstracts.', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'For example #TAUTHOR_TAG experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4 % improvement in F-score .', 'found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts.', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'For example , #TAUTHOR_TAG experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4 % improvement in F-score .', 'found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts.', '', '', '', '', '', '', '', '', '', '']",0
"['to further boost performance, we employed Linear Discriminant Analysis (LDA) to find a linear projection of the four-dimensional vec- tors that maximizes the separation of the Gaussians (corresponding to the HMM states).', ' #TAUTHOR_TAG describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matrices of the classes , and using Singular Value Decomposition ( SVD ) to compute the eigenvectors of the new space .', 'sentenceMM']","['to further boost performance, we employed Linear Discriminant Analysis (LDA) to find a linear projection of the four-dimensional vec- tors that maximizes the separation of the Gaussians (corresponding to the HMM states).', ' #TAUTHOR_TAG describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matrices of the classes , and using Singular Value Decomposition ( SVD ) to compute the eigenvectors of the new space .', 'HMM']","['to further boost performance, we employed Linear Discriminant Analysis (LDA) to find a linear projection of the four-dimensional vec- tors that maximizes the separation of the Gaussians (corresponding to the HMM states).', ' #TAUTHOR_TAG describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matrices of the classes , and using Singular Value Decomposition ( SVD ) to compute the eigenvectors of the new space .', '']","['In an attempt to further boost performance, we employed Linear Discriminant Analysis (LDA) to find a linear projection of the four-dimensional vec- tors that maximizes the separation of the Gaussians (corresponding to the HMM states).', ' #TAUTHOR_TAG describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matrices of the classes , and using Singular Value Decomposition ( SVD ) to compute the eigenvectors of the new space .', '']",5
"['information', 'are already appropriately labeled', '', '', 'Such a component would serve as the first stage of a clinical question answering system #TAUTHOR_TAG or summarization system ( Mc #AUTHOR_TAG', 'We chose to controlled bench which all other clinical are measured.']","['information', 'are, already appropriately labeled.', '', '', 'Such a component would serve as the first stage of a clinical question answering system #TAUTHOR_TAG or summarization system ( Mc #AUTHOR_TAG', 'We chose to controlled benchmark which all other clinical are measured.']","['information', 'are already appropriately labeled', '', '', 'Such a component would serve as the first stage of a clinical question answering system #TAUTHOR_TAG or summarization system ( Mc #AUTHOR_TAG .', 'We chose to controlled which all other clinical studies are measured.']","['', '', '', '', 'Such a component would serve as the first stage of a clinical question answering system #TAUTHOR_TAG or summarization system ( Mc #AUTHOR_TAG .', '']",3
"['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']",0
"[' #AUTHOR_TAG and #TAUTHOR_TAG , we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts .', 'The four states in our H correspond to the information that characterizes each (""introduction"", """",results """")']","[' #AUTHOR_TAG and #TAUTHOR_TAG , we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts .', 'The four states in our correspond to the information that characterizes each (""introduction"", ""methods"",']","[' #AUTHOR_TAG and #TAUTHOR_TAG , we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts .', 'The four states in our Hs correspond to the information that characterizes each section (""introduction"", """", ""results"", """")']","[' #AUTHOR_TAG and #TAUTHOR_TAG , we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts .', '']",5
"['predict', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #TAUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['predictable', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #TAUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #TAUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #TAUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['', 'The transition probability matrix of theMM was initialized with uniform probabilities graph', '', 'Using the section labels , the HMM was trained using the HTK toolkit #TAUTHOR_TAG , which efficiently performs the forward-backward algorithm and BaumWelch estimation .', 'HTK']","['', 'The transition probability matrix of the HMM was initialized with uniform probabilities graph.', '', 'Using the section labels , the HMM was trained using the HTK toolkit #TAUTHOR_TAG , which efficiently performs the forward-backward algorithm and BaumWelch estimation .', 'HTK']","['', 'The transition probability matrix of the HMM was initialized with uniform probabilities graph', '', 'Using the section labels , the HMM was trained using the HTK toolkit #TAUTHOR_TAG , which efficiently performs the forward-backward algorithm and BaumWelch estimation .', '']","['', 'The transition probability matrix of the HMM was initialized with uniform probabilities over a fully connected graph.', '', 'Using the section labels , the HMM was trained using the HTK toolkit #TAUTHOR_TAG , which efficiently performs the forward-backward algorithm and BaumWelch estimation .', '']",5
"['Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications.', 'As an, scientific abstracts across many different fields generally follow the pattern of ""introduction"" , ""methods"" , ""results"" , and ""conclusions"" #TAUTHOR_TAG ; OrË\x98asan , 2001 ) .', 'The ability to explicitly identify these sections in un-structured text could play an important role in such as document summarization information retrieval information extr', '', '', '']","['Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications.', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"" , ""methods"" , ""results"" , and ""conclusions"" #TAUTHOR_TAG ; OrË\x98asan , 2001 ) .', 'The ability to explicitly identify these sections in un-structured text could play an important role in such as document summarization information retrieval information extraction', '', '', '']","['Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications.', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"" , ""methods"" , ""results"" , and ""conclusions"" #TAUTHOR_TAG ; OrË\x98asan , 2001 ) .', 'The ability to explicitly identify these sections in un-structured text could play an important role in such as document summarization information retrieval information extraction', '', '', '']","['Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications.', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"" , ""methods"" , ""results"" , and ""conclusions"" #TAUTHOR_TAG ; OrË\x98asan , 2001 ) .', 'The ability to explicitly identify these sections in un-structured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering.', '', '', '']",0
"['An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors ( log probabilities of observing entire sentences based on our language models ) , as opposed to sequences of terms , as done in #TAUTHOR_TAG .', 'This technique provides two important advantages.', 'during trainingorder', '', '']","['An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors ( log probabilities of observing entire sentences based on our language models ) , as opposed to sequences of terms , as done in #TAUTHOR_TAG .', 'This technique provides two important advantages.', 'during training,', '', '']","['An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors ( log probabilities of observing entire sentences based on our language models ) , as opposed to sequences of terms , as done in #TAUTHOR_TAG .', 'This technique provides two important advantages.', 'during training', '', '']","['An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors ( log probabilities of observing entire sentences based on our language models ) , as opposed to sequences of terms , as done in #TAUTHOR_TAG .', 'This technique provides two important advantages.', '', '', '']",1
"['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']",0
"['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #TAUTHOR_TAG for concept identification and SemRep #AUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #TAUTHOR_TAG for concept identification and SemRep #AUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #TAUTHOR_TAG for concept identification and SemRep #AUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks .', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'Furthermore , the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #TAUTHOR_TAG for concept identification and SemRep #AUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks .', '', '', '', '']",0
"['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG , attribut']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG , attribution']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG ,']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', '']",1
"['', '', '', '', '', '', '', 'variety reasons medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev a', 'needsLINE', '', '', '', '', '']","['', '', '', '', '', '', '', 'variety reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retrieval a', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'a variety reasons, medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'For a variety of reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', '', '', '', '', '', '', '']",0
"['Although this study the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (', 'Our task is closer to the work of #TAUTHOR_TAG , who looked at the problem of intellectual attribution in scientific texts .']","['Although this study the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements', 'Our task is closer to the work of #TAUTHOR_TAG , who looked at the problem of intellectual attribution in scientific texts .']","['Although this study the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (', 'Our task is closer to the work of #TAUTHOR_TAG , who looked at the problem of intellectual attribution in scientific texts .']","['Although this study falls under the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (Mc #AUTHOR_TAG .', 'Our task is closer to the work of #TAUTHOR_TAG , who looked at the problem of intellectual attribution in scientific texts .']",1
"['information', 'crossstructured abstracts are after all, already appropriately labeled', '', '', 'Such a component would serve as the first stage of a clinical question answering system ( Demner- #AUTHOR_TAG or summarization system #TAUTHOR_TAG .', 'We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured.']","['information', 'crossvalidation task-structured abstracts are, after all, already appropriately labeled.', '', '', 'Such a component would serve as the first stage of a clinical question answering system ( Demner- #AUTHOR_TAG or summarization system #TAUTHOR_TAG .', 'We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured.']","['information', 'cross are after all, already appropriately labeled', '', '', 'Such a component would serve as the first stage of a clinical question answering system ( Demner- #AUTHOR_TAG or summarization system #TAUTHOR_TAG .', 'We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured.']","['', '', '', '', 'Such a component would serve as the first stage of a clinical question answering system ( Demner- #AUTHOR_TAG or summarization system #TAUTHOR_TAG .', 'We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured.']",3
['Table (b) again reproduces the results from #TAUTHOR_TAG (2003) for a comparable task on a different subset of 206 unstructured abstracts.'],['Table (b) again reproduces the results from #TAUTHOR_TAG (2003) for a comparable task on a different subset of 206 unstructured abstracts.'],['Table (b) again reproduces the results from #TAUTHOR_TAG (2003) for a comparable task on a different subset of 206 unstructured abstracts.'],['Table (b) again reproduces the results from #TAUTHOR_TAG (2003) for a comparable task on a different subset of 206 unstructured abstracts.'],1
"['predict', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #TAUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['predictable', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #TAUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #TAUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #TAUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', '', 'variety reasons medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev a', 'needsLINE', '', '', '', '', '']","['', '', '', '', '', '', '', 'variety reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retrieval a', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'a variety reasons, medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'For a variety of reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', '', '', '', '', '', '', '']",0
"['predict', ', scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #TAUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['predictable', 'example, scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #TAUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #TAUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #TAUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['shown in Tables 2(a) and b). Table2(a) reports the classification error rate; once again, applying the Markov assumption to model discourse transitions improves performance reduces error rate.', 'Table 2(b) reports accuracy, precision, recall, and F- measure for four separate binary classifiers (HMM with LDA) specifically trained for each of the sections (one per row in the table).', 'The table also presents the closest comparable experimental results reported by #TAUTHOR_TAG .1 McK Sivas ( henceforth', '', '', '']","['shown in Tables 2(a) and 2(b). Table 2(a) reports the classification error rate; once again, applying the Markov assumption to model discourse transitions improves performance, reduces error rate.', 'Table 2(b) reports accuracy, precision, recall, and F- measure for four separate binary classifiers (HMM with LDA) specifically trained for each of the sections (one per row in the table).', 'The table also presents the closest comparable experimental results reported by #TAUTHOR_TAG .1 McKnight Srinivasan ( henceforth', '', '', '']","['are shown in Tables 2(a) and b). Table2(a) reports the multi-way classification error rate; once again, applying the Markov assumption to model discourse transitions improves performance further reduces error rate.', 'Table 2(b) reports accuracy, precision, recall, and F- measure for four separate binary classifiers (HMM with LDA) specifically trained for each of the sections (one per row in the table).', 'The table also presents the closest comparable experimental results reported by #TAUTHOR_TAG .1 McKnight Sivas ( henceforth', '', '', '']","['The results of our second set of experiments (with RCTs only) are shown in Tables 2(a) and 2(b). Table 2(a) reports the multi-way classification error rate; once again, applying the Markov assumption to model discourse transitions improves performance, and using LDA further reduces error rate.', 'Table 2(b) reports accuracy, precision, recall, and F- measure for four separate binary classifiers (HMM with LDA) specifically trained for each of the sections (one per row in the table).', '', '', '', '']",1
"['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG , attribut']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG , attribution']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG ,']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', '']",1
"['', '', '', '', '', '', '', '', '', '', '', '', '', 'the in the same domain , we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models ( HMMs ) ; cfXXX #TAUTHOR_TAG .', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'the in the same domain , we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models ( HMMs ) ; cfXXX #TAUTHOR_TAG .', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'the work in the same domain , we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models ( HMMs ) ; cfXXX #TAUTHOR_TAG .', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'Building on the work of #AUTHOR_TAG in the same domain , we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models ( HMMs ) ; cfXXX #TAUTHOR_TAG .', '', '']",0
"['', '', '', '', '', '', 'presents experiments generative content models for analyzing the discourse structure of medical abstracts , which has been confirmed to follow the four-section pattern discussed above #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', 'presents experiments generative content models for analyzing the discourse structure of medical abstracts , which has been confirmed to follow the four-section pattern discussed above #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', 'presents experiments generative content models for analyzing the discourse structure of medical abstracts , which has been confirmed to follow the four-section pattern discussed above #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', 'This paper presents experiments with generative content models for analyzing the discourse structure of medical abstracts , which has been confirmed to follow the four-section pattern discussed above #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', '', 'variety reasons medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev a', 'needsLINE', '', '', '', '', '']","['', '', '', '', '', '', '', 'variety reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retrieval a', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'a variety reasons, medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'For a variety of reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #AUTHOR_TAG for concept identification and SemRep #TAUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #AUTHOR_TAG for concept identification and SemRep #TAUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #AUTHOR_TAG for concept identification and SemRep #TAUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks .', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'Furthermore , the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #AUTHOR_TAG for concept identification and SemRep #TAUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks .', '', '', '', '']",0
"['Although not the first to employ a generative approach to directly model content , the seminal work of #TAUTHOR_TAG is a noteworthy point of reference and comparison .', ', our study differs in several important respects.', '', '', 'and', '']","['Although not the first to employ a generative approach to directly model content , the seminal work of #TAUTHOR_TAG is a noteworthy point of reference and comparison .', 'However, our study differs in several important respects.', '', '', 'and', '']","['Although not the first to employ a generative approach to directly model content , the seminal work of #TAUTHOR_TAG is a noteworthy point of reference and comparison .', ', our study differs in several important respects.', '', '', 'and', '']","['Although not the first to employ a generative approach to directly model content , the seminal work of #TAUTHOR_TAG is a noteworthy point of reference and comparison .', 'However, our study differs in several important respects.', '', '', '', '']",1
"['', '', '', '', 'using continuous distributions allows us to leverage a variety of tools ( e.g. , LDA ) that have been shown to be successful in other fields , such as speech recognition #TAUTHOR_TAG .']","['', '', '', '', 'using continuous distributions allows us to leverage a variety of tools ( e.g. , LDA ) that have been shown to be successful in other fields , such as speech recognition #TAUTHOR_TAG .']","['', '', '', '', 'using continuous distributions allows us to leverage a variety of tools ( e.g. , LDA ) that have been shown to be successful in other fields , such as speech recognition #TAUTHOR_TAG .']","['', '', '', '', 'Second , using continuous distributions allows us to leverage a variety of tools ( e.g. , LDA ) that have been shown to be successful in other fields , such as speech recognition #TAUTHOR_TAG .']",0
"['We work with a semi-technical text on meteorological phenomena #TAUTHOR_TAG , meant for primary school students .', 'The text gradually introduces concepts related to precipitation, and explains them.', 'Its nature makes it appropriate for the semantic analysis task in an incremental approach.', 'The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text.']","['We work with a semi-technical text on meteorological phenomena #TAUTHOR_TAG , meant for primary school students .', 'The text gradually introduces concepts related to precipitation, and explains them.', 'Its nature makes it appropriate for the semantic analysis task in an incremental approach.', 'The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text.']","['We work with a semi-technical text on meteorological phenomena #TAUTHOR_TAG , meant for primary school students .', 'The text gradually introduces concepts related to precipitation, and explains them.', 'Its nature makes it appropriate for the semantic analysis task in an incremental approach.', 'The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text.']","['We work with a semi-technical text on meteorological phenomena #TAUTHOR_TAG , meant for primary school students .', 'The text gradually introduces concepts related to precipitation, and explains them.', 'Its nature makes it appropriate for the semantic analysis task in an incremental approach.', 'The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text.']",5
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']",0
"['To process a pair P not encountered previously, the system builds a graph centered on the main element (often the head) of P .', ""This idea was inspired by #TAUTHOR_TAG , who used a list of arguments surrounding the main verb together with the verb 's subcategorization information and previously processed examples to analyse semantic roles ( case relations ) ."", 'recent approaches, is translated into features Frame']","['To process a pair P not encountered previously, the system builds a graph centered on the main element (often the head) of P .', ""This idea was inspired by #TAUTHOR_TAG , who used a list of arguments surrounding the main verb together with the verb 's subcategorization information and previously processed examples to analyse semantic roles ( case relations ) ."", 'recent approaches, is translated into features']","['To process a pair P not encountered previously, the system builds a graph centered on the main element (often the head) of P .', ""This idea was inspired by #TAUTHOR_TAG , who used a list of arguments surrounding the main verb together with the verb 's subcategorization information and previously processed examples to analyse semantic roles ( case relations ) ."", 'recent approaches, syntactic information is translated into features Frame']","['To process a pair P not encountered previously, the system builds a graph centered on the main element (often the head) of P .', ""This idea was inspired by #TAUTHOR_TAG , who used a list of arguments surrounding the main verb together with the verb 's subcategorization information and previously processed examples to analyse semantic roles ( case relations ) ."", '']",4
"['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #TAUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #AUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #TAUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #AUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #TAUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #AUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #TAUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #AUTHOR_TAG .']",0
"['', '', '', '', '', '', 'The list , a synthesis of a number of relation lists cited in the literature , has been designed to be general , domainindependent #TAUTHOR_TAG a ) .']","['', '', '', '', '', '', 'The list , a synthesis of a number of relation lists cited in the literature , has been designed to be general , domainindependent #TAUTHOR_TAG a ) .']","['', '', '', '', '', '', 'The list , a synthesis of a number of relation lists cited in the literature , has been designed to be general , domainindependent #TAUTHOR_TAG a ) .']","['', '', '', '', '', '', 'The list , a synthesis of a number of relation lists cited in the literature , has been designed to be general , domainindependent #TAUTHOR_TAG a ) .']",4
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #TAUTHOR_TAG or the system #AUTHOR_TAG .', '', 'sem relations designed']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #TAUTHOR_TAG or the system #AUTHOR_TAG .', '', 'semantic relations designed']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #TAUTHOR_TAG or the system #AUTHOR_TAG .', '', 'semantic relations are designed']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #TAUTHOR_TAG or the system #AUTHOR_TAG .', '', '']",0
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']",0
"['In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts.', 'It helps them build complex knowledge bases by combining components : events , entities and modifiers #TAUTHOR_TAG .', ""The system's interface facilitates the expert's task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary.""]","['In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts.', 'It helps them build complex knowledge bases by combining components : events , entities and modifiers #TAUTHOR_TAG .', ""The system's interface facilitates the expert's task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary.""]","['In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts.', 'It helps them build complex knowledge bases by combining components : events , entities and modifiers #TAUTHOR_TAG .', ""The system's interface facilitates the expert's task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary.""]","['In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts.', 'It helps them build complex knowledge bases by combining components : events , entities and modifiers #TAUTHOR_TAG .', ""The system's interface facilitates the expert's task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary.""]",0
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #TAUTHOR_TAG .', 'systemsoun ).', 'Lists of semantic relations are designed to capture salient domain']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #TAUTHOR_TAG .', 'systems noun ).', 'Lists of semantic relations are designed to capture salient domain']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #TAUTHOR_TAG .', 'Such systemsoun phrases #AUTHOR_TAG ).', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #TAUTHOR_TAG .', '', 'Lists of semantic relations are designed to capture salient domain information.']",0
"['ing is essential to elements meaning inter', 'This an idea', 'The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century BC and the work', 'He was a grammarian who analysed Sanskrit #TAUTHOR_TAG .', 'resur', '']","['analysing is essential to elements meaning', 'This an idea.', 'The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century and the work', 'He was a grammarian who analysed Sanskrit #TAUTHOR_TAG .', 'resurfaced', '']","['it is essential to elements meaning inter', 'This', 'The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century B.C. and the work', 'He was a grammarian who analysed Sanskrit #TAUTHOR_TAG .', 'resur', '']","['', '', 'The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century B.C. and the work of Panini1 .', 'He was a grammarian who analysed Sanskrit #TAUTHOR_TAG .', '', '']",0
"['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']",0
"['', 'gram notion is the basis for semantic relations #AUTHOR_TAG', 'nière (1959), who proposes grouping verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants -for example, agent or instrument -to such grammatical elements as subject, direct object, indirect object.', 'This idea was expanded to include nouns and their modifiers through verb nominalizations #TAUTHOR_TAG .']","['', 'notion is the basis for semantic relations #AUTHOR_TAG', 'Tesnière (1959), who proposes grouping verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants -for example, agent or instrument -to such grammatical elements as subject, direct object, indirect object.', 'This idea was expanded to include nouns and their modifiers through verb nominalizations #TAUTHOR_TAG .']","['', 'is the basis for semantic relations #AUTHOR_TAG .', 'nière (1959), who proposes a grouping verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants -for example, agent or instrument -to such grammatical elements as subject, direct object, indirect object.', 'This idea was expanded to include nouns and their modifiers through verb nominalizations #TAUTHOR_TAG .']","['', '', 'Tesnière (1959), who proposes a grouping of verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants -for example, agent or instrument -to such grammatical elements as subject, direct object, indirect object.', 'This idea was expanded to include nouns and their modifiers through verb nominalizations #TAUTHOR_TAG .']",0
"['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']",0
"['The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information , DIPETT #TAUTHOR_TAG .', 'parser Prolog', 'relations', '']","['The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information , DIPETT #TAUTHOR_TAG .', 'parser, Prolog,', 'relations', '']","['The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information , DIPETT #TAUTHOR_TAG .', 'Prolog', 'ical relations', '']","['The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information , DIPETT #TAUTHOR_TAG .', '', '', '']",5
"['Some methods of semantic relation analysis rely on predefined templates with information from', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #AUTHOR_TAG ; noun phrases in #TAUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates with information from', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #AUTHOR_TAG ; noun phrases in #TAUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates with information from', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #AUTHOR_TAG ; noun phrases in #TAUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #AUTHOR_TAG ; noun phrases in #TAUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']",0
"['is to.', '', 'The chronicled endeavour to text elements organise', 'a grammariananskrit #AUTHOR_TAG', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['is to', '', 'The chronicled endeavour to text elements organise', 'a grammarian Sanskrit #AUTHOR_TAG', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['it is to.', '', 'The chronicled endeavour to text elements organise', 'a grammariananskrit #AUTHOR_TAG .', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent research in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['', '', '', 'He was a grammarian who analysed Sanskrit #AUTHOR_TAG .', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic role labelling #AUTHOR_TAG .']",0
"['is to.', '', 'The chronicled endeavour to text elements organise', 'a grammariananskrit #AUTHOR_TAG', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['is to', '', 'The chronicled endeavour to text elements organise', 'a grammarian Sanskrit #AUTHOR_TAG', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['it is to.', '', 'The chronicled endeavour to text elements organise', 'a grammariananskrit #AUTHOR_TAG .', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent research in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['', '', '', 'He was a grammarian who analysed Sanskrit #AUTHOR_TAG .', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic role labelling #AUTHOR_TAG .']",0
"['Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text.', 'This design idea was adopted from TANKA #TAUTHOR_TAG b ) .', 'encoded marksubpos', '']","['Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text.', 'This design idea was adopted from TANKA #TAUTHOR_TAG b ) .', 'encoded markers', '']","['Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text.', 'This design idea was adopted from TANKA #TAUTHOR_TAG b ) .', 'encoded marksub', '']","['Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text.', 'This design idea was adopted from TANKA #TAUTHOR_TAG b ) .', '', '']",5
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']",0
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #TAUTHOR_TAG .', ', lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the #AUTHOR_TAG', '', '']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #TAUTHOR_TAG .', 'methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the #AUTHOR_TAG', '', '']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #TAUTHOR_TAG .', 'other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', '', '']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #TAUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', '', '']",0
"['The list of semantic relations with which we work is based on extensive literature study #TAUTHOR_TAG a ) .', 'Three lists of relations for three syntactic levels -inter-clause, intra-clause (case) and nounmodifier relations -were next combined based on syntactic and semantic phenomena.', 'The list is the one used in the experiments', 'relations general ', '', '', '']","['The list of semantic relations with which we work is based on extensive literature study #TAUTHOR_TAG a ) .', 'Three lists of relations for three syntactic levels -inter-clause, intra-clause (case) and nounmodifier relations -were next combined based on syntactic and semantic phenomena.', 'The list is the one used in the experiments', 'relations general 6', '', '', '']","['The list of semantic relations with which we work is based on extensive literature study #TAUTHOR_TAG a ) .', 'Three lists of relations for three syntactic levels -inter-clause, intra-clause (case) and nounmodifier relations -were next combined based on syntactic and semantic phenomena.', 'The resulting list is the one used in the experiments', 'The relations ', '', '', '']","['The list of semantic relations with which we work is based on extensive literature study #TAUTHOR_TAG a ) .', 'Three lists of relations for three syntactic levels -inter-clause, intra-clause (case) and nounmodifier relations -were next combined based on syntactic and semantic phenomena.', 'The resulting list is the one used in the experiments we present in this paper.', '', '', '', '']",5
"['Word reordering between German and English is a complex problem.', 'Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish #TAUTHOR_TAG , we tried to adapt the same approach to the German-English language pair .', 'It turned out that there is a larger variety of long reordering patterns in this case.', 'performed after', '', '', '']","['Word reordering between German and English is a complex problem.', 'Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish #TAUTHOR_TAG , we tried to adapt the same approach to the German-English language pair .', 'It turned out that there is a larger variety of long reordering patterns in this case.', 'performed after', '', '', '']","['Word reordering between German and English is a complex problem.', 'Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish #TAUTHOR_TAG , we tried to adapt the same approach to the German-English language pair .', 'It turned out that there is a larger variety of long reordering patterns in this case.', 'performed after', '', '', '']","['Word reordering between German and English is a complex problem.', 'Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish #TAUTHOR_TAG , we tried to adapt the same approach to the German-English language pair .', 'It turned out that there is a larger variety of long reordering patterns in this case.', '', '', '', '']",4
"['ical phrasebased MT suffers from ambig', '', 'Future research should apply the work of #TAUTHOR_TAG and #AUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['phrase-based MT suffers from', '', 'Future research should apply the work of #TAUTHOR_TAG and #AUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['ical phrase-based MT suffers from', '', 'Future research should apply the work of #TAUTHOR_TAG and #AUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['', '', 'Future research should apply the work of #TAUTHOR_TAG and #AUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']",3
"['Hierarchical phrase-based MT suffers fromurious ambiguity', 'of non', 'Future research should apply the work of #AUTHOR_TAG and #TAUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['Hierarchical phrase-based MT suffers from spurious ambiguity:', 'of', 'Future research should apply the work of #AUTHOR_TAG and #TAUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['Hierarchical phrase-based MT suffers fromurious ambiguity: A', 'of non', 'Future research should apply the work of #AUTHOR_TAG and #TAUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['', '', 'Future research should apply the work of #AUTHOR_TAG and #TAUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']",3
"['In our prior work #TAUTHOR_TAG , we examined whether techniques used for predicting the helpfulness of product reviews #AUTHOR_TAG could be tailored to our peer-review domain , where the definition of helpfulness is largely influenced by the educational context of peer review .', 'While previously we used the average of two expert-provided ratings as our gold standard of peerreview helpfulness 1 , there are other types of helpfulness rating', '', '']","['In our prior work #TAUTHOR_TAG , we examined whether techniques used for predicting the helpfulness of product reviews #AUTHOR_TAG could be tailored to our peer-review domain , where the definition of helpfulness is largely influenced by the educational context of peer review .', 'While previously we used the average of two expert-provided ratings as our gold standard of peer-review helpfulness 1 , there are other types of helpfulness rating', '', '']","['In our prior work #TAUTHOR_TAG , we examined whether techniques used for predicting the helpfulness of product reviews #AUTHOR_TAG could be tailored to our peer-review domain , where the definition of helpfulness is largely influenced by the educational context of peer review .', 'While previously we used the average of two expert-provided ratings as our gold standard of peerreview helpfulness 1 , there are other types of helpfulness rating', '', '']","['In our prior work #TAUTHOR_TAG , we examined whether techniques used for predicting the helpfulness of product reviews #AUTHOR_TAG could be tailored to our peer-review domain , where the definition of helpfulness is largely influenced by the educational context of peer review .', 'While previously we used the average of two expert-provided ratings as our gold standard of peer-review helpfulness 1 , there are other types of helpfulness rating (e.g.', '', '']",2
"['We', 'ary pers', '', '', 'this comparing utilities inness predict those', '( Details of how the average-expert model performs can be found in our prior work #TAUTHOR_TAG . )']","['Weka', 'complementary', '', '', 'this comparing utilities in helpfulness predicting those', '( Details of how the average-expert model performs can be found in our prior work #TAUTHOR_TAG . )']","['We', '', '', '', 'this paper is comparing feature utilities in predict', '( Details of how the average-expert model performs can be found in our prior work #TAUTHOR_TAG . )']","['', '', '', '', '', '( Details of how the average-expert model performs can be found in our prior work #TAUTHOR_TAG . )']",2
"['In selecting features for Korean, we have to ac- count for relatively free word order #AUTHOR_TAG', 'We follow our previous work #TAUTHOR_TAG in our feature choices , using a fiveword window that includes the target stem and two words on either side for context ( see also #AUTHOR_TAG .', '', '', '']","['In selecting features for Korean, we have to ac- count for relatively free word order #AUTHOR_TAG', 'We follow our previous work #TAUTHOR_TAG in our feature choices , using a fiveword window that includes the target stem and two words on either side for context ( see also #AUTHOR_TAG .', '', '', '']","['In selecting features for Korean, we have to ac- count for relatively free word order #AUTHOR_TAG .', 'We follow our previous work #TAUTHOR_TAG in our feature choices , using a fiveword window that includes the target stem and two words on either side for context ( see also #AUTHOR_TAG .', '', '', '']","['In selecting features for Korean, we have to ac- count for relatively free word order #AUTHOR_TAG .', 'We follow our previous work #TAUTHOR_TAG in our feature choices , using a fiveword window that includes the target stem and two words on either side for context ( see also #AUTHOR_TAG .', '', '', '']",2
"['The same annotation scheme as in our previous work on anger detection has been applied , see e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', 'user6-4 angry', 'serv']","['The same annotation scheme as in our previous work on anger detection has been applied , see e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', 'user angry,', 'servings']","['The same annotation scheme as in our previous work on anger detection has been applied , see e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', '-4 angry', '']","['The same annotation scheme as in our previous work on anger detection has been applied , see e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', '', '']",2
"['', '', '', '- doing so until all classes have been merged', 'This process produces a hierarchical clustering of the word types in the corpus , and these clusterings have been found useful in many applications #TAUTHOR_TAG .', '']","['', '', '', 'doing so until all classes have been merged.', 'This process produces a hierarchical clustering of the word types in the corpus , and these clusterings have been found useful in many applications #TAUTHOR_TAG .', '']","['', '', '', '- doing so until all classes have been merged', 'This process produces a hierarchical clustering of the word types in the corpus , and these clusterings have been found useful in many applications #TAUTHOR_TAG .', '']","['', '', '', '', 'This process produces a hierarchical clustering of the word types in the corpus , and these clusterings have been found useful in many applications #TAUTHOR_TAG .', '']",4
"['Following #TAUTHOR_TAG , we also compare the performance of our system with a system using features based on the Brown clusters of the word types in a document .', '']","['Following #TAUTHOR_TAG , we also compare the performance of our system with a system using features based on the Brown clusters of the word types in a document .', '']","['Following #TAUTHOR_TAG , we also compare the performance of our system with a system using features based on the Brown clusters of the word types in a document .', '']","['Following #TAUTHOR_TAG , we also compare the performance of our system with a system using features based on the Brown clusters of the word types in a document .', '']",5
"['In this section we describe in detail the baseline NER system we use.', 'It is inspired by the system described in #TAUTHOR_TAG .', 'Because NER annotations are commonly not nested (for, Army"" is treated as a single entity, instead of organization"") is to a', '']","['In this section we describe in detail the baseline NER system we use.', 'It is inspired by the system described in #TAUTHOR_TAG .', 'Because NER annotations are commonly not nested (for example, Army"" is treated as a single entity, instead of organization Army"") is to a', '']","['In this section we describe in detail the baseline NER system we use.', 'It is inspired by the system described in #TAUTHOR_TAG .', 'Because NER annotations are commonly not nested (for example, is treated as a single entity, instead of it is to', '']","['In this section we describe in detail the baseline NER system we use.', 'It is inspired by the system described in #TAUTHOR_TAG .', '', '']",4
"['', 'generally accepted the semantics of verbs in particular are correlated withag properties', 'exc', '- models basis a implementing our scheme.', 'This choice is inspired by recent work on learning syntactic categories #TAUTHOR_TAG , which successfully utilized such language models to represent word window contexts of target words .', '']","['', 'generally accepted the semantics of verbs in particular are correlated with properties', 'excel', 'models basis a implementing our scheme.', 'This choice is inspired by recent work on learning syntactic categories #TAUTHOR_TAG , which successfully utilized such language models to represent word window contexts of target words .', '']","['', 'accepted the semantics of verbs in particular are correlated withagmatic properties', 'exc', 'the basis a concrete model implementing our scheme.', 'This choice is inspired by recent work on learning syntactic categories #TAUTHOR_TAG , which successfully utilized such language models to represent word window contexts of target words .', '']","['', 'It is generally accepted that the semantics of verbs in particular are correlated with their syntagmatic properties #AUTHOR_TAG .', '', '', 'This choice is inspired by recent work on learning syntactic categories #TAUTHOR_TAG , which successfully utilized such language models to represent word window contexts of target words .', '']",4
"['of as weather structured or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #TAUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry orric.']","['of as weather structured or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #TAUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.']","['of as weather reports structured or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #TAUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry orric.']","['', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #TAUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'In these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.']",1
"['Our motivation for generation of material for language education exists in work such as #AUTHOR_TAG and #TAUTHOR_TAG , which deal with automatic generation of classic fill in the blank questions .', 'Our work is naturally complementary to these efforts, as their methods require a corpus of in-vocab text to serve as seed sentences.']","['Our motivation for generation of material for language education exists in work such as #AUTHOR_TAG and #TAUTHOR_TAG , which deal with automatic generation of classic fill in the blank questions .', 'Our work is naturally complementary to these efforts, as their methods require a corpus of in-vocab text to serve as seed sentences.']","['Our motivation for generation of material for language education exists in work such as #AUTHOR_TAG and #TAUTHOR_TAG , which deal with automatic generation of classic fill in the blank questions .', 'Our work is naturally complementary to these efforts, as their methods require a corpus of in-vocab text to serve as seed sentences.']","['Our motivation for generation of material for language education exists in work such as #AUTHOR_TAG and #TAUTHOR_TAG , which deal with automatic generation of classic fill in the blank questions .', 'Our work is naturally complementary to these efforts, as their methods require a corpus of in-vocab text to serve as seed sentences.']",4
"['of ofative as structured or #AUTHOR_TAG which generates descriptions of objects', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #TAUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'sem are sometimes also introduced that responses to previous lines of or']","['of of as structured or #AUTHOR_TAG which generates descriptions of objects', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #TAUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'semantic are sometimes also introduced that responses to previous lines of or']","['of of as structured or #AUTHOR_TAG which generates descriptions of objects', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #TAUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'sem are sometimes also introduced that seek responses to previous lines of or']","['', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #TAUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'In these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.']",1
"['weather or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan #TAUTHOR_TAG , where specified meter or rhyme schemes are enforced .', 'papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry orric.']","['weather or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan #TAUTHOR_TAG , where specified meter or rhyme schemes are enforced .', 'papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.']","['weather reports or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan #TAUTHOR_TAG , where specified meter or rhyme schemes are enforced .', 'these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry orric.']","['', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan #TAUTHOR_TAG , where specified meter or rhyme schemes are enforced .', 'In these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.']",1
"['a character n- , is most and followed by many', '', 'presence a all diction experiments', 'of wordsL): Instead of using the raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'We use length as the only feature to train a decision tree for each and use the nodes the', '']","['a character , is most and followed by many', '', 'presence a all dictionaries experiments.', 'of words (L): Instead of using the raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'We use length as the only feature to train a decision tree for each and use the nodes the', '']","['a character n- , is most and followed by', '', 'presence a features all available dictionaries', 'of wordsL): Instead of using the raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'We use length as the only feature to train a decision tree for each fold and use the nodes the tree', '']","['', '', '', '3. Length of words (L): Instead of using the raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'We use length as the only feature to train a decision tree for each fold and use the nodes obtained from the tree to create boolean features.', '']",2
"['with a character n-- approach , which is most common and followed by many language identification', '', 'ence in DictionariesD): We use presence in a dictionary as a features for all available dictionaries in previous experiments.', 'raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'the only', '']","['with a character n-gram-based approach , which is most common and followed by many language identification', '', 'Presence in Dictionaries (D): We use presence in a dictionary as a features for all available dictionaries in previous experiments.', 'raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'the only', '']","['with a character n--based approach , which is most common and followed by many language identification researchers.', '', 'in DictionariesD): We use presence in a dictionary as a features for all available dictionaries in previous experiments.', 'raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'the only feature', '']","['', '', '2. Presence in Dictionaries (D): We use presence in a dictionary as a features for all available dictionaries in previous experiments.', 'raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', '', '']",2
"['The shape-based metric.', ""The only disambiguation metric that we used in our previous work #TAUTHOR_TAG b ) was the shape-based metric , according to which the `` best '' trees are those that are skewed to the right ."", 'The explanation for this metric is that text processing is, essentially, a left-to-right process.', 'In many genres, people write texts so that the most important ideas go first, both at the paragraph and at the text', 'the', '(see #AUTHOR_TAG c)']","['The shape-based metric.', ""The only disambiguation metric that we used in our previous work #TAUTHOR_TAG b ) was the shape-based metric , according to which the `` best '' trees are those that are skewed to the right ."", 'The explanation for this metric is that text processing is, essentially, a left-to-right process.', 'In many genres, people write texts so that the most important ideas go first, both at the paragraph and at the text', 'the', '(see #AUTHOR_TAG c)']","['The shape-based metric.', ""The only disambiguation metric that we used in our previous work #TAUTHOR_TAG b ) was the shape-based metric , according to which the `` best '' trees are those that are skewed to the right ."", 'The explanation for this metric is that text processing is, essentially, a left-to-right process.', 'In many genres, people write texts so that the most important ideas go first, both at the paragraph and at the text levels.', 'the', '(see #AUTHOR_TAG c)']","['The shape-based metric.', ""The only disambiguation metric that we used in our previous work #TAUTHOR_TAG b ) was the shape-based metric , according to which the `` best '' trees are those that are skewed to the right ."", 'The explanation for this metric is that text processing is, essentially, a left-to-right process.', 'In many genres, people write texts so that the most important ideas go first, both at the paragraph and at the text levels.', '', '']",2
"['', '', 'is', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', 'is', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']",0
"['However, a major obstacle to this approach is the lack of parallel corpora for model training.', 'Only a few such corpora exist , including the Hansard English-French corpus and the HKUST EnglishChinese corpus #TAUTHOR_TAG .', 'In this paper, we will describe a method which automatically searches for parallel texts on the Web.', '']","['However, a major obstacle to this approach is the lack of parallel corpora for model training.', 'Only a few such corpora exist , including the Hansard English-French corpus and the HKUST EnglishChinese corpus #TAUTHOR_TAG .', 'In this paper, we will describe a method which automatically searches for parallel texts on the Web.', '']","['However, a major obstacle to this approach is the lack of parallel corpora for model training.', 'Only a few such corpora exist , including the Hansard English-French corpus and the HKUST EnglishChinese corpus #TAUTHOR_TAG .', 'In this paper, we will describe a method which automatically searches for parallel texts on the Web.', '']","['However, a major obstacle to this approach is the lack of parallel corpora for model training.', 'Only a few such corpora exist , including the Hansard English-French corpus and the HKUST EnglishChinese corpus #TAUTHOR_TAG .', 'In this paper, we will describe a method which automatically searches for parallel texts on the Web.', '']",0
"['', '', 'parallel is', 'A number of alignment techniques have been proposed , varying from statistical methods #AUTHOR_TAG to lexical methods #TAUTHOR_TAG .', 'The we adopted', '', '', '', '', '']","['', '', 'parallel is', 'A number of alignment techniques have been proposed , varying from statistical methods #AUTHOR_TAG to lexical methods #TAUTHOR_TAG .', 'The we adopted', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #AUTHOR_TAG to lexical methods #TAUTHOR_TAG .', 'The method we adopted is', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #AUTHOR_TAG to lexical methods #TAUTHOR_TAG .', '', '', '', '', '', '']",0
"['Beside HTML markups, other criteria may also be incorporated.', 'For example , it would be helpful to consider strong correspondence between certain English and Chinese words , as in #TAUTHOR_TAG .', 'We hope to implement such correspondences in our future research.']","['Beside HTML markups, other criteria may also be incorporated.', 'For example , it would be helpful to consider strong correspondence between certain English and Chinese words , as in #TAUTHOR_TAG .', 'We hope to implement such correspondences in our future research.']","['Beside HTML markups, other criteria may also be incorporated.', 'For example , it would be helpful to consider strong correspondence between certain English and Chinese words , as in #TAUTHOR_TAG .', 'We hope to implement such correspondences in our future research.']","['Beside HTML markups, other criteria may also be incorporated.', 'For example , it would be helpful to consider strong correspondence between certain English and Chinese words , as in #TAUTHOR_TAG .', 'We hope to implement such correspondences in our future research.']",3
"['', '', 'is', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', 'is', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']",0
"['we with A Atl- hint', 'Figure 4 shows the architecture of Atlas-Andes; any other system built with APE look similar.', ""Robust natural language understanding in Atlas-Andes is provided by RosÃ© 's CARMEL system ( RosÃ© 2000 ) ; it uses the spelling correction algorithm devised by #TAUTHOR_TAG .""]","['we with APE hints', 'Figure 4 shows the architecture of Atlas-Andes; any other system built with APE look similar.', ""Robust natural language understanding in Atlas-Andes is provided by RosÃ© 's CARMEL system ( RosÃ© 2000 ) ; it uses the spelling correction algorithm devised by #TAUTHOR_TAG .""]","['with A', 'Figure 4 shows the architecture of Atlas-Andes; any other system built with APE would look similar.', ""Robust natural language understanding in Atlas-Andes is provided by RosÃ© 's CARMEL system ( RosÃ© 2000 ) ; it uses the spelling correction algorithm devised by #TAUTHOR_TAG .""]","['', 'Figure 4 shows the architecture of Atlas-Andes; any other system built with APE would look similar.', ""Robust natural language understanding in Atlas-Andes is provided by RosÃ© 's CARMEL system ( RosÃ© 2000 ) ; it uses the spelling correction algorithm devised by #TAUTHOR_TAG .""]",5
"[""2 See #TAUTHOR_TAG for how MIMIC 's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation .""]","[""2 See #TAUTHOR_TAG for how MIMIC 's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation .""]","[""2 See #TAUTHOR_TAG for how MIMIC 's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation .""]","[""2 See #TAUTHOR_TAG for how MIMIC 's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation .""]",0
"['The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems ( e.g. , ( Bennacef et at. , 1996 ; #TAUTHOR_TAG ) .', 'an act to sol the', '', '', '', '']","['The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems ( e.g. , ( Bennacef et at. , 1996 ; #TAUTHOR_TAG ) .', 'an act to solicit the', '', '', '', '']","['The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems ( e.g. , ( Bennacef et at. , 1996 ; #TAUTHOR_TAG ) .', 'to sol', '', '', '', '']","['The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems ( e.g. , ( Bennacef et at. , 1996 ; #TAUTHOR_TAG ) .', '', '', '', '', '']",1
"['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'initiative models contribution to domain/problemsolving goals, initiative the- ', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'initiative models contribution to domain/problemsolving goals, initiative the', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'task initiative models contribution to domain/problemsolving goals, dialogue initiative ', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', '', '']",0
"['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'initiative models contribution to domain/problemsolving goals, initiative the- ', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'initiative models contribution to domain/problemsolving goals, initiative the', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'task initiative models contribution to domain/problemsolving goals, dialogue initiative ', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', '', '']",0
"['We conducted two experiments to evaluate MIMICs automatic adaptation capabilities.', 'We compared MIMIC with two control systems: MIM- a nonadapt mixed-init version of MIMIC that resembles the behavior of many existing dialogue systems.', 'In this section we summarize these experiments and their results.', 'A companion paper describes the evaluation process and results in further detail #TAUTHOR_TAG .', 'Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information.', '', '', '']","[""We conducted two experiments to evaluate MIMIC's automatic adaptation capabilities."", 'We compared MIMIC with two control systems: MIMIC-MI, a nonadaptive mixed-initiative version of MIMIC that resembles the behavior of many existing dialogue systems.', 'In this section we summarize these experiments and their results.', 'A companion paper describes the evaluation process and results in further detail #TAUTHOR_TAG .', 'Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information.', '', '', '']","['We conducted two experiments to evaluate MIMICs automatic adaptation capabilities.', 'We compared MIMIC with two control systems: MIM- a nonadaptive mixed-initiative version of MIMIC that resembles the behavior of many existing dialogue systems.', 'In this section we summarize these experiments and their results.', 'A companion paper describes the evaluation process and results in further detail #TAUTHOR_TAG .', 'Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information.', '', '', '']","[""We conducted two experiments to evaluate MIMIC's automatic adaptation capabilities."", 'We compared MIMIC with two control systems: MIMIC-SI, a system-initiative version of MIMIC in which the system retains both initiatives throughout the dialogue, and MIMIC-MI, a nonadaptive mixed-initiative version of MIMIC that resembles the behavior of many existing dialogue systems.', 'In this section we summarize these experiments and their results.', 'A companion paper describes the evaluation process and results in further detail #TAUTHOR_TAG .', 'Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information.', '', '', '']",2
"['5An alternative strategy to step ( 4 ) is to perform a database lookup based on the ambiguous query and summarize the results #TAUTHOR_TAG , which we leave for future work .']","['5An alternative strategy to step ( 4 ) is to perform a database lookup based on the ambiguous query and summarize the results #TAUTHOR_TAG , which we leave for future work .']","['5An alternative strategy to step ( 4 ) is to perform a database lookup based on the ambiguous query and summarize the results #TAUTHOR_TAG , which we leave for future work .']","['5An alternative strategy to step ( 4 ) is to perform a database lookup based on the ambiguous query and summarize the results #TAUTHOR_TAG , which we leave for future work .']",3
"['We conducted two experiments to evaluate MICs automatic adaptation capabilities', 'We compared MIC with two control systems', '', '', '', '', ', a number of performance features , largely based on the PARADISE dialogue evaluation scheme #TAUTHOR_TAG , were automatically logged , derived , or manually annotated .', '']","[""We conducted two experiments to evaluate MIMIC's automatic adaptation capabilities."", 'We compared MIMIC with two control systems:', '', '', '', '', ', a number of performance features , largely based on the PARADISE dialogue evaluation scheme #TAUTHOR_TAG , were automatically logged , derived , or manually annotated .', '']","['We conducted two experiments to evaluate MICs automatic adaptation capabilities.', 'We compared MIC with two control systems', '', '', '', '', ', a number of performance features , largely based on the PARADISE dialogue evaluation scheme #TAUTHOR_TAG , were automatically logged , derived , or manually annotated .', '']","[""We conducted two experiments to evaluate MIMIC's automatic adaptation capabilities."", '', '', '', '', '', 'Furthermore , a number of performance features , largely based on the PARADISE dialogue evaluation scheme #TAUTHOR_TAG , were automatically logged , derived , or manually annotated .', '']",5
"['', 'The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -- this is similar to the goals of the MELISSA project #TAUTHOR_TAG .', 'It is intended to both speed the development of SLSs and to localize the speech-specific code within the application.', 'JAVOX allows developers to add speechfaces']","['', 'The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -- this is similar to the goals of the MELISSA project #TAUTHOR_TAG .', 'It is intended to both speed the development of SLSs and to localize the speech-specific code within the application.', 'JAVOX allows developers to add speech interfaces']","['', 'The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -- this is similar to the goals of the MELISSA project #TAUTHOR_TAG .', 'It is intended to both speed the development of SLSs and to localize the speech-specific code within the application.', 'JAVOX allows developers to add speech interfaces']","['', 'The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -- this is similar to the goals of the MELISSA project #TAUTHOR_TAG .', 'It is intended to both speed the development of SLSs and to localize the speech-specific code within the application.', '']",1
"['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #AUTHOR_TAG hua Chen and Chen, 94; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds , a key point in bilingual applications #TAUTHOR_TAG Lin , 99 ) .', 'Fur', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #AUTHOR_TAG hua Chen and Chen, 94; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds , a key point in bilingual applications #TAUTHOR_TAG Lin , 99 ) .', 'Furuse', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #AUTHOR_TAG hua Chen and Chen, 94; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds , a key point in bilingual applications #TAUTHOR_TAG Lin , 99 ) .', 'Fur', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #AUTHOR_TAG hua Chen and Chen, 94; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds , a key point in bilingual applications #TAUTHOR_TAG Lin , 99 ) .', '', '', '', '']",0
"['Finding relevant units in a text has been explored in many areas of natural language processing.', '', '', 'This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; #TAUTHOR_TAG .']","['Finding relevant units in a text has been explored in many areas of natural language processing.', '', '', 'This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; #TAUTHOR_TAG .']","['Finding relevant units in a text has been explored in many areas of natural language processing.', '', '', 'This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; #TAUTHOR_TAG .']","['Finding relevant units in a text has been explored in many areas of natural language processing.', '', '', 'This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; #TAUTHOR_TAG .']",0
"['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #TAUTHOR_TAG ; hua Chen and Chen , 94 ; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds, a key point in bilingual applications #AUTHOR_TAG Lin, 99).', '', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #TAUTHOR_TAG ; hua Chen and Chen , 94 ; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds, a key point in bilingual applications #AUTHOR_TAG Lin, 99).', '', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #TAUTHOR_TAG ; hua Chen and Chen , 94 ; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds, a key point in bilingual applications #AUTHOR_TAG Lin, 99).', '', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #TAUTHOR_TAG ; hua Chen and Chen , 94 ; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds, a key point in bilingual applications #AUTHOR_TAG Lin, 99).', '', '', '', '']",5
"['The speech and language processing architecture is based on that of the SRI CommandTalk system #TAUTHOR_TAG ; Stent et a. , 1999 ) .', 'The system a aboutd Open', '', '', '', '', '']","['The speech and language processing architecture is based on that of the SRI CommandTalk system #TAUTHOR_TAG ; Stent et a. , 1999 ) .', 'The system a about SPd Open', '', '', '', '', '']","['The speech and language processing architecture is based on that of the SRI CommandTalk system #TAUTHOR_TAG ; Stent et a. , 1999 ) .', 'The system a suite about', '', '', '', '', '']","['The speech and language processing architecture is based on that of the SRI CommandTalk system #TAUTHOR_TAG ; Stent et a. , 1999 ) .', '', '', '', '', '', '']",5
"['', '', 'recent on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot #AUTHOR_TAG and NCARArs InterBOT project #AUTHOR_TAG', '.', 'CornmandTalk #TAUTHOR_TAG , Circuit Fix-It Shop #AUTHOR_TAG and TRAINS-96 #AUTHOR_TAG are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents .', '', '', '', '', '']","['', '', 'recent on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot #AUTHOR_TAG and NCARArs InterBOT project #AUTHOR_TAG', 'task.', 'CornmandTalk #TAUTHOR_TAG , Circuit Fix-It Shop #AUTHOR_TAG and TRAINS-96 #AUTHOR_TAG are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents .', '', '', '', '', '']","['', '', 'recent work on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot #AUTHOR_TAG and NCARArs InterBOT project #AUTHOR_TAG .', '', 'CornmandTalk #TAUTHOR_TAG , Circuit Fix-It Shop #AUTHOR_TAG and TRAINS-96 #AUTHOR_TAG are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents .', '', '', '', '', '']","['', '', 'More recent work on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot #AUTHOR_TAG and NCARArs InterBOT project #AUTHOR_TAG .', '', 'CornmandTalk #TAUTHOR_TAG , Circuit Fix-It Shop #AUTHOR_TAG and TRAINS-96 #AUTHOR_TAG are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents .', '', '', '', '', '']",0
"['', '', '', '', '', 'isation toward a common format is required.', 'This is done with transducers (Kaplan and]).', 'ech', '(ceptiveates', '', 'We do this with a first-order HMM part-ofspeech tagger ( Merialdo #TAUTHOR_TAG .', '']","['', '', '', '', '', 'normalisation toward a common format is required.', 'This is done with transducers (Kaplan and', '', '(deceptive', '', 'We do this with a first-order HMM part-ofspeech tagger ( Merialdo #TAUTHOR_TAG .', '']","['', '', '', '', '', 'toward a common format is required.', 'This is done with transducers (Kaplan and', '', '(ceptiveates', '', 'We do this with a first-order HMM part-ofspeech tagger ( Merialdo #TAUTHOR_TAG .', '']","['', '', '', '', '', '', 'This is done with transducers (Kaplan and Kay, [10]).', '', '', '', 'We do this with a first-order HMM part-ofspeech tagger ( Merialdo #TAUTHOR_TAG .', '']",5
"['', '', 'boundaries the is processed into a- by an alignment', 'This alignment is done on the basis of both length ( Gale and Church #TAUTHOR_TAG and a notion of cognateness ( Simard [ 16 ] )', '', 'common format', '', '', '', '', '', '']","['', '', 'boundaries the is processed into a by an alignment', 'This alignment is done on the basis of both length ( Gale and Church #TAUTHOR_TAG and a notion of cognateness ( Simard [ 16 ] )', '', 'common format', '', '', '', '', '', '']","['', '', 'sentence boundaries the text is processed into a- by', 'This alignment is done on the basis of both length ( Gale and Church #TAUTHOR_TAG and a notion of cognateness ( Simard [ 16 ] )', '', 'a common format', '', '', '', '', '', '']","['', '', '', 'This alignment is done on the basis of both length ( Gale and Church #TAUTHOR_TAG and a notion of cognateness ( Simard [ 16 ] ) .', '', '', '', '', '', '', '', '']",5
"['â\x80¢ Before indexing the text , we process it with Textract #TAUTHOR_TAG , which performs lemmatization , and discovers proper names and technical terms .', '', '']","['â\x80¢ Before indexing the text , we process it with Textract #TAUTHOR_TAG , which performs lemmatization , and discovers proper names and technical terms .', '', '']","['â\x80¢ Before indexing the text , we process it with Textract #TAUTHOR_TAG , which performs lemmatization , and discovers proper names and technical terms .', '', '']","['â\x80¢ Before indexing the text , we process it with Textract #TAUTHOR_TAG , which performs lemmatization , and discovers proper names and technical terms .', '', '']",5
"['MorphAna: Morphological Analysis provided by sines yields the word stems of nouns, verbs and adjectives, as well as the full forms of unknown words.', 'We are using a lexicon of approx.', '100000 word stems of German #TAUTHOR_TAG .']","['MorphAna: Morphological Analysis provided by sines yields the word stems of nouns, verbs and adjectives, as well as the full forms of unknown words.', 'We are using a lexicon of approx.', '100000 word stems of German #TAUTHOR_TAG .']","['MorphAna: Morphological Analysis provided by sines yields the word stems of nouns, verbs and adjectives, as well as the full forms of unknown words.', 'We are using a lexicon of approx.', '100000 word stems of German #TAUTHOR_TAG .']","['MorphAna: Morphological Analysis provided by sines yields the word stems of nouns, verbs and adjectives, as well as the full forms of unknown words.', 'We are using a lexicon of approx.', '100000 word stems of German #TAUTHOR_TAG .']",5
"['Linguistic preprocessing of text documents is carried out by re-using smes , an information extraction core system for real-world German text processing #TAUTHOR_TAG .', 'The design criterion ofines is to a set of basic we build multVM-', '', '', '', '', '', '', '', '']","['Linguistic preprocessing of text documents is carried out by re-using smes , an information extraction core system for real-world German text processing #TAUTHOR_TAG .', 'The design criterion of sines is to a set of basic, we build', '', '', '', '', '', '', '', '']","['Linguistic preprocessing of text documents is carried out by re-using smes , an information extraction core system for real-world German text processing #TAUTHOR_TAG .', 'The fundamental design criterion ofines is to a set of basic we examined buildVM-', '', '', '', '', '', '', '', '']","['Linguistic preprocessing of text documents is carried out by re-using smes , an information extraction core system for real-world German text processing #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']",5
"['The NP-based QA System.', 'Our implementation of the NP-based QA system uses the Empire noun phrase finder , which is described in detail in #TAUTHOR_TAG .', 'Empire identifies base NPs --non-recursive noun phrases --using a very simple algorithm that matches part-of-speech tag sequences based on a learned noun phrase grammar.', 'The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal .', 'the filter the', '']","['The NP-based QA System.', 'Our implementation of the NP-based QA system uses the Empire noun phrase finder , which is described in detail in #TAUTHOR_TAG .', 'Empire identifies base NPs --non-recursive noun phrases --using a very simple algorithm that matches part-of-speech tag sequences based on a learned noun phrase grammar.', 'The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal .', 'the filter the', '']","['The NP-based QA System.', 'Our implementation of the NP-based QA system uses the Empire noun phrase finder , which is described in detail in #TAUTHOR_TAG .', 'Empire identifies base NPs --non-recursive noun phrases --using a very simple algorithm that matches part-of-speech tag sequences based on a learned noun phrase grammar.', 'The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal #AUTHOR_TAG .', 'the NP filter the application', '']","['The NP-based QA System.', 'Our implementation of the NP-based QA system uses the Empire noun phrase finder , which is described in detail in #TAUTHOR_TAG .', 'Empire identifies base NPs --non-recursive noun phrases --using a very simple algorithm that matches part-of-speech tag sequences based on a learned noun phrase grammar.', 'The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal #AUTHOR_TAG .', '', '']",5
"['ization algorithms will', '', 'Although a number of methods for query-dependent text summarization are beginning to be developed and evaluated in a variety of realistic settings #TAUTHOR_TAG , we again propose the use of vector space methods from IR , which can be easily extended to the summarization task #AUTHOR_TAG :']","['summarization algorithms will', '', 'Although a number of methods for query-dependent text summarization are beginning to be developed and evaluated in a variety of realistic settings #TAUTHOR_TAG , we again propose the use of vector space methods from IR , which can be easily extended to the summarization task #AUTHOR_TAG :']","['will improve', '', 'Although a number of methods for query-dependent text summarization are beginning to be developed and evaluated in a variety of realistic settings #TAUTHOR_TAG , we again propose the use of vector space methods from IR , which can be easily extended to the summarization task #AUTHOR_TAG :']","['', '', 'Although a number of methods for query-dependent text summarization are beginning to be developed and evaluated in a variety of realistic settings #TAUTHOR_TAG , we again propose the use of vector space methods from IR , which can be easily extended to the summarization task #AUTHOR_TAG :']",1
"['The aim of this paper is to give a detailed account of the techniques used in TnT.', ', we present results of the tagger on the NEGRA corpus #AUTHOR_TAG and the Pennbank', 'The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in #TAUTHOR_TAG .', '.']","['The aim of this paper is to give a detailed account of the techniques used in TnT.', 'Additionally, we present results of the tagger on the NEGRA corpus #AUTHOR_TAG and the Penn Treebank', 'The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in #TAUTHOR_TAG .', '.']","['The aim of this paper is to give a detailed account of the techniques used in TnT.', ', we present results of the tagger on the NEGRA corpus #AUTHOR_TAG and the Penn Treebank', 'The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in #TAUTHOR_TAG .', ' #AUTHOR_TAG .']","['The aim of this paper is to give a detailed account of the techniques used in TnT.', 'Additionally, we present results of the tagger on the NEGRA corpus #AUTHOR_TAG and the Penn Treebank #AUTHOR_TAG .', 'The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in #TAUTHOR_TAG .', '']",1
"['', '', '', '', '', '', '', 'According to current tagger comparisons ( van #AUTHOR_TAG , and according to a comparsion of the results presented here with those in #TAUTHOR_TAG , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here .', 'It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both.']","['', '', '', '', '', '', '', 'According to current tagger comparisons ( van #AUTHOR_TAG , and according to a comparsion of the results presented here with those in #TAUTHOR_TAG , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here .', 'It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both.']","['', '', '', '', '', '', '', 'According to current tagger comparisons ( van #AUTHOR_TAG , and according to a comparsion of the results presented here with those in #TAUTHOR_TAG , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here .', 'It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both.']","['', '', '', '', '', '', '', 'According to current tagger comparisons ( van #AUTHOR_TAG , and according to a comparsion of the results presented here with those in #TAUTHOR_TAG , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here .', 'It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both.']",1
"['', ')) and densitylot', 'sem', ""This confirms that although Kozima 's approach #TAUTHOR_TAG is computationally expensive , it does produce more precise segmentation .""]","['', 'and density', 'semantic', ""This confirms that although Kozima 's approach #TAUTHOR_TAG is computationally expensive , it does produce more precise segmentation .""]","['', ')) andlot', 'sem', ""This confirms that although Kozima 's approach #TAUTHOR_TAG is computationally expensive , it does produce more precise segmentation .""]","['', '', '', ""This confirms that although Kozima 's approach #TAUTHOR_TAG is computationally expensive , it does produce more precise segmentation .""]",1
"[""R98 ( , , , , â\x80\x9e ) uses a variant of Kozima 's semantic similarity measure #TAUTHOR_TAG to compute block similarity ."", 'similarity a function of word co- occurrence statistics in given', '', '', '']","[""R98 ( , , , , â\x80\x9e ) uses a variant of Kozima 's semantic similarity measure #TAUTHOR_TAG to compute block similarity ."", 'similarity a function of word co- occurrence statistics in given', '', '', '']","[""R98 ( , , , , â\x80\x9e ) uses a variant of Kozima 's semantic similarity measure #TAUTHOR_TAG to compute block similarity ."", 'Word similarity a function of word co- occurrence statistics in given', '', '', '']","[""R98 ( , , , , â\x80\x9e ) uses a variant of Kozima 's semantic similarity measure #TAUTHOR_TAG to compute block similarity ."", 'Word similarity is a function of word co- occurrence statistics in the given document.', '', '', '']",2
"['In related work, #AUTHOR_TAG describes an ap- proach to packing in which alternative feature structures are represented as packed, distributed disjunctions of feature structure fragments.', 'Although the approach may have potential , the shifting of complex accounting into the unification algorithm is at variance with the findings of #TAUTHOR_TAG , who report large speed-ups from the elimination of disjunction processing during unification .', '']","['In related work, #AUTHOR_TAG describes an ap- proach to packing in which alternative feature structures are represented as packed, distributed disjunctions of feature structure fragments.', 'Although the approach may have potential , the shifting of complex accounting into the unification algorithm is at variance with the findings of #TAUTHOR_TAG , who report large speed-ups from the elimination of disjunction processing during unification .', '']","['In related work, #AUTHOR_TAG describes an ap- proach to packing in which alternative feature structures are represented as packed, distributed disjunctions of feature structure fragments.', 'Although the approach may have potential , the shifting of complex accounting into the unification algorithm is at variance with the findings of #TAUTHOR_TAG , who report large speed-ups from the elimination of disjunction processing during unification .', '']","['In related work, #AUTHOR_TAG describes an ap- proach to packing in which alternative feature structures are represented as packed, distributed disjunctions of feature structure fragments.', 'Although the approach may have potential , the shifting of complex accounting into the unification algorithm is at variance with the findings of #TAUTHOR_TAG , who report large speed-ups from the elimination of disjunction processing during unification .', '']",1
"['we an mathematical in', 'stochsee Section ', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #TAUTHOR_TAG and #AUTHOR_TAG .', 'We leave this for future work.']","['we an mathematical in', 'stochastic (see Section', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #TAUTHOR_TAG and #AUTHOR_TAG .', 'We leave this for future work.']","['an original mathematical argument in', 'stochsee Section 1).', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #TAUTHOR_TAG and #AUTHOR_TAG .', 'We leave this for future work.']","['', '', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #TAUTHOR_TAG and #AUTHOR_TAG .', 'We leave this for future work.']",3
"['we have an mathematical in', 'stochsee Section ', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #AUTHOR_TAG and #TAUTHOR_TAG .', 'We leave this for future work.']","['we have an mathematical in', 'stochastic (see Section', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #AUTHOR_TAG and #TAUTHOR_TAG .', 'We leave this for future work.']","['we have provided an original mathematical argument in', 'stochsee Section 1).', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #AUTHOR_TAG and #TAUTHOR_TAG .', 'We leave this for future work.']","['', '', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #AUTHOR_TAG and #TAUTHOR_TAG .', 'We leave this for future work.']",3
"['Accuracy is not the best measure to assess segmentation quality , therefore we also conducted experiments using the WindowDiff measure as proposed by #TAUTHOR_TAG .', 'WindowDiff returns 0 in case of a perfect segmentation; 1 is the worst possible score.', 'However, it only takes into account segment boundaries and disregards segment types.', '.', '', '', '', '', '', '', 'after']","['Accuracy is not the best measure to assess segmentation quality , therefore we also conducted experiments using the WindowDiff measure as proposed by #TAUTHOR_TAG .', 'WindowDiff returns 0 in case of a perfect segmentation; 1 is the worst possible score.', 'However, it only takes into account segment boundaries and disregards segment types.', '', '', '', '', '', '', '', 'after']","['Accuracy is not the best measure to assess segmentation quality , therefore we also conducted experiments using the WindowDiff measure as proposed by #TAUTHOR_TAG .', 'WindowDiff returns 0 in case of a perfect segmentation; 1 is the worst possible score.', 'However, it only takes into account segment boundaries and disregards segment types.', '', '', '', '', '', '', '', 'after']","['Accuracy is not the best measure to assess segmentation quality , therefore we also conducted experiments using the WindowDiff measure as proposed by #TAUTHOR_TAG .', 'WindowDiff returns 0 in case of a perfect segmentation; 1 is the worst possible score.', 'However, it only takes into account segment boundaries and disregards segment types.', '', '', '', '', '', '', '', '']",5
"['Merony some relations, there is no contradiction when y 1 and y 2 share a meronym, ie. ""part of"" relation.', 'For example, in the set born in(Mozart,•) there is no contradiction between the y values ""Salzburg"" and ""Austria"", but ""Salzburg"" conflicts with ""Vienna"".', 'Although this is only true in cases where y occurs in an upward monotone context #TAUTHOR_TAG , in practice genuine contradictions between y-values sharing a meronym relationship are extremely rare', 'assigned contradictions between meronyms a probability to zero.', 'used']","['Meronyms: some relations, there is no contradiction when y 1 and y 2 share a meronym, i.e. ""part of"" relation.', 'For example, in the set born in(Mozart,•) there is no contradiction between the y values ""Salzburg"" and ""Austria"", but ""Salzburg"" conflicts with ""Vienna"".', 'Although this is only true in cases where y occurs in an upward monotone context #TAUTHOR_TAG , in practice genuine contradictions between y-values sharing a meronym relationship are extremely rare', 'assigned contradictions between meronyms a probability to zero.', 'used']","['Merony some relations, there is no contradiction when y 1 and y 2 share a meronym, ie. ""part of"" relation.', 'For example, in the set born in(Mozart,•) there is no contradiction between the y values ""Salzburg"" and ""Austria"", but ""Salzburg"" conflicts with ""Vienna"".', 'Although this is only true in cases where y occurs in an upward monotone context #TAUTHOR_TAG , in practice genuine contradictions between y-values sharing a meronym relationship are extremely rare .', 'assigned contradictions between meronyms a probability to zero.', 'We used']","['Meronyms: For some relations, there is no contradiction when y 1 and y 2 share a meronym, i.e. ""part of"" relation.', 'For example, in the set born in(Mozart,•) there is no contradiction between the y values ""Salzburg"" and ""Austria"", but ""Salzburg"" conflicts with ""Vienna"".', 'Although this is only true in cases where y occurs in an upward monotone context #TAUTHOR_TAG , in practice genuine contradictions between y-values sharing a meronym relationship are extremely rare .', 'We therefore simply assigned contradictions between meronyms a probability close to zero.', '']",4
"['use', '4', 'We parse each sentence with the Collins parser #TAUTHOR_TAG .', 'Then the document has one big parse tree, is DO']","['use', '', 'We parse each sentence with the Collins parser #TAUTHOR_TAG .', 'Then the document has one big parse tree, is']","['we use', '', 'We parse each sentence with the Collins parser #TAUTHOR_TAG .', 'Then the document has one big parse tree, is DO']","['', '', 'We parse each sentence with the Collins parser #TAUTHOR_TAG .', '']",5
"[' #AUTHOR_TAG , we introduced the �Movie Review Polarity Dataset Enriched with Annotator Rationales.', 'It is based on the dataset of #TAUTHOR_TAG ,9 which consists of 1000 positive and 1000 negative movie reviews , tokenized and divided into 10 folds ( F0 -- F9 ) .', 'experiments use F9 as final blind test set.']","[' #AUTHOR_TAG , we introduced the �Movie Review Polarity Dataset Enriched with Annotator Rationales.�8', 'It is based on the dataset of #TAUTHOR_TAG ,9 which consists of 1000 positive and 1000 negative movie reviews , tokenized and divided into 10 folds ( F0 -- F9 ) .', 'experiments use F9 as final blind test set.']","[' #AUTHOR_TAG , we introduced the �Movie Review Polarity Dataset Enriched with Annotator Rationales.�8', 'It is based on the dataset of #TAUTHOR_TAG ,9 which consists of 1000 positive and 1000 negative movie reviews , tokenized and divided into 10 folds ( F0 -- F9 ) .', 'experiments use F9 as final blind test set.']","[' #AUTHOR_TAG , we introduced the �Movie Review Polarity Dataset Enriched with Annotator Rationales.�8', 'It is based on the dataset of #TAUTHOR_TAG ,9 which consists of 1000 positive and 1000 negative movie reviews , tokenized and divided into 10 folds ( F0 -- F9 ) .', 'All our experiments use F9 as their final blind test set.']",2
"['an', '', '', '', 'We collect substring rationales for a sentiment classification task #TAUTHOR_TAG and use them to obtain significant accuracy improvements for each annotator', '', '']","['', '', '', '', 'We collect substring rationales for a sentiment classification task #TAUTHOR_TAG and use them to obtain significant accuracy improvements for each annotator', '', '']","['', '', '', '', 'We collect substring rationales for a sentiment classification task #TAUTHOR_TAG and use them to obtain significant accuracy improvements for each annotator .', '', '']","['', '', '', '', 'We collect substring rationales for a sentiment classification task #TAUTHOR_TAG and use them to obtain significant accuracy improvements for each annotator .', '', '']",5
"['where f (•) extracts a feature vector from a classified, θ are the corresponding weights of those features, and Z θ (x) def = y ux is a normalizer', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'let { 1 ... v 17744 } be the set of word types with count ≥ 4 in the 2000-document corpus.', '', '', '', '']","['where f (•) extracts a feature vector from a classified document, θ are the corresponding weights of those features, and Z θ (x) def = y u(x, is a normalizer.', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'let {v 1 ..., v 17744 } be the set of word types with count ≥ 4 in the 2000-document corpus.', '', '', '', '']","['where f (•) extracts a feature vector from a classified document, θ are the corresponding weights of those features, and Z θ (x) def = y ux is a normalizer.', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'let V = {v 1 ... v 17744 } be the set of word types with count ≥ 4 in the full 2000-document corpus.', '', '', '', '']","['where f (•) extracts a feature vector from a classified document, θ are the corresponding weights of those features, and Z θ (x) def = y u(x, y) is a normalizer.', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'Specifically, let V = {v 1 , ..., v 17744 } be the set of word types with count ≥ 4 in the full 2000-document corpus.', '', '', '', '']",5
"['', '', '', 'We gather similar words using #TAUTHOR_TAG a ) , mining similar verbs from a comparable-sized parsed corpus , and collecting similar nouns from a broader 10 GB corpus of English text']","['', '', '', 'We gather similar words using #TAUTHOR_TAG a ) , mining similar verbs from a comparable-sized parsed corpus , and collecting similar nouns from a broader 10 GB corpus of English text']","['', '', '', 'We gather similar words using #TAUTHOR_TAG a ) , mining similar verbs from a comparable-sized parsed corpus , and collecting similar nouns from a broader 10 GB corpus of English text .4']","['', '', '', ""We gather similar words using #TAUTHOR_TAG a ) , mining similar verbs from a comparable-sized parsed corpus , and collecting similar nouns from a broader 10 GB corpus of English text .4 We also use #AUTHOR_TAG 's approach to obtaining web-counts .""]",5
"['We also made use of the person-name/instance pairs automatically extracted by #TAUTHOR_TAG .2This data provides counts for pairs such as ""Edwin Moses , hurdler"" and ""William Farley , industrialist.', 'We have features for all concepts and therefore learn their association with each verb.']","['We also made use of the person-name/instance pairs automatically extracted by #TAUTHOR_TAG .2This data provides counts for pairs such as ""Edwin Moses , hurdler"" and ""William Farley , industrialist.', 'We have features for all concepts and therefore learn their association with each verb.']","['We also made use of the person-name/instance pairs automatically extracted by #TAUTHOR_TAG .2This data provides counts for pairs such as ""Edwin Moses , hurdler"" and ""William Farley , industrialist.', 'We have features for all concepts and therefore learn their association with each verb.']","['We also made use of the person-name/instance pairs automatically extracted by #TAUTHOR_TAG .2This data provides counts for pairs such as ""Edwin Moses , hurdler"" and ""William Farley , industrialist.', 'We have features for all concepts and therefore learn their association with each verb.']",5
"['we evaluate D on a common application of selectional preferences choosing the correct antecedent for in', ""We study the cases where a 9Recall that even the #TAUTHOR_TAG system , built on the world 's largest corpus , achieves only 34 % recall ( Table 1 ) ( with only 48 % of positives and 27 % of all pairs previously observed , but see Footnote 5 ) ."", 'the direct object pred', 'pron ante obey', '']","['we evaluate DSP on a common application of selectional preferences: choosing the correct antecedent for in', ""We study the cases where a 9Recall that even the #TAUTHOR_TAG system , built on the world 's largest corpus , achieves only 34 % recall ( Table 1 ) ( with only 48 % of positives and 27 % of all pairs previously observed , but see Footnote 5 ) ."", 'the direct object', 'obey', '']","['we evaluate D on a common application of selectional preferences: choosing the correct antecedent for in', ""We study the cases where a 9Recall that even the #TAUTHOR_TAG system , built on the world 's largest corpus , achieves only 34 % recall ( Table 1 ) ( with only 48 % of positives and 27 % of all pairs previously observed , but see Footnote 5 ) ."", 'the direct object', 'must obey', '']","['Finally, we evaluate DSP on a common application of selectional preferences: choosing the correct antecedent for pronouns in text #AUTHOR_TAG .', ""We study the cases where a 9Recall that even the #TAUTHOR_TAG system , built on the world 's largest corpus , achieves only 34 % recall ( Table 1 ) ( with only 48 % of positives and 27 % of all pairs previously observed , but see Footnote 5 ) ."", '', '', '']",1
"['', 'weights on-rence features (', 'specificityrank verb context', 'The DSP parameters for eat for example, place high weight on features like Pr(n|braise), Pr(n|ration), and Pr(n|garnish).', "" #TAUTHOR_TAG a ) 's similar word list for eat misses these but includes sleep ( ranked 6 ) and sit ( ranked 14 ) , because these have similar subjects to eat ."", '', '']","['', 'weights on features (Section', 'similarityranking verb', 'The DSP parameters for eat, for example, place high weight on features like Pr(n|braise), Pr(n|ration), and Pr(n|garnish).', "" #TAUTHOR_TAG a ) 's similar word list for eat misses these but includes sleep ( ranked 6 ) and sit ( ranked 14 ) , because these have similar subjects to eat ."", '', '']","['', 'on (', '', 'The DSP parameters for eat for example, place high weight on features like Pr(n|braise), Pr(n|ration), and Pr(n|garnish).', "" #TAUTHOR_TAG a ) 's similar word list for eat misses these but includes sleep ( ranked 6 ) and sit ( ranked 14 ) , because these have similar subjects to eat ."", '', '']","['', '', '', 'The DSP parameters for eat, for example, place high weight on features like Pr(n|braise), Pr(n|ration), and Pr(n|garnish).', "" #TAUTHOR_TAG a ) 's similar word list for eat misses these but includes sleep ( ranked 6 ) and sit ( ranked 14 ) , because these have similar subjects to eat ."", '', '']",0
"['DC', '', '', 'search this cor replic', 'not be able to a each example.', 'The similarity-smoothed examples will be undefined if SIMS(w) is empty.', 'Also , the #TAUTHOR_TAG approach will be undefined if the pair is unobserved on the web .', 'As a reasonable default for these cases, we assign them a negative decision.']","['LDC', '', '', 'search this corpus replicable.', 'not be able to a each example.', 'The similarity-smoothed examples will be undefined if SIMS(w) is empty.', 'Also , the #TAUTHOR_TAG approach will be undefined if the pair is unobserved on the web .', 'As a reasonable default for these cases, we assign them a negative decision.']","['', '', '', 'this corpus replic', 'not be able to a score each example.', 'The similarity-smoothed examples will be undefined if SIMS(w) is empty.', 'Also , the #TAUTHOR_TAG approach will be undefined if the pair is unobserved on the web .', 'As a reasonable default for these cases, we assign them a negative decision.']","['', '', '', '', 'not be able to provide a score for each example.', 'The similarity-smoothed examples will be undefined if SIMS(w) is empty.', 'Also , the #TAUTHOR_TAG approach will be undefined if the pair is unobserved on the web .', 'As a reasonable default for these cases, we assign them a negative decision.']",5
"['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'refer this as Pairation', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'refer this as Pairwise', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'We refer this as Pair', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'We refer to this as Pairwise Disambiguation.', '', '']",1
"['The advantage of tuning similarity to the application of interest has been shown previously by #TAUTHOR_TAG .', 'They optimize a few metaparameters separately for the tasks of thesaurus generation and pseudodisambiguation.', '', '']","['The advantage of tuning similarity to the application of interest has been shown previously by #TAUTHOR_TAG .', 'They optimize a few metaparameters separately for the tasks of thesaurus generation and pseudodisambiguation.', '', '']","['The advantage of tuning similarity to the application of interest has been shown previously by #TAUTHOR_TAG .', 'They optimize a few metaparameters separately for the tasks of thesaurus generation and pseudodisambiguation.', '', '']","['The advantage of tuning similarity to the application of interest has been shown previously by #TAUTHOR_TAG .', 'They optimize a few metaparameters separately for the tasks of thesaurus generation and pseudodisambiguation.', '', '']",1
"['', '', '', ""a MI is proportional to #AUTHOR_TAG 's conditional probability scores for pseudodisambiguation of (v, n, n ′ ) triples: Pr(v|n) = Pr(v, n)/Pr(n), which was shown to be a better measure of association than co-occurrence frequency f (v, n)."", 'Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', 'MI was also recently used for inference-rule SPs by #TAUTHOR_TAG .']","['', '', '', ""a MI is proportional to #AUTHOR_TAG 's conditional probability scores for pseudodisambiguation of (v, n, n ′ ) triples: Pr(v|n) = Pr(v, n)/Pr(n), which was shown to be a better measure of association than co-occurrence frequency f (v, n)."", 'Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', 'MI was also recently used for inference-rule SPs by #TAUTHOR_TAG .']","['', '', '', ""is proportional to #AUTHOR_TAG 's conditional probability scores for pseudodisambiguation of (v, n, n ′ ) triples: Pr(v|n) = Pr(v, n)/Pr(n), which was shown to be a better measure of association than co-occurrence frequency f (v, n)."", 'Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', 'MI was also recently used for inference-rule SPs by #TAUTHOR_TAG .']","['', '', '', ""Thus rather than a single training procedure, we can actually partition the examples by predicate, and train a For a fixed verb, MI is proportional to #AUTHOR_TAG 's conditional probability scores for pseudodisambiguation of (v, n, n ′ ) triples: Pr(v|n) = Pr(v, n)/Pr(n), which was shown to be a better measure of association than co-occurrence frequency f (v, n)."", 'Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', 'MI was also recently used for inference-rule SPs by #TAUTHOR_TAG .']",0
"['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'refer this as Pairation', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'refer this as Pairwise', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'We refer this as Pair', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'We refer to this as Pairwise Disambiguation.', '', '']",1
"['Most approaches to SPs generalize from observed predicate-argument pairs to semantically similar ones by modeling the semantic class of the argument, following #AUTHOR_TAG', ', we might have a class Mexican and that the entire class is suitable for eating.', 'Usually , the classes are from WordNet #AUTHOR_TAG , although they can also be inferred from clustering #TAUTHOR_TAG .', 'number Word']","['Most approaches to SPs generalize from observed predicate-argument pairs to semantically similar ones by modeling the semantic class of the argument, following #AUTHOR_TAG', 'example, we might have a class Mexican and that the entire class is suitable for eating.', 'Usually , the classes are from WordNet #AUTHOR_TAG , although they can also be inferred from clustering #TAUTHOR_TAG .', 'number']","['Most approaches to SPs generalize from observed predicate-argument pairs to semantically similar ones by modeling the semantic class of the argument, following #AUTHOR_TAG .', ', we might have a class Mexican Food and that the entire class is suitable for eating.', 'Usually , the classes are from WordNet #AUTHOR_TAG , although they can also be inferred from clustering #TAUTHOR_TAG .', 'a number Word']","['Most approaches to SPs generalize from observed predicate-argument pairs to semantically similar ones by modeling the semantic class of the argument, following #AUTHOR_TAG .', 'For example, we might have a class Mexican Food and learn that the entire class is suitable for eating.', 'Usually , the classes are from WordNet #AUTHOR_TAG , although they can also be inferred from clustering #TAUTHOR_TAG .', '']",0
"['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (and', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', '', '', '', '']",1
"['Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules #TAUTHOR_TAG .', 'Inferences such as ""[X wins Y] ⇒ [X plays Y]"" are only valid for certain argu-ments X and Y.', 'extract sem arguments']","['Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules #TAUTHOR_TAG .', 'Inferences such as ""[X wins Y] ⇒ [X plays Y]"" are only valid for certain argu-ments X and Y.', 'semantic arguments.']","['Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules #TAUTHOR_TAG .', 'Inferences such as ""[X wins Y] ⇒ [X plays Y]"" are only valid for certain argu-ments X and Y.', '']","['Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules #TAUTHOR_TAG .', 'Inferences such as ""[X wins Y] ⇒ [X plays Y]"" are only valid for certain argu-ments X and Y.', '']",0
"['', '', 'to', "" #AUTHOR_TAG compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and #TAUTHOR_TAG a ) 's information-theoretic metric work best ."", '']","['', '', 'to', "" #AUTHOR_TAG compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and #TAUTHOR_TAG a ) 's information-theoretic metric work best ."", '']","['', '', 'to', "" #AUTHOR_TAG compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and #TAUTHOR_TAG a ) 's information-theoretic metric work best ."", '']","['', '', '', "" #AUTHOR_TAG compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and #TAUTHOR_TAG a ) 's information-theoretic metric work best ."", '']",0
"['We parsed the 3 GB AQUAINT corpus #AUTHOR_TAG using Minipar #TAUTHOR_TAG b ) , and collected verb-object and verb-subject frequencies , building an empirical MI model from this data', 'bs and n', '', '']","['We parsed the 3 GB AQUAINT corpus #AUTHOR_TAG using Minipar #TAUTHOR_TAG b ) , and collected verb-object and verb-subject frequencies , building an empirical MI model from this data', 'Verbs and', '', '']","['We parsed the 3 GB AQUAINT corpus #AUTHOR_TAG using Minipar #TAUTHOR_TAG b ) , and collected verb-object and verb-subject frequencies , building an empirical MI model from this data .', 'bs and n', '', '']","['We parsed the 3 GB AQUAINT corpus #AUTHOR_TAG using Minipar #TAUTHOR_TAG b ) , and collected verb-object and verb-subject frequencies , building an empirical MI model from this data .', '', '', '']",5
"['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (and', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', '', '', '', '']",1
"['', 'the positives automaticallypus then extract the predicate-argument pairs that have a statistical association in this data.', 'We measure this association using pointwise Mutual Information ( MI ) #TAUTHOR_TAG .', 'The MI between a verb predicate, v, and its object argument, n, is:']","['', 'the positives, automatically then extract the predicate-argument pairs that have a statistical association in this data.', 'We measure this association using pointwise Mutual Information ( MI ) #TAUTHOR_TAG .', 'The MI between a verb predicate, v, and its object argument, n, is:']","['', 'the positives, automatically then extract the predicate-argument pairs that have a statistical association in this data.', 'We measure this association using pointwise Mutual Information ( MI ) #TAUTHOR_TAG .', 'The MI between a verb predicate, v, and its object argument, n, is:']","['', 'To create the positives, we automatically parse a large corpus, and then extract the predicate-argument pairs that have a statistical association in this data.', 'We measure this association using pointwise Mutual Information ( MI ) #TAUTHOR_TAG .', 'The MI between a verb predicate, v, and its object argument, n, is:']",5
"['every feature feature', '', 'icate will be completely independent', ""For a fixed verb , MI is proportional to #TAUTHOR_TAG 's conditional probability scores for pseudodisambiguation of ( v , n , n â\x80² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) ."", 'Normalizing by Prv)ielding MI) to a constantbs', '']","['every feature feature', '', 'predicate will be completely independent', ""a fixed verb , MI is proportional to #TAUTHOR_TAG 's conditional probability scores for pseudodisambiguation of ( v , n , n â\x80² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) ."", 'Normalizing by Pr(v) (yielding MI) to a constant', '']","['some feature', '', 'will be completely independent', ""a 1For a fixed verb , MI is proportional to #TAUTHOR_TAG 's conditional probability scores for pseudodisambiguation of ( v , n , n â\x80² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) ."", 'Normalizing by Prv)ielding MI) to a constant threshold', '']","['', '', '', ""Thus rather than a single training procedure , we can actually partition the examples by predicate , and train a 1For a fixed verb , MI is proportional to #TAUTHOR_TAG 's conditional probability scores for pseudodisambiguation of ( v , n , n â\x80² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) ."", 'Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', '']",4
"['HOLMES is given the following set of six domainindependent rules , which are similar to the upward monotone rules introduced by #TAUTHOR_TAG .']","['HOLMES is given the following set of six domainindependent rules , which are similar to the upward monotone rules introduced by #TAUTHOR_TAG .']","['HOLMES is given the following set of six domainindependent rules , which are similar to the upward monotone rules introduced by #TAUTHOR_TAG .']","['HOLMES is given the following set of six domainindependent rules , which are similar to the upward monotone rules introduced by #TAUTHOR_TAG .']",1
"['ual Entailment systems are given two textual fragments text and H, and attempt to decide if the meaning of H can be inferred', ""While many approaches have addressed this problem , our work is most closely related to that of #TAUTHOR_TAG , which convert the inputs into logical forms and then attempt to ` prove ' H from T plus a set of axioms ."", '']","['Textual Entailment systems are given two textual fragments, text and H, and attempt to decide if the meaning of H can be inferred', ""While many approaches have addressed this problem , our work is most closely related to that of #TAUTHOR_TAG , which convert the inputs into logical forms and then attempt to ` prove ' H from T plus a set of axioms ."", '']","['ual Entailment systems are given two textual fragments, text T and hypothesis H, and attempt to decide if the meaning of H can be inferred', ""While many approaches have addressed this problem , our work is most closely related to that of #TAUTHOR_TAG , which convert the inputs into logical forms and then attempt to ` prove ' H from T plus a set of axioms ."", '']","['Textual Entailment systems are given two textual fragments, text T and hypothesis H, and attempt to decide if the meaning of H can be inferred from the meaning of T #AUTHOR_TAG .', ""While many approaches have addressed this problem , our work is most closely related to that of #TAUTHOR_TAG , which convert the inputs into logical forms and then attempt to ` prove ' H from T plus a set of axioms ."", '']",1
"['The studies presented by #TAUTHOR_TAG and #AUTHOR_TAG differed in the number of states that they used .', 'evaluated against the reduced tag set of 17 tags developed by #AUTHOR_TAG , while #AUTHOR_TAG evaluated against the full Penn Treebank tag set.', 'ran all our estimators in to Noah with his']","['The studies presented by #TAUTHOR_TAG and #AUTHOR_TAG differed in the number of states that they used .', 'evaluated against the reduced tag set of 17 tags developed by #AUTHOR_TAG , while #AUTHOR_TAG evaluated against the full Penn Treebank tag set.', 'ran all our estimators in to Noah with his']","['The studies presented by #TAUTHOR_TAG and #AUTHOR_TAG differed in the number of states that they used .', 'evaluated against the reduced tag set of 17 tags developed by #AUTHOR_TAG , while #AUTHOR_TAG evaluated against the full Penn Treebank tag set.', 'We ran all our estimators in to Noah Smith with his']","['The studies presented by #TAUTHOR_TAG and #AUTHOR_TAG differed in the number of states that they used .', 'evaluated against the reduced tag set of 17 tags developed by #AUTHOR_TAG , while #AUTHOR_TAG evaluated against the full Penn Treebank tag set.', '']",1
"['As might be expected, our evaluation measures disagree somewhat, but the following broad tendancies seem clear.', 'On small data sets all of the Bayesian estimators strongly outperform EM ( and , to a lesser extent , VB ) with respect to all of our evaluation measures , confirming the results reported in #TAUTHOR_TAG .', 'This perhapsatively']","['As might be expected, our evaluation measures disagree somewhat, but the following broad tendancies seem clear.', 'On small data sets all of the Bayesian estimators strongly outperform EM ( and , to a lesser extent , VB ) with respect to all of our evaluation measures , confirming the results reported in #TAUTHOR_TAG .', 'This perhaps comparatively']","['As might be expected, our evaluation measures disagree somewhat, but the following broad tendancies seem clear.', 'On small data sets all of the Bayesian estimators strongly outperform EM ( and , to a lesser extent , VB ) with respect to all of our evaluation measures , confirming the results reported in #TAUTHOR_TAG .', 'This']","['As might be expected, our evaluation measures disagree somewhat, but the following broad tendancies seem clear.', 'On small data sets all of the Bayesian estimators strongly outperform EM ( and , to a lesser extent , VB ) with respect to all of our evaluation measures , confirming the results reported in #TAUTHOR_TAG .', '']",1
['The resulting training procedure is analogous to the one presented in #AUTHOR_TAG and #TAUTHOR_TAG .'],['The resulting training procedure is analogous to the one presented in #AUTHOR_TAG and #TAUTHOR_TAG .'],['The resulting training procedure is analogous to the one presented in #AUTHOR_TAG and #TAUTHOR_TAG .'],['The resulting training procedure is analogous to the one presented in #AUTHOR_TAG and #TAUTHOR_TAG .'],1
"['', '', '', '', '', '', '', 'm and n are the number of nodes of the two trees ( m > = n ) #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', '', 'm and n are the number of nodes of the two trees ( m > = n ) #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', '', 'm and n are the number of nodes of the two trees ( m > = n ) #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '']",3
"['of future', 'we to explore our estim on other language in to obtain more on its', 'Secondly , as #TAUTHOR_TAG show , marginalizing out the different segmentations during decoding leads to improved performance .', 'including achieving a', '', '']","['of future', 'we to explore our estimator on other language in to obtain more on its', 'Secondly , as #TAUTHOR_TAG show , marginalizing out the different segmentations during decoding leads to improved performance .', 'including achieving a', '', '']","['of', 'we plan to explore our estim on other language pairs in to obtain more evidence on its', 'Secondly , as #TAUTHOR_TAG show , marginalizing out the different segmentations during decoding leads to improved performance .', '', '', '']","['', 'Firstly, we plan to explore our estimator on other language pairs in order to obtain more evidence on its behavior.', 'Secondly , as #TAUTHOR_TAG show , marginalizing out the different segmentations during decoding leads to improved performance .', '', '', '']",3
"['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']",0
"['De #AUTHOR_TAG segmentation the gener lead overitting training', 'Based on this advise ( Moore and #TAUTHOR_TAG exclude the latent segmentation variables and opt for a heuristic training procedure', '', '', '', '']","['(De #AUTHOR_TAG segmentation the generative lead overfitting training', 'Based on this advise ( Moore and #TAUTHOR_TAG exclude the latent segmentation variables and opt for a heuristic training procedure', '', '', '', '']","['De #AUTHOR_TAG that segmentation the generative translation model lead overitting', 'Based on this advise ( Moore and #TAUTHOR_TAG exclude the latent segmentation variables and opt for a heuristic training procedure .', '', '', '', '']","['', 'Based on this advise ( Moore and #TAUTHOR_TAG exclude the latent segmentation variables and opt for a heuristic training procedure .', '', '', '', '']",1
"['we identify a set of,, and training', '', 'variables we wish to consider are an increased number of word ; more flexible regions -- see #TAUTHOR_TAG on learning a state transition diagram for acoustic regions in phone recognition -- and phonological features and syllable boundaries', '', '', '']","['we identify a set of features, variables, and training', '', 'variables we wish to consider are an increased number of word ; more flexible regions -- see #TAUTHOR_TAG on learning a state transition diagram for acoustic regions in phone recognition -- and phonological features and syllable boundaries', '', '', '']","['identify a set of and training methods', '', 'ent variables we wish to consider are an increased number of word classes ; more flexible regions -- see #TAUTHOR_TAG on learning a state transition diagram for acoustic regions in phone recognition -- and phonological features and syllable boundaries .', '', '', '']","['', '', 'Latent variables we wish to consider are an increased number of word classes ; more flexible regions -- see #TAUTHOR_TAG on learning a state transition diagram for acoustic regions in phone recognition -- and phonological features and syllable boundaries .', '', '', '']",0
"['In future work, we would like to identify a set of features, latent variables, and training methods that port well across languages and string-transduction tasks.', 'We would like to use features that look at wide context on the input side , which is inexpensive #TAUTHOR_TAG .', '', '', '', '']","['In future work, we would like to identify a set of features, latent variables, and training methods that port well across languages and string-transduction tasks.', 'We would like to use features that look at wide context on the input side , which is inexpensive #TAUTHOR_TAG .', '', '', '', '']","['In future work, we would like to identify a set of features, latent variables, and training methods that port well across languages and string-transduction tasks.', 'We would like to use features that look at wide context on the input side , which is inexpensive #TAUTHOR_TAG .', '', '', '', '']","['In future work, we would like to identify a set of features, latent variables, and training methods that port well across languages and string-transduction tasks.', 'We would like to use features that look at wide context on the input side , which is inexpensive #TAUTHOR_TAG .', '', '', '', '']",3
"['', '', '', '', '', '', '', '', 'to improve the similarity', ' #TAUTHOR_TAG for example discusses a method where a syntactic parse of the text is performed and the context of a word is modeled using dependency triples .']","['', '', '', '', '', '', '', '', 'to improve the similarity', ' #TAUTHOR_TAG for example discusses a method where a syntactic parse of the text is performed and the context of a word is modeled using dependency triples .']","['', '', '', '', '', '', '', '', 'to improve the similarity estimates.', ' #TAUTHOR_TAG for example discusses a method where a syntactic parse of the text is performed and the context of a word is modeled using dependency triples .']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG for example discusses a method where a syntactic parse of the text is performed and the context of a word is modeled using dependency triples .']",0
"['In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , #TAUTHOR_TAG , to ranking models for Web search applications .']","['In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , #TAUTHOR_TAG , to ranking models for Web search applications .']","['In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , #TAUTHOR_TAG , to ranking models for Web search applications .']","['In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , #TAUTHOR_TAG , to ranking models for Web search applications .']",0
"['As already mentioned in the literature , see for example #TAUTHOR_TAG , knowledge about implicit predicates could be potentially useful for a variety of NLP tasks such as language generation , information extraction , question answering or machine translation .', 'Many applications of semantic relations in NLP are connected to parap', '', '', '', '', '', '', '', '']","['As already mentioned in the literature , see for example #TAUTHOR_TAG , knowledge about implicit predicates could be potentially useful for a variety of NLP tasks such as language generation , information extraction , question answering or machine translation .', 'Many applications of semantic relations in NLP are connected to paraphrasing', '', '', '', '', '', '', '', '']","['As already mentioned in the literature , see for example #TAUTHOR_TAG , knowledge about implicit predicates could be potentially useful for a variety of NLP tasks such as language generation , information extraction , question answering or machine translation .', 'Many applications of semantic relations in NLP are connected to parap', '', '', '', '', '', '', '', '']","['As already mentioned in the literature , see for example #TAUTHOR_TAG , knowledge about implicit predicates could be potentially useful for a variety of NLP tasks such as language generation , information extraction , question answering or machine translation .', 'Many applications of semantic relations in NLP are connected to paraphrasing or query expansion, see for example #AUTHOR_TAG .', '', '', '', '', '', '', '', '']",0
"['', '', '', '', '', 'riv a singleative', 'Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', 'rivaling a single generative', 'Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', 'Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', 'Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set #TAUTHOR_TAG .', '', '', '', '']",1
"['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #TAUTHOR_TAG and products of latent variable grammars #AUTHOR_TAG , despite being a single generative PCFG .', '', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #TAUTHOR_TAG and products of latent variable grammars #AUTHOR_TAG , despite being a single generative PCFG .', '', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #TAUTHOR_TAG and products of latent variable grammars #AUTHOR_TAG , despite being a single generative PCFG .', '', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #TAUTHOR_TAG and products of latent variable grammars #AUTHOR_TAG , despite being a single generative PCFG .', '', '', '', '', '']",1
"['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #AUTHOR_TAG and products of latent variable grammars #TAUTHOR_TAG , despite being a single generative PCFG .', 'Our most model achie an', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #AUTHOR_TAG and products of latent variable grammars #TAUTHOR_TAG , despite being a single generative PCFG .', 'Our most model achieves an', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #AUTHOR_TAG and products of latent variable grammars #TAUTHOR_TAG , despite being a single generative PCFG .', 'Our most achie', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #AUTHOR_TAG and products of latent variable grammars #TAUTHOR_TAG , despite being a single generative PCFG .', '', '', '', '', '']",1
"[""Another possibly critical feature is the 'mention of names'."", ""In multi-party discussion people usually mention each other 's name for the purpose of disentanglement #TAUTHOR_TAG ."", ""In our corpus we found 175 instances where a participant mentions other participant's name."", ""In to these 'Subject of thetopicshift cue can be for a"", '', '', '']","[""Another possibly critical feature is the 'mention of names'."", ""In multi-party discussion people usually mention each other 's name for the purpose of disentanglement #TAUTHOR_TAG ."", ""In our corpus we found 175 instances where a participant mentions other participant's name."", ""In to these, 'Subject of the 'topic-shift cue can be for a"", '', '', '']","[""Another possibly critical feature is the 'mention of names'."", ""In multi-party discussion people usually mention each other 's name for the purpose of disentanglement #TAUTHOR_TAG ."", ""In our corpus we found 175 instances where a participant mentions other participant's name."", ""In to these 'Subject of can be for"", '', '', '']","[""Another possibly critical feature is the 'mention of names'."", ""In multi-party discussion people usually mention each other 's name for the purpose of disentanglement #TAUTHOR_TAG ."", ""In our corpus we found 175 instances where a participant mentions other participant's name."", '', '', '', '']",0
"['we introduced the idea of evaluating induction systems based on their ability to produce useful cluster prototypes.', 'We found that the oldest system #TAUTHOR_TAG yielded the best prototypes , and that using these prototypes gave state-of-the-art performance on WSJ , as well as improvements on nearly all of the non-English corpora .', 'results suggest a for improving']","['we introduced the idea of evaluating induction systems based on their ability to produce useful cluster prototypes.', 'We found that the oldest system #TAUTHOR_TAG yielded the best prototypes , and that using these prototypes gave state-of-the-art performance on WSJ , as well as improvements on nearly all of the non-English corpora .', 'results suggest a for improving']","['we introduced the idea of evaluating induction systems based on their ability to produce useful cluster prototypes.', 'We found that the oldest system #TAUTHOR_TAG yielded the best prototypes , and that using these prototypes gave state-of-the-art performance on WSJ , as well as improvements on nearly all of the non-English corpora .', 'suggest for']","['Finally, we introduced the idea of evaluating induction systems based on their ability to produce useful cluster prototypes.', 'We found that the oldest system #TAUTHOR_TAG yielded the best prototypes , and that using these prototypes gave state-of-the-art performance on WSJ , as well as improvements on nearly all of the non-English corpora .', '']",0
"['We run our techniques on a large set of relations to output a first repository of typed functional relations', '2', 'Future Work: Functionality is one of the several properties a relation can possess.', 'Others include selectional preferences , transitivity #TAUTHOR_TAG , mutual exclusion , symmetry , etc. .', 'These properties are very useful in increasing our understanding about these Open IE relation strings.', 'We believe that the general principles developed in this work, for example, connecting the Open IE knowledge with an existing knowledge resource, will come in very handy in identifying these other properties.']","['We run our techniques on a large set of relations to output a first repository of typed functional relations.', '2', 'Future Work: Functionality is one of the several properties a relation can possess.', 'Others include selectional preferences , transitivity #TAUTHOR_TAG , mutual exclusion , symmetry , etc. .', 'These properties are very useful in increasing our understanding about these Open IE relation strings.', 'We believe that the general principles developed in this work, for example, connecting the Open IE knowledge with an existing knowledge resource, will come in very handy in identifying these other properties.']","['We run our techniques on a large set of relations to output a first repository of typed functional relations.', '', 'Future Work: Functionality is one of the several properties a relation can possess.', 'Others include selectional preferences , transitivity #TAUTHOR_TAG , mutual exclusion , symmetry , etc. .', 'These properties are very useful in increasing our understanding about these Open IE relation strings.', 'We believe that the general principles developed in this work, for example, connecting the Open IE knowledge with an existing knowledge resource, will come in very handy in identifying these other properties.']","['We run our techniques on a large set of relations to output a first repository of typed functional relations.', '', 'Future Work: Functionality is one of the several properties a relation can possess.', 'Others include selectional preferences , transitivity #TAUTHOR_TAG , mutual exclusion , symmetry , etc. .', 'These properties are very useful in increasing our understanding about these Open IE relation strings.', 'We believe that the general principles developed in this work, for example, connecting the Open IE knowledge with an existing knowledge resource, will come in very handy in identifying these other properties.']",0
"['Sophisticated phrase table combination.', 'Finally , we experiment with a method for combining phrase tables proposed in #TAUTHOR_TAG .', 'The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one of the Indonesian-English bi-text', 'built simple concaten', 'The two tables are then merged as all phrase pairs from the one are retained, and to them are added those phrase pairs from the second one that are not present in the first one', '', '']","['Sophisticated phrase table combination.', 'Finally , we experiment with a method for combining phrase tables proposed in #TAUTHOR_TAG .', 'The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one of the Indonesian-English bi-text.', 'built simple concatenation.', 'The two tables are then merged as all phrase pairs from the one are retained, and to them are added those phrase pairs from the second one that are not present in the first one.', '', '']","['Sophisticated phrase table combination.', 'Finally , we experiment with a method for combining phrase tables proposed in #TAUTHOR_TAG .', 'The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one copy of the Indonesian-English bi-text.', 'is built', 'The two tables are then merged as all phrase pairs from the one are retained, and to them are added those phrase pairs from the second one that are not present in the first one.', '', '']","['Sophisticated phrase table combination.', 'Finally , we experiment with a method for combining phrase tables proposed in #TAUTHOR_TAG .', 'The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one copy of the Indonesian-English bi-text.', '', 'The two tables are then merged as follows: all phrase pairs from the first one are retained, and to them are added those phrase pairs from the second one that are not present in the first one.', '', '']",5
"['third relevant line of research rext which for', 'our previous work #TAUTHOR_TAG experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of alltexts was', '', '']","['third relevant line of research reusing which for', 'our previous work #TAUTHOR_TAG experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of all was', '', '']","['A third relevant line of research re which for', 'our previous work #TAUTHOR_TAG experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of all bi-texts was', '', '']","['', 'For example , our previous work #TAUTHOR_TAG experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of all bi-texts was English .', '', '']",1
"['', '', '', '', '', '', '', '', '', 'We found the same number using our previous approach #TAUTHOR_TAG , which is roughly equivalent to our core module .', 'Our approach with similar estimated productivity.']","['', '', '', '', '', '', '', '', '', 'We found the same number using our previous approach #TAUTHOR_TAG , which is roughly equivalent to our core module .', 'Our approach with similar estimated productivity.']","['', '', '', '', '', '', '', '', '', 'We found the same number using our previous approach #TAUTHOR_TAG , which is roughly equivalent to our core module .', 'Our approach with similar estimated productivity.']","['', '', '', '', '', '', '', '', '', 'We found the same number using our previous approach #TAUTHOR_TAG , which is roughly equivalent to our core module .', '']",2
"['We take some core ideas from our previous work on mining script information #TAUTHOR_TAG .', '', '', '', '', '']","['We take some core ideas from our previous work on mining script information #TAUTHOR_TAG .', '', '', '', '', '']","['We take some core ideas from our previous work on mining script information #TAUTHOR_TAG .', '', '', '', '', '']","['We take some core ideas from our previous work on mining script information #TAUTHOR_TAG .', '', '', '', '', '']",2
"['paraphrases are difficult to use tasks', '', '', '', '', '', '', 'Our own work #TAUTHOR_TAG extends the first idea to paraphrase fragment extraction on monolingual parallel and comparable corpora .', 'gram', '']","['paraphrases are difficult to use tasks.', '', '', '', '', '', '', 'Our own work #TAUTHOR_TAG extends the first idea to paraphrase fragment extraction on monolingual parallel and comparable corpora .', '', '']","[', sentential paraphrases are difficult to use', '', '', '', '', '', '', 'Our own work #TAUTHOR_TAG extends the first idea to paraphrase fragment extraction on monolingual parallel and comparable corpora .', 'gram', '']","['', '', '', '', '', '', '', 'Our own work #TAUTHOR_TAG extends the first idea to paraphrase fragment extraction on monolingual parallel and comparable corpora .', '', '']",2
"['Provided with the candidate fragment elements , we previously #TAUTHOR_TAG used a chunker3 to finalize the output fragments , in order to follow the linguistic definition of a ( para - ) phrase .', 'in the applying a dependency parser to constrain the boundary of the fragments (', '', '']","['Provided with the candidate fragment elements , we previously #TAUTHOR_TAG used a chunker3 to finalize the output fragments , in order to follow the linguistic definition of a ( para - ) phrase .', 'in the applying a dependency parser to constrain the boundary of the fragments', '', '']","['Provided with the candidate fragment elements , we previously #TAUTHOR_TAG used a chunker3 to finalize the output fragments , in order to follow the linguistic definition of a ( para - ) phrase .', 'in applying a dependency parser to constrain the boundary of the fragments (', '', '']","['Provided with the candidate fragment elements , we previously #TAUTHOR_TAG used a chunker3 to finalize the output fragments , in order to follow the linguistic definition of a ( para - ) phrase .', 'We extend this step in the current system by applying a dependency parser to constrain the boundary of the fragments (Sec.', '', '']",2
"['Similar to #TAUTHOR_TAG a ) , our summarization system is , which consists of three key components : an initial sentence pre-selection module to select some important sentence candidates ; the above compression model to generate n-best compressions for each ; and IL summar select the summary']","['Similar to #TAUTHOR_TAG a ) , our summarization system is , which consists of three key components : an initial sentence pre-selection module to select some important sentence candidates ; the above compression model to generate n-best compressions for each ; and ILP summarization select the summary']","['Similar to #TAUTHOR_TAG a ) , our summarization system is , which consists of three key components : an initial sentence pre-selection module to select some important sentence candidates ; the above compression model to generate n-best compressions for each sentence ; and select the best summary sentences']","['Similar to #TAUTHOR_TAG a ) , our summarization system is , which consists of three key components : an initial sentence pre-selection module to select some important sentence candidates ; the above compression model to generate n-best compressions for each sentence ; and then an ILP summarization method to select the best summary sentences from the multiple compressed sentences .']",1
"['Our approach to the problem is more compatible with the empirical evidence we presented in our prior work #TAUTHOR_TAG where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality .', 'Rather we showed that the quality of translation was markedly inferior, compared to overall translation quality, for sentences that were translated into multiple English sentences.', 'This over a.', '', '']","['Our approach to the problem is more compatible with the empirical evidence we presented in our prior work #TAUTHOR_TAG where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality .', 'Rather we showed that the quality of translation was markedly inferior, compared to overall translation quality, for sentences that were translated into multiple English sentences.', 'This over a sentence.', '', '']","['Our approach to the problem is more compatible with the empirical evidence we presented in our prior work #TAUTHOR_TAG where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality .', 'Rather we showed that the quality of translation was markedly inferior, compared to overall translation quality, for sentences that were translated into multiple English sentences.', 'over', '', '']","['Our approach to the problem is more compatible with the empirical evidence we presented in our prior work #TAUTHOR_TAG where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality .', 'Rather we showed that the quality of translation was markedly inferior, compared to overall translation quality, for sentences that were translated into multiple English sentences.', '', '', '']",1
"['During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one.', 'These automatic transformations are based on linguistic rules #TAUTHOR_TAG .', 'tectogrammaticalctors are assigned by the C4.5ifier (2aboktsk']","['During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one.', 'These automatic transformations are based on linguistic rules #TAUTHOR_TAG .', 'tectogrammatical functors are assigned by the C4.5 classifier (2abokrtsk9']","['During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one.', 'These automatic transformations are based on linguistic rules #TAUTHOR_TAG .', 'tectogrammatical functors are assigned by the C4.5 classifier (2aboktsk']","['During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one.', 'These automatic transformations are based on linguistic rules #TAUTHOR_TAG .', 'Subsequently, tectogrammatical functors are assigned by the C4.5 classifier (2abokrtsk9 et al., 2002).']",5
"['The analytical parsing of Czech runs in two steps: the statistical dependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors', 'We carried out two parallel experiments with two parsers available for Czech , parser I #AUTHOR_TAG and parser II #TAUTHOR_TAG .', '']","['The analytical parsing of Czech runs in two steps: the statistical dependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors.', 'We carried out two parallel experiments with two parsers available for Czech , parser I #AUTHOR_TAG and parser II #TAUTHOR_TAG .', '']","['The analytical parsing of Czech runs in two steps: the statistical dependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors.', 'We carried out two parallel experiments with two parsers available for Czech , parser I #AUTHOR_TAG and parser II #TAUTHOR_TAG .', '']","['The analytical parsing of Czech runs in two steps: the statistical dependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors.', 'We carried out two parallel experiments with two parsers available for Czech , parser I #AUTHOR_TAG and parser II #TAUTHOR_TAG .', '']",5
"['we created a probabilistic CzechEnglish dictionary by running GIZA + + training ( translation models 1-4 , see #TAUTHOR_TAG on the training part of the English-Czech WSJ parallel corpus extended by the parallel corpus of entry/translation pairs from the manual dictionary.', 'entrytranslation pairs seen in the corpusJ become more probable', '', '']","['we created a probabilistic CzechEnglish dictionary by running GIZA + + training ( translation models 1-4 , see #TAUTHOR_TAG on the training part of the English-Czech WSJ parallel corpus extended by the parallel corpus of entry/translation pairs from the manual dictionary.', 'entry/translation pairs seen in the corpus become more probable.', '', '']","['we created a probabilistic CzechEnglish dictionary by running GIZA + + training ( translation models 1-4 , see #TAUTHOR_TAG on the training part of the English-Czech WSJ parallel corpus extended by the parallel corpus of entry/translation pairs from the manual dictionary.', 'the entry/translation pairs seen in the parallel corpusJ become more probable', '', '']","['To make the dictionary more sensitive to a specific domain, which is in our case the domain of financial news, we created a probabilistic CzechEnglish dictionary by running GIZA + + training ( translation models 1-4 , see #TAUTHOR_TAG on the training part of the English-Czech WSJ parallel corpus extended by the parallel corpus of entry/translation pairs from the manual dictionary.', 'As a result, the entry/translation pairs seen in the parallel corpus of WSJ become more probable.', '', '']",5
"['', '', '', '', 'For the evaluation of the results we use the BLEU score #TAUTHOR_TAG .', '', '']","['', '', '', '', 'For the evaluation of the results we use the BLEU score #TAUTHOR_TAG .', '', '']","['', '', '', '', 'For the evaluation of the results we use the BLEU score #TAUTHOR_TAG .', '', '']","['', '', '', '', 'For the evaluation of the results we use the BLEU score #TAUTHOR_TAG .', '', '']",5
"['', '', '', '', '', '', 'We also compare the results with the output generated by the statistical translation system GIZA + + / ISI ReWrite Decoder #TAUTHOR_TAG , trained on the same parallel corpus .']","['', '', '', '', '', '', 'We also compare the results with the output generated by the statistical translation system GIZA + + / ISI ReWrite Decoder #TAUTHOR_TAG , trained on the same parallel corpus .']","['', '', '', '', '', '', 'We also compare the results with the output generated by the statistical translation system GIZA + + / ISI ReWrite Decoder #TAUTHOR_TAG , trained on the same parallel corpus .']","['', '', '', '', '', '', 'We also compare the results with the output generated by the statistical translation system GIZA + + / ISI ReWrite Decoder #TAUTHOR_TAG , trained on the same parallel corpus .']",1
"[""We evaluated our translations with IBM 's BLEU evaluation metric #TAUTHOR_TAG , using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP ( Haji 6 et al. , 2002 ) ."", 'We used four reference retranslations of 490 sentences fifth', 'each in against']","[""We evaluated our translations with IBM 's BLEU evaluation metric #TAUTHOR_TAG , using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP ( Haji 6 et al. , 2002 ) ."", 'We used four reference retranslations of 490 sentences fifth', 'each in against']","[""We evaluated our translations with IBM 's BLEU evaluation metric #TAUTHOR_TAG , using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP ( Haji 6 et al. , 2002 ) ."", 'We used four reference retranslations of 490 sentences', 'each reference in against']","[""We evaluated our translations with IBM 's BLEU evaluation metric #TAUTHOR_TAG , using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP ( Haji 6 et al. , 2002 ) ."", '', '']",5
"['', '', '', 'lex.', 'We performed translation experiments with an implementation of the IBM-4 translation model #TAUTHOR_TAG .', 'A description of the system can be found in #AUTHOR_TAG .', 'Table5 presents anish', '', '', '', '', '', '']","['', '', '', 'lexicon distribution.', 'We performed translation experiments with an implementation of the IBM-4 translation model #TAUTHOR_TAG .', 'A description of the system can be found in #AUTHOR_TAG .', 'Table 5 presents an', '', '', '', '', '', '']","['', '', '', '', 'We performed translation experiments with an implementation of the IBM-4 translation model #TAUTHOR_TAG .', 'A description of the system can be found in #AUTHOR_TAG .', 'Table 5 presents an assessmentish', '', '', '', '', '', '']","['', '', '', '', 'We performed translation experiments with an implementation of the IBM-4 translation model #TAUTHOR_TAG .', 'A description of the system can be found in #AUTHOR_TAG .', '', '', '', '', '', '', '']",5
"['The maximum entropy approach #TAUTHOR_TAG presents a powerful framework for the combination of several knowledge sources .', 'This principle recommends to choose the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy.', 'The distribution is required to satisfy constraints, which represent facts known from the data.', 'These constraints are expressed on the basis of feature functions hu,(s,t),']","['The maximum entropy approach #TAUTHOR_TAG presents a powerful framework for the combination of several knowledge sources .', 'This principle recommends to choose the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy.', 'The distribution is required to satisfy constraints, which represent facts known from the data.', 'These constraints are expressed on the basis of feature functions hu,(s,t),']","['The maximum entropy approach #TAUTHOR_TAG presents a powerful framework for the combination of several knowledge sources .', 'This principle recommends to choose the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy.', 'The distribution is required to satisfy constraints, which represent facts known from the data.', 'These constraints are expressed on the basis of feature functions hu,(s,t),']","['The maximum entropy approach #TAUTHOR_TAG presents a powerful framework for the combination of several knowledge sources .', 'This principle recommends to choose the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy.', 'The distribution is required to satisfy constraints, which represent facts known from the data.', 'These constraints are expressed on the basis of feature functions hu,(s,t),']",5
"['The input string be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string can be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string can be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']",0
"['where A = {Am } is the set of model parameters with one weight A, for each feature function hm', 'For an introduction to maximum entropy modeling and training procedures , the reader is referred to the corresponding literature , for instance #TAUTHOR_TAG or #AUTHOR_TAG .']","['where A = {Am } is the set of model parameters with one weight A, for each feature function hm', 'For an introduction to maximum entropy modeling and training procedures , the reader is referred to the corresponding literature , for instance #TAUTHOR_TAG or #AUTHOR_TAG .']","['where A = {Am } is the set of model parameters with one weight A, for each feature function hm .', 'For an introduction to maximum entropy modeling and training procedures , the reader is referred to the corresponding literature , for instance #TAUTHOR_TAG or #AUTHOR_TAG .']","['where A = {Am } is the set of model parameters with one weight A, for each feature function hm .', 'For an introduction to maximum entropy modeling and training procedures , the reader is referred to the corresponding literature , for instance #TAUTHOR_TAG or #AUTHOR_TAG .']",0
"['The input string be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string can be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string can be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']",0
"['Due to using a global model like CRFs , our previous work in #TAUTHOR_TAG c ) reported the best results over the evaluated corpora of Bakeoff-2 until now7 .', 'Though those are better than results that the results of character-level parsing approach ( state-']","['Due to using a global model like CRFs , our previous work in #TAUTHOR_TAG c ) reported the best results over the evaluated corpora of Bakeoff-2 until now7 .', 'Though those are better than results that the results of character-level parsing approach (Scheme']","['Due to using a global model like CRFs , our previous work in #TAUTHOR_TAG c ) reported the best results over the evaluated corpora of Bakeoff-2 until now7 .', 'Though those results are slightly better than the results that the results of character-level dependency parsing approach (']","['Due to using a global model like CRFs , our previous work in #TAUTHOR_TAG c ) reported the best results over the evaluated corpora of Bakeoff-2 until now7 .', '']",1
"['1 The representation in #TAUTHOR_TAG is even more compact than ours for grammars that are not self-embedding .', 'we use our an intermediate in approximating an unrestricted context-free grammar with autom.', ""For this purpose, Mohri and Pereira's representation offers little advantage.""]","['1 The representation in #TAUTHOR_TAG is even more compact than ours for grammars that are not self-embedding .', 'we use our an intermediate in approximating an unrestricted context-free grammar, with automaton.', ""For this purpose, Mohri and Pereira's representation offers little advantage.""]","['1 The representation in #TAUTHOR_TAG is even more compact than ours for grammars that are not self-embedding .', 'we use our an intermediate result in approximating an unrestricted context-free grammar, with', ""For this purpose, Mohri and Pereira's representation offers little advantage.""]","['1 The representation in #TAUTHOR_TAG is even more compact than ours for grammars that are not self-embedding .', 'However, in this paper we use our representation as an intermediate result in approximating an unrestricted context-free grammar, with the final objective of obtaining a single minimal deterministic automaton.', ""For this purpose, Mohri and Pereira's representation offers little advantage.""]",1
"['By restricting height of the stack of a pushdown automaton, one obstructs recognition of a set of strings in the context-free language, and therefore a subset approximation results.', 'This idea was proposed by Krauwer and des #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and was rediscovered by #AUTHOR_TAG and recently by #TAUTHOR_TAG .', 'treatment the historical of method']","['By restricting height of the stack of a pushdown automaton, one obstructs recognition of a set of strings in the context-free language, and therefore a subset approximation results.', 'This idea was proposed by Krauwer and des #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and was rediscovered by #AUTHOR_TAG and recently by #TAUTHOR_TAG .', 'treatment the historical of method.']","['By restricting the height of the stack of a pushdown automaton, one obstructs recognition of a set of strings in the context-free language, and therefore a subset approximation results.', 'This idea was proposed by Krauwer and des #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and was rediscovered by #AUTHOR_TAG and recently by #TAUTHOR_TAG .', 'treatment the historical roots of']","['By restricting the height of the stack of a pushdown automaton, one obstructs recognition of a set of strings in the context-free language, and therefore a subset approximation results.', 'This idea was proposed by Krauwer and des #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and was rediscovered by #AUTHOR_TAG and recently by #TAUTHOR_TAG .', '']",0
"['We rephrase the method of #TAUTHOR_TAG as follows : First , we construct the approximating finite automaton according to the unparameterized RTN method above .', '', '', '']","['We rephrase the method of #TAUTHOR_TAG as follows : First , we construct the approximating finite automaton according to the unparameterized RTN method above .', '', '', '']","['We rephrase the method of #TAUTHOR_TAG as follows : First , we construct the approximating finite automaton according to the unparameterized RTN method above .', '', '', '']","['We rephrase the method of #TAUTHOR_TAG as follows : First , we construct the approximating finite automaton according to the unparameterized RTN method above .', '', '', '']",5
"['This method can be generalized , inspired by #TAUTHOR_TAG , who derive N-gram probabilities from stochastic context-free grammars .', 'By ignoring the probabilities, each N = 1, 2, 3 .... gives rise to a superset approximation that can be described as follows: The set of strings derivable from a nonterminal A is approximated by the set of strings al that']","['This method can be generalized , inspired by #TAUTHOR_TAG , who derive N-gram probabilities from stochastic context-free grammars .', 'By ignoring the probabilities, each N = 1, 2, 3 .... gives rise to a superset approximation that can be described as follows: The set of strings derivable from a nonterminal A is approximated by the set of strings al that']","['This method can be generalized , inspired by #TAUTHOR_TAG , who derive N-gram probabilities from stochastic context-free grammars .', 'By ignoring the probabilities, each N = 1, 2, 3 .... gives rise to a superset approximation that can be described as follows: The set of strings derivable from a nonterminal A is approximated by the set of strings al that']","['This method can be generalized , inspired by #TAUTHOR_TAG , who derive N-gram probabilities from stochastic context-free grammars .', '']",0
['See #TAUTHOR_TAG for a variant of this approximation that constructs finite transducers rather than finite automata .'],['See #TAUTHOR_TAG for a variant of this approximation that constructs finite transducers rather than finite automata .'],['See #TAUTHOR_TAG for a variant of this approximation that constructs finite transducers rather than finite automata .'],['See #TAUTHOR_TAG for a variant of this approximation that constructs finite transducers rather than finite automata .'],0
"['', '', '', 'considering this eliminates selfding is purely prag of the we have tried thatont approximations, this has the lowest complexity in terms of the sizes of intermediate structures and of the resulting finite automata', 'The full formulation of the integrated grammar transformation and construction of the finite automaton is rather long and is therefore not given here.', 'A very similar formulation , for another grammar transformation , is given in #TAUTHOR_TAG .']","['', '', '', 'considering this eliminates self-embedding is purely pragmatic: of the we have tried that approximations, this has the lowest complexity in terms of the sizes of intermediate structures and of the resulting finite automata.In', 'full formulation of the integrated grammar transformation and construction of the finite automaton is rather long and is therefore not given here.', 'A very similar formulation , for another grammar transformation , is given in #TAUTHOR_TAG .']","['', '', '', 'considering this transformation eliminates selfding is purely prag of we have tried thatontrivial subset approximations, this transformation has the lowest complexity in terms of the sizes of intermediate structures and of the resulting finite automata', 'The full formulation of the integrated grammar transformation and construction of the finite automaton is rather long and is therefore not given here.', 'A very similar formulation , for another grammar transformation , is given in #TAUTHOR_TAG .']","['', '', '', '', '', 'A very similar formulation , for another grammar transformation , is given in #TAUTHOR_TAG .']",1
"['in and employed in expert,-based', '(', 'these rules are by an expert linguist, conversant with the sound and spelling systems of the language of concern.', 'Typical letter-to-sound rule sets are those described by #AUTHOR_TAG , Mc #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']","['in and employed in expert, knowledge-based', '(Post', 'these rules are by an expert linguist, conversant with the sound and spelling systems of the language of concern.', 'Typical letter-to-sound rule sets are those described by #AUTHOR_TAG , Mc #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']","['in and employed in expert', '(', 'these rules are specified by an expert linguist, conversant with the sound and spelling systems of the language of concern.', 'Typical letter-to-sound rule sets are those described by #AUTHOR_TAG , Mc #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']","['', '', 'Conventionally, these rules are specified by an expert linguist, conversant with the sound and spelling systems of the language of concern.', 'Typical letter-to-sound rule sets are those described by #AUTHOR_TAG , Mc #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']",0
"['It is also conceivable that data-driven techniques can actually outperform traditional rules.', ', this possibility is not usually given much credence.', ""For instance , #TAUTHOR_TAG recently wrote : `` To our knowledge , learning algorithms , although promising , have not ( yet ) reached the level of rule sets developed by humans '' ( p. 520 ) ."", '520).', 'this stating ""such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as by poor transcription scores"" (p.', '115 note 4).']","['It is also conceivable that data-driven techniques can actually outperform traditional rules.', 'However, this possibility is not usually given much credence.', ""For instance , #TAUTHOR_TAG recently wrote : `` To our knowledge , learning algorithms , although promising , have not ( yet ) reached the level of rule sets developed by humans '' ( p. 520 ) ."", '520).', 'this stating ""such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as by poor transcription scores"" (p.', '115, note 14).']","['It is also conceivable that data-driven techniques can actually outperform traditional rules.', ', this possibility is not usually given much credence.', ""For instance , #TAUTHOR_TAG recently wrote : `` To our knowledge , learning algorithms , although promising , have not ( yet ) reached the level of rule sets developed by humans '' ( p. 520 ) ."", '520).', 'this further, stating ""such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as by poor transcription scores"" (p.', '115, note 14).']","['It is also conceivable that data-driven techniques can actually outperform traditional rules.', 'However, this possibility is not usually given much credence.', ""For instance , #TAUTHOR_TAG recently wrote : `` To our knowledge , learning algorithms , although promising , have not ( yet ) reached the level of rule sets developed by humans '' ( p. 520 ) ."", '520).', ' #AUTHOR_TAG takes this further, stating ""such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as revealed by their poor transcription scores"" (p.', '115, note 14).']",0
"['', '', 'See also the work of #TAUTHOR_TAG , which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis .', '']","['', '', 'See also the work of #TAUTHOR_TAG , which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis .', '']","['', '', 'See also the work of #TAUTHOR_TAG , which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis .', '']","['', '', 'See also the work of #TAUTHOR_TAG , which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis .', '']",0
"['the above characterization is very wide ranging.', 'Consequently , fusion has been applied to a wide variety of pattern recognition and decision theoretic problems -- using a plethora of theories , techniques , and tools -- including some applications in computational linguistics ( e.g. , #TAUTHOR_TAG ; van Halteren , Zavrel , and Daelemans 1998 ) and speech technology ( e.g. , Bowles and Damper 1989 ; Romary and Pierre11989 ) .', '', '', '']","['the above characterization is very wide ranging.', 'Consequently , fusion has been applied to a wide variety of pattern recognition and decision theoretic problems -- using a plethora of theories , techniques , and tools -- including some applications in computational linguistics ( e.g. , #TAUTHOR_TAG ; van Halteren , Zavrel , and Daelemans 1998 ) and speech technology ( e.g. , Bowles and Damper 1989 ; Romary and Pierre11989 ) .', '', '', '']","['the above characterization is very wide ranging.', 'Consequently , fusion has been applied to a wide variety of pattern recognition and decision theoretic problems -- using a plethora of theories , techniques , and tools -- including some applications in computational linguistics ( e.g. , #TAUTHOR_TAG ; van Halteren , Zavrel , and Daelemans 1998 ) and speech technology ( e.g. , Bowles and Damper 1989 ; Romary and Pierre11989 ) .', '', '', '']","['Clearly, the above characterization is very wide ranging.', 'Consequently , fusion has been applied to a wide variety of pattern recognition and decision theoretic problems -- using a plethora of theories , techniques , and tools -- including some applications in computational linguistics ( e.g. , #TAUTHOR_TAG ; van Halteren , Zavrel , and Daelemans 1998 ) and speech technology ( e.g. , Bowles and Damper 1989 ; Romary and Pierre11989 ) .', '', '', '']",0
"['Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; #TAUTHOR_TAG 1995; Wu and Xia 1994).', 'Most of these algorithms can be summarized as follows:']","['Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; #TAUTHOR_TAG 1995; Wu and Xia 1994).', 'Most of these algorithms can be summarized as follows:']","['Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; #TAUTHOR_TAG 1995; Wu and Xia 1994).', 'Most of these algorithms can be summarized as follows:']","['Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; #TAUTHOR_TAG 1995; Wu and Xia 1994).', 'Most of these algorithms can be summarized as follows:']",0
"['Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by #TAUTHOR_TAG b ) .', 'These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution.', 'review these Table 1.']","['Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by #TAUTHOR_TAG b ) .', 'These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution.', 'review these Table 1.']","['Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by #TAUTHOR_TAG b ) .', 'These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution.', 'Table 1.']","['Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by #TAUTHOR_TAG b ) .', 'These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution.', '']",0
"['The probability distribution trans (.1, ~) is a word-to-word translation model.', 'Unlike the models proposed by #TAUTHOR_TAG b ) , this model is symmetric , because both word bags are generated together from a joint probability distribution .', ""Brown and his colleagues' models, 4.3, generate bitext given other hall so"", '']","['The probability distribution trans (.1, ~) is a word-to-word translation model.', 'Unlike the models proposed by #TAUTHOR_TAG b ) , this model is symmetric , because both word bags are generated together from a joint probability distribution .', ""Brown and his colleagues' models, 4.3, generate bitext given other hall so"", '']","['The probability distribution trans (.1, ~) is a word-to-word translation model.', 'Unlike the models proposed by #TAUTHOR_TAG b ) , this model is symmetric , because both word bags are generated together from a joint probability distribution .', ""Brown and his colleagues' models, Section 4.3, generate one the bitext given the other hall so"", '']","['The probability distribution trans (.1, ~) is a word-to-word translation model.', 'Unlike the models proposed by #TAUTHOR_TAG b ) , this model is symmetric , because both word bags are generated together from a joint probability distribution .', '', '']",1
"['in bitext space is another kind of collocation.', ""If each word 's translation is treated as a sense tag #TAUTHOR_TAG , then `` translational '' collocations have the unique property that the collocate and the word sense are one and the same !"", 'Method B exploits this property under the hypothesis that ""one sense per collocation"" holds for translational collocations.', 'This hypothesis implies that if u and v are possible mutual translations, and a token u co-occurs with a token v in the bitext, then with very high probability the pair (u,) was generated from the concept and should be', '', '', '']","['in bitext space is another kind of collocation.', ""If each word 's translation is treated as a sense tag #TAUTHOR_TAG , then `` translational '' collocations have the unique property that the collocate and the word sense are one and the same !"", 'Method B exploits this property under the hypothesis that ""one sense per collocation"" holds for translational collocations.', 'This hypothesis implies that if u and v are possible mutual translations, and a token u co-occurs with a token v in the bitext, then with very high probability the pair (u, v) was generated from the concept and should be', '', '', '']","['in bitext space is another kind of collocation.', ""If each word 's translation is treated as a sense tag #TAUTHOR_TAG , then `` translational '' collocations have the unique property that the collocate and the word sense are one and the same !"", 'Method B exploits this property under the hypothesis that ""one sense per collocation"" holds for translational collocations.', 'This hypothesis implies that if u and v are possible mutual translations, and a token u co-occurs with a token v in the bitext, then with very high probability the pair (u, v) was generated from the same concept and should be', '', '', '']","['in bitext space is another kind of collocation.', ""If each word 's translation is treated as a sense tag #TAUTHOR_TAG , then `` translational '' collocations have the unique property that the collocate and the word sense are one and the same !"", 'Method B exploits this property under the hypothesis that ""one sense per collocation"" holds for translational collocations.', 'This hypothesis implies that if u and v are possible mutual translations, and a token u co-occurs with a token v in the bitext, then with very high probability the pair (u, v) was generated from the same concept and should be linked.', '', '', '']",5
"['In informal experiments described elsewhere #TAUTHOR_TAG , I found that the G2 statistic suggested by #AUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere #TAUTHOR_TAG , I found that the G2 statistic suggested by #AUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere #TAUTHOR_TAG , I found that the G2 statistic suggested by #AUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere #TAUTHOR_TAG , I found that the G2 statistic suggested by #AUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']",2
"['¢ cross-language information retrieval ( e.g. , McCarley 1999 ) , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , #TAUTHOR_TAG , â\x80¢ certain machine-assisted translation tools ( e.g. , Mackitch 1994 ; Melamed 1996a ) ,¢']","['cross-language information retrieval ( e.g. , McCarley 1999 ) , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , #TAUTHOR_TAG , â\x80¢ certain machine-assisted translation tools ( e.g. , Macklovitch 1994 ; Melamed 1996a ) ,']","['¢ cross-language information retrieval ( e.g. , McCarley 1999 ) , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , #TAUTHOR_TAG , â\x80¢ certain machine-assisted translation tools ( e.g. , Mackitch 1994 ; Melamed 1996a ) ,¢']","['â\x80¢ cross-language information retrieval ( e.g. , McCarley 1999 ) , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , #TAUTHOR_TAG , â\x80¢ certain machine-assisted translation tools ( e.g. , Macklovitch 1994 ; Melamed 1996a ) , â\x80¢ concordancing for bilingual lexicography ( e.g. , Catizone , Russell , and Warwick 1989 ; Gale and Church 1991 ) ,']",0
"[""In this situation , #TAUTHOR_TAG b , 293 ) recommend `` evaluating the expectations using only a single , probable alignment . ''"", 'The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:']","[""In this situation , #TAUTHOR_TAG b , 293 ) recommend `` evaluating the expectations using only a single , probable alignment . ''"", 'The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:']","[""In this situation , #TAUTHOR_TAG b , 293 ) recommend `` evaluating the expectations using only a single , probable alignment . ''"", 'The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:']","[""In this situation , #TAUTHOR_TAG b , 293 ) recommend `` evaluating the expectations using only a single , probable alignment . ''"", 'The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:']",4
"['estimation aux only', '', '', 'frequent are translated less than rare (Catizone,, andwick ', 'we', 'aux', 'effect aux linked word.', 'Just as easily , we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not ( cfXXX #TAUTHOR_TAG .', 'Brown et al. 1993).', 'When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B (links (u, v)[cooc(u, v), A +) scorec (u, vlZ = classu, v)) = log B((u, v)[coocu), z)"" (3)6']","['estimation auxiliary only', '', '', 'frequent are translated less than rare (Catizone, Russell, and Warwick', 'we', 'auxiliary', 'effected auxiliary linked word texts.', 'Just as easily , we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not ( cfXXX #TAUTHOR_TAG .', 'Brown et al. 1993).', 'When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B (links (u, v)[cooc(u, v), A +) scorec (u, vlZ = class(u, v)) = log B(links(u, v)[cooc(u, v), z)"" (37)']","['the estimation only', '', '', 'are translated less consistently than rare words (Catizone,, and', '', '', 'linked word tokens', 'Just as easily , we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not ( cfXXX #TAUTHOR_TAG .', 'Brown et al. 1993).', 'When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B (links (u, v)[cooc(u, v), A +) scorec (u, vlZ = classu, v)) = log B((u, v)[coocu, v), A z)"" (3']","['', '', '', 'For example, frequent words are translated less consistently than rare words (Catizone, Russell, and Warwick 1989).', '', '', '', 'Just as easily , we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not ( cfXXX #TAUTHOR_TAG .', 'Brown et al. 1993).', 'When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B (links (u, v)[cooc(u, v), A +) scorec (u, vlZ = class(u, v)) = log B(links(u, v)[cooc(u, v), A z)"" (37) Section 6.1.1 describes the link classes used in the experiments below.']",5
"[""Until now , translation models have been evaluated either subjectively ( e.g. White and O'Connell 1993 ) or using relative metrics , such as perplexity with respect to other models #TAUTHOR_TAG b ) ."", 'Objective and more accurate tests can be carried out using a ""gold', 'an', '', '', '', '']","[""Until now , translation models have been evaluated either subjectively ( e.g. White and O'Connell 1993 ) or using relative metrics , such as perplexity with respect to other models #TAUTHOR_TAG b ) ."", 'Objective and more accurate tests can be carried out using a ""gold', '', '', '', '', '']","[""Until now , translation models have been evaluated either subjectively ( e.g. White and O'Connell 1993 ) or using relative metrics , such as perplexity with respect to other models #TAUTHOR_TAG b ) ."", 'Objective and more accurate tests can be carried out using a ""gold standard.""', '', '', '', '', '']","[""Until now , translation models have been evaluated either subjectively ( e.g. White and O'Connell 1993 ) or using relative metrics , such as perplexity with respect to other models #TAUTHOR_TAG b ) ."", 'Objective and more accurate tests can be carried out using a ""gold standard.""', '', '', '', '', '']",1
"['In informal experiments described elsewhere ( Melamed 1995 I found that the G2 statistic suggested by #TAUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere ( Melamed 1995 I found that the G2 statistic suggested by #TAUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere ( Melamed 1995 I found that the G2 statistic suggested by #TAUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere ( Melamed 1995 ) , I found that the G2 statistic suggested by #TAUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']",0
"['The above equation holds regardless of how we represent concepts.', 'There are many plausible representations , such as pairs of trees from synchronous tree adjoining grammars ( Abeille et al. 1990 ; Shieber 1994 ; #TAUTHOR_TAG , lexical conceptual structures ( Dorr 1992 ) and WordNet synsets ( Fellbaum 1998 ; Vossen 1998 ) .', '']","['The above equation holds regardless of how we represent concepts.', 'There are many plausible representations , such as pairs of trees from synchronous tree adjoining grammars ( Abeille et al. 1990 ; Shieber 1994 ; #TAUTHOR_TAG , lexical conceptual structures ( Dorr 1992 ) and WordNet synsets ( Fellbaum 1998 ; Vossen 1998 ) .', '']","['The above equation holds regardless of how we represent concepts.', 'There are many plausible representations , such as pairs of trees from synchronous tree adjoining grammars ( Abeille et al. 1990 ; Shieber 1994 ; #TAUTHOR_TAG , lexical conceptual structures ( Dorr 1992 ) and WordNet synsets ( Fellbaum 1998 ; Vossen 1998 ) .', '']","['The above equation holds regardless of how we represent concepts.', 'There are many plausible representations , such as pairs of trees from synchronous tree adjoining grammars ( Abeille et al. 1990 ; Shieber 1994 ; #TAUTHOR_TAG , lexical conceptual structures ( Dorr 1992 ) and WordNet synsets ( Fellbaum 1998 ; Vossen 1998 ) .', '']",0
"['â\x80¢ cross-language information retrieval ( e.g. , #TAUTHOR_TAG , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , Nerbonne et al.1997 ) ,¢ certain machine-assisted tools ( Mackitch  ; Melamed 19']","['â\x80¢ cross-language information retrieval ( e.g. , #TAUTHOR_TAG , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , Nerbonne et al. 1997 ) , certain machine-assisted tools ( Macklovitch ; Melamed 1996a']","['â\x80¢ cross-language information retrieval ( e.g. , #TAUTHOR_TAG , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , Nerbonne et al.1997 ) ,¢ certain machine-assisted translation tools ( Mack ; Melamed 1996a']","['â\x80¢ cross-language information retrieval ( e.g. , #TAUTHOR_TAG , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , Nerbonne et al. 1997 ) , â\x80¢ certain machine-assisted translation tools ( e.g. , Macklovitch 1994 ; Melamed 1996a ) , â\x80¢ concordancing for bilingual lexicography ( e.g. , Catizone , Russell , and Warwick 1989 ; Gale and Church 1991 ) ,']",0
"[""Many other such cases are described in Danlos 's book #TAUTHOR_TAG ."", 'The common theme behind many of these examples is that pipelines have difficulties satisfying linguistic constraints (such as unambiguous reference) or performing linguistic optimizations (such as using pronouns instead of longer referring expressions whenever possible) in cases where the constraints or optimizations depend on decisions made in multiple modules.', 'This is largely due to the fact that pipelined systems cannot perform general search over a decision space that includes decisions made in more than one module.']","[""Many other such cases are described in Danlos 's book #TAUTHOR_TAG ."", 'The common theme behind many of these examples is that pipelines have difficulties satisfying linguistic constraints (such as unambiguous reference) or performing linguistic optimizations (such as using pronouns instead of longer referring expressions whenever possible) in cases where the constraints or optimizations depend on decisions made in multiple modules.', 'This is largely due to the fact that pipelined systems cannot perform general search over a decision space that includes decisions made in more than one module.']","[""Many other such cases are described in Danlos 's book #TAUTHOR_TAG ."", 'The common theme behind many of these examples is that pipelines have difficulties satisfying linguistic constraints (such as unambiguous reference) or performing linguistic optimizations (such as using pronouns instead of longer referring expressions whenever possible) in cases where the constraints or optimizations depend on decisions made in multiple modules.', 'This is largely due to the fact that pipelined systems cannot perform general search over a decision space that includes decisions made in more than one module.']","[""Many other such cases are described in Danlos 's book #TAUTHOR_TAG ."", 'The common theme behind many of these examples is that pipelines have difficulties satisfying linguistic constraints (such as unambiguous reference) or performing linguistic optimizations (such as using pronouns instead of longer referring expressions whenever possible) in cases where the constraints or optimizations depend on decisions made in multiple modules.', 'This is largely due to the fact that pipelined systems cannot perform general search over a decision space that includes decisions made in more than one module.']",0
"['Despite these arguments, most applied NLG systems use a pipelined architecture; indeed, a pipeline was used in every one of the systems surveyed by #AUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages , and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems #TAUTHOR_TAG .']","['Despite these arguments, most applied NLG systems use a pipelined architecture; indeed, a pipeline was used in every one of the systems surveyed by #AUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages , and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems #TAUTHOR_TAG .']","['Despite these arguments, most applied NLG systems use a pipelined architecture; indeed, a pipeline was used in every one of the systems surveyed by #AUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages , and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems #TAUTHOR_TAG .']","['Despite these arguments, most applied NLG systems use a pipelined architecture; indeed, a pipeline was used in every one of the systems surveyed by #AUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages , and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems #TAUTHOR_TAG .']",0
"['Despite these arguments , most applied NLG systems use a pipelined architecture ; indeed , a pipeline was used in every one of the systems surveyed by #TAUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages, and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems (Mittal et.9).']","['Despite these arguments , most applied NLG systems use a pipelined architecture ; indeed , a pipeline was used in every one of the systems surveyed by #TAUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages, and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems (Mittal et al.']","['Despite these arguments , most applied NLG systems use a pipelined architecture ; indeed , a pipeline was used in every one of the systems surveyed by #TAUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages, and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems (Mitt']","['Despite these arguments , most applied NLG systems use a pipelined architecture ; indeed , a pipeline was used in every one of the systems surveyed by #TAUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages, and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems (Mittal et al. 1998).']",0
"['', '', 'approach has at its center a le #AUTHOR_TAG', 'Thex is used to mediate and map between a language-independent domain model and a language-dependent ontology widely used in NLG , the Upper Model #TAUTHOR_TAG .', 'Although the idea of a two-level representation accommodating language-neutral and language-specific requirements is not new (see for example Nirenburg and Levin [1992], Dorr and Voss [1993], and Di Eugenio [1998]), Stede is among the few who make effective use of those two levels in a complex system.']","['', '', 'approach has at its center a #AUTHOR_TAG', 'The is used to mediate and map between a language-independent domain model and a language-dependent ontology widely used in NLG , the Upper Model #TAUTHOR_TAG .', 'Although the idea of a two-level representation accommodating language-neutral and language-specific requirements is not new (see for example Nirenburg and Levin [1992], Dorr and Voss [1993], and Di Eugenio [1998]), Stede is among the few who make effective use of those two levels in a complex system.']","['', '', 'has at its center a lexicon #AUTHOR_TAG .', 'The lexicon is used to mediate and map between a language-independent domain model and a language-dependent ontology widely used in NLG , the Upper Model #TAUTHOR_TAG .', 'Although the idea of a two-level representation accommodating language-neutral and language-specific requirements is not new (see for example Nirenburg and Levin [1992], Dorr and Voss [1993], and Di Eugenio [1998]), Stede is among the few who make effective use of those two levels in a complex system.']","['', '', '', 'The lexicon is used to mediate and map between a language-independent domain model and a language-dependent ontology widely used in NLG , the Upper Model #TAUTHOR_TAG .', 'Although the idea of a two-level representation accommodating language-neutral and language-specific requirements is not new (see for example Nirenburg and Levin [1992], Dorr and Voss [1993], and Di Eugenio [1998]), Stede is among the few who make effective use of those two levels in a complex system.']",0
"['lyskyalle `` #AUTHOR_TAG contextensitive SPE [ be replaced by a much simpler one , based on finite-state transducers ( FSTs ) ; the same conclusion was reached independently by Kaplan and Kay , whose work remained an underground classic until it was finally published in #TAUTHOR_TAG .', 'These-level the Xerox rule (al', 'now dominant tools in JapanesexAc reducing morph', '']","['Shortly Halle `` #AUTHOR_TAG context-sensitive SPE [ be replaced by a much simpler one , based on finite-state transducers ( FSTs ) ; the same conclusion was reached independently by Kaplan and Kay , whose work remained an underground classic until it was finally published in #TAUTHOR_TAG .', 'These two-level the Xerox rule', 'now dominant tools in Japanese reducing morphological', '']","['lysky `` #AUTHOR_TAG SPE [ could ] be replaced by a much simpler one , based on finite-state transducers ( FSTs ) ; the same conclusion was reached independently by Kaplan and Kay , whose work remained an underground classic until it was finally published in #TAUTHOR_TAG .', 'These works- the Xerox rule compiler (al', 'are now dominant tools inAc', '']","['', '', '', '']",0
"['OT therefore holds out the promise of simplifying grammars , by factoring all complex phenomena into simple surface-level constraints that partially mask one another .1 Whether this is always possible under an appropriate definition of ""simple constraints"" ( e.g. , #TAUTHOR_TAG b ) is of course an empirical question .']","['OT therefore holds out the promise of simplifying grammars , by factoring all complex phenomena into simple surface-level constraints that partially mask one another .1 Whether this is always possible under an appropriate definition of ""simple constraints"" ( e.g. , #TAUTHOR_TAG b ) is of course an empirical question .']","['OT therefore holds out the promise of simplifying grammars , by factoring all complex phenomena into simple surface-level constraints that partially mask one another .1 Whether this is always possible under an appropriate definition of ""simple constraints"" ( e.g. , #TAUTHOR_TAG b ) is of course an empirical question .']","['OT therefore holds out the promise of simplifying grammars , by factoring all complex phenomena into simple surface-level constraints that partially mask one another .1 Whether this is always possible under an appropriate definition of ""simple constraints"" ( e.g. , #TAUTHOR_TAG b ) is of course an empirical question .']",0
"['', 'In some cases rankings may work well enough.', ' #TAUTHOR_TAG report excellent part-of-speech tagging results using a handcrafted approach that is close to OT .3 Moreulatively , imagine an OT grammar forlistic revision of parsed sentences', '', '', '', '', '']","['', 'In some cases rankings may work well enough.', ' #TAUTHOR_TAG report excellent part-of-speech tagging results using a handcrafted approach that is close to OT .3 More speculatively , imagine an OT grammar for stylistic revision of parsed sentences', '', '', '', '', '']","['', 'In some cases rankings may work well enough.', ' #TAUTHOR_TAG report excellent part-of-speech tagging results using a handcrafted approach that is close to OT .3 Moreulatively , imagine an OT grammar forlistic revision of parsed sentences .', '', '', '', '', '']","['', 'In some cases rankings may work well enough.', ' #TAUTHOR_TAG report excellent part-of-speech tagging results using a handcrafted approach that is close to OT .3 More speculatively , imagine an OT grammar for stylistic revision of parsed sentences .', '', '', '', '', '']",0
"['hidden', 'functions', 'typical OT grammars offer much richer finite-state models of left context #TAUTHOR_TAG a ) than provided by the traditional HMM finite-state topologies', '', '', '']","['hidden', 'functions', 'typical OT grammars offer much richer finite-state models of left context #TAUTHOR_TAG a ) than provided by the traditional HMM finite-state topologies', '', '', '']","['hidden', 'functions', 'typical OT grammars offer much richer finite-state models of left context #TAUTHOR_TAG a ) than provided by the traditional HMM finite-state topologies .', '', '', '']","['', '', 'But typical OT grammars offer much richer finite-state models of left context #TAUTHOR_TAG a ) than provided by the traditional HMM finite-state topologies .', '', '', '']",0
"['', 'a', '', ""In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993"", ' #TAUTHOR_TAG use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .']","['', 'a', '', ""In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993)."", ' #TAUTHOR_TAG use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .']","['', '', '', ""In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993"", ' #TAUTHOR_TAG use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .']","['', '', '', ""In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993)."", ' #TAUTHOR_TAG use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .']",0
"['we want to retain legomena with a 2 compute the corresponding significance ands exact test', '', '', '', '', '', 's exact test leads to a slightly better recall with the same precision scores (0.31 for both tests).', ""While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure #TAUTHOR_TAG :""]","['we want to retain legomena with a 2-0 compute the corresponding significance and exact test', '', '', '', '', '', 'exact test leads to a slightly better recall with the same precision scores (0.31 for both tests).', ""While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure #TAUTHOR_TAG :""]","['we want to retain dis legomena with compute the corresponding significance levels ands exact test', '', '', '', '', '', 'exact test leads to a slightly better recall with the same precision scores (0.31 for both tests).', ""While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure #TAUTHOR_TAG :""]","['', '', '', '', '', '', ""For the higherfrequency words, Fisher's exact test leads to a slightly better recall with the same precision scores (0.31 for both tests)."", ""While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure #TAUTHOR_TAG :""]",0
"['ofmar is measured', '', '', '(', 'For example , #TAUTHOR_TAG proves that Chinese numerals such as wu zhao zhao zhao zhao zhao wu zhao zhao zhao zhao wu zhao zhao zhao wu zhao zhao wu zhao , for the number 500000000000000000500000000000000500000000000500000000500 ,', '', '', '', '']","['of grammar is measured', '', '', '(or', 'For example , #TAUTHOR_TAG proves that Chinese numerals such as wu zhao zhao zhao zhao zhao wu zhao zhao zhao zhao wu zhao zhao zhao wu zhao zhao wu zhao , for the number 5000000000000000005000000000000005000000000005000000005000 ,', '', '', '', '']","['of is measured', '', '', '(', 'For example , #TAUTHOR_TAG proves that Chinese numerals such as wu zhao zhao zhao zhao zhao wu zhao zhao zhao zhao wu zhao zhao zhao wu zhao zhao wu zhao , for the number 5000000000000000005000000000000005000000000005000000005000 ,', '', '', '', '']","['', '', '', '', 'For example , #TAUTHOR_TAG proves that Chinese numerals such as wu zhao zhao zhao zhao zhao wu zhao zhao zhao zhao wu zhao zhao zhao wu zhao zhao wu zhao , for the number 5000000000000000005000000000000005000000000005000000005000 , are not context-free , which implies that Chinese is not a context-free language and thus might parse in exponential worst-case time .', '', '', '', '']",0
"['', '', '', '', 'For some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes #TAUTHOR_TAG .', 'This parser produces trees to represent the structure of the sentences that compose the text.', 'However is set to ""skip"" or surrender attempts to parse clauses after reaching a time-out threshold.', 'When the parser sk parse', '']","['', '', '', '', 'For some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes #TAUTHOR_TAG .', 'This parser produces trees to represent the structure of the sentences that compose the text.', 'However, is set to ""skip"" or surrender attempts to parse clauses after reaching a time-out threshold.', 'When the parser parse', '']","['', '', '', '', 'For some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes #TAUTHOR_TAG .', 'This parser produces trees to represent the structure of the sentences that compose the text.', 'However it is set to ""skip"" or surrender attempts to parse clauses after reaching a time-out threshold.', 'When the parser skips,', '']","['', '', '', '', 'For example , some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes #TAUTHOR_TAG .', 'This parser produces trees to represent the structure of the sentences that compose the text.', 'However, it is set to ""skip"" or surrender attempts to parse clauses after reaching a time-out threshold.', '', '']",0
"['ari', 'this classification method we can also derive the probability that a case belongs to a particular group (i.e., posterior probabilities), which is roughly proportional to the Mahalanobis distance from that group centroid.', 'Discriminant analysis has been employed by researchers in automatic text genre detection #TAUTHOR_TAG b ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables .']","['', 'this classification method we can also derive the probability that a case belongs to a particular group (i.e., posterior probabilities), which is roughly proportional to the Mahalanobis distance from that group centroid.', 'Discriminant analysis has been employed by researchers in automatic text genre detection #TAUTHOR_TAG b ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables .']","['', 'Using this classification method we can also derive the probability that a case belongs to a particular group (i.e., posterior probabilities), which is roughly proportional to the Mahalanobis distance from that group centroid.', 'Discriminant analysis has been employed by researchers in automatic text genre detection #TAUTHOR_TAG b ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables .']","['', 'Using this classification method we can also derive the probability that a case belongs to a particular group (i.e., posterior probabilities), which is roughly proportional to the Mahalanobis distance from that group centroid.', 'Discriminant analysis has been employed by researchers in automatic text genre detection #TAUTHOR_TAG b ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables .']",0
"['The algorithm we implemented is inspired by the work of #TAUTHOR_TAG on word sense disambiguation .', 'He classified the senses of a word on the basis of other words that the given word co-occurs with.', ' #AUTHOR_TAG']","['The algorithm we implemented is inspired by the work of #TAUTHOR_TAG on word sense disambiguation .', 'He classified the senses of a word on the basis of other words that the given word co-occurs with.', ' #AUTHOR_TAG']","['The algorithm we implemented is inspired by the work of #TAUTHOR_TAG on word sense disambiguation .', 'He classified the senses of a word on the basis of other words that the given word co-occurs with.', ' #AUTHOR_TAG']","['The algorithm we implemented is inspired by the work of #TAUTHOR_TAG on word sense disambiguation .', 'He classified the senses of a word on the basis of other words that the given word co-occurs with.', ' #AUTHOR_TAG']",4
"['The automatic annotation of nouns and verbs in the corpus has been done by matching them with the WordNet database files.', 'Before doing the annotation, though, some preprocessing of the data was required to maximize the matching between our corpus and WordNet.', 'The changes made were inspired by those described in #TAUTHOR_TAG , page 75 ) .', '', '']","['The automatic annotation of nouns and verbs in the corpus has been done by matching them with the WordNet database files.', 'Before doing the annotation, though, some preprocessing of the data was required to maximize the matching between our corpus and WordNet.', 'The changes made were inspired by those described in #TAUTHOR_TAG , page 75 ) .', '', '']","['The automatic annotation of nouns and verbs in the corpus has been done by matching them with the WordNet database files.', 'Before doing the annotation, though, some preprocessing of the data was required to maximize the matching between our corpus and WordNet.', 'The changes made were inspired by those described in #TAUTHOR_TAG , page 75 ) .', '', '']","['The automatic annotation of nouns and verbs in the corpus has been done by matching them with the WordNet database files.', 'Before doing the annotation, though, some preprocessing of the data was required to maximize the matching between our corpus and WordNet.', 'The changes made were inspired by those described in #TAUTHOR_TAG , page 75 ) .', '', '']",4
"['', '', '', '', 'and POS-tagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work #TAUTHOR_TAG a ) , while being more than an order of magnitude faster .']","['', '', '', '', 'and POS-tagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work #TAUTHOR_TAG a ) , while being more than an order of magnitude faster .']","['', '', '', '', 'and POS-tagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work #TAUTHOR_TAG a ) , while being more than an order of magnitude faster .']","['', '', '', '', 'For the joint segmentation and POS-tagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work #TAUTHOR_TAG a ) , while being more than an order of magnitude faster .']",1
"['Previously #TAUTHOR_TAG , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests .', 'In each test, the discriminative model was retrained and reevaluated without a particular group of features.', 'We summarize the findings of this study in this section.']","['Previously #TAUTHOR_TAG , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests .', 'In each test, the discriminative model was retrained and reevaluated without a particular group of features.', 'We summarize the findings of this study in this section.']","['Previously #TAUTHOR_TAG , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests .', 'In each test, the discriminative model was retrained and reevaluated without a particular group of features.', 'We summarize the findings of this study in this section.']","['Previously #TAUTHOR_TAG , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests .', 'In each test, the discriminative model was retrained and reevaluated without a particular group of features.', 'We summarize the findings of this study in this section.']",2
"['', '', 'This evaluation set-up is an improvement versus the one we previously reported #TAUTHOR_TAG , in which fixed partitions were used for training , development , and testing .']","['', '', 'This evaluation set-up is an improvement versus the one we previously reported #TAUTHOR_TAG , in which fixed partitions were used for training , development , and testing .']","['', '', 'This evaluation set-up is an improvement versus the one we previously reported #TAUTHOR_TAG , in which fixed partitions were used for training , development , and testing .']","['', '', 'This evaluation set-up is an improvement versus the one we previously reported #TAUTHOR_TAG , in which fixed partitions were used for training , development , and testing .']",2
"['We now give an overview of the training algorithm, which is crucial to both the speed and accuracy of the resulting decoder.', 'CCGBank #TAUTHOR_TAG is used to train the model .', 'For each training sentence, the corresponding CCGBank derivation together with all its sub-derivations are treated as gold-standard hypotheses.', 'All other hypotheses that can be constructed from the same bag of words are non-gold hypotheses.', '', '']","['We now give an overview of the training algorithm, which is crucial to both the speed and accuracy of the resulting decoder.', 'CCGBank #TAUTHOR_TAG is used to train the model .', 'For each training sentence, the corresponding CCGBank derivation together with all its sub-derivations are treated as gold-standard hypotheses.', 'All other hypotheses that can be constructed from the same bag of words are non-gold hypotheses.', '', '']","['We now give an overview of the training algorithm, which is crucial to both the speed and accuracy of the resulting decoder.', 'CCGBank #TAUTHOR_TAG is used to train the model .', 'For each training sentence, the corresponding CCGBank derivation together with all its sub-derivations are treated as gold-standard hypotheses.', 'All other hypotheses that can be constructed from the same bag of words are non-gold hypotheses.', '', '']","['We now give an overview of the training algorithm, which is crucial to both the speed and accuracy of the resulting decoder.', 'CCGBank #TAUTHOR_TAG is used to train the model .', 'For each training sentence, the corresponding CCGBank derivation together with all its sub-derivations are treated as gold-standard hypotheses.', 'All other hypotheses that can be constructed from the same bag of words are non-gold hypotheses.', '', '']",5
"['', '', '', '', '', '', '', '', 'In our previous papers #TAUTHOR_TAG ; Zhang , Blackwood , and Clark 2012 , we applied a set of beams to this structure , which makes it similar to the data structure used for phrase-based MT decoding ( Koehn 2010', '', '']","['', '', '', '', '', '', '', '', 'In our previous papers #TAUTHOR_TAG ; Zhang , Blackwood , and Clark 2012 , we applied a set of beams to this structure , which makes it similar to the data structure used for phrase-based MT decoding ( Koehn 2010', '', '']","['', '', '', '', '', '', '', '', 'In our previous papers #TAUTHOR_TAG ; Zhang , Blackwood , and Clark 2012 , we applied a set of beams to this structure , which makes it similar to the data structure used for phrase-based MT decoding ( Koehn 2010', '', '']","['', '', '', '', '', '', '', '', 'In our previous papers #TAUTHOR_TAG ; Zhang , Blackwood , and Clark 2012 ) , we applied a set of beams to this structure , which makes it similar to the data structure used for phrase-based MT decoding ( Koehn 2010 ) .', '', '']",1
"['', '', '', '', '', '', '', 'This was done by MERT optimization #TAUTHOR_TAG towards post-edits under the TER target metric .', '', '', '', '']","['', '', '', '', '', '', '', 'This was done by MERT optimization #TAUTHOR_TAG towards post-edits under the TER target metric .', '', '', '', '']","['', '', '', '', '', '', '', 'This was done by MERT optimization #TAUTHOR_TAG towards post-edits under the TER target metric .', '', '', '', '']","['', '', '', '', '', '', '', 'This was done by MERT optimization #TAUTHOR_TAG towards post-edits under the TER target metric .', '', '', '', '']",5
"['Generalization for Online-to-Batch Conversion.', 'In practice , perceptron-type algorithms are often applied in a batch learning scenario , i.e. , the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set #TAUTHOR_TAG .', 'The difference to the online learning scenario is that we treat the multi-epoch algorithm as an empirical risk minimizer that selects a final weight vector w T,K whose expected loss on un to', '', '', '', '', '', '', '', '', '']","['Generalization for Online-to-Batch Conversion.', 'In practice , perceptron-type algorithms are often applied in a batch learning scenario , i.e. , the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set #TAUTHOR_TAG .', 'The difference to the online learning scenario is that we treat the multi-epoch algorithm as an empirical risk minimizer that selects a final weight vector w T,K whose expected loss on unseen to', '', '', '', '', '', '', '', '', '']","['Generalization for Online-to-Batch Conversion.', 'In practice , perceptron-type algorithms are often applied in a batch learning scenario , i.e. , the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set #TAUTHOR_TAG .', 'The difference to the online learning scenario is that we treat the multi-epoch algorithm as an empirical risk minimizer that selects a final weight vector w T,K whose expected loss on un to', '', '', '', '', '', '', '', '', '']","['Generalization for Online-to-Batch Conversion.', 'In practice , perceptron-type algorithms are often applied in a batch learning scenario , i.e. , the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set #TAUTHOR_TAG .', 'The difference to the online learning scenario is that we treat the multi-epoch algorithm as an empirical risk minimizer that selects a final weight vector w T,K whose expected loss on unseen data we would like to bound.', '', '', '', '', '', '', '', '', '']",1
"['', '', 'prepare SMT creators corpus used their own WMT10 system #AUTHOR_TAG , based on the Moses phrase-based decoder #TAUTHOR_TAG with dense features .', 'similar system using theolingual and parallel data 5 Ken', '', '', '', '', '', '', '']","['', '', 'prepare SMT creators corpus used their own WMT10 system #AUTHOR_TAG , based on the Moses phrase-based decoder #TAUTHOR_TAG with dense features .', 'similar system using the monolingual and parallel data: 5-gram KenLM', '', '', '', '', '', '', '']","['', '', 'prepare SMT outputs the creators the corpus used their own WMT10 system #AUTHOR_TAG , based on the Moses phrase-based decoder #TAUTHOR_TAG with dense features .', 'a similar Moses system using theolingual and parallel data:', '', '', '', '', '', '', '']","['', '', 'To prepare SMT outputs for post-editing , the creators of the corpus used their own WMT10 system #AUTHOR_TAG , based on the Moses phrase-based decoder #TAUTHOR_TAG with dense features .', '', '', '', '', '', '', '', '']",5
"['In contrast , a single statistical model allows one to maintain a single table #TAUTHOR_TAG .']","['In contrast , a single statistical model allows one to maintain a single table #TAUTHOR_TAG .']","['In contrast , a single statistical model allows one to maintain a single table #TAUTHOR_TAG .']","['In contrast , a single statistical model allows one to maintain a single table #TAUTHOR_TAG .']",0
['IGEN uses standard chart generation techniques #TAUTHOR_TAG in its base generator to efficiently produce generation candidates .'],['IGEN uses standard chart generation techniques #TAUTHOR_TAG in its base generator to efficiently produce generation candidates .'],['IGEN uses standard chart generation techniques #TAUTHOR_TAG in its base generator to efficiently produce generation candidates .'],['IGEN uses standard chart generation techniques #TAUTHOR_TAG in its base generator to efficiently produce generation candidates .'],0
"[""Notice that it is not possible to use corpus annotation to determine the likelihood of a given property to be chosen , unless we know in advance all of the properties that can be attributed to a given object , as in the case of Jordan 's work on the COCONUT domain #TAUTHOR_TAG .""]","[""Notice that it is not possible to use corpus annotation to determine the likelihood of a given property to be chosen , unless we know in advance all of the properties that can be attributed to a given object , as in the case of Jordan 's work on the COCONUT domain #TAUTHOR_TAG .""]","[""Notice that it is not possible to use corpus annotation to determine the likelihood of a given property to be chosen , unless we know in advance all of the properties that can be attributed to a given object , as in the case of Jordan 's work on the COCONUT domain #TAUTHOR_TAG .""]","[""Notice that it is not possible to use corpus annotation to determine the likelihood of a given property to be chosen , unless we know in advance all of the properties that can be attributed to a given object , as in the case of Jordan 's work on the COCONUT domain #TAUTHOR_TAG .""]",0
['It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence ( in the sense of #AUTHOR_TAG ) #TAUTHOR_TAG a ) .'],['It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence ( in the sense of #AUTHOR_TAG ) #TAUTHOR_TAG a ) .'],['It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence ( in the sense of #AUTHOR_TAG ) #TAUTHOR_TAG a ) .'],['It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence ( in the sense of #AUTHOR_TAG ) #TAUTHOR_TAG a ) .'],0
"['Using WordNet , annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in #TAUTHOR_TAG b ) .']","['Using WordNet , annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in #TAUTHOR_TAG b ) .']","['Using WordNet , annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in #TAUTHOR_TAG b ) .']","['Using WordNet , annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in #TAUTHOR_TAG b ) .']",0
"[""In addition to a referring function , noun phrases ( NP ) can also serve communicative goals such as providing new information about the referent and expressing the speaker 's emotional attitude towards the referent #TAUTHOR_TAG .""]","[""In addition to a referring function , noun phrases ( NP ) can also serve communicative goals such as providing new information about the referent and expressing the speaker 's emotional attitude towards the referent #TAUTHOR_TAG .""]","[""In addition to a referring function , noun phrases ( NP ) can also serve communicative goals such as providing new information about the referent and expressing the speaker 's emotional attitude towards the referent #TAUTHOR_TAG .""]","[""In addition to a referring function , noun phrases ( NP ) can also serve communicative goals such as providing new information about the referent and expressing the speaker 's emotional attitude towards the referent #TAUTHOR_TAG .""]",0
"['In what follows we explain the properties of the model by applying it to a small number of adjective-noun combinations taken from the lexical semantics literature.', 'Table 1 gives the interpretations of eight adjective-noun combinations discussed in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Table 2 shows the five most likely interpretations for these combinations as derived by the model discussed in the previous sections (v is the most likely interpretation, ']","['In what follows we explain the properties of the model by applying it to a small number of adjective-noun combinations taken from the lexical semantics literature.', 'Table 1 gives the interpretations of eight adjective-noun combinations discussed in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Table 2 shows the five most likely interpretations for these combinations as derived by the model discussed in the previous sections (v is the most likely interpretation, 2']","['In what follows we explain the properties of the model by applying it to a small number of adjective-noun combinations taken from the lexical semantics literature.', 'Table 1 gives the interpretations of eight adjective-noun combinations discussed in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Table 2 shows the five most likely interpretations for these combinations as derived by the model discussed in the previous sections (v is the most likely interpretation, v 2']","['In what follows we explain the properties of the model by applying it to a small number of adjective-noun combinations taken from the lexical semantics literature.', 'Table 1 gives the interpretations of eight adjective-noun combinations discussed in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Table 2 shows the five most likely interpretations for these combinations as derived by the model discussed in the previous sections (v is the most likely interpretation, v 2 is the second most likely interpretation, etc.).']",5
"['Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to.', 'Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see #TAUTHOR_TAG and the references therein ) .']","['Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to.', 'Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see #TAUTHOR_TAG and the references therein ) .']","['Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to.', 'Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see #TAUTHOR_TAG and the references therein ) .']","['Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to.', 'Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see #TAUTHOR_TAG and the references therein ) .']",0
"['We chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly from the BNC.', 'We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature #TAUTHOR_TAG .', 'randomly sampled adjectives (difficult slow,', 'ject to unous ""', '', '', '', '', '', '', '', 'frequency (diff v estimated only on the basis of infinit constructions (see ( 7', '']","['We chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly from the BNC.', 'We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature #TAUTHOR_TAG .', 'randomly sampled adjectives (difficult, slow,', 'to unambiguous', '', '', '', '', '', '', '', 'frequency (difficult, v) estimated only on the basis of infinitival constructions (see ( 17)).', '']","['We chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly from the BNC.', 'We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature #TAUTHOR_TAG .', 'we randomly sampled nine adjectives (difficult', 'to unous ""', '', '', '', '', '', '', '', '(diff was estimated only on the basis of infinitival constructions (see ( 7', '']","['We chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly selected from the BNC.', 'We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '', 'As a result, the frequency f (difficult, v) was estimated only on the basis of infinitival constructions (see ( 17)).', '']",5
"['', '', '', '', '', '', '', '.', ' #TAUTHOR_TAG avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify .', 'ej treatsouns as having a qualia structure as part of theirx entries', 'structure for has a equivalent', '', '', '', '']","['', '', '', '', '', '', '', 'eat.', ' #TAUTHOR_TAG avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify .', 'treats nouns as having a qualia structure as part of their entries,', 'structure for has a equivalent', '', '', '', '']","['', '', '', '', '', '', '', '.', ' #TAUTHOR_TAG avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify .', 'ej treats nouns as having a qualia structure as part of theirx', 'for has a value equivalent', '', '', '', '']","['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify .', '', '', '', '', '', '']",0
"['We have presented an ensemble approach to word sense disambiguation #TAUTHOR_TAG where multiple Naive Bayesian classifiers , each based on co -- occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line .']","['We have presented an ensemble approach to word sense disambiguation #TAUTHOR_TAG where multiple Naive Bayesian classifiers , each based on co -- occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line .']","['We have presented an ensemble approach to word sense disambiguation #TAUTHOR_TAG where multiple Naive Bayesian classifiers , each based on co -- occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line .']","['We have presented an ensemble approach to word sense disambiguation #TAUTHOR_TAG where multiple Naive Bayesian classifiers , each based on co -- occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line .']",0
['See #TAUTHOR_TAG for a discussion .'],['See #TAUTHOR_TAG for a discussion .'],['See #TAUTHOR_TAG for a discussion .'],['See #TAUTHOR_TAG for a discussion .'],0
['Other definitions of predicates may be found in #TAUTHOR_TAG .'],['Other definitions of predicates may be found in #TAUTHOR_TAG .'],['Other definitions of predicates may be found in #TAUTHOR_TAG .'],['Other definitions of predicates may be found in #TAUTHOR_TAG .'],0
"['This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an over-generalisation compared with those given in #TAUTHOR_TAG .']","['This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an over-generalisation compared with those given in #TAUTHOR_TAG .']","['This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an over-generalisation compared with those given in #TAUTHOR_TAG .']","['This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an over-generalisation compared with those given in #TAUTHOR_TAG .']",1
['The task we used to compare different generalisation techniques is similar to that used by #TAUTHOR_TAG and #AUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #TAUTHOR_TAG and #AUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #TAUTHOR_TAG and #AUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #TAUTHOR_TAG and #AUTHOR_TAG .'],1
"['The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important #TAUTHOR_TAG .']","['The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important #TAUTHOR_TAG .']","['The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important #TAUTHOR_TAG .']","['The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important #TAUTHOR_TAG .']",4
"['However , #TAUTHOR_TAG claims that the log-likelihood chisquared statistic ( G2 ) is more appropriate for corpus-based NLP .']","['However , #TAUTHOR_TAG claims that the log-likelihood chisquared statistic ( G2 ) is more appropriate for corpus-based NLP .']","['However , #TAUTHOR_TAG claims that the log-likelihood chisquared statistic ( G2 ) is more appropriate for corpus-based NLP .']","['However , #TAUTHOR_TAG claims that the log-likelihood chisquared statistic ( G2 ) is more appropriate for corpus-based NLP .']",4
['The task we used to compare different generalisation techniques is similar to that used by #AUTHOR_TAG and #TAUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #AUTHOR_TAG and #TAUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #AUTHOR_TAG and #TAUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #AUTHOR_TAG and #TAUTHOR_TAG .'],1
"['The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by #TAUTHOR_TAG that the G2 statistic is better suited for use in corpus-based NLP .']","['The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by #TAUTHOR_TAG that the G2 statistic is better suited for use in corpus-based NLP .']","['The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by #TAUTHOR_TAG that the G2 statistic is better suited for use in corpus-based NLP .']","['The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by #TAUTHOR_TAG that the G2 statistic is better suited for use in corpus-based NLP .']",1
"['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]",1
"['These observations and this line of reasoning has not escaped the attention of theoretical linguists : #TAUTHOR_TAG propose that argument structure is , in fact , encoded syntactically .', 'They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity.', 'This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation.']","['These observations and this line of reasoning has not escaped the attention of theoretical linguists : #TAUTHOR_TAG propose that argument structure is , in fact , encoded syntactically .', 'They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity.', 'This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation.']","['These observations and this line of reasoning has not escaped the attention of theoretical linguists : #TAUTHOR_TAG propose that argument structure is , in fact , encoded syntactically .', 'They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity.', 'This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation.']","['These observations and this line of reasoning has not escaped the attention of theoretical linguists : #TAUTHOR_TAG propose that argument structure is , in fact , encoded syntactically .', 'They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity.', 'This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation.']",0
"['The light verb v DO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity.', 'It projects a functional head , voice #TAUTHOR_TAG , whose specifier is the external argument .', '']","['The light verb v DO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity.', 'It projects a functional head , voice #TAUTHOR_TAG , whose specifier is the external argument .', '']","['The light verb v DO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity.', 'It projects a functional head , voice #TAUTHOR_TAG , whose specifier is the external argument .', '']","['The light verb v DO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity.', 'It projects a functional head , voice #TAUTHOR_TAG , whose specifier is the external argument .', '']",0
"['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]",1
"['In this paper , I present a computational implementation of Distributed Morphology #TAUTHOR_TAG , a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation .', 'This framework leads to finer-grained semantics capable of better capturing linguistic generalizations.']","['In this paper , I present a computational implementation of Distributed Morphology #TAUTHOR_TAG , a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation .', 'This framework leads to finer-grained semantics capable of better capturing linguistic generalizations.']","['In this paper , I present a computational implementation of Distributed Morphology #TAUTHOR_TAG , a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation .', 'This framework leads to finer-grained semantics capable of better capturing linguistic generalizations.']","['In this paper , I present a computational implementation of Distributed Morphology #TAUTHOR_TAG , a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation .', 'This framework leads to finer-grained semantics capable of better capturing linguistic generalizations.']",5
"['A commonxical semantic representation in the computational linguistics literature is a frame-based model where syntactic are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed as simple predicates over.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #AUTHOR_TAG and PropBank #TAUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed as simple predicates over arguments.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #AUTHOR_TAG and PropBank #TAUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed as simple predicates over.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #AUTHOR_TAG and PropBank #TAUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed as simple predicates over their arguments.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #AUTHOR_TAG and PropBank #TAUTHOR_TAG .""]",0
"['In #TAUTHOR_TAG , I present evidence from Mandarin Chinese that this analysis is on the right track .', 'The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework.']","['In #TAUTHOR_TAG , I present evidence from Mandarin Chinese that this analysis is on the right track .', 'The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework.']","['In #TAUTHOR_TAG , I present evidence from Mandarin Chinese that this analysis is on the right track .', 'The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework.']","['In #TAUTHOR_TAG , I present evidence from Mandarin Chinese that this analysis is on the right track .', 'The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework.']",2
"['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']",0
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']",0
"['', '', 'a set of features and a small number ofxical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #AUTHOR_TAG using a #TAUTHOR_TAG style analysis', '']","['', '', 'a set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #AUTHOR_TAG using a #TAUTHOR_TAG style analysis', '']","['', '', 'a minimal set of features and a small number ofxical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #AUTHOR_TAG using a #TAUTHOR_TAG style analysis .', '']","['', '', 'With a minimal set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #AUTHOR_TAG using a #TAUTHOR_TAG style analysis .', '']",0
"['Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Unders, activities and states both depict situations that are inherently temporally unbounded (atelic); states static situations, whereas activities denote on-going dynamic situations.', 'Accomplishments and achievements both express a change of state, and hence are temporally bounded (tic); achievements are punctual, whereas accomplishments extend a period of time.', ' #TAUTHOR_TAG observes that accomplishments differ from achievements only in terms of event duration , which is often a question of granularity .']","['Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Under classification, activities and states both depict situations that are inherently temporally unbounded (atelic); states static situations, whereas activities denote on-going dynamic situations.', 'Accomplishments and achievements both express a change of state, and hence are temporally bounded (telic); achievements are punctual, whereas accomplishments extend a period of time.', ' #TAUTHOR_TAG observes that accomplishments differ from achievements only in terms of event duration , which is often a question of granularity .']","['Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Unders classification, activities and states both depict situations that are inherently temporally unbounded (atelic); states static situations, whereas activities denote on-going dynamic situations.', 'Accomplishments and achievements both express a change of state, and hence are temporally bounded (tic); achievements are punctual, whereas accomplishments extend a period of time.', ' #TAUTHOR_TAG observes that accomplishments differ from achievements only in terms of event duration , which is often a question of granularity .']","[""Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Under Vendler's classification, activities and states both depict situations that are inherently temporally unbounded (atelic); states denote static situations, whereas activities denote on-going dynamic situations."", 'Accomplishments and achievements both express a change of state, and hence are temporally bounded (telic); achievements are punctual, whereas accomplishments extend over a period of time.', ' #TAUTHOR_TAG observes that accomplishments differ from achievements only in terms of event duration , which is often a question of granularity .']",0
"['', '', 'With a minimal set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #TAUTHOR_TAG using a #AUTHOR_TAG style analysis .', '']","['', '', 'With a minimal set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #TAUTHOR_TAG using a #AUTHOR_TAG style analysis .', '']","['', '', 'With a minimal set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #TAUTHOR_TAG using a #AUTHOR_TAG style analysis .', '']","['', '', 'With a minimal set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #TAUTHOR_TAG using a #AUTHOR_TAG style analysis .', '']",0
"['', '', 'compos derivedhe', ""This framework , where the `` semantic load '' is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content , is essentially the model advocated by #TAUTHOR_TAG a ) , among many others ."", 'Note that such an approach is no longer lexicalist: each lexical semantic structures.', '']","['', '', 'compositionally derived', ""This framework , where the `` semantic load '' is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content , is essentially the model advocated by #TAUTHOR_TAG a ) , among many others ."", 'Note that such an approach is no longer lexicalist: each lexical semantic structures.', '']","['', '', 'derived', ""This framework , where the `` semantic load '' is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content , is essentially the model advocated by #TAUTHOR_TAG a ) , among many others ."", 'Note that such an approach is no longer lexicalist: each lexical item semantic structures.', '']","['', '', '', ""This framework , where the `` semantic load '' is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content , is essentially the model advocated by #TAUTHOR_TAG a ) , among many others ."", 'Note that such an approach is no longer lexicalist: each lexical item does not fully encode its associated syntactic and semantic structures.', '']",0
"['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]",1
"['Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs.', 'Here , I adopt the model proposed by #TAUTHOR_TAG and decompose lexical verbs into verbalizing heads and verbal roots .', 'izing heads introduce relevant eventive interpretations in the syntax and correspond to (assumed) universal primitives of the human cognitive system.', 'abstract (categoryless) concepts and basically correspond to- items drawn from encyclopedic.', '']","['Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs.', 'Here , I adopt the model proposed by #TAUTHOR_TAG and decompose lexical verbs into verbalizing heads and verbal roots .', 'heads introduce relevant eventive interpretations in the syntax, and correspond to (assumed) universal primitives of the human cognitive system.', 'abstract (categoryless) concepts and basically correspond to items drawn from encyclopedic knowledge.', '']","['Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs.', 'Here , I adopt the model proposed by #TAUTHOR_TAG and decompose lexical verbs into verbalizing heads and verbal roots .', 'izing heads introduce relevant eventive interpretations in the syntax, and correspond to (assumed) universal primitives of the human cognitive system.', 'abstract (categoryless) concepts and basically correspond to-class items drawn from encyclopedic knowledge.', '']","['Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs.', 'Here , I adopt the model proposed by #TAUTHOR_TAG and decompose lexical verbs into verbalizing heads and verbal roots .', 'Verbalizing heads introduce relevant eventive interpretations in the syntax, and correspond to (assumed) universal primitives of the human cognitive system.', 'On the other hand, verbal roots represent abstract (categoryless) concepts and basically correspond to open-class items drawn from encyclopedic knowledge.', '']",5
"['A commonxical semantic representation in the computational linguistics is a frame-based model where syntactic are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed simple predicates over.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #TAUTHOR_TAG and PropBank #AUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics is a frame-based model where syntactic are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed simple predicates over arguments.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #TAUTHOR_TAG and PropBank #AUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed simple predicates over.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #TAUTHOR_TAG and PropBank #AUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed as simple predicates over their arguments.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #TAUTHOR_TAG and PropBank #AUTHOR_TAG .""]",0
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']",0
"['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']",0
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']",0
"[' #TAUTHOR_TAG has developed an agenda-driven chart parser for the feature-driven formalism described above ; please refer to his paper for a description of the parsing algorithm .', 'I have adapted for needs and developed grammar fragments that reflect my non-lexicalist semantic framework', '""The flattened."" is shown in Figure .']","[' #TAUTHOR_TAG has developed an agenda-driven chart parser for the feature-driven formalism described above ; please refer to his paper for a description of the parsing algorithm .', 'I have adapted for needs and developed grammar fragments that reflect my non-lexicalist semantic framework.', '""The flattened."" is shown in Figure 1.']","[' #TAUTHOR_TAG has developed an agenda-driven chart parser for the feature-driven formalism described above ; please refer to his paper for a description of the parsing algorithm .', 'I have adapted for needs and developed grammar fragments that reflect my non-lexicalist semantic framework.', 'the sentence ""The tire flattened."" is shown in Figure 1.']","[' #TAUTHOR_TAG has developed an agenda-driven chart parser for the feature-driven formalism described above ; please refer to his paper for a description of the parsing algorithm .', 'I have adapted it for my needs and developed grammar fragments that reflect my non-lexicalist semantic framework.', '']",2
"['The typical solution to the redundancy problem is to group verbs according to their argument realization patterns #TAUTHOR_TAG , possibly arranged in an inheritance hierarchy .', 'The argument structure and syntax-tosemantics mapping would then only need to be specified once for each verb class.', 'lex']","['The typical solution to the redundancy problem is to group verbs according to their argument realization patterns #TAUTHOR_TAG , possibly arranged in an inheritance hierarchy .', 'The argument structure and syntax-tosemantics mapping would then only need to be specified once for each verb class.', 'lexical']","['The typical solution to the redundancy problem is to group verbs according to their argument realization patterns #TAUTHOR_TAG , possibly arranged in an inheritance hierarchy .', 'The argument structure and syntax-tosemantics mapping would then only need to be specified once for each verb class.', '']","['The typical solution to the redundancy problem is to group verbs according to their argument realization patterns #TAUTHOR_TAG , possibly arranged in an inheritance hierarchy .', 'The argument structure and syntax-tosemantics mapping would then only need to be specified once for each verb class.', '']",1
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #AUTHOR_TAG b ; Rappaport #TAUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #AUTHOR_TAG b ; Rappaport #TAUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #AUTHOR_TAG b ; Rappaport #TAUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #AUTHOR_TAG b ; Rappaport #TAUTHOR_TAG .', 'Consider the following example:']",0
"['Dowty breaks the event described by (2) into two subevents, the activity ofeping the floor and its result, the state of the floor being clean.', ""A more recent approach , advocated by #AUTHOR_TAG , describes a basic set of event templates corresponding to Vendler 's event classes #TAUTHOR_TAG : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )""]","['Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean.', ""A more recent approach , advocated by #AUTHOR_TAG , describes a basic set of event templates corresponding to Vendler 's event classes #TAUTHOR_TAG : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )""]","['Dowty breaks the event described by (2) into two subevents, the activity ofeping the floor and its result, the state of the floor being clean.', ""A more recent approach , advocated by #AUTHOR_TAG , describes a basic set of event templates corresponding to Vendler 's event classes #TAUTHOR_TAG : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )""]","['Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean.', ""A more recent approach , advocated by #AUTHOR_TAG , describes a basic set of event templates corresponding to Vendler 's event classes #TAUTHOR_TAG : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )""]",0
"['', '', '', '', '', '', 'surface format via language generation tools', ' #TAUTHOR_TAG b ) and #AUTHOR_TAG a ) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method .']","['', '', '', '', '', '', 'surface format via language generation tools.', ' #TAUTHOR_TAG b ) and #AUTHOR_TAG a ) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method .']","['', '', '', '', '', '', 'the surface structure format via language generation tools.', ' #TAUTHOR_TAG b ) and #AUTHOR_TAG a ) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method .']","['', '', '', '', '', '', '', ' #TAUTHOR_TAG b ) and #AUTHOR_TAG a ) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method .']",0
"['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by #TAUTHOR_TAG .', 'Later works, such as #AUTHOR_TAG a), #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method.', '', '']","['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by #TAUTHOR_TAG .', 'Later works, such as #AUTHOR_TAG a), #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method.', '', '']","['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by #TAUTHOR_TAG .', 'Later works, such as #AUTHOR_TAG a), #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method.', '', '']","['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by #TAUTHOR_TAG .', 'Later works, such as #AUTHOR_TAG a), #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method.', '', '']",0
"['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools.', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']",0
"['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #TAUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #TAUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #TAUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #TAUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']",0
"['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']",0
"['', '', 'presented', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools', '']","['', '', 'presented', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools.', '']","['', '', 'is presented', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']",0
"['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']",0
"['The Google n-gram data was collected by Google Research for statistical language modelling , and has been used for many tasks such as lexical disambiguation #TAUTHOR_TAG , and contains English n-grams and their observed frequency counts , for counts of at least 40 .', 'The feature of the n-gram corpus is pages 2', '5', '']","['The Google n-gram data was collected by Google Research for statistical language modelling , and has been used for many tasks such as lexical disambiguation #TAUTHOR_TAG , and contains English n-grams and their observed frequency counts , for counts of at least 40 .', 'The feature of the n-gram corpus is pages', '', '']","['The Google n-gram data was collected by Google Research for statistical language modelling , and has been used for many tasks such as lexical disambiguation #TAUTHOR_TAG , and contains English n-grams and their observed frequency counts , for counts of at least 40 .', 'The striking feature of the n-gram corpus is', '', '']","['The Google n-gram data was collected by Google Research for statistical language modelling , and has been used for many tasks such as lexical disambiguation #TAUTHOR_TAG , and contains English n-grams and their observed frequency counts , for counts of at least 40 .', '', '', '']",0
"['Steganography is concerned with hiding information in some cover medium , by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer #TAUTHOR_TAG .', 'The is act', '', '']","['Steganography is concerned with hiding information in some cover medium , by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer #TAUTHOR_TAG .', 'The is act', '', '']","['Steganography is concerned with hiding information in some cover medium , by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer #TAUTHOR_TAG .', 'is', '', '']","['Steganography is concerned with hiding information in some cover medium , by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer #TAUTHOR_TAG .', '', '', '']",0
"['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools.', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']",0
"['The semantic method is the most sophisticated approach for linguistic stegography, and perhaps impractical given the current-ofthe-art for NLP technology.', 'It requires some sophisticated tools and knowledge to model natural language semantics.', ' #AUTHOR_TAG transform', ' #TAUTHOR_TAG aimed to embed information by exploiting the linguistic phenomenon of presupposition , with the idea that some presuppositional information can be removed without changing the meaning of a sentence .']","['The semantic method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology.', 'It requires some sophisticated tools and knowledge to model natural language semantics.', ' #AUTHOR_TAG transformations', ' #TAUTHOR_TAG aimed to embed information by exploiting the linguistic phenomenon of presupposition , with the idea that some presuppositional information can be removed without changing the meaning of a sentence .']","['The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology.', 'It requires some sophisticated tools and knowledge to model natural language semantics.', ' #AUTHOR_TAG', ' #TAUTHOR_TAG aimed to embed information by exploiting the linguistic phenomenon of presupposition , with the idea that some presuppositional information can be removed without changing the meaning of a sentence .']","['The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology.', 'It requires some sophisticated tools and knowledge to model natural language semantics.', '', ' #TAUTHOR_TAG aimed to embed information by exploiting the linguistic phenomenon of presupposition , with the idea that some presuppositional information can be removed without changing the meaning of a sentence .']",0
"['1 gives summary', '', '', '', '', '', '', '', 'parap chart compares the gold price at the end of last year with the end of this year.', ' #TAUTHOR_TAG also note that the applicability of paraphrases is strongly influenced by context .', 'Section 4 describes parap']","['1 gives summary', '', '', '', '', '', '', '', 'paraphrase chart compares the gold price at the end of last year with the end of this year.', ' #TAUTHOR_TAG also note that the applicability of paraphrases is strongly influenced by context .', 'Section 4 describes paraphrase']","['1 gives summary statistics', '', '', '', '', '', '', '', 'The chart compares the gold price at the end of last year with the end of this year.', ' #TAUTHOR_TAG also note that the applicability of paraphrases is strongly influenced by context .', 'Section 4 describes']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG also note that the applicability of paraphrases is strongly influenced by context .', '']",0
"['', '', 'The paraphrase dictionary that we use was generated for us by Chris Callison-Burch , using the technique described in #TAUTHOR_TAG , which exploits a parallel corpus and methods developed for statistical machine translation .']","['', '', 'The paraphrase dictionary that we use was generated for us by Chris Callison-Burch , using the technique described in #TAUTHOR_TAG , which exploits a parallel corpus and methods developed for statistical machine translation .']","['', '', 'The paraphrase dictionary that we use was generated for us by Chris Callison-Burch , using the technique described in #TAUTHOR_TAG , which exploits a parallel corpus and methods developed for statistical machine translation .']","['', '', 'The paraphrase dictionary that we use was generated for us by Chris Callison-Burch , using the technique described in #TAUTHOR_TAG , which exploits a parallel corpus and methods developed for statistical machine translation .']",5
"['', '', 'presented', '', 'other wordsxical subst the secret message is embedded into syntactic parse trees of the sentences.', ' #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools', '']","['', '', 'presented', '', 'other words, lexical substitution the secret message is embedded into syntactic parse trees of the sentences.', ' #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools.', '']","['', '', 'is presented', '', 'other words performing lexical substitution the secret message is embedded into syntactic parse trees of the sentences.', ' #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', '', '', 'In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences.', ' #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']",0
"[' transformations in Listicography.', 'Note that we are concerned with transformations which are linguistic in nature , rather than dealing with superficial properties of the text , e.g. the amount of white space between words #TAUTHOR_TAG .', 'Our proposed', '', '']","['2 transformations in Linguistic', 'Note that we are concerned with transformations which are linguistic in nature , rather than dealing with superficial properties of the text , e.g. the amount of white space between words #TAUTHOR_TAG .', 'Our proposed', '', '']","['the previous transformations in Listic Steganography.', 'Note that we are concerned with transformations which are linguistic in nature , rather than dealing with superficial properties of the text , e.g. the amount of white space between words #TAUTHOR_TAG .', 'Our proposed', '', '']","['', 'Note that we are concerned with transformations which are linguistic in nature , rather than dealing with superficial properties of the text , e.g. the amount of white space between words #TAUTHOR_TAG .', '', '', '']",1
"['', '', 'Our proposed method is based on the automatically acquired paraphrase dictionary described in #TAUTHOR_TAG , in which the application of paraphrases from the dictionary encodes secret bits .', 'One advantage of the dictionary is that it has wide coverage, being automatically extracted; however a disadvantage is that it contains many paraphrases which are either inappropriate or only appropriate in certain contexts.', 'to']","['', '', 'Our proposed method is based on the automatically acquired paraphrase dictionary described in #TAUTHOR_TAG , in which the application of paraphrases from the dictionary encodes secret bits .', 'One advantage of the dictionary is that it has wide coverage, being automatically extracted; however, a disadvantage is that it contains many paraphrases which are either inappropriate, or only appropriate in certain contexts.', 'to']","['', '', 'Our proposed method is based on the automatically acquired paraphrase dictionary described in #TAUTHOR_TAG , in which the application of paraphrases from the dictionary encodes secret bits .', 'One advantage of the dictionary is that it has wide coverage, being automatically extracted; however a disadvantage is that it contains many paraphrases which are either inappropriate, or only appropriate in certain contexts.', 'to']","['', '', 'Our proposed method is based on the automatically acquired paraphrase dictionary described in #TAUTHOR_TAG , in which the application of paraphrases from the dictionary encodes secret bits .', 'One advantage of the dictionary is that it has wide coverage, being automatically extracted; however, a disadvantage is that it contains many paraphrases which are either inappropriate, or only appropriate in certain contexts.', '']",5
"['', '', '', '', 'any steg cover', 'ub natural and electronic text is an obvious medium to consider.', 'However , the literature on Linguistic Steganography , in which linguistic properties of a text are modified to hide information , is small compared with other media #TAUTHOR_TAG .', 'The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer.', 'Language the', '', 'transformations reli problemistic Steganography']","['', '', '', '', 'any steganography cover', 'natural and electronic text is an obvious medium to consider.', 'However , the literature on Linguistic Steganography , in which linguistic properties of a text are modified to hide information , is small compared with other media #TAUTHOR_TAG .', 'The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer.', 'Language the', '', 'transformations reliably problem Steganography.']","['', '', '', '', 'any steganography system', 'natural languages and is an obvious medium to consider.', 'However , the literature on Linguistic Steganography , in which linguistic properties of a text are modified to hide information , is small compared with other media #TAUTHOR_TAG .', 'The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer.', 'Language the property', '', 'istic transformationsistic Steganography.']","['', '', '', '', '', '', 'However , the literature on Linguistic Steganography , in which linguistic properties of a text are modified to hide information , is small compared with other media #TAUTHOR_TAG .', 'The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer.', '', '', '']",0
"['to improve the grammaticality checking, we use a parser as an addition to the basic Google ngram method.', 'We use the #TAUTHOR_TAG CCG parser to analyse the sentence before and after paraphrasing .', '', '', '', '']","['to improve the grammaticality checking, we use a parser as an addition to the basic Google ngram method.', 'We use the #TAUTHOR_TAG CCG parser to analyse the sentence before and after paraphrasing .', '', '', '', '']","['to improve the grammaticality checking, we use a parser as an addition to the basic Google ngram method.', 'We use the #TAUTHOR_TAG CCG parser to analyse the sentence before and after paraphrasing .', '', '', '', '']","['In order to improve the grammaticality checking, we use a parser as an addition to the basic Google ngram method.', 'We use the #TAUTHOR_TAG CCG parser to analyse the sentence before and after paraphrasing .', '', '', '', '']",5
"['', '', 'presented', '', '', ' #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', 'presented', '', '', ' #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', 'is presented', '', '', ' #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', '', '', '', ' #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']",0
"['In our previous work #TAUTHOR_TAG , we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only .', 'We use a language model to pick the best path we the ambiguity in the lattice and passed it to our SMT system.', '', '']","['In our previous work #TAUTHOR_TAG , we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only .', 'We use a language model to pick the best path; we the ambiguity in the lattice and passed it to our SMT system.', '', '']","['In our previous work #TAUTHOR_TAG , we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only .', 'use a language model to pick the best path; we kept the ambiguity in the lattice and passed it to our SMT system.', '', '']","['In our previous work #TAUTHOR_TAG , we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only .', 'We did not use a language model to pick the best path; instead we kept the ambiguity in the lattice and passed it to our SMT system.', '', '']",1
"['use the-source #AUTHOR_TAG to build a phrase-based SMT system trained mostly MSA (64M words) L corpor DA.', 'Our system uses a standard phrase-based architecture.', 'The parallel corpus is word-aligned using GIZA + + #TAUTHOR_TAG .', 'Phrase translations to10 words are extracted in the phrase', '', '', '', '', '', '', '', '']","['use the open-source #AUTHOR_TAG to build a phrase-based SMT system trained mostly MSA (64M words side) LDC corpora DA data.', 'Our system uses a standard phrase-based architecture.', 'The parallel corpus is word-aligned using GIZA + + #TAUTHOR_TAG .', 'Phrase translations to 10 words are extracted in the phrase', '', '', '', '', '', '', '', '']","['We use #AUTHOR_TAG to build a phrase-based SMT system trained mostly MSA data (64M words', 'Our system uses a standard phrase-based architecture.', 'The parallel corpus is word-aligned using GIZA + + #TAUTHOR_TAG .', 'Phrase translations to10 words are extracted in', '', '', '', '', '', '', '', '']","['We use the open-source Moses toolkit #AUTHOR_TAG to build a phrase-based SMT system trained on mostly MSA data (64M words on the Arabic side) obtained from several LDC corpora including some limited DA data.', 'Our system uses a standard phrase-based architecture.', 'The parallel corpus is word-aligned using GIZA + + #TAUTHOR_TAG .', 'Phrase translations of up to 10 words are extracted in the Moses phrase table.', '', '', '', '', '', '', '', '']",5
"['', '', '', '', '', 'MSA the translation.', 'This is a similar conclusion to our previous work in #TAUTHOR_TAG .']","['', '', '', '', '', 'MSA the translation.', 'This is a similar conclusion to our previous work in #TAUTHOR_TAG .']","['', '', '', '', '', 'M the English translation.', 'This is a similar conclusion to our previous work in #TAUTHOR_TAG .']","['', '', '', '', '', '', 'This is a similar conclusion to our previous work in #TAUTHOR_TAG .']",1
"['We use the open-source Moses toolkit #TAUTHOR_TAG to build a phrase-based SMT system trained on mostly MSA data ( 64M words on the Arabic side ) obtained from several LDC corpora including some limited DA data .', '', '', '', '', '', '', '', '', '', '', '']","['We use the open-source Moses toolkit #TAUTHOR_TAG to build a phrase-based SMT system trained on mostly MSA data ( 64M words on the Arabic side ) obtained from several LDC corpora including some limited DA data .', '', '', '', '', '', '', '', '', '', '', '']","['We use the open-source Moses toolkit #TAUTHOR_TAG to build a phrase-based SMT system trained on mostly MSA data ( 64M words on the Arabic side ) obtained from several LDC corpora including some limited DA data .', '', '', '', '', '', '', '', '', '', '', '']","['We use the open-source Moses toolkit #TAUTHOR_TAG to build a phrase-based SMT system trained on mostly MSA data ( 64M words on the Arabic side ) obtained from several LDC corpora including some limited DA data .', '', '', '', '', '', '', '', '', '', '', '']",5
"['assumptions and computational theoriesencies either dis disfluencies make processing more', '', '', '', '', '', 'speech production and speech processing are done incrementally, using contextual information the moments of processing (see, e.g., Tanenhaus et al.195', 'This sort processing requires quite a architecture and different mechanisms for ambiguity resolution.', 'Few approaches to parsing have tried to handle disfluent utterances ( notable exceptions are #TAUTHOR_TAG Shriberg , Bear , & #AUTHOR_TAG .']","['assumptions and computational theories either disfluencies make processing more', '', '', '', '', '', 'speech production and speech processing are done incrementally, using contextual information the moments of processing (see, e.g., Tanenhaus et al. 1995).', 'This sort processing requires quite a architecture and different mechanisms for ambiguity resolution', 'Few approaches to parsing have tried to handle disfluent utterances ( notable exceptions are #TAUTHOR_TAG Shriberg , Bear , & #AUTHOR_TAG .']","['and computational theoriesencies either disfluencies make processing', '', '', '', '', '', ', speech production and speech processing are done incrementally, using contextual information the earliest moments of processing (see, e.g., Tanenhaus et al.195', 'This sort processing requires quite a different architecture and different mechanisms for ambiguity resolution', 'Few approaches to parsing have tried to handle disfluent utterances ( notable exceptions are #TAUTHOR_TAG Shriberg , Bear , & #AUTHOR_TAG .']","['', '', '', '', '', '', 'In humans, speech production and speech processing are done incrementally, using contextual information from the earliest moments of processing (see, e.g., Tanenhaus et al. 1995).', '', 'Few approaches to parsing have tried to handle disfluent utterances ( notable exceptions are #TAUTHOR_TAG Shriberg , Bear , & #AUTHOR_TAG .']",0
"['Similar to our previous work #AUTHOR_TAG b ) , we used the supervised WSD approach described in #TAUTHOR_TAG for our experiments , using the naive Bayes algorithm as our classifier .', 'sources includesof- and local coll.', 'ves', '']","['Similar to our previous work #AUTHOR_TAG b ) , we used the supervised WSD approach described in #TAUTHOR_TAG for our experiments , using the naive Bayes algorithm as our classifier .', 'sources include and local collocations.', 'achieves', '']","['Similar to our previous work #AUTHOR_TAG b ) , we used the supervised WSD approach described in #TAUTHOR_TAG for our experiments , using the naive Bayes algorithm as our classifier .', 'ledge sources used includesof- and local collocations.', 'ves', '']","['Similar to our previous work #AUTHOR_TAG b ) , we used the supervised WSD approach described in #TAUTHOR_TAG for our experiments , using the naive Bayes algorithm as our classifier .', '', '', '']",5
"['', '', '', '', '', 'We chose to follow #TAUTHOR_TAG and split the sentences evenly to facilitate further comparison .']","['', '', '', '', '', 'We chose to follow #TAUTHOR_TAG and split the sentences evenly to facilitate further comparison .']","['', '', '', '', '', 'We chose to follow #TAUTHOR_TAG and split the sentences evenly to facilitate further comparison .']","['', '', '', '', '', 'We chose to follow #TAUTHOR_TAG and split the sentences evenly to facilitate further comparison .']",5
"['We built a two-stage baseline system , using the perceptron segmentation model from our previous work #TAUTHOR_TAG and the perceptron POS tagging model from #AUTHOR_TAG .', '', '', '']","['We built a two-stage baseline system , using the perceptron segmentation model from our previous work #TAUTHOR_TAG and the perceptron POS tagging model from #AUTHOR_TAG .', '', '', '']","['We built a two-stage baseline system , using the perceptron segmentation model from our previous work #TAUTHOR_TAG and the perceptron POS tagging model from #AUTHOR_TAG .', '', '', '']","['We built a two-stage baseline system , using the perceptron segmentation model from our previous work #TAUTHOR_TAG and the perceptron POS tagging model from #AUTHOR_TAG .', '', '', '']",2
"['ical Dirich ( observ.', 'Our HDP extension is also inspired from the Bayesian model proposed by #TAUTHOR_TAG .', ', their model is strictly customized for entity coreference resolution, and therefore, extending it to include additional features for each observable object is a challenging task #AUTHOR_TAG .']","['Dirichlet observable L.', 'Our HDP extension is also inspired from the Bayesian model proposed by #TAUTHOR_TAG .', 'However, their model is strictly customized for entity coreference resolution, and therefore, extending it to include additional features for each observable object is a challenging task #AUTHOR_TAG .']","['( observ', 'Our HDP extension is also inspired from the Bayesian model proposed by #TAUTHOR_TAG .', ', their model is strictly customized for entity coreference resolution, and therefore, extending it to include additional features for each observable object is a challenging task #AUTHOR_TAG .']","['', 'Our HDP extension is also inspired from the Bayesian model proposed by #TAUTHOR_TAG .', 'However, their model is strictly customized for entity coreference resolution, and therefore, extending it to include additional features for each observable object is a challenging task #AUTHOR_TAG .']",4
"['ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG :  .']","['ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']","['ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']","['ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']",4
"['ME approach has the merit of easily combining different features to predict the probability of each class.', 'We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG :  .']","['ME approach has the merit of easily combining different features to predict the probability of each class.', 'We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']","['ME approach has the merit of easily combining different features to predict the probability of each class.', 'We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']","['ME approach has the merit of easily combining different features to predict the probability of each class.', 'We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']",4
"['More recently , an alignment selection approach was proposed in #TAUTHOR_TAG , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a hand-picked threshold .', 'The alignments used in that work were generated from different aligners (HMM, block model, and maximum entropy model).', '', '', '', '']","['More recently , an alignment selection approach was proposed in #TAUTHOR_TAG , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a hand-picked threshold .', 'The alignments used in that work were generated from different aligners (HMM, block model, and maximum entropy model).', '', '', '', '']","['More recently , an alignment selection approach was proposed in #TAUTHOR_TAG , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a hand-picked threshold .', 'The alignments used in that work were generated from different aligners (HMM, block model, and maximum entropy model).', '', '', '', '']","['More recently , an alignment selection approach was proposed in #TAUTHOR_TAG , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a hand-picked threshold .', 'The alignments used in that work were generated from different aligners (HMM, block model, and maximum entropy model).', '', '', '', '']",1
"['', '', '', '', ""Inspired by #TAUTHOR_TAG , we split one phrase type into several subsymbols , which contain category information of current constituent 's parent ."", 'P a S, will be substituted byPˆ', 'This strategy severely increases the of to train', 'this use a cluster CTBal types,', '', '']","['', '', '', '', ""Inspired by #TAUTHOR_TAG , we split one phrase type into several subsymbols , which contain category information of current constituent 's parent ."", 'NP a S, will be substituted by', 'This strategy severely increases the of to train', 'this use a cluster CTB types,', '', '']","['', '', '', '', ""Inspired by #TAUTHOR_TAG , we split one phrase type into several subsymbols , which contain category information of current constituent 's parent ."", 'a S, will be substituted byPˆ', 'This strategy severely increases the number of to', 'use a cluster CTB phrasal types,', '', '']","['', '', '', '', ""Inspired by #TAUTHOR_TAG , we split one phrase type into several subsymbols , which contain category information of current constituent 's parent ."", 'For example, an NP immediately dominated by a S, will be substituted by NPˆS.', '', '', '', '']",4
"['The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach #TAUTHOR_TAG .', '', '', '', '', '', '']","['The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach #TAUTHOR_TAG .', '', '', '', '', '', '']","['The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach #TAUTHOR_TAG .', '', '', '', '', '', '']","['The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach #TAUTHOR_TAG .', '', '', '', '', '', '']",4
['Previous sentiment-analysis work in different domains has considered inter-document similarity #AUTHOR_TAG or explicit inter-document references in the form of hyperlinks #TAUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #AUTHOR_TAG or explicit inter-document references in the form of hyperlinks #TAUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #AUTHOR_TAG or explicit inter-document references in the form of hyperlinks #TAUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #AUTHOR_TAG or explicit inter-document references in the form of hyperlinks #TAUTHOR_TAG .'],0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']",0
"['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cludingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also believe that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['More sophisticated approaches have been proposed #TAUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #AUTHOR_TAG .', ' #AUTHOR_TAG citation analysis #AUTHOR_TAG and computational rhetical analysis #AUTHOR_TAG']","['More sophisticated approaches have been proposed #TAUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #AUTHOR_TAG .', ' #AUTHOR_TAG citation analysis #AUTHOR_TAG and computational rhetorical analysis #AUTHOR_TAG']","['More sophisticated approaches have been proposed #TAUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #AUTHOR_TAG .', ' #AUTHOR_TAG citation analysis #AUTHOR_TAG and computational rhetorical analysis #AUTHOR_TAG .']","['More sophisticated approaches have been proposed #TAUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #AUTHOR_TAG .', '']",0
"['', 'More approaches have been proposed including anpol', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', 'More approaches have been proposed including an', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', 'More sophisticated approaches have been proposedpol', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', '', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a document or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', '', '']",0
"['arity classifiers proposed in the recent categorize in- dependently labeled', 'linked l', 'For, we may find textual4 evidence of a high likelihood of agreement be-tween two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings (see #AUTHOR_TAG but cfXXX #TAUTHOR_TAG .', '']","['classifiers proposed in the recent categorize in- dependently. labeled', 'linked', 'For example, we may find textual4 evidence of a high likelihood of agreement be-tween two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings (see #AUTHOR_TAG but cfXXX #TAUTHOR_TAG .', '']","['proposed in the recent literature categorize in- dependently. A be labeled', '', 'For, we may find textual4 evidence of a high likelihood of agreement be-tween two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings (see #AUTHOR_TAG but cfXXX #TAUTHOR_TAG .', '']","['', '', 'For example, we may find textual4 evidence of a high likelihood of agreement be-tween two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings (see #AUTHOR_TAG but cfXXX #TAUTHOR_TAG .', '']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']",0
"['In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.', 'Fol- lowing standard practice in sentiment analysis #TAUTHOR_TAG , the input to SVMlight con- sisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.', 'The ind value for each speech segment s was based on the signed distanceds fromthevectorrepresentingstothe trained SVM decision plane:  � ds 3�4s� d s �3�s�34s def ds = 3s dev']","['In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.5', 'Fol- lowing standard practice in sentiment analysis #TAUTHOR_TAG , the input to SVMlight con- sisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.', 'The ind value for each speech segment s was based on the signed distanceds fromthevectorrepresentingstothe trained SVM decision plane: \x0e � ds \x0e23�4s� d s �23�4s� def ds = deviation']","['In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.', 'Fol- lowing standard practice in sentiment analysis #TAUTHOR_TAG , the input to SVMlight con- sisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.', 'The ind value for each speech segment s was based on the signed distanceds fromthevectorrepresentingstothe trained SVM decision plane: \x0e � ds \x0e23�4s� d s �23�4s� ds ��23�4s def ds = 3']","['In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.5', 'Fol- lowing standard practice in sentiment analysis #TAUTHOR_TAG , the input to SVMlight con- sisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.', '']",5
['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cludingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also believe that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['properties Det a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['properties a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['a proposal falls the realm analysis, an extremely active research area devoted to', 'we treat a debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['', ""In particular , since we treat each individual speech within a debate as a single `` document '' , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .""]",0
['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyper- links #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyper- links #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyper- links #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyper- links #AUTHOR_TAG .'],0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cludingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also believe that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']",3
"['', 'More sophisticated approaches have been proposed , including an revers makes use ofpolarity indicators within speech segments', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #TAUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']","['', 'More sophisticated approaches have been proposed , including an reversal makes use of sentimentpolarity indicators within speech segments', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #TAUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']","['', 'More sophisticated approaches have been proposed , makes use ofpolarity indicators within speech segments', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #TAUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']","['', 'More sophisticated approaches have been proposed #AUTHOR_TAG , including an extension that, in an interesting reversal of our problem, makes use of sentimentpolarity indicators within speech segments #AUTHOR_TAG .', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #TAUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['We used a simple method to learn to identify cross-speaker references indicating agreement.', 'More sophisticated approaches have been proposed #AUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #TAUTHOR_TAG .', 'ging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetical analysis #AUTHOR_TAG']","['We used a simple method to learn to identify cross-speaker references indicating agreement.', 'More sophisticated approaches have been proposed #AUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #TAUTHOR_TAG .', 'tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG']","['We used a simple method to learn to identify cross-speaker references indicating agreement.', 'More sophisticated approaches have been proposed #AUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #TAUTHOR_TAG .', ' #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']","['We used a simple method to learn to identify cross-speaker references indicating agreement.', 'More sophisticated approaches have been proposed #AUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #TAUTHOR_TAG .', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']",0
"['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']",1
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"[""In the United States , for example , governmental bodies are providing and soliciting political documents via the Internet , with lofty goals in mind : electronic rulemaking ( eRulemaking ) initiatives involving the `` electronic collection , distribution , synthesis , and analysis of public commentary in the regulatory rulemaking process '' , may `` [ alter ] the citizen-government relationship '' #TAUTHOR_TAG ."", 'much media attention has been focused recently on the potential Internet sites on politics  or at 3', 'important to help understand and analyzeically orient']","[""In the United States , for example , governmental bodies are providing and soliciting political documents via the Internet , with lofty goals in mind : electronic rulemaking ( eRulemaking ) initiatives involving the `` electronic collection , distribution , synthesis , and analysis of public commentary in the regulatory rulemaking process '' , may `` [ alter ] the citizen-government relationship '' #TAUTHOR_TAG ."", 'much media attention has been focused recently on the potential Internet sites on politics 2 or at 3', 'important to help understand and analyze politically oriented']","[""In the United States , for example , governmental bodies are providing and soliciting political documents via the Internet , with lofty goals in mind : electronic rulemaking ( eRulemaking ) initiatives involving the `` electronic collection , distribution , synthesis , and analysis of public commentary in the regulatory rulemaking process '' , may `` [ alter ] the citizen-government relationship '' #TAUTHOR_TAG ."", ', much media attention has been focused recently on the potential impact Internet sites on politics 2 or at', 'important to help understand and analyze politically orient']","[""In the United States , for example , governmental bodies are providing and soliciting political documents via the Internet , with lofty goals in mind : electronic rulemaking ( eRulemaking ) initiatives involving the `` electronic collection , distribution , synthesis , and analysis of public commentary in the regulatory rulemaking process '' , may `` [ alter ] the citizen-government relationship '' #TAUTHOR_TAG ."", 'Additionally, much media attention has been focused recently on the potential impact that Internet sites may have on politics 2 , or at least on political journalism 3 .', '']",0
"['a a proposal falls analysis an extremely active research area', 'since we treat each individual speech within a debate as a single ""document"", we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['a a proposal falls analysis, an extremely active research area', 'since we treat each individual speech within a debate as a single ""document"", we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['a proposal falls analysis an extremely active research area', 'since we treat each individual speech within a debate as a single ""document"", we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['', 'In particular, since we treat each individual speech within a debate as a single ""document"", we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']",0
"['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , Kondor and #AUTHOR_TAG , and #AUTHOR_TAG .', ' #TAUTHOR_TAG maintains a survey of this area .']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , Kondor and #AUTHOR_TAG , and #AUTHOR_TAG .', ' #TAUTHOR_TAG maintains a survey of this area .']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , Kondor and #AUTHOR_TAG , and #AUTHOR_TAG .', ' #TAUTHOR_TAG maintains a survey of this area .']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , Kondor and #AUTHOR_TAG , and #AUTHOR_TAG .', ' #TAUTHOR_TAG maintains a survey of this area .']",0
['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']",0
"['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']",1
"['supportoppose problem can be approached through standard vector machines', 'explo', 'Our classification framework , directly inspired by #TAUTHOR_TAG , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label .', '']","['support/oppose problem can be approached through standard vector machines', 'exploited', 'Our classification framework , directly inspired by #TAUTHOR_TAG , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label .', '']","['The support/oppose classification problem can be approached through support vector machines', '', 'Our classification framework , directly inspired by #TAUTHOR_TAG , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label .', '']","['', '', 'Our classification framework , directly inspired by #TAUTHOR_TAG , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label .', '']",5
['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']",0
"['Notable early papers on graph-based semisupervised learning include #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']",0
"['currently not have an efficient means to encode disagreement information as constraints; we to incorpor such information in future.', 'Relationships between the unlabeled items #TAUTHOR_TAG consider sequential relations between different types of emails ( e.g. , between requests and satisfactions thereof ) to classify messages , and thus also explicitly exploit the structure of conversations .']","['currently not have an efficient means to encode disagreement information as constraints; we to incorporating such information in future work.', 'Relationships between the unlabeled items #TAUTHOR_TAG consider sequential relations between different types of emails ( e.g. , between requests and satisfactions thereof ) to classify messages , and thus also explicitly exploit the structure of conversations .']","['currently do not have an efficient means to encode disagreement information as hard constraints; we plan to such information in future work.', 'Relationships between the unlabeled items #TAUTHOR_TAG consider sequential relations between different types of emails ( e.g. , between requests and satisfactions thereof ) to classify messages , and thus also explicitly exploit the structure of conversations .']","['We currently do not have an efficient means to encode disagreement information as hard constraints; we plan to investigate incorporating such information in future work.', 'Relationships between the unlabeled items #TAUTHOR_TAG consider sequential relations between different types of emails ( e.g. , between requests and satisfactions thereof ) to classify messages , and thus also explicitly exploit the structure of conversations .']",0
"['', 'to , given the dense nature of language and the fact that ( U.S. ) bills often reach several hundred pages in length #TAUTHOR_TAG .', '']","['', 'to , given the dense nature of language and the fact that ( U.S. ) bills often reach several hundred pages in length #TAUTHOR_TAG .', '']","['', 'to , given the dense nature ofative language and the fact that ( U.S. ) bills often reach several hundred pages in length #TAUTHOR_TAG .', '']","['', '', '']",0
"['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']",1
"['properties Det a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['properties a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['a proposal falls the realm analysis, an extremely active research area devoted to', 'we treat a debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['', ""In particular , since we treat each individual speech within a debate as a single `` document '' , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .""]",0
"['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']",0
"['properties Det a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['properties a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['a proposal falls the realm analysis, an extremely active research area devoted to', 'we treat a debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['', ""In particular , since we treat each individual speech within a debate as a single `` document '' , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .""]",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a document or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', '', '']",0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']",0
"['', 'More approaches have been proposed including anpol', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', 'More approaches have been proposed including an', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', 'More sophisticated approaches have been proposedpol', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', '', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a or, mostproposed direct relationships tolabel texts', 'An exception is #TAUTHOR_TAG , who experimented with determining the political orientation of websites essentially by classifying the concatenation of all the documents found on that site .']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a or author, most previously-proposed direct relationships to texts)', 'An exception is #TAUTHOR_TAG , who experimented with determining the political orientation of websites essentially by classifying the concatenation of all the documents found on that site .']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or, mostproposed methods relationships to', 'An exception is #TAUTHOR_TAG , who experimented with determining the political orientation of websites essentially by classifying the concatenation of all the documents found on that site .']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #AUTHOR_TAG .', 'An exception is #TAUTHOR_TAG , who experimented with determining the political orientation of websites essentially by classifying the concatenation of all the documents found on that site .']",0
"['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']",3
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a document or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', '', '']",0
"['-polarity classifiers proposed in the recent literature categorize each document independently.', 'A others of inter-document labeled', 'be linked through of', 'For example, we may find textual4 evidence of a high likelihood of agreement between two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings ( see #TAUTHOR_TAG but cfXXX #AUTHOR_TAG ) .', '']","['sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A others of inter-document labeled', 'be linked through of', 'For example, we may find textual4 evidence of a high likelihood of agreement between two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings ( see #TAUTHOR_TAG but cfXXX #AUTHOR_TAG ) .', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others of inter- be labeled', 'can be linked through of', 'For example, we may find textual4 evidence of a high likelihood of agreement between two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings ( see #TAUTHOR_TAG but cfXXX #AUTHOR_TAG ) .', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', '', '', 'For example, we may find textual4 evidence of a high likelihood of agreement between two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings ( see #TAUTHOR_TAG but cfXXX #AUTHOR_TAG ) .', '']",0
['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']",0
"['', 'final', '', 'Our plan is to implement a windowed or moving-average version of BLEU as in #TAUTHOR_TAG .']","['', 'final', '', 'Our plan is to implement a windowed or moving-average version of BLEU as in #TAUTHOR_TAG .']","['', '', '', 'Our plan is to implement a windowed or moving-average version of BLEU as in #TAUTHOR_TAG .']","['', '', '', 'Our plan is to implement a windowed or moving-average version of BLEU as in #TAUTHOR_TAG .']",3
"['The flexible architecture we have presented enables interesting future research : ( i ) a straightforward improvement is the use of lexical similarity to reduce data sparseness , e.g. #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['The flexible architecture we have presented enables interesting future research : ( i ) a straightforward improvement is the use of lexical similarity to reduce data sparseness , e.g. #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['The flexible architecture we have presented enables interesting future research : ( i ) a straightforward improvement is the use of lexical similarity to reduce data sparseness , e.g. #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['The flexible architecture we have presented enables interesting future research : ( i ) a straightforward improvement is the use of lexical similarity to reduce data sparseness , e.g. #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']",0
"['The right column in Table1 shows the scores if (using the product-of-ranks algorithm) four source languages are taken into account in parallel.', 'an average of 51.8 the improvement over the English only variant (50.6) is.', 'This contrasts with the findings described in #TAUTHOR_TAG where significant improvements could be achieved by increasing the number of source languages .', 'So this casts some doubt on these.', 'However, as English was not considered as a source language there, the performance levels were mostly between 10 and 20, leaving much room for improvement.', 'This to a 5 for', '', '', '']","['The right column in Table 1 shows the scores if (using the product-of-ranks algorithm) four source languages are taken into account in parallel.', 'an average of 51.8 the improvement over the English only variant (50.6) is minimal.', 'This contrasts with the findings described in #TAUTHOR_TAG where significant improvements could be achieved by increasing the number of source languages .', 'So this casts some doubt on these.', 'However, as English was not considered as a source language there, the performance levels were mostly between 10 and 20, leaving much room for improvement.', 'This to a 50 for', '', '', '']","['The right column in Table 1 shows the scores if (using the product-of-ranks algorithm) four source languages are taken into account in parallel.', 'an average score of 51.8 the improvement over the English only variant (50.6) is.', 'This contrasts with the findings described in #TAUTHOR_TAG where significant improvements could be achieved by increasing the number of source languages .', 'So this casts some doubt on these.', 'However, as English was not considered as a source language there, the performance levels were mostly between 10 and 20, leaving much room for improvement.', 'This to a score 5 for', '', '', '']","['The right column in Table 1 shows the scores if (using the product-of-ranks algorithm) four source languages are taken into account in parallel.', 'As can be seen, with an average score of 51.8 the improvement over the English only variant (50.6) is minimal.', 'This contrasts with the findings described in #TAUTHOR_TAG where significant improvements could be achieved by increasing the number of source languages .', 'So this casts some doubt on these.', 'However, as English was not considered as a source language there, the performance levels were mostly between 10 and 20, leaving much room for improvement.', '', '', '', '']",1
"['always translations to source', 'already have word equations for four and all we want is to compute the translations into a fifth language, we can simply extend our approach to what we call the product-of-ranks algorithm.', 'As suggested in #TAUTHOR_TAG this can be done by looking up the ranks of each of the four given words ( i.e. the words occurring in a particular word equation ) within the association vector of a translation candidate , and by multiplying these ranks .', 'So for each candidate we obtain a product of ranks.', 'We then assume that the candidate with the smallest product will be the best translation.', 'the nervous in, Spanishioso their', '', '', '']","['always translations to source', 'already have word equations for four and all we want is to compute the translations into a fifth language, we can simply extend our approach to what we call the product-of-ranks algorithm.', 'As suggested in #TAUTHOR_TAG this can be done by looking up the ranks of each of the four given words ( i.e. the words occurring in a particular word equation ) within the association vector of a translation candidate , and by multiplying these ranks .', 'So for each candidate we obtain a product of ranks.', 'We then assume that the candidate with the smallest product will be the best translation.', 'the nervous in English, Spanish, their', '', '', '']","['always translations to', 'already have word equations for and all we want is to compute the translations into a fifth language, we can simply extend our approach to what we call the product-of-ranks algorithm.', 'As suggested in #TAUTHOR_TAG this can be done by looking up the ranks of each of the four given words ( i.e. the words occurring in a particular word equation ) within the association vector of a translation candidate , and by multiplying these ranks .', 'So for each candidate we obtain a product of ranks.', 'We then assume that the candidate with the smallest product will be the best translation. 3', 'nervous in Spanishioso their', '', '', '']","['', 'However, if we assume, for example, that we already have word equations for four languages, and all we want is to compute the translations into a fifth language, then we can simply extend our approach to what we call the product-of-ranks algorithm.', 'As suggested in #TAUTHOR_TAG this can be done by looking up the ranks of each of the four given words ( i.e. the words occurring in a particular word equation ) within the association vector of a translation candidate , and by multiplying these ranks .', 'So for each candidate we obtain a product of ranks.', 'We then assume that the candidate with the smallest product will be the best translation. 3', '', '', '', '']",4
"['Whereas #TAUTHOR_TAG dealt only with an English corpus , the current work shows that this methodology is applicable to a wide range of languages and corpora .', 'We were to light on criteria performance', '', '']","['Whereas #TAUTHOR_TAG dealt only with an English corpus , the current work shows that this methodology is applicable to a wide range of languages and corpora .', 'We were to light on criteria performance,', '', '']","['Whereas #TAUTHOR_TAG dealt only with an English corpus , the current work shows that this methodology is applicable to a wide range of languages and corpora .', 'We were to some light on performance', '', '']","['Whereas #TAUTHOR_TAG dealt only with an English corpus , the current work shows that this methodology is applicable to a wide range of languages and corpora .', '', '', '']",1
"['ocussed rules', '', '', 'For automatically extracting these surface level mappings we will draw on the approach to learning paraphrases from a corpus that is described in #TAUTHOR_TAG .', '']","['focussed rules', '', '', 'For automatically extracting these surface level mappings we will draw on the approach to learning paraphrases from a corpus that is described in #TAUTHOR_TAG .', '']","['has focussed', '', '', 'For automatically extracting these surface level mappings we will draw on the approach to learning paraphrases from a corpus that is described in #TAUTHOR_TAG .', '']","['', '', '', 'For automatically extracting these surface level mappings we will draw on the approach to learning paraphrases from a corpus that is described in #TAUTHOR_TAG .', '']",3
"['we expected to see clear benefits from both using Gaz andString', '', '', '', '', '', '', 'entries too', 'A possible future direction would be to compare the query string to retrieved results using a method similar to that of #TAUTHOR_TAG .', 'This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry.']","['we expected to see clear benefits from both using and SimString', '', '', '', '', '', '', 'entries too', 'A possible future direction would be to compare the query string to retrieved results using a method similar to that of #TAUTHOR_TAG .', 'This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry.']","['we expected to see clear benefits from both using Gazetteers andString', '', '', '', '', '', '', 'is too', 'A possible future direction would be to compare the query string to retrieved results using a method similar to that of #TAUTHOR_TAG .', 'This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry.']","['', '', '', '', '', '', '', '', 'A possible future direction would be to compare the query string to retrieved results using a method similar to that of #TAUTHOR_TAG .', 'This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry.']",3
"['The article classifier is a discriminative model that draws on the state-of-the-art approach described in #TAUTHOR_TAG .', 'The A', '']","['The article classifier is a discriminative model that draws on the state-of-the-art approach described in #TAUTHOR_TAG .', 'The', '']","['The article classifier is a discriminative model that draws on the state-of-the-art approach described in #TAUTHOR_TAG .', 'The model', '']","['The article classifier is a discriminative model that draws on the state-of-the-art approach described in #TAUTHOR_TAG .', '', '']",5
"['The choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine-learning methods on error correction tasks #TAUTHOR_TAG .', 'Thus, the classifiers trained on the learner data make use of a discriminative model.', '']","['The choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine-learning methods on error correction tasks #TAUTHOR_TAG .', 'Thus, the classifiers trained on the learner data make use of a discriminative model.', '']","['The choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine-learning methods on error correction tasks #TAUTHOR_TAG .', 'Thus, the classifiers trained on the learner data make use of a discriminative model.', '']","['The choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine-learning methods on error correction tasks #TAUTHOR_TAG .', 'Thus, the classifiers trained on the learner data make use of a discriminative model.', '']",4
"['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']",1
"['row the Table6 results', 'is for', '', '', '', '', '', '', '', '', 'approach discovers words are highly Agree categories and these words turn to be useful features for classification', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['row the Table 6 results.', 'is for', '', '', '', '', '', '', '', '', 'approach discovers words are highly categories and these words turn to be useful features for classification.', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['the Table 6', 'is for', '', '', '', '', '', '', '', '', 'discovers the words are highly Agreeree categories and these words turn to be useful features for classification', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', '', 'The MI approach discovers the words that are highly associated with Agree/Disagree categories and these words turn to be useful features for classification.', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']",4
"['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']",1
"['row the Table6 results', 'is for', '', '', '', '', '', '', '', '', 'approach discovers words are highly Agree categories and these words turn to be useful features for classification', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['row the Table 6 results.', 'is for', '', '', '', '', '', '', '', '', 'approach discovers words are highly categories and these words turn to be useful features for classification.', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['the Table 6', 'is for', '', '', '', '', '', '', '', '', 'discovers the words are highly Agreeree categories and these words turn to be useful features for classification', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', '', 'The MI approach discovers the words that are highly associated with Agree/Disagree categories and these words turn to be useful features for classification.', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']",4
